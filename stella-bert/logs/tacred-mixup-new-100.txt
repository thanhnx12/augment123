{'ids': [101, 2132, 1997, 1996, 9593, 102, 2197, 2005, 2023, 1010, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 4]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 5]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 3]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 5]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 3]}
{'ids': [101, 2342, 5678, 1234, 4321, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [5, 3]}
#############params############
cuda:0
Task=Tacred, 5-shot
Encoding model: bert
pattern=hardprompt
mem=1, margin=0.3, gen=1, gen_num=5
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
CurrentTrain: epoch  0, batch     0 | loss: 12.2377892
CurrentTrain: epoch  0, batch     1 | loss: 11.8358202
CurrentTrain: epoch  0, batch     2 | loss: 11.5842304
CurrentTrain: epoch  0, batch     3 | loss: 11.7963333
CurrentTrain: epoch  0, batch     4 | loss: 11.3291626
CurrentTrain: epoch  0, batch     5 | loss: 11.3988247
CurrentTrain: epoch  0, batch     6 | loss: 11.4306774
CurrentTrain: epoch  0, batch     7 | loss: 11.4957294
CurrentTrain: epoch  0, batch     8 | loss: 10.9524660
CurrentTrain: epoch  0, batch     9 | loss: 11.0981150
CurrentTrain: epoch  0, batch    10 | loss: 11.0817156
CurrentTrain: epoch  0, batch    11 | loss: 11.0157957
CurrentTrain: epoch  0, batch    12 | loss: 10.9861202
CurrentTrain: epoch  0, batch    13 | loss: 10.7110462
CurrentTrain: epoch  0, batch    14 | loss: 10.5633354
CurrentTrain: epoch  0, batch    15 | loss: 10.2521629
CurrentTrain: epoch  0, batch    16 | loss: 9.5208607
CurrentTrain: epoch  0, batch    17 | loss: 10.0118418
CurrentTrain: epoch  0, batch    18 | loss: 9.9925213
CurrentTrain: epoch  0, batch    19 | loss: 10.5049925
CurrentTrain: epoch  0, batch    20 | loss: 9.9245691
CurrentTrain: epoch  0, batch    21 | loss: 10.7969608
CurrentTrain: epoch  0, batch    22 | loss: 10.3663940
CurrentTrain: epoch  0, batch    23 | loss: 9.9787502
CurrentTrain: epoch  0, batch    24 | loss: 10.1565428
CurrentTrain: epoch  0, batch    25 | loss: 9.8991623
CurrentTrain: epoch  0, batch    26 | loss: 10.0962982
CurrentTrain: epoch  0, batch    27 | loss: 9.3844519
CurrentTrain: epoch  0, batch    28 | loss: 9.7764397
CurrentTrain: epoch  0, batch    29 | loss: 9.7736034
CurrentTrain: epoch  0, batch    30 | loss: 9.4480782
CurrentTrain: epoch  0, batch    31 | loss: 9.9147511
CurrentTrain: epoch  0, batch    32 | loss: 9.6330633
CurrentTrain: epoch  0, batch    33 | loss: 9.6556149
CurrentTrain: epoch  0, batch    34 | loss: 8.9573956
CurrentTrain: epoch  0, batch    35 | loss: 9.5650816
CurrentTrain: epoch  0, batch    36 | loss: 9.7023954
CurrentTrain: epoch  0, batch    37 | loss: 9.6724091
CurrentTrain: epoch  1, batch     0 | loss: 9.4604149
CurrentTrain: epoch  1, batch     1 | loss: 10.1246471
CurrentTrain: epoch  1, batch     2 | loss: 8.5899754
CurrentTrain: epoch  1, batch     3 | loss: 9.2962093
CurrentTrain: epoch  1, batch     4 | loss: 8.6637697
CurrentTrain: epoch  1, batch     5 | loss: 9.6263733
CurrentTrain: epoch  1, batch     6 | loss: 8.9486284
CurrentTrain: epoch  1, batch     7 | loss: 9.0029678
CurrentTrain: epoch  1, batch     8 | loss: 8.8491497
CurrentTrain: epoch  1, batch     9 | loss: 8.9430141
CurrentTrain: epoch  1, batch    10 | loss: 9.5420208
CurrentTrain: epoch  1, batch    11 | loss: 9.6031132
CurrentTrain: epoch  1, batch    12 | loss: 9.1848850
CurrentTrain: epoch  1, batch    13 | loss: 8.3578682
CurrentTrain: epoch  1, batch    14 | loss: 8.9222250
CurrentTrain: epoch  1, batch    15 | loss: 8.7862034
CurrentTrain: epoch  1, batch    16 | loss: 8.7784939
CurrentTrain: epoch  1, batch    17 | loss: 9.0060778
CurrentTrain: epoch  1, batch    18 | loss: 8.9019585
CurrentTrain: epoch  1, batch    19 | loss: 9.1300135
CurrentTrain: epoch  1, batch    20 | loss: 9.2238483
CurrentTrain: epoch  1, batch    21 | loss: 8.7556190
CurrentTrain: epoch  1, batch    22 | loss: 8.7446423
CurrentTrain: epoch  1, batch    23 | loss: 8.4535732
CurrentTrain: epoch  1, batch    24 | loss: 8.9085588
CurrentTrain: epoch  1, batch    25 | loss: 7.8729029
CurrentTrain: epoch  1, batch    26 | loss: 8.9874878
CurrentTrain: epoch  1, batch    27 | loss: 8.0600681
CurrentTrain: epoch  1, batch    28 | loss: 8.3288574
CurrentTrain: epoch  1, batch    29 | loss: 7.3486710
CurrentTrain: epoch  1, batch    30 | loss: 8.0324583
CurrentTrain: epoch  1, batch    31 | loss: 9.0403643
CurrentTrain: epoch  1, batch    32 | loss: 8.3986797
CurrentTrain: epoch  1, batch    33 | loss: 8.3034315
CurrentTrain: epoch  1, batch    34 | loss: 8.3720951
CurrentTrain: epoch  1, batch    35 | loss: 7.7797775
CurrentTrain: epoch  1, batch    36 | loss: 8.1887569
CurrentTrain: epoch  1, batch    37 | loss: 9.3430576
CurrentTrain: epoch  2, batch     0 | loss: 7.3662424
CurrentTrain: epoch  2, batch     1 | loss: 8.3544626
CurrentTrain: epoch  2, batch     2 | loss: 8.4783211
CurrentTrain: epoch  2, batch     3 | loss: 7.9830246
CurrentTrain: epoch  2, batch     4 | loss: 8.9861774
CurrentTrain: epoch  2, batch     5 | loss: 9.1120319
CurrentTrain: epoch  2, batch     6 | loss: 8.2785549
CurrentTrain: epoch  2, batch     7 | loss: 7.8161860
CurrentTrain: epoch  2, batch     8 | loss: 7.7946243
CurrentTrain: epoch  2, batch     9 | loss: 8.1371365
CurrentTrain: epoch  2, batch    10 | loss: 8.1274719
CurrentTrain: epoch  2, batch    11 | loss: 8.1458416
CurrentTrain: epoch  2, batch    12 | loss: 7.7329111
CurrentTrain: epoch  2, batch    13 | loss: 7.4998751
CurrentTrain: epoch  2, batch    14 | loss: 6.7733631
CurrentTrain: epoch  2, batch    15 | loss: 7.4271975
CurrentTrain: epoch  2, batch    16 | loss: 7.8946323
CurrentTrain: epoch  2, batch    17 | loss: 8.1287365
CurrentTrain: epoch  2, batch    18 | loss: 7.7022080
CurrentTrain: epoch  2, batch    19 | loss: 7.6633844
CurrentTrain: epoch  2, batch    20 | loss: 7.5645056
CurrentTrain: epoch  2, batch    21 | loss: 7.2468576
CurrentTrain: epoch  2, batch    22 | loss: 6.6268282
CurrentTrain: epoch  2, batch    23 | loss: 7.0505657
CurrentTrain: epoch  2, batch    24 | loss: 7.3652039
CurrentTrain: epoch  2, batch    25 | loss: 7.9841595
CurrentTrain: epoch  2, batch    26 | loss: 6.9228649
CurrentTrain: epoch  2, batch    27 | loss: 8.3433628
CurrentTrain: epoch  2, batch    28 | loss: 6.2205820
CurrentTrain: epoch  2, batch    29 | loss: 7.9827604
CurrentTrain: epoch  2, batch    30 | loss: 7.5686135
CurrentTrain: epoch  2, batch    31 | loss: 6.7521391
CurrentTrain: epoch  2, batch    32 | loss: 7.1855884
CurrentTrain: epoch  2, batch    33 | loss: 7.1788774
CurrentTrain: epoch  2, batch    34 | loss: 8.3621635
CurrentTrain: epoch  2, batch    35 | loss: 6.9254699
CurrentTrain: epoch  2, batch    36 | loss: 7.5592299
CurrentTrain: epoch  2, batch    37 | loss: 6.8255949
CurrentTrain: epoch  3, batch     0 | loss: 7.7647505
CurrentTrain: epoch  3, batch     1 | loss: 7.5025458
CurrentTrain: epoch  3, batch     2 | loss: 7.7400827
CurrentTrain: epoch  3, batch     3 | loss: 8.1283417
CurrentTrain: epoch  3, batch     4 | loss: 7.6592603
CurrentTrain: epoch  3, batch     5 | loss: 7.6934776
CurrentTrain: epoch  3, batch     6 | loss: 8.0932388
CurrentTrain: epoch  3, batch     7 | loss: 6.8233399
CurrentTrain: epoch  3, batch     8 | loss: 7.4070482
CurrentTrain: epoch  3, batch     9 | loss: 7.3779402
CurrentTrain: epoch  3, batch    10 | loss: 6.8089685
CurrentTrain: epoch  3, batch    11 | loss: 6.3608518
CurrentTrain: epoch  3, batch    12 | loss: 7.6196122
CurrentTrain: epoch  3, batch    13 | loss: 8.0267200
CurrentTrain: epoch  3, batch    14 | loss: 7.0713158
CurrentTrain: epoch  3, batch    15 | loss: 7.1864080
CurrentTrain: epoch  3, batch    16 | loss: 7.9409227
CurrentTrain: epoch  3, batch    17 | loss: 7.0805454
CurrentTrain: epoch  3, batch    18 | loss: 7.2674842
CurrentTrain: epoch  3, batch    19 | loss: 7.0971551
CurrentTrain: epoch  3, batch    20 | loss: 7.1673136
CurrentTrain: epoch  3, batch    21 | loss: 7.2108817
CurrentTrain: epoch  3, batch    22 | loss: 8.0766506
CurrentTrain: epoch  3, batch    23 | loss: 7.5205364
CurrentTrain: epoch  3, batch    24 | loss: 6.2361536
CurrentTrain: epoch  3, batch    25 | loss: 6.7487731
CurrentTrain: epoch  3, batch    26 | loss: 6.3052359
CurrentTrain: epoch  3, batch    27 | loss: 7.1938982
CurrentTrain: epoch  3, batch    28 | loss: 7.2758160
CurrentTrain: epoch  3, batch    29 | loss: 5.9751406
CurrentTrain: epoch  3, batch    30 | loss: 7.0339866
CurrentTrain: epoch  3, batch    31 | loss: 7.0741363
CurrentTrain: epoch  3, batch    32 | loss: 6.2167683
CurrentTrain: epoch  3, batch    33 | loss: 5.7902369
CurrentTrain: epoch  3, batch    34 | loss: 6.7244143
CurrentTrain: epoch  3, batch    35 | loss: 6.2465477
CurrentTrain: epoch  3, batch    36 | loss: 6.7644510
CurrentTrain: epoch  3, batch    37 | loss: 6.6600256
CurrentTrain: epoch  4, batch     0 | loss: 6.9214773
CurrentTrain: epoch  4, batch     1 | loss: 6.3543296
CurrentTrain: epoch  4, batch     2 | loss: 5.6729169
CurrentTrain: epoch  4, batch     3 | loss: 6.7485514
CurrentTrain: epoch  4, batch     4 | loss: 7.2618380
CurrentTrain: epoch  4, batch     5 | loss: 6.6126189
CurrentTrain: epoch  4, batch     6 | loss: 6.2170911
CurrentTrain: epoch  4, batch     7 | loss: 6.6977735
CurrentTrain: epoch  4, batch     8 | loss: 7.4788270
CurrentTrain: epoch  4, batch     9 | loss: 6.5936441
CurrentTrain: epoch  4, batch    10 | loss: 6.9046702
CurrentTrain: epoch  4, batch    11 | loss: 6.0163383
CurrentTrain: epoch  4, batch    12 | loss: 6.5755177
CurrentTrain: epoch  4, batch    13 | loss: 6.2283492
CurrentTrain: epoch  4, batch    14 | loss: 7.0001431
CurrentTrain: epoch  4, batch    15 | loss: 6.6601152
CurrentTrain: epoch  4, batch    16 | loss: 6.3596520
CurrentTrain: epoch  4, batch    17 | loss: 6.3576050
CurrentTrain: epoch  4, batch    18 | loss: 5.9598074
CurrentTrain: epoch  4, batch    19 | loss: 6.0913982
CurrentTrain: epoch  4, batch    20 | loss: 6.2184505
CurrentTrain: epoch  4, batch    21 | loss: 6.5159440
CurrentTrain: epoch  4, batch    22 | loss: 6.6188974
CurrentTrain: epoch  4, batch    23 | loss: 5.9724197
CurrentTrain: epoch  4, batch    24 | loss: 6.6317444
CurrentTrain: epoch  4, batch    25 | loss: 6.5978203
CurrentTrain: epoch  4, batch    26 | loss: 6.0009141
CurrentTrain: epoch  4, batch    27 | loss: 7.6149282
CurrentTrain: epoch  4, batch    28 | loss: 5.8510528
CurrentTrain: epoch  4, batch    29 | loss: 6.1155725
CurrentTrain: epoch  4, batch    30 | loss: 5.9866090
CurrentTrain: epoch  4, batch    31 | loss: 6.0753689
CurrentTrain: epoch  4, batch    32 | loss: 6.2112637
CurrentTrain: epoch  4, batch    33 | loss: 5.6074681
CurrentTrain: epoch  4, batch    34 | loss: 6.8721824
CurrentTrain: epoch  4, batch    35 | loss: 6.1603594
CurrentTrain: epoch  4, batch    36 | loss: 5.9010696
CurrentTrain: epoch  4, batch    37 | loss: 6.5777607
CurrentTrain: epoch  5, batch     0 | loss: 5.6601758
CurrentTrain: epoch  5, batch     1 | loss: 6.0248494
CurrentTrain: epoch  5, batch     2 | loss: 6.2602463
CurrentTrain: epoch  5, batch     3 | loss: 6.3877387
CurrentTrain: epoch  5, batch     4 | loss: 5.9552431
CurrentTrain: epoch  5, batch     5 | loss: 5.9370213
CurrentTrain: epoch  5, batch     6 | loss: 6.2484322
CurrentTrain: epoch  5, batch     7 | loss: 6.5060091
CurrentTrain: epoch  5, batch     8 | loss: 6.5059867
CurrentTrain: epoch  5, batch     9 | loss: 5.7736840
CurrentTrain: epoch  5, batch    10 | loss: 5.7672777
CurrentTrain: epoch  5, batch    11 | loss: 6.0279074
CurrentTrain: epoch  5, batch    12 | loss: 5.7482686
CurrentTrain: epoch  5, batch    13 | loss: 5.9997821
CurrentTrain: epoch  5, batch    14 | loss: 6.2035551
CurrentTrain: epoch  5, batch    15 | loss: 6.5068035
CurrentTrain: epoch  5, batch    16 | loss: 5.3515067
CurrentTrain: epoch  5, batch    17 | loss: 5.5702515
CurrentTrain: epoch  5, batch    18 | loss: 6.6157694
CurrentTrain: epoch  5, batch    19 | loss: 7.0879307
CurrentTrain: epoch  5, batch    20 | loss: 5.5562043
CurrentTrain: epoch  5, batch    21 | loss: 5.8516216
CurrentTrain: epoch  5, batch    22 | loss: 5.6183128
CurrentTrain: epoch  5, batch    23 | loss: 6.0548382
CurrentTrain: epoch  5, batch    24 | loss: 6.8281794
CurrentTrain: epoch  5, batch    25 | loss: 5.7778754
CurrentTrain: epoch  5, batch    26 | loss: 5.8007574
CurrentTrain: epoch  5, batch    27 | loss: 5.6567163
CurrentTrain: epoch  5, batch    28 | loss: 6.8478708
CurrentTrain: epoch  5, batch    29 | loss: 6.6075182
CurrentTrain: epoch  5, batch    30 | loss: 5.7610102
CurrentTrain: epoch  5, batch    31 | loss: 5.8279133
CurrentTrain: epoch  5, batch    32 | loss: 5.3630514
CurrentTrain: epoch  5, batch    33 | loss: 5.9219146
CurrentTrain: epoch  5, batch    34 | loss: 5.7536297
CurrentTrain: epoch  5, batch    35 | loss: 5.9297442
CurrentTrain: epoch  5, batch    36 | loss: 6.1582942
CurrentTrain: epoch  5, batch    37 | loss: 5.3770695
CurrentTrain: epoch  6, batch     0 | loss: 5.3385010
CurrentTrain: epoch  6, batch     1 | loss: 5.7504702
CurrentTrain: epoch  6, batch     2 | loss: 6.0827885
CurrentTrain: epoch  6, batch     3 | loss: 6.0616360
CurrentTrain: epoch  6, batch     4 | loss: 5.5673351
CurrentTrain: epoch  6, batch     5 | loss: 5.4255438
CurrentTrain: epoch  6, batch     6 | loss: 5.8536959
CurrentTrain: epoch  6, batch     7 | loss: 5.7188549
CurrentTrain: epoch  6, batch     8 | loss: 5.2314873
CurrentTrain: epoch  6, batch     9 | loss: 5.6400099
CurrentTrain: epoch  6, batch    10 | loss: 5.3543816
CurrentTrain: epoch  6, batch    11 | loss: 5.3050299
CurrentTrain: epoch  6, batch    12 | loss: 5.7439237
CurrentTrain: epoch  6, batch    13 | loss: 5.4360719
CurrentTrain: epoch  6, batch    14 | loss: 5.3918200
CurrentTrain: epoch  6, batch    15 | loss: 5.1954913
CurrentTrain: epoch  6, batch    16 | loss: 5.9823422
CurrentTrain: epoch  6, batch    17 | loss: 5.4264145
CurrentTrain: epoch  6, batch    18 | loss: 5.6327276
CurrentTrain: epoch  6, batch    19 | loss: 5.9033957
CurrentTrain: epoch  6, batch    20 | loss: 6.1786757
CurrentTrain: epoch  6, batch    21 | loss: 6.3660412
CurrentTrain: epoch  6, batch    22 | loss: 6.0595322
CurrentTrain: epoch  6, batch    23 | loss: 5.5738835
CurrentTrain: epoch  6, batch    24 | loss: 5.1174212
CurrentTrain: epoch  6, batch    25 | loss: 5.9595833
CurrentTrain: epoch  6, batch    26 | loss: 6.1485519
CurrentTrain: epoch  6, batch    27 | loss: 5.7259197
CurrentTrain: epoch  6, batch    28 | loss: 5.8726430
CurrentTrain: epoch  6, batch    29 | loss: 5.5694523
CurrentTrain: epoch  6, batch    30 | loss: 6.0045009
CurrentTrain: epoch  6, batch    31 | loss: 5.6451173
CurrentTrain: epoch  6, batch    32 | loss: 5.2247005
CurrentTrain: epoch  6, batch    33 | loss: 6.1387463
CurrentTrain: epoch  6, batch    34 | loss: 5.2706861
CurrentTrain: epoch  6, batch    35 | loss: 5.5575624
CurrentTrain: epoch  6, batch    36 | loss: 5.3598919
CurrentTrain: epoch  6, batch    37 | loss: 5.5043011
CurrentTrain: epoch  7, batch     0 | loss: 5.8221326
CurrentTrain: epoch  7, batch     1 | loss: 5.2134027
CurrentTrain: epoch  7, batch     2 | loss: 5.3066864
CurrentTrain: epoch  7, batch     3 | loss: 5.0514336
CurrentTrain: epoch  7, batch     4 | loss: 5.5705714
CurrentTrain: epoch  7, batch     5 | loss: 5.2637019
CurrentTrain: epoch  7, batch     6 | loss: 5.3848391
CurrentTrain: epoch  7, batch     7 | loss: 5.0422788
CurrentTrain: epoch  7, batch     8 | loss: 5.4018226
CurrentTrain: epoch  7, batch     9 | loss: 5.1225381
CurrentTrain: epoch  7, batch    10 | loss: 5.3415217
CurrentTrain: epoch  7, batch    11 | loss: 5.3493118
CurrentTrain: epoch  7, batch    12 | loss: 5.3571339
CurrentTrain: epoch  7, batch    13 | loss: 5.5703020
CurrentTrain: epoch  7, batch    14 | loss: 5.9958162
CurrentTrain: epoch  7, batch    15 | loss: 5.4087534
CurrentTrain: epoch  7, batch    16 | loss: 5.5808349
CurrentTrain: epoch  7, batch    17 | loss: 5.3512669
CurrentTrain: epoch  7, batch    18 | loss: 4.9717011
CurrentTrain: epoch  7, batch    19 | loss: 5.1010613
CurrentTrain: epoch  7, batch    20 | loss: 5.5419488
CurrentTrain: epoch  7, batch    21 | loss: 5.0689411
CurrentTrain: epoch  7, batch    22 | loss: 6.1445966
CurrentTrain: epoch  7, batch    23 | loss: 5.4027791
CurrentTrain: epoch  7, batch    24 | loss: 5.8069553
CurrentTrain: epoch  7, batch    25 | loss: 5.1294775
CurrentTrain: epoch  7, batch    26 | loss: 5.2494717
CurrentTrain: epoch  7, batch    27 | loss: 5.3885818
CurrentTrain: epoch  7, batch    28 | loss: 5.1891451
CurrentTrain: epoch  7, batch    29 | loss: 5.2763824
CurrentTrain: epoch  7, batch    30 | loss: 5.2565598
CurrentTrain: epoch  7, batch    31 | loss: 5.2446299
CurrentTrain: epoch  7, batch    32 | loss: 5.1272998
CurrentTrain: epoch  7, batch    33 | loss: 5.2244992
CurrentTrain: epoch  7, batch    34 | loss: 5.0223141
CurrentTrain: epoch  7, batch    35 | loss: 5.1779542
CurrentTrain: epoch  7, batch    36 | loss: 5.1301193
CurrentTrain: epoch  7, batch    37 | loss: 4.8143196
CurrentTrain: epoch  8, batch     0 | loss: 5.1579475
CurrentTrain: epoch  8, batch     1 | loss: 5.1543798
CurrentTrain: epoch  8, batch     2 | loss: 4.8897972
CurrentTrain: epoch  8, batch     3 | loss: 5.0410523
CurrentTrain: epoch  8, batch     4 | loss: 5.2717929
CurrentTrain: epoch  8, batch     5 | loss: 4.9771128
CurrentTrain: epoch  8, batch     6 | loss: 5.0834179
CurrentTrain: epoch  8, batch     7 | loss: 5.0067358
CurrentTrain: epoch  8, batch     8 | loss: 5.0641761
CurrentTrain: epoch  8, batch     9 | loss: 5.0935326
CurrentTrain: epoch  8, batch    10 | loss: 5.2907119
CurrentTrain: epoch  8, batch    11 | loss: 4.9250479
CurrentTrain: epoch  8, batch    12 | loss: 5.0914650
CurrentTrain: epoch  8, batch    13 | loss: 4.9756813
CurrentTrain: epoch  8, batch    14 | loss: 5.2059898
CurrentTrain: epoch  8, batch    15 | loss: 5.2468882
CurrentTrain: epoch  8, batch    16 | loss: 4.9808016
CurrentTrain: epoch  8, batch    17 | loss: 4.8144884
CurrentTrain: epoch  8, batch    18 | loss: 5.2888255
CurrentTrain: epoch  8, batch    19 | loss: 4.9981937
CurrentTrain: epoch  8, batch    20 | loss: 5.1061277
CurrentTrain: epoch  8, batch    21 | loss: 5.0941725
CurrentTrain: epoch  8, batch    22 | loss: 5.3479795
CurrentTrain: epoch  8, batch    23 | loss: 5.2284288
CurrentTrain: epoch  8, batch    24 | loss: 4.9951601
CurrentTrain: epoch  8, batch    25 | loss: 5.0256500
CurrentTrain: epoch  8, batch    26 | loss: 5.3343859
CurrentTrain: epoch  8, batch    27 | loss: 4.9719343
CurrentTrain: epoch  8, batch    28 | loss: 5.2509747
CurrentTrain: epoch  8, batch    29 | loss: 5.0940399
CurrentTrain: epoch  8, batch    30 | loss: 4.9406633
CurrentTrain: epoch  8, batch    31 | loss: 5.1270304
CurrentTrain: epoch  8, batch    32 | loss: 4.7761073
CurrentTrain: epoch  8, batch    33 | loss: 4.9832006
CurrentTrain: epoch  8, batch    34 | loss: 4.9552345
CurrentTrain: epoch  8, batch    35 | loss: 5.4438825
CurrentTrain: epoch  8, batch    36 | loss: 4.9208779
CurrentTrain: epoch  8, batch    37 | loss: 4.9012098
CurrentTrain: epoch  9, batch     0 | loss: 5.3065910
CurrentTrain: epoch  9, batch     1 | loss: 5.1796370
CurrentTrain: epoch  9, batch     2 | loss: 5.1072073
CurrentTrain: epoch  9, batch     3 | loss: 4.9213343
CurrentTrain: epoch  9, batch     4 | loss: 4.8819547
CurrentTrain: epoch  9, batch     5 | loss: 5.1034369
CurrentTrain: epoch  9, batch     6 | loss: 5.3321552
CurrentTrain: epoch  9, batch     7 | loss: 4.9197969
CurrentTrain: epoch  9, batch     8 | loss: 4.9653072
CurrentTrain: epoch  9, batch     9 | loss: 4.8860769
CurrentTrain: epoch  9, batch    10 | loss: 5.0107727
CurrentTrain: epoch  9, batch    11 | loss: 4.8371091
CurrentTrain: epoch  9, batch    12 | loss: 4.9469938
CurrentTrain: epoch  9, batch    13 | loss: 5.0067148
CurrentTrain: epoch  9, batch    14 | loss: 4.9856386
CurrentTrain: epoch  9, batch    15 | loss: 4.8672819
CurrentTrain: epoch  9, batch    16 | loss: 4.8858490
CurrentTrain: epoch  9, batch    17 | loss: 5.0205936
CurrentTrain: epoch  9, batch    18 | loss: 5.0734935
CurrentTrain: epoch  9, batch    19 | loss: 4.8799629
CurrentTrain: epoch  9, batch    20 | loss: 4.8950119
CurrentTrain: epoch  9, batch    21 | loss: 4.7830744
CurrentTrain: epoch  9, batch    22 | loss: 4.8854637
CurrentTrain: epoch  9, batch    23 | loss: 4.9289637
CurrentTrain: epoch  9, batch    24 | loss: 4.9857821
CurrentTrain: epoch  9, batch    25 | loss: 4.7893872
CurrentTrain: epoch  9, batch    26 | loss: 5.1338005
CurrentTrain: epoch  9, batch    27 | loss: 5.0343213
CurrentTrain: epoch  9, batch    28 | loss: 4.9264212
CurrentTrain: epoch  9, batch    29 | loss: 5.0215325
CurrentTrain: epoch  9, batch    30 | loss: 4.7740507
CurrentTrain: epoch  9, batch    31 | loss: 4.8163271
CurrentTrain: epoch  9, batch    32 | loss: 4.8064499
CurrentTrain: epoch  9, batch    33 | loss: 4.7759576
CurrentTrain: epoch  9, batch    34 | loss: 4.9853191
CurrentTrain: epoch  9, batch    35 | loss: 4.7680750
CurrentTrain: epoch  9, batch    36 | loss: 4.7871542
CurrentTrain: epoch  9, batch    37 | loss: 4.9062581
#### person countries of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person countries of residence" means a person is living in a country.
Here is an example:
Relation: person countries of residence
Context: khamenei , 67 , has final say on all state matters in iran as supreme leader , a post he has held since 1989 .
Head Entity: khamenei
Tail Entity: iran
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person countries of residence":
Relation: person countries of residence  
Context: After years of living in the United States, Maria decided to return to her homeland, spain, to reconnect with her roots.  
Head Entity: Maria  
Tail Entity: spain  

Relation: person countries of residence  
Context: The famous actor, Leonardo DiCaprio, has been known to spend a significant amount of time in both the United States and australia, where he enjoys the natural beauty.  
Head Entity: Leonardo DiCaprio  
Tail Entity: australia  

Relation: person countries of residence  
Context: Following his retirement, the former president moved to canada, where he enjoys a quieter life away from the public eye.  
Head Entity: former president  
Tail Entity: canada  

Relation: person countries of residence  
Context: After completing her studies in the UK, Aisha decided to settle in germany, where she found a job and made new friends.  
Head Entity: Aisha  
Tail Entity: germany  

Relation: person countries of residence  
Context: The renowned scientist, Dr. Chen, has been conducting research in sweden for the past five years, contributing to various environmental projects.  
Head Entity: Dr. Chen  
Tail Entity: sweden  
#### organization top members employees ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization top members employees" means an organization 's employer is a person.
Here is an example:
Relation: organization top members employees
Context: `` customer relationships are the backbone of banking , and banks are constantly striving to meet customer demands , '' said peter garuccio , spokesman for the american bankers association .
Head Entity: american bankers association
Tail Entity: peter garuccio
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization top members employees":
1. Relation: organization top members employees  
   Context: "As the CEO of the tech giant, she has been instrumental in driving innovation," said a company spokesperson about Jane Doe, who leads the organization.  
   Head Entity: tech giant  
   Tail Entity: Jane Doe  

2. Relation: organization top members employees  
   Context: "The board of directors is pleased to announce the appointment of John Smith as the new CFO," stated the press release from the financial services firm.  
   Head Entity: financial services firm  
   Tail Entity: John Smith  

3. Relation: organization top members employees  
   Context: "Under his leadership, the nonprofit has expanded its outreach programs significantly," remarked a colleague about Mark Johnson, the executive director.  
   Head Entity: nonprofit  
   Tail Entity: Mark Johnson  

4. Relation: organization top members employees  
   Context: "The university's research department has made groundbreaking discoveries thanks to the efforts of Dr. Emily White," said the dean during the annual meeting.  
   Head Entity: university  
   Tail Entity: Dr. Emily White  

5. Relation: organization top members employees  
   Context: "The fashion label has gained international acclaim, largely due to the creative vision of its founder, Sarah Lee," noted a fashion critic.  
   Head Entity: fashion label  
   Tail Entity: Sarah Lee  
#### organization member of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization member of" means an organization is the member of an organization.
Here is an example:
Relation: organization member of
Context: over the course of the week the european union engaged in a gentlemanly tug-of-war with the organization of the islamic conference -lrb- oic -rrb- and the african regional group - which is controlled by the oic - over a range of terms and conditions .
Head Entity: oic
Tail Entity: organization of the islamic conference
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization member of":
Relation: organization member of  
Context: The United Nations has been working closely with the World Health Organization to address global health issues and improve international cooperation.  
Head Entity: World Health Organization  
Tail Entity: United Nations  

Relation: organization member of  
Context: During the annual conference, the International Olympic Committee discussed its collaboration with various national sports organizations to promote athletic excellence.  
Head Entity: International Olympic Committee  
Tail Entity: national sports organizations  

Relation: organization member of  
Context: The North Atlantic Treaty Organization held a summit where member countries deliberated on collective defense strategies and regional security.  
Head Entity: North Atlantic Treaty Organization  
Tail Entity: member countries  

Relation: organization member of  
Context: The International Monetary Fund announced new initiatives in partnership with several regional development banks to enhance economic stability in member nations.  
Head Entity: International Monetary Fund  
Tail Entity: regional development banks  

Relation: organization member of  
Context: The Global Climate Alliance is working with various environmental organizations to tackle climate change and promote sustainable practices worldwide.  
Head Entity: Global Climate Alliance  
Tail Entity: environmental organizations  
#### person origin ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person origin" means a person 's nationality is a country.
Here is an example:
Relation: person origin
Context: urgent chadian pm dies in paris hospital chad 's prime minister pascal yoadimnadji has died from a cerebral hemorrhage in a paris hospital , the chadian ambassador said friday .
Head Entity: pascal yoadimnadji
Tail Entity: chadian
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person origin":
Relation: person origin  
Context: the renowned scientist albert einstein was born in ulm, germany, and later became a citizen of the united states.  
Head Entity: albert einstein  
Tail Entity: german  

Relation: person origin  
Context: the famous author chimamanda ngozi adichie hails from enugu, nigeria, where she developed her passion for storytelling.  
Head Entity: chimamanda ngozi adichie  
Tail Entity: nigerian  

Relation: person origin  
Context: the legendary musician bob marley was born in nine mile, jamaica, and is celebrated worldwide for his contributions to reggae music.  
Head Entity: bob marley  
Tail Entity: jamaican  

Relation: person origin  
Context: the acclaimed filmmaker akira kurosawa was born in tokyo, japan, and is known for his influential works in cinema.  
Head Entity: akira kurosawa  
Tail Entity: japanese  

Relation: person origin  
Context: the famous physicist stephen hawking was born in oxford, england, and made groundbreaking contributions to theoretical physics.  
Head Entity: stephen hawking  
Tail Entity: british  
#### person title ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person title" means a person 's title is a title.
Here is an example:
Relation: person title
Context: `` making the amendment retroactive will ... help repair the image of the sentencing guidelines in communities of color , '' naacp chairman julian bond wrote to the commission .
Head Entity: julian bond
Tail Entity: chairman
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person title":
Relation: person title  
Context: `` After years of dedicated service, the board appointed Dr. Emily Carter as the new president of the university. ''  
Head Entity: Dr. Emily Carter  
Tail Entity: president  

Relation: person title  
Context: `` In his latest book, former senator John Smith shares insights from his time as the majority leader in Congress. ''  
Head Entity: John Smith  
Tail Entity: majority leader  

Relation: person title  
Context: `` The company announced that Sarah Johnson will take over as the chief executive officer starting next month. ''  
Head Entity: Sarah Johnson  
Tail Entity: chief executive officer  

Relation: person title  
Context: `` During the ceremony, the mayor recognized Tom Richards for his contributions as the city’s fire chief. ''  
Head Entity: Tom Richards  
Tail Entity: fire chief  

Relation: person title  
Context: `` The organization celebrated its 50th anniversary by honoring its founder, Lisa Green, who served as the executive director for decades. ''  
Head Entity: Lisa Green  
Tail Entity: executive director  
#### organization country of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization country of headquarters" means an organization is located in a country.
Here is an example:
Relation: organization country of headquarters
Context: chunghwa telecom co , taiwan 's leading telecom operator , said friday its 2007 net profit rose some eight percent from a year earlier , largely due to cost reductions .
Head Entity: chunghwa telecom
Tail Entity: taiwan
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization country of headquarters":
Relation: organization country of headquarters  
Context: Samsung Electronics, a global leader in technology, announced its plans to expand operations in South Korea, where it has been headquartered since its inception.  
Head Entity: Samsung Electronics  
Tail Entity: South Korea  

Relation: organization country of headquarters  
Context: Nestlé, the world's largest food and beverage company, has its headquarters located in Switzerland, where it was founded over 150 years ago.  
Head Entity: Nestlé  
Tail Entity: Switzerland  

Relation: organization country of headquarters  
Context: Toyota Motor Corporation, a major player in the automotive industry, is headquartered in Japan, contributing significantly to the country's economy.  
Head Entity: Toyota Motor Corporation  
Tail Entity: Japan  

Relation: organization country of headquarters  
Context: Unilever, a multinational consumer goods company, operates its headquarters in the United Kingdom, where it was established in the late 19th century.  
Head Entity: Unilever  
Tail Entity: United Kingdom  

Relation: organization country of headquarters  
Context: Siemens AG, a global engineering and technology company, has its headquarters in Germany, playing a crucial role in the country's industrial landscape.  
Head Entity: Siemens AG  
Tail Entity: Germany  
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    1 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    2 | acc: 87.50%,  total acc: 83.33%   
[EVAL] batch:    3 | acc: 62.50%,  total acc: 78.12%   
[EVAL] batch:    4 | acc: 93.75%,  total acc: 81.25%   
[EVAL] batch:    5 | acc: 75.00%,  total acc: 80.21%   
[EVAL] batch:    6 | acc: 93.75%,  total acc: 82.14%   
[EVAL] batch:    7 | acc: 100.00%,  total acc: 84.38%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 86.11%   
[EVAL] batch:    9 | acc: 93.75%,  total acc: 86.88%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 88.07%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 88.54%   
[EVAL] batch:   12 | acc: 93.75%,  total acc: 88.94%   
[EVAL] batch:   13 | acc: 68.75%,  total acc: 87.50%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 86.67%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 84.77%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 84.19%   
[EVAL] batch:   17 | acc: 68.75%,  total acc: 83.33%   
[EVAL] batch:   18 | acc: 87.50%,  total acc: 83.55%   
[EVAL] batch:   19 | acc: 87.50%,  total acc: 83.75%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 84.52%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 85.23%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 85.87%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 86.46%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 87.00%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 87.50%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 87.73%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 88.17%   
[EVAL] batch:   28 | acc: 100.00%,  total acc: 88.58%   
[EVAL] batch:   29 | acc: 87.50%,  total acc: 88.54%   
[EVAL] batch:   30 | acc: 87.50%,  total acc: 88.51%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 88.67%   
[EVAL] batch:   32 | acc: 37.50%,  total acc: 87.12%   
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    1 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    2 | acc: 87.50%,  total acc: 83.33%   
[EVAL] batch:    3 | acc: 62.50%,  total acc: 78.12%   
[EVAL] batch:    4 | acc: 93.75%,  total acc: 81.25%   
[EVAL] batch:    5 | acc: 75.00%,  total acc: 80.21%   
[EVAL] batch:    6 | acc: 93.75%,  total acc: 82.14%   
[EVAL] batch:    7 | acc: 100.00%,  total acc: 84.38%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 86.11%   
[EVAL] batch:    9 | acc: 93.75%,  total acc: 86.88%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 88.07%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 88.54%   
[EVAL] batch:   12 | acc: 93.75%,  total acc: 88.94%   
[EVAL] batch:   13 | acc: 68.75%,  total acc: 87.50%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 86.67%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 84.77%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 84.19%   
[EVAL] batch:   17 | acc: 68.75%,  total acc: 83.33%   
[EVAL] batch:   18 | acc: 87.50%,  total acc: 83.55%   
[EVAL] batch:   19 | acc: 87.50%,  total acc: 83.75%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 84.52%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 85.23%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 85.87%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 86.46%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 87.00%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 87.50%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 87.73%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 88.17%   
[EVAL] batch:   28 | acc: 100.00%,  total acc: 88.58%   
[EVAL] batch:   29 | acc: 87.50%,  total acc: 88.54%   
[EVAL] batch:   30 | acc: 87.50%,  total acc: 88.51%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 88.67%   
[EVAL] batch:   32 | acc: 37.50%,  total acc: 87.12%   
cur_acc:  ['0.8712']
his_acc:  ['0.8712']
CurrentTrain: epoch  0, batch     0 | loss: 6.3973942
CurrentTrain: epoch  0, batch     1 | loss: 7.3796716
CurrentTrain: epoch  1, batch     0 | loss: 6.4657888
CurrentTrain: epoch  1, batch     1 | loss: 5.3782830
CurrentTrain: epoch  2, batch     0 | loss: 6.1777396
CurrentTrain: epoch  2, batch     1 | loss: 5.3747253
CurrentTrain: epoch  3, batch     0 | loss: 5.5423403
CurrentTrain: epoch  3, batch     1 | loss: 5.1534314
CurrentTrain: epoch  4, batch     0 | loss: 5.3756881
CurrentTrain: epoch  4, batch     1 | loss: 5.0625086
CurrentTrain: epoch  5, batch     0 | loss: 5.0119185
CurrentTrain: epoch  5, batch     1 | loss: 3.9117169
CurrentTrain: epoch  6, batch     0 | loss: 4.4607000
CurrentTrain: epoch  6, batch     1 | loss: 3.8968837
CurrentTrain: epoch  7, batch     0 | loss: 4.1129036
CurrentTrain: epoch  7, batch     1 | loss: 4.0668969
CurrentTrain: epoch  8, batch     0 | loss: 3.4643028
CurrentTrain: epoch  8, batch     1 | loss: 4.1775894
CurrentTrain: epoch  9, batch     0 | loss: 3.3281112
CurrentTrain: epoch  9, batch     1 | loss: 3.7418110
#### person date of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person date of birth" means a person was born in a date.
Here is an example:
Relation: person date of birth
Context: born in 1950 in the northeastern city of basel , ospel left school at 15 to take an apprenticeship at the transvalor brokerage house before joining swiss banking corporation -lrb- sbs -rrb- , which merged with union bank of switzerland to form ubs in 1998 .
Head Entity: ospel
Tail Entity: 1950
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person date of birth":
Relation: person date of birth  
Context: she was born on July 4, 1985, in a small town in California, where she spent her childhood before moving to New York for college.  
Head Entity: she  
Tail Entity: July 4, 1985  

Relation: person date of birth  
Context: the famous physicist was born in 1879 in Ulm, in the Kingdom of Württemberg in the German Empire, and later moved to Munich.  
Head Entity: the famous physicist  
Tail Entity: 1879  

Relation: person date of birth  
Context: born in 1992 in a bustling city, he quickly became known for his contributions to technology and innovation.  
Head Entity: he  
Tail Entity: 1992  

Relation: person date of birth  
Context: the renowned author was born in 1965 in a small village, where she developed a love for storytelling from a young age.  
Head Entity: the renowned author  
Tail Entity: 1965  

Relation: person date of birth  
Context: born in 1978 in the heart of London, she grew up surrounded by art and culture, which influenced her career as a painter.  
Head Entity: she  
Tail Entity: 1978  
#### person stateorprovince of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of birth" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of birth
Context: jane matilda bolin was born on april 11 , 1908 , in poughkeepsie , ny .
Head Entity: jane matilda bolin
Tail Entity: ny
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of birth":
Relation: person stateorprovince of birth  
Context: albert einstein was born on march 14, 1879, in ulm, württemberg, germany.  
Head Entity: albert einstein  
Tail Entity: württemberg  

Relation: person stateorprovince of birth  
Context: marilyn monroe was born on june 1, 1926, in los angeles, california.  
Head Entity: marilyn monroe  
Tail Entity: california  

Relation: person stateorprovince of birth  
Context: barack obama was born on august 4, 1961, in honolulu, hawaii.  
Head Entity: barack obama  
Tail Entity: hawaii  

Relation: person stateorprovince of birth  
Context: agatha christie was born on september 15, 1890, in torquay, devon.  
Head Entity: agatha christie  
Tail Entity: devon  

Relation: person stateorprovince of birth  
Context: nelson mandela was born on july 18, 1918, in mvezo, eastern cape, south africa.  
Head Entity: nelson mandela  
Tail Entity: eastern cape  
#### person parents ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person parents" means a person 's parent is a person.
Here is an example:
Relation: person parents
Context: lynne spears told the court that lutfi had treated her daughter like a hostage in her own home , drugged her and took over her finances .
Head Entity: her
Tail Entity: lynne spears
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person parents":
1. Relation: person parents  
   Context: During the family reunion, Sarah shared stories about how her mother always encouraged her to pursue her dreams.  
   Head Entity: her mother  
   Tail Entity: Sarah  

2. Relation: person parents  
   Context: After the ceremony, James reflected on how his father had always been his role model and source of inspiration.  
   Head Entity: his father  
   Tail Entity: James  

3. Relation: person parents  
   Context: Emily often reminisced about the lessons her dad taught her about hard work and perseverance.  
   Head Entity: her dad  
   Tail Entity: Emily  

4. Relation: person parents  
   Context: At the graduation party, Michael thanked his parents for their unwavering support throughout his education.  
   Head Entity: his parents  
   Tail Entity: Michael  

5. Relation: person parents  
   Context: In her memoir, Anna described the sacrifices her mother made to provide for her and her siblings.  
   Head Entity: her mother  
   Tail Entity: Anna  
#### person employee of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person employee of" means a person is an employee of an organization.
Here is an example:
Relation: person employee of
Context: seeking revenge , axel reunites with old pal sgt. billy rosewood -lrb- judge reinhold -rrb- and jon flint -lrb- hector elizondo -rrb- of the beverly hills police department .
Head Entity: hector elizondo
Tail Entity: beverly hills police department
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person employee of":
Relation: person employee of  
Context: After years of hard work, Maria finally secured a position at the prestigious tech firm, where she collaborates with talented engineers and designers.  
Head Entity: Maria  
Tail Entity: prestigious tech firm  

Relation: person employee of  
Context: John has been with the company for over a decade, contributing to various projects and earning several promotions along the way.  
Head Entity: John  
Tail Entity: the company  

Relation: person employee of  
Context: As a renowned chef, Marco has worked in several high-end restaurants, but his current role at the gourmet bistro has been his most fulfilling yet.  
Head Entity: Marco  
Tail Entity: gourmet bistro  

Relation: person employee of  
Context: After graduating from university, Sarah landed a job at a leading marketing agency, where she quickly made a name for herself.  
Head Entity: Sarah  
Tail Entity: leading marketing agency  

Relation: person employee of  
Context: David's expertise in finance led him to a senior analyst position at a major investment bank, where he advises clients on their portfolios.  
Head Entity: David  
Tail Entity: major investment bank  
#### person stateorprovince of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of death" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of death
Context: irene morgan kirkaldy , whose defiance of bus segregation laws more than a decade before rosa parks ' landmark case helped lay the foundation for later civil rights victories , died friday at her home in hayes , va. .
Head Entity: irene morgan kirkaldy
Tail Entity: va.
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of death":
Relation: person stateorprovince of death  
Context: john doe, a renowned author known for his thrilling novels, passed away peacefully in his sleep at his residence in los angeles, ca.  
Head Entity: john doe  
Tail Entity: ca.  

Relation: person stateorprovince of death  
Context: after a long battle with illness, mary jane, a beloved community leader, succumbed to her condition in a hospital in phoenix, az.  
Head Entity: mary jane  
Tail Entity: az.  

Relation: person stateorprovince of death  
Context: the famous musician, alex smith, tragically died in a car accident while traveling through the scenic routes of oregon, or.  
Head Entity: alex smith  
Tail Entity: or.  

Relation: person stateorprovince of death  
Context: in a heartbreaking announcement, the family of elizabeth taylor revealed that she passed away at her home in new york, ny, surrounded by loved ones.  
Head Entity: elizabeth taylor  
Tail Entity: ny.  

Relation: person stateorprovince of death  
Context: the world mourned the loss of legendary scientist, dr. emma wilson, who died at the age of 85 in her hometown of boston, ma.  
Head Entity: dr. emma wilson  
Tail Entity: ma.  
Mixup data size:  3730
MixupTrain:  epoch  0, batch     0 | loss: 5.6528282
MixupTrain:  epoch  0, batch     1 | loss: 5.6358442
MixupTrain:  epoch  0, batch     2 | loss: 4.5286121
MixupTrain:  epoch  0, batch     3 | loss: 4.2679772
MixupTrain:  epoch  0, batch     4 | loss: 4.6226325
MixupTrain:  epoch  0, batch     5 | loss: 4.1691012
MixupTrain:  epoch  0, batch     6 | loss: 4.4512277
MixupTrain:  epoch  0, batch     7 | loss: 4.2665567
MixupTrain:  epoch  0, batch     8 | loss: 4.6185350
MixupTrain:  epoch  0, batch     9 | loss: 4.1470180
MixupTrain:  epoch  0, batch    10 | loss: 4.0081720
MixupTrain:  epoch  0, batch    11 | loss: 3.6953640
MixupTrain:  epoch  0, batch    12 | loss: 3.6622334
MixupTrain:  epoch  0, batch    13 | loss: 4.2816277
MixupTrain:  epoch  0, batch    14 | loss: 3.5706124
MixupTrain:  epoch  0, batch    15 | loss: 4.0274925
MixupTrain:  epoch  0, batch    16 | loss: 3.5795913
MixupTrain:  epoch  0, batch    17 | loss: 3.3270831
MixupTrain:  epoch  0, batch    18 | loss: 3.4075234
MixupTrain:  epoch  0, batch    19 | loss: 3.4095299
MixupTrain:  epoch  0, batch    20 | loss: 3.2492628
MixupTrain:  epoch  0, batch    21 | loss: 3.2639985
MixupTrain:  epoch  0, batch    22 | loss: 3.3920617
MixupTrain:  epoch  0, batch    23 | loss: 3.1668682
MixupTrain:  epoch  0, batch    24 | loss: 3.2156925
MixupTrain:  epoch  0, batch    25 | loss: 3.3581901
MixupTrain:  epoch  0, batch    26 | loss: 3.0546689
MixupTrain:  epoch  0, batch    27 | loss: 2.5552139
MixupTrain:  epoch  0, batch    28 | loss: 2.9268103
MixupTrain:  epoch  0, batch    29 | loss: 3.0069542
MixupTrain:  epoch  0, batch    30 | loss: 3.0900722
MixupTrain:  epoch  0, batch    31 | loss: 3.0546918
MixupTrain:  epoch  0, batch    32 | loss: 3.1287112
MixupTrain:  epoch  0, batch    33 | loss: 2.8641791
MixupTrain:  epoch  0, batch    34 | loss: 3.0571265
MixupTrain:  epoch  0, batch    35 | loss: 2.9597843
MixupTrain:  epoch  0, batch    36 | loss: 2.9879832
MixupTrain:  epoch  0, batch    37 | loss: 3.1391759
MixupTrain:  epoch  0, batch    38 | loss: 3.4966154
MixupTrain:  epoch  0, batch    39 | loss: 2.8065906
MixupTrain:  epoch  0, batch    40 | loss: 2.7870049
MixupTrain:  epoch  0, batch    41 | loss: 3.0140419
MixupTrain:  epoch  0, batch    42 | loss: 2.6277680
MixupTrain:  epoch  0, batch    43 | loss: 2.7166502
MixupTrain:  epoch  0, batch    44 | loss: 2.5888383
MixupTrain:  epoch  0, batch    45 | loss: 3.0603585
MixupTrain:  epoch  0, batch    46 | loss: 3.0355215
MixupTrain:  epoch  0, batch    47 | loss: 2.7780004
MixupTrain:  epoch  0, batch    48 | loss: 2.5986199
MixupTrain:  epoch  0, batch    49 | loss: 2.5346074
MixupTrain:  epoch  0, batch    50 | loss: 2.3238676
MixupTrain:  epoch  0, batch    51 | loss: 2.4357114
MixupTrain:  epoch  0, batch    52 | loss: 2.3741097
MixupTrain:  epoch  0, batch    53 | loss: 2.4610713
MixupTrain:  epoch  0, batch    54 | loss: 2.6790571
MixupTrain:  epoch  0, batch    55 | loss: 2.5005736
MixupTrain:  epoch  0, batch    56 | loss: 2.4058886
MixupTrain:  epoch  0, batch    57 | loss: 2.5967519
MixupTrain:  epoch  0, batch    58 | loss: 2.6167145
MixupTrain:  epoch  0, batch    59 | loss: 2.5207071
MixupTrain:  epoch  0, batch    60 | loss: 2.5202968
MixupTrain:  epoch  0, batch    61 | loss: 2.3590331
MixupTrain:  epoch  0, batch    62 | loss: 2.3090546
MixupTrain:  epoch  0, batch    63 | loss: 2.4677622
MixupTrain:  epoch  0, batch    64 | loss: 2.5580707
MixupTrain:  epoch  0, batch    65 | loss: 2.3048201
MixupTrain:  epoch  0, batch    66 | loss: 2.5269785
MixupTrain:  epoch  0, batch    67 | loss: 2.5737844
MixupTrain:  epoch  0, batch    68 | loss: 2.2736721
MixupTrain:  epoch  0, batch    69 | loss: 2.2439966
MixupTrain:  epoch  0, batch    70 | loss: 2.3239319
MixupTrain:  epoch  0, batch    71 | loss: 2.3897867
MixupTrain:  epoch  0, batch    72 | loss: 2.3115513
MixupTrain:  epoch  0, batch    73 | loss: 2.2661808
MixupTrain:  epoch  0, batch    74 | loss: 2.2823923
MixupTrain:  epoch  0, batch    75 | loss: 2.3163776
MixupTrain:  epoch  0, batch    76 | loss: 2.2334719
MixupTrain:  epoch  0, batch    77 | loss: 2.2753119
MixupTrain:  epoch  0, batch    78 | loss: 2.1915569
MixupTrain:  epoch  0, batch    79 | loss: 2.2316513
MixupTrain:  epoch  0, batch    80 | loss: 2.2314274
MixupTrain:  epoch  0, batch    81 | loss: 2.2311587
MixupTrain:  epoch  0, batch    82 | loss: 2.2159514
MixupTrain:  epoch  0, batch    83 | loss: 2.2702417
MixupTrain:  epoch  0, batch    84 | loss: 2.2889266
MixupTrain:  epoch  0, batch    85 | loss: 2.2761123
MixupTrain:  epoch  0, batch    86 | loss: 2.2172647
MixupTrain:  epoch  0, batch    87 | loss: 2.1227264
MixupTrain:  epoch  0, batch    88 | loss: 2.1706650
MixupTrain:  epoch  0, batch    89 | loss: 2.3324037
MixupTrain:  epoch  0, batch    90 | loss: 2.2326488
MixupTrain:  epoch  0, batch    91 | loss: 2.1747763
MixupTrain:  epoch  0, batch    92 | loss: 2.1658587
MixupTrain:  epoch  0, batch    93 | loss: 2.1445127
MixupTrain:  epoch  0, batch    94 | loss: 2.1433883
MixupTrain:  epoch  0, batch    95 | loss: 2.1993384
MixupTrain:  epoch  0, batch    96 | loss: 2.0363774
MixupTrain:  epoch  0, batch    97 | loss: 2.1383057
MixupTrain:  epoch  0, batch    98 | loss: 2.2121329
MixupTrain:  epoch  0, batch    99 | loss: 2.2101421
MixupTrain:  epoch  0, batch   100 | loss: 2.1114078
MixupTrain:  epoch  0, batch   101 | loss: 2.1292562
MixupTrain:  epoch  0, batch   102 | loss: 2.1300583
MixupTrain:  epoch  0, batch   103 | loss: 2.1478500
MixupTrain:  epoch  0, batch   104 | loss: 2.1471796
MixupTrain:  epoch  0, batch   105 | loss: 2.1501675
MixupTrain:  epoch  0, batch   106 | loss: 2.2988553
MixupTrain:  epoch  0, batch   107 | loss: 2.1142054
MixupTrain:  epoch  0, batch   108 | loss: 2.0856500
MixupTrain:  epoch  0, batch   109 | loss: 2.1671371
MixupTrain:  epoch  0, batch   110 | loss: 2.1178565
MixupTrain:  epoch  0, batch   111 | loss: 2.2062774
MixupTrain:  epoch  0, batch   112 | loss: 2.1533170
MixupTrain:  epoch  0, batch   113 | loss: 2.1011617
MixupTrain:  epoch  0, batch   114 | loss: 2.0963027
MixupTrain:  epoch  0, batch   115 | loss: 2.0252140
MixupTrain:  epoch  0, batch   116 | loss: 2.0871294
MixupTrain:  epoch  0, batch   117 | loss: 2.0629497
MixupTrain:  epoch  0, batch   118 | loss: 2.0219648
MixupTrain:  epoch  0, batch   119 | loss: 2.0375917
MixupTrain:  epoch  0, batch   120 | loss: 2.0907249
MixupTrain:  epoch  0, batch   121 | loss: 2.0534844
MixupTrain:  epoch  0, batch   122 | loss: 2.1246815
MixupTrain:  epoch  0, batch   123 | loss: 2.1089339
MixupTrain:  epoch  0, batch   124 | loss: 2.0514145
MixupTrain:  epoch  0, batch   125 | loss: 2.0460224
MixupTrain:  epoch  0, batch   126 | loss: 2.0802722
MixupTrain:  epoch  0, batch   127 | loss: 2.0304215
MixupTrain:  epoch  0, batch   128 | loss: 2.0268137
MixupTrain:  epoch  0, batch   129 | loss: 2.0653877
MixupTrain:  epoch  0, batch   130 | loss: 2.1245987
MixupTrain:  epoch  0, batch   131 | loss: 2.1151545
MixupTrain:  epoch  0, batch   132 | loss: 2.0238309
MixupTrain:  epoch  0, batch   133 | loss: 2.0314865
MixupTrain:  epoch  0, batch   134 | loss: 1.9890676
MixupTrain:  epoch  0, batch   135 | loss: 2.0315895
MixupTrain:  epoch  0, batch   136 | loss: 2.0772445
MixupTrain:  epoch  0, batch   137 | loss: 2.0054848
MixupTrain:  epoch  0, batch   138 | loss: 2.0511336
MixupTrain:  epoch  0, batch   139 | loss: 2.0193620
MixupTrain:  epoch  0, batch   140 | loss: 2.0145607
MixupTrain:  epoch  0, batch   141 | loss: 2.0638394
MixupTrain:  epoch  0, batch   142 | loss: 2.0138702
MixupTrain:  epoch  0, batch   143 | loss: 2.0828056
MixupTrain:  epoch  0, batch   144 | loss: 2.0192413
MixupTrain:  epoch  0, batch   145 | loss: 2.0200863
MixupTrain:  epoch  0, batch   146 | loss: 2.0175827
MixupTrain:  epoch  0, batch   147 | loss: 2.0758691
MixupTrain:  epoch  0, batch   148 | loss: 2.0439992
MixupTrain:  epoch  0, batch   149 | loss: 2.0415976
MixupTrain:  epoch  0, batch   150 | loss: 1.9803061
MixupTrain:  epoch  0, batch   151 | loss: 2.0712292
MixupTrain:  epoch  0, batch   152 | loss: 2.0333860
MixupTrain:  epoch  0, batch   153 | loss: 1.9352249
MixupTrain:  epoch  0, batch   154 | loss: 2.0337510
MixupTrain:  epoch  0, batch   155 | loss: 2.0124860
MixupTrain:  epoch  0, batch   156 | loss: 2.0575566
MixupTrain:  epoch  0, batch   157 | loss: 2.0549893
MixupTrain:  epoch  0, batch   158 | loss: 2.0380378
MixupTrain:  epoch  0, batch   159 | loss: 2.0227063
MixupTrain:  epoch  0, batch   160 | loss: 2.0008767
MixupTrain:  epoch  0, batch   161 | loss: 1.9971589
MixupTrain:  epoch  0, batch   162 | loss: 2.0072408
MixupTrain:  epoch  0, batch   163 | loss: 2.0499656
MixupTrain:  epoch  0, batch   164 | loss: 1.9992336
MixupTrain:  epoch  0, batch   165 | loss: 2.0361958
MixupTrain:  epoch  0, batch   166 | loss: 2.0356536
MixupTrain:  epoch  0, batch   167 | loss: 2.0370994
MixupTrain:  epoch  0, batch   168 | loss: 1.9899273
MixupTrain:  epoch  0, batch   169 | loss: 2.0199146
MixupTrain:  epoch  0, batch   170 | loss: 2.0182633
MixupTrain:  epoch  0, batch   171 | loss: 1.9988298
MixupTrain:  epoch  0, batch   172 | loss: 1.9868208
MixupTrain:  epoch  0, batch   173 | loss: 1.9811639
MixupTrain:  epoch  0, batch   174 | loss: 1.9948027
MixupTrain:  epoch  0, batch   175 | loss: 2.0290279
MixupTrain:  epoch  0, batch   176 | loss: 2.0204875
MixupTrain:  epoch  0, batch   177 | loss: 2.0263810
MixupTrain:  epoch  0, batch   178 | loss: 1.9523782
MixupTrain:  epoch  0, batch   179 | loss: 2.0210280
MixupTrain:  epoch  0, batch   180 | loss: 1.9684036
MixupTrain:  epoch  0, batch   181 | loss: 2.0024972
MixupTrain:  epoch  0, batch   182 | loss: 1.9413695
MixupTrain:  epoch  0, batch   183 | loss: 2.0223780
MixupTrain:  epoch  0, batch   184 | loss: 1.9849485
MixupTrain:  epoch  0, batch   185 | loss: 1.9722084
MixupTrain:  epoch  0, batch   186 | loss: 2.0246682
MixupTrain:  epoch  0, batch   187 | loss: 1.9743779
MixupTrain:  epoch  0, batch   188 | loss: 2.0080829
MixupTrain:  epoch  0, batch   189 | loss: 1.9935515
MixupTrain:  epoch  0, batch   190 | loss: 1.9587300
MixupTrain:  epoch  0, batch   191 | loss: 1.9500968
MixupTrain:  epoch  0, batch   192 | loss: 1.9335449
MixupTrain:  epoch  0, batch   193 | loss: 1.9752929
MixupTrain:  epoch  0, batch   194 | loss: 1.9521878
MixupTrain:  epoch  0, batch   195 | loss: 1.9601240
MixupTrain:  epoch  0, batch   196 | loss: 1.9374403
MixupTrain:  epoch  0, batch   197 | loss: 1.9597971
MixupTrain:  epoch  0, batch   198 | loss: 1.9984863
MixupTrain:  epoch  0, batch   199 | loss: 1.9645896
MixupTrain:  epoch  0, batch   200 | loss: 1.9332464
MixupTrain:  epoch  0, batch   201 | loss: 1.9621338
MixupTrain:  epoch  0, batch   202 | loss: 1.9987848
MixupTrain:  epoch  0, batch   203 | loss: 2.0079441
MixupTrain:  epoch  0, batch   204 | loss: 1.9805086
MixupTrain:  epoch  0, batch   205 | loss: 1.9128038
MixupTrain:  epoch  0, batch   206 | loss: 1.9772956
MixupTrain:  epoch  0, batch   207 | loss: 1.9847717
MixupTrain:  epoch  0, batch   208 | loss: 1.9615889
MixupTrain:  epoch  0, batch   209 | loss: 1.9779351
MixupTrain:  epoch  0, batch   210 | loss: 1.9665895
MixupTrain:  epoch  0, batch   211 | loss: 1.9838235
MixupTrain:  epoch  0, batch   212 | loss: 1.9707652
MixupTrain:  epoch  0, batch   213 | loss: 1.9656574
MixupTrain:  epoch  0, batch   214 | loss: 1.9652200
MixupTrain:  epoch  0, batch   215 | loss: 1.9579257
MixupTrain:  epoch  0, batch   216 | loss: 1.9343679
MixupTrain:  epoch  0, batch   217 | loss: 1.9491520
MixupTrain:  epoch  0, batch   218 | loss: 1.9662119
MixupTrain:  epoch  0, batch   219 | loss: 1.9600576
MixupTrain:  epoch  0, batch   220 | loss: 1.9787762
MixupTrain:  epoch  0, batch   221 | loss: 1.9643645
MixupTrain:  epoch  0, batch   222 | loss: 1.9740754
MixupTrain:  epoch  0, batch   223 | loss: 1.9795022
MixupTrain:  epoch  0, batch   224 | loss: 1.9639325
MixupTrain:  epoch  0, batch   225 | loss: 1.9447242
MixupTrain:  epoch  0, batch   226 | loss: 1.9980508
MixupTrain:  epoch  0, batch   227 | loss: 1.9392431
MixupTrain:  epoch  0, batch   228 | loss: 1.9348354
MixupTrain:  epoch  0, batch   229 | loss: 1.9755409
MixupTrain:  epoch  0, batch   230 | loss: 1.9674041
MixupTrain:  epoch  0, batch   231 | loss: 1.9419339
MixupTrain:  epoch  0, batch   232 | loss: 1.9420123
MixupTrain:  epoch  0, batch   233 | loss: 1.8949780
MemoryTrain:  epoch  0, batch     0 | loss: 1.9363017
MemoryTrain:  epoch  0, batch     1 | loss: 3.0548558
MemoryTrain:  epoch  0, batch     2 | loss: 2.8615036
MemoryTrain:  epoch  0, batch     3 | loss: 2.8642082
MemoryTrain:  epoch  0, batch     4 | loss: 2.0395312
MemoryTrain:  epoch  1, batch     0 | loss: 1.8743184
MemoryTrain:  epoch  1, batch     1 | loss: 1.8872576
MemoryTrain:  epoch  1, batch     2 | loss: 1.8667068
MemoryTrain:  epoch  1, batch     3 | loss: 1.8301934
MemoryTrain:  epoch  1, batch     4 | loss: 1.8378656
MemoryTrain:  epoch  2, batch     0 | loss: 1.8456305
MemoryTrain:  epoch  2, batch     1 | loss: 1.8612967
MemoryTrain:  epoch  2, batch     2 | loss: 1.8446991
MemoryTrain:  epoch  2, batch     3 | loss: 1.8706411
MemoryTrain:  epoch  2, batch     4 | loss: 1.8817163
MemoryTrain:  epoch  3, batch     0 | loss: 1.8784659
MemoryTrain:  epoch  3, batch     1 | loss: 1.8449796
MemoryTrain:  epoch  3, batch     2 | loss: 1.8361303
MemoryTrain:  epoch  3, batch     3 | loss: 1.8703238
MemoryTrain:  epoch  3, batch     4 | loss: 1.8361648
MemoryTrain:  epoch  4, batch     0 | loss: 1.8397602
MemoryTrain:  epoch  4, batch     1 | loss: 1.8337388
MemoryTrain:  epoch  4, batch     2 | loss: 1.8489673
MemoryTrain:  epoch  4, batch     3 | loss: 1.8653891
MemoryTrain:  epoch  4, batch     4 | loss: 1.8254585
MemoryTrain:  epoch  5, batch     0 | loss: 1.8566960
MemoryTrain:  epoch  5, batch     1 | loss: 1.8457711
MemoryTrain:  epoch  5, batch     2 | loss: 1.8497504
MemoryTrain:  epoch  5, batch     3 | loss: 1.8553630
MemoryTrain:  epoch  5, batch     4 | loss: 1.8058226
MemoryTrain:  epoch  6, batch     0 | loss: 1.8483117
MemoryTrain:  epoch  6, batch     1 | loss: 1.8640603
MemoryTrain:  epoch  6, batch     2 | loss: 1.8412281
MemoryTrain:  epoch  6, batch     3 | loss: 1.8521144
MemoryTrain:  epoch  6, batch     4 | loss: 1.8770740
MemoryTrain:  epoch  7, batch     0 | loss: 1.8541801
MemoryTrain:  epoch  7, batch     1 | loss: 1.8581259
MemoryTrain:  epoch  7, batch     2 | loss: 1.8685398
MemoryTrain:  epoch  7, batch     3 | loss: 1.8560810
MemoryTrain:  epoch  7, batch     4 | loss: 1.8982532
MemoryTrain:  epoch  8, batch     0 | loss: 1.8630469
MemoryTrain:  epoch  8, batch     1 | loss: 1.8624973
MemoryTrain:  epoch  8, batch     2 | loss: 1.8456335
MemoryTrain:  epoch  8, batch     3 | loss: 1.8522139
MemoryTrain:  epoch  8, batch     4 | loss: 1.8193808
MemoryTrain:  epoch  9, batch     0 | loss: 1.8535779
MemoryTrain:  epoch  9, batch     1 | loss: 1.8560669
MemoryTrain:  epoch  9, batch     2 | loss: 1.8677692
MemoryTrain:  epoch  9, batch     3 | loss: 1.8427688
MemoryTrain:  epoch  9, batch     4 | loss: 1.8863273
[EVAL] batch:    0 | acc: 87.50%,  total acc: 87.50%   
[EVAL] batch:    1 | acc: 93.75%,  total acc: 90.62%   
[EVAL] batch:    2 | acc: 100.00%,  total acc: 93.75%   
[EVAL] batch:    3 | acc: 93.75%,  total acc: 93.75%   
[EVAL] batch:    4 | acc: 100.00%,  total acc: 95.00%   
[EVAL] batch:    5 | acc: 100.00%,  total acc: 95.83%   
[EVAL] batch:    6 | acc: 87.50%,  total acc: 94.64%   
[EVAL] batch:    7 | acc: 93.75%,  total acc: 94.53%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 95.14%   
[EVAL] batch:    9 | acc: 87.50%,  total acc: 94.38%   
[EVAL] batch:   10 | acc: 87.50%,  total acc: 93.75%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 93.75%   
[EVAL] batch:   12 | acc: 81.25%,  total acc: 92.79%   
[EVAL] batch:   13 | acc: 18.75%,  total acc: 87.50%   
[EVAL] batch:    0 | acc: 68.75%,  total acc: 68.75%   
[EVAL] batch:    1 | acc: 56.25%,  total acc: 62.50%   
[EVAL] batch:    2 | acc: 68.75%,  total acc: 64.58%   
[EVAL] batch:    3 | acc: 43.75%,  total acc: 59.38%   
[EVAL] batch:    4 | acc: 68.75%,  total acc: 61.25%   
[EVAL] batch:    5 | acc: 68.75%,  total acc: 62.50%   
[EVAL] batch:    6 | acc: 93.75%,  total acc: 66.96%   
[EVAL] batch:    7 | acc: 93.75%,  total acc: 70.31%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 73.61%   
[EVAL] batch:    9 | acc: 87.50%,  total acc: 75.00%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 77.27%   
[EVAL] batch:   11 | acc: 87.50%,  total acc: 78.12%   
[EVAL] batch:   12 | acc: 93.75%,  total acc: 79.33%   
[EVAL] batch:   13 | acc: 68.75%,  total acc: 78.57%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 78.33%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 76.95%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 76.84%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 76.04%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 75.33%   
[EVAL] batch:   19 | acc: 87.50%,  total acc: 75.94%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 77.08%   
[EVAL] batch:   21 | acc: 93.75%,  total acc: 77.84%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 78.80%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 79.69%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 80.50%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 81.25%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 81.71%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 82.37%   
[EVAL] batch:   28 | acc: 100.00%,  total acc: 82.97%   
[EVAL] batch:   29 | acc: 87.50%,  total acc: 83.12%   
[EVAL] batch:   30 | acc: 100.00%,  total acc: 83.67%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 83.98%   
[EVAL] batch:   32 | acc: 100.00%,  total acc: 84.47%   
[EVAL] batch:   33 | acc: 81.25%,  total acc: 84.38%   
[EVAL] batch:   34 | acc: 100.00%,  total acc: 84.82%   
[EVAL] batch:   35 | acc: 93.75%,  total acc: 85.07%   
[EVAL] batch:   36 | acc: 100.00%,  total acc: 85.47%   
[EVAL] batch:   37 | acc: 100.00%,  total acc: 85.86%   
[EVAL] batch:   38 | acc: 100.00%,  total acc: 86.22%   
[EVAL] batch:   39 | acc: 81.25%,  total acc: 86.09%   
[EVAL] batch:   40 | acc: 100.00%,  total acc: 86.43%   
[EVAL] batch:   41 | acc: 93.75%,  total acc: 86.61%   
[EVAL] batch:   42 | acc: 93.75%,  total acc: 86.77%   
[EVAL] batch:   43 | acc: 81.25%,  total acc: 86.65%   
[EVAL] batch:   44 | acc: 100.00%,  total acc: 86.94%   
[EVAL] batch:   45 | acc: 37.50%,  total acc: 85.87%   
[EVAL] batch:   46 | acc: 0.00%,  total acc: 84.04%   
cur_acc:  ['0.8712', '0.8750']
his_acc:  ['0.8712', '0.8404']
CurrentTrain: epoch  0, batch     0 | loss: 5.8615093
CurrentTrain: epoch  0, batch     1 | loss: 7.7195411
CurrentTrain: epoch  1, batch     0 | loss: 5.7865629
CurrentTrain: epoch  1, batch     1 | loss: 5.8748689
CurrentTrain: epoch  2, batch     0 | loss: 4.8884139
CurrentTrain: epoch  2, batch     1 | loss: 5.2532144
CurrentTrain: epoch  3, batch     0 | loss: 4.7326441
CurrentTrain: epoch  3, batch     1 | loss: 3.9429348
CurrentTrain: epoch  4, batch     0 | loss: 3.7416830
CurrentTrain: epoch  4, batch     1 | loss: 4.4698834
CurrentTrain: epoch  5, batch     0 | loss: 3.7213895
CurrentTrain: epoch  5, batch     1 | loss: 3.5574031
CurrentTrain: epoch  6, batch     0 | loss: 3.6593862
CurrentTrain: epoch  6, batch     1 | loss: 2.4287584
CurrentTrain: epoch  7, batch     0 | loss: 2.9181125
CurrentTrain: epoch  7, batch     1 | loss: 3.6969011
CurrentTrain: epoch  8, batch     0 | loss: 2.2093830
CurrentTrain: epoch  8, batch     1 | loss: 4.3836966
CurrentTrain: epoch  9, batch     0 | loss: 2.5831962
CurrentTrain: epoch  9, batch     1 | loss: 2.9738007
#### person country of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person country of birth" means a person was born in a country.
Here is an example:
Relation: person country of birth
Context: de maiziere noted that germany took in another former inmate from guantanamo in 2006 -- murat kurnaz , a turkish national who was born and grew up in germany .
Head Entity: murat kurnaz
Tail Entity: germany
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person country of birth":
Relation: person country of birth  
Context: born in 1985 in the bustling city of new delhi, arjun was always proud of his indian heritage and culture.  
Head Entity: arjun  
Tail Entity: india  

Relation: person country of birth  
Context: during the interview, she mentioned that despite living in the united states for over a decade, her roots are firmly planted in the vibrant landscapes of brazil, where she was born.  
Head Entity: she  
Tail Entity: brazil  

Relation: person country of birth  
Context: the documentary highlighted the life of the famous artist, who was born in spain and later moved to france to pursue his career.  
Head Entity: the famous artist  
Tail Entity: spain  

Relation: person country of birth  
Context: as a child, emma often reminisced about her early years spent in the picturesque countryside of ireland, where she was born.  
Head Entity: emma  
Tail Entity: ireland  

Relation: person country of birth  
Context: the biography revealed that the renowned scientist was born in japan before relocating to the united kingdom for his groundbreaking research.  
Head Entity: the renowned scientist  
Tail Entity: japan  
#### organization website ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization website" means an organization 's website is an url.
Here is an example:
Relation: organization website
Context: http://www.pentaxsailaway.com/ paul j. sail away with pentax sweepstakes
Head Entity: pentax
Tail Entity: http://www.pentaxsailaway.com/
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization website":
Relation: organization website  
Context: Visit our official site at https://www.techinnovators.com for the latest updates.  
Head Entity: Tech Innovators  
Tail Entity: https://www.techinnovators.com  

Relation: organization website  
Context: For more information, check out the website of Green Earth Initiative at http://www.greenearth.org.  
Head Entity: Green Earth Initiative  
Tail Entity: http://www.greenearth.org  

Relation: organization website  
Context: The blog post can be found on the company’s website: https://www.creativeworks.com/blog.  
Head Entity: Creative Works  
Tail Entity: https://www.creativeworks.com/blog  

Relation: organization website  
Context: To learn more about our services, visit us at http://www.healthcareplus.com.  
Head Entity: Healthcare Plus  
Tail Entity: http://www.healthcareplus.com  

Relation: organization website  
Context: You can find the latest news on our website: https://www.sustainablefutures.org.  
Head Entity: Sustainable Futures  
Tail Entity: https://www.sustainablefutures.org  
#### organization shareholders ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization shareholders" means an organization was invested by a person.
Here is an example:
Relation: organization shareholders
Context: ------ liberty media acquired a 41 percent stake in directv in late february by exchanging it for a 16 percent stake in news corp plus $ 625 million -lrb- euro402 5 million -rrb- in cash .
Head Entity: directv
Tail Entity: liberty media
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization shareholders":
Relation: organization shareholders  
Context: In 2020, Amazon announced that it had acquired a significant share in the electric vehicle startup Rivian, marking a major investment in the future of transportation.  
Head Entity: Rivian  
Tail Entity: Amazon  

Relation: organization shareholders  
Context: The recent merger between AT&T and Time Warner has resulted in significant changes in their shareholder structure, with various investment firms increasing their stakes.  
Head Entity: Time Warner  
Tail Entity: AT&T  

Relation: organization shareholders  
Context: Facebook's acquisition of Instagram in 2012 was a strategic move that allowed the social media giant to expand its influence, with Mark Zuckerberg being a key figure in the investment.  
Head Entity: Instagram  
Tail Entity: Facebook  

Relation: organization shareholders  
Context: In a surprising turn of events, Tesla's purchase of SolarCity has led to a complex web of shareholder relationships, with Elon Musk playing a pivotal role in the investment.  
Head Entity: SolarCity  
Tail Entity: Tesla  

Relation: organization shareholders  
Context: The partnership between Google and Nest Labs has resulted in a significant investment, with Alphabet Inc. increasing its ownership stake in the smart home technology company.  
Head Entity: Nest Labs  
Tail Entity: Google  
#### organization dissolved ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization dissolved" means an organization was dissolved in a date.
Here is an example:
Relation: organization dissolved
Context: the tse suffered its worst-ever system crash in november 2005 which paralyzed the world 's second largest bourse and forced it to shelve plan for a listing of its own .
Head Entity: tse
Tail Entity: november 2005
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization dissolved":
Relation: organization dissolved  
Context: The once-prominent tech startup, Innovatech, officially ceased operations in March 2020 after struggling to secure funding.  
Head Entity: Innovatech  
Tail Entity: March 2020  

Relation: organization dissolved  
Context: After years of financial difficulties, the local charity, Helping Hands, announced its closure in January 2019, leaving many in the community without support.  
Head Entity: Helping Hands  
Tail Entity: January 2019  

Relation: organization dissolved  
Context: The historic publishing house, Classic Reads, was dissolved in July 2021, marking the end of an era in literary history.  
Head Entity: Classic Reads  
Tail Entity: July 2021  

Relation: organization dissolved  
Context: Following a series of scandals, the political party, United Front, was officially dissolved in February 2022, leading to a significant shift in the political landscape.  
Head Entity: United Front  
Tail Entity: February 2022  

Relation: organization dissolved  
Context: The beloved local theater, The Grand Stage, announced its permanent closure in December 2020 due to the impact of the pandemic on the arts.  
Head Entity: The Grand Stage  
Tail Entity: December 2020  
#### organization founded by ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization founded by" means an organization was found by a person.
Here is an example:
Relation: organization founded by
Context: born in new york , she inherited most of her fortune from her father , ted arison , who founded carnival cruise lines and also owned the miami heat basketball team .
Head Entity: carnival cruise lines
Tail Entity: ted arison
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization founded by":
1. Relation: organization founded by  
   Context: in 1975, steve jobs and steve wozniak started apple inc., which revolutionized the personal computer industry.  
   Head Entity: apple inc.  
   Tail Entity: steve jobs  

2. Relation: organization founded by  
   Context: the famous physicist albert einstein was one of the founders of the hebrew university of jerusalem, established in 1918.  
   Head Entity: hebrew university of jerusalem  
   Tail Entity: albert einstein  

3. Relation: organization founded by  
   Context: in 1998, larry page and sergey brin launched google, which has since become a dominant force in the tech industry.  
   Head Entity: google  
   Tail Entity: larry page  

4. Relation: organization founded by  
   Context: the renowned chef julia child played a pivotal role in establishing the culinary institute of america, which trains aspiring chefs.  
   Head Entity: culinary institute of america  
   Tail Entity: julia child  

5. Relation: organization founded by  
   Context: in 2004, mark zuckerberg, along with his college roommates, created facebook, which transformed social networking.  
   Head Entity: facebook  
   Tail Entity: mark zuckerberg  
Mixup data size:  6820
MixupTrain:  epoch  0, batch     0 | loss: 6.2097645
MixupTrain:  epoch  0, batch     1 | loss: 5.7846403
MixupTrain:  epoch  0, batch     2 | loss: 5.6083088
MixupTrain:  epoch  0, batch     3 | loss: 6.7321510
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2197, 2005, 2023, 1010, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 4]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 5]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 3]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 5]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 3]}
{'ids': [101, 2342, 5678, 1234, 4321, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [5, 3]}
#############params############
cuda:0
Task=Tacred, 5-shot
Encoding model: bert
pattern=hardprompt
mem=1, margin=0.3, gen=1, gen_num=5
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
CurrentTrain: epoch  0, batch     0 | loss: 12.2377892
CurrentTrain: epoch  0, batch     1 | loss: 11.8358202
CurrentTrain: epoch  0, batch     2 | loss: 11.5842304
CurrentTrain: epoch  0, batch     3 | loss: 11.7963333
CurrentTrain: epoch  0, batch     4 | loss: 11.3291626
CurrentTrain: epoch  0, batch     5 | loss: 11.3988247
CurrentTrain: epoch  0, batch     6 | loss: 11.4306774
CurrentTrain: epoch  0, batch     7 | loss: 11.4957294
CurrentTrain: epoch  0, batch     8 | loss: 10.9524660
CurrentTrain: epoch  0, batch     9 | loss: 11.0981150
CurrentTrain: epoch  0, batch    10 | loss: 11.0817156
CurrentTrain: epoch  0, batch    11 | loss: 11.0157957
CurrentTrain: epoch  0, batch    12 | loss: 10.9861202
CurrentTrain: epoch  0, batch    13 | loss: 10.7110462
CurrentTrain: epoch  0, batch    14 | loss: 10.5633354
CurrentTrain: epoch  0, batch    15 | loss: 10.2521629
CurrentTrain: epoch  0, batch    16 | loss: 9.5208607
CurrentTrain: epoch  0, batch    17 | loss: 10.0118418
CurrentTrain: epoch  0, batch    18 | loss: 9.9925213
CurrentTrain: epoch  0, batch    19 | loss: 10.5049925
CurrentTrain: epoch  0, batch    20 | loss: 9.9245691
CurrentTrain: epoch  0, batch    21 | loss: 10.7969608
CurrentTrain: epoch  0, batch    22 | loss: 10.3663940
CurrentTrain: epoch  0, batch    23 | loss: 9.9787502
CurrentTrain: epoch  0, batch    24 | loss: 10.1565428
CurrentTrain: epoch  0, batch    25 | loss: 9.8991623
CurrentTrain: epoch  0, batch    26 | loss: 10.0962982
CurrentTrain: epoch  0, batch    27 | loss: 9.3844519
CurrentTrain: epoch  0, batch    28 | loss: 9.7764397
CurrentTrain: epoch  0, batch    29 | loss: 9.7736034
CurrentTrain: epoch  0, batch    30 | loss: 9.4480782
CurrentTrain: epoch  0, batch    31 | loss: 9.9147511
CurrentTrain: epoch  0, batch    32 | loss: 9.6330633
CurrentTrain: epoch  0, batch    33 | loss: 9.6556149
CurrentTrain: epoch  0, batch    34 | loss: 8.9573956
CurrentTrain: epoch  0, batch    35 | loss: 9.5650816
CurrentTrain: epoch  0, batch    36 | loss: 9.7023954
CurrentTrain: epoch  0, batch    37 | loss: 9.6724091
CurrentTrain: epoch  1, batch     0 | loss: 9.4604149
CurrentTrain: epoch  1, batch     1 | loss: 10.1246471
CurrentTrain: epoch  1, batch     2 | loss: 8.5899754
CurrentTrain: epoch  1, batch     3 | loss: 9.2962093
CurrentTrain: epoch  1, batch     4 | loss: 8.6637697
CurrentTrain: epoch  1, batch     5 | loss: 9.6263733
CurrentTrain: epoch  1, batch     6 | loss: 8.9486284
CurrentTrain: epoch  1, batch     7 | loss: 9.0029678
CurrentTrain: epoch  1, batch     8 | loss: 8.8491497
CurrentTrain: epoch  1, batch     9 | loss: 8.9430141
CurrentTrain: epoch  1, batch    10 | loss: 9.5420208
CurrentTrain: epoch  1, batch    11 | loss: 9.6031132
CurrentTrain: epoch  1, batch    12 | loss: 9.1848850
CurrentTrain: epoch  1, batch    13 | loss: 8.3578682
CurrentTrain: epoch  1, batch    14 | loss: 8.9222250
CurrentTrain: epoch  1, batch    15 | loss: 8.7862034
CurrentTrain: epoch  1, batch    16 | loss: 8.7784939
CurrentTrain: epoch  1, batch    17 | loss: 9.0060778
CurrentTrain: epoch  1, batch    18 | loss: 8.9019585
CurrentTrain: epoch  1, batch    19 | loss: 9.1300135
CurrentTrain: epoch  1, batch    20 | loss: 9.2238483
CurrentTrain: epoch  1, batch    21 | loss: 8.7556190
CurrentTrain: epoch  1, batch    22 | loss: 8.7446423
CurrentTrain: epoch  1, batch    23 | loss: 8.4535732
CurrentTrain: epoch  1, batch    24 | loss: 8.9085588
CurrentTrain: epoch  1, batch    25 | loss: 7.8729029
CurrentTrain: epoch  1, batch    26 | loss: 8.9874878
CurrentTrain: epoch  1, batch    27 | loss: 8.0600681
CurrentTrain: epoch  1, batch    28 | loss: 8.3288574
CurrentTrain: epoch  1, batch    29 | loss: 7.3486710
CurrentTrain: epoch  1, batch    30 | loss: 8.0324583
CurrentTrain: epoch  1, batch    31 | loss: 9.0403643
CurrentTrain: epoch  1, batch    32 | loss: 8.3986797
CurrentTrain: epoch  1, batch    33 | loss: 8.3034315
CurrentTrain: epoch  1, batch    34 | loss: 8.3720951
CurrentTrain: epoch  1, batch    35 | loss: 7.7797775
CurrentTrain: epoch  1, batch    36 | loss: 8.1887569
CurrentTrain: epoch  1, batch    37 | loss: 9.3430576
CurrentTrain: epoch  2, batch     0 | loss: 7.3662424
CurrentTrain: epoch  2, batch     1 | loss: 8.3544626
CurrentTrain: epoch  2, batch     2 | loss: 8.4783211
CurrentTrain: epoch  2, batch     3 | loss: 7.9830246
CurrentTrain: epoch  2, batch     4 | loss: 8.9861774
CurrentTrain: epoch  2, batch     5 | loss: 9.1120319
CurrentTrain: epoch  2, batch     6 | loss: 8.2785549
CurrentTrain: epoch  2, batch     7 | loss: 7.8161860
CurrentTrain: epoch  2, batch     8 | loss: 7.7946243
CurrentTrain: epoch  2, batch     9 | loss: 8.1371365
CurrentTrain: epoch  2, batch    10 | loss: 8.1274719
CurrentTrain: epoch  2, batch    11 | loss: 8.1458416
CurrentTrain: epoch  2, batch    12 | loss: 7.7329111
CurrentTrain: epoch  2, batch    13 | loss: 7.4998751
CurrentTrain: epoch  2, batch    14 | loss: 6.7733631
CurrentTrain: epoch  2, batch    15 | loss: 7.4271975
CurrentTrain: epoch  2, batch    16 | loss: 7.8946323
CurrentTrain: epoch  2, batch    17 | loss: 8.1287365
CurrentTrain: epoch  2, batch    18 | loss: 7.7022080
CurrentTrain: epoch  2, batch    19 | loss: 7.6633844
CurrentTrain: epoch  2, batch    20 | loss: 7.5645056
CurrentTrain: epoch  2, batch    21 | loss: 7.2468576
CurrentTrain: epoch  2, batch    22 | loss: 6.6268282
CurrentTrain: epoch  2, batch    23 | loss: 7.0505657
CurrentTrain: epoch  2, batch    24 | loss: 7.3652039
CurrentTrain: epoch  2, batch    25 | loss: 7.9841595
CurrentTrain: epoch  2, batch    26 | loss: 6.9228649
CurrentTrain: epoch  2, batch    27 | loss: 8.3433628
CurrentTrain: epoch  2, batch    28 | loss: 6.2205820
CurrentTrain: epoch  2, batch    29 | loss: 7.9827604
CurrentTrain: epoch  2, batch    30 | loss: 7.5686135
CurrentTrain: epoch  2, batch    31 | loss: 6.7521391
CurrentTrain: epoch  2, batch    32 | loss: 7.1855884
CurrentTrain: epoch  2, batch    33 | loss: 7.1788774
CurrentTrain: epoch  2, batch    34 | loss: 8.3621635
CurrentTrain: epoch  2, batch    35 | loss: 6.9254699
CurrentTrain: epoch  2, batch    36 | loss: 7.5592299
CurrentTrain: epoch  2, batch    37 | loss: 6.8255949
CurrentTrain: epoch  3, batch     0 | loss: 7.7647505
CurrentTrain: epoch  3, batch     1 | loss: 7.5025458
CurrentTrain: epoch  3, batch     2 | loss: 7.7400827
CurrentTrain: epoch  3, batch     3 | loss: 8.1283417
CurrentTrain: epoch  3, batch     4 | loss: 7.6592603
CurrentTrain: epoch  3, batch     5 | loss: 7.6934776
CurrentTrain: epoch  3, batch     6 | loss: 8.0932388
CurrentTrain: epoch  3, batch     7 | loss: 6.8233399
CurrentTrain: epoch  3, batch     8 | loss: 7.4070482
CurrentTrain: epoch  3, batch     9 | loss: 7.3779402
CurrentTrain: epoch  3, batch    10 | loss: 6.8089685
CurrentTrain: epoch  3, batch    11 | loss: 6.3608518
CurrentTrain: epoch  3, batch    12 | loss: 7.6196122
CurrentTrain: epoch  3, batch    13 | loss: 8.0267200
CurrentTrain: epoch  3, batch    14 | loss: 7.0713158
CurrentTrain: epoch  3, batch    15 | loss: 7.1864080
CurrentTrain: epoch  3, batch    16 | loss: 7.9409227
CurrentTrain: epoch  3, batch    17 | loss: 7.0805454
CurrentTrain: epoch  3, batch    18 | loss: 7.2674842
CurrentTrain: epoch  3, batch    19 | loss: 7.0971551
CurrentTrain: epoch  3, batch    20 | loss: 7.1673136
CurrentTrain: epoch  3, batch    21 | loss: 7.2108817
CurrentTrain: epoch  3, batch    22 | loss: 8.0766506
CurrentTrain: epoch  3, batch    23 | loss: 7.5205364
CurrentTrain: epoch  3, batch    24 | loss: 6.2361536
CurrentTrain: epoch  3, batch    25 | loss: 6.7487731
CurrentTrain: epoch  3, batch    26 | loss: 6.3052359
CurrentTrain: epoch  3, batch    27 | loss: 7.1938982
CurrentTrain: epoch  3, batch    28 | loss: 7.2758160
CurrentTrain: epoch  3, batch    29 | loss: 5.9751406
CurrentTrain: epoch  3, batch    30 | loss: 7.0339866
CurrentTrain: epoch  3, batch    31 | loss: 7.0741363
CurrentTrain: epoch  3, batch    32 | loss: 6.2167683
CurrentTrain: epoch  3, batch    33 | loss: 5.7902369
CurrentTrain: epoch  3, batch    34 | loss: 6.7244143
CurrentTrain: epoch  3, batch    35 | loss: 6.2465477
CurrentTrain: epoch  3, batch    36 | loss: 6.7644510
CurrentTrain: epoch  3, batch    37 | loss: 6.6600256
CurrentTrain: epoch  4, batch     0 | loss: 6.9214773
CurrentTrain: epoch  4, batch     1 | loss: 6.3543296
CurrentTrain: epoch  4, batch     2 | loss: 5.6729169
CurrentTrain: epoch  4, batch     3 | loss: 6.7485514
CurrentTrain: epoch  4, batch     4 | loss: 7.2618380
CurrentTrain: epoch  4, batch     5 | loss: 6.6126189
CurrentTrain: epoch  4, batch     6 | loss: 6.2170911
CurrentTrain: epoch  4, batch     7 | loss: 6.6977735
CurrentTrain: epoch  4, batch     8 | loss: 7.4788270
CurrentTrain: epoch  4, batch     9 | loss: 6.5936441
CurrentTrain: epoch  4, batch    10 | loss: 6.9046702
CurrentTrain: epoch  4, batch    11 | loss: 6.0163383
CurrentTrain: epoch  4, batch    12 | loss: 6.5755177
CurrentTrain: epoch  4, batch    13 | loss: 6.2283492
CurrentTrain: epoch  4, batch    14 | loss: 7.0001431
CurrentTrain: epoch  4, batch    15 | loss: 6.6601152
CurrentTrain: epoch  4, batch    16 | loss: 6.3596520
CurrentTrain: epoch  4, batch    17 | loss: 6.3576050
CurrentTrain: epoch  4, batch    18 | loss: 5.9598074
CurrentTrain: epoch  4, batch    19 | loss: 6.0913982
CurrentTrain: epoch  4, batch    20 | loss: 6.2184505
CurrentTrain: epoch  4, batch    21 | loss: 6.5159440
CurrentTrain: epoch  4, batch    22 | loss: 6.6188974
CurrentTrain: epoch  4, batch    23 | loss: 5.9724197
CurrentTrain: epoch  4, batch    24 | loss: 6.6317444
CurrentTrain: epoch  4, batch    25 | loss: 6.5978203
CurrentTrain: epoch  4, batch    26 | loss: 6.0009141
CurrentTrain: epoch  4, batch    27 | loss: 7.6149282
CurrentTrain: epoch  4, batch    28 | loss: 5.8510528
CurrentTrain: epoch  4, batch    29 | loss: 6.1155725
CurrentTrain: epoch  4, batch    30 | loss: 5.9866090
CurrentTrain: epoch  4, batch    31 | loss: 6.0753689
CurrentTrain: epoch  4, batch    32 | loss: 6.2112637
CurrentTrain: epoch  4, batch    33 | loss: 5.6074681
CurrentTrain: epoch  4, batch    34 | loss: 6.8721824
CurrentTrain: epoch  4, batch    35 | loss: 6.1603594
CurrentTrain: epoch  4, batch    36 | loss: 5.9010696
CurrentTrain: epoch  4, batch    37 | loss: 6.5777607
CurrentTrain: epoch  5, batch     0 | loss: 5.6601758
CurrentTrain: epoch  5, batch     1 | loss: 6.0248494
CurrentTrain: epoch  5, batch     2 | loss: 6.2602463
CurrentTrain: epoch  5, batch     3 | loss: 6.3877387
CurrentTrain: epoch  5, batch     4 | loss: 5.9552431
CurrentTrain: epoch  5, batch     5 | loss: 5.9370213
CurrentTrain: epoch  5, batch     6 | loss: 6.2484322
CurrentTrain: epoch  5, batch     7 | loss: 6.5060091
CurrentTrain: epoch  5, batch     8 | loss: 6.5059867
CurrentTrain: epoch  5, batch     9 | loss: 5.7736840
CurrentTrain: epoch  5, batch    10 | loss: 5.7672777
CurrentTrain: epoch  5, batch    11 | loss: 6.0279074
CurrentTrain: epoch  5, batch    12 | loss: 5.7482686
CurrentTrain: epoch  5, batch    13 | loss: 5.9997821
CurrentTrain: epoch  5, batch    14 | loss: 6.2035551
CurrentTrain: epoch  5, batch    15 | loss: 6.5068035
CurrentTrain: epoch  5, batch    16 | loss: 5.3515067
CurrentTrain: epoch  5, batch    17 | loss: 5.5702515
CurrentTrain: epoch  5, batch    18 | loss: 6.6157694
CurrentTrain: epoch  5, batch    19 | loss: 7.0879307
CurrentTrain: epoch  5, batch    20 | loss: 5.5562043
CurrentTrain: epoch  5, batch    21 | loss: 5.8516216
CurrentTrain: epoch  5, batch    22 | loss: 5.6183128
CurrentTrain: epoch  5, batch    23 | loss: 6.0548382
CurrentTrain: epoch  5, batch    24 | loss: 6.8281794
CurrentTrain: epoch  5, batch    25 | loss: 5.7778754
CurrentTrain: epoch  5, batch    26 | loss: 5.8007574
CurrentTrain: epoch  5, batch    27 | loss: 5.6567163
CurrentTrain: epoch  5, batch    28 | loss: 6.8478708
CurrentTrain: epoch  5, batch    29 | loss: 6.6075182
CurrentTrain: epoch  5, batch    30 | loss: 5.7610102
CurrentTrain: epoch  5, batch    31 | loss: 5.8279133
CurrentTrain: epoch  5, batch    32 | loss: 5.3630514
CurrentTrain: epoch  5, batch    33 | loss: 5.9219146
CurrentTrain: epoch  5, batch    34 | loss: 5.7536297
CurrentTrain: epoch  5, batch    35 | loss: 5.9297442
CurrentTrain: epoch  5, batch    36 | loss: 6.1582942
CurrentTrain: epoch  5, batch    37 | loss: 5.3770695
CurrentTrain: epoch  6, batch     0 | loss: 5.3385010
CurrentTrain: epoch  6, batch     1 | loss: 5.7504702
CurrentTrain: epoch  6, batch     2 | loss: 6.0827885
CurrentTrain: epoch  6, batch     3 | loss: 6.0616360
CurrentTrain: epoch  6, batch     4 | loss: 5.5673351
CurrentTrain: epoch  6, batch     5 | loss: 5.4255438
CurrentTrain: epoch  6, batch     6 | loss: 5.8536959
CurrentTrain: epoch  6, batch     7 | loss: 5.7188549
CurrentTrain: epoch  6, batch     8 | loss: 5.2314873
CurrentTrain: epoch  6, batch     9 | loss: 5.6400099
CurrentTrain: epoch  6, batch    10 | loss: 5.3543816
CurrentTrain: epoch  6, batch    11 | loss: 5.3050299
CurrentTrain: epoch  6, batch    12 | loss: 5.7439237
CurrentTrain: epoch  6, batch    13 | loss: 5.4360719
CurrentTrain: epoch  6, batch    14 | loss: 5.3918200
CurrentTrain: epoch  6, batch    15 | loss: 5.1954913
CurrentTrain: epoch  6, batch    16 | loss: 5.9823422
CurrentTrain: epoch  6, batch    17 | loss: 5.4264145
CurrentTrain: epoch  6, batch    18 | loss: 5.6327276
CurrentTrain: epoch  6, batch    19 | loss: 5.9033957
CurrentTrain: epoch  6, batch    20 | loss: 6.1786757
CurrentTrain: epoch  6, batch    21 | loss: 6.3660412
CurrentTrain: epoch  6, batch    22 | loss: 6.0595322
CurrentTrain: epoch  6, batch    23 | loss: 5.5738835
CurrentTrain: epoch  6, batch    24 | loss: 5.1174212
CurrentTrain: epoch  6, batch    25 | loss: 5.9595833
CurrentTrain: epoch  6, batch    26 | loss: 6.1485519
CurrentTrain: epoch  6, batch    27 | loss: 5.7259197
CurrentTrain: epoch  6, batch    28 | loss: 5.8726430
CurrentTrain: epoch  6, batch    29 | loss: 5.5694523
CurrentTrain: epoch  6, batch    30 | loss: 6.0045009
CurrentTrain: epoch  6, batch    31 | loss: 5.6451173
CurrentTrain: epoch  6, batch    32 | loss: 5.2247005
CurrentTrain: epoch  6, batch    33 | loss: 6.1387463
CurrentTrain: epoch  6, batch    34 | loss: 5.2706861
CurrentTrain: epoch  6, batch    35 | loss: 5.5575624
CurrentTrain: epoch  6, batch    36 | loss: 5.3598919
CurrentTrain: epoch  6, batch    37 | loss: 5.5043011
CurrentTrain: epoch  7, batch     0 | loss: 5.8221326
CurrentTrain: epoch  7, batch     1 | loss: 5.2134027
CurrentTrain: epoch  7, batch     2 | loss: 5.3066864
CurrentTrain: epoch  7, batch     3 | loss: 5.0514336
CurrentTrain: epoch  7, batch     4 | loss: 5.5705714
CurrentTrain: epoch  7, batch     5 | loss: 5.2637019
CurrentTrain: epoch  7, batch     6 | loss: 5.3848391
CurrentTrain: epoch  7, batch     7 | loss: 5.0422788
CurrentTrain: epoch  7, batch     8 | loss: 5.4018226
CurrentTrain: epoch  7, batch     9 | loss: 5.1225381
CurrentTrain: epoch  7, batch    10 | loss: 5.3415217
CurrentTrain: epoch  7, batch    11 | loss: 5.3493118
CurrentTrain: epoch  7, batch    12 | loss: 5.3571339
CurrentTrain: epoch  7, batch    13 | loss: 5.5703020
CurrentTrain: epoch  7, batch    14 | loss: 5.9958162
CurrentTrain: epoch  7, batch    15 | loss: 5.4087534
CurrentTrain: epoch  7, batch    16 | loss: 5.5808349
CurrentTrain: epoch  7, batch    17 | loss: 5.3512669
CurrentTrain: epoch  7, batch    18 | loss: 4.9717011
CurrentTrain: epoch  7, batch    19 | loss: 5.1010613
CurrentTrain: epoch  7, batch    20 | loss: 5.5419488
CurrentTrain: epoch  7, batch    21 | loss: 5.0689411
CurrentTrain: epoch  7, batch    22 | loss: 6.1445966
CurrentTrain: epoch  7, batch    23 | loss: 5.4027791
CurrentTrain: epoch  7, batch    24 | loss: 5.8069553
CurrentTrain: epoch  7, batch    25 | loss: 5.1294775
CurrentTrain: epoch  7, batch    26 | loss: 5.2494717
CurrentTrain: epoch  7, batch    27 | loss: 5.3885818
CurrentTrain: epoch  7, batch    28 | loss: 5.1891451
CurrentTrain: epoch  7, batch    29 | loss: 5.2763824
CurrentTrain: epoch  7, batch    30 | loss: 5.2565598
CurrentTrain: epoch  7, batch    31 | loss: 5.2446299
CurrentTrain: epoch  7, batch    32 | loss: 5.1272998
CurrentTrain: epoch  7, batch    33 | loss: 5.2244992
CurrentTrain: epoch  7, batch    34 | loss: 5.0223141
CurrentTrain: epoch  7, batch    35 | loss: 5.1779542
CurrentTrain: epoch  7, batch    36 | loss: 5.1301193
CurrentTrain: epoch  7, batch    37 | loss: 4.8143196
CurrentTrain: epoch  8, batch     0 | loss: 5.1579475
CurrentTrain: epoch  8, batch     1 | loss: 5.1543798
CurrentTrain: epoch  8, batch     2 | loss: 4.8897972
CurrentTrain: epoch  8, batch     3 | loss: 5.0410523
CurrentTrain: epoch  8, batch     4 | loss: 5.2717929
CurrentTrain: epoch  8, batch     5 | loss: 4.9771128
CurrentTrain: epoch  8, batch     6 | loss: 5.0834179
CurrentTrain: epoch  8, batch     7 | loss: 5.0067358
CurrentTrain: epoch  8, batch     8 | loss: 5.0641761
CurrentTrain: epoch  8, batch     9 | loss: 5.0935326
CurrentTrain: epoch  8, batch    10 | loss: 5.2907119
CurrentTrain: epoch  8, batch    11 | loss: 4.9250479
CurrentTrain: epoch  8, batch    12 | loss: 5.0914650
CurrentTrain: epoch  8, batch    13 | loss: 4.9756813
CurrentTrain: epoch  8, batch    14 | loss: 5.2059898
CurrentTrain: epoch  8, batch    15 | loss: 5.2468882
CurrentTrain: epoch  8, batch    16 | loss: 4.9808016
CurrentTrain: epoch  8, batch    17 | loss: 4.8144884
CurrentTrain: epoch  8, batch    18 | loss: 5.2888255
CurrentTrain: epoch  8, batch    19 | loss: 4.9981937
CurrentTrain: epoch  8, batch    20 | loss: 5.1061277
CurrentTrain: epoch  8, batch    21 | loss: 5.0941725
CurrentTrain: epoch  8, batch    22 | loss: 5.3479795
CurrentTrain: epoch  8, batch    23 | loss: 5.2284288
CurrentTrain: epoch  8, batch    24 | loss: 4.9951601
CurrentTrain: epoch  8, batch    25 | loss: 5.0256500
CurrentTrain: epoch  8, batch    26 | loss: 5.3343859
CurrentTrain: epoch  8, batch    27 | loss: 4.9719343
CurrentTrain: epoch  8, batch    28 | loss: 5.2509747
CurrentTrain: epoch  8, batch    29 | loss: 5.0940399
CurrentTrain: epoch  8, batch    30 | loss: 4.9406633
CurrentTrain: epoch  8, batch    31 | loss: 5.1270304
CurrentTrain: epoch  8, batch    32 | loss: 4.7761073
CurrentTrain: epoch  8, batch    33 | loss: 4.9832006
CurrentTrain: epoch  8, batch    34 | loss: 4.9552345
CurrentTrain: epoch  8, batch    35 | loss: 5.4438825
CurrentTrain: epoch  8, batch    36 | loss: 4.9208779
CurrentTrain: epoch  8, batch    37 | loss: 4.9012098
CurrentTrain: epoch  9, batch     0 | loss: 5.3065910
CurrentTrain: epoch  9, batch     1 | loss: 5.1796370
CurrentTrain: epoch  9, batch     2 | loss: 5.1072073
CurrentTrain: epoch  9, batch     3 | loss: 4.9213343
CurrentTrain: epoch  9, batch     4 | loss: 4.8819547
CurrentTrain: epoch  9, batch     5 | loss: 5.1034369
CurrentTrain: epoch  9, batch     6 | loss: 5.3321552
CurrentTrain: epoch  9, batch     7 | loss: 4.9197969
CurrentTrain: epoch  9, batch     8 | loss: 4.9653072
CurrentTrain: epoch  9, batch     9 | loss: 4.8860769
CurrentTrain: epoch  9, batch    10 | loss: 5.0107727
CurrentTrain: epoch  9, batch    11 | loss: 4.8371091
CurrentTrain: epoch  9, batch    12 | loss: 4.9469938
CurrentTrain: epoch  9, batch    13 | loss: 5.0067148
CurrentTrain: epoch  9, batch    14 | loss: 4.9856386
CurrentTrain: epoch  9, batch    15 | loss: 4.8672819
CurrentTrain: epoch  9, batch    16 | loss: 4.8858490
CurrentTrain: epoch  9, batch    17 | loss: 5.0205936
CurrentTrain: epoch  9, batch    18 | loss: 5.0734935
CurrentTrain: epoch  9, batch    19 | loss: 4.8799629
CurrentTrain: epoch  9, batch    20 | loss: 4.8950119
CurrentTrain: epoch  9, batch    21 | loss: 4.7830744
CurrentTrain: epoch  9, batch    22 | loss: 4.8854637
CurrentTrain: epoch  9, batch    23 | loss: 4.9289637
CurrentTrain: epoch  9, batch    24 | loss: 4.9857821
CurrentTrain: epoch  9, batch    25 | loss: 4.7893872
CurrentTrain: epoch  9, batch    26 | loss: 5.1338005
CurrentTrain: epoch  9, batch    27 | loss: 5.0343213
CurrentTrain: epoch  9, batch    28 | loss: 4.9264212
CurrentTrain: epoch  9, batch    29 | loss: 5.0215325
CurrentTrain: epoch  9, batch    30 | loss: 4.7740507
CurrentTrain: epoch  9, batch    31 | loss: 4.8163271
CurrentTrain: epoch  9, batch    32 | loss: 4.8064499
CurrentTrain: epoch  9, batch    33 | loss: 4.7759576
CurrentTrain: epoch  9, batch    34 | loss: 4.9853191
CurrentTrain: epoch  9, batch    35 | loss: 4.7680750
CurrentTrain: epoch  9, batch    36 | loss: 4.7871542
CurrentTrain: epoch  9, batch    37 | loss: 4.9062581
#### person countries of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person countries of residence" means a person is living in a country.
Here is an example:
Relation: person countries of residence
Context: khamenei , 67 , has final say on all state matters in iran as supreme leader , a post he has held since 1989 .
Head Entity: khamenei
Tail Entity: iran
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person countries of residence":
Relation: person countries of residence  
Context: After years of living in the United States, Maria decided to return to her homeland, spain, to reconnect with her roots.  
Head Entity: Maria  
Tail Entity: spain  

Relation: person countries of residence  
Context: The famous actor, Leonardo DiCaprio, has been known to spend a significant amount of time in both the United States and australia, where he enjoys the natural beauty.  
Head Entity: Leonardo DiCaprio  
Tail Entity: australia  

Relation: person countries of residence  
Context: Following his retirement, the former president moved to canada, where he enjoys a quieter life away from the public eye.  
Head Entity: the former president  
Tail Entity: canada  

Relation: person countries of residence  
Context: After completing her studies in the UK, Aisha decided to settle in germany, where she found a job that she loves.  
Head Entity: Aisha  
Tail Entity: germany  

Relation: person countries of residence  
Context: The renowned scientist has spent most of his career in sweden, contributing to groundbreaking research in renewable energy.  
Head Entity: The renowned scientist  
Tail Entity: sweden  
#### organization top members employees ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization top members employees" means an organization 's employer is a person.
Here is an example:
Relation: organization top members employees
Context: `` customer relationships are the backbone of banking , and banks are constantly striving to meet customer demands , '' said peter garuccio , spokesman for the american bankers association .
Head Entity: american bankers association
Tail Entity: peter garuccio
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization top members employees":
1. Relation: organization top members employees  
   Context: "As the CEO of the tech giant, she has been instrumental in driving innovation," said a company spokesperson about Jane Doe, who leads the organization.  
   Head Entity: tech giant  
   Tail Entity: Jane Doe  

2. Relation: organization top members employees  
   Context: "The board of directors is pleased to announce the appointment of John Smith as the new CFO," stated the press release from the financial services firm.  
   Head Entity: financial services firm  
   Tail Entity: John Smith  

3. Relation: organization top members employees  
   Context: "In her role as Chief Marketing Officer, Maria Lopez has transformed the company's branding strategy," noted an industry analyst regarding the marketing agency.  
   Head Entity: marketing agency  
   Tail Entity: Maria Lopez  

4. Relation: organization top members employees  
   Context: "The university's president emphasized the importance of research in her speech at the annual conference," reported the local news outlet about Dr. Emily Chen.  
   Head Entity: university  
   Tail Entity: Dr. Emily Chen  

5. Relation: organization top members employees  
   Context: "The nonprofit organization has appointed David Brown as its new executive director to lead its initiatives," announced the organization's board.  
   Head Entity: nonprofit organization  
   Tail Entity: David Brown  
#### organization member of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization member of" means an organization is the member of an organization.
Here is an example:
Relation: organization member of
Context: over the course of the week the european union engaged in a gentlemanly tug-of-war with the organization of the islamic conference -lrb- oic -rrb- and the african regional group - which is controlled by the oic - over a range of terms and conditions .
Head Entity: oic
Tail Entity: organization of the islamic conference
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization member of":
Relation: organization member of  
Context: The United Nations has been working closely with the World Health Organization to address global health issues and improve international cooperation.  
Head Entity: World Health Organization  
Tail Entity: United Nations  

Relation: organization member of  
Context: During the annual conference, the International Olympic Committee discussed its collaboration with various national sports organizations to promote athletic excellence.  
Head Entity: International Olympic Committee  
Tail Entity: national sports organizations  

Relation: organization member of  
Context: The North Atlantic Treaty Organization held a summit where member countries deliberated on collective defense strategies and regional security.  
Head Entity: North Atlantic Treaty Organization  
Tail Entity: member countries  

Relation: organization member of  
Context: The International Monetary Fund announced new initiatives in partnership with several regional development banks to enhance economic stability in member nations.  
Head Entity: International Monetary Fund  
Tail Entity: regional development banks  

Relation: organization member of  
Context: The Global Climate Alliance is working with various environmental organizations to tackle climate change and promote sustainable practices worldwide.  
Head Entity: Global Climate Alliance  
Tail Entity: environmental organizations  
#### person origin ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person origin" means a person 's nationality is a country.
Here is an example:
Relation: person origin
Context: urgent chadian pm dies in paris hospital chad 's prime minister pascal yoadimnadji has died from a cerebral hemorrhage in a paris hospital , the chadian ambassador said friday .
Head Entity: pascal yoadimnadji
Tail Entity: chadian
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person origin":
Relation: person origin  
Context: the renowned scientist albert einstein was born in ulm, germany, and later became a citizen of the united states.  
Head Entity: albert einstein  
Tail Entity: german  

Relation: person origin  
Context: the famous author chimamanda ngozi adichie hails from enugu, nigeria, where she developed her passion for storytelling.  
Head Entity: chimamanda ngozi adichie  
Tail Entity: nigerian  

Relation: person origin  
Context: the legendary musician bob marley was born in nine mile, jamaica, and is celebrated worldwide for his contributions to reggae music.  
Head Entity: bob marley  
Tail Entity: jamaican  

Relation: person origin  
Context: the acclaimed filmmaker akira kurosawa was born in tokyo, japan, and is known for his influential works in cinema.  
Head Entity: akira kurosawa  
Tail Entity: japanese  

Relation: person origin  
Context: the famous physicist stephen hawking was born in oxford, england, and made groundbreaking contributions to theoretical physics.  
Head Entity: stephen hawking  
Tail Entity: british  
#### person title ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person title" means a person 's title is a title.
Here is an example:
Relation: person title
Context: `` making the amendment retroactive will ... help repair the image of the sentencing guidelines in communities of color , '' naacp chairman julian bond wrote to the commission .
Head Entity: julian bond
Tail Entity: chairman
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person title":
Relation: person title  
Context: `` After years of dedicated service, the board appointed Dr. Emily Carter as the new president of the university. ''  
Head Entity: Dr. Emily Carter  
Tail Entity: president  

Relation: person title  
Context: `` In her latest book, renowned author Sarah Johnson shares her journey as a leading figure in contemporary literature. ''  
Head Entity: Sarah Johnson  
Tail Entity: leading figure  

Relation: person title  
Context: `` The city council elected Mark Thompson to serve as the chief of police, a role he has long aspired to. ''  
Head Entity: Mark Thompson  
Tail Entity: chief of police  

Relation: person title  
Context: `` During the annual gala, the organization honored Maria Lopez for her outstanding contributions as the executive director. ''  
Head Entity: Maria Lopez  
Tail Entity: executive director  

Relation: person title  
Context: `` Following the recent elections, James Lee was officially recognized as the mayor of the town, a position he campaigned for vigorously. ''  
Head Entity: James Lee  
Tail Entity: mayor  
#### organization country of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization country of headquarters" means an organization is located in a country.
Here is an example:
Relation: organization country of headquarters
Context: chunghwa telecom co , taiwan 's leading telecom operator , said friday its 2007 net profit rose some eight percent from a year earlier , largely due to cost reductions .
Head Entity: chunghwa telecom
Tail Entity: taiwan
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization country of headquarters":
Relation: organization country of headquarters  
Context: Samsung Electronics, a global leader in technology, announced its plans to expand operations in South Korea, aiming to enhance its production capabilities.  
Head Entity: Samsung Electronics  
Tail Entity: South Korea  

Relation: organization country of headquarters  
Context: Nestlé, the world's largest food and beverage company, has its headquarters situated in Switzerland, where it was founded over 150 years ago.  
Head Entity: Nestlé  
Tail Entity: Switzerland  

Relation: organization country of headquarters  
Context: Toyota Motor Corporation, known for its innovative automotive solutions, is headquartered in Japan, contributing significantly to the country's economy.  
Head Entity: Toyota Motor Corporation  
Tail Entity: Japan  

Relation: organization country of headquarters  
Context: Unilever, a multinational consumer goods company, operates its main office in the United Kingdom, where it was established in the late 19th century.  
Head Entity: Unilever  
Tail Entity: United Kingdom  

Relation: organization country of headquarters  
Context: Siemens AG, a global powerhouse in electronics and electrical engineering, has its headquarters located in Germany, playing a crucial role in the European market.  
Head Entity: Siemens AG  
Tail Entity: Germany  
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    1 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    2 | acc: 87.50%,  total acc: 83.33%   
[EVAL] batch:    3 | acc: 62.50%,  total acc: 78.12%   
[EVAL] batch:    4 | acc: 93.75%,  total acc: 81.25%   
[EVAL] batch:    5 | acc: 75.00%,  total acc: 80.21%   
[EVAL] batch:    6 | acc: 93.75%,  total acc: 82.14%   
[EVAL] batch:    7 | acc: 100.00%,  total acc: 84.38%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 86.11%   
[EVAL] batch:    9 | acc: 93.75%,  total acc: 86.88%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 88.07%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 88.54%   
[EVAL] batch:   12 | acc: 93.75%,  total acc: 88.94%   
[EVAL] batch:   13 | acc: 68.75%,  total acc: 87.50%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 86.67%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 84.77%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 84.19%   
[EVAL] batch:   17 | acc: 68.75%,  total acc: 83.33%   
[EVAL] batch:   18 | acc: 87.50%,  total acc: 83.55%   
[EVAL] batch:   19 | acc: 87.50%,  total acc: 83.75%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 84.52%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 85.23%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 85.87%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 86.46%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 87.00%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 87.50%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 87.73%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 88.17%   
[EVAL] batch:   28 | acc: 100.00%,  total acc: 88.58%   
[EVAL] batch:   29 | acc: 87.50%,  total acc: 88.54%   
[EVAL] batch:   30 | acc: 87.50%,  total acc: 88.51%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 88.67%   
[EVAL] batch:   32 | acc: 37.50%,  total acc: 87.12%   
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    1 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    2 | acc: 87.50%,  total acc: 83.33%   
[EVAL] batch:    3 | acc: 62.50%,  total acc: 78.12%   
[EVAL] batch:    4 | acc: 93.75%,  total acc: 81.25%   
[EVAL] batch:    5 | acc: 75.00%,  total acc: 80.21%   
[EVAL] batch:    6 | acc: 93.75%,  total acc: 82.14%   
[EVAL] batch:    7 | acc: 100.00%,  total acc: 84.38%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 86.11%   
[EVAL] batch:    9 | acc: 93.75%,  total acc: 86.88%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 88.07%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 88.54%   
[EVAL] batch:   12 | acc: 93.75%,  total acc: 88.94%   
[EVAL] batch:   13 | acc: 68.75%,  total acc: 87.50%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 86.67%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 84.77%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 84.19%   
[EVAL] batch:   17 | acc: 68.75%,  total acc: 83.33%   
[EVAL] batch:   18 | acc: 87.50%,  total acc: 83.55%   
[EVAL] batch:   19 | acc: 87.50%,  total acc: 83.75%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 84.52%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 85.23%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 85.87%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 86.46%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 87.00%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 87.50%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 87.73%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 88.17%   
[EVAL] batch:   28 | acc: 100.00%,  total acc: 88.58%   
[EVAL] batch:   29 | acc: 87.50%,  total acc: 88.54%   
[EVAL] batch:   30 | acc: 87.50%,  total acc: 88.51%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 88.67%   
[EVAL] batch:   32 | acc: 37.50%,  total acc: 87.12%   
cur_acc:  ['0.8712']
his_acc:  ['0.8712']
CurrentTrain: epoch  0, batch     0 | loss: 6.3973942
CurrentTrain: epoch  0, batch     1 | loss: 7.3796716
CurrentTrain: epoch  1, batch     0 | loss: 6.4657888
CurrentTrain: epoch  1, batch     1 | loss: 5.3782830
CurrentTrain: epoch  2, batch     0 | loss: 6.1777396
CurrentTrain: epoch  2, batch     1 | loss: 5.3747253
CurrentTrain: epoch  3, batch     0 | loss: 5.5423403
CurrentTrain: epoch  3, batch     1 | loss: 5.1534314
CurrentTrain: epoch  4, batch     0 | loss: 5.3756881
CurrentTrain: epoch  4, batch     1 | loss: 5.0625086
CurrentTrain: epoch  5, batch     0 | loss: 5.0119185
CurrentTrain: epoch  5, batch     1 | loss: 3.9117169
CurrentTrain: epoch  6, batch     0 | loss: 4.4607000
CurrentTrain: epoch  6, batch     1 | loss: 3.8968837
CurrentTrain: epoch  7, batch     0 | loss: 4.1129036
CurrentTrain: epoch  7, batch     1 | loss: 4.0668969
CurrentTrain: epoch  8, batch     0 | loss: 3.4643028
CurrentTrain: epoch  8, batch     1 | loss: 4.1775894
CurrentTrain: epoch  9, batch     0 | loss: 3.3281112
CurrentTrain: epoch  9, batch     1 | loss: 3.7418110
#### person date of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person date of birth" means a person was born in a date.
Here is an example:
Relation: person date of birth
Context: born in 1950 in the northeastern city of basel , ospel left school at 15 to take an apprenticeship at the transvalor brokerage house before joining swiss banking corporation -lrb- sbs -rrb- , which merged with union bank of switzerland to form ubs in 1998 .
Head Entity: ospel
Tail Entity: 1950
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person date of birth":
Relation: person date of birth  
Context: she was born on July 4, 1985, in a small town in California, where she spent her childhood before moving to New York for her career.  
Head Entity: she  
Tail Entity: July 4, 1985  

Relation: person date of birth  
Context: the famous physicist was born in 1879 in Ulm, a city in the Kingdom of Württemberg in the German Empire, and later moved to Munich.  
Head Entity: the famous physicist  
Tail Entity: 1879  

Relation: person date of birth  
Context: born in 1992 in a bustling city, he quickly became known for his contributions to technology and innovation.  
Head Entity: he  
Tail Entity: 1992  

Relation: person date of birth  
Context: the renowned author was born in 1965 in a small village, where she developed her love for storytelling from a young age.  
Head Entity: the renowned author  
Tail Entity: 1965  

Relation: person date of birth  
Context: born in 1978 in a coastal town, she grew up surrounded by the ocean, which inspired her future career as a marine biologist.  
Head Entity: she  
Tail Entity: 1978  
#### person stateorprovince of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of birth" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of birth
Context: jane matilda bolin was born on april 11 , 1908 , in poughkeepsie , ny .
Head Entity: jane matilda bolin
Tail Entity: ny
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of birth":
Relation: person stateorprovince of birth  
Context: albert einstein was born on march 14, 1879, in ulm, baden-württemberg, germany.  
Head Entity: albert einstein  
Tail Entity: baden-württemberg  

Relation: person stateorprovince of birth  
Context: marilyn monroe was born on june 1, 1926, in los angeles, california.  
Head Entity: marilyn monroe  
Tail Entity: california  

Relation: person stateorprovince of birth  
Context: barack obama was born on august 4, 1961, in honolulu, hawaii.  
Head Entity: barack obama  
Tail Entity: hawaii  

Relation: person stateorprovince of birth  
Context: agatha christie was born on september 15, 1890, in torquay, devon.  
Head Entity: agatha christie  
Tail Entity: devon  

Relation: person stateorprovince of birth  
Context: nelson mandela was born on july 18, 1918, in mvezo, eastern cape.  
Head Entity: nelson mandela  
Tail Entity: eastern cape  
#### person parents ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person parents" means a person 's parent is a person.
Here is an example:
Relation: person parents
Context: lynne spears told the court that lutfi had treated her daughter like a hostage in her own home , drugged her and took over her finances .
Head Entity: her
Tail Entity: lynne spears
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person parents":
1. Relation: person parents  
   Context: After years of hard work, Sarah finally made her parents proud by graduating at the top of her class.  
   Head Entity: her  
   Tail Entity: parents  

2. Relation: person parents  
   Context: During the family reunion, Michael shared stories about how his father taught him valuable life lessons.  
   Head Entity: his  
   Tail Entity: father  

3. Relation: person parents  
   Context: Emily often reminisces about the summer vacations she spent with her mother at the beach.  
   Head Entity: her  
   Tail Entity: mother  

4. Relation: person parents  
   Context: The documentary highlighted how the struggles of his parents shaped his career as an artist.  
   Head Entity: his  
   Tail Entity: parents  

5. Relation: person parents  
   Context: Jessica credits her success to the unwavering support she received from her father throughout her life.  
   Head Entity: her  
   Tail Entity: father  
#### person employee of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person employee of" means a person is an employee of an organization.
Here is an example:
Relation: person employee of
Context: seeking revenge , axel reunites with old pal sgt. billy rosewood -lrb- judge reinhold -rrb- and jon flint -lrb- hector elizondo -rrb- of the beverly hills police department .
Head Entity: hector elizondo
Tail Entity: beverly hills police department
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person employee of":
Relation: person employee of  
Context: After years of hard work, Maria finally landed a job at the prestigious tech firm, where she collaborates with some of the brightest minds in the industry.  
Head Entity: Maria  
Tail Entity: prestigious tech firm  

Relation: person employee of  
Context: John has been with the company for over a decade, contributing to numerous successful projects and earning the respect of his colleagues.  
Head Entity: John  
Tail Entity: the company  

Relation: person employee of  
Context: As a lead designer at the fashion house, Sarah showcases her creativity and innovation, making a name for herself in the competitive industry.  
Head Entity: Sarah  
Tail Entity: the fashion house  

Relation: person employee of  
Context: After graduating from university, Tom accepted a position at a well-known financial institution, where he quickly climbed the corporate ladder.  
Head Entity: Tom  
Tail Entity: well-known financial institution  

Relation: person employee of  
Context: Emily's dedication to her role at the non-profit organization has made a significant impact on the community, earning her several awards.  
Head Entity: Emily  
Tail Entity: non-profit organization  
#### person stateorprovince of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of death" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of death
Context: irene morgan kirkaldy , whose defiance of bus segregation laws more than a decade before rosa parks ' landmark case helped lay the foundation for later civil rights victories , died friday at her home in hayes , va. .
Head Entity: irene morgan kirkaldy
Tail Entity: va.
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of death":
Relation: person stateorprovince of death  
Context: john doe, a renowned author known for his thrilling novels, passed away peacefully in his sleep at his residence in los angeles, ca.  
Head Entity: john doe  
Tail Entity: ca.  

Relation: person stateorprovince of death  
Context: after a long battle with illness, elizabeth taylor, the iconic actress, died at the age of 79 in her home located in bel air, ca.  
Head Entity: elizabeth taylor  
Tail Entity: ca.  

Relation: person stateorprovince of death  
Context: the famous physicist, albert einstein, took his last breath in princeton, nj, where he had lived for many years.  
Head Entity: albert einstein  
Tail Entity: nj.  

Relation: person stateorprovince of death  
Context: the beloved musician, prince, was found unresponsive in his home in minneapolis, mn, leading to an outpouring of grief from fans worldwide.  
Head Entity: prince  
Tail Entity: mn.  

Relation: person stateorprovince of death  
Context: the celebrated civil rights leader, martin luther king jr., was assassinated in memphis, tn, a tragic event that shocked the nation.  
Head Entity: martin luther king jr.  
Tail Entity: tn.  
Mixup data size:  3730
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch     0 | loss: 5.6834540
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch     1 | loss: 5.4101176
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch     2 | loss: 4.6666393
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch     3 | loss: 4.4605703
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch     4 | loss: 4.8348622
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch     5 | loss: 4.6824341
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch     6 | loss: 4.7431602
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch     7 | loss: 4.8108282
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch     8 | loss: 4.3787618
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch     9 | loss: 4.1702895
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    10 | loss: 4.0005803
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    11 | loss: 3.7040267
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    12 | loss: 3.7108583
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    13 | loss: 4.8339567
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    14 | loss: 3.7817111
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    15 | loss: 4.2946458
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    16 | loss: 3.6715741
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    17 | loss: 3.4006972
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    18 | loss: 3.7592230
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    19 | loss: 3.3492160
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    20 | loss: 3.5297554
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    21 | loss: 3.4605267
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    22 | loss: 3.8071289
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    23 | loss: 3.5121291
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    24 | loss: 3.5574739
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    25 | loss: 3.3343101
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    26 | loss: 3.3617153
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    27 | loss: 2.8773587
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    28 | loss: 3.1241558
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    29 | loss: 3.3164196
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    30 | loss: 2.8730395
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    31 | loss: 3.2291768
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    32 | loss: 3.1148853
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    33 | loss: 2.9354539
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    34 | loss: 3.1181703
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    35 | loss: 2.8439755
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    36 | loss: 3.2190795
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    37 | loss: 3.3678174
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    38 | loss: 3.2510900
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    39 | loss: 2.8312078
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    40 | loss: 2.7963488
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    41 | loss: 2.9104862
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    42 | loss: 2.7297578
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    43 | loss: 2.7580266
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    44 | loss: 2.5921988
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    45 | loss: 3.1007521
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    46 | loss: 2.9930854
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    47 | loss: 2.8765447
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    48 | loss: 2.6639919
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    49 | loss: 2.6287420
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    50 | loss: 2.4323335
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    51 | loss: 2.4706182
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    52 | loss: 2.4465179
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    53 | loss: 2.5348196
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    54 | loss: 2.7779713
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    55 | loss: 2.5254669
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    56 | loss: 2.5208621
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    57 | loss: 2.4911852
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    58 | loss: 2.5231316
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    59 | loss: 2.5399399
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    60 | loss: 2.5802643
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    61 | loss: 2.3959997
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    62 | loss: 2.3574121
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    63 | loss: 2.4415174
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    64 | loss: 2.5680804
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    65 | loss: 2.3433311
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    66 | loss: 2.4371972
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    67 | loss: 2.5374289
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    68 | loss: 2.2876048
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    69 | loss: 2.3049154
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    70 | loss: 2.3260946
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    71 | loss: 2.4029324
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    72 | loss: 2.3462932
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    73 | loss: 2.3678422
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    74 | loss: 2.2298882
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    75 | loss: 2.2670603
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    76 | loss: 2.3590047
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    77 | loss: 2.2431245
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    78 | loss: 2.1866901
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    79 | loss: 2.2668650
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    80 | loss: 2.1833069
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    81 | loss: 2.3740768
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    82 | loss: 2.2103910
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    83 | loss: 2.2522850
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    84 | loss: 2.2375128
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    85 | loss: 2.2469664
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    86 | loss: 2.2781363
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    87 | loss: 2.1586928
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    88 | loss: 2.1323743
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    89 | loss: 2.3217759
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    90 | loss: 2.2018340
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    91 | loss: 2.2005200
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    92 | loss: 2.1787629
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    93 | loss: 2.1940558
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    94 | loss: 2.1565711
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    95 | loss: 2.2242084
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    96 | loss: 2.0539370
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    97 | loss: 2.0890088
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    98 | loss: 2.2062595
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch    99 | loss: 2.2615499
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   100 | loss: 2.1401005
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   101 | loss: 2.1497791
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   102 | loss: 2.1080403
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   103 | loss: 2.1658540
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   104 | loss: 2.1671631
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   105 | loss: 2.1782455
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   106 | loss: 2.2345462
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   107 | loss: 2.0652452
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   108 | loss: 2.1180401
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   109 | loss: 2.1419971
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   110 | loss: 2.0910668
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   111 | loss: 2.1872544
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   112 | loss: 2.1566107
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   113 | loss: 2.0970473
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   114 | loss: 2.0839567
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   115 | loss: 2.0417304
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   116 | loss: 2.0969806
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   117 | loss: 2.0939422
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   118 | loss: 2.0680017
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   119 | loss: 2.0675960
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   120 | loss: 2.0465951
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   121 | loss: 2.0730562
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   122 | loss: 2.1387477
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   123 | loss: 2.0990133
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   124 | loss: 2.0407956
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   125 | loss: 2.0383921
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   126 | loss: 2.0901775
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   127 | loss: 2.0808582
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   128 | loss: 2.0331914
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   129 | loss: 2.0422668
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   130 | loss: 2.1070390
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   131 | loss: 2.0812249
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   132 | loss: 2.0091164
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   133 | loss: 2.0606003
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   134 | loss: 2.0197968
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   135 | loss: 2.0285349
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   136 | loss: 2.1009388
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   137 | loss: 2.0231028
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   138 | loss: 2.0560660
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   139 | loss: 2.0637238
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   140 | loss: 2.0050375
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   141 | loss: 2.0164800
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   142 | loss: 2.0366173
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   143 | loss: 2.0910678
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   144 | loss: 2.0381751
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   145 | loss: 2.0206656
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   146 | loss: 2.0485651
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   147 | loss: 2.0839260
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   148 | loss: 1.9917901
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   149 | loss: 2.0124402
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   150 | loss: 2.0479183
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   151 | loss: 2.0824616
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   152 | loss: 2.0354323
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   153 | loss: 1.9741639
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   154 | loss: 2.0316458
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   155 | loss: 2.0379162
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   156 | loss: 2.0591741
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   157 | loss: 2.0105603
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   158 | loss: 2.0361371
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   159 | loss: 1.9589189
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   160 | loss: 1.9893718
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   161 | loss: 1.9834569
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   162 | loss: 2.0123949
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   163 | loss: 2.0549064
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   164 | loss: 1.9743514
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   165 | loss: 2.0105448
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   166 | loss: 2.0487492
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   167 | loss: 1.9826169
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   168 | loss: 1.9839976
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   169 | loss: 2.0144300
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   170 | loss: 2.0328989
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   171 | loss: 2.0151303
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   172 | loss: 1.9983281
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   173 | loss: 1.9940107
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   174 | loss: 1.9548783
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   175 | loss: 2.0330167
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   176 | loss: 2.0374024
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   177 | loss: 2.0379753
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   178 | loss: 1.9896257
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   179 | loss: 2.0151601
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   180 | loss: 1.9769553
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   181 | loss: 1.9936223
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   182 | loss: 1.9415884
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   183 | loss: 1.9879386
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   184 | loss: 1.9480000
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   185 | loss: 1.9484880
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   186 | loss: 1.9414339
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   187 | loss: 1.9757539
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   188 | loss: 2.0031865
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   189 | loss: 2.0095530
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   190 | loss: 1.9525807
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   191 | loss: 1.9462618
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   192 | loss: 1.9293983
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   193 | loss: 1.9576298
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   194 | loss: 1.9317757
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   195 | loss: 1.9620264
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   196 | loss: 1.9102776
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   197 | loss: 1.9766505
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   198 | loss: 2.0022478
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   199 | loss: 1.9766610
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   200 | loss: 1.9460582
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   201 | loss: 1.9776624
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   202 | loss: 1.9766328
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   203 | loss: 2.0111179
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   204 | loss: 1.9853909
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   205 | loss: 1.9077237
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   206 | loss: 2.0069985
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   207 | loss: 1.9973819
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   208 | loss: 1.9396362
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   209 | loss: 1.9856263
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   210 | loss: 1.9907095
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   211 | loss: 1.9976826
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   212 | loss: 1.9449490
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   213 | loss: 1.9607533
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   214 | loss: 1.9770439
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   215 | loss: 1.9662838
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   216 | loss: 1.9448193
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   217 | loss: 1.9628038
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   218 | loss: 1.9388869
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   219 | loss: 1.9654186
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   220 | loss: 1.9836426
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   221 | loss: 1.9343622
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   222 | loss: 1.9685237
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   223 | loss: 1.9700327
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   224 | loss: 1.9934360
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   225 | loss: 1.9760364
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   226 | loss: 1.9910171
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   227 | loss: 1.9650667
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   228 | loss: 1.9281998
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   229 | loss: 1.9277365
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   230 | loss: 1.9556137
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   231 | loss: 1.9638050
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch   232 | loss: 1.9229195
merged_hidden:  torch.Size([4, 768])
merged_labels:  torch.Size([4])
MixupTrain:  epoch  0, batch   233 | loss: 1.8555130
MemoryTrain:  epoch  0, batch     0 | loss: 1.9249033
MemoryTrain:  epoch  0, batch     1 | loss: 3.0322273
MemoryTrain:  epoch  0, batch     2 | loss: 2.9955444
MemoryTrain:  epoch  0, batch     3 | loss: 2.7848554
MemoryTrain:  epoch  0, batch     4 | loss: 2.3028622
MemoryTrain:  epoch  1, batch     0 | loss: 1.8708626
MemoryTrain:  epoch  1, batch     1 | loss: 1.9097499
MemoryTrain:  epoch  1, batch     2 | loss: 1.8843789
MemoryTrain:  epoch  1, batch     3 | loss: 1.8639827
MemoryTrain:  epoch  1, batch     4 | loss: 1.8560162
MemoryTrain:  epoch  2, batch     0 | loss: 1.8715808
MemoryTrain:  epoch  2, batch     1 | loss: 1.8711185
MemoryTrain:  epoch  2, batch     2 | loss: 1.8724971
MemoryTrain:  epoch  2, batch     3 | loss: 1.9025896
MemoryTrain:  epoch  2, batch     4 | loss: 1.8480804
MemoryTrain:  epoch  3, batch     0 | loss: 1.8594875
MemoryTrain:  epoch  3, batch     1 | loss: 1.8696694
MemoryTrain:  epoch  3, batch     2 | loss: 1.8642662
MemoryTrain:  epoch  3, batch     3 | loss: 1.8603243
MemoryTrain:  epoch  3, batch     4 | loss: 1.8321741
MemoryTrain:  epoch  4, batch     0 | loss: 1.8415403
MemoryTrain:  epoch  4, batch     1 | loss: 1.8629558
MemoryTrain:  epoch  4, batch     2 | loss: 1.8674403
MemoryTrain:  epoch  4, batch     3 | loss: 1.8695462
MemoryTrain:  epoch  4, batch     4 | loss: 1.8582569
MemoryTrain:  epoch  5, batch     0 | loss: 1.8557088
MemoryTrain:  epoch  5, batch     1 | loss: 1.8937813
MemoryTrain:  epoch  5, batch     2 | loss: 1.8421570
MemoryTrain:  epoch  5, batch     3 | loss: 1.8772233
MemoryTrain:  epoch  5, batch     4 | loss: 1.8421512
MemoryTrain:  epoch  6, batch     0 | loss: 1.8546441
MemoryTrain:  epoch  6, batch     1 | loss: 1.8498437
MemoryTrain:  epoch  6, batch     2 | loss: 1.8474635
MemoryTrain:  epoch  6, batch     3 | loss: 1.8512765
MemoryTrain:  epoch  6, batch     4 | loss: 1.8591335
MemoryTrain:  epoch  7, batch     0 | loss: 1.8647277
MemoryTrain:  epoch  7, batch     1 | loss: 1.8504809
MemoryTrain:  epoch  7, batch     2 | loss: 1.8665534
MemoryTrain:  epoch  7, batch     3 | loss: 1.8490943
MemoryTrain:  epoch  7, batch     4 | loss: 2.0766258
MemoryTrain:  epoch  8, batch     0 | loss: 1.8625457
MemoryTrain:  epoch  8, batch     1 | loss: 1.8857839
MemoryTrain:  epoch  8, batch     2 | loss: 1.8459215
MemoryTrain:  epoch  8, batch     3 | loss: 1.8800683
MemoryTrain:  epoch  8, batch     4 | loss: 1.8233602
MemoryTrain:  epoch  9, batch     0 | loss: 1.8620406
MemoryTrain:  epoch  9, batch     1 | loss: 1.8776605
MemoryTrain:  epoch  9, batch     2 | loss: 1.9015019
MemoryTrain:  epoch  9, batch     3 | loss: 1.8764073
MemoryTrain:  epoch  9, batch     4 | loss: 1.8908693
[EVAL] batch:    0 | acc: 87.50%,  total acc: 87.50%   
[EVAL] batch:    1 | acc: 93.75%,  total acc: 90.62%   
[EVAL] batch:    2 | acc: 100.00%,  total acc: 93.75%   
[EVAL] batch:    3 | acc: 93.75%,  total acc: 93.75%   
[EVAL] batch:    4 | acc: 100.00%,  total acc: 95.00%   
[EVAL] batch:    5 | acc: 100.00%,  total acc: 95.83%   
[EVAL] batch:    6 | acc: 81.25%,  total acc: 93.75%   
[EVAL] batch:    7 | acc: 93.75%,  total acc: 93.75%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 94.44%   
[EVAL] batch:    9 | acc: 87.50%,  total acc: 93.75%   
[EVAL] batch:   10 | acc: 87.50%,  total acc: 93.18%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 93.23%   
[EVAL] batch:   12 | acc: 81.25%,  total acc: 92.31%   
[EVAL] batch:   13 | acc: 25.00%,  total acc: 87.50%   
[EVAL] batch:    0 | acc: 68.75%,  total acc: 68.75%   
[EVAL] batch:    1 | acc: 75.00%,  total acc: 71.88%   
[EVAL] batch:    2 | acc: 75.00%,  total acc: 72.92%   
[EVAL] batch:    3 | acc: 56.25%,  total acc: 68.75%   
[EVAL] batch:    4 | acc: 75.00%,  total acc: 70.00%   
[EVAL] batch:    5 | acc: 68.75%,  total acc: 69.79%   
[EVAL] batch:    6 | acc: 93.75%,  total acc: 73.21%   
[EVAL] batch:    7 | acc: 100.00%,  total acc: 76.56%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 79.17%   
[EVAL] batch:    9 | acc: 87.50%,  total acc: 80.00%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 81.82%   
[EVAL] batch:   11 | acc: 87.50%,  total acc: 82.29%   
[EVAL] batch:   12 | acc: 93.75%,  total acc: 83.17%   
[EVAL] batch:   13 | acc: 68.75%,  total acc: 82.14%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 81.67%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 80.08%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 79.78%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 78.82%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 77.96%   
[EVAL] batch:   19 | acc: 87.50%,  total acc: 78.44%   
[EVAL] batch:   20 | acc: 93.75%,  total acc: 79.17%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 80.11%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 80.98%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 81.77%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 82.50%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 83.17%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 83.56%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 84.15%   
[EVAL] batch:   28 | acc: 87.50%,  total acc: 84.27%   
[EVAL] batch:   29 | acc: 81.25%,  total acc: 84.17%   
[EVAL] batch:   30 | acc: 100.00%,  total acc: 84.68%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 84.96%   
[EVAL] batch:   32 | acc: 100.00%,  total acc: 85.42%   
[EVAL] batch:   33 | acc: 81.25%,  total acc: 85.29%   
[EVAL] batch:   34 | acc: 100.00%,  total acc: 85.71%   
[EVAL] batch:   35 | acc: 93.75%,  total acc: 85.94%   
[EVAL] batch:   36 | acc: 100.00%,  total acc: 86.32%   
[EVAL] batch:   37 | acc: 100.00%,  total acc: 86.68%   
[EVAL] batch:   38 | acc: 100.00%,  total acc: 87.02%   
[EVAL] batch:   39 | acc: 75.00%,  total acc: 86.72%   
[EVAL] batch:   40 | acc: 100.00%,  total acc: 87.04%   
[EVAL] batch:   41 | acc: 93.75%,  total acc: 87.20%   
[EVAL] batch:   42 | acc: 93.75%,  total acc: 87.35%   
[EVAL] batch:   43 | acc: 81.25%,  total acc: 87.22%   
[EVAL] batch:   44 | acc: 100.00%,  total acc: 87.50%   
[EVAL] batch:   45 | acc: 43.75%,  total acc: 86.55%   
[EVAL] batch:   46 | acc: 0.00%,  total acc: 84.71%   
cur_acc:  ['0.8712', '0.8750']
his_acc:  ['0.8712', '0.8471']
CurrentTrain: epoch  0, batch     0 | loss: 5.5258837
CurrentTrain: epoch  0, batch     1 | loss: 7.6135340
CurrentTrain: epoch  1, batch     0 | loss: 5.8323936
CurrentTrain: epoch  1, batch     1 | loss: 5.0353494
CurrentTrain: epoch  2, batch     0 | loss: 4.3900461
CurrentTrain: epoch  2, batch     1 | loss: 4.6146545
CurrentTrain: epoch  3, batch     0 | loss: 3.9451888
CurrentTrain: epoch  3, batch     1 | loss: 3.7096100
CurrentTrain: epoch  4, batch     0 | loss: 2.9300318
CurrentTrain: epoch  4, batch     1 | loss: 3.7482369
CurrentTrain: epoch  5, batch     0 | loss: 3.0410981
CurrentTrain: epoch  5, batch     1 | loss: 2.6936760
CurrentTrain: epoch  6, batch     0 | loss: 2.9269757
CurrentTrain: epoch  6, batch     1 | loss: 2.1655674
CurrentTrain: epoch  7, batch     0 | loss: 2.4864054
CurrentTrain: epoch  7, batch     1 | loss: 2.5192039
CurrentTrain: epoch  8, batch     0 | loss: 2.1051612
CurrentTrain: epoch  8, batch     1 | loss: 3.1150973
CurrentTrain: epoch  9, batch     0 | loss: 2.1227884
CurrentTrain: epoch  9, batch     1 | loss: 2.3963940
#### person country of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person country of birth" means a person was born in a country.
Here is an example:
Relation: person country of birth
Context: in testimony by satellite link from germany to a house of representatives ' panel , murat kurnaz recounted his five-year detention , alleging a wide range of torture and abuse .
Head Entity: murat kurnaz
Tail Entity: germany
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person country of birth":
Relation: person country of birth  
Context: The famous physicist Albert Einstein was born in the Kingdom of Württemberg in the German Empire.  
Head Entity: Albert Einstein  
Tail Entity: Germany  

Relation: person country of birth  
Context: During an interview, the actress Sofia Vergara shared her experiences growing up in Barranquilla, Colombia, before moving to the United States.  
Head Entity: Sofia Vergara  
Tail Entity: Colombia  

Relation: person country of birth  
Context: The renowned author Gabriel García Márquez was born in Aracataca, a small town in Colombia, which greatly influenced his literary works.  
Head Entity: Gabriel García Márquez  
Tail Entity: Colombia  

Relation: person country of birth  
Context: In a documentary, the musician Freddie Mercury discussed his childhood in Zanzibar, where he was born before moving to England.  
Head Entity: Freddie Mercury  
Tail Entity: Tanzania  

Relation: person country of birth  
Context: The famous painter Pablo Picasso was born in Málaga, Spain, which played a significant role in his early artistic development.  
Head Entity: Pablo Picasso  
Tail Entity: Spain  
#### organization website ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization website" means an organization 's website is an url.
Here is an example:
Relation: organization website
Context: http://www.pentaxsailaway.com/ paul j. sail away with pentax sweepstakes
Head Entity: pentax
Tail Entity: http://www.pentaxsailaway.com/
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization website":
Relation: organization website  
Context: Visit our official site at https://www.techinnovators.com for the latest updates.  
Head Entity: Tech Innovators  
Tail Entity: https://www.techinnovators.com  

Relation: organization website  
Context: For more information, check out the website of Green Earth Solutions at http://www.greenearthsolutions.org.  
Head Entity: Green Earth Solutions  
Tail Entity: http://www.greenearthsolutions.org  

Relation: organization website  
Context: You can find our services listed on https://www.creativeagency.com, where we showcase our portfolio.  
Head Entity: Creative Agency  
Tail Entity: https://www.creativeagency.com  

Relation: organization website  
Context: The official website for Global Health Initiative is located at http://www.globalhealthinitiative.net.  
Head Entity: Global Health Initiative  
Tail Entity: http://www.globalhealthinitiative.net  

Relation: organization website  
Context: Learn more about our mission at https://www.educationforall.org, the website of Education for All.  
Head Entity: Education for All  
Tail Entity: https://www.educationforall.org  
#### organization shareholders ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization shareholders" means an organization was invested by a person.
Here is an example:
Relation: organization shareholders
Context: marsans already owns the madrid-based air comet and 95 percent of aerolineas argentinas .
Head Entity: aerolineas argentinas
Tail Entity: marsans
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization shareholders":
Relation: organization shareholders  
Context: tech giant apple has seen significant investments from warren buffett's berkshire hathaway.  
Head Entity: apple  
Tail Entity: berkshire hathaway  

Relation: organization shareholders  
Context: the famous investor george soros has acquired a substantial stake in the online retail company alibaba.  
Head Entity: alibaba  
Tail Entity: george soros  

Relation: organization shareholders  
Context: the pharmaceutical company pfizer has received funding from the investment firm blackrock.  
Head Entity: pfizer  
Tail Entity: blackrock  

Relation: organization shareholders  
Context: the renewable energy firm nextera energy has attracted investments from the investment group vanguard.  
Head Entity: nextera energy  
Tail Entity: vanguard  

Relation: organization shareholders  
Context: the automotive manufacturer tesla has been partially funded by elon musk's personal investments.  
Head Entity: tesla  
Tail Entity: elon musk  
#### organization dissolved ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization dissolved" means an organization was dissolved in a date.
Here is an example:
Relation: organization dissolved
Context: the tse suffered its worst-ever system crash in november 2005 which paralyzed the world 's second largest bourse and forced it to shelve plan for a listing of its own .
Head Entity: tse
Tail Entity: november 2005
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization dissolved":
Relation: organization dissolved  
Context: The once-prominent tech startup, Innovatech, officially ceased operations in March 2020 after struggling to secure funding.  
Head Entity: Innovatech  
Tail Entity: March 2020  

Relation: organization dissolved  
Context: After years of financial difficulties, the local arts council announced its dissolution in January 2019, leaving many artists without support.  
Head Entity: local arts council  
Tail Entity: January 2019  

Relation: organization dissolved  
Context: The historic bookstore, Pages & Co., closed its doors for good in July 2021, marking the end of an era for the community.  
Head Entity: Pages & Co.  
Tail Entity: July 2021  

Relation: organization dissolved  
Context: Following a series of scandals, the charity organization, Helping Hands, was officially dissolved in February 2022.  
Head Entity: Helping Hands  
Tail Entity: February 2022  

Relation: organization dissolved  
Context: The environmental group, Green Future, announced its dissolution in October 2018 due to a lack of funding and support.  
Head Entity: Green Future  
Tail Entity: October 2018  
#### organization founded by ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization founded by" means an organization was found by a person.
Here is an example:
Relation: organization founded by
Context: born in new york , she inherited most of her fortune from her father , ted arison , who founded carnival cruise lines and also owned the miami heat basketball team .
Head Entity: carnival cruise lines
Tail Entity: ted arison
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization founded by":
1. Relation: organization founded by  
   Context: in 1975, steve jobs and steve wozniak started apple inc., which revolutionized the personal computing industry.  
   Head Entity: apple inc.  
   Tail Entity: steve jobs  

2. Relation: organization founded by  
   Context: the famous fashion brand gucci was established in florence by guccio gucci in 1921, becoming a symbol of luxury and style.  
   Head Entity: gucci  
   Tail Entity: guccio gucci  

3. Relation: organization founded by  
   Context: in 1994, jeff bezos launched amazon.com from his garage, transforming the way people shop online.  
   Head Entity: amazon.com  
   Tail Entity: jeff bezos  

4. Relation: organization founded by  
   Context: the non-profit organization greenpeace was co-founded by irving stowe and dorothy stowe in 1971 to promote environmental awareness.  
   Head Entity: greenpeace  
   Tail Entity: irving stowe  

5. Relation: organization founded by  
   Context: the social media platform facebook was created by mark zuckerberg along with his college roommates in 2004 while they were at harvard university.  
   Head Entity: facebook  
   Tail Entity: mark zuckerberg  
Mixup data size:  6820
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch     0 | loss: 5.4799209
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch     1 | loss: 5.1503086
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch     2 | loss: 5.3616590
merged_hidden:  torch.Size([32, 768])
merged_labels:  torch.Size([32])
MixupTrain:  epoch  0, batch     3 | loss: 5.9013042
merged_hidden:  torch.Size([32, 744])
merged_labels:  torch.Size([32])
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2197, 2005, 2023, 1010, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 4]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 5]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 3]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 5]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 3]}
{'ids': [101, 2342, 5678, 1234, 4321, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [5, 3]}
#############params############
cuda:0
Task=Tacred, 5-shot
Encoding model: bert
pattern=hardprompt
mem=1, margin=0.3, gen=1, gen_num=5
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
CurrentTrain: epoch  0, batch     0 | loss: 12.2377892
CurrentTrain: epoch  0, batch     1 | loss: 11.8358202
CurrentTrain: epoch  0, batch     2 | loss: 11.5842304
CurrentTrain: epoch  0, batch     3 | loss: 11.7963333
CurrentTrain: epoch  0, batch     4 | loss: 11.3291626
CurrentTrain: epoch  0, batch     5 | loss: 11.3988247
CurrentTrain: epoch  0, batch     6 | loss: 11.4306774
CurrentTrain: epoch  0, batch     7 | loss: 11.4957294
CurrentTrain: epoch  0, batch     8 | loss: 10.9524660
CurrentTrain: epoch  0, batch     9 | loss: 11.0981150
CurrentTrain: epoch  0, batch    10 | loss: 11.0817156
CurrentTrain: epoch  0, batch    11 | loss: 11.0157957
CurrentTrain: epoch  0, batch    12 | loss: 10.9861202
CurrentTrain: epoch  0, batch    13 | loss: 10.7110462
CurrentTrain: epoch  0, batch    14 | loss: 10.5633354
CurrentTrain: epoch  0, batch    15 | loss: 10.2521629
CurrentTrain: epoch  0, batch    16 | loss: 9.5208607
CurrentTrain: epoch  0, batch    17 | loss: 10.0118418
CurrentTrain: epoch  0, batch    18 | loss: 9.9925213
CurrentTrain: epoch  0, batch    19 | loss: 10.5049925
CurrentTrain: epoch  0, batch    20 | loss: 9.9245691
CurrentTrain: epoch  0, batch    21 | loss: 10.7969608
CurrentTrain: epoch  0, batch    22 | loss: 10.3663940
CurrentTrain: epoch  0, batch    23 | loss: 9.9787502
CurrentTrain: epoch  0, batch    24 | loss: 10.1565428
CurrentTrain: epoch  0, batch    25 | loss: 9.8991623
CurrentTrain: epoch  0, batch    26 | loss: 10.0962982
CurrentTrain: epoch  0, batch    27 | loss: 9.3844519
CurrentTrain: epoch  0, batch    28 | loss: 9.7764397
CurrentTrain: epoch  0, batch    29 | loss: 9.7736034
CurrentTrain: epoch  0, batch    30 | loss: 9.4480782
CurrentTrain: epoch  0, batch    31 | loss: 9.9147511
CurrentTrain: epoch  0, batch    32 | loss: 9.6330633
CurrentTrain: epoch  0, batch    33 | loss: 9.6556149
CurrentTrain: epoch  0, batch    34 | loss: 8.9573956
CurrentTrain: epoch  0, batch    35 | loss: 9.5650816
CurrentTrain: epoch  0, batch    36 | loss: 9.7023954
CurrentTrain: epoch  0, batch    37 | loss: 9.6724091
CurrentTrain: epoch  1, batch     0 | loss: 9.4604149
CurrentTrain: epoch  1, batch     1 | loss: 10.1246471
CurrentTrain: epoch  1, batch     2 | loss: 8.5899754
CurrentTrain: epoch  1, batch     3 | loss: 9.2962093
CurrentTrain: epoch  1, batch     4 | loss: 8.6637697
CurrentTrain: epoch  1, batch     5 | loss: 9.6263733
CurrentTrain: epoch  1, batch     6 | loss: 8.9486284
CurrentTrain: epoch  1, batch     7 | loss: 9.0029678
CurrentTrain: epoch  1, batch     8 | loss: 8.8491497
CurrentTrain: epoch  1, batch     9 | loss: 8.9430141
CurrentTrain: epoch  1, batch    10 | loss: 9.5420208
CurrentTrain: epoch  1, batch    11 | loss: 9.6031132
CurrentTrain: epoch  1, batch    12 | loss: 9.1848850
CurrentTrain: epoch  1, batch    13 | loss: 8.3578682
CurrentTrain: epoch  1, batch    14 | loss: 8.9222250
CurrentTrain: epoch  1, batch    15 | loss: 8.7862034
CurrentTrain: epoch  1, batch    16 | loss: 8.7784939
CurrentTrain: epoch  1, batch    17 | loss: 9.0060778
CurrentTrain: epoch  1, batch    18 | loss: 8.9019585
CurrentTrain: epoch  1, batch    19 | loss: 9.1300135
CurrentTrain: epoch  1, batch    20 | loss: 9.2238483
CurrentTrain: epoch  1, batch    21 | loss: 8.7556190
CurrentTrain: epoch  1, batch    22 | loss: 8.7446423
CurrentTrain: epoch  1, batch    23 | loss: 8.4535732
CurrentTrain: epoch  1, batch    24 | loss: 8.9085588
CurrentTrain: epoch  1, batch    25 | loss: 7.8729029
CurrentTrain: epoch  1, batch    26 | loss: 8.9874878
CurrentTrain: epoch  1, batch    27 | loss: 8.0600681
CurrentTrain: epoch  1, batch    28 | loss: 8.3288574
CurrentTrain: epoch  1, batch    29 | loss: 7.3486710
CurrentTrain: epoch  1, batch    30 | loss: 8.0324583
CurrentTrain: epoch  1, batch    31 | loss: 9.0403643
CurrentTrain: epoch  1, batch    32 | loss: 8.3986797
CurrentTrain: epoch  1, batch    33 | loss: 8.3034315
CurrentTrain: epoch  1, batch    34 | loss: 8.3720951
CurrentTrain: epoch  1, batch    35 | loss: 7.7797775
CurrentTrain: epoch  1, batch    36 | loss: 8.1887569
CurrentTrain: epoch  1, batch    37 | loss: 9.3430576
CurrentTrain: epoch  2, batch     0 | loss: 7.3662424
CurrentTrain: epoch  2, batch     1 | loss: 8.3544626
CurrentTrain: epoch  2, batch     2 | loss: 8.4783211
CurrentTrain: epoch  2, batch     3 | loss: 7.9830246
CurrentTrain: epoch  2, batch     4 | loss: 8.9861774
CurrentTrain: epoch  2, batch     5 | loss: 9.1120319
CurrentTrain: epoch  2, batch     6 | loss: 8.2785549
CurrentTrain: epoch  2, batch     7 | loss: 7.8161860
CurrentTrain: epoch  2, batch     8 | loss: 7.7946243
CurrentTrain: epoch  2, batch     9 | loss: 8.1371365
CurrentTrain: epoch  2, batch    10 | loss: 8.1274719
CurrentTrain: epoch  2, batch    11 | loss: 8.1458416
CurrentTrain: epoch  2, batch    12 | loss: 7.7329111
CurrentTrain: epoch  2, batch    13 | loss: 7.4998751
CurrentTrain: epoch  2, batch    14 | loss: 6.7733631
CurrentTrain: epoch  2, batch    15 | loss: 7.4271975
CurrentTrain: epoch  2, batch    16 | loss: 7.8946323
CurrentTrain: epoch  2, batch    17 | loss: 8.1287365
CurrentTrain: epoch  2, batch    18 | loss: 7.7022080
CurrentTrain: epoch  2, batch    19 | loss: 7.6633844
CurrentTrain: epoch  2, batch    20 | loss: 7.5645056
CurrentTrain: epoch  2, batch    21 | loss: 7.2468576
CurrentTrain: epoch  2, batch    22 | loss: 6.6268282
CurrentTrain: epoch  2, batch    23 | loss: 7.0505657
CurrentTrain: epoch  2, batch    24 | loss: 7.3652039
CurrentTrain: epoch  2, batch    25 | loss: 7.9841595
CurrentTrain: epoch  2, batch    26 | loss: 6.9228649
CurrentTrain: epoch  2, batch    27 | loss: 8.3433628
CurrentTrain: epoch  2, batch    28 | loss: 6.2205820
CurrentTrain: epoch  2, batch    29 | loss: 7.9827604
CurrentTrain: epoch  2, batch    30 | loss: 7.5686135
CurrentTrain: epoch  2, batch    31 | loss: 6.7521391
CurrentTrain: epoch  2, batch    32 | loss: 7.1855884
CurrentTrain: epoch  2, batch    33 | loss: 7.1788774
CurrentTrain: epoch  2, batch    34 | loss: 8.3621635
CurrentTrain: epoch  2, batch    35 | loss: 6.9254699
CurrentTrain: epoch  2, batch    36 | loss: 7.5592299
CurrentTrain: epoch  2, batch    37 | loss: 6.8255949
CurrentTrain: epoch  3, batch     0 | loss: 7.7647505
CurrentTrain: epoch  3, batch     1 | loss: 7.5025458
CurrentTrain: epoch  3, batch     2 | loss: 7.7400827
CurrentTrain: epoch  3, batch     3 | loss: 8.1283417
CurrentTrain: epoch  3, batch     4 | loss: 7.6592603
CurrentTrain: epoch  3, batch     5 | loss: 7.6934776
CurrentTrain: epoch  3, batch     6 | loss: 8.0932388
CurrentTrain: epoch  3, batch     7 | loss: 6.8233399
CurrentTrain: epoch  3, batch     8 | loss: 7.4070482
CurrentTrain: epoch  3, batch     9 | loss: 7.3779402
CurrentTrain: epoch  3, batch    10 | loss: 6.8089685
CurrentTrain: epoch  3, batch    11 | loss: 6.3608518
CurrentTrain: epoch  3, batch    12 | loss: 7.6196122
CurrentTrain: epoch  3, batch    13 | loss: 8.0267200
CurrentTrain: epoch  3, batch    14 | loss: 7.0713158
CurrentTrain: epoch  3, batch    15 | loss: 7.1864080
CurrentTrain: epoch  3, batch    16 | loss: 7.9409227
CurrentTrain: epoch  3, batch    17 | loss: 7.0805454
CurrentTrain: epoch  3, batch    18 | loss: 7.2674842
CurrentTrain: epoch  3, batch    19 | loss: 7.0971551
CurrentTrain: epoch  3, batch    20 | loss: 7.1673136
CurrentTrain: epoch  3, batch    21 | loss: 7.2108817
CurrentTrain: epoch  3, batch    22 | loss: 8.0766506
CurrentTrain: epoch  3, batch    23 | loss: 7.5205364
CurrentTrain: epoch  3, batch    24 | loss: 6.2361536
CurrentTrain: epoch  3, batch    25 | loss: 6.7487731
CurrentTrain: epoch  3, batch    26 | loss: 6.3052359
CurrentTrain: epoch  3, batch    27 | loss: 7.1938982
CurrentTrain: epoch  3, batch    28 | loss: 7.2758160
CurrentTrain: epoch  3, batch    29 | loss: 5.9751406
CurrentTrain: epoch  3, batch    30 | loss: 7.0339866
CurrentTrain: epoch  3, batch    31 | loss: 7.0741363
CurrentTrain: epoch  3, batch    32 | loss: 6.2167683
CurrentTrain: epoch  3, batch    33 | loss: 5.7902369
CurrentTrain: epoch  3, batch    34 | loss: 6.7244143
CurrentTrain: epoch  3, batch    35 | loss: 6.2465477
CurrentTrain: epoch  3, batch    36 | loss: 6.7644510
CurrentTrain: epoch  3, batch    37 | loss: 6.6600256
CurrentTrain: epoch  4, batch     0 | loss: 6.9214773
CurrentTrain: epoch  4, batch     1 | loss: 6.3543296
CurrentTrain: epoch  4, batch     2 | loss: 5.6729169
CurrentTrain: epoch  4, batch     3 | loss: 6.7485514
CurrentTrain: epoch  4, batch     4 | loss: 7.2618380
CurrentTrain: epoch  4, batch     5 | loss: 6.6126189
CurrentTrain: epoch  4, batch     6 | loss: 6.2170911
CurrentTrain: epoch  4, batch     7 | loss: 6.6977735
CurrentTrain: epoch  4, batch     8 | loss: 7.4788270
CurrentTrain: epoch  4, batch     9 | loss: 6.5936441
CurrentTrain: epoch  4, batch    10 | loss: 6.9046702
CurrentTrain: epoch  4, batch    11 | loss: 6.0163383
CurrentTrain: epoch  4, batch    12 | loss: 6.5755177
CurrentTrain: epoch  4, batch    13 | loss: 6.2283492
CurrentTrain: epoch  4, batch    14 | loss: 7.0001431
CurrentTrain: epoch  4, batch    15 | loss: 6.6601152
CurrentTrain: epoch  4, batch    16 | loss: 6.3596520
CurrentTrain: epoch  4, batch    17 | loss: 6.3576050
CurrentTrain: epoch  4, batch    18 | loss: 5.9598074
CurrentTrain: epoch  4, batch    19 | loss: 6.0913982
CurrentTrain: epoch  4, batch    20 | loss: 6.2184505
CurrentTrain: epoch  4, batch    21 | loss: 6.5159440
CurrentTrain: epoch  4, batch    22 | loss: 6.6188974
CurrentTrain: epoch  4, batch    23 | loss: 5.9724197
CurrentTrain: epoch  4, batch    24 | loss: 6.6317444
CurrentTrain: epoch  4, batch    25 | loss: 6.5978203
CurrentTrain: epoch  4, batch    26 | loss: 6.0009141
CurrentTrain: epoch  4, batch    27 | loss: 7.6149282
CurrentTrain: epoch  4, batch    28 | loss: 5.8510528
CurrentTrain: epoch  4, batch    29 | loss: 6.1155725
CurrentTrain: epoch  4, batch    30 | loss: 5.9866090
CurrentTrain: epoch  4, batch    31 | loss: 6.0753689
CurrentTrain: epoch  4, batch    32 | loss: 6.2112637
CurrentTrain: epoch  4, batch    33 | loss: 5.6074681
CurrentTrain: epoch  4, batch    34 | loss: 6.8721824
CurrentTrain: epoch  4, batch    35 | loss: 6.1603594
CurrentTrain: epoch  4, batch    36 | loss: 5.9010696
CurrentTrain: epoch  4, batch    37 | loss: 6.5777607
CurrentTrain: epoch  5, batch     0 | loss: 5.6601758
CurrentTrain: epoch  5, batch     1 | loss: 6.0248494
CurrentTrain: epoch  5, batch     2 | loss: 6.2602463
CurrentTrain: epoch  5, batch     3 | loss: 6.3877387
CurrentTrain: epoch  5, batch     4 | loss: 5.9552431
CurrentTrain: epoch  5, batch     5 | loss: 5.9370213
CurrentTrain: epoch  5, batch     6 | loss: 6.2484322
CurrentTrain: epoch  5, batch     7 | loss: 6.5060091
CurrentTrain: epoch  5, batch     8 | loss: 6.5059867
CurrentTrain: epoch  5, batch     9 | loss: 5.7736840
CurrentTrain: epoch  5, batch    10 | loss: 5.7672777
CurrentTrain: epoch  5, batch    11 | loss: 6.0279074
CurrentTrain: epoch  5, batch    12 | loss: 5.7482686
CurrentTrain: epoch  5, batch    13 | loss: 5.9997821
CurrentTrain: epoch  5, batch    14 | loss: 6.2035551
CurrentTrain: epoch  5, batch    15 | loss: 6.5068035
CurrentTrain: epoch  5, batch    16 | loss: 5.3515067
CurrentTrain: epoch  5, batch    17 | loss: 5.5702515
CurrentTrain: epoch  5, batch    18 | loss: 6.6157694
CurrentTrain: epoch  5, batch    19 | loss: 7.0879307
CurrentTrain: epoch  5, batch    20 | loss: 5.5562043
CurrentTrain: epoch  5, batch    21 | loss: 5.8516216
CurrentTrain: epoch  5, batch    22 | loss: 5.6183128
CurrentTrain: epoch  5, batch    23 | loss: 6.0548382
CurrentTrain: epoch  5, batch    24 | loss: 6.8281794
CurrentTrain: epoch  5, batch    25 | loss: 5.7778754
CurrentTrain: epoch  5, batch    26 | loss: 5.8007574
CurrentTrain: epoch  5, batch    27 | loss: 5.6567163
CurrentTrain: epoch  5, batch    28 | loss: 6.8478708
CurrentTrain: epoch  5, batch    29 | loss: 6.6075182
CurrentTrain: epoch  5, batch    30 | loss: 5.7610102
CurrentTrain: epoch  5, batch    31 | loss: 5.8279133
CurrentTrain: epoch  5, batch    32 | loss: 5.3630514
CurrentTrain: epoch  5, batch    33 | loss: 5.9219146
CurrentTrain: epoch  5, batch    34 | loss: 5.7536297
CurrentTrain: epoch  5, batch    35 | loss: 5.9297442
CurrentTrain: epoch  5, batch    36 | loss: 6.1582942
CurrentTrain: epoch  5, batch    37 | loss: 5.3770695
CurrentTrain: epoch  6, batch     0 | loss: 5.3385010
CurrentTrain: epoch  6, batch     1 | loss: 5.7504702
CurrentTrain: epoch  6, batch     2 | loss: 6.0827885
CurrentTrain: epoch  6, batch     3 | loss: 6.0616360
CurrentTrain: epoch  6, batch     4 | loss: 5.5673351
CurrentTrain: epoch  6, batch     5 | loss: 5.4255438
CurrentTrain: epoch  6, batch     6 | loss: 5.8536959
CurrentTrain: epoch  6, batch     7 | loss: 5.7188549
CurrentTrain: epoch  6, batch     8 | loss: 5.2314873
CurrentTrain: epoch  6, batch     9 | loss: 5.6400099
CurrentTrain: epoch  6, batch    10 | loss: 5.3543816
CurrentTrain: epoch  6, batch    11 | loss: 5.3050299
CurrentTrain: epoch  6, batch    12 | loss: 5.7439237
CurrentTrain: epoch  6, batch    13 | loss: 5.4360719
CurrentTrain: epoch  6, batch    14 | loss: 5.3918200
CurrentTrain: epoch  6, batch    15 | loss: 5.1954913
CurrentTrain: epoch  6, batch    16 | loss: 5.9823422
CurrentTrain: epoch  6, batch    17 | loss: 5.4264145
CurrentTrain: epoch  6, batch    18 | loss: 5.6327276
CurrentTrain: epoch  6, batch    19 | loss: 5.9033957
CurrentTrain: epoch  6, batch    20 | loss: 6.1786757
CurrentTrain: epoch  6, batch    21 | loss: 6.3660412
CurrentTrain: epoch  6, batch    22 | loss: 6.0595322
CurrentTrain: epoch  6, batch    23 | loss: 5.5738835
CurrentTrain: epoch  6, batch    24 | loss: 5.1174212
CurrentTrain: epoch  6, batch    25 | loss: 5.9595833
CurrentTrain: epoch  6, batch    26 | loss: 6.1485519
CurrentTrain: epoch  6, batch    27 | loss: 5.7259197
CurrentTrain: epoch  6, batch    28 | loss: 5.8726430
CurrentTrain: epoch  6, batch    29 | loss: 5.5694523
CurrentTrain: epoch  6, batch    30 | loss: 6.0045009
CurrentTrain: epoch  6, batch    31 | loss: 5.6451173
CurrentTrain: epoch  6, batch    32 | loss: 5.2247005
CurrentTrain: epoch  6, batch    33 | loss: 6.1387463
CurrentTrain: epoch  6, batch    34 | loss: 5.2706861
CurrentTrain: epoch  6, batch    35 | loss: 5.5575624
CurrentTrain: epoch  6, batch    36 | loss: 5.3598919
CurrentTrain: epoch  6, batch    37 | loss: 5.5043011
CurrentTrain: epoch  7, batch     0 | loss: 5.8221326
CurrentTrain: epoch  7, batch     1 | loss: 5.2134027
CurrentTrain: epoch  7, batch     2 | loss: 5.3066864
CurrentTrain: epoch  7, batch     3 | loss: 5.0514336
CurrentTrain: epoch  7, batch     4 | loss: 5.5705714
CurrentTrain: epoch  7, batch     5 | loss: 5.2637019
CurrentTrain: epoch  7, batch     6 | loss: 5.3848391
CurrentTrain: epoch  7, batch     7 | loss: 5.0422788
CurrentTrain: epoch  7, batch     8 | loss: 5.4018226
CurrentTrain: epoch  7, batch     9 | loss: 5.1225381
CurrentTrain: epoch  7, batch    10 | loss: 5.3415217
CurrentTrain: epoch  7, batch    11 | loss: 5.3493118
CurrentTrain: epoch  7, batch    12 | loss: 5.3571339
CurrentTrain: epoch  7, batch    13 | loss: 5.5703020
CurrentTrain: epoch  7, batch    14 | loss: 5.9958162
CurrentTrain: epoch  7, batch    15 | loss: 5.4087534
CurrentTrain: epoch  7, batch    16 | loss: 5.5808349
CurrentTrain: epoch  7, batch    17 | loss: 5.3512669
CurrentTrain: epoch  7, batch    18 | loss: 4.9717011
CurrentTrain: epoch  7, batch    19 | loss: 5.1010613
CurrentTrain: epoch  7, batch    20 | loss: 5.5419488
CurrentTrain: epoch  7, batch    21 | loss: 5.0689411
CurrentTrain: epoch  7, batch    22 | loss: 6.1445966
CurrentTrain: epoch  7, batch    23 | loss: 5.4027791
CurrentTrain: epoch  7, batch    24 | loss: 5.8069553
CurrentTrain: epoch  7, batch    25 | loss: 5.1294775
CurrentTrain: epoch  7, batch    26 | loss: 5.2494717
CurrentTrain: epoch  7, batch    27 | loss: 5.3885818
CurrentTrain: epoch  7, batch    28 | loss: 5.1891451
CurrentTrain: epoch  7, batch    29 | loss: 5.2763824
CurrentTrain: epoch  7, batch    30 | loss: 5.2565598
CurrentTrain: epoch  7, batch    31 | loss: 5.2446299
CurrentTrain: epoch  7, batch    32 | loss: 5.1272998
CurrentTrain: epoch  7, batch    33 | loss: 5.2244992
CurrentTrain: epoch  7, batch    34 | loss: 5.0223141
CurrentTrain: epoch  7, batch    35 | loss: 5.1779542
CurrentTrain: epoch  7, batch    36 | loss: 5.1301193
CurrentTrain: epoch  7, batch    37 | loss: 4.8143196
CurrentTrain: epoch  8, batch     0 | loss: 5.1579475
CurrentTrain: epoch  8, batch     1 | loss: 5.1543798
CurrentTrain: epoch  8, batch     2 | loss: 4.8897972
CurrentTrain: epoch  8, batch     3 | loss: 5.0410523
CurrentTrain: epoch  8, batch     4 | loss: 5.2717929
CurrentTrain: epoch  8, batch     5 | loss: 4.9771128
CurrentTrain: epoch  8, batch     6 | loss: 5.0834179
CurrentTrain: epoch  8, batch     7 | loss: 5.0067358
CurrentTrain: epoch  8, batch     8 | loss: 5.0641761
CurrentTrain: epoch  8, batch     9 | loss: 5.0935326
CurrentTrain: epoch  8, batch    10 | loss: 5.2907119
CurrentTrain: epoch  8, batch    11 | loss: 4.9250479
CurrentTrain: epoch  8, batch    12 | loss: 5.0914650
CurrentTrain: epoch  8, batch    13 | loss: 4.9756813
CurrentTrain: epoch  8, batch    14 | loss: 5.2059898
CurrentTrain: epoch  8, batch    15 | loss: 5.2468882
CurrentTrain: epoch  8, batch    16 | loss: 4.9808016
CurrentTrain: epoch  8, batch    17 | loss: 4.8144884
CurrentTrain: epoch  8, batch    18 | loss: 5.2888255
CurrentTrain: epoch  8, batch    19 | loss: 4.9981937
CurrentTrain: epoch  8, batch    20 | loss: 5.1061277
CurrentTrain: epoch  8, batch    21 | loss: 5.0941725
CurrentTrain: epoch  8, batch    22 | loss: 5.3479795
CurrentTrain: epoch  8, batch    23 | loss: 5.2284288
CurrentTrain: epoch  8, batch    24 | loss: 4.9951601
CurrentTrain: epoch  8, batch    25 | loss: 5.0256500
CurrentTrain: epoch  8, batch    26 | loss: 5.3343859
CurrentTrain: epoch  8, batch    27 | loss: 4.9719343
CurrentTrain: epoch  8, batch    28 | loss: 5.2509747
CurrentTrain: epoch  8, batch    29 | loss: 5.0940399
CurrentTrain: epoch  8, batch    30 | loss: 4.9406633
CurrentTrain: epoch  8, batch    31 | loss: 5.1270304
CurrentTrain: epoch  8, batch    32 | loss: 4.7761073
CurrentTrain: epoch  8, batch    33 | loss: 4.9832006
CurrentTrain: epoch  8, batch    34 | loss: 4.9552345
CurrentTrain: epoch  8, batch    35 | loss: 5.4438825
CurrentTrain: epoch  8, batch    36 | loss: 4.9208779
CurrentTrain: epoch  8, batch    37 | loss: 4.9012098
CurrentTrain: epoch  9, batch     0 | loss: 5.3065910
CurrentTrain: epoch  9, batch     1 | loss: 5.1796370
CurrentTrain: epoch  9, batch     2 | loss: 5.1072073
CurrentTrain: epoch  9, batch     3 | loss: 4.9213343
CurrentTrain: epoch  9, batch     4 | loss: 4.8819547
CurrentTrain: epoch  9, batch     5 | loss: 5.1034369
CurrentTrain: epoch  9, batch     6 | loss: 5.3321552
CurrentTrain: epoch  9, batch     7 | loss: 4.9197969
CurrentTrain: epoch  9, batch     8 | loss: 4.9653072
CurrentTrain: epoch  9, batch     9 | loss: 4.8860769
CurrentTrain: epoch  9, batch    10 | loss: 5.0107727
CurrentTrain: epoch  9, batch    11 | loss: 4.8371091
CurrentTrain: epoch  9, batch    12 | loss: 4.9469938
CurrentTrain: epoch  9, batch    13 | loss: 5.0067148
CurrentTrain: epoch  9, batch    14 | loss: 4.9856386
CurrentTrain: epoch  9, batch    15 | loss: 4.8672819
CurrentTrain: epoch  9, batch    16 | loss: 4.8858490
CurrentTrain: epoch  9, batch    17 | loss: 5.0205936
CurrentTrain: epoch  9, batch    18 | loss: 5.0734935
CurrentTrain: epoch  9, batch    19 | loss: 4.8799629
CurrentTrain: epoch  9, batch    20 | loss: 4.8950119
CurrentTrain: epoch  9, batch    21 | loss: 4.7830744
CurrentTrain: epoch  9, batch    22 | loss: 4.8854637
CurrentTrain: epoch  9, batch    23 | loss: 4.9289637
CurrentTrain: epoch  9, batch    24 | loss: 4.9857821
CurrentTrain: epoch  9, batch    25 | loss: 4.7893872
CurrentTrain: epoch  9, batch    26 | loss: 5.1338005
CurrentTrain: epoch  9, batch    27 | loss: 5.0343213
CurrentTrain: epoch  9, batch    28 | loss: 4.9264212
CurrentTrain: epoch  9, batch    29 | loss: 5.0215325
CurrentTrain: epoch  9, batch    30 | loss: 4.7740507
CurrentTrain: epoch  9, batch    31 | loss: 4.8163271
CurrentTrain: epoch  9, batch    32 | loss: 4.8064499
CurrentTrain: epoch  9, batch    33 | loss: 4.7759576
CurrentTrain: epoch  9, batch    34 | loss: 4.9853191
CurrentTrain: epoch  9, batch    35 | loss: 4.7680750
CurrentTrain: epoch  9, batch    36 | loss: 4.7871542
CurrentTrain: epoch  9, batch    37 | loss: 4.9062581
#### person countries of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person countries of residence" means a person is living in a country.
Here is an example:
Relation: person countries of residence
Context: khamenei , 67 , has final say on all state matters in iran as supreme leader , a post he has held since 1989 .
Head Entity: khamenei
Tail Entity: iran
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person countries of residence":
Relation: person countries of residence  
Context: After years of living in the United States, Maria decided to return to her homeland, spain, where she felt a deep connection.  
Head Entity: Maria  
Tail Entity: spain  

Relation: person countries of residence  
Context: The famous actor, Leonardo DiCaprio, has been known to spend a significant amount of time in both the United States and australia, where he enjoys the natural beauty.  
Head Entity: Leonardo DiCaprio  
Tail Entity: australia  

Relation: person countries of residence  
Context: Following his retirement, the renowned scientist moved to canada, where he continues his research in a peaceful environment.  
Head Entity: the renowned scientist  
Tail Entity: canada  

Relation: person countries of residence  
Context: After completing her studies in the UK, Aisha decided to settle in germany, where she found a vibrant community of fellow artists.  
Head Entity: Aisha  
Tail Entity: germany  

Relation: person countries of residence  
Context: The diplomat has lived in several countries throughout his career, but he currently resides in japan, where he is working on international relations.  
Head Entity: The diplomat  
Tail Entity: japan  
#### organization top members employees ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization top members employees" means an organization 's employer is a person.
Here is an example:
Relation: organization top members employees
Context: `` customer relationships are the backbone of banking , and banks are constantly striving to meet customer demands , '' said peter garuccio , spokesman for the american bankers association .
Head Entity: american bankers association
Tail Entity: peter garuccio
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization top members employees":
1. Relation: organization top members employees  
   Context: "As the CEO of the tech giant, she has been instrumental in driving innovation," said a company spokesperson about Jane Doe, who leads the organization.  
   Head Entity: tech giant  
   Tail Entity: Jane Doe  

2. Relation: organization top members employees  
   Context: "The board of directors is pleased to announce the appointment of John Smith as the new CFO," stated the press release from the financial services firm.  
   Head Entity: financial services firm  
   Tail Entity: John Smith  

3. Relation: organization top members employees  
   Context: "During the annual meeting, the president of the nonprofit organization highlighted the contributions of their dedicated volunteers," reported the local news outlet.  
   Head Entity: nonprofit organization  
   Tail Entity: president  

4. Relation: organization top members employees  
   Context: "In a recent interview, the founder of the startup discussed the importance of teamwork and credited his co-founder for their success," said the tech blog.  
   Head Entity: startup  
   Tail Entity: co-founder  

5. Relation: organization top members employees  
   Context: "The university's chancellor emphasized the role of faculty in shaping the future of education during the commencement speech," noted the university's official website.  
   Head Entity: university  
   Tail Entity: chancellor  
#### organization member of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization member of" means an organization is the member of an organization.
Here is an example:
Relation: organization member of
Context: over the course of the week the european union engaged in a gentlemanly tug-of-war with the organization of the islamic conference -lrb- oic -rrb- and the african regional group - which is controlled by the oic - over a range of terms and conditions .
Head Entity: oic
Tail Entity: organization of the islamic conference
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization member of":
Relation: organization member of  
Context: The United Nations has been working closely with the World Health Organization to address global health issues and improve international health standards.  
Head Entity: World Health Organization  
Tail Entity: United Nations  

Relation: organization member of  
Context: During the annual conference, the International Olympic Committee discussed its collaboration with various national sports organizations to promote athletic excellence worldwide.  
Head Entity: International Olympic Committee  
Tail Entity: national sports organizations  

Relation: organization member of  
Context: The North Atlantic Treaty Organization held a summit where member countries deliberated on collective defense strategies and military cooperation.  
Head Entity: North Atlantic Treaty Organization  
Tail Entity: member countries  

Relation: organization member of  
Context: The International Monetary Fund announced new initiatives in partnership with regional development banks to enhance economic stability in member nations.  
Head Entity: International Monetary Fund  
Tail Entity: regional development banks  

Relation: organization member of  
Context: The Global Climate Alliance is a coalition of various environmental organizations working together to combat climate change and promote sustainable practices.  
Head Entity: Global Climate Alliance  
Tail Entity: environmental organizations  
#### person origin ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person origin" means a person 's nationality is a country.
Here is an example:
Relation: person origin
Context: urgent chadian pm dies in paris hospital chad 's prime minister pascal yoadimnadji has died from a cerebral hemorrhage in a paris hospital , the chadian ambassador said friday .
Head Entity: pascal yoadimnadji
Tail Entity: chadian
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person origin":
Relation: person origin  
Context: the renowned scientist albert einstein was born in ulm, germany, and later became a citizen of the united states.  
Head Entity: albert einstein  
Tail Entity: german  

Relation: person origin  
Context: the famous author chimamanda ngozi adichie hails from enugu, nigeria, where she developed her passion for storytelling.  
Head Entity: chimamanda ngozi adichie  
Tail Entity: nigerian  

Relation: person origin  
Context: the legendary musician bob marley was born in nine mile, jamaica, and is celebrated worldwide for his contributions to reggae music.  
Head Entity: bob marley  
Tail Entity: jamaican  

Relation: person origin  
Context: the acclaimed filmmaker akira kurosawa was born in tokyo, japan, and is known for his influential works in cinema.  
Head Entity: akira kurosawa  
Tail Entity: japanese  

Relation: person origin  
Context: the famous physicist stephen hawking was born in oxford, england, and made groundbreaking contributions to theoretical physics.  
Head Entity: stephen hawking  
Tail Entity: british  
#### person title ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person title" means a person 's title is a title.
Here is an example:
Relation: person title
Context: `` making the amendment retroactive will ... help repair the image of the sentencing guidelines in communities of color , '' naacp chairman julian bond wrote to the commission .
Head Entity: julian bond
Tail Entity: chairman
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person title":
Relation: person title  
Context: `` After years of dedicated service, the board recognized Dr. Emily Carter as the new president of the organization during the annual meeting. ''  
Head Entity: Dr. Emily Carter  
Tail Entity: president  

Relation: person title  
Context: `` In his acceptance speech, the newly elected mayor, John Smith, promised to improve the city's infrastructure and public services. ''  
Head Entity: John Smith  
Tail Entity: mayor  

Relation: person title  
Context: `` The renowned scientist, Dr. Lisa Wong, received the prestigious award for her groundbreaking research in renewable energy. ''  
Head Entity: Dr. Lisa Wong  
Tail Entity: scientist  

Relation: person title  
Context: `` As the chief executive officer of the company, Maria Gonzalez outlined her vision for the future during the quarterly earnings call. ''  
Head Entity: Maria Gonzalez  
Tail Entity: chief executive officer  

Relation: person title  
Context: `` The community celebrated the appointment of Sarah Johnson as the new principal of the local high school, recognizing her commitment to education. ''  
Head Entity: Sarah Johnson  
Tail Entity: principal  
#### organization country of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization country of headquarters" means an organization is located in a country.
Here is an example:
Relation: organization country of headquarters
Context: chunghwa telecom co , taiwan 's leading telecom operator , said friday its 2007 net profit rose some eight percent from a year earlier , largely due to cost reductions .
Head Entity: chunghwa telecom
Tail Entity: taiwan
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization country of headquarters":
Relation: organization country of headquarters  
Context: Samsung Electronics, a global leader in technology, announced its plans to expand operations in South Korea, aiming to enhance its production capabilities.  
Head Entity: Samsung Electronics  
Tail Entity: South Korea  

Relation: organization country of headquarters  
Context: Nestlé, the world's largest food and beverage company, has its headquarters situated in Switzerland, where it was founded over 150 years ago.  
Head Entity: Nestlé  
Tail Entity: Switzerland  

Relation: organization country of headquarters  
Context: Toyota Motor Corporation, known for its innovative automotive solutions, is headquartered in Japan, contributing significantly to the country's economy.  
Head Entity: Toyota Motor Corporation  
Tail Entity: Japan  

Relation: organization country of headquarters  
Context: Unilever, a multinational consumer goods company, operates its main office in the United Kingdom, where it was established in the late 19th century.  
Head Entity: Unilever  
Tail Entity: United Kingdom  

Relation: organization country of headquarters  
Context: Siemens AG, a global powerhouse in electronics and electrical engineering, has its headquarters located in Germany, playing a crucial role in the European market.  
Head Entity: Siemens AG  
Tail Entity: Germany  
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    1 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    2 | acc: 87.50%,  total acc: 83.33%   
[EVAL] batch:    3 | acc: 62.50%,  total acc: 78.12%   
[EVAL] batch:    4 | acc: 93.75%,  total acc: 81.25%   
[EVAL] batch:    5 | acc: 75.00%,  total acc: 80.21%   
[EVAL] batch:    6 | acc: 93.75%,  total acc: 82.14%   
[EVAL] batch:    7 | acc: 100.00%,  total acc: 84.38%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 86.11%   
[EVAL] batch:    9 | acc: 93.75%,  total acc: 86.88%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 88.07%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 88.54%   
[EVAL] batch:   12 | acc: 93.75%,  total acc: 88.94%   
[EVAL] batch:   13 | acc: 68.75%,  total acc: 87.50%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 86.67%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 84.77%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 84.19%   
[EVAL] batch:   17 | acc: 68.75%,  total acc: 83.33%   
[EVAL] batch:   18 | acc: 87.50%,  total acc: 83.55%   
[EVAL] batch:   19 | acc: 87.50%,  total acc: 83.75%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 84.52%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 85.23%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 85.87%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 86.46%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 87.00%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 87.50%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 87.73%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 88.17%   
[EVAL] batch:   28 | acc: 100.00%,  total acc: 88.58%   
[EVAL] batch:   29 | acc: 87.50%,  total acc: 88.54%   
[EVAL] batch:   30 | acc: 87.50%,  total acc: 88.51%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 88.67%   
[EVAL] batch:   32 | acc: 37.50%,  total acc: 87.12%   
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    1 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    2 | acc: 87.50%,  total acc: 83.33%   
[EVAL] batch:    3 | acc: 62.50%,  total acc: 78.12%   
[EVAL] batch:    4 | acc: 93.75%,  total acc: 81.25%   
[EVAL] batch:    5 | acc: 75.00%,  total acc: 80.21%   
[EVAL] batch:    6 | acc: 93.75%,  total acc: 82.14%   
[EVAL] batch:    7 | acc: 100.00%,  total acc: 84.38%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 86.11%   
[EVAL] batch:    9 | acc: 93.75%,  total acc: 86.88%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 88.07%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 88.54%   
[EVAL] batch:   12 | acc: 93.75%,  total acc: 88.94%   
[EVAL] batch:   13 | acc: 68.75%,  total acc: 87.50%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 86.67%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 84.77%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 84.19%   
[EVAL] batch:   17 | acc: 68.75%,  total acc: 83.33%   
[EVAL] batch:   18 | acc: 87.50%,  total acc: 83.55%   
[EVAL] batch:   19 | acc: 87.50%,  total acc: 83.75%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 84.52%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 85.23%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 85.87%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 86.46%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 87.00%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 87.50%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 87.73%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 88.17%   
[EVAL] batch:   28 | acc: 100.00%,  total acc: 88.58%   
[EVAL] batch:   29 | acc: 87.50%,  total acc: 88.54%   
[EVAL] batch:   30 | acc: 87.50%,  total acc: 88.51%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 88.67%   
[EVAL] batch:   32 | acc: 37.50%,  total acc: 87.12%   
cur_acc:  ['0.8712']
his_acc:  ['0.8712']
CurrentTrain: epoch  0, batch     0 | loss: 6.3973942
CurrentTrain: epoch  0, batch     1 | loss: 7.3796716
CurrentTrain: epoch  1, batch     0 | loss: 6.4657888
CurrentTrain: epoch  1, batch     1 | loss: 5.3782830
CurrentTrain: epoch  2, batch     0 | loss: 6.1777396
CurrentTrain: epoch  2, batch     1 | loss: 5.3747253
CurrentTrain: epoch  3, batch     0 | loss: 5.5423403
CurrentTrain: epoch  3, batch     1 | loss: 5.1534314
CurrentTrain: epoch  4, batch     0 | loss: 5.3756881
CurrentTrain: epoch  4, batch     1 | loss: 5.0625086
CurrentTrain: epoch  5, batch     0 | loss: 5.0119185
CurrentTrain: epoch  5, batch     1 | loss: 3.9117169
CurrentTrain: epoch  6, batch     0 | loss: 4.4607000
CurrentTrain: epoch  6, batch     1 | loss: 3.8968837
CurrentTrain: epoch  7, batch     0 | loss: 4.1129036
CurrentTrain: epoch  7, batch     1 | loss: 4.0668969
CurrentTrain: epoch  8, batch     0 | loss: 3.4643028
CurrentTrain: epoch  8, batch     1 | loss: 4.1775894
CurrentTrain: epoch  9, batch     0 | loss: 3.3281112
CurrentTrain: epoch  9, batch     1 | loss: 3.7418110
#### person date of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person date of birth" means a person was born in a date.
Here is an example:
Relation: person date of birth
Context: born in 1950 in the northeastern city of basel , ospel left school at 15 to take an apprenticeship at the transvalor brokerage house before joining swiss banking corporation -lrb- sbs -rrb- , which merged with union bank of switzerland to form ubs in 1998 .
Head Entity: ospel
Tail Entity: 1950
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person date of birth":
Relation: person date of birth  
Context: she was born on July 4, 1985, in a small town in California, where she spent her childhood before moving to New York for her career.  
Head Entity: she  
Tail Entity: July 4, 1985  

Relation: person date of birth  
Context: the famous physicist was born in 1879 in Ulm, a city in the Kingdom of Württemberg in the German Empire, and later moved to Munich.  
Head Entity: the famous physicist  
Tail Entity: 1879  

Relation: person date of birth  
Context: born in 1992 in a bustling city, he quickly became known for his contributions to technology and innovation.  
Head Entity: he  
Tail Entity: 1992  

Relation: person date of birth  
Context: the author was born in 1965 in a small village, where she developed her love for storytelling from an early age.  
Head Entity: the author  
Tail Entity: 1965  

Relation: person date of birth  
Context: born in 1978 in the heart of London, she grew up surrounded by art and culture, which influenced her career as a painter.  
Head Entity: she  
Tail Entity: 1978  
#### person stateorprovince of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of birth" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of birth
Context: jane matilda bolin was born on april 11 , 1908 , in poughkeepsie , ny .
Head Entity: jane matilda bolin
Tail Entity: ny
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of birth":
Relation: person stateorprovince of birth  
Context: albert einstein was born on march 14, 1879, in ulm, württemberg, germany.  
Head Entity: albert einstein  
Tail Entity: württemberg  

Relation: person stateorprovince of birth  
Context: marilyn monroe was born on june 1, 1926, in los angeles, california.  
Head Entity: marilyn monroe  
Tail Entity: california  

Relation: person stateorprovince of birth  
Context: barack obama was born on august 4, 1961, in honolulu, hawaii.  
Head Entity: barack obama  
Tail Entity: hawaii  

Relation: person stateorprovince of birth  
Context: agatha christie was born on september 15, 1890, in torquay, devon.  
Head Entity: agatha christie  
Tail Entity: devon  

Relation: person stateorprovince of birth  
Context: nelson mandela was born on july 18, 1918, in mvezo, eastern cape.  
Head Entity: nelson mandela  
Tail Entity: eastern cape  
#### person parents ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person parents" means a person 's parent is a person.
Here is an example:
Relation: person parents
Context: lynne spears told the court that lutfi had treated her daughter like a hostage in her own home , drugged her and took over her finances .
Head Entity: her
Tail Entity: lynne spears
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person parents":
1. Relation: person parents  
   Context: After years of hard work, Sarah finally made her parents proud by graduating at the top of her class.  
   Head Entity: her  
   Tail Entity: parents  

2. Relation: person parents  
   Context: During the family reunion, John shared stories about how his father taught him valuable life lessons.  
   Head Entity: his  
   Tail Entity: father  

3. Relation: person parents  
   Context: Emily often reminisces about the summer vacations she spent with her mother at the beach.  
   Head Entity: her  
   Tail Entity: mother  

4. Relation: person parents  
   Context: The documentary highlighted how the struggles of his parents shaped his career as an artist.  
   Head Entity: his  
   Tail Entity: parents  

5. Relation: person parents  
   Context: When asked about her inspiration, Lisa mentioned that her father was her biggest role model growing up.  
   Head Entity: her  
   Tail Entity: father  
#### person employee of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person employee of" means a person is an employee of an organization.
Here is an example:
Relation: person employee of
Context: seeking revenge , axel reunites with old pal sgt. billy rosewood -lrb- judge reinhold -rrb- and jon flint -lrb- hector elizondo -rrb- of the beverly hills police department .
Head Entity: hector elizondo
Tail Entity: beverly hills police department
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person employee of":
Relation: person employee of  
Context: After years of hard work, Maria finally secured a position at the prestigious tech firm, where she collaborates with talented engineers and designers.  
Head Entity: Maria  
Tail Entity: prestigious tech firm  

Relation: person employee of  
Context: John has been with the company for over a decade, contributing to various projects and earning several promotions along the way.  
Head Entity: John  
Tail Entity: the company  

Relation: person employee of  
Context: As a renowned chef, Marco has worked in several high-end restaurants, but his current role at the gourmet bistro has been his most fulfilling yet.  
Head Entity: Marco  
Tail Entity: gourmet bistro  

Relation: person employee of  
Context: After graduating from university, Sarah landed a job at a leading marketing agency, where she quickly made a name for herself.  
Head Entity: Sarah  
Tail Entity: leading marketing agency  

Relation: person employee of  
Context: David's expertise in finance led him to a senior analyst position at a major investment bank, where he advises clients on their portfolios.  
Head Entity: David  
Tail Entity: major investment bank  
#### person stateorprovince of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of death" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of death
Context: irene morgan kirkaldy , whose defiance of bus segregation laws more than a decade before rosa parks ' landmark case helped lay the foundation for later civil rights victories , died friday at her home in hayes , va. .
Head Entity: irene morgan kirkaldy
Tail Entity: va.
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of death":
Relation: person stateorprovince of death  
Context: john doe, a renowned author known for his thrilling novels, passed away unexpectedly in his home in los angeles, ca.  
Head Entity: john doe  
Tail Entity: ca.  

Relation: person stateorprovince of death  
Context: after a long battle with illness, mary jane, a beloved community leader, died peacefully in her hometown of springfield, il.  
Head Entity: mary jane  
Tail Entity: il.  

Relation: person stateorprovince of death  
Context: the famous musician, alex smith, tragically lost his life in a car accident while traveling through the scenic routes of oregon, or.  
Head Entity: alex smith  
Tail Entity: or.  

Relation: person stateorprovince of death  
Context: in a heartbreaking announcement, the family of elizabeth taylor revealed that she passed away in her luxurious estate located in las vegas, nv.  
Head Entity: elizabeth taylor  
Tail Entity: nv.  

Relation: person stateorprovince of death  
Context: the world mourned the loss of legendary scientist, dr. emma wilson, who died at the age of 92 in her residence in boston, ma.  
Head Entity: dr. emma wilson  
Tail Entity: ma.  
Mixup data size:  3730
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2197, 2005, 2023, 1010, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 4]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 5]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 3]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 5]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 3]}
{'ids': [101, 2342, 5678, 1234, 4321, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [5, 3]}
#############params############
cuda:0
Task=Tacred, 5-shot
Encoding model: bert
pattern=hardprompt
mem=1, margin=0.3, gen=1, gen_num=5
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
CurrentTrain: epoch  0, batch     0 | loss: 12.2377892
CurrentTrain: epoch  0, batch     1 | loss: 11.8358202
CurrentTrain: epoch  0, batch     2 | loss: 11.5842304
CurrentTrain: epoch  0, batch     3 | loss: 11.7963333
CurrentTrain: epoch  0, batch     4 | loss: 11.3291626
CurrentTrain: epoch  0, batch     5 | loss: 11.3988247
CurrentTrain: epoch  0, batch     6 | loss: 11.4306774
CurrentTrain: epoch  0, batch     7 | loss: 11.4957294
CurrentTrain: epoch  0, batch     8 | loss: 10.9524660
CurrentTrain: epoch  0, batch     9 | loss: 11.0981150
CurrentTrain: epoch  0, batch    10 | loss: 11.0817156
CurrentTrain: epoch  0, batch    11 | loss: 11.0157957
CurrentTrain: epoch  0, batch    12 | loss: 10.9861202
CurrentTrain: epoch  0, batch    13 | loss: 10.7110462
CurrentTrain: epoch  0, batch    14 | loss: 10.5633354
CurrentTrain: epoch  0, batch    15 | loss: 10.2521629
CurrentTrain: epoch  0, batch    16 | loss: 9.5208607
CurrentTrain: epoch  0, batch    17 | loss: 10.0118418
CurrentTrain: epoch  0, batch    18 | loss: 9.9925213
CurrentTrain: epoch  0, batch    19 | loss: 10.5049925
CurrentTrain: epoch  0, batch    20 | loss: 9.9245691
CurrentTrain: epoch  0, batch    21 | loss: 10.7969608
CurrentTrain: epoch  0, batch    22 | loss: 10.3663940
CurrentTrain: epoch  0, batch    23 | loss: 9.9787502
CurrentTrain: epoch  0, batch    24 | loss: 10.1565428
CurrentTrain: epoch  0, batch    25 | loss: 9.8991623
CurrentTrain: epoch  0, batch    26 | loss: 10.0962982
CurrentTrain: epoch  0, batch    27 | loss: 9.3844519
CurrentTrain: epoch  0, batch    28 | loss: 9.7764397
CurrentTrain: epoch  0, batch    29 | loss: 9.7736034
CurrentTrain: epoch  0, batch    30 | loss: 9.4480782
CurrentTrain: epoch  0, batch    31 | loss: 9.9147511
CurrentTrain: epoch  0, batch    32 | loss: 9.6330633
CurrentTrain: epoch  0, batch    33 | loss: 9.6556149
CurrentTrain: epoch  0, batch    34 | loss: 8.9573956
CurrentTrain: epoch  0, batch    35 | loss: 9.5650816
CurrentTrain: epoch  0, batch    36 | loss: 9.7023954
CurrentTrain: epoch  0, batch    37 | loss: 9.6724091
CurrentTrain: epoch  1, batch     0 | loss: 9.4604149
CurrentTrain: epoch  1, batch     1 | loss: 10.1246471
CurrentTrain: epoch  1, batch     2 | loss: 8.5899754
CurrentTrain: epoch  1, batch     3 | loss: 9.2962093
CurrentTrain: epoch  1, batch     4 | loss: 8.6637697
CurrentTrain: epoch  1, batch     5 | loss: 9.6263733
CurrentTrain: epoch  1, batch     6 | loss: 8.9486284
CurrentTrain: epoch  1, batch     7 | loss: 9.0029678
CurrentTrain: epoch  1, batch     8 | loss: 8.8491497
CurrentTrain: epoch  1, batch     9 | loss: 8.9430141
CurrentTrain: epoch  1, batch    10 | loss: 9.5420208
CurrentTrain: epoch  1, batch    11 | loss: 9.6031132
CurrentTrain: epoch  1, batch    12 | loss: 9.1848850
CurrentTrain: epoch  1, batch    13 | loss: 8.3578682
CurrentTrain: epoch  1, batch    14 | loss: 8.9222250
CurrentTrain: epoch  1, batch    15 | loss: 8.7862034
CurrentTrain: epoch  1, batch    16 | loss: 8.7784939
CurrentTrain: epoch  1, batch    17 | loss: 9.0060778
CurrentTrain: epoch  1, batch    18 | loss: 8.9019585
CurrentTrain: epoch  1, batch    19 | loss: 9.1300135
CurrentTrain: epoch  1, batch    20 | loss: 9.2238483
CurrentTrain: epoch  1, batch    21 | loss: 8.7556190
CurrentTrain: epoch  1, batch    22 | loss: 8.7446423
CurrentTrain: epoch  1, batch    23 | loss: 8.4535732
CurrentTrain: epoch  1, batch    24 | loss: 8.9085588
CurrentTrain: epoch  1, batch    25 | loss: 7.8729029
CurrentTrain: epoch  1, batch    26 | loss: 8.9874878
CurrentTrain: epoch  1, batch    27 | loss: 8.0600681
CurrentTrain: epoch  1, batch    28 | loss: 8.3288574
CurrentTrain: epoch  1, batch    29 | loss: 7.3486710
CurrentTrain: epoch  1, batch    30 | loss: 8.0324583
CurrentTrain: epoch  1, batch    31 | loss: 9.0403643
CurrentTrain: epoch  1, batch    32 | loss: 8.3986797
CurrentTrain: epoch  1, batch    33 | loss: 8.3034315
CurrentTrain: epoch  1, batch    34 | loss: 8.3720951
CurrentTrain: epoch  1, batch    35 | loss: 7.7797775
CurrentTrain: epoch  1, batch    36 | loss: 8.1887569
CurrentTrain: epoch  1, batch    37 | loss: 9.3430576
CurrentTrain: epoch  2, batch     0 | loss: 7.3662424
CurrentTrain: epoch  2, batch     1 | loss: 8.3544626
CurrentTrain: epoch  2, batch     2 | loss: 8.4783211
CurrentTrain: epoch  2, batch     3 | loss: 7.9830246
CurrentTrain: epoch  2, batch     4 | loss: 8.9861774
CurrentTrain: epoch  2, batch     5 | loss: 9.1120319
CurrentTrain: epoch  2, batch     6 | loss: 8.2785549
CurrentTrain: epoch  2, batch     7 | loss: 7.8161860
CurrentTrain: epoch  2, batch     8 | loss: 7.7946243
CurrentTrain: epoch  2, batch     9 | loss: 8.1371365
CurrentTrain: epoch  2, batch    10 | loss: 8.1274719
CurrentTrain: epoch  2, batch    11 | loss: 8.1458416
CurrentTrain: epoch  2, batch    12 | loss: 7.7329111
CurrentTrain: epoch  2, batch    13 | loss: 7.4998751
CurrentTrain: epoch  2, batch    14 | loss: 6.7733631
CurrentTrain: epoch  2, batch    15 | loss: 7.4271975
CurrentTrain: epoch  2, batch    16 | loss: 7.8946323
CurrentTrain: epoch  2, batch    17 | loss: 8.1287365
CurrentTrain: epoch  2, batch    18 | loss: 7.7022080
CurrentTrain: epoch  2, batch    19 | loss: 7.6633844
CurrentTrain: epoch  2, batch    20 | loss: 7.5645056
CurrentTrain: epoch  2, batch    21 | loss: 7.2468576
CurrentTrain: epoch  2, batch    22 | loss: 6.6268282
CurrentTrain: epoch  2, batch    23 | loss: 7.0505657
CurrentTrain: epoch  2, batch    24 | loss: 7.3652039
CurrentTrain: epoch  2, batch    25 | loss: 7.9841595
CurrentTrain: epoch  2, batch    26 | loss: 6.9228649
CurrentTrain: epoch  2, batch    27 | loss: 8.3433628
CurrentTrain: epoch  2, batch    28 | loss: 6.2205820
CurrentTrain: epoch  2, batch    29 | loss: 7.9827604
CurrentTrain: epoch  2, batch    30 | loss: 7.5686135
CurrentTrain: epoch  2, batch    31 | loss: 6.7521391
CurrentTrain: epoch  2, batch    32 | loss: 7.1855884
CurrentTrain: epoch  2, batch    33 | loss: 7.1788774
CurrentTrain: epoch  2, batch    34 | loss: 8.3621635
CurrentTrain: epoch  2, batch    35 | loss: 6.9254699
CurrentTrain: epoch  2, batch    36 | loss: 7.5592299
CurrentTrain: epoch  2, batch    37 | loss: 6.8255949
CurrentTrain: epoch  3, batch     0 | loss: 7.7647505
CurrentTrain: epoch  3, batch     1 | loss: 7.5025458
CurrentTrain: epoch  3, batch     2 | loss: 7.7400827
CurrentTrain: epoch  3, batch     3 | loss: 8.1283417
CurrentTrain: epoch  3, batch     4 | loss: 7.6592603
CurrentTrain: epoch  3, batch     5 | loss: 7.6934776
CurrentTrain: epoch  3, batch     6 | loss: 8.0932388
CurrentTrain: epoch  3, batch     7 | loss: 6.8233399
CurrentTrain: epoch  3, batch     8 | loss: 7.4070482
CurrentTrain: epoch  3, batch     9 | loss: 7.3779402
CurrentTrain: epoch  3, batch    10 | loss: 6.8089685
CurrentTrain: epoch  3, batch    11 | loss: 6.3608518
CurrentTrain: epoch  3, batch    12 | loss: 7.6196122
CurrentTrain: epoch  3, batch    13 | loss: 8.0267200
CurrentTrain: epoch  3, batch    14 | loss: 7.0713158
CurrentTrain: epoch  3, batch    15 | loss: 7.1864080
CurrentTrain: epoch  3, batch    16 | loss: 7.9409227
CurrentTrain: epoch  3, batch    17 | loss: 7.0805454
CurrentTrain: epoch  3, batch    18 | loss: 7.2674842
CurrentTrain: epoch  3, batch    19 | loss: 7.0971551
CurrentTrain: epoch  3, batch    20 | loss: 7.1673136
CurrentTrain: epoch  3, batch    21 | loss: 7.2108817
CurrentTrain: epoch  3, batch    22 | loss: 8.0766506
CurrentTrain: epoch  3, batch    23 | loss: 7.5205364
CurrentTrain: epoch  3, batch    24 | loss: 6.2361536
CurrentTrain: epoch  3, batch    25 | loss: 6.7487731
CurrentTrain: epoch  3, batch    26 | loss: 6.3052359
CurrentTrain: epoch  3, batch    27 | loss: 7.1938982
CurrentTrain: epoch  3, batch    28 | loss: 7.2758160
CurrentTrain: epoch  3, batch    29 | loss: 5.9751406
CurrentTrain: epoch  3, batch    30 | loss: 7.0339866
CurrentTrain: epoch  3, batch    31 | loss: 7.0741363
CurrentTrain: epoch  3, batch    32 | loss: 6.2167683
CurrentTrain: epoch  3, batch    33 | loss: 5.7902369
CurrentTrain: epoch  3, batch    34 | loss: 6.7244143
CurrentTrain: epoch  3, batch    35 | loss: 6.2465477
CurrentTrain: epoch  3, batch    36 | loss: 6.7644510
CurrentTrain: epoch  3, batch    37 | loss: 6.6600256
CurrentTrain: epoch  4, batch     0 | loss: 6.9214773
CurrentTrain: epoch  4, batch     1 | loss: 6.3543296
CurrentTrain: epoch  4, batch     2 | loss: 5.6729169
CurrentTrain: epoch  4, batch     3 | loss: 6.7485514
CurrentTrain: epoch  4, batch     4 | loss: 7.2618380
CurrentTrain: epoch  4, batch     5 | loss: 6.6126189
CurrentTrain: epoch  4, batch     6 | loss: 6.2170911
CurrentTrain: epoch  4, batch     7 | loss: 6.6977735
CurrentTrain: epoch  4, batch     8 | loss: 7.4788270
CurrentTrain: epoch  4, batch     9 | loss: 6.5936441
CurrentTrain: epoch  4, batch    10 | loss: 6.9046702
CurrentTrain: epoch  4, batch    11 | loss: 6.0163383
CurrentTrain: epoch  4, batch    12 | loss: 6.5755177
CurrentTrain: epoch  4, batch    13 | loss: 6.2283492
CurrentTrain: epoch  4, batch    14 | loss: 7.0001431
CurrentTrain: epoch  4, batch    15 | loss: 6.6601152
CurrentTrain: epoch  4, batch    16 | loss: 6.3596520
CurrentTrain: epoch  4, batch    17 | loss: 6.3576050
CurrentTrain: epoch  4, batch    18 | loss: 5.9598074
CurrentTrain: epoch  4, batch    19 | loss: 6.0913982
CurrentTrain: epoch  4, batch    20 | loss: 6.2184505
CurrentTrain: epoch  4, batch    21 | loss: 6.5159440
CurrentTrain: epoch  4, batch    22 | loss: 6.6188974
CurrentTrain: epoch  4, batch    23 | loss: 5.9724197
CurrentTrain: epoch  4, batch    24 | loss: 6.6317444
CurrentTrain: epoch  4, batch    25 | loss: 6.5978203
CurrentTrain: epoch  4, batch    26 | loss: 6.0009141
CurrentTrain: epoch  4, batch    27 | loss: 7.6149282
CurrentTrain: epoch  4, batch    28 | loss: 5.8510528
CurrentTrain: epoch  4, batch    29 | loss: 6.1155725
CurrentTrain: epoch  4, batch    30 | loss: 5.9866090
CurrentTrain: epoch  4, batch    31 | loss: 6.0753689
CurrentTrain: epoch  4, batch    32 | loss: 6.2112637
CurrentTrain: epoch  4, batch    33 | loss: 5.6074681
CurrentTrain: epoch  4, batch    34 | loss: 6.8721824
CurrentTrain: epoch  4, batch    35 | loss: 6.1603594
CurrentTrain: epoch  4, batch    36 | loss: 5.9010696
CurrentTrain: epoch  4, batch    37 | loss: 6.5777607
CurrentTrain: epoch  5, batch     0 | loss: 5.6601758
CurrentTrain: epoch  5, batch     1 | loss: 6.0248494
CurrentTrain: epoch  5, batch     2 | loss: 6.2602463
CurrentTrain: epoch  5, batch     3 | loss: 6.3877387
CurrentTrain: epoch  5, batch     4 | loss: 5.9552431
CurrentTrain: epoch  5, batch     5 | loss: 5.9370213
CurrentTrain: epoch  5, batch     6 | loss: 6.2484322
CurrentTrain: epoch  5, batch     7 | loss: 6.5060091
CurrentTrain: epoch  5, batch     8 | loss: 6.5059867
CurrentTrain: epoch  5, batch     9 | loss: 5.7736840
CurrentTrain: epoch  5, batch    10 | loss: 5.7672777
CurrentTrain: epoch  5, batch    11 | loss: 6.0279074
CurrentTrain: epoch  5, batch    12 | loss: 5.7482686
CurrentTrain: epoch  5, batch    13 | loss: 5.9997821
CurrentTrain: epoch  5, batch    14 | loss: 6.2035551
CurrentTrain: epoch  5, batch    15 | loss: 6.5068035
CurrentTrain: epoch  5, batch    16 | loss: 5.3515067
CurrentTrain: epoch  5, batch    17 | loss: 5.5702515
CurrentTrain: epoch  5, batch    18 | loss: 6.6157694
CurrentTrain: epoch  5, batch    19 | loss: 7.0879307
CurrentTrain: epoch  5, batch    20 | loss: 5.5562043
CurrentTrain: epoch  5, batch    21 | loss: 5.8516216
CurrentTrain: epoch  5, batch    22 | loss: 5.6183128
CurrentTrain: epoch  5, batch    23 | loss: 6.0548382
CurrentTrain: epoch  5, batch    24 | loss: 6.8281794
CurrentTrain: epoch  5, batch    25 | loss: 5.7778754
CurrentTrain: epoch  5, batch    26 | loss: 5.8007574
CurrentTrain: epoch  5, batch    27 | loss: 5.6567163
CurrentTrain: epoch  5, batch    28 | loss: 6.8478708
CurrentTrain: epoch  5, batch    29 | loss: 6.6075182
CurrentTrain: epoch  5, batch    30 | loss: 5.7610102
CurrentTrain: epoch  5, batch    31 | loss: 5.8279133
CurrentTrain: epoch  5, batch    32 | loss: 5.3630514
CurrentTrain: epoch  5, batch    33 | loss: 5.9219146
CurrentTrain: epoch  5, batch    34 | loss: 5.7536297
CurrentTrain: epoch  5, batch    35 | loss: 5.9297442
CurrentTrain: epoch  5, batch    36 | loss: 6.1582942
CurrentTrain: epoch  5, batch    37 | loss: 5.3770695
CurrentTrain: epoch  6, batch     0 | loss: 5.3385010
CurrentTrain: epoch  6, batch     1 | loss: 5.7504702
CurrentTrain: epoch  6, batch     2 | loss: 6.0827885
CurrentTrain: epoch  6, batch     3 | loss: 6.0616360
CurrentTrain: epoch  6, batch     4 | loss: 5.5673351
CurrentTrain: epoch  6, batch     5 | loss: 5.4255438
CurrentTrain: epoch  6, batch     6 | loss: 5.8536959
CurrentTrain: epoch  6, batch     7 | loss: 5.7188549
CurrentTrain: epoch  6, batch     8 | loss: 5.2314873
CurrentTrain: epoch  6, batch     9 | loss: 5.6400099
CurrentTrain: epoch  6, batch    10 | loss: 5.3543816
CurrentTrain: epoch  6, batch    11 | loss: 5.3050299
CurrentTrain: epoch  6, batch    12 | loss: 5.7439237
CurrentTrain: epoch  6, batch    13 | loss: 5.4360719
CurrentTrain: epoch  6, batch    14 | loss: 5.3918200
CurrentTrain: epoch  6, batch    15 | loss: 5.1954913
CurrentTrain: epoch  6, batch    16 | loss: 5.9823422
CurrentTrain: epoch  6, batch    17 | loss: 5.4264145
CurrentTrain: epoch  6, batch    18 | loss: 5.6327276
CurrentTrain: epoch  6, batch    19 | loss: 5.9033957
CurrentTrain: epoch  6, batch    20 | loss: 6.1786757
CurrentTrain: epoch  6, batch    21 | loss: 6.3660412
CurrentTrain: epoch  6, batch    22 | loss: 6.0595322
CurrentTrain: epoch  6, batch    23 | loss: 5.5738835
CurrentTrain: epoch  6, batch    24 | loss: 5.1174212
CurrentTrain: epoch  6, batch    25 | loss: 5.9595833
CurrentTrain: epoch  6, batch    26 | loss: 6.1485519
CurrentTrain: epoch  6, batch    27 | loss: 5.7259197
CurrentTrain: epoch  6, batch    28 | loss: 5.8726430
CurrentTrain: epoch  6, batch    29 | loss: 5.5694523
CurrentTrain: epoch  6, batch    30 | loss: 6.0045009
CurrentTrain: epoch  6, batch    31 | loss: 5.6451173
CurrentTrain: epoch  6, batch    32 | loss: 5.2247005
CurrentTrain: epoch  6, batch    33 | loss: 6.1387463
CurrentTrain: epoch  6, batch    34 | loss: 5.2706861
CurrentTrain: epoch  6, batch    35 | loss: 5.5575624
CurrentTrain: epoch  6, batch    36 | loss: 5.3598919
CurrentTrain: epoch  6, batch    37 | loss: 5.5043011
CurrentTrain: epoch  7, batch     0 | loss: 5.8221326
CurrentTrain: epoch  7, batch     1 | loss: 5.2134027
CurrentTrain: epoch  7, batch     2 | loss: 5.3066864
CurrentTrain: epoch  7, batch     3 | loss: 5.0514336
CurrentTrain: epoch  7, batch     4 | loss: 5.5705714
CurrentTrain: epoch  7, batch     5 | loss: 5.2637019
CurrentTrain: epoch  7, batch     6 | loss: 5.3848391
CurrentTrain: epoch  7, batch     7 | loss: 5.0422788
CurrentTrain: epoch  7, batch     8 | loss: 5.4018226
CurrentTrain: epoch  7, batch     9 | loss: 5.1225381
CurrentTrain: epoch  7, batch    10 | loss: 5.3415217
CurrentTrain: epoch  7, batch    11 | loss: 5.3493118
CurrentTrain: epoch  7, batch    12 | loss: 5.3571339
CurrentTrain: epoch  7, batch    13 | loss: 5.5703020
CurrentTrain: epoch  7, batch    14 | loss: 5.9958162
CurrentTrain: epoch  7, batch    15 | loss: 5.4087534
CurrentTrain: epoch  7, batch    16 | loss: 5.5808349
CurrentTrain: epoch  7, batch    17 | loss: 5.3512669
CurrentTrain: epoch  7, batch    18 | loss: 4.9717011
CurrentTrain: epoch  7, batch    19 | loss: 5.1010613
CurrentTrain: epoch  7, batch    20 | loss: 5.5419488
CurrentTrain: epoch  7, batch    21 | loss: 5.0689411
CurrentTrain: epoch  7, batch    22 | loss: 6.1445966
CurrentTrain: epoch  7, batch    23 | loss: 5.4027791
CurrentTrain: epoch  7, batch    24 | loss: 5.8069553
CurrentTrain: epoch  7, batch    25 | loss: 5.1294775
CurrentTrain: epoch  7, batch    26 | loss: 5.2494717
CurrentTrain: epoch  7, batch    27 | loss: 5.3885818
CurrentTrain: epoch  7, batch    28 | loss: 5.1891451
CurrentTrain: epoch  7, batch    29 | loss: 5.2763824
CurrentTrain: epoch  7, batch    30 | loss: 5.2565598
CurrentTrain: epoch  7, batch    31 | loss: 5.2446299
CurrentTrain: epoch  7, batch    32 | loss: 5.1272998
CurrentTrain: epoch  7, batch    33 | loss: 5.2244992
CurrentTrain: epoch  7, batch    34 | loss: 5.0223141
CurrentTrain: epoch  7, batch    35 | loss: 5.1779542
CurrentTrain: epoch  7, batch    36 | loss: 5.1301193
CurrentTrain: epoch  7, batch    37 | loss: 4.8143196
CurrentTrain: epoch  8, batch     0 | loss: 5.1579475
CurrentTrain: epoch  8, batch     1 | loss: 5.1543798
CurrentTrain: epoch  8, batch     2 | loss: 4.8897972
CurrentTrain: epoch  8, batch     3 | loss: 5.0410523
CurrentTrain: epoch  8, batch     4 | loss: 5.2717929
CurrentTrain: epoch  8, batch     5 | loss: 4.9771128
CurrentTrain: epoch  8, batch     6 | loss: 5.0834179
CurrentTrain: epoch  8, batch     7 | loss: 5.0067358
CurrentTrain: epoch  8, batch     8 | loss: 5.0641761
CurrentTrain: epoch  8, batch     9 | loss: 5.0935326
CurrentTrain: epoch  8, batch    10 | loss: 5.2907119
CurrentTrain: epoch  8, batch    11 | loss: 4.9250479
CurrentTrain: epoch  8, batch    12 | loss: 5.0914650
CurrentTrain: epoch  8, batch    13 | loss: 4.9756813
CurrentTrain: epoch  8, batch    14 | loss: 5.2059898
CurrentTrain: epoch  8, batch    15 | loss: 5.2468882
CurrentTrain: epoch  8, batch    16 | loss: 4.9808016
CurrentTrain: epoch  8, batch    17 | loss: 4.8144884
CurrentTrain: epoch  8, batch    18 | loss: 5.2888255
CurrentTrain: epoch  8, batch    19 | loss: 4.9981937
CurrentTrain: epoch  8, batch    20 | loss: 5.1061277
CurrentTrain: epoch  8, batch    21 | loss: 5.0941725
CurrentTrain: epoch  8, batch    22 | loss: 5.3479795
CurrentTrain: epoch  8, batch    23 | loss: 5.2284288
CurrentTrain: epoch  8, batch    24 | loss: 4.9951601
CurrentTrain: epoch  8, batch    25 | loss: 5.0256500
CurrentTrain: epoch  8, batch    26 | loss: 5.3343859
CurrentTrain: epoch  8, batch    27 | loss: 4.9719343
CurrentTrain: epoch  8, batch    28 | loss: 5.2509747
CurrentTrain: epoch  8, batch    29 | loss: 5.0940399
CurrentTrain: epoch  8, batch    30 | loss: 4.9406633
CurrentTrain: epoch  8, batch    31 | loss: 5.1270304
CurrentTrain: epoch  8, batch    32 | loss: 4.7761073
CurrentTrain: epoch  8, batch    33 | loss: 4.9832006
CurrentTrain: epoch  8, batch    34 | loss: 4.9552345
CurrentTrain: epoch  8, batch    35 | loss: 5.4438825
CurrentTrain: epoch  8, batch    36 | loss: 4.9208779
CurrentTrain: epoch  8, batch    37 | loss: 4.9012098
CurrentTrain: epoch  9, batch     0 | loss: 5.3065910
CurrentTrain: epoch  9, batch     1 | loss: 5.1796370
CurrentTrain: epoch  9, batch     2 | loss: 5.1072073
CurrentTrain: epoch  9, batch     3 | loss: 4.9213343
CurrentTrain: epoch  9, batch     4 | loss: 4.8819547
CurrentTrain: epoch  9, batch     5 | loss: 5.1034369
CurrentTrain: epoch  9, batch     6 | loss: 5.3321552
CurrentTrain: epoch  9, batch     7 | loss: 4.9197969
CurrentTrain: epoch  9, batch     8 | loss: 4.9653072
CurrentTrain: epoch  9, batch     9 | loss: 4.8860769
CurrentTrain: epoch  9, batch    10 | loss: 5.0107727
CurrentTrain: epoch  9, batch    11 | loss: 4.8371091
CurrentTrain: epoch  9, batch    12 | loss: 4.9469938
CurrentTrain: epoch  9, batch    13 | loss: 5.0067148
CurrentTrain: epoch  9, batch    14 | loss: 4.9856386
CurrentTrain: epoch  9, batch    15 | loss: 4.8672819
CurrentTrain: epoch  9, batch    16 | loss: 4.8858490
CurrentTrain: epoch  9, batch    17 | loss: 5.0205936
CurrentTrain: epoch  9, batch    18 | loss: 5.0734935
CurrentTrain: epoch  9, batch    19 | loss: 4.8799629
CurrentTrain: epoch  9, batch    20 | loss: 4.8950119
CurrentTrain: epoch  9, batch    21 | loss: 4.7830744
CurrentTrain: epoch  9, batch    22 | loss: 4.8854637
CurrentTrain: epoch  9, batch    23 | loss: 4.9289637
CurrentTrain: epoch  9, batch    24 | loss: 4.9857821
CurrentTrain: epoch  9, batch    25 | loss: 4.7893872
CurrentTrain: epoch  9, batch    26 | loss: 5.1338005
CurrentTrain: epoch  9, batch    27 | loss: 5.0343213
CurrentTrain: epoch  9, batch    28 | loss: 4.9264212
CurrentTrain: epoch  9, batch    29 | loss: 5.0215325
CurrentTrain: epoch  9, batch    30 | loss: 4.7740507
CurrentTrain: epoch  9, batch    31 | loss: 4.8163271
CurrentTrain: epoch  9, batch    32 | loss: 4.8064499
CurrentTrain: epoch  9, batch    33 | loss: 4.7759576
CurrentTrain: epoch  9, batch    34 | loss: 4.9853191
CurrentTrain: epoch  9, batch    35 | loss: 4.7680750
CurrentTrain: epoch  9, batch    36 | loss: 4.7871542
CurrentTrain: epoch  9, batch    37 | loss: 4.9062581
#### person countries of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person countries of residence" means a person is living in a country.
Here is an example:
Relation: person countries of residence
Context: khamenei , 67 , has final say on all state matters in iran as supreme leader , a post he has held since 1989 .
Head Entity: khamenei
Tail Entity: iran
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person countries of residence":
Relation: person countries of residence  
Context: After years of living in the United States, Maria decided to return to her hometown in Spain.  
Head Entity: Maria  
Tail Entity: Spain  

Relation: person countries of residence  
Context: The famous actor, Leonardo DiCaprio, has been known to spend a significant amount of time in both the United States and Australia.  
Head Entity: Leonardo DiCaprio  
Tail Entity: Australia  

Relation: person countries of residence  
Context: Following his retirement, the former president moved to Canada to enjoy a quieter life away from politics.  
Head Entity: former president  
Tail Entity: Canada  

Relation: person countries of residence  
Context: After completing her studies in France, Sophie chose to settle down in Italy, where she found a job and made new friends.  
Head Entity: Sophie  
Tail Entity: Italy  

Relation: person countries of residence  
Context: The renowned scientist, Dr. Wang, has conducted much of his research while residing in Germany, where he has access to top laboratories.  
Head Entity: Dr. Wang  
Tail Entity: Germany  
#### organization top members employees ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization top members employees" means an organization 's employer is a person.
Here is an example:
Relation: organization top members employees
Context: `` customer relationships are the backbone of banking , and banks are constantly striving to meet customer demands , '' said peter garuccio , spokesman for the american bankers association .
Head Entity: american bankers association
Tail Entity: peter garuccio
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization top members employees":
1. Relation: organization top members employees  
   Context: "As the CEO of the tech giant, she has been instrumental in driving innovation," said a company spokesperson about Jane Doe, who leads the organization.  
   Head Entity: tech giant  
   Tail Entity: Jane Doe  

2. Relation: organization top members employees  
   Context: "The board of directors is pleased to announce the appointment of John Smith as the new CFO," stated the press release from the financial services firm.  
   Head Entity: financial services firm  
   Tail Entity: John Smith  

3. Relation: organization top members employees  
   Context: "In her role as Chief Marketing Officer, Maria Lopez has transformed the company's brand strategy," noted an industry analyst regarding the marketing agency.  
   Head Entity: marketing agency  
   Tail Entity: Maria Lopez  

4. Relation: organization top members employees  
   Context: "The university's president emphasized the importance of research in her speech," said a faculty member about Dr. Emily Johnson's leadership at the institution.  
   Head Entity: university  
   Tail Entity: Dr. Emily Johnson  

5. Relation: organization top members employees  
   Context: "The nonprofit organization has appointed a new executive director to lead its initiatives," reported a local news outlet about the recent hire of Tom Brown.  
   Head Entity: nonprofit organization  
   Tail Entity: Tom Brown  
#### organization member of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization member of" means an organization is the member of an organization.
Here is an example:
Relation: organization member of
Context: over the course of the week the european union engaged in a gentlemanly tug-of-war with the organization of the islamic conference -lrb- oic -rrb- and the african regional group - which is controlled by the oic - over a range of terms and conditions .
Head Entity: oic
Tail Entity: organization of the islamic conference
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization member of":
Relation: organization member of  
Context: The United Nations has been working closely with the World Health Organization to address global health issues and improve international cooperation.  
Head Entity: World Health Organization  
Tail Entity: United Nations  

Relation: organization member of  
Context: During the annual conference, the International Olympic Committee discussed its collaboration with various national sports organizations to promote athletic excellence.  
Head Entity: International Olympic Committee  
Tail Entity: national sports organizations  

Relation: organization member of  
Context: The North Atlantic Treaty Organization held a summit where member countries deliberated on collective defense strategies and regional security.  
Head Entity: North Atlantic Treaty Organization  
Tail Entity: member countries  

Relation: organization member of  
Context: The Global Climate Alliance is a coalition of various environmental organizations working together to combat climate change and promote sustainability.  
Head Entity: Global Climate Alliance  
Tail Entity: environmental organizations  

Relation: organization member of  
Context: The International Federation of Red Cross and Red Crescent Societies coordinated with local humanitarian groups to provide disaster relief in affected areas.  
Head Entity: International Federation of Red Cross and Red Crescent Societies  
Tail Entity: local humanitarian groups  
#### person origin ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person origin" means a person 's nationality is a country.
Here is an example:
Relation: person origin
Context: urgent chadian pm dies in paris hospital chad 's prime minister pascal yoadimnadji has died from a cerebral hemorrhage in a paris hospital , the chadian ambassador said friday .
Head Entity: pascal yoadimnadji
Tail Entity: chadian
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person origin":
Relation: person origin  
Context: the renowned scientist albert einstein was born in ulm, germany, and later became a citizen of the united states.  
Head Entity: albert einstein  
Tail Entity: german  

Relation: person origin  
Context: the famous author chimamanda ngozi adichie hails from enugu, nigeria, where she developed her passion for storytelling.  
Head Entity: chimamanda ngozi adichie  
Tail Entity: nigerian  

Relation: person origin  
Context: the legendary musician bob marley was born in nine mile, jamaica, and is celebrated worldwide for his contributions to reggae music.  
Head Entity: bob marley  
Tail Entity: jamaican  

Relation: person origin  
Context: the acclaimed filmmaker akira kurosawa was born in tokyo, japan, and is known for his influential works in cinema.  
Head Entity: akira kurosawa  
Tail Entity: japanese  

Relation: person origin  
Context: the famous physicist stephen hawking was born in oxford, england, and made groundbreaking contributions to theoretical physics.  
Head Entity: stephen hawking  
Tail Entity: british  
#### person title ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person title" means a person 's title is a title.
Here is an example:
Relation: person title
Context: `` making the amendment retroactive will ... help repair the image of the sentencing guidelines in communities of color , '' naacp chairman julian bond wrote to the commission .
Head Entity: julian bond
Tail Entity: chairman
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person title":
Relation: person title  
Context: `` After years of dedicated service, the board appointed Dr. Emily Carter as the new president of the university. ''  
Head Entity: Dr. Emily Carter  
Tail Entity: president  

Relation: person title  
Context: `` In her latest book, renowned author Sarah Johnson shares her journey as a leading voice in contemporary literature. ''  
Head Entity: Sarah Johnson  
Tail Entity: author  

Relation: person title  
Context: `` The city council elected Mark Thompson to serve as the new mayor, promising to bring positive changes to the community. ''  
Head Entity: Mark Thompson  
Tail Entity: mayor  

Relation: person title  
Context: `` During the annual conference, the committee recognized Dr. Lisa Chen for her outstanding contributions as the chief scientist in the field of renewable energy. ''  
Head Entity: Dr. Lisa Chen  
Tail Entity: chief scientist  

Relation: person title  
Context: `` Following a successful campaign, Jessica Lee was celebrated as the youngest senator in the state’s history. ''  
Head Entity: Jessica Lee  
Tail Entity: senator  
#### organization country of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization country of headquarters" means an organization is located in a country.
Here is an example:
Relation: organization country of headquarters
Context: chunghwa telecom co , taiwan 's leading telecom operator , said friday its 2007 net profit rose some eight percent from a year earlier , largely due to cost reductions .
Head Entity: chunghwa telecom
Tail Entity: taiwan
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization country of headquarters":
Relation: organization country of headquarters  
Context: Samsung Electronics, a global leader in technology, announced its plans to expand operations in South Korea, aiming to enhance its production capabilities.  
Head Entity: Samsung Electronics  
Tail Entity: South Korea  

Relation: organization country of headquarters  
Context: Nestlé, the world's largest food and beverage company, has its headquarters situated in Switzerland, where it was founded over 150 years ago.  
Head Entity: Nestlé  
Tail Entity: Switzerland  

Relation: organization country of headquarters  
Context: Toyota Motor Corporation, known for its innovative automotive solutions, is headquartered in Japan, contributing significantly to the country's economy.  
Head Entity: Toyota Motor Corporation  
Tail Entity: Japan  

Relation: organization country of headquarters  
Context: Unilever, a multinational consumer goods company, operates its main offices from the United Kingdom, where it was established in the late 19th century.  
Head Entity: Unilever  
Tail Entity: United Kingdom  

Relation: organization country of headquarters  
Context: Siemens AG, a global powerhouse in electronics and electrical engineering, has its headquarters located in Germany, reflecting its long-standing industrial heritage.  
Head Entity: Siemens AG  
Tail Entity: Germany  
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    1 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    2 | acc: 87.50%,  total acc: 83.33%   
[EVAL] batch:    3 | acc: 62.50%,  total acc: 78.12%   
[EVAL] batch:    4 | acc: 93.75%,  total acc: 81.25%   
[EVAL] batch:    5 | acc: 75.00%,  total acc: 80.21%   
[EVAL] batch:    6 | acc: 93.75%,  total acc: 82.14%   
[EVAL] batch:    7 | acc: 100.00%,  total acc: 84.38%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 86.11%   
[EVAL] batch:    9 | acc: 93.75%,  total acc: 86.88%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 88.07%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 88.54%   
[EVAL] batch:   12 | acc: 93.75%,  total acc: 88.94%   
[EVAL] batch:   13 | acc: 68.75%,  total acc: 87.50%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 86.67%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 84.77%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 84.19%   
[EVAL] batch:   17 | acc: 68.75%,  total acc: 83.33%   
[EVAL] batch:   18 | acc: 87.50%,  total acc: 83.55%   
[EVAL] batch:   19 | acc: 87.50%,  total acc: 83.75%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 84.52%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 85.23%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 85.87%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 86.46%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 87.00%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 87.50%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 87.73%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 88.17%   
[EVAL] batch:   28 | acc: 100.00%,  total acc: 88.58%   
[EVAL] batch:   29 | acc: 87.50%,  total acc: 88.54%   
[EVAL] batch:   30 | acc: 87.50%,  total acc: 88.51%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 88.67%   
[EVAL] batch:   32 | acc: 37.50%,  total acc: 87.12%   
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    1 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    2 | acc: 87.50%,  total acc: 83.33%   
[EVAL] batch:    3 | acc: 62.50%,  total acc: 78.12%   
[EVAL] batch:    4 | acc: 93.75%,  total acc: 81.25%   
[EVAL] batch:    5 | acc: 75.00%,  total acc: 80.21%   
[EVAL] batch:    6 | acc: 93.75%,  total acc: 82.14%   
[EVAL] batch:    7 | acc: 100.00%,  total acc: 84.38%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 86.11%   
[EVAL] batch:    9 | acc: 93.75%,  total acc: 86.88%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 88.07%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 88.54%   
[EVAL] batch:   12 | acc: 93.75%,  total acc: 88.94%   
[EVAL] batch:   13 | acc: 68.75%,  total acc: 87.50%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 86.67%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 84.77%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 84.19%   
[EVAL] batch:   17 | acc: 68.75%,  total acc: 83.33%   
[EVAL] batch:   18 | acc: 87.50%,  total acc: 83.55%   
[EVAL] batch:   19 | acc: 87.50%,  total acc: 83.75%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 84.52%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 85.23%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 85.87%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 86.46%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 87.00%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 87.50%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 87.73%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 88.17%   
[EVAL] batch:   28 | acc: 100.00%,  total acc: 88.58%   
[EVAL] batch:   29 | acc: 87.50%,  total acc: 88.54%   
[EVAL] batch:   30 | acc: 87.50%,  total acc: 88.51%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 88.67%   
[EVAL] batch:   32 | acc: 37.50%,  total acc: 87.12%   
cur_acc:  ['0.8712']
his_acc:  ['0.8712']
CurrentTrain: epoch  0, batch     0 | loss: 6.3973942
CurrentTrain: epoch  0, batch     1 | loss: 7.3796716
CurrentTrain: epoch  1, batch     0 | loss: 6.4657888
CurrentTrain: epoch  1, batch     1 | loss: 5.3782830
CurrentTrain: epoch  2, batch     0 | loss: 6.1777396
CurrentTrain: epoch  2, batch     1 | loss: 5.3747253
CurrentTrain: epoch  3, batch     0 | loss: 5.5423403
CurrentTrain: epoch  3, batch     1 | loss: 5.1534314
CurrentTrain: epoch  4, batch     0 | loss: 5.3756881
CurrentTrain: epoch  4, batch     1 | loss: 5.0625086
CurrentTrain: epoch  5, batch     0 | loss: 5.0119185
CurrentTrain: epoch  5, batch     1 | loss: 3.9117169
CurrentTrain: epoch  6, batch     0 | loss: 4.4607000
CurrentTrain: epoch  6, batch     1 | loss: 3.8968837
CurrentTrain: epoch  7, batch     0 | loss: 4.1129036
CurrentTrain: epoch  7, batch     1 | loss: 4.0668969
CurrentTrain: epoch  8, batch     0 | loss: 3.4643028
CurrentTrain: epoch  8, batch     1 | loss: 4.1775894
CurrentTrain: epoch  9, batch     0 | loss: 3.3281112
CurrentTrain: epoch  9, batch     1 | loss: 3.7418110
#### person date of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person date of birth" means a person was born in a date.
Here is an example:
Relation: person date of birth
Context: born in 1950 in the northeastern city of basel , ospel left school at 15 to take an apprenticeship at the transvalor brokerage house before joining swiss banking corporation -lrb- sbs -rrb- , which merged with union bank of switzerland to form ubs in 1998 .
Head Entity: ospel
Tail Entity: 1950
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person date of birth":
Relation: person date of birth  
Context: she was born on July 4, 1985, in a small town in California, where she spent her childhood before moving to New York for college.  
Head Entity: she  
Tail Entity: July 4, 1985  

Relation: person date of birth  
Context: the famous physicist was born in 1879 in Ulm, in the Kingdom of Württemberg in the German Empire, and later moved to Munich.  
Head Entity: the famous physicist  
Tail Entity: 1879  

Relation: person date of birth  
Context: born in 1992 in a bustling city, he quickly became known for his contributions to technology and innovation.  
Head Entity: he  
Tail Entity: 1992  

Relation: person date of birth  
Context: the author was born in 1965 in a small village, where she developed a love for storytelling from a young age.  
Head Entity: the author  
Tail Entity: 1965  

Relation: person date of birth  
Context: born in 1978 in the heart of London, she grew up surrounded by art and culture, which influenced her career as a painter.  
Head Entity: she  
Tail Entity: 1978  
#### person stateorprovince of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of birth" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of birth
Context: jane matilda bolin was born on april 11 , 1908 , in poughkeepsie , ny .
Head Entity: jane matilda bolin
Tail Entity: ny
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of birth":
Relation: person stateorprovince of birth  
Context: albert einstein was born on march 14, 1879, in ulm, baden-württemberg, germany.  
Head Entity: albert einstein  
Tail Entity: baden-württemberg  

Relation: person stateorprovince of birth  
Context: marilyn monroe was born on june 1, 1926, in los angeles, california.  
Head Entity: marilyn monroe  
Tail Entity: california  

Relation: person stateorprovince of birth  
Context: barack obama was born on august 4, 1961, in honolulu, hawaii.  
Head Entity: barack obama  
Tail Entity: hawaii  

Relation: person stateorprovince of birth  
Context: agatha christie was born on september 15, 1890, in torquay, devon.  
Head Entity: agatha christie  
Tail Entity: devon  

Relation: person stateorprovince of birth  
Context: nelson mandela was born on july 18, 1918, in mvezo, eastern cape.  
Head Entity: nelson mandela  
Tail Entity: eastern cape  
#### person parents ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person parents" means a person 's parent is a person.
Here is an example:
Relation: person parents
Context: lynne spears told the court that lutfi had treated her daughter like a hostage in her own home , drugged her and took over her finances .
Head Entity: her
Tail Entity: lynne spears
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person parents":
1. Relation: person parents  
   Context: After years of hard work, Sarah finally made her parents proud by graduating at the top of her class.  
   Head Entity: her  
   Tail Entity: parents  

2. Relation: person parents  
   Context: During the family reunion, Michael shared stories about how his father taught him valuable life lessons.  
   Head Entity: his  
   Tail Entity: father  

3. Relation: person parents  
   Context: Emily often reminisces about the summer vacations she spent with her mother at the beach.  
   Head Entity: her  
   Tail Entity: mother  

4. Relation: person parents  
   Context: The documentary highlighted how the struggles of his parents shaped his career as an artist.  
   Head Entity: his  
   Tail Entity: parents  

5. Relation: person parents  
   Context: Jessica credits her success to the unwavering support she received from her father throughout her life.  
   Head Entity: her  
   Tail Entity: father  
#### person employee of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person employee of" means a person is an employee of an organization.
Here is an example:
Relation: person employee of
Context: seeking revenge , axel reunites with old pal sgt. billy rosewood -lrb- judge reinhold -rrb- and jon flint -lrb- hector elizondo -rrb- of the beverly hills police department .
Head Entity: hector elizondo
Tail Entity: beverly hills police department
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person employee of":
Relation: person employee of  
Context: After years of hard work, Maria finally landed a job at the prestigious tech company, where she would be working alongside some of the brightest minds in the industry.  
Head Entity: Maria  
Tail Entity: prestigious tech company  

Relation: person employee of  
Context: John has been with the marketing firm for over a decade, contributing to numerous successful campaigns and earning the respect of his colleagues.  
Head Entity: John  
Tail Entity: marketing firm  

Relation: person employee of  
Context: As a lead designer at the fashion house, Sarah was responsible for creating stunning collections that captivated audiences during fashion week.  
Head Entity: Sarah  
Tail Entity: fashion house  

Relation: person employee of  
Context: After completing his internship, David was offered a full-time position at the renowned law firm, where he would be working on high-profile cases.  
Head Entity: David  
Tail Entity: renowned law firm  

Relation: person employee of  
Context: Emily's dedication and innovative ideas led her to become a senior analyst at the financial institution, where she played a key role in strategic planning.  
Head Entity: Emily  
Tail Entity: financial institution  
#### person stateorprovince of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of death" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of death
Context: irene morgan kirkaldy , whose defiance of bus segregation laws more than a decade before rosa parks ' landmark case helped lay the foundation for later civil rights victories , died friday at her home in hayes , va. .
Head Entity: irene morgan kirkaldy
Tail Entity: va.
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of death":
Relation: person stateorprovince of death  
Context: john doe, a renowned author known for his thrilling novels, passed away peacefully in his sleep at his residence in los angeles, ca.  
Head Entity: john doe  
Tail Entity: ca.  

Relation: person stateorprovince of death  
Context: after a long battle with illness, sarah connor, the famous scientist, succumbed to her condition in a hospital in boston, ma.  
Head Entity: sarah connor  
Tail Entity: ma.  

Relation: person stateorprovince of death  
Context: the beloved actor, tom hanks, tragically died in a car accident while traveling through the scenic routes of oregon, or.  
Head Entity: tom hanks  
Tail Entity: or.  

Relation: person stateorprovince of death  
Context: in a shocking turn of events, the legendary musician, prince, was found dead in his home located in minneapolis, mn.  
Head Entity: prince  
Tail Entity: mn.  

Relation: person stateorprovince of death  
Context: the influential civil rights leader, nelson mandela, passed away at the age of 95 in his hometown of johannesburg, gauteng.  
Head Entity: nelson mandela  
Tail Entity: gauteng.  
Mixup data size:  3730
MixupTrain:  epoch  0, batch     0 | loss: 5.2677336
MixupTrain:  epoch  0, batch     1 | loss: 5.6019025
MixupTrain:  epoch  0, batch     2 | loss: 4.4860764
MixupTrain:  epoch  0, batch     3 | loss: 4.3962779
MixupTrain:  epoch  0, batch     4 | loss: 4.5590878
MixupTrain:  epoch  0, batch     5 | loss: 4.4732261
MixupTrain:  epoch  0, batch     6 | loss: 4.7720413
MixupTrain:  epoch  0, batch     7 | loss: 4.5360274
MixupTrain:  epoch  0, batch     8 | loss: 4.3399229
MixupTrain:  epoch  0, batch     9 | loss: 3.9367700
MixupTrain:  epoch  0, batch    10 | loss: 3.9769943
MixupTrain:  epoch  0, batch    11 | loss: 3.6848228
MixupTrain:  epoch  0, batch    12 | loss: 3.7252841
MixupTrain:  epoch  0, batch    13 | loss: 4.7073588
MixupTrain:  epoch  0, batch    14 | loss: 3.6842260
MixupTrain:  epoch  0, batch    15 | loss: 4.0969992
MixupTrain:  epoch  0, batch    16 | loss: 3.6561987
MixupTrain:  epoch  0, batch    17 | loss: 3.2056537
MixupTrain:  epoch  0, batch    18 | loss: 3.7883458
MixupTrain:  epoch  0, batch    19 | loss: 3.3287275
MixupTrain:  epoch  0, batch    20 | loss: 3.4238682
MixupTrain:  epoch  0, batch    21 | loss: 3.4903202
MixupTrain:  epoch  0, batch    22 | loss: 3.7582359
MixupTrain:  epoch  0, batch    23 | loss: 3.5797625
MixupTrain:  epoch  0, batch    24 | loss: 3.4630897
MixupTrain:  epoch  0, batch    25 | loss: 3.3587756
MixupTrain:  epoch  0, batch    26 | loss: 3.2284105
MixupTrain:  epoch  0, batch    27 | loss: 2.7973878
MixupTrain:  epoch  0, batch    28 | loss: 3.0677071
MixupTrain:  epoch  0, batch    29 | loss: 3.2788756
MixupTrain:  epoch  0, batch    30 | loss: 2.9550812
MixupTrain:  epoch  0, batch    31 | loss: 3.1434450
MixupTrain:  epoch  0, batch    32 | loss: 3.1423273
MixupTrain:  epoch  0, batch    33 | loss: 2.9847000
MixupTrain:  epoch  0, batch    34 | loss: 3.2389231
MixupTrain:  epoch  0, batch    35 | loss: 2.9411471
MixupTrain:  epoch  0, batch    36 | loss: 3.0866184
MixupTrain:  epoch  0, batch    37 | loss: 3.2997406
MixupTrain:  epoch  0, batch    38 | loss: 3.3466928
MixupTrain:  epoch  0, batch    39 | loss: 2.8953581
MixupTrain:  epoch  0, batch    40 | loss: 2.7603302
MixupTrain:  epoch  0, batch    41 | loss: 2.9816260
MixupTrain:  epoch  0, batch    42 | loss: 2.6705353
MixupTrain:  epoch  0, batch    43 | loss: 2.7755249
MixupTrain:  epoch  0, batch    44 | loss: 2.6665750
MixupTrain:  epoch  0, batch    45 | loss: 3.0757637
MixupTrain:  epoch  0, batch    46 | loss: 3.0252180
MixupTrain:  epoch  0, batch    47 | loss: 2.8752327
MixupTrain:  epoch  0, batch    48 | loss: 2.6647651
MixupTrain:  epoch  0, batch    49 | loss: 2.6522794
MixupTrain:  epoch  0, batch    50 | loss: 2.3673987
MixupTrain:  epoch  0, batch    51 | loss: 2.4926772
MixupTrain:  epoch  0, batch    52 | loss: 2.4917378
MixupTrain:  epoch  0, batch    53 | loss: 2.4638939
MixupTrain:  epoch  0, batch    54 | loss: 2.7194214
MixupTrain:  epoch  0, batch    55 | loss: 2.5244818
MixupTrain:  epoch  0, batch    56 | loss: 2.5390596
MixupTrain:  epoch  0, batch    57 | loss: 2.5810692
MixupTrain:  epoch  0, batch    58 | loss: 2.4485884
MixupTrain:  epoch  0, batch    59 | loss: 2.4943259
MixupTrain:  epoch  0, batch    60 | loss: 2.5348823
MixupTrain:  epoch  0, batch    61 | loss: 2.3843870
MixupTrain:  epoch  0, batch    62 | loss: 2.3429537
MixupTrain:  epoch  0, batch    63 | loss: 2.4676476
MixupTrain:  epoch  0, batch    64 | loss: 2.5739212
MixupTrain:  epoch  0, batch    65 | loss: 2.3784237
MixupTrain:  epoch  0, batch    66 | loss: 2.4406347
MixupTrain:  epoch  0, batch    67 | loss: 2.5264990
MixupTrain:  epoch  0, batch    68 | loss: 2.2984562
MixupTrain:  epoch  0, batch    69 | loss: 2.2883353
MixupTrain:  epoch  0, batch    70 | loss: 2.2875867
MixupTrain:  epoch  0, batch    71 | loss: 2.4218946
MixupTrain:  epoch  0, batch    72 | loss: 2.3402629
MixupTrain:  epoch  0, batch    73 | loss: 2.3634076
MixupTrain:  epoch  0, batch    74 | loss: 2.2923090
MixupTrain:  epoch  0, batch    75 | loss: 2.2856379
MixupTrain:  epoch  0, batch    76 | loss: 2.3118043
MixupTrain:  epoch  0, batch    77 | loss: 2.2382708
MixupTrain:  epoch  0, batch    78 | loss: 2.2410574
MixupTrain:  epoch  0, batch    79 | loss: 2.2596846
MixupTrain:  epoch  0, batch    80 | loss: 2.2091227
MixupTrain:  epoch  0, batch    81 | loss: 2.2896271
MixupTrain:  epoch  0, batch    82 | loss: 2.2134805
MixupTrain:  epoch  0, batch    83 | loss: 2.2817874
MixupTrain:  epoch  0, batch    84 | loss: 2.2471514
MixupTrain:  epoch  0, batch    85 | loss: 2.2281175
MixupTrain:  epoch  0, batch    86 | loss: 2.2770109
MixupTrain:  epoch  0, batch    87 | loss: 2.1440420
MixupTrain:  epoch  0, batch    88 | loss: 2.1572993
MixupTrain:  epoch  0, batch    89 | loss: 2.2818935
MixupTrain:  epoch  0, batch    90 | loss: 2.2163091
MixupTrain:  epoch  0, batch    91 | loss: 2.1827674
MixupTrain:  epoch  0, batch    92 | loss: 2.1859040
MixupTrain:  epoch  0, batch    93 | loss: 2.2181683
MixupTrain:  epoch  0, batch    94 | loss: 2.1537182
MixupTrain:  epoch  0, batch    95 | loss: 2.1674786
MixupTrain:  epoch  0, batch    96 | loss: 2.0541434
MixupTrain:  epoch  0, batch    97 | loss: 2.1310773
MixupTrain:  epoch  0, batch    98 | loss: 2.1740589
MixupTrain:  epoch  0, batch    99 | loss: 2.2361162
MixupTrain:  epoch  0, batch   100 | loss: 2.1112337
MixupTrain:  epoch  0, batch   101 | loss: 2.1249213
MixupTrain:  epoch  0, batch   102 | loss: 2.1086369
MixupTrain:  epoch  0, batch   103 | loss: 2.1378224
MixupTrain:  epoch  0, batch   104 | loss: 2.1386826
MixupTrain:  epoch  0, batch   105 | loss: 2.1482148
MixupTrain:  epoch  0, batch   106 | loss: 2.2173061
MixupTrain:  epoch  0, batch   107 | loss: 2.0883734
MixupTrain:  epoch  0, batch   108 | loss: 2.1067882
MixupTrain:  epoch  0, batch   109 | loss: 2.1326730
MixupTrain:  epoch  0, batch   110 | loss: 2.1008019
MixupTrain:  epoch  0, batch   111 | loss: 2.1633720
MixupTrain:  epoch  0, batch   112 | loss: 2.1373460
MixupTrain:  epoch  0, batch   113 | loss: 2.0575154
MixupTrain:  epoch  0, batch   114 | loss: 2.1049497
MixupTrain:  epoch  0, batch   115 | loss: 2.0439222
MixupTrain:  epoch  0, batch   116 | loss: 2.0548801
MixupTrain:  epoch  0, batch   117 | loss: 2.0686016
MixupTrain:  epoch  0, batch   118 | loss: 2.0414255
MixupTrain:  epoch  0, batch   119 | loss: 2.0323763
MixupTrain:  epoch  0, batch   120 | loss: 2.0517905
MixupTrain:  epoch  0, batch   121 | loss: 2.0660179
MixupTrain:  epoch  0, batch   122 | loss: 2.1084127
MixupTrain:  epoch  0, batch   123 | loss: 2.0900633
MixupTrain:  epoch  0, batch   124 | loss: 2.0647652
MixupTrain:  epoch  0, batch   125 | loss: 2.0160544
MixupTrain:  epoch  0, batch   126 | loss: 2.0620961
MixupTrain:  epoch  0, batch   127 | loss: 2.0344911
MixupTrain:  epoch  0, batch   128 | loss: 2.0355740
MixupTrain:  epoch  0, batch   129 | loss: 2.0427856
MixupTrain:  epoch  0, batch   130 | loss: 2.0835600
MixupTrain:  epoch  0, batch   131 | loss: 2.0808079
MixupTrain:  epoch  0, batch   132 | loss: 2.0012712
MixupTrain:  epoch  0, batch   133 | loss: 2.0449381
MixupTrain:  epoch  0, batch   134 | loss: 2.0013471
MixupTrain:  epoch  0, batch   135 | loss: 2.0174272
MixupTrain:  epoch  0, batch   136 | loss: 2.0523610
MixupTrain:  epoch  0, batch   137 | loss: 1.9964066
MixupTrain:  epoch  0, batch   138 | loss: 2.0394909
MixupTrain:  epoch  0, batch   139 | loss: 2.0401976
MixupTrain:  epoch  0, batch   140 | loss: 2.0093503
MixupTrain:  epoch  0, batch   141 | loss: 2.0144844
MixupTrain:  epoch  0, batch   142 | loss: 2.0032830
MixupTrain:  epoch  0, batch   143 | loss: 2.0367312
MixupTrain:  epoch  0, batch   144 | loss: 1.9949355
MixupTrain:  epoch  0, batch   145 | loss: 1.9947500
MixupTrain:  epoch  0, batch   146 | loss: 2.0411646
MixupTrain:  epoch  0, batch   147 | loss: 2.0570261
MixupTrain:  epoch  0, batch   148 | loss: 2.0040400
MixupTrain:  epoch  0, batch   149 | loss: 2.0138249
MixupTrain:  epoch  0, batch   150 | loss: 2.0013018
MixupTrain:  epoch  0, batch   151 | loss: 2.0329394
MixupTrain:  epoch  0, batch   152 | loss: 2.0212808
MixupTrain:  epoch  0, batch   153 | loss: 1.9748943
MixupTrain:  epoch  0, batch   154 | loss: 2.0095453
MixupTrain:  epoch  0, batch   155 | loss: 2.0070090
MixupTrain:  epoch  0, batch   156 | loss: 2.0175481
MixupTrain:  epoch  0, batch   157 | loss: 2.0120635
MixupTrain:  epoch  0, batch   158 | loss: 2.0292623
MixupTrain:  epoch  0, batch   159 | loss: 2.0017076
MixupTrain:  epoch  0, batch   160 | loss: 1.9865026
MixupTrain:  epoch  0, batch   161 | loss: 1.9670383
MixupTrain:  epoch  0, batch   162 | loss: 1.9994246
MixupTrain:  epoch  0, batch   163 | loss: 2.0161991
MixupTrain:  epoch  0, batch   164 | loss: 1.9629899
MixupTrain:  epoch  0, batch   165 | loss: 1.9947002
MixupTrain:  epoch  0, batch   166 | loss: 2.0164700
MixupTrain:  epoch  0, batch   167 | loss: 2.0055447
MixupTrain:  epoch  0, batch   168 | loss: 1.9846609
MixupTrain:  epoch  0, batch   169 | loss: 1.9938109
MixupTrain:  epoch  0, batch   170 | loss: 2.0128548
MixupTrain:  epoch  0, batch   171 | loss: 1.9734857
MixupTrain:  epoch  0, batch   172 | loss: 1.9645274
MixupTrain:  epoch  0, batch   173 | loss: 1.9794210
MixupTrain:  epoch  0, batch   174 | loss: 1.9780350
MixupTrain:  epoch  0, batch   175 | loss: 2.0120859
MixupTrain:  epoch  0, batch   176 | loss: 1.9959810
MixupTrain:  epoch  0, batch   177 | loss: 2.0102222
MixupTrain:  epoch  0, batch   178 | loss: 1.9502327
MixupTrain:  epoch  0, batch   179 | loss: 1.9888394
MixupTrain:  epoch  0, batch   180 | loss: 1.9499215
MixupTrain:  epoch  0, batch   181 | loss: 1.9770468
MixupTrain:  epoch  0, batch   182 | loss: 1.9263874
MixupTrain:  epoch  0, batch   183 | loss: 2.0014637
MixupTrain:  epoch  0, batch   184 | loss: 1.9560156
MixupTrain:  epoch  0, batch   185 | loss: 1.9608513
MixupTrain:  epoch  0, batch   186 | loss: 1.9592280
MixupTrain:  epoch  0, batch   187 | loss: 1.9675280
MixupTrain:  epoch  0, batch   188 | loss: 2.0000727
MixupTrain:  epoch  0, batch   189 | loss: 1.9849186
MixupTrain:  epoch  0, batch   190 | loss: 1.9463342
MixupTrain:  epoch  0, batch   191 | loss: 1.9336069
MixupTrain:  epoch  0, batch   192 | loss: 1.9357228
MixupTrain:  epoch  0, batch   193 | loss: 1.9609599
MixupTrain:  epoch  0, batch   194 | loss: 1.9346808
MixupTrain:  epoch  0, batch   195 | loss: 1.9448946
MixupTrain:  epoch  0, batch   196 | loss: 1.9252059
MixupTrain:  epoch  0, batch   197 | loss: 1.9532726
MixupTrain:  epoch  0, batch   198 | loss: 2.0051310
MixupTrain:  epoch  0, batch   199 | loss: 1.9675789
MixupTrain:  epoch  0, batch   200 | loss: 1.9323001
MixupTrain:  epoch  0, batch   201 | loss: 1.9530520
MixupTrain:  epoch  0, batch   202 | loss: 1.9562974
MixupTrain:  epoch  0, batch   203 | loss: 1.9987466
MixupTrain:  epoch  0, batch   204 | loss: 1.9666939
MixupTrain:  epoch  0, batch   205 | loss: 1.9168701
MixupTrain:  epoch  0, batch   206 | loss: 1.9608293
MixupTrain:  epoch  0, batch   207 | loss: 1.9696615
MixupTrain:  epoch  0, batch   208 | loss: 1.9366429
MixupTrain:  epoch  0, batch   209 | loss: 1.9595709
MixupTrain:  epoch  0, batch   210 | loss: 1.9612114
MixupTrain:  epoch  0, batch   211 | loss: 1.9710128
MixupTrain:  epoch  0, batch   212 | loss: 1.9521091
MixupTrain:  epoch  0, batch   213 | loss: 1.9465232
MixupTrain:  epoch  0, batch   214 | loss: 1.9543133
MixupTrain:  epoch  0, batch   215 | loss: 1.9501534
MixupTrain:  epoch  0, batch   216 | loss: 1.9325420
MixupTrain:  epoch  0, batch   217 | loss: 1.9578472
MixupTrain:  epoch  0, batch   218 | loss: 1.9515558
MixupTrain:  epoch  0, batch   219 | loss: 1.9492843
MixupTrain:  epoch  0, batch   220 | loss: 1.9679797
MixupTrain:  epoch  0, batch   221 | loss: 1.9438517
MixupTrain:  epoch  0, batch   222 | loss: 1.9551396
MixupTrain:  epoch  0, batch   223 | loss: 1.9577174
MixupTrain:  epoch  0, batch   224 | loss: 1.9454427
MixupTrain:  epoch  0, batch   225 | loss: 1.9331901
MixupTrain:  epoch  0, batch   226 | loss: 1.9719064
MixupTrain:  epoch  0, batch   227 | loss: 1.9386904
MixupTrain:  epoch  0, batch   228 | loss: 1.9233301
MixupTrain:  epoch  0, batch   229 | loss: 1.9462156
MixupTrain:  epoch  0, batch   230 | loss: 1.9650486
MixupTrain:  epoch  0, batch   231 | loss: 1.9357835
MixupTrain:  epoch  0, batch   232 | loss: 1.9240046
MixupTrain:  epoch  0, batch   233 | loss: 1.8683225
MemoryTrain:  epoch  0, batch     0 | loss: 1.9107755
MemoryTrain:  epoch  0, batch     1 | loss: 3.1387377
MemoryTrain:  epoch  0, batch     2 | loss: 2.9651525
MemoryTrain:  epoch  0, batch     3 | loss: 2.8737721
MemoryTrain:  epoch  0, batch     4 | loss: 2.2988262
MemoryTrain:  epoch  1, batch     0 | loss: 1.8615527
MemoryTrain:  epoch  1, batch     1 | loss: 1.8961115
MemoryTrain:  epoch  1, batch     2 | loss: 1.8512977
MemoryTrain:  epoch  1, batch     3 | loss: 1.8489549
MemoryTrain:  epoch  1, batch     4 | loss: 1.8585654
MemoryTrain:  epoch  2, batch     0 | loss: 1.8708853
MemoryTrain:  epoch  2, batch     1 | loss: 1.8660371
MemoryTrain:  epoch  2, batch     2 | loss: 1.8684450
MemoryTrain:  epoch  2, batch     3 | loss: 1.8442553
MemoryTrain:  epoch  2, batch     4 | loss: 1.8411250
MemoryTrain:  epoch  3, batch     0 | loss: 1.8600719
MemoryTrain:  epoch  3, batch     1 | loss: 1.8631941
MemoryTrain:  epoch  3, batch     2 | loss: 1.8456303
MemoryTrain:  epoch  3, batch     3 | loss: 1.8481286
MemoryTrain:  epoch  3, batch     4 | loss: 1.8443315
MemoryTrain:  epoch  4, batch     0 | loss: 1.8415322
MemoryTrain:  epoch  4, batch     1 | loss: 1.8308184
MemoryTrain:  epoch  4, batch     2 | loss: 1.8599017
MemoryTrain:  epoch  4, batch     3 | loss: 1.8609346
MemoryTrain:  epoch  4, batch     4 | loss: 1.8502173
MemoryTrain:  epoch  5, batch     0 | loss: 1.8572993
MemoryTrain:  epoch  5, batch     1 | loss: 1.8797902
MemoryTrain:  epoch  5, batch     2 | loss: 1.8744106
MemoryTrain:  epoch  5, batch     3 | loss: 1.8723379
MemoryTrain:  epoch  5, batch     4 | loss: 1.8211999
MemoryTrain:  epoch  6, batch     0 | loss: 1.8630949
MemoryTrain:  epoch  6, batch     1 | loss: 1.8387982
MemoryTrain:  epoch  6, batch     2 | loss: 1.8372213
MemoryTrain:  epoch  6, batch     3 | loss: 1.8523840
MemoryTrain:  epoch  6, batch     4 | loss: 1.8710604
MemoryTrain:  epoch  7, batch     0 | loss: 1.8483680
MemoryTrain:  epoch  7, batch     1 | loss: 1.8384035
MemoryTrain:  epoch  7, batch     2 | loss: 1.8562529
MemoryTrain:  epoch  7, batch     3 | loss: 1.8299174
MemoryTrain:  epoch  7, batch     4 | loss: 1.9051499
MemoryTrain:  epoch  8, batch     0 | loss: 1.8355904
MemoryTrain:  epoch  8, batch     1 | loss: 1.8665009
MemoryTrain:  epoch  8, batch     2 | loss: 1.8402345
MemoryTrain:  epoch  8, batch     3 | loss: 1.8400480
MemoryTrain:  epoch  8, batch     4 | loss: 1.8035322
MemoryTrain:  epoch  9, batch     0 | loss: 1.8526180
MemoryTrain:  epoch  9, batch     1 | loss: 1.8720737
MemoryTrain:  epoch  9, batch     2 | loss: 1.8790282
MemoryTrain:  epoch  9, batch     3 | loss: 1.8369787
MemoryTrain:  epoch  9, batch     4 | loss: 1.8883431
[EVAL] batch:    0 | acc: 87.50%,  total acc: 87.50%   
[EVAL] batch:    1 | acc: 93.75%,  total acc: 90.62%   
[EVAL] batch:    2 | acc: 93.75%,  total acc: 91.67%   
[EVAL] batch:    3 | acc: 93.75%,  total acc: 92.19%   
[EVAL] batch:    4 | acc: 100.00%,  total acc: 93.75%   
[EVAL] batch:    5 | acc: 100.00%,  total acc: 94.79%   
[EVAL] batch:    6 | acc: 81.25%,  total acc: 92.86%   
[EVAL] batch:    7 | acc: 93.75%,  total acc: 92.97%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 93.75%   
[EVAL] batch:    9 | acc: 87.50%,  total acc: 93.12%   
[EVAL] batch:   10 | acc: 87.50%,  total acc: 92.61%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 92.71%   
[EVAL] batch:   12 | acc: 81.25%,  total acc: 91.83%   
[EVAL] batch:   13 | acc: 25.00%,  total acc: 87.05%   
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   
[EVAL] batch:    1 | acc: 87.50%,  total acc: 81.25%   
[EVAL] batch:    2 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    3 | acc: 56.25%,  total acc: 75.00%   
[EVAL] batch:    4 | acc: 87.50%,  total acc: 77.50%   
[EVAL] batch:    5 | acc: 68.75%,  total acc: 76.04%   
[EVAL] batch:    6 | acc: 100.00%,  total acc: 79.46%   
[EVAL] batch:    7 | acc: 100.00%,  total acc: 82.03%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 84.03%   
[EVAL] batch:    9 | acc: 87.50%,  total acc: 84.38%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 85.80%   
[EVAL] batch:   11 | acc: 87.50%,  total acc: 85.94%   
[EVAL] batch:   12 | acc: 93.75%,  total acc: 86.54%   
[EVAL] batch:   13 | acc: 68.75%,  total acc: 85.27%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 84.58%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 82.81%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 82.35%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 81.25%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 80.26%   
[EVAL] batch:   19 | acc: 87.50%,  total acc: 80.62%   
[EVAL] batch:   20 | acc: 93.75%,  total acc: 81.25%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 82.10%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 82.88%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 83.59%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 84.25%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 84.86%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 85.19%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 85.71%   
[EVAL] batch:   28 | acc: 93.75%,  total acc: 85.99%   
[EVAL] batch:   29 | acc: 81.25%,  total acc: 85.83%   
[EVAL] batch:   30 | acc: 100.00%,  total acc: 86.29%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 86.52%   
[EVAL] batch:   32 | acc: 100.00%,  total acc: 86.93%   
[EVAL] batch:   33 | acc: 81.25%,  total acc: 86.76%   
[EVAL] batch:   34 | acc: 100.00%,  total acc: 87.14%   
[EVAL] batch:   35 | acc: 87.50%,  total acc: 87.15%   
[EVAL] batch:   36 | acc: 100.00%,  total acc: 87.50%   
[EVAL] batch:   37 | acc: 100.00%,  total acc: 87.83%   
[EVAL] batch:   38 | acc: 100.00%,  total acc: 88.14%   
[EVAL] batch:   39 | acc: 75.00%,  total acc: 87.81%   
[EVAL] batch:   40 | acc: 100.00%,  total acc: 88.11%   
[EVAL] batch:   41 | acc: 93.75%,  total acc: 88.24%   
[EVAL] batch:   42 | acc: 93.75%,  total acc: 88.37%   
[EVAL] batch:   43 | acc: 81.25%,  total acc: 88.21%   
[EVAL] batch:   44 | acc: 100.00%,  total acc: 88.47%   
[EVAL] batch:   45 | acc: 43.75%,  total acc: 87.50%   
[EVAL] batch:   46 | acc: 0.00%,  total acc: 85.64%   
cur_acc:  ['0.8712', '0.8705']
his_acc:  ['0.8712', '0.8564']
CurrentTrain: epoch  0, batch     0 | loss: 5.6352749
CurrentTrain: epoch  0, batch     1 | loss: 7.6153326
CurrentTrain: epoch  1, batch     0 | loss: 5.7505999
CurrentTrain: epoch  1, batch     1 | loss: 5.3179588
CurrentTrain: epoch  2, batch     0 | loss: 4.7194953
CurrentTrain: epoch  2, batch     1 | loss: 4.3988700
CurrentTrain: epoch  3, batch     0 | loss: 3.9803908
CurrentTrain: epoch  3, batch     1 | loss: 3.7368562
CurrentTrain: epoch  4, batch     0 | loss: 3.5531521
CurrentTrain: epoch  4, batch     1 | loss: 3.7579100
CurrentTrain: epoch  5, batch     0 | loss: 3.1216886
CurrentTrain: epoch  5, batch     1 | loss: 2.6645179
CurrentTrain: epoch  6, batch     0 | loss: 3.0688066
CurrentTrain: epoch  6, batch     1 | loss: 2.1108932
CurrentTrain: epoch  7, batch     0 | loss: 2.6537447
CurrentTrain: epoch  7, batch     1 | loss: 2.6334488
CurrentTrain: epoch  8, batch     0 | loss: 2.0438557
CurrentTrain: epoch  8, batch     1 | loss: 3.1301646
CurrentTrain: epoch  9, batch     0 | loss: 2.1033149
CurrentTrain: epoch  9, batch     1 | loss: 2.4602797
#### person country of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person country of birth" means a person was born in a country.
Here is an example:
Relation: person country of birth
Context: in testimony by satellite link from germany to a house of representatives ' panel , murat kurnaz recounted his five-year detention , alleging a wide range of torture and abuse .
Head Entity: murat kurnaz
Tail Entity: germany
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person country of birth":
Relation: person country of birth  
Context: The famous physicist Albert Einstein was born in the Kingdom of Württemberg in the German Empire.  
Head Entity: Albert Einstein  
Tail Entity: Germany  

Relation: person country of birth  
Context: During an interview, the actress Penélope Cruz shared her experiences growing up in Spain and how it shaped her career.  
Head Entity: Penélope Cruz  
Tail Entity: Spain  

Relation: person country of birth  
Context: The renowned author Gabriel García Márquez was born in Aracataca, a small town in Colombia, which inspired much of his writing.  
Head Entity: Gabriel García Márquez  
Tail Entity: Colombia  

Relation: person country of birth  
Context: In a recent documentary, the musician Freddie Mercury discussed his childhood in Zanzibar before moving to England.  
Head Entity: Freddie Mercury  
Tail Entity: Tanzania  

Relation: person country of birth  
Context: The celebrated scientist Marie Curie was born in Warsaw, Poland, before she moved to France to continue her research.  
Head Entity: Marie Curie  
Tail Entity: Poland  
#### organization website ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization website" means an organization 's website is an url.
Here is an example:
Relation: organization website
Context: http://www.pentaxsailaway.com/ paul j. sail away with pentax sweepstakes
Head Entity: pentax
Tail Entity: http://www.pentaxsailaway.com/
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization website":
Relation: organization website  
Context: Visit our official site at https://www.techinnovators.com for the latest updates.  
Head Entity: Tech Innovators  
Tail Entity: https://www.techinnovators.com  

Relation: organization website  
Context: For more information, check out the website of Green Earth Initiative at http://www.greenearth.org.  
Head Entity: Green Earth Initiative  
Tail Entity: http://www.greenearth.org  

Relation: organization website  
Context: The blog post can be found at https://www.culinarycreations.com/blog, which is managed by Culinary Creations.  
Head Entity: Culinary Creations  
Tail Entity: https://www.culinarycreations.com/blog  

Relation: organization website  
Context: You can learn more about our services by visiting http://www.fitnessworld.com.  
Head Entity: Fitness World  
Tail Entity: http://www.fitnessworld.com  

Relation: organization website  
Context: The latest news is available on the official site: https://www.artisticvisions.org.  
Head Entity: Artistic Visions  
Tail Entity: https://www.artisticvisions.org  
#### organization shareholders ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization shareholders" means an organization was invested by a person.
Here is an example:
Relation: organization shareholders
Context: marsans already owns the madrid-based air comet and 95 percent of aerolineas argentinas .
Head Entity: aerolineas argentinas
Tail Entity: marsans
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization shareholders":
Relation: organization shareholders  
Context: tech giant Apple has seen significant investments from Warren Buffett's Berkshire Hathaway.  
Head Entity: Apple  
Tail Entity: Berkshire Hathaway  

Relation: organization shareholders  
Context: The investment firm Vanguard Group has acquired a substantial stake in the renewable energy company NextEra Energy.  
Head Entity: NextEra Energy  
Tail Entity: Vanguard Group  

Relation: organization shareholders  
Context: Tesla's stock has been heavily bought by investment firm BlackRock, making them one of the largest shareholders.  
Head Entity: Tesla  
Tail Entity: BlackRock  

Relation: organization shareholders  
Context: The pharmaceutical company Pfizer has received major investments from the investment group Fidelity.  
Head Entity: Pfizer  
Tail Entity: Fidelity  

Relation: organization shareholders  
Context: The social media platform Facebook has attracted significant funding from the investment firm Sequoia Capital.  
Head Entity: Facebook  
Tail Entity: Sequoia Capital  
#### organization dissolved ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization dissolved" means an organization was dissolved in a date.
Here is an example:
Relation: organization dissolved
Context: the tse suffered its worst-ever system crash in november 2005 which paralyzed the world 's second largest bourse and forced it to shelve plan for a listing of its own .
Head Entity: tse
Tail Entity: november 2005
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization dissolved":
Relation: organization dissolved  
Context: The once-prominent tech startup, Innovatech, officially ceased operations in March 2020 after struggling to secure funding.  
Head Entity: Innovatech  
Tail Entity: March 2020  

Relation: organization dissolved  
Context: After years of financial difficulties, the local arts council announced its dissolution in January 2019, leaving many artists without support.  
Head Entity: local arts council  
Tail Entity: January 2019  

Relation: organization dissolved  
Context: The historic bookstore, Pages & Co., closed its doors for good in July 2021, marking the end of an era for the community.  
Head Entity: Pages & Co.  
Tail Entity: July 2021  

Relation: organization dissolved  
Context: Following a series of scandals, the charity organization Hope for All was officially dissolved in February 2022, prompting an investigation into its finances.  
Head Entity: Hope for All  
Tail Entity: February 2022  

Relation: organization dissolved  
Context: The environmental group Green Future announced its dissolution in December 2020, citing a lack of resources and support from the community.  
Head Entity: Green Future  
Tail Entity: December 2020  
#### organization founded by ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization founded by" means an organization was found by a person.
Here is an example:
Relation: organization founded by
Context: born in new york , she inherited most of her fortune from her father , ted arison , who founded carnival cruise lines and also owned the miami heat basketball team .
Head Entity: carnival cruise lines
Tail Entity: ted arison
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization founded by":
1. Relation: organization founded by  
   Context: in 1975, steve jobs and steve wozniak started apple inc., which revolutionized the personal computer industry.  
   Head Entity: apple inc.  
   Tail Entity: steve jobs  

2. Relation: organization founded by  
   Context: the famous physicist albert einstein was one of the founders of the hebrew university of jerusalem, established in 1918.  
   Head Entity: hebrew university of jerusalem  
   Tail Entity: albert einstein  

3. Relation: organization founded by  
   Context: in 1998, larry page and sergey brin launched google, which has since become a dominant force in the tech industry.  
   Head Entity: google  
   Tail Entity: larry page  

4. Relation: organization founded by  
   Context: the renowned chef julia child played a pivotal role in establishing the culinary institute of america, which trains aspiring chefs.  
   Head Entity: culinary institute of america  
   Tail Entity: julia child  

5. Relation: organization founded by  
   Context: in 2004, mark zuckerberg, along with his college roommates, created facebook, which transformed social networking.  
   Head Entity: facebook  
   Tail Entity: mark zuckerberg  
Mixup data size:  6820
MixupTrain:  epoch  0, batch     0 | loss: 5.3577175
MixupTrain:  epoch  0, batch     1 | loss: 5.1518021
MixupTrain:  epoch  0, batch     2 | loss: 5.0292625
MixupTrain:  epoch  0, batch     3 | loss: 5.5769167
MixupTrain:  epoch  0, batch     6 | loss: 4.9628239
MixupTrain:  epoch  0, batch     7 | loss: 4.7057505
MixupTrain:  epoch  0, batch     8 | loss: 4.5162153
MixupTrain:  epoch  0, batch     9 | loss: 3.9708447
MixupTrain:  epoch  0, batch    10 | loss: 4.4327502
MixupTrain:  epoch  0, batch    11 | loss: 4.5665536
MixupTrain:  epoch  0, batch    12 | loss: 4.4560862
MixupTrain:  epoch  0, batch    13 | loss: 5.1045127
MixupTrain:  epoch  0, batch    14 | loss: 3.8556528
MixupTrain:  epoch  0, batch    15 | loss: 5.2539377
MixupTrain:  epoch  0, batch    16 | loss: 4.4253454
MixupTrain:  epoch  0, batch    17 | loss: 4.8733625
MixupTrain:  epoch  0, batch    19 | loss: 5.2078505
MixupTrain:  epoch  0, batch    20 | loss: 4.5351028
MixupTrain:  epoch  0, batch    21 | loss: 4.4083395
MixupTrain:  epoch  0, batch    22 | loss: 3.9339459
MixupTrain:  epoch  0, batch    23 | loss: 3.9796536
MixupTrain:  epoch  0, batch    25 | loss: 4.4137044
MixupTrain:  epoch  0, batch    26 | loss: 4.2532802
MixupTrain:  epoch  0, batch    29 | loss: 4.0989523
MixupTrain:  epoch  0, batch    31 | loss: 3.7465277
MixupTrain:  epoch  0, batch    32 | loss: 4.2833862
MixupTrain:  epoch  0, batch    33 | loss: 3.8627846
MixupTrain:  epoch  0, batch    34 | loss: 4.2293987
MixupTrain:  epoch  0, batch    35 | loss: 3.7492189
MixupTrain:  epoch  0, batch    36 | loss: 3.4126091
MixupTrain:  epoch  0, batch    37 | loss: 3.8314886
MixupTrain:  epoch  0, batch    38 | loss: 3.8327317
MixupTrain:  epoch  0, batch    39 | loss: 3.5818038
MixupTrain:  epoch  0, batch    40 | loss: 3.0470600
MixupTrain:  epoch  0, batch    42 | loss: 3.4580941
MixupTrain:  epoch  0, batch    43 | loss: 3.7836633
MixupTrain:  epoch  0, batch    44 | loss: 4.0062938
MixupTrain:  epoch  0, batch    46 | loss: 3.5013003
MixupTrain:  epoch  0, batch    47 | loss: 3.8293357
MixupTrain:  epoch  0, batch    48 | loss: 3.4134207
MixupTrain:  epoch  0, batch    49 | loss: 3.4003155
MixupTrain:  epoch  0, batch    50 | loss: 3.3603470
MixupTrain:  epoch  0, batch    51 | loss: 3.8342595
MixupTrain:  epoch  0, batch    52 | loss: 3.6920955
MixupTrain:  epoch  0, batch    53 | loss: 3.2979577
MixupTrain:  epoch  0, batch    54 | loss: 3.5812616
MixupTrain:  epoch  0, batch    57 | loss: 3.4853487
MixupTrain:  epoch  0, batch    58 | loss: 3.0382051
MixupTrain:  epoch  0, batch    59 | loss: 3.1720538
MixupTrain:  epoch  0, batch    60 | loss: 3.4674690
MixupTrain:  epoch  0, batch    61 | loss: 3.4503331
MixupTrain:  epoch  0, batch    62 | loss: 2.8431773
MixupTrain:  epoch  0, batch    63 | loss: 3.5145817
MixupTrain:  epoch  0, batch    66 | loss: 2.6141250
MixupTrain:  epoch  0, batch    67 | loss: 3.1115022
MixupTrain:  epoch  0, batch    68 | loss: 2.9252527
MixupTrain:  epoch  0, batch    69 | loss: 2.8280966
MixupTrain:  epoch  0, batch    70 | loss: 3.4593401
MixupTrain:  epoch  0, batch    71 | loss: 3.2903180
MixupTrain:  epoch  0, batch    72 | loss: 3.0572567
MixupTrain:  epoch  0, batch    73 | loss: 3.2631159
MixupTrain:  epoch  0, batch    74 | loss: 2.8417096
MixupTrain:  epoch  0, batch    75 | loss: 2.7820148
MixupTrain:  epoch  0, batch    77 | loss: 3.6677647
MixupTrain:  epoch  0, batch    78 | loss: 3.2995296
MixupTrain:  epoch  0, batch    81 | loss: 3.0852540
MixupTrain:  epoch  0, batch    83 | loss: 3.0079110
MixupTrain:  epoch  0, batch    84 | loss: 2.8815470
MixupTrain:  epoch  0, batch    87 | loss: 2.9718394
MixupTrain:  epoch  0, batch    88 | loss: 3.1898434
MixupTrain:  epoch  0, batch    89 | loss: 2.3968859
MixupTrain:  epoch  0, batch    90 | loss: 3.1332173
MixupTrain:  epoch  0, batch    91 | loss: 2.8297286
MixupTrain:  epoch  0, batch    92 | loss: 2.7367427
MixupTrain:  epoch  0, batch    93 | loss: 2.7063987
MixupTrain:  epoch  0, batch    94 | loss: 2.7500186
MixupTrain:  epoch  0, batch    95 | loss: 2.5496311
MixupTrain:  epoch  0, batch    97 | loss: 2.9216366
MixupTrain:  epoch  0, batch   100 | loss: 2.8322964
MixupTrain:  epoch  0, batch   102 | loss: 2.8829560
MixupTrain:  epoch  0, batch   105 | loss: 2.5578980
MixupTrain:  epoch  0, batch   106 | loss: 2.5426285
MixupTrain:  epoch  0, batch   107 | loss: 2.7786875
MixupTrain:  epoch  0, batch   108 | loss: 2.7027259
MixupTrain:  epoch  0, batch   109 | loss: 2.7235529
MixupTrain:  epoch  0, batch   110 | loss: 2.8050108
MixupTrain:  epoch  0, batch   111 | loss: 3.0488377
MixupTrain:  epoch  0, batch   112 | loss: 2.9734740
MixupTrain:  epoch  0, batch   113 | loss: 2.9439182
MixupTrain:  epoch  0, batch   114 | loss: 3.0359302
MixupTrain:  epoch  0, batch   115 | loss: 2.8032296
MixupTrain:  epoch  0, batch   117 | loss: 2.9756770
MixupTrain:  epoch  0, batch   118 | loss: 2.4100959
MixupTrain:  epoch  0, batch   119 | loss: 2.7055483
MixupTrain:  epoch  0, batch   121 | loss: 2.8906565
MixupTrain:  epoch  0, batch   122 | loss: 3.0291586
MixupTrain:  epoch  0, batch   123 | loss: 2.7900202
MixupTrain:  epoch  0, batch   124 | loss: 2.6364172
MixupTrain:  epoch  0, batch   125 | loss: 2.8906856
MixupTrain:  epoch  0, batch   126 | loss: 2.5635967
MixupTrain:  epoch  0, batch   127 | loss: 2.7576108
MixupTrain:  epoch  0, batch   129 | loss: 2.3919022
MixupTrain:  epoch  0, batch   130 | loss: 2.8282256
MixupTrain:  epoch  0, batch   131 | loss: 2.7473953
MixupTrain:  epoch  0, batch   132 | loss: 2.9166055
MixupTrain:  epoch  0, batch   133 | loss: 2.8452711
MixupTrain:  epoch  0, batch   135 | loss: 2.6313303
MixupTrain:  epoch  0, batch   136 | loss: 2.2284892
MixupTrain:  epoch  0, batch   137 | loss: 2.7092044
MixupTrain:  epoch  0, batch   139 | loss: 2.6337554
MixupTrain:  epoch  0, batch   140 | loss: 2.9306881
MixupTrain:  epoch  0, batch   141 | loss: 2.8915024
MixupTrain:  epoch  0, batch   142 | loss: 2.6719711
MixupTrain:  epoch  0, batch   143 | loss: 3.0537629
MixupTrain:  epoch  0, batch   144 | loss: 2.7653863
MixupTrain:  epoch  0, batch   145 | loss: 2.8830428
MixupTrain:  epoch  0, batch   146 | loss: 2.8978796
MixupTrain:  epoch  0, batch   148 | loss: 2.6034367
MixupTrain:  epoch  0, batch   150 | loss: 2.6128397
MixupTrain:  epoch  0, batch   152 | loss: 2.4807043
MixupTrain:  epoch  0, batch   153 | loss: 2.5195303
MixupTrain:  epoch  0, batch   154 | loss: 2.7156849
MixupTrain:  epoch  0, batch   156 | loss: 2.5453587
MixupTrain:  epoch  0, batch   157 | loss: 2.4597323
MixupTrain:  epoch  0, batch   158 | loss: 2.5344930
MixupTrain:  epoch  0, batch   160 | loss: 2.4224870
MixupTrain:  epoch  0, batch   161 | loss: 2.5581005
MixupTrain:  epoch  0, batch   162 | loss: 2.8617454
MixupTrain:  epoch  0, batch   163 | loss: 2.7625875
MixupTrain:  epoch  0, batch   164 | loss: 2.7756038
MixupTrain:  epoch  0, batch   167 | loss: 2.6068168
MixupTrain:  epoch  0, batch   168 | loss: 2.4143672
MixupTrain:  epoch  0, batch   169 | loss: 2.8773606
MixupTrain:  epoch  0, batch   170 | loss: 2.8277397
MixupTrain:  epoch  0, batch   171 | loss: 2.5153680
MixupTrain:  epoch  0, batch   173 | loss: 2.4322839
MixupTrain:  epoch  0, batch   175 | loss: 2.5419621
MixupTrain:  epoch  0, batch   176 | loss: 2.7230532
MixupTrain:  epoch  0, batch   177 | loss: 2.3999083
MixupTrain:  epoch  0, batch   178 | loss: 2.6486411
MixupTrain:  epoch  0, batch   180 | loss: 2.6864302
MixupTrain:  epoch  0, batch   181 | loss: 2.5625367
MixupTrain:  epoch  0, batch   186 | loss: 2.5447445
MixupTrain:  epoch  0, batch   187 | loss: 2.5604143
MixupTrain:  epoch  0, batch   188 | loss: 2.5276632
MixupTrain:  epoch  0, batch   190 | loss: 3.1318173
MixupTrain:  epoch  0, batch   191 | loss: 2.7126741
MixupTrain:  epoch  0, batch   192 | loss: 2.4283185
MixupTrain:  epoch  0, batch   193 | loss: 2.3792522
MixupTrain:  epoch  0, batch   196 | loss: 2.4644673
MixupTrain:  epoch  0, batch   198 | loss: 2.4507036
MixupTrain:  epoch  0, batch   199 | loss: 2.7655122
MixupTrain:  epoch  0, batch   200 | loss: 2.2675734
MixupTrain:  epoch  0, batch   201 | loss: 2.7535195
MixupTrain:  epoch  0, batch   202 | loss: 2.6142585
MixupTrain:  epoch  0, batch   204 | loss: 2.5481663
MixupTrain:  epoch  0, batch   205 | loss: 2.4306388
MixupTrain:  epoch  0, batch   207 | loss: 2.5789719
MixupTrain:  epoch  0, batch   208 | loss: 2.2154970
MixupTrain:  epoch  0, batch   210 | loss: 2.4702086
MixupTrain:  epoch  0, batch   211 | loss: 2.4232726
MixupTrain:  epoch  0, batch   212 | loss: 2.8764358
MixupTrain:  epoch  0, batch   213 | loss: 2.5498059
MixupTrain:  epoch  0, batch   214 | loss: 2.5258217
MixupTrain:  epoch  0, batch   216 | loss: 2.7384312
MixupTrain:  epoch  0, batch   217 | loss: 2.5619066
MixupTrain:  epoch  0, batch   218 | loss: 2.5149264
MixupTrain:  epoch  0, batch   219 | loss: 2.3227973
MixupTrain:  epoch  0, batch   220 | loss: 2.6887152
MixupTrain:  epoch  0, batch   221 | loss: 2.5197988
MixupTrain:  epoch  0, batch   222 | loss: 2.2756872
MixupTrain:  epoch  0, batch   223 | loss: 2.5245793
MixupTrain:  epoch  0, batch   225 | loss: 2.2488940
MixupTrain:  epoch  0, batch   226 | loss: 2.6237035
MixupTrain:  epoch  0, batch   227 | loss: 2.4581501
MixupTrain:  epoch  0, batch   228 | loss: 2.1112461
MixupTrain:  epoch  0, batch   229 | loss: 2.2404795
MixupTrain:  epoch  0, batch   231 | loss: 2.3976750
MixupTrain:  epoch  0, batch   232 | loss: 2.6140699
MixupTrain:  epoch  0, batch   234 | loss: 2.5746171
MixupTrain:  epoch  0, batch   235 | loss: 2.5336390
MixupTrain:  epoch  0, batch   238 | loss: 2.3326292
MixupTrain:  epoch  0, batch   239 | loss: 2.6522593
MixupTrain:  epoch  0, batch   240 | loss: 2.4762831
MixupTrain:  epoch  0, batch   241 | loss: 2.4969342
MixupTrain:  epoch  0, batch   242 | loss: 2.4225116
MixupTrain:  epoch  0, batch   243 | loss: 2.3553376
MixupTrain:  epoch  0, batch   244 | loss: 2.2259398
MixupTrain:  epoch  0, batch   245 | loss: 2.4377308
MixupTrain:  epoch  0, batch   247 | loss: 2.2297251
MixupTrain:  epoch  0, batch   248 | loss: 2.4822602
MixupTrain:  epoch  0, batch   249 | loss: 2.5854807
MixupTrain:  epoch  0, batch   250 | loss: 2.4233384
MixupTrain:  epoch  0, batch   251 | loss: 2.5073154
MixupTrain:  epoch  0, batch   252 | loss: 2.3715959
MixupTrain:  epoch  0, batch   253 | loss: 2.4748125
MixupTrain:  epoch  0, batch   254 | loss: 2.6214881
MixupTrain:  epoch  0, batch   256 | loss: 2.3320954
MixupTrain:  epoch  0, batch   257 | loss: 2.2398074
MixupTrain:  epoch  0, batch   258 | loss: 2.6219726
MixupTrain:  epoch  0, batch   259 | loss: 2.4053662
MixupTrain:  epoch  0, batch   261 | loss: 2.5766070
MixupTrain:  epoch  0, batch   262 | loss: 2.3908725
MixupTrain:  epoch  0, batch   264 | loss: 2.4570084
MixupTrain:  epoch  0, batch   266 | loss: 2.3166921
MixupTrain:  epoch  0, batch   267 | loss: 2.4492788
MixupTrain:  epoch  0, batch   268 | loss: 2.5443454
MixupTrain:  epoch  0, batch   269 | loss: 2.4546425
MixupTrain:  epoch  0, batch   270 | loss: 2.5316057
MixupTrain:  epoch  0, batch   272 | loss: 2.2354183
MixupTrain:  epoch  0, batch   273 | loss: 2.6961417
MixupTrain:  epoch  0, batch   274 | loss: 2.2971544
MixupTrain:  epoch  0, batch   275 | loss: 2.6739287
MixupTrain:  epoch  0, batch   276 | loss: 2.2877834
MixupTrain:  epoch  0, batch   277 | loss: 2.6950111
MixupTrain:  epoch  0, batch   278 | loss: 2.4057703
MixupTrain:  epoch  0, batch   279 | loss: 2.1293118
MixupTrain:  epoch  0, batch   280 | loss: 2.5402913
MixupTrain:  epoch  0, batch   282 | loss: 2.6389217
MixupTrain:  epoch  0, batch   283 | loss: 2.5744653
MixupTrain:  epoch  0, batch   284 | loss: 2.4019623
MixupTrain:  epoch  0, batch   285 | loss: 2.4290881
MixupTrain:  epoch  0, batch   286 | loss: 2.4043558
MixupTrain:  epoch  0, batch   287 | loss: 2.1976633
MixupTrain:  epoch  0, batch   288 | loss: 2.7275248
MixupTrain:  epoch  0, batch   289 | loss: 2.3424072
MixupTrain:  epoch  0, batch   290 | loss: 2.5292041
MixupTrain:  epoch  0, batch   291 | loss: 2.4619257
MixupTrain:  epoch  0, batch   292 | loss: 2.3613296
MixupTrain:  epoch  0, batch   294 | loss: 2.4805999
MixupTrain:  epoch  0, batch   295 | loss: 2.6962295
MixupTrain:  epoch  0, batch   296 | loss: 2.4746532
MixupTrain:  epoch  0, batch   297 | loss: 2.5020604
MixupTrain:  epoch  0, batch   299 | loss: 2.1149428
MixupTrain:  epoch  0, batch   300 | loss: 2.3542559
MixupTrain:  epoch  0, batch   301 | loss: 2.2055459
MixupTrain:  epoch  0, batch   303 | loss: 2.5559626
MixupTrain:  epoch  0, batch   304 | loss: 2.2313104
MixupTrain:  epoch  0, batch   306 | loss: 2.7870831
MixupTrain:  epoch  0, batch   307 | loss: 2.8107018
MixupTrain:  epoch  0, batch   308 | loss: 2.4776461
MixupTrain:  epoch  0, batch   309 | loss: 2.0334425
MixupTrain:  epoch  0, batch   310 | loss: 2.5937071
MixupTrain:  epoch  0, batch   311 | loss: 2.2608805
MixupTrain:  epoch  0, batch   312 | loss: 2.4859805
MixupTrain:  epoch  0, batch   313 | loss: 2.1671357
MixupTrain:  epoch  0, batch   314 | loss: 2.3808856
MixupTrain:  epoch  0, batch   315 | loss: 2.2247391
MixupTrain:  epoch  0, batch   316 | loss: 2.3843827
MixupTrain:  epoch  0, batch   317 | loss: 2.2766073
MixupTrain:  epoch  0, batch   318 | loss: 2.6115000
MixupTrain:  epoch  0, batch   321 | loss: 2.4823790
MixupTrain:  epoch  0, batch   323 | loss: 2.4015253
MixupTrain:  epoch  0, batch   324 | loss: 2.4198444
MixupTrain:  epoch  0, batch   325 | loss: 2.4993656
MixupTrain:  epoch  0, batch   327 | loss: 2.5457644
MixupTrain:  epoch  0, batch   328 | loss: 2.6444480
MixupTrain:  epoch  0, batch   329 | loss: 2.7829943
MixupTrain:  epoch  0, batch   331 | loss: 2.5018601
MixupTrain:  epoch  0, batch   333 | loss: 2.4112840
MixupTrain:  epoch  0, batch   334 | loss: 2.4738955
MixupTrain:  epoch  0, batch   335 | loss: 2.3983517
MixupTrain:  epoch  0, batch   339 | loss: 2.3324633
MixupTrain:  epoch  0, batch   341 | loss: 2.2684581
MixupTrain:  epoch  0, batch   343 | loss: 2.5899506
MixupTrain:  epoch  0, batch   344 | loss: 2.4086483
MixupTrain:  epoch  0, batch   345 | loss: 2.2673583
MixupTrain:  epoch  0, batch   346 | loss: 2.2762158
MixupTrain:  epoch  0, batch   347 | loss: 2.3719668
MixupTrain:  epoch  0, batch   348 | loss: 2.4815016
MixupTrain:  epoch  0, batch   349 | loss: 2.3864279
MixupTrain:  epoch  0, batch   350 | loss: 2.3661935
MixupTrain:  epoch  0, batch   351 | loss: 2.2846611
MixupTrain:  epoch  0, batch   352 | loss: 2.3305039
MixupTrain:  epoch  0, batch   353 | loss: 2.4538469
MixupTrain:  epoch  0, batch   354 | loss: 2.5927610
MixupTrain:  epoch  0, batch   355 | loss: 2.3611851
MixupTrain:  epoch  0, batch   357 | loss: 2.4529319
MixupTrain:  epoch  0, batch   359 | loss: 2.6255291
MixupTrain:  epoch  0, batch   360 | loss: 2.3285356
MixupTrain:  epoch  0, batch   361 | loss: 2.3701828
MixupTrain:  epoch  0, batch   362 | loss: 2.4066291
MixupTrain:  epoch  0, batch   363 | loss: 2.2253504
MixupTrain:  epoch  0, batch   364 | loss: 2.3471816
MixupTrain:  epoch  0, batch   365 | loss: 2.4616163
MixupTrain:  epoch  0, batch   366 | loss: 2.3648639
MixupTrain:  epoch  0, batch   368 | loss: 2.3827000
MixupTrain:  epoch  0, batch   370 | loss: 2.4233470
MixupTrain:  epoch  0, batch   371 | loss: 2.3576272
MixupTrain:  epoch  0, batch   372 | loss: 2.2701938
MixupTrain:  epoch  0, batch   373 | loss: 2.4569097
MixupTrain:  epoch  0, batch   375 | loss: 2.4796786
MixupTrain:  epoch  0, batch   377 | loss: 2.2247207
MixupTrain:  epoch  0, batch   379 | loss: 2.5174756
MixupTrain:  epoch  0, batch   380 | loss: 2.2356408
MixupTrain:  epoch  0, batch   381 | loss: 2.2822144
MixupTrain:  epoch  0, batch   383 | loss: 2.4820287
MixupTrain:  epoch  0, batch   384 | loss: 2.4559302
MixupTrain:  epoch  0, batch   385 | loss: 2.1521122
MixupTrain:  epoch  0, batch   386 | loss: 2.3775454
MixupTrain:  epoch  0, batch   387 | loss: 2.2507219
MixupTrain:  epoch  0, batch   388 | loss: 2.2849700
MixupTrain:  epoch  0, batch   389 | loss: 2.3971715
MixupTrain:  epoch  0, batch   390 | loss: 2.3447943
MixupTrain:  epoch  0, batch   391 | loss: 2.3976479
MixupTrain:  epoch  0, batch   392 | loss: 2.4526486
MixupTrain:  epoch  0, batch   394 | loss: 2.3045919
MixupTrain:  epoch  0, batch   396 | loss: 2.2875581
MixupTrain:  epoch  0, batch   397 | loss: 2.5800042
MixupTrain:  epoch  0, batch   398 | loss: 2.2165051
MixupTrain:  epoch  0, batch   400 | loss: 2.4284544
MixupTrain:  epoch  0, batch   401 | loss: 2.3908994
MixupTrain:  epoch  0, batch   402 | loss: 2.5655327
MixupTrain:  epoch  0, batch   403 | loss: 2.4862442
MixupTrain:  epoch  0, batch   404 | loss: 2.2691965
MixupTrain:  epoch  0, batch   405 | loss: 2.3433614
MixupTrain:  epoch  0, batch   406 | loss: 2.0754757
MixupTrain:  epoch  0, batch   407 | loss: 2.3915033
MixupTrain:  epoch  0, batch   408 | loss: 2.4454277
MixupTrain:  epoch  0, batch   409 | loss: 2.5428298
MixupTrain:  epoch  0, batch   410 | loss: 2.1710408
MixupTrain:  epoch  0, batch   411 | loss: 2.3624520
MixupTrain:  epoch  0, batch   415 | loss: 2.3987169
MixupTrain:  epoch  0, batch   417 | loss: 2.2774630
MixupTrain:  epoch  0, batch   418 | loss: 2.2894211
MixupTrain:  epoch  0, batch   419 | loss: 2.4383063
MixupTrain:  epoch  0, batch   420 | loss: 2.4310875
MixupTrain:  epoch  0, batch   421 | loss: 2.4529452
MixupTrain:  epoch  0, batch   422 | loss: 2.2578068
MixupTrain:  epoch  0, batch   423 | loss: 2.6929460
MixupTrain:  epoch  0, batch   424 | loss: 2.4022369
MixupTrain:  epoch  0, batch   425 | loss: 2.1185594
MixupTrain:  epoch  0, batch   426 | loss: 2.9732146
MemoryTrain:  epoch  0, batch     0 | loss: 2.2438583
MemoryTrain:  epoch  0, batch     1 | loss: 2.8356793
MemoryTrain:  epoch  0, batch     2 | loss: 3.7078109
MemoryTrain:  epoch  0, batch     3 | loss: 2.4635932
MemoryTrain:  epoch  0, batch     4 | loss: 2.7773836
MemoryTrain:  epoch  0, batch     5 | loss: 2.1623096
MemoryTrain:  epoch  1, batch     0 | loss: 1.8783205
MemoryTrain:  epoch  1, batch     1 | loss: 1.8750093
MemoryTrain:  epoch  1, batch     2 | loss: 1.9036987
MemoryTrain:  epoch  1, batch     3 | loss: 1.8596320
MemoryTrain:  epoch  1, batch     4 | loss: 1.8728771
MemoryTrain:  epoch  1, batch     5 | loss: 1.8881309
MemoryTrain:  epoch  2, batch     0 | loss: 2.1208534
MemoryTrain:  epoch  2, batch     1 | loss: 1.8876293
MemoryTrain:  epoch  2, batch     2 | loss: 1.8979659
MemoryTrain:  epoch  2, batch     3 | loss: 1.8347981
MemoryTrain:  epoch  2, batch     4 | loss: 1.9027066
MemoryTrain:  epoch  2, batch     5 | loss: 1.9530385
MemoryTrain:  epoch  3, batch     0 | loss: 1.9719013
MemoryTrain:  epoch  3, batch     1 | loss: 1.8710454
MemoryTrain:  epoch  3, batch     2 | loss: 1.8605876
MemoryTrain:  epoch  3, batch     3 | loss: 2.0461078
MemoryTrain:  epoch  3, batch     4 | loss: 1.8385417
MemoryTrain:  epoch  3, batch     5 | loss: 1.9863455
MemoryTrain:  epoch  4, batch     0 | loss: 1.8471866
MemoryTrain:  epoch  4, batch     1 | loss: 1.8304036
MemoryTrain:  epoch  4, batch     2 | loss: 1.8384416
MemoryTrain:  epoch  4, batch     3 | loss: 1.8427272
MemoryTrain:  epoch  4, batch     4 | loss: 1.8437195
MemoryTrain:  epoch  4, batch     5 | loss: 1.8537420
MemoryTrain:  epoch  5, batch     0 | loss: 1.8492993
MemoryTrain:  epoch  5, batch     1 | loss: 1.8475754
MemoryTrain:  epoch  5, batch     2 | loss: 1.8533247
MemoryTrain:  epoch  5, batch     3 | loss: 1.8367422
MemoryTrain:  epoch  5, batch     4 | loss: 1.8444345
MemoryTrain:  epoch  5, batch     5 | loss: 1.8362162
MemoryTrain:  epoch  6, batch     0 | loss: 1.8319604
MemoryTrain:  epoch  6, batch     1 | loss: 1.8412430
MemoryTrain:  epoch  6, batch     2 | loss: 1.8281413
MemoryTrain:  epoch  6, batch     3 | loss: 1.8340729
MemoryTrain:  epoch  6, batch     4 | loss: 1.8470083
MemoryTrain:  epoch  6, batch     5 | loss: 1.8559933
MemoryTrain:  epoch  7, batch     0 | loss: 1.8560902
MemoryTrain:  epoch  7, batch     1 | loss: 1.8395541
MemoryTrain:  epoch  7, batch     2 | loss: 1.8632715
MemoryTrain:  epoch  7, batch     3 | loss: 1.8615971
MemoryTrain:  epoch  7, batch     4 | loss: 1.8483007
MemoryTrain:  epoch  7, batch     5 | loss: 1.8524311
MemoryTrain:  epoch  8, batch     0 | loss: 1.8740958
MemoryTrain:  epoch  8, batch     1 | loss: 1.8433321
MemoryTrain:  epoch  8, batch     2 | loss: 1.8526897
MemoryTrain:  epoch  8, batch     3 | loss: 1.8522274
MemoryTrain:  epoch  8, batch     4 | loss: 1.8473376
MemoryTrain:  epoch  8, batch     5 | loss: 1.8651557
MemoryTrain:  epoch  9, batch     0 | loss: 1.8443135
MemoryTrain:  epoch  9, batch     1 | loss: 1.8527499
MemoryTrain:  epoch  9, batch     2 | loss: 1.8408022
MemoryTrain:  epoch  9, batch     3 | loss: 1.8467603
MemoryTrain:  epoch  9, batch     4 | loss: 1.8613719
MemoryTrain:  epoch  9, batch     5 | loss: 1.8519448
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   
[EVAL] batch:    1 | acc: 93.75%,  total acc: 84.38%   
[EVAL] batch:    2 | acc: 93.75%,  total acc: 87.50%   
[EVAL] batch:    3 | acc: 87.50%,  total acc: 87.50%   
[EVAL] batch:    4 | acc: 62.50%,  total acc: 82.50%   
[EVAL] batch:    5 | acc: 87.50%,  total acc: 83.33%   
[EVAL] batch:    6 | acc: 68.75%,  total acc: 81.25%   
[EVAL] batch:    7 | acc: 12.50%,  total acc: 72.66%   
[EVAL] batch:    0 | acc: 6.25%,  total acc: 6.25%   
[EVAL] batch:    1 | acc: 43.75%,  total acc: 25.00%   
[EVAL] batch:    2 | acc: 25.00%,  total acc: 25.00%   
[EVAL] batch:    3 | acc: 18.75%,  total acc: 23.44%   
[EVAL] batch:    4 | acc: 25.00%,  total acc: 23.75%   
[EVAL] batch:    5 | acc: 31.25%,  total acc: 25.00%   
[EVAL] batch:    6 | acc: 37.50%,  total acc: 26.79%   
[EVAL] batch:    7 | acc: 25.00%,  total acc: 26.56%   
[EVAL] batch:    8 | acc: 37.50%,  total acc: 27.78%   
[EVAL] batch:    9 | acc: 25.00%,  total acc: 27.50%   
[EVAL] batch:   10 | acc: 25.00%,  total acc: 27.27%   
[EVAL] batch:   11 | acc: 37.50%,  total acc: 28.12%   
[EVAL] batch:   12 | acc: 18.75%,  total acc: 27.40%   
[EVAL] batch:   13 | acc: 25.00%,  total acc: 27.23%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 30.42%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 32.03%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 34.56%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 36.11%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 37.50%   
[EVAL] batch:   19 | acc: 87.50%,  total acc: 40.00%   
[EVAL] batch:   20 | acc: 87.50%,  total acc: 42.26%   
[EVAL] batch:   21 | acc: 93.75%,  total acc: 44.60%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 47.01%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 49.22%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 51.25%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 53.12%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 54.63%   
[EVAL] batch:   27 | acc: 93.75%,  total acc: 56.03%   
[EVAL] batch:   28 | acc: 87.50%,  total acc: 57.11%   
[EVAL] batch:   29 | acc: 81.25%,  total acc: 57.92%   
[EVAL] batch:   30 | acc: 87.50%,  total acc: 58.87%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 59.96%   
[EVAL] batch:   32 | acc: 93.75%,  total acc: 60.98%   
[EVAL] batch:   33 | acc: 62.50%,  total acc: 61.03%   
[EVAL] batch:   34 | acc: 50.00%,  total acc: 60.71%   
[EVAL] batch:   35 | acc: 25.00%,  total acc: 59.72%   
[EVAL] batch:   36 | acc: 25.00%,  total acc: 58.78%   
[EVAL] batch:   37 | acc: 43.75%,  total acc: 58.39%   
[EVAL] batch:   38 | acc: 50.00%,  total acc: 58.17%   
[EVAL] batch:   39 | acc: 75.00%,  total acc: 58.59%   
[EVAL] batch:   40 | acc: 87.50%,  total acc: 59.30%   
[EVAL] batch:   41 | acc: 75.00%,  total acc: 59.67%   
[EVAL] batch:   42 | acc: 81.25%,  total acc: 60.17%   
[EVAL] batch:   43 | acc: 75.00%,  total acc: 60.51%   
[EVAL] batch:   44 | acc: 93.75%,  total acc: 61.25%   
[EVAL] batch:   45 | acc: 31.25%,  total acc: 60.60%   
[EVAL] batch:   46 | acc: 68.75%,  total acc: 60.77%   
[EVAL] batch:   47 | acc: 93.75%,  total acc: 61.46%   
[EVAL] batch:   48 | acc: 93.75%,  total acc: 62.12%   
[EVAL] batch:   49 | acc: 87.50%,  total acc: 62.62%   
[EVAL] batch:   50 | acc: 62.50%,  total acc: 62.62%   
[EVAL] batch:   51 | acc: 87.50%,  total acc: 63.10%   
[EVAL] batch:   52 | acc: 68.75%,  total acc: 63.21%   
[EVAL] batch:   53 | acc: 18.75%,  total acc: 62.38%   
cur_acc:  ['0.8712', '0.8705', '0.7266']
his_acc:  ['0.8712', '0.8564', '0.6238']
CurrentTrain: epoch  0, batch     0 | loss: 5.0672054
CurrentTrain: epoch  0, batch     1 | loss: 5.2987919
CurrentTrain: epoch  1, batch     0 | loss: 3.9338913
CurrentTrain: epoch  1, batch     1 | loss: 3.8854244
CurrentTrain: epoch  2, batch     0 | loss: 4.3608122
CurrentTrain: epoch  2, batch     1 | loss: 3.4314547
CurrentTrain: epoch  3, batch     0 | loss: 3.4617128
CurrentTrain: epoch  3, batch     1 | loss: 2.8655903
CurrentTrain: epoch  4, batch     0 | loss: 2.9642444
CurrentTrain: epoch  4, batch     1 | loss: 2.1780236
CurrentTrain: epoch  5, batch     0 | loss: 2.5164456
CurrentTrain: epoch  5, batch     1 | loss: 2.2829857
CurrentTrain: epoch  6, batch     0 | loss: 2.2620263
CurrentTrain: epoch  6, batch     1 | loss: 2.2625396
CurrentTrain: epoch  7, batch     0 | loss: 2.2116761
CurrentTrain: epoch  7, batch     1 | loss: 2.2249637
CurrentTrain: epoch  8, batch     0 | loss: 2.2550759
CurrentTrain: epoch  8, batch     1 | loss: 1.8943950
CurrentTrain: epoch  9, batch     0 | loss: 2.0596433
CurrentTrain: epoch  9, batch     1 | loss: 2.1745403
#### person cause of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person cause of death" means a person was died of an event.
Here is an example:
Relation: person cause of death
Context: mr scheider had suffered from multiple myeloma for several years , and died of complications from a staph infection , his wife , brenda siemer , said .
Head Entity: mr scheider
Tail Entity: complications from a staph infection
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person cause of death":
Relation: person cause of death  
Context: after battling lung cancer for over a year, john doe passed away peacefully in his sleep, surrounded by family.  
Head Entity: john doe  
Tail Entity: lung cancer  

Relation: person cause of death  
Context: the renowned author, jane smith, tragically lost her life due to a car accident while returning from a book signing event.  
Head Entity: jane smith  
Tail Entity: car accident  

Relation: person cause of death  
Context: following a long struggle with heart disease, mr. thompson succumbed to his illness last night at the hospital.  
Head Entity: mr. thompson  
Tail Entity: heart disease  

Relation: person cause of death  
Context: the community mourned the loss of officer jones, who was killed in the line of duty during a robbery attempt.  
Head Entity: officer jones  
Tail Entity: robbery attempt  

Relation: person cause of death  
Context: after a courageous fight against diabetes complications, mrs. wilson passed away, leaving behind a legacy of kindness.  
Head Entity: mrs. wilson  
Tail Entity: diabetes complications  
#### organization political religious affiliation ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization political religious affiliation" means an organization is the member of a religion.
Here is an example:
Relation: organization political religious affiliation
Context: the militia has also suffered from allegations of being involved in clashes with rival shiite militias , particularly the badr corp , the military wing linked to supreme iraqi islamic council , the party led by powerful politician abdel aziz al-hakim .
Head Entity: badr corp
Tail Entity: shiite
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization political religious affiliation":
Relation: organization political religious affiliation  
Context: The Christian Democratic Union has been a significant player in German politics, often aligning itself with various religious groups to promote its agenda.  
Head Entity: Christian Democratic Union  
Tail Entity: Christian  

Relation: organization political religious affiliation  
Context: The Islamic Society of North America has been actively involved in political advocacy, representing the interests of the Muslim community in the United States.  
Head Entity: Islamic Society of North America  
Tail Entity: Muslim  

Relation: organization political religious affiliation  
Context: The National Council of Churches has worked closely with various denominations to influence social policy and promote interfaith dialogue.  
Head Entity: National Council of Churches  
Tail Entity: Christian  

Relation: organization political religious affiliation  
Context: The Jewish Federation has been instrumental in lobbying for policies that support the Jewish community and its values in the political arena.  
Head Entity: Jewish Federation  
Tail Entity: Jewish  

Relation: organization political religious affiliation  
Context: The Hindu American Foundation has been advocating for the rights and recognition of Hindus in the political landscape of the United States.  
Head Entity: Hindu American Foundation  
Tail Entity: Hindu  
#### organization stateorprovince of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization stateorprovince of headquarters" means an organization is located in a state or province.
Here is an example:
Relation: organization stateorprovince of headquarters
Context: washington , nov 30 -lrb- xinhua -rrb- -- nasa has skipped space shuttle endeavour 's second landing opportunity at kennedy space center in florida on sunday afternoon due to bad weather , according to nasa tv .
Head Entity: kennedy space center
Tail Entity: florida
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization stateorprovince of headquarters":
Relation: organization stateorprovince of headquarters  
Context: the headquarters of the multinational technology company is located in cupertino, california, where it has been a significant player in the tech industry for decades.  
Head Entity: multinational technology company  
Tail Entity: california  

Relation: organization stateorprovince of headquarters  
Context: after years of expansion, the non-profit organization has established its main office in a historic building in downtown boston, massachusetts.  
Head Entity: non-profit organization  
Tail Entity: massachusetts  

Relation: organization stateorprovince of headquarters  
Context: the famous coffee chain has its corporate headquarters situated in seattle, washington, which is known for its vibrant coffee culture.  
Head Entity: coffee chain  
Tail Entity: washington  

Relation: organization stateorprovince of headquarters  
Context: the global automotive manufacturer announced that its new headquarters will be based in detroit, michigan, a city renowned for its automotive history.  
Head Entity: global automotive manufacturer  
Tail Entity: michigan  

Relation: organization stateorprovince of headquarters  
Context: the international humanitarian organization operates from its main office in geneva, switzerland, coordinating relief efforts worldwide.  
Head Entity: international humanitarian organization  
Tail Entity: switzerland  
#### person other family ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person other family" means a person 's relative is a person.
Here is an example:
Relation: person other family
Context: parren mitchell 's sister-in-law , juanita jackson mitchell , was the long - time head and legal counsel of the maryland naacp .
Head Entity: parren mitchell
Tail Entity: juanita jackson mitchell
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person other family":
Relation: person other family  
Context: The famous actor, Tom Hanks, has a brother named Jim Hanks who is also involved in the film industry.  
Head Entity: Tom Hanks  
Tail Entity: Jim Hanks  

Relation: person other family  
Context: During the family reunion, Sarah introduced her cousin, Emily, who had just returned from studying abroad.  
Head Entity: Sarah  
Tail Entity: Emily  

Relation: person other family  
Context: In her memoir, Michelle Obama writes fondly about her father, Fraser Robinson III, who was a significant influence in her life.  
Head Entity: Michelle Obama  
Tail Entity: Fraser Robinson III  

Relation: person other family  
Context: At the wedding, John was thrilled to see his sister, Lisa, who had traveled from overseas to attend the ceremony.  
Head Entity: John  
Tail Entity: Lisa  

Relation: person other family  
Context: The renowned scientist, Albert Einstein, had a close relationship with his cousin, Elsa Einstein, who later became his wife.  
Head Entity: Albert Einstein  
Tail Entity: Elsa Einstein  
#### person city of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person city of death" means a person was died in a city.
Here is an example:
Relation: person city of death
Context: irene morgan kirkaldy , 90 , who died of alzheimer 's disease aug. 10 at her home in gloucester , va. , quietly changed history in 1944 when she refused to give up her seat on a crowded greyhound bus to a white couple .
Head Entity: her
Tail Entity: gloucester
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person city of death":
Relation: person city of death  
Context: john smith, a renowned author, passed away on march 5 in his apartment located in new york city, leaving behind a legacy of literary works that inspired many.  
Head Entity: john smith  
Tail Entity: new york city  

Relation: person city of death  
Context: after a long battle with cancer, elizabeth taylor died on march 23 at a hospital in los angeles, where she had spent her final days surrounded by family and friends.  
Head Entity: elizabeth taylor  
Tail Entity: los angeles  

Relation: person city of death  
Context: the famous physicist, albert einstein, died on april 18, 1955, in princeton, new jersey, where he had lived for many years while working at the institute for advanced study.  
Head Entity: albert einstein  
Tail Entity: princeton  

Relation: person city of death  
Context: on january 1, 2020, the beloved actor, kobe bryant, tragically lost his life in a helicopter crash in calabasas, california, shocking fans around the world.  
Head Entity: kobe bryant  
Tail Entity: calabasas  

Relation: person city of death  
Context: the legendary musician, freddie mercury, passed away on november 24, 1991, at his home in london, england, leaving a profound impact on the music industry.  
Head Entity: freddie mercury  
Tail Entity: london  
Mixup data size:  10810
MixupTrain:  epoch  0, batch     0 | loss: 4.3467636
MixupTrain:  epoch  0, batch     1 | loss: 4.6713386
MixupTrain:  epoch  0, batch     2 | loss: 3.6714940
MixupTrain:  epoch  0, batch     3 | loss: 3.7807279
MixupTrain:  epoch  0, batch     4 | loss: 3.8363504
MixupTrain:  epoch  0, batch     5 | loss: 4.2852616
MixupTrain:  epoch  0, batch     6 | loss: 3.6167021
MixupTrain:  epoch  0, batch     7 | loss: 3.4886043
MixupTrain:  epoch  0, batch     8 | loss: 3.9617791
MixupTrain:  epoch  0, batch     9 | loss: 3.0393159
MixupTrain:  epoch  0, batch    10 | loss: 3.5015831
MixupTrain:  epoch  0, batch    11 | loss: 3.8110495
MixupTrain:  epoch  0, batch    12 | loss: 3.4804473
MixupTrain:  epoch  0, batch    13 | loss: 3.1154540
MixupTrain:  epoch  0, batch    14 | loss: 3.5360117
MixupTrain:  epoch  0, batch    15 | loss: 3.3492658
MixupTrain:  epoch  0, batch    16 | loss: 3.3431954
MixupTrain:  epoch  0, batch    17 | loss: 3.2179048
MixupTrain:  epoch  0, batch    18 | loss: 3.1961358
MixupTrain:  epoch  0, batch    19 | loss: 3.2060733
MixupTrain:  epoch  0, batch    20 | loss: 3.0085063
MixupTrain:  epoch  0, batch    21 | loss: 3.0240703
MixupTrain:  epoch  0, batch    22 | loss: 2.8792620
MixupTrain:  epoch  0, batch    23 | loss: 3.1585050
MixupTrain:  epoch  0, batch    24 | loss: 2.7197104
MixupTrain:  epoch  0, batch    25 | loss: 2.6874766
MixupTrain:  epoch  0, batch    26 | loss: 2.9385102
MixupTrain:  epoch  0, batch    27 | loss: 3.1305676
MixupTrain:  epoch  0, batch    28 | loss: 3.0908706
MixupTrain:  epoch  0, batch    29 | loss: 2.5317092
MixupTrain:  epoch  0, batch    30 | loss: 2.8863490
MixupTrain:  epoch  0, batch    31 | loss: 2.7295351
MixupTrain:  epoch  0, batch    32 | loss: 2.8268890
MixupTrain:  epoch  0, batch    33 | loss: 3.2360444
MixupTrain:  epoch  0, batch    34 | loss: 2.3179035
MixupTrain:  epoch  0, batch    35 | loss: 2.7095952
MixupTrain:  epoch  0, batch    36 | loss: 2.4164243
MixupTrain:  epoch  0, batch    37 | loss: 2.6885705
MixupTrain:  epoch  0, batch    38 | loss: 2.7372310
MixupTrain:  epoch  0, batch    39 | loss: 2.9902959
MixupTrain:  epoch  0, batch    40 | loss: 2.7021143
MixupTrain:  epoch  0, batch    41 | loss: 2.5118704
MixupTrain:  epoch  0, batch    42 | loss: 2.7683575
MixupTrain:  epoch  0, batch    43 | loss: 2.5293546
MixupTrain:  epoch  0, batch    44 | loss: 2.4193184
MixupTrain:  epoch  0, batch    45 | loss: 2.7675083
MixupTrain:  epoch  0, batch    46 | loss: 2.6521077
MixupTrain:  epoch  0, batch    47 | loss: 2.7725749
MixupTrain:  epoch  0, batch    48 | loss: 2.4972429
MixupTrain:  epoch  0, batch    49 | loss: 2.3704648
MixupTrain:  epoch  0, batch    50 | loss: 2.8229275
MixupTrain:  epoch  0, batch    51 | loss: 2.7802591
MixupTrain:  epoch  0, batch    52 | loss: 2.4281406
MixupTrain:  epoch  0, batch    53 | loss: 2.1518795
MixupTrain:  epoch  0, batch    54 | loss: 2.5197282
MixupTrain:  epoch  0, batch    55 | loss: 2.3993776
MixupTrain:  epoch  0, batch    56 | loss: 2.5654364
MixupTrain:  epoch  0, batch    57 | loss: 2.7866163
MixupTrain:  epoch  0, batch    58 | loss: 2.5953317
MixupTrain:  epoch  0, batch    59 | loss: 2.7215662
MixupTrain:  epoch  0, batch    60 | loss: 2.8137889
MixupTrain:  epoch  0, batch    61 | loss: 2.6709023
MixupTrain:  epoch  0, batch    62 | loss: 2.3760972
MixupTrain:  epoch  0, batch    63 | loss: 2.6374099
MixupTrain:  epoch  0, batch    64 | loss: 2.6744697
MixupTrain:  epoch  0, batch    65 | loss: 2.5424166
MixupTrain:  epoch  0, batch    66 | loss: 2.2668047
MixupTrain:  epoch  0, batch    67 | loss: 2.4736152
MixupTrain:  epoch  0, batch    68 | loss: 2.3795094
MixupTrain:  epoch  0, batch    69 | loss: 2.4977713
MixupTrain:  epoch  0, batch    70 | loss: 2.4355309
MixupTrain:  epoch  0, batch    71 | loss: 2.4272881
MixupTrain:  epoch  0, batch    72 | loss: 2.3257194
MixupTrain:  epoch  0, batch    73 | loss: 2.4845209
MixupTrain:  epoch  0, batch    74 | loss: 2.2300861
MixupTrain:  epoch  0, batch    75 | loss: 2.4310455
MixupTrain:  epoch  0, batch    76 | loss: 2.5372577
MixupTrain:  epoch  0, batch    77 | loss: 2.4392557
MixupTrain:  epoch  0, batch    78 | loss: 2.0521657
MixupTrain:  epoch  0, batch    79 | loss: 2.2525511
MixupTrain:  epoch  0, batch    80 | loss: 2.5703249
MixupTrain:  epoch  0, batch    81 | loss: 2.4061804
MixupTrain:  epoch  0, batch    82 | loss: 2.1423564
MixupTrain:  epoch  0, batch    83 | loss: 2.1004157
MixupTrain:  epoch  0, batch    84 | loss: 2.3698468
MixupTrain:  epoch  0, batch    85 | loss: 2.4583771
MixupTrain:  epoch  0, batch    86 | loss: 2.3478231
MixupTrain:  epoch  0, batch    87 | loss: 2.3938105
MixupTrain:  epoch  0, batch    88 | loss: 2.2762926
MixupTrain:  epoch  0, batch    89 | loss: 2.3103218
MixupTrain:  epoch  0, batch    90 | loss: 2.3411069
MixupTrain:  epoch  0, batch    91 | loss: 2.2846937
MixupTrain:  epoch  0, batch    92 | loss: 2.4568257
MixupTrain:  epoch  0, batch    93 | loss: 2.1635516
MixupTrain:  epoch  0, batch    94 | loss: 2.1827888
MixupTrain:  epoch  0, batch    95 | loss: 2.2786205
MixupTrain:  epoch  0, batch    96 | loss: 2.5066762
MixupTrain:  epoch  0, batch    97 | loss: 2.2964027
MixupTrain:  epoch  0, batch    98 | loss: 2.2044375
MixupTrain:  epoch  0, batch    99 | loss: 2.3084288
MixupTrain:  epoch  0, batch   100 | loss: 2.3315539
MixupTrain:  epoch  0, batch   101 | loss: 2.2061808
MixupTrain:  epoch  0, batch   102 | loss: 2.2775924
MixupTrain:  epoch  0, batch   103 | loss: 2.3157644
MixupTrain:  epoch  0, batch   104 | loss: 2.2696261
MixupTrain:  epoch  0, batch   105 | loss: 2.1306415
MixupTrain:  epoch  0, batch   106 | loss: 2.4184504
MixupTrain:  epoch  0, batch   107 | loss: 2.1741660
MixupTrain:  epoch  0, batch   108 | loss: 2.0553291
MixupTrain:  epoch  0, batch   109 | loss: 2.4029429
MixupTrain:  epoch  0, batch   110 | loss: 2.2280200
MixupTrain:  epoch  0, batch   111 | loss: 2.3904977
MixupTrain:  epoch  0, batch   112 | loss: 2.3107665
MixupTrain:  epoch  0, batch   113 | loss: 2.1532724
MixupTrain:  epoch  0, batch   114 | loss: 2.2511296
MixupTrain:  epoch  0, batch   115 | loss: 2.1766777
MixupTrain:  epoch  0, batch   116 | loss: 2.0725155
MixupTrain:  epoch  0, batch   117 | loss: 2.1881490
MixupTrain:  epoch  0, batch   118 | loss: 2.2098107
MixupTrain:  epoch  0, batch   119 | loss: 2.1506083
MixupTrain:  epoch  0, batch   120 | loss: 2.1417904
MixupTrain:  epoch  0, batch   121 | loss: 2.2191913
MixupTrain:  epoch  0, batch   122 | loss: 2.0976403
MixupTrain:  epoch  0, batch   123 | loss: 2.2255278
MixupTrain:  epoch  0, batch   124 | loss: 2.2645648
MixupTrain:  epoch  0, batch   125 | loss: 2.2027884
MixupTrain:  epoch  0, batch   126 | loss: 2.1561241
MixupTrain:  epoch  0, batch   127 | loss: 1.9979894
MixupTrain:  epoch  0, batch   128 | loss: 2.1299911
MixupTrain:  epoch  0, batch   129 | loss: 2.0778890
MixupTrain:  epoch  0, batch   130 | loss: 2.1717126
MixupTrain:  epoch  0, batch   131 | loss: 1.9991508
MixupTrain:  epoch  0, batch   132 | loss: 2.2170897
MixupTrain:  epoch  0, batch   133 | loss: 2.1162076
MixupTrain:  epoch  0, batch   134 | loss: 2.0770736
MixupTrain:  epoch  0, batch   135 | loss: 2.1507218
MixupTrain:  epoch  0, batch   136 | loss: 2.2399030
MixupTrain:  epoch  0, batch   137 | loss: 2.2107975
MixupTrain:  epoch  0, batch   138 | loss: 2.1898799
MixupTrain:  epoch  0, batch   139 | loss: 2.1552322
MixupTrain:  epoch  0, batch   140 | loss: 2.1822343
MixupTrain:  epoch  0, batch   141 | loss: 2.0485392
MixupTrain:  epoch  0, batch   142 | loss: 2.1631510
MixupTrain:  epoch  0, batch   143 | loss: 2.2121406
MixupTrain:  epoch  0, batch   144 | loss: 2.1013975
MixupTrain:  epoch  0, batch   145 | loss: 2.1063600
MixupTrain:  epoch  0, batch   146 | loss: 2.0657001
MixupTrain:  epoch  0, batch   147 | loss: 2.0694199
MixupTrain:  epoch  0, batch   148 | loss: 2.2024860
MixupTrain:  epoch  0, batch   149 | loss: 2.0858226
MixupTrain:  epoch  0, batch   150 | loss: 2.0828171
MixupTrain:  epoch  0, batch   151 | loss: 1.9770782
MixupTrain:  epoch  0, batch   152 | loss: 2.3720636
MixupTrain:  epoch  0, batch   153 | loss: 2.1707025
MixupTrain:  epoch  0, batch   154 | loss: 2.1924515
MixupTrain:  epoch  0, batch   155 | loss: 2.1071420
MixupTrain:  epoch  0, batch   156 | loss: 2.0712252
MixupTrain:  epoch  0, batch   157 | loss: 2.1528096
MixupTrain:  epoch  0, batch   158 | loss: 2.1650951
MixupTrain:  epoch  0, batch   159 | loss: 2.0529561
MixupTrain:  epoch  0, batch   160 | loss: 2.4406724
MixupTrain:  epoch  0, batch   161 | loss: 2.2412906
MixupTrain:  epoch  0, batch   162 | loss: 2.2244885
MixupTrain:  epoch  0, batch   163 | loss: 2.1189985
MixupTrain:  epoch  0, batch   164 | loss: 2.2488403
MixupTrain:  epoch  0, batch   165 | loss: 2.1490078
MixupTrain:  epoch  0, batch   166 | loss: 2.2707138
MixupTrain:  epoch  0, batch   167 | loss: 2.1931820
MixupTrain:  epoch  0, batch   168 | loss: 2.1695104
MixupTrain:  epoch  0, batch   169 | loss: 1.9790077
MixupTrain:  epoch  0, batch   170 | loss: 2.0525994
MixupTrain:  epoch  0, batch   171 | loss: 2.1442938
MixupTrain:  epoch  0, batch   172 | loss: 2.1377411
MixupTrain:  epoch  0, batch   173 | loss: 2.1399713
MixupTrain:  epoch  0, batch   174 | loss: 2.0522823
MixupTrain:  epoch  0, batch   175 | loss: 2.0478828
MixupTrain:  epoch  0, batch   176 | loss: 2.1101418
MixupTrain:  epoch  0, batch   177 | loss: 2.1413515
MixupTrain:  epoch  0, batch   178 | loss: 2.1816783
MixupTrain:  epoch  0, batch   179 | loss: 2.0617428
MixupTrain:  epoch  0, batch   180 | loss: 2.2000871
MixupTrain:  epoch  0, batch   181 | loss: 2.0631280
MixupTrain:  epoch  0, batch   182 | loss: 2.2252893
MixupTrain:  epoch  0, batch   183 | loss: 2.2440093
MixupTrain:  epoch  0, batch   184 | loss: 2.0937526
MixupTrain:  epoch  0, batch   185 | loss: 2.2163296
MixupTrain:  epoch  0, batch   186 | loss: 2.1057580
MixupTrain:  epoch  0, batch   187 | loss: 2.2231665
MixupTrain:  epoch  0, batch   188 | loss: 2.2593966
MixupTrain:  epoch  0, batch   189 | loss: 2.1284833
MixupTrain:  epoch  0, batch   190 | loss: 2.0962114
MixupTrain:  epoch  0, batch   191 | loss: 2.0497675
MixupTrain:  epoch  0, batch   192 | loss: 2.0312691
MixupTrain:  epoch  0, batch   193 | loss: 2.0808496
MixupTrain:  epoch  0, batch   194 | loss: 1.9930149
MixupTrain:  epoch  0, batch   195 | loss: 2.0693488
MixupTrain:  epoch  0, batch   196 | loss: 2.0101199
MixupTrain:  epoch  0, batch   197 | loss: 2.2075334
MixupTrain:  epoch  0, batch   198 | loss: 1.9987637
MixupTrain:  epoch  0, batch   199 | loss: 2.1581154
MixupTrain:  epoch  0, batch   200 | loss: 2.1868205
MixupTrain:  epoch  0, batch   201 | loss: 2.1092806
MixupTrain:  epoch  0, batch   202 | loss: 2.1185684
MixupTrain:  epoch  0, batch   203 | loss: 2.2320900
MixupTrain:  epoch  0, batch   204 | loss: 2.2322400
MixupTrain:  epoch  0, batch   205 | loss: 2.0704725
MixupTrain:  epoch  0, batch   206 | loss: 2.2541966
MixupTrain:  epoch  0, batch   207 | loss: 2.0463052
MixupTrain:  epoch  0, batch   208 | loss: 2.0373034
MixupTrain:  epoch  0, batch   209 | loss: 2.2501798
MixupTrain:  epoch  0, batch   210 | loss: 2.0834208
MixupTrain:  epoch  0, batch   211 | loss: 2.0595956
MixupTrain:  epoch  0, batch   212 | loss: 2.0821612
MixupTrain:  epoch  0, batch   213 | loss: 2.0321698
MixupTrain:  epoch  0, batch   214 | loss: 2.0764384
MixupTrain:  epoch  0, batch   215 | loss: 2.1553612
MixupTrain:  epoch  0, batch   216 | loss: 2.0552318
MixupTrain:  epoch  0, batch   217 | loss: 2.0966029
MixupTrain:  epoch  0, batch   218 | loss: 2.1576681
MixupTrain:  epoch  0, batch   219 | loss: 2.0614920
MixupTrain:  epoch  0, batch   220 | loss: 1.9753141
MixupTrain:  epoch  0, batch   221 | loss: 2.1301429
MixupTrain:  epoch  0, batch   222 | loss: 2.1778355
MixupTrain:  epoch  0, batch   223 | loss: 2.1650419
MixupTrain:  epoch  0, batch   224 | loss: 2.1349611
MixupTrain:  epoch  0, batch   225 | loss: 2.1163330
MixupTrain:  epoch  0, batch   226 | loss: 2.0427938
MixupTrain:  epoch  0, batch   227 | loss: 1.9882078
MixupTrain:  epoch  0, batch   228 | loss: 2.1084859
MixupTrain:  epoch  0, batch   229 | loss: 2.1575077
MixupTrain:  epoch  0, batch   230 | loss: 2.2134190
MixupTrain:  epoch  0, batch   231 | loss: 2.2090049
MixupTrain:  epoch  0, batch   232 | loss: 2.0363910
MixupTrain:  epoch  0, batch   233 | loss: 2.0802872
MixupTrain:  epoch  0, batch   234 | loss: 2.0710249
MixupTrain:  epoch  0, batch   235 | loss: 2.1211171
MixupTrain:  epoch  0, batch   236 | loss: 2.1821904
MixupTrain:  epoch  0, batch   237 | loss: 2.1218977
MixupTrain:  epoch  0, batch   238 | loss: 2.1354740
MixupTrain:  epoch  0, batch   239 | loss: 2.0287199
MixupTrain:  epoch  0, batch   240 | loss: 2.0420098
MixupTrain:  epoch  0, batch   241 | loss: 2.0667830
MixupTrain:  epoch  0, batch   242 | loss: 2.1282017
MixupTrain:  epoch  0, batch   243 | loss: 2.0944307
MixupTrain:  epoch  0, batch   244 | loss: 2.1905797
MixupTrain:  epoch  0, batch   245 | loss: 2.0534520
MixupTrain:  epoch  0, batch   246 | loss: 2.2066693
MixupTrain:  epoch  0, batch   247 | loss: 2.0928006
MixupTrain:  epoch  0, batch   248 | loss: 2.1943493
MixupTrain:  epoch  0, batch   249 | loss: 2.1048231
MixupTrain:  epoch  0, batch   250 | loss: 1.9883561
MixupTrain:  epoch  0, batch   251 | loss: 2.0240586
MixupTrain:  epoch  0, batch   252 | loss: 2.2147403
MixupTrain:  epoch  0, batch   253 | loss: 2.0972877
MixupTrain:  epoch  0, batch   254 | loss: 2.1484005
MixupTrain:  epoch  0, batch   255 | loss: 1.9823725
MixupTrain:  epoch  0, batch   256 | loss: 1.8959179
MixupTrain:  epoch  0, batch   257 | loss: 2.1725850
MixupTrain:  epoch  0, batch   258 | loss: 2.0520475
MixupTrain:  epoch  0, batch   259 | loss: 1.9730608
MixupTrain:  epoch  0, batch   260 | loss: 2.0907066
MixupTrain:  epoch  0, batch   261 | loss: 2.0782285
MixupTrain:  epoch  0, batch   262 | loss: 2.1256826
MixupTrain:  epoch  0, batch   263 | loss: 2.1302042
MixupTrain:  epoch  0, batch   264 | loss: 2.0772357
MixupTrain:  epoch  0, batch   265 | loss: 2.0515027
MixupTrain:  epoch  0, batch   266 | loss: 2.1073160
MixupTrain:  epoch  0, batch   267 | loss: 2.0674222
MixupTrain:  epoch  0, batch   268 | loss: 2.0662165
MixupTrain:  epoch  0, batch   269 | loss: 2.0091066
MixupTrain:  epoch  0, batch   270 | loss: 1.9880322
MixupTrain:  epoch  0, batch   271 | loss: 2.0986686
MixupTrain:  epoch  0, batch   272 | loss: 2.1672764
MixupTrain:  epoch  0, batch   273 | loss: 2.0345280
MixupTrain:  epoch  0, batch   274 | loss: 1.9724351
MixupTrain:  epoch  0, batch   275 | loss: 1.9996738
MixupTrain:  epoch  0, batch   276 | loss: 2.2416439
MixupTrain:  epoch  0, batch   277 | loss: 1.9592361
MixupTrain:  epoch  0, batch   278 | loss: 2.0915515
MixupTrain:  epoch  0, batch   279 | loss: 2.0423326
MixupTrain:  epoch  0, batch   280 | loss: 2.1030948
MixupTrain:  epoch  0, batch   281 | loss: 2.0346665
MixupTrain:  epoch  0, batch   282 | loss: 2.1024904
MixupTrain:  epoch  0, batch   283 | loss: 1.9924688
MixupTrain:  epoch  0, batch   284 | loss: 2.1124933
MixupTrain:  epoch  0, batch   285 | loss: 1.9951339
MixupTrain:  epoch  0, batch   286 | loss: 2.0575595
MixupTrain:  epoch  0, batch   287 | loss: 2.1493039
MixupTrain:  epoch  0, batch   288 | loss: 2.1082311
MixupTrain:  epoch  0, batch   289 | loss: 2.1121659
MixupTrain:  epoch  0, batch   290 | loss: 2.0348742
MixupTrain:  epoch  0, batch   291 | loss: 2.0159245
MixupTrain:  epoch  0, batch   292 | loss: 2.0425038
MixupTrain:  epoch  0, batch   293 | loss: 2.0820847
MixupTrain:  epoch  0, batch   294 | loss: 2.0195897
MixupTrain:  epoch  0, batch   295 | loss: 2.0719309
MixupTrain:  epoch  0, batch   296 | loss: 2.0695028
MixupTrain:  epoch  0, batch   297 | loss: 2.0507569
MixupTrain:  epoch  0, batch   298 | loss: 2.1048322
MixupTrain:  epoch  0, batch   299 | loss: 2.1421993
MixupTrain:  epoch  0, batch   300 | loss: 2.0446219
MixupTrain:  epoch  0, batch   301 | loss: 2.0572562
MixupTrain:  epoch  0, batch   302 | loss: 2.0562530
MixupTrain:  epoch  0, batch   303 | loss: 2.1344047
MixupTrain:  epoch  0, batch   304 | loss: 2.0273838
MixupTrain:  epoch  0, batch   305 | loss: 2.1652453
MixupTrain:  epoch  0, batch   306 | loss: 1.9066497
MixupTrain:  epoch  0, batch   307 | loss: 2.1856856
MixupTrain:  epoch  0, batch   308 | loss: 2.0163236
MixupTrain:  epoch  0, batch   309 | loss: 2.0533478
MixupTrain:  epoch  0, batch   310 | loss: 2.1260989
MixupTrain:  epoch  0, batch   311 | loss: 2.0627553
MixupTrain:  epoch  0, batch   312 | loss: 2.0893598
MixupTrain:  epoch  0, batch   313 | loss: 2.2118423
MixupTrain:  epoch  0, batch   314 | loss: 2.0268502
MixupTrain:  epoch  0, batch   315 | loss: 2.1336794
MixupTrain:  epoch  0, batch   316 | loss: 2.1439219
MixupTrain:  epoch  0, batch   317 | loss: 2.1622396
MixupTrain:  epoch  0, batch   318 | loss: 2.0402131
MixupTrain:  epoch  0, batch   319 | loss: 2.1654451
MixupTrain:  epoch  0, batch   320 | loss: 2.0305290
MixupTrain:  epoch  0, batch   321 | loss: 2.0345216
MixupTrain:  epoch  0, batch   322 | loss: 2.1466637
MixupTrain:  epoch  0, batch   323 | loss: 1.9647833
MixupTrain:  epoch  0, batch   324 | loss: 2.2085099
MixupTrain:  epoch  0, batch   325 | loss: 2.0876567
MixupTrain:  epoch  0, batch   326 | loss: 2.0364647
MixupTrain:  epoch  0, batch   327 | loss: 2.0905418
MixupTrain:  epoch  0, batch   328 | loss: 1.9916879
MixupTrain:  epoch  0, batch   329 | loss: 1.9470301
MixupTrain:  epoch  0, batch   330 | loss: 2.0423918
MixupTrain:  epoch  0, batch   331 | loss: 2.0038352
MixupTrain:  epoch  0, batch   332 | loss: 1.9845060
MixupTrain:  epoch  0, batch   333 | loss: 2.0923743
MixupTrain:  epoch  0, batch   334 | loss: 2.1702948
MixupTrain:  epoch  0, batch   335 | loss: 2.0875769
MixupTrain:  epoch  0, batch   336 | loss: 2.1322293
MixupTrain:  epoch  0, batch   337 | loss: 2.0275025
MixupTrain:  epoch  0, batch   338 | loss: 2.0420108
MixupTrain:  epoch  0, batch   339 | loss: 2.1120534
MixupTrain:  epoch  0, batch   340 | loss: 1.9661644
MixupTrain:  epoch  0, batch   341 | loss: 2.0397158
MixupTrain:  epoch  0, batch   342 | loss: 2.1111033
MixupTrain:  epoch  0, batch   343 | loss: 1.9872724
MixupTrain:  epoch  0, batch   344 | loss: 1.9558079
MixupTrain:  epoch  0, batch   345 | loss: 2.1340809
MixupTrain:  epoch  0, batch   346 | loss: 2.0778532
MixupTrain:  epoch  0, batch   347 | loss: 2.0118289
MixupTrain:  epoch  0, batch   348 | loss: 2.0967638
MixupTrain:  epoch  0, batch   349 | loss: 2.0732236
MixupTrain:  epoch  0, batch   350 | loss: 2.0479016
MixupTrain:  epoch  0, batch   351 | loss: 2.0261710
MixupTrain:  epoch  0, batch   352 | loss: 2.1836283
MixupTrain:  epoch  0, batch   353 | loss: 1.9261322
MixupTrain:  epoch  0, batch   354 | loss: 1.9898591
MixupTrain:  epoch  0, batch   355 | loss: 1.9466610
MixupTrain:  epoch  0, batch   356 | loss: 2.0947974
MixupTrain:  epoch  0, batch   357 | loss: 2.1656561
MixupTrain:  epoch  0, batch   358 | loss: 2.1031947
MixupTrain:  epoch  0, batch   359 | loss: 2.0019813
MixupTrain:  epoch  0, batch   360 | loss: 2.0160649
MixupTrain:  epoch  0, batch   361 | loss: 2.0944939
MixupTrain:  epoch  0, batch   362 | loss: 1.9832555
MixupTrain:  epoch  0, batch   363 | loss: 2.1550348
MixupTrain:  epoch  0, batch   364 | loss: 1.9883908
MixupTrain:  epoch  0, batch   365 | loss: 2.0882063
MixupTrain:  epoch  0, batch   366 | loss: 2.0565534
MixupTrain:  epoch  0, batch   367 | loss: 2.0392618
MixupTrain:  epoch  0, batch   368 | loss: 2.0851812
MixupTrain:  epoch  0, batch   369 | loss: 2.0600982
MixupTrain:  epoch  0, batch   370 | loss: 1.9647149
MixupTrain:  epoch  0, batch   371 | loss: 2.0389571
MixupTrain:  epoch  0, batch   372 | loss: 2.2366872
MixupTrain:  epoch  0, batch   373 | loss: 2.0638041
MixupTrain:  epoch  0, batch   374 | loss: 2.0682387
MixupTrain:  epoch  0, batch   375 | loss: 2.0213854
MixupTrain:  epoch  0, batch   376 | loss: 1.8932748
MixupTrain:  epoch  0, batch   377 | loss: 2.0883584
MixupTrain:  epoch  0, batch   378 | loss: 2.1433492
MixupTrain:  epoch  0, batch   379 | loss: 2.0700665
MixupTrain:  epoch  0, batch   380 | loss: 2.1013474
MixupTrain:  epoch  0, batch   381 | loss: 2.0540509
MixupTrain:  epoch  0, batch   382 | loss: 1.9563199
MixupTrain:  epoch  0, batch   383 | loss: 2.1597676
MixupTrain:  epoch  0, batch   384 | loss: 2.1051302
MixupTrain:  epoch  0, batch   385 | loss: 2.0321002
MixupTrain:  epoch  0, batch   386 | loss: 1.9681306
MixupTrain:  epoch  0, batch   387 | loss: 2.0632439
MixupTrain:  epoch  0, batch   388 | loss: 2.0525565
MixupTrain:  epoch  0, batch   389 | loss: 2.0055597
MixupTrain:  epoch  0, batch   390 | loss: 1.9845319
MixupTrain:  epoch  0, batch   391 | loss: 2.0778039
MixupTrain:  epoch  0, batch   392 | loss: 1.9520624
MixupTrain:  epoch  0, batch   393 | loss: 2.1455352
MixupTrain:  epoch  0, batch   394 | loss: 1.9919699
MixupTrain:  epoch  0, batch   395 | loss: 1.9705957
MixupTrain:  epoch  0, batch   396 | loss: 1.9609864
MixupTrain:  epoch  0, batch   397 | loss: 2.0737360
MixupTrain:  epoch  0, batch   398 | loss: 1.9435041
MixupTrain:  epoch  0, batch   399 | loss: 2.0845001
MixupTrain:  epoch  0, batch   400 | loss: 2.1314688
MixupTrain:  epoch  0, batch   401 | loss: 1.9441717
MixupTrain:  epoch  0, batch   402 | loss: 2.0537891
MixupTrain:  epoch  0, batch   403 | loss: 2.0916295
MixupTrain:  epoch  0, batch   404 | loss: 2.1079366
MixupTrain:  epoch  0, batch   405 | loss: 2.0806627
MixupTrain:  epoch  0, batch   406 | loss: 2.0001709
MixupTrain:  epoch  0, batch   407 | loss: 1.9372168
MixupTrain:  epoch  0, batch   408 | loss: 2.0031624
MixupTrain:  epoch  0, batch   409 | loss: 2.0572076
MixupTrain:  epoch  0, batch   410 | loss: 2.0103042
MixupTrain:  epoch  0, batch   411 | loss: 1.9909074
MixupTrain:  epoch  0, batch   412 | loss: 2.0223684
MixupTrain:  epoch  0, batch   413 | loss: 2.2292285
MixupTrain:  epoch  0, batch   414 | loss: 1.9929007
MixupTrain:  epoch  0, batch   415 | loss: 2.0997460
MixupTrain:  epoch  0, batch   416 | loss: 2.0678189
MixupTrain:  epoch  0, batch   417 | loss: 2.1269135
MixupTrain:  epoch  0, batch   418 | loss: 2.0823812
MixupTrain:  epoch  0, batch   419 | loss: 2.0410943
MixupTrain:  epoch  0, batch   420 | loss: 1.9754351
MixupTrain:  epoch  0, batch   421 | loss: 2.0576189
MixupTrain:  epoch  0, batch   422 | loss: 1.9770894
MixupTrain:  epoch  0, batch   423 | loss: 1.9216889
MixupTrain:  epoch  0, batch   424 | loss: 2.1036777
MixupTrain:  epoch  0, batch   425 | loss: 2.0362577
MixupTrain:  epoch  0, batch   426 | loss: 2.0115778
MixupTrain:  epoch  0, batch   427 | loss: 2.0696664
MixupTrain:  epoch  0, batch   428 | loss: 1.9260883
MixupTrain:  epoch  0, batch   429 | loss: 2.1606071
MixupTrain:  epoch  0, batch   430 | loss: 2.0807824
MixupTrain:  epoch  0, batch   431 | loss: 2.1632857
MixupTrain:  epoch  0, batch   432 | loss: 2.1237047
MixupTrain:  epoch  0, batch   433 | loss: 1.9756110
MixupTrain:  epoch  0, batch   434 | loss: 1.9465117
MixupTrain:  epoch  0, batch   435 | loss: 2.0298533
MixupTrain:  epoch  0, batch   436 | loss: 2.0365934
MixupTrain:  epoch  0, batch   437 | loss: 2.1484401
MixupTrain:  epoch  0, batch   438 | loss: 1.9555616
MixupTrain:  epoch  0, batch   439 | loss: 2.0604606
MixupTrain:  epoch  0, batch   440 | loss: 2.0295136
MixupTrain:  epoch  0, batch   441 | loss: 2.1657362
MixupTrain:  epoch  0, batch   442 | loss: 1.9122810
MixupTrain:  epoch  0, batch   443 | loss: 2.0891223
MixupTrain:  epoch  0, batch   444 | loss: 2.0676415
MixupTrain:  epoch  0, batch   445 | loss: 2.0313725
MixupTrain:  epoch  0, batch   446 | loss: 1.9938865
MixupTrain:  epoch  0, batch   447 | loss: 1.9929149
MixupTrain:  epoch  0, batch   448 | loss: 2.0656624
MixupTrain:  epoch  0, batch   449 | loss: 2.0642233
MixupTrain:  epoch  0, batch   450 | loss: 1.9321740
MixupTrain:  epoch  0, batch   451 | loss: 2.1847219
MixupTrain:  epoch  0, batch   452 | loss: 2.0176468
MixupTrain:  epoch  0, batch   453 | loss: 1.9678755
MixupTrain:  epoch  0, batch   454 | loss: 2.0799136
MixupTrain:  epoch  0, batch   455 | loss: 2.1655157
MixupTrain:  epoch  0, batch   456 | loss: 1.9663379
MixupTrain:  epoch  0, batch   457 | loss: 2.1722813
MixupTrain:  epoch  0, batch   458 | loss: 2.0354090
MixupTrain:  epoch  0, batch   459 | loss: 2.1657519
MixupTrain:  epoch  0, batch   460 | loss: 2.0641692
MixupTrain:  epoch  0, batch   461 | loss: 1.9991846
MixupTrain:  epoch  0, batch   462 | loss: 1.9612465
MixupTrain:  epoch  0, batch   463 | loss: 1.9612601
MixupTrain:  epoch  0, batch   464 | loss: 2.0004768
MixupTrain:  epoch  0, batch   465 | loss: 1.9934853
MixupTrain:  epoch  0, batch   466 | loss: 2.0175738
MixupTrain:  epoch  0, batch   467 | loss: 1.9939352
MixupTrain:  epoch  0, batch   468 | loss: 2.0088952
MixupTrain:  epoch  0, batch   469 | loss: 2.0879903
MixupTrain:  epoch  0, batch   470 | loss: 2.1577210
MixupTrain:  epoch  0, batch   471 | loss: 2.0142417
MixupTrain:  epoch  0, batch   472 | loss: 1.9792109
MixupTrain:  epoch  0, batch   473 | loss: 2.0676951
MixupTrain:  epoch  0, batch   474 | loss: 1.9791613
MixupTrain:  epoch  0, batch   475 | loss: 2.0092778
MixupTrain:  epoch  0, batch   476 | loss: 2.0438032
MixupTrain:  epoch  0, batch   477 | loss: 2.0585365
MixupTrain:  epoch  0, batch   478 | loss: 1.9960964
MixupTrain:  epoch  0, batch   479 | loss: 1.9653341
MixupTrain:  epoch  0, batch   480 | loss: 2.0700221
MixupTrain:  epoch  0, batch   481 | loss: 2.0465641
MixupTrain:  epoch  0, batch   482 | loss: 2.0552683
MixupTrain:  epoch  0, batch   483 | loss: 2.0970545
MixupTrain:  epoch  0, batch   484 | loss: 2.0455890
MixupTrain:  epoch  0, batch   485 | loss: 1.9202160
MixupTrain:  epoch  0, batch   486 | loss: 2.1943409
MixupTrain:  epoch  0, batch   487 | loss: 1.9988301
MixupTrain:  epoch  0, batch   488 | loss: 2.0213375
MixupTrain:  epoch  0, batch   489 | loss: 2.0437148
MixupTrain:  epoch  0, batch   490 | loss: 2.0779376
MixupTrain:  epoch  0, batch   491 | loss: 2.0631404
MixupTrain:  epoch  0, batch   492 | loss: 2.0653489
MixupTrain:  epoch  0, batch   493 | loss: 2.1369035
MixupTrain:  epoch  0, batch   494 | loss: 1.9843472
MixupTrain:  epoch  0, batch   495 | loss: 1.9693438
MixupTrain:  epoch  0, batch   496 | loss: 2.0775580
MixupTrain:  epoch  0, batch   497 | loss: 2.1234188
MixupTrain:  epoch  0, batch   498 | loss: 2.0208871
MixupTrain:  epoch  0, batch   499 | loss: 1.9437802
MixupTrain:  epoch  0, batch   500 | loss: 1.9503042
MixupTrain:  epoch  0, batch   501 | loss: 2.0853231
MixupTrain:  epoch  0, batch   502 | loss: 2.0890474
MixupTrain:  epoch  0, batch   503 | loss: 2.2055702
MixupTrain:  epoch  0, batch   504 | loss: 1.9702908
MixupTrain:  epoch  0, batch   505 | loss: 1.9917195
MixupTrain:  epoch  0, batch   506 | loss: 2.0916607
MixupTrain:  epoch  0, batch   507 | loss: 1.9918616
MixupTrain:  epoch  0, batch   508 | loss: 2.0196238
MixupTrain:  epoch  0, batch   509 | loss: 2.0468981
MixupTrain:  epoch  0, batch   510 | loss: 2.0722315
MixupTrain:  epoch  0, batch   511 | loss: 2.0124652
MixupTrain:  epoch  0, batch   512 | loss: 2.0183461
MixupTrain:  epoch  0, batch   513 | loss: 1.9748375
MixupTrain:  epoch  0, batch   514 | loss: 2.0674219
MixupTrain:  epoch  0, batch   515 | loss: 2.0075943
MixupTrain:  epoch  0, batch   516 | loss: 1.9439672
MixupTrain:  epoch  0, batch   517 | loss: 2.0386376
MixupTrain:  epoch  0, batch   518 | loss: 1.9562604
MixupTrain:  epoch  0, batch   519 | loss: 1.9152095
MixupTrain:  epoch  0, batch   520 | loss: 1.9960225
MixupTrain:  epoch  0, batch   521 | loss: 2.0126584
MixupTrain:  epoch  0, batch   522 | loss: 1.9869316
MixupTrain:  epoch  0, batch   523 | loss: 1.9710934
MixupTrain:  epoch  0, batch   524 | loss: 1.9895715
MixupTrain:  epoch  0, batch   525 | loss: 2.0063784
MixupTrain:  epoch  0, batch   526 | loss: 1.9420946
MixupTrain:  epoch  0, batch   527 | loss: 2.0170360
MixupTrain:  epoch  0, batch   528 | loss: 2.0337315
MixupTrain:  epoch  0, batch   529 | loss: 2.0295219
MixupTrain:  epoch  0, batch   530 | loss: 2.0962758
MixupTrain:  epoch  0, batch   531 | loss: 1.9635748
MixupTrain:  epoch  0, batch   532 | loss: 1.9551625
MixupTrain:  epoch  0, batch   533 | loss: 2.0093012
MixupTrain:  epoch  0, batch   534 | loss: 2.0599427
MixupTrain:  epoch  0, batch   535 | loss: 1.9982396
MixupTrain:  epoch  0, batch   536 | loss: 2.1563506
MixupTrain:  epoch  0, batch   537 | loss: 1.9611602
MixupTrain:  epoch  0, batch   538 | loss: 2.0307932
MixupTrain:  epoch  0, batch   539 | loss: 2.0608888
MixupTrain:  epoch  0, batch   540 | loss: 2.0857320
MixupTrain:  epoch  0, batch   541 | loss: 2.1649070
MixupTrain:  epoch  0, batch   542 | loss: 2.0071349
MixupTrain:  epoch  0, batch   543 | loss: 1.9729365
MixupTrain:  epoch  0, batch   544 | loss: 2.0328031
MixupTrain:  epoch  0, batch   545 | loss: 2.2001777
MixupTrain:  epoch  0, batch   546 | loss: 1.9954431
MixupTrain:  epoch  0, batch   547 | loss: 2.0461380
MixupTrain:  epoch  0, batch   548 | loss: 1.9683832
MixupTrain:  epoch  0, batch   549 | loss: 1.9514291
MixupTrain:  epoch  0, batch   550 | loss: 2.1341813
MixupTrain:  epoch  0, batch   551 | loss: 1.9863956
MixupTrain:  epoch  0, batch   552 | loss: 2.0350931
MixupTrain:  epoch  0, batch   553 | loss: 2.0937700
MixupTrain:  epoch  0, batch   554 | loss: 2.0925305
MixupTrain:  epoch  0, batch   555 | loss: 1.9581542
MixupTrain:  epoch  0, batch   556 | loss: 2.0024805
MixupTrain:  epoch  0, batch   557 | loss: 2.0325887
MixupTrain:  epoch  0, batch   558 | loss: 2.0979772
MixupTrain:  epoch  0, batch   559 | loss: 2.0047996
MixupTrain:  epoch  0, batch   560 | loss: 2.0367675
MixupTrain:  epoch  0, batch   561 | loss: 1.9324563
MixupTrain:  epoch  0, batch   562 | loss: 1.9719725
MixupTrain:  epoch  0, batch   563 | loss: 2.1473610
MixupTrain:  epoch  0, batch   564 | loss: 2.1384516
MixupTrain:  epoch  0, batch   565 | loss: 1.9246701
MixupTrain:  epoch  0, batch   566 | loss: 1.9706908
MixupTrain:  epoch  0, batch   567 | loss: 2.1328454
MixupTrain:  epoch  0, batch   568 | loss: 1.9421377
MixupTrain:  epoch  0, batch   569 | loss: 2.0424039
MixupTrain:  epoch  0, batch   570 | loss: 1.9794407
MixupTrain:  epoch  0, batch   571 | loss: 2.0658274
MixupTrain:  epoch  0, batch   572 | loss: 1.9987266
MixupTrain:  epoch  0, batch   573 | loss: 1.8487396
MixupTrain:  epoch  0, batch   574 | loss: 2.1129322
MixupTrain:  epoch  0, batch   575 | loss: 1.9348552
MixupTrain:  epoch  0, batch   576 | loss: 2.0664978
MixupTrain:  epoch  0, batch   577 | loss: 2.0276718
MixupTrain:  epoch  0, batch   578 | loss: 2.0181813
MixupTrain:  epoch  0, batch   579 | loss: 2.0370965
MixupTrain:  epoch  0, batch   580 | loss: 1.9701213
MixupTrain:  epoch  0, batch   581 | loss: 1.9521191
MixupTrain:  epoch  0, batch   582 | loss: 1.9450622
MixupTrain:  epoch  0, batch   583 | loss: 2.0593095
MixupTrain:  epoch  0, batch   584 | loss: 2.1290672
MixupTrain:  epoch  0, batch   585 | loss: 2.0640030
MixupTrain:  epoch  0, batch   586 | loss: 2.1170340
MixupTrain:  epoch  0, batch   587 | loss: 2.1404591
MixupTrain:  epoch  0, batch   588 | loss: 2.0445123
MixupTrain:  epoch  0, batch   589 | loss: 1.9537591
MixupTrain:  epoch  0, batch   590 | loss: 2.0481961
MixupTrain:  epoch  0, batch   591 | loss: 2.0198298
MixupTrain:  epoch  0, batch   592 | loss: 2.0122786
MixupTrain:  epoch  0, batch   593 | loss: 1.9303784
MixupTrain:  epoch  0, batch   594 | loss: 2.0782328
MixupTrain:  epoch  0, batch   595 | loss: 2.1142406
MixupTrain:  epoch  0, batch   596 | loss: 2.0196738
MixupTrain:  epoch  0, batch   597 | loss: 1.9578054
MixupTrain:  epoch  0, batch   598 | loss: 2.2307923
MixupTrain:  epoch  0, batch   599 | loss: 2.1355178
MixupTrain:  epoch  0, batch   600 | loss: 2.0969586
MixupTrain:  epoch  0, batch   601 | loss: 1.9586647
MixupTrain:  epoch  0, batch   602 | loss: 2.1161551
MixupTrain:  epoch  0, batch   603 | loss: 1.9778037
MixupTrain:  epoch  0, batch   604 | loss: 2.0460224
MixupTrain:  epoch  0, batch   605 | loss: 2.0077236
MixupTrain:  epoch  0, batch   606 | loss: 1.9770145
MixupTrain:  epoch  0, batch   607 | loss: 2.0508785
MixupTrain:  epoch  0, batch   608 | loss: 2.0208969
MixupTrain:  epoch  0, batch   609 | loss: 2.0505762
MixupTrain:  epoch  0, batch   610 | loss: 2.0946286
MixupTrain:  epoch  0, batch   611 | loss: 1.9443321
MixupTrain:  epoch  0, batch   612 | loss: 1.9930577
MixupTrain:  epoch  0, batch   613 | loss: 1.9252150
MixupTrain:  epoch  0, batch   614 | loss: 2.0336905
MixupTrain:  epoch  0, batch   615 | loss: 1.9790395
MixupTrain:  epoch  0, batch   616 | loss: 1.9488757
MixupTrain:  epoch  0, batch   617 | loss: 2.0673976
MixupTrain:  epoch  0, batch   618 | loss: 1.9505910
MixupTrain:  epoch  0, batch   619 | loss: 2.1043673
MixupTrain:  epoch  0, batch   620 | loss: 2.1194766
MixupTrain:  epoch  0, batch   621 | loss: 2.0719380
MixupTrain:  epoch  0, batch   622 | loss: 2.0172682
MixupTrain:  epoch  0, batch   623 | loss: 1.9138397
MixupTrain:  epoch  0, batch   624 | loss: 1.9867021
MixupTrain:  epoch  0, batch   625 | loss: 2.1349502
MixupTrain:  epoch  0, batch   626 | loss: 2.0300720
MixupTrain:  epoch  0, batch   627 | loss: 1.9510757
MixupTrain:  epoch  0, batch   628 | loss: 1.9500012
MixupTrain:  epoch  0, batch   629 | loss: 1.9254129
MixupTrain:  epoch  0, batch   630 | loss: 2.1207705
MixupTrain:  epoch  0, batch   631 | loss: 2.0090811
MixupTrain:  epoch  0, batch   632 | loss: 2.0584383
MixupTrain:  epoch  0, batch   633 | loss: 2.0477276
MixupTrain:  epoch  0, batch   634 | loss: 1.9611917
MixupTrain:  epoch  0, batch   635 | loss: 2.0166402
MixupTrain:  epoch  0, batch   636 | loss: 2.0950632
MixupTrain:  epoch  0, batch   637 | loss: 1.9324594
MixupTrain:  epoch  0, batch   638 | loss: 2.1053648
MixupTrain:  epoch  0, batch   639 | loss: 2.0584252
MixupTrain:  epoch  0, batch   640 | loss: 1.9973136
MixupTrain:  epoch  0, batch   641 | loss: 2.0054951
MixupTrain:  epoch  0, batch   642 | loss: 2.0559640
MixupTrain:  epoch  0, batch   643 | loss: 2.0770931
MixupTrain:  epoch  0, batch   644 | loss: 2.1333070
MixupTrain:  epoch  0, batch   645 | loss: 2.0756633
MixupTrain:  epoch  0, batch   646 | loss: 2.0527701
MixupTrain:  epoch  0, batch   647 | loss: 1.9931722
MixupTrain:  epoch  0, batch   648 | loss: 2.0025773
MixupTrain:  epoch  0, batch   649 | loss: 2.1473525
MixupTrain:  epoch  0, batch   650 | loss: 1.9640245
MixupTrain:  epoch  0, batch   651 | loss: 2.1749339
MixupTrain:  epoch  0, batch   652 | loss: 2.0575030
MixupTrain:  epoch  0, batch   653 | loss: 1.9814750
MixupTrain:  epoch  0, batch   654 | loss: 2.0033772
MixupTrain:  epoch  0, batch   655 | loss: 2.0896463
MixupTrain:  epoch  0, batch   656 | loss: 1.9341401
MixupTrain:  epoch  0, batch   657 | loss: 2.1049194
MixupTrain:  epoch  0, batch   658 | loss: 1.9871746
MixupTrain:  epoch  0, batch   659 | loss: 1.9638410
MixupTrain:  epoch  0, batch   660 | loss: 2.0554738
MixupTrain:  epoch  0, batch   661 | loss: 2.0165896
MixupTrain:  epoch  0, batch   662 | loss: 1.9568516
MixupTrain:  epoch  0, batch   663 | loss: 2.0474849
MixupTrain:  epoch  0, batch   664 | loss: 1.9802108
MixupTrain:  epoch  0, batch   665 | loss: 1.9115555
MixupTrain:  epoch  0, batch   666 | loss: 2.0699265
MixupTrain:  epoch  0, batch   667 | loss: 1.9726647
MixupTrain:  epoch  0, batch   668 | loss: 2.0476270
MixupTrain:  epoch  0, batch   669 | loss: 2.0254457
MixupTrain:  epoch  0, batch   670 | loss: 1.9637674
MixupTrain:  epoch  0, batch   671 | loss: 2.0377710
MixupTrain:  epoch  0, batch   672 | loss: 1.9664323
MixupTrain:  epoch  0, batch   673 | loss: 2.0222745
MixupTrain:  epoch  0, batch   674 | loss: 2.0495543
MixupTrain:  epoch  0, batch   675 | loss: 1.9076504
MemoryTrain:  epoch  0, batch     0 | loss: 1.9084103
MemoryTrain:  epoch  0, batch     1 | loss: 2.4205244
MemoryTrain:  epoch  0, batch     2 | loss: 2.3654029
MemoryTrain:  epoch  0, batch     3 | loss: 2.0494504
MemoryTrain:  epoch  0, batch     4 | loss: 2.8646741
MemoryTrain:  epoch  0, batch     5 | loss: 2.6078668
MemoryTrain:  epoch  0, batch     6 | loss: 2.4459519
MemoryTrain:  epoch  0, batch     7 | loss: 2.1308022
MemoryTrain:  epoch  1, batch     0 | loss: 1.8238409
MemoryTrain:  epoch  1, batch     1 | loss: 1.8407984
MemoryTrain:  epoch  1, batch     2 | loss: 1.8261964
MemoryTrain:  epoch  1, batch     3 | loss: 1.9095316
MemoryTrain:  epoch  1, batch     4 | loss: 1.8483996
MemoryTrain:  epoch  1, batch     5 | loss: 1.8723922
MemoryTrain:  epoch  1, batch     6 | loss: 1.8673983
MemoryTrain:  epoch  1, batch     7 | loss: 1.8266246
MemoryTrain:  epoch  2, batch     0 | loss: 1.8403432
MemoryTrain:  epoch  2, batch     1 | loss: 1.8526635
MemoryTrain:  epoch  2, batch     2 | loss: 1.8674790
MemoryTrain:  epoch  2, batch     3 | loss: 1.8258413
MemoryTrain:  epoch  2, batch     4 | loss: 1.8449943
MemoryTrain:  epoch  2, batch     5 | loss: 1.8143307
MemoryTrain:  epoch  2, batch     6 | loss: 1.8615251
MemoryTrain:  epoch  2, batch     7 | loss: 1.8234178
MemoryTrain:  epoch  3, batch     0 | loss: 1.8290062
MemoryTrain:  epoch  3, batch     1 | loss: 1.8138613
MemoryTrain:  epoch  3, batch     2 | loss: 1.8366230
MemoryTrain:  epoch  3, batch     3 | loss: 1.8300627
MemoryTrain:  epoch  3, batch     4 | loss: 1.8273463
MemoryTrain:  epoch  3, batch     5 | loss: 1.8186283
MemoryTrain:  epoch  3, batch     6 | loss: 1.8257036
MemoryTrain:  epoch  3, batch     7 | loss: 1.8275456
MemoryTrain:  epoch  4, batch     0 | loss: 1.8211228
MemoryTrain:  epoch  4, batch     1 | loss: 1.8241968
MemoryTrain:  epoch  4, batch     2 | loss: 1.8411129
MemoryTrain:  epoch  4, batch     3 | loss: 1.8219045
MemoryTrain:  epoch  4, batch     4 | loss: 1.8237289
MemoryTrain:  epoch  4, batch     5 | loss: 1.8192816
MemoryTrain:  epoch  4, batch     6 | loss: 1.8364539
MemoryTrain:  epoch  4, batch     7 | loss: 1.8295300
MemoryTrain:  epoch  5, batch     0 | loss: 1.8145373
MemoryTrain:  epoch  5, batch     1 | loss: 1.8233421
MemoryTrain:  epoch  5, batch     2 | loss: 1.8270049
MemoryTrain:  epoch  5, batch     3 | loss: 1.8232822
MemoryTrain:  epoch  5, batch     4 | loss: 1.8247831
MemoryTrain:  epoch  5, batch     5 | loss: 1.8432450
MemoryTrain:  epoch  5, batch     6 | loss: 1.8163216
MemoryTrain:  epoch  5, batch     7 | loss: 1.8287313
MemoryTrain:  epoch  6, batch     0 | loss: 1.8194585
MemoryTrain:  epoch  6, batch     1 | loss: 1.8293922
MemoryTrain:  epoch  6, batch     2 | loss: 1.8220496
MemoryTrain:  epoch  6, batch     3 | loss: 1.8215235
MemoryTrain:  epoch  6, batch     4 | loss: 1.8378491
MemoryTrain:  epoch  6, batch     5 | loss: 1.8385451
MemoryTrain:  epoch  6, batch     6 | loss: 1.8231144
MemoryTrain:  epoch  6, batch     7 | loss: 1.8549345
MemoryTrain:  epoch  7, batch     0 | loss: 1.8168929
MemoryTrain:  epoch  7, batch     1 | loss: 1.8354151
MemoryTrain:  epoch  7, batch     2 | loss: 1.8303473
MemoryTrain:  epoch  7, batch     3 | loss: 1.8259799
MemoryTrain:  epoch  7, batch     4 | loss: 1.8170844
MemoryTrain:  epoch  7, batch     5 | loss: 1.8305329
MemoryTrain:  epoch  7, batch     6 | loss: 1.8349686
MemoryTrain:  epoch  7, batch     7 | loss: 1.8258667
MemoryTrain:  epoch  8, batch     0 | loss: 1.8337278
MemoryTrain:  epoch  8, batch     1 | loss: 1.8138494
MemoryTrain:  epoch  8, batch     2 | loss: 1.8250198
MemoryTrain:  epoch  8, batch     3 | loss: 1.8157625
MemoryTrain:  epoch  8, batch     4 | loss: 1.8250153
MemoryTrain:  epoch  8, batch     5 | loss: 1.8200393
MemoryTrain:  epoch  8, batch     6 | loss: 1.8165126
MemoryTrain:  epoch  8, batch     7 | loss: 1.8227468
MemoryTrain:  epoch  9, batch     0 | loss: 1.8171296
MemoryTrain:  epoch  9, batch     1 | loss: 1.8152212
MemoryTrain:  epoch  9, batch     2 | loss: 1.8171352
MemoryTrain:  epoch  9, batch     3 | loss: 1.8162985
MemoryTrain:  epoch  9, batch     4 | loss: 1.8220804
MemoryTrain:  epoch  9, batch     5 | loss: 1.8126826
MemoryTrain:  epoch  9, batch     6 | loss: 1.8122332
MemoryTrain:  epoch  9, batch     7 | loss: 1.8164768
[EVAL] batch:    0 | acc: 100.00%,  total acc: 100.00%   
[EVAL] batch:    1 | acc: 100.00%,  total acc: 100.00%   
[EVAL] batch:    2 | acc: 93.75%,  total acc: 97.92%   
[EVAL] batch:    3 | acc: 87.50%,  total acc: 95.31%   
[EVAL] batch:    4 | acc: 100.00%,  total acc: 96.25%   
[EVAL] batch:    5 | acc: 100.00%,  total acc: 96.88%   
[EVAL] batch:    6 | acc: 93.75%,  total acc: 96.43%   
[EVAL] batch:    7 | acc: 93.75%,  total acc: 96.09%   
[EVAL] batch:    8 | acc: 68.75%,  total acc: 93.06%   
[EVAL] batch:    9 | acc: 93.75%,  total acc: 93.12%   
[EVAL] batch:   10 | acc: 93.75%,  total acc: 93.18%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 93.23%   
[EVAL] batch:   12 | acc: 50.00%,  total acc: 89.90%   
[EVAL] batch:    0 | acc: 6.25%,  total acc: 6.25%   
[EVAL] batch:    1 | acc: 37.50%,  total acc: 21.88%   
[EVAL] batch:    2 | acc: 18.75%,  total acc: 20.83%   
[EVAL] batch:    3 | acc: 6.25%,  total acc: 17.19%   
[EVAL] batch:    4 | acc: 18.75%,  total acc: 17.50%   
[EVAL] batch:    5 | acc: 25.00%,  total acc: 18.75%   
[EVAL] batch:    6 | acc: 37.50%,  total acc: 21.43%   
[EVAL] batch:    7 | acc: 25.00%,  total acc: 21.88%   
[EVAL] batch:    8 | acc: 37.50%,  total acc: 23.61%   
[EVAL] batch:    9 | acc: 31.25%,  total acc: 24.38%   
[EVAL] batch:   10 | acc: 25.00%,  total acc: 24.43%   
[EVAL] batch:   11 | acc: 50.00%,  total acc: 26.56%   
[EVAL] batch:   12 | acc: 18.75%,  total acc: 25.96%   
[EVAL] batch:   13 | acc: 37.50%,  total acc: 26.79%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 30.00%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 31.64%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 34.19%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 35.76%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 37.17%   
[EVAL] batch:   19 | acc: 87.50%,  total acc: 39.69%   
[EVAL] batch:   20 | acc: 93.75%,  total acc: 42.26%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 44.89%   
[EVAL] batch:   22 | acc: 87.50%,  total acc: 46.74%   
[EVAL] batch:   23 | acc: 93.75%,  total acc: 48.70%   
[EVAL] batch:   24 | acc: 93.75%,  total acc: 50.50%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 52.40%   
[EVAL] batch:   26 | acc: 75.00%,  total acc: 53.24%   
[EVAL] batch:   27 | acc: 56.25%,  total acc: 53.35%   
[EVAL] batch:   28 | acc: 62.50%,  total acc: 53.66%   
[EVAL] batch:   29 | acc: 50.00%,  total acc: 53.54%   
[EVAL] batch:   30 | acc: 56.25%,  total acc: 53.63%   
[EVAL] batch:   31 | acc: 37.50%,  total acc: 53.12%   
[EVAL] batch:   32 | acc: 87.50%,  total acc: 54.17%   
[EVAL] batch:   33 | acc: 25.00%,  total acc: 53.31%   
[EVAL] batch:   34 | acc: 25.00%,  total acc: 52.50%   
[EVAL] batch:   35 | acc: 0.00%,  total acc: 51.04%   
[EVAL] batch:   36 | acc: 0.00%,  total acc: 49.66%   
[EVAL] batch:   37 | acc: 18.75%,  total acc: 48.85%   
[EVAL] batch:   38 | acc: 12.50%,  total acc: 47.92%   
[EVAL] batch:   39 | acc: 68.75%,  total acc: 48.44%   
[EVAL] batch:   40 | acc: 93.75%,  total acc: 49.54%   
[EVAL] batch:   41 | acc: 81.25%,  total acc: 50.30%   
[EVAL] batch:   42 | acc: 87.50%,  total acc: 51.16%   
[EVAL] batch:   43 | acc: 75.00%,  total acc: 51.70%   
[EVAL] batch:   44 | acc: 81.25%,  total acc: 52.36%   
[EVAL] batch:   45 | acc: 25.00%,  total acc: 51.77%   
[EVAL] batch:   46 | acc: 68.75%,  total acc: 52.13%   
[EVAL] batch:   47 | acc: 93.75%,  total acc: 52.99%   
[EVAL] batch:   48 | acc: 87.50%,  total acc: 53.70%   
[EVAL] batch:   49 | acc: 81.25%,  total acc: 54.25%   
[EVAL] batch:   50 | acc: 62.50%,  total acc: 54.41%   
[EVAL] batch:   51 | acc: 87.50%,  total acc: 55.05%   
[EVAL] batch:   52 | acc: 68.75%,  total acc: 55.31%   
[EVAL] batch:   53 | acc: 100.00%,  total acc: 56.13%   
[EVAL] batch:   54 | acc: 100.00%,  total acc: 56.93%   
[EVAL] batch:   55 | acc: 93.75%,  total acc: 57.59%   
[EVAL] batch:   56 | acc: 93.75%,  total acc: 58.22%   
[EVAL] batch:   57 | acc: 93.75%,  total acc: 58.84%   
[EVAL] batch:   58 | acc: 100.00%,  total acc: 59.53%   
[EVAL] batch:   59 | acc: 93.75%,  total acc: 60.10%   
[EVAL] batch:   60 | acc: 93.75%,  total acc: 60.66%   
[EVAL] batch:   61 | acc: 75.00%,  total acc: 60.89%   
[EVAL] batch:   62 | acc: 87.50%,  total acc: 61.31%   
[EVAL] batch:   63 | acc: 93.75%,  total acc: 61.82%   
[EVAL] batch:   64 | acc: 93.75%,  total acc: 62.31%   
[EVAL] batch:   65 | acc: 68.75%,  total acc: 62.41%   
cur_acc:  ['0.8712', '0.8705', '0.7266', '0.8990']
his_acc:  ['0.8712', '0.8564', '0.6238', '0.6241']
CurrentTrain: epoch  0, batch     0 | loss: 7.9669967
CurrentTrain: epoch  0, batch     1 | loss: 7.7363334
CurrentTrain: epoch  1, batch     0 | loss: 6.1798005
CurrentTrain: epoch  1, batch     1 | loss: 8.9820929
CurrentTrain: epoch  2, batch     0 | loss: 7.1361370
CurrentTrain: epoch  2, batch     1 | loss: 6.6598353
CurrentTrain: epoch  3, batch     0 | loss: 5.9188290
CurrentTrain: epoch  3, batch     1 | loss: 8.0709448
CurrentTrain: epoch  4, batch     0 | loss: 5.4607654
CurrentTrain: epoch  4, batch     1 | loss: 7.7029757
CurrentTrain: epoch  5, batch     0 | loss: 6.3902950
CurrentTrain: epoch  5, batch     1 | loss: 5.9879737
CurrentTrain: epoch  6, batch     0 | loss: 5.8532810
CurrentTrain: epoch  6, batch     1 | loss: 6.9744415
CurrentTrain: epoch  7, batch     0 | loss: 4.5303316
CurrentTrain: epoch  7, batch     1 | loss: 8.3699865
CurrentTrain: epoch  8, batch     0 | loss: 5.3329992
CurrentTrain: epoch  8, batch     1 | loss: 6.1020041
CurrentTrain: epoch  9, batch     0 | loss: 5.0557103
CurrentTrain: epoch  9, batch     1 | loss: 5.9017878
#### organization subsidiaries ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization subsidiaries" means an organization 's subsidiary is an organization.
Here is an example:
Relation: organization subsidiaries
Context: venture fund buys sporting chain highland capital 's consumer fund includes lululemon athletica , a yoga retailer , and o beverages , a flavored water company developed by tom first , one of the two `` juice guys '' who cofounded nantucket nectars .
Head Entity: highland capital
Tail Entity: o beverages
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization subsidiaries":
Relation: organization subsidiaries  
Context: The tech giant Alphabet Inc. has several subsidiaries, including YouTube, which has transformed the way we consume video content online.  
Head Entity: Alphabet Inc.  
Tail Entity: YouTube  

Relation: organization subsidiaries  
Context: The automotive manufacturer General Motors has a number of subsidiaries, one of which is Chevrolet, known for its popular line of trucks and cars.  
Head Entity: General Motors  
Tail Entity: Chevrolet  

Relation: organization subsidiaries  
Context: The multinational conglomerate Procter & Gamble owns various subsidiaries, including Gillette, which specializes in personal care products.  
Head Entity: Procter & Gamble  
Tail Entity: Gillette  

Relation: organization subsidiaries  
Context: The beverage company Coca-Cola has several subsidiaries, one of which is Minute Maid, famous for its fruit juices and drinks.  
Head Entity: Coca-Cola  
Tail Entity: Minute Maid  

Relation: organization subsidiaries  
Context: The financial services corporation Berkshire Hathaway has numerous subsidiaries, including Geico, which is well-known for its auto insurance services.  
Head Entity: Berkshire Hathaway  
Tail Entity: Geico  
#### organization parents ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization parents" means an organization 's parent is an organization.
Here is an example:
Relation: organization parents
Context: those who try to salvage possessions from the debris of their homes can easily turn into victims too , said dr. irwin redlener , director of the national center for disaster preparedness at columbia university mailman school of medicine .
Head Entity: national center for disaster preparedness
Tail Entity: columbia university mailman school of medicine
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization parents":
Relation: organization parents  
Context: The tech giant Google has been a subsidiary of Alphabet Inc. since its restructuring in 2015, allowing for greater focus on its various ventures.  
Head Entity: Google  
Tail Entity: Alphabet Inc.  

Relation: organization parents  
Context: The renowned film studio Pixar Animation Studios is a subsidiary of The Walt Disney Company, which has significantly influenced the animation industry.  
Head Entity: Pixar Animation Studios  
Tail Entity: The Walt Disney Company  

Relation: organization parents  
Context: The popular social media platform Instagram was acquired by Facebook Inc. in 2012, expanding Facebook's reach in the digital landscape.  
Head Entity: Instagram  
Tail Entity: Facebook Inc.  

Relation: organization parents  
Context: The global coffeehouse chain Starbucks Corporation has its roots in the original Starbucks store opened in Seattle, Washington, which was later acquired by the corporation.  
Head Entity: Starbucks Corporation  
Tail Entity: original Starbucks store  

Relation: organization parents  
Context: The leading online retailer Amazon.com, Inc. has expanded its operations through the acquisition of Whole Foods Market, enhancing its presence in the grocery sector.  
Head Entity: Amazon.com, Inc.  
Tail Entity: Whole Foods Market  
#### organization alternate names ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization alternate names" means a person 's alias is a person.
Here is an example:
Relation: organization alternate names
Context: i received an email today from the friends of the mckune memorial library -lrb- that is the chelsea library to most of us -rrb- , which had a couple great ideas for last-minute gifts .
Head Entity: chelsea library
Tail Entity: mckune memorial library
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization alternate names":
Relation: organization alternate names  
Context: The local community center, known as the Smithtown Recreation Hall, is hosting a charity event this weekend.  
Head Entity: Smithtown Recreation Hall  
Tail Entity: local community center  

Relation: organization alternate names  
Context: The famous art gallery, referred to as the Downtown Art Space, will be featuring a new exhibition next month.  
Head Entity: Downtown Art Space  
Tail Entity: famous art gallery  

Relation: organization alternate names  
Context: The annual festival, celebrated as the Riverdale Fair, attracts visitors from all over the region.  
Head Entity: Riverdale Fair  
Tail Entity: annual festival  

Relation: organization alternate names  
Context: The tech startup, often called GreenTech Innovations, has just secured a major investment.  
Head Entity: GreenTech Innovations  
Tail Entity: tech startup  

Relation: organization alternate names  
Context: The historical museum, which many locals refer to as the Old Town Museum, is offering free admission this weekend.  
Head Entity: Old Town Museum  
Tail Entity: historical museum  
#### organization city of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization city of headquarters" means an organization is located in a city.
Here is an example:
Relation: organization city of headquarters
Context: the justice and equality movement -lrb- jem -rrb- , a major rebel movement in darfur , is still insisting on its conditions for the resumption of the talks , including the release of dozens of rebel fighters who were arrested after an attack in omdurman near khartoum in may 2008 .
Head Entity: justice and equality movement
Tail Entity: darfur
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization city of headquarters":
Relation: organization city of headquarters  
Context: the headquarters of the international red cross is located in geneva, switzerland, where it coordinates humanitarian efforts worldwide.  
Head Entity: international red cross  
Tail Entity: geneva  

Relation: organization city of headquarters  
Context: google's main office is situated in mountain view, california, which serves as the hub for its global operations.  
Head Entity: google  
Tail Entity: mountain view  

Relation: organization city of headquarters  
Context: the united nations has its headquarters in new york city, where it conducts its diplomatic activities and meetings.  
Head Entity: united nations  
Tail Entity: new york city  

Relation: organization city of headquarters  
Context: the headquarters of the european union is based in brussels, belgium, making it a central point for political discussions in europe.  
Head Entity: european union  
Tail Entity: brussels  

Relation: organization city of headquarters  
Context: the world health organization is headquartered in geneva, switzerland, focusing on global health issues and policies.  
Head Entity: world health organization  
Tail Entity: geneva  
#### person siblings ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person siblings" means a person 's sibling is a person.
Here is an example:
Relation: person siblings
Context: forsberg , a political science professor at city college of new york , died oct. 19 in a bronx hospital of cancer , said her sister , celia seupel .
Head Entity: forsberg
Tail Entity: celia seupel
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person siblings":
Relation: person siblings  
Context: During the family reunion, John introduced his sister, Emily, who had just returned from studying abroad.  
Head Entity: John  
Tail Entity: Emily  

Relation: person siblings  
Context: After the game, Sarah celebrated her victory with her brother, Michael, who had been cheering for her from the stands.  
Head Entity: Sarah  
Tail Entity: Michael  

Relation: person siblings  
Context: In her memoir, Lisa writes fondly about her childhood adventures with her brother, Tom, who always had her back.  
Head Entity: Lisa  
Tail Entity: Tom  

Relation: person siblings  
Context: At the wedding, Anna was thrilled to see her brother, David, who flew in from another state to be her best man.  
Head Entity: Anna  
Tail Entity: David  

Relation: person siblings  
Context: The documentary featured interviews with Rachel and her sister, Jessica, discussing their upbringing and close bond.  
Head Entity: Rachel  
Tail Entity: Jessica  
Mixup data size:  15700
MixupTrain:  epoch  0, batch     0 | loss: 4.5521040
MixupTrain:  epoch  0, batch     1 | loss: 5.1357055
MixupTrain:  epoch  0, batch     2 | loss: 4.8743114
MixupTrain:  epoch  0, batch     3 | loss: 5.1345553
MixupTrain:  epoch  0, batch     4 | loss: 5.3889732
MixupTrain:  epoch  0, batch     5 | loss: 5.1407967
MixupTrain:  epoch  0, batch     6 | loss: 4.6853328
MixupTrain:  epoch  0, batch     7 | loss: 5.1245384
MixupTrain:  epoch  0, batch     8 | loss: 5.6040263
MixupTrain:  epoch  0, batch     9 | loss: 4.8171539
MixupTrain:  epoch  0, batch    10 | loss: 5.8899527
MixupTrain:  epoch  0, batch    11 | loss: 5.3110995
MixupTrain:  epoch  0, batch    12 | loss: 3.1310024
MixupTrain:  epoch  0, batch    13 | loss: 5.9031658
MixupTrain:  epoch  0, batch    14 | loss: 4.3472414
MixupTrain:  epoch  0, batch    15 | loss: 5.1277304
MixupTrain:  epoch  0, batch    16 | loss: 5.2609186
MixupTrain:  epoch  0, batch    17 | loss: 3.7051229
MixupTrain:  epoch  0, batch    18 | loss: 3.6476860
MixupTrain:  epoch  0, batch    19 | loss: 4.1259027
MixupTrain:  epoch  0, batch    20 | loss: 3.9686046
MixupTrain:  epoch  0, batch    21 | loss: 4.7644520
MixupTrain:  epoch  0, batch    22 | loss: 4.1935835
MixupTrain:  epoch  0, batch    23 | loss: 3.6371982
MixupTrain:  epoch  0, batch    24 | loss: 4.9494367
MixupTrain:  epoch  0, batch    25 | loss: 4.7465620
MixupTrain:  epoch  0, batch    26 | loss: 4.7776871
MixupTrain:  epoch  0, batch    27 | loss: 4.0603781
MixupTrain:  epoch  0, batch    28 | loss: 5.3646269
MixupTrain:  epoch  0, batch    29 | loss: 5.0804715
MixupTrain:  epoch  0, batch    30 | loss: 3.9218097
MixupTrain:  epoch  0, batch    31 | loss: 4.0698042
MixupTrain:  epoch  0, batch    32 | loss: 4.1272149
MixupTrain:  epoch  0, batch    33 | loss: 4.4192734
MixupTrain:  epoch  0, batch    34 | loss: 3.4662042
MixupTrain:  epoch  0, batch    35 | loss: 4.9410081
MixupTrain:  epoch  0, batch    36 | loss: 3.7643449
MixupTrain:  epoch  0, batch    37 | loss: 3.9485066
MixupTrain:  epoch  0, batch    38 | loss: 4.6211052
MixupTrain:  epoch  0, batch    39 | loss: 3.3433862
MixupTrain:  epoch  0, batch    40 | loss: 4.5675211
MixupTrain:  epoch  0, batch    41 | loss: 4.0154138
MixupTrain:  epoch  0, batch    42 | loss: 4.4587650
MixupTrain:  epoch  0, batch    43 | loss: 3.4767272
MixupTrain:  epoch  0, batch    44 | loss: 3.9090683
MixupTrain:  epoch  0, batch    45 | loss: 4.5174437
MixupTrain:  epoch  0, batch    46 | loss: 3.4538128
MixupTrain:  epoch  0, batch    47 | loss: 4.5570164
MixupTrain:  epoch  0, batch    48 | loss: 4.5690074
MixupTrain:  epoch  0, batch    49 | loss: 3.4980266
MixupTrain:  epoch  0, batch    50 | loss: 3.3459892
MixupTrain:  epoch  0, batch    51 | loss: 4.2785120
MixupTrain:  epoch  0, batch    52 | loss: 3.7162747
MixupTrain:  epoch  0, batch    53 | loss: 4.3321433
MixupTrain:  epoch  0, batch    54 | loss: 3.2879391
MixupTrain:  epoch  0, batch    55 | loss: 4.3777838
MixupTrain:  epoch  0, batch    56 | loss: 4.6499596
MixupTrain:  epoch  0, batch    57 | loss: 3.5233834
MixupTrain:  epoch  0, batch    58 | loss: 3.8705275
MixupTrain:  epoch  0, batch    59 | loss: 3.3937459
MixupTrain:  epoch  0, batch    60 | loss: 3.4893951
MixupTrain:  epoch  0, batch    61 | loss: 3.8924651
MixupTrain:  epoch  0, batch    62 | loss: 4.5976048
MixupTrain:  epoch  0, batch    63 | loss: 3.6168687
MixupTrain:  epoch  0, batch    64 | loss: 3.8266521
MixupTrain:  epoch  0, batch    65 | loss: 3.7616191
MixupTrain:  epoch  0, batch    66 | loss: 4.0607462
MixupTrain:  epoch  0, batch    67 | loss: 4.2481337
MixupTrain:  epoch  0, batch    68 | loss: 3.0181141
MixupTrain:  epoch  0, batch    69 | loss: 3.7976878
MixupTrain:  epoch  0, batch    70 | loss: 4.6361213
MixupTrain:  epoch  0, batch    71 | loss: 4.2212276
MixupTrain:  epoch  0, batch    72 | loss: 3.8841851
MixupTrain:  epoch  0, batch    73 | loss: 4.6400909
MixupTrain:  epoch  0, batch    74 | loss: 2.7609701
MixupTrain:  epoch  0, batch    75 | loss: 2.4911792
MixupTrain:  epoch  0, batch    76 | loss: 3.6251612
MixupTrain:  epoch  0, batch    77 | loss: 4.0775652
MixupTrain:  epoch  0, batch    78 | loss: 4.4669070
MixupTrain:  epoch  0, batch    79 | loss: 3.8030534
MixupTrain:  epoch  0, batch    80 | loss: 3.1315684
MixupTrain:  epoch  0, batch    81 | loss: 3.9165897
MixupTrain:  epoch  0, batch    82 | loss: 4.0734177
MixupTrain:  epoch  0, batch    83 | loss: 4.3461542
MixupTrain:  epoch  0, batch    84 | loss: 3.1289964
MixupTrain:  epoch  0, batch    85 | loss: 4.1419163
MixupTrain:  epoch  0, batch    86 | loss: 4.1969261
MixupTrain:  epoch  0, batch    87 | loss: 3.8889754
MixupTrain:  epoch  0, batch    88 | loss: 3.4709308
MixupTrain:  epoch  0, batch    89 | loss: 3.6941066
MixupTrain:  epoch  0, batch    90 | loss: 3.4777212
MixupTrain:  epoch  0, batch    91 | loss: 3.3234074
MixupTrain:  epoch  0, batch    92 | loss: 4.6332016
MixupTrain:  epoch  0, batch    93 | loss: 3.0311866
MixupTrain:  epoch  0, batch    94 | loss: 3.1611128
MixupTrain:  epoch  0, batch    95 | loss: 3.1704741
MixupTrain:  epoch  0, batch    96 | loss: 3.3947310
MixupTrain:  epoch  0, batch    97 | loss: 3.4016051
MixupTrain:  epoch  0, batch    98 | loss: 3.3728509
MixupTrain:  epoch  0, batch    99 | loss: 4.0985351
MixupTrain:  epoch  0, batch   100 | loss: 3.6963997
MixupTrain:  epoch  0, batch   101 | loss: 2.9724548
MixupTrain:  epoch  0, batch   102 | loss: 2.9942865
MixupTrain:  epoch  0, batch   103 | loss: 3.4432597
MixupTrain:  epoch  0, batch   104 | loss: 3.7697759
MixupTrain:  epoch  0, batch   105 | loss: 4.0344219
MixupTrain:  epoch  0, batch   106 | loss: 3.6102607
MixupTrain:  epoch  0, batch   107 | loss: 3.2930312
MixupTrain:  epoch  0, batch   108 | loss: 3.7979076
MixupTrain:  epoch  0, batch   109 | loss: 2.9780133
MixupTrain:  epoch  0, batch   110 | loss: 2.9895937
MixupTrain:  epoch  0, batch   111 | loss: 2.5565009
MixupTrain:  epoch  0, batch   112 | loss: 4.0067101
MixupTrain:  epoch  0, batch   113 | loss: 2.9015849
MixupTrain:  epoch  0, batch   114 | loss: 3.2731843
MixupTrain:  epoch  0, batch   115 | loss: 4.0747552
MixupTrain:  epoch  0, batch   116 | loss: 3.2108479
MixupTrain:  epoch  0, batch   117 | loss: 3.1729937
MixupTrain:  epoch  0, batch   118 | loss: 2.9211373
MixupTrain:  epoch  0, batch   119 | loss: 3.7411277
MixupTrain:  epoch  0, batch   120 | loss: 3.4600992
MixupTrain:  epoch  0, batch   121 | loss: 3.3308477
MixupTrain:  epoch  0, batch   122 | loss: 3.8176527
MixupTrain:  epoch  0, batch   123 | loss: 3.4464452
MixupTrain:  epoch  0, batch   124 | loss: 3.9069433
MixupTrain:  epoch  0, batch   125 | loss: 3.2212863
MixupTrain:  epoch  0, batch   126 | loss: 2.9551618
MixupTrain:  epoch  0, batch   127 | loss: 3.3436389
MixupTrain:  epoch  0, batch   128 | loss: 3.3556323
MixupTrain:  epoch  0, batch   129 | loss: 3.2994008
MixupTrain:  epoch  0, batch   130 | loss: 2.8627479
MixupTrain:  epoch  0, batch   131 | loss: 3.0895829
MixupTrain:  epoch  0, batch   132 | loss: 3.7552259
MixupTrain:  epoch  0, batch   133 | loss: 3.6583135
MixupTrain:  epoch  0, batch   134 | loss: 3.4889565
MixupTrain:  epoch  0, batch   135 | loss: 3.1611416
MixupTrain:  epoch  0, batch   136 | loss: 3.2750492
MixupTrain:  epoch  0, batch   137 | loss: 3.5033848
MixupTrain:  epoch  0, batch   138 | loss: 3.1676404
MixupTrain:  epoch  0, batch   139 | loss: 3.0684614
MixupTrain:  epoch  0, batch   140 | loss: 2.9805069
MixupTrain:  epoch  0, batch   141 | loss: 3.4599848
MixupTrain:  epoch  0, batch   142 | loss: 3.2027845
MixupTrain:  epoch  0, batch   143 | loss: 3.6250882
MixupTrain:  epoch  0, batch   144 | loss: 3.3599548
MixupTrain:  epoch  0, batch   145 | loss: 3.2488148
MixupTrain:  epoch  0, batch   146 | loss: 3.3369770
MixupTrain:  epoch  0, batch   147 | loss: 3.2952931
MixupTrain:  epoch  0, batch   148 | loss: 3.1268916
MixupTrain:  epoch  0, batch   149 | loss: 3.0287809
MixupTrain:  epoch  0, batch   150 | loss: 3.5055013
MixupTrain:  epoch  0, batch   151 | loss: 3.1342421
MixupTrain:  epoch  0, batch   152 | loss: 3.7747197
MixupTrain:  epoch  0, batch   153 | loss: 3.5330362
MixupTrain:  epoch  0, batch   154 | loss: 3.0160096
MixupTrain:  epoch  0, batch   155 | loss: 2.5472832
MixupTrain:  epoch  0, batch   156 | loss: 3.7507739
MixupTrain:  epoch  0, batch   157 | loss: 3.5098794
MixupTrain:  epoch  0, batch   158 | loss: 3.0709233
MixupTrain:  epoch  0, batch   159 | loss: 3.4524865
MixupTrain:  epoch  0, batch   160 | loss: 3.0542409
MixupTrain:  epoch  0, batch   161 | loss: 3.3456964
MixupTrain:  epoch  0, batch   162 | loss: 3.1807611
MixupTrain:  epoch  0, batch   163 | loss: 2.4999518
MixupTrain:  epoch  0, batch   164 | loss: 3.2927594
MixupTrain:  epoch  0, batch   165 | loss: 3.3464131
MixupTrain:  epoch  0, batch   166 | loss: 2.6956172
MixupTrain:  epoch  0, batch   167 | loss: 2.8984499
MixupTrain:  epoch  0, batch   168 | loss: 3.1993761
MixupTrain:  epoch  0, batch   169 | loss: 3.1080275
MixupTrain:  epoch  0, batch   170 | loss: 2.8694122
MixupTrain:  epoch  0, batch   171 | loss: 3.6480832
MixupTrain:  epoch  0, batch   172 | loss: 3.7577558
MixupTrain:  epoch  0, batch   173 | loss: 2.8205445
MixupTrain:  epoch  0, batch   174 | loss: 3.8424921
MixupTrain:  epoch  0, batch   175 | loss: 2.4053001
MixupTrain:  epoch  0, batch   176 | loss: 3.2143316
MixupTrain:  epoch  0, batch   177 | loss: 2.8595023
MixupTrain:  epoch  0, batch   178 | loss: 3.7454662
MixupTrain:  epoch  0, batch   179 | loss: 3.7795703
MixupTrain:  epoch  0, batch   180 | loss: 3.2943437
MixupTrain:  epoch  0, batch   181 | loss: 3.1281445
MixupTrain:  epoch  0, batch   182 | loss: 3.6731899
MixupTrain:  epoch  0, batch   183 | loss: 2.6925206
MixupTrain:  epoch  0, batch   184 | loss: 3.0790069
MixupTrain:  epoch  0, batch   185 | loss: 3.2284937
MixupTrain:  epoch  0, batch   186 | loss: 2.6698613
MixupTrain:  epoch  0, batch   187 | loss: 3.8503590
MixupTrain:  epoch  0, batch   188 | loss: 3.0823479
MixupTrain:  epoch  0, batch   189 | loss: 3.3354082
MixupTrain:  epoch  0, batch   190 | loss: 3.2842603
MixupTrain:  epoch  0, batch   191 | loss: 3.5303769
MixupTrain:  epoch  0, batch   192 | loss: 3.3602049
MixupTrain:  epoch  0, batch   193 | loss: 2.9714751
MixupTrain:  epoch  0, batch   194 | loss: 3.1571815
MixupTrain:  epoch  0, batch   195 | loss: 3.1663966
MixupTrain:  epoch  0, batch   196 | loss: 2.6252286
MixupTrain:  epoch  0, batch   197 | loss: 2.9806850
MixupTrain:  epoch  0, batch   198 | loss: 3.5235693
MixupTrain:  epoch  0, batch   199 | loss: 2.4056959
MixupTrain:  epoch  0, batch   200 | loss: 3.2346642
MixupTrain:  epoch  0, batch   201 | loss: 3.2199712
MixupTrain:  epoch  0, batch   202 | loss: 2.7834816
MixupTrain:  epoch  0, batch   203 | loss: 3.5923641
MixupTrain:  epoch  0, batch   204 | loss: 3.0533104
MixupTrain:  epoch  0, batch   205 | loss: 3.1738248
MixupTrain:  epoch  0, batch   206 | loss: 3.7072222
MixupTrain:  epoch  0, batch   207 | loss: 2.9669147
MixupTrain:  epoch  0, batch   208 | loss: 3.5367279
MixupTrain:  epoch  0, batch   209 | loss: 2.6289973
MixupTrain:  epoch  0, batch   210 | loss: 3.3206363
MixupTrain:  epoch  0, batch   211 | loss: 3.6930957
MixupTrain:  epoch  0, batch   212 | loss: 2.9600987
MixupTrain:  epoch  0, batch   213 | loss: 3.0690250
MixupTrain:  epoch  0, batch   214 | loss: 2.6704676
MixupTrain:  epoch  0, batch   215 | loss: 3.1469469
MixupTrain:  epoch  0, batch   216 | loss: 3.2241392
MixupTrain:  epoch  0, batch   217 | loss: 2.8064003
MixupTrain:  epoch  0, batch   218 | loss: 3.1690130
MixupTrain:  epoch  0, batch   219 | loss: 2.6969013
MixupTrain:  epoch  0, batch   220 | loss: 3.2519944
MixupTrain:  epoch  0, batch   221 | loss: 3.7091551
MixupTrain:  epoch  0, batch   222 | loss: 3.4713335
MixupTrain:  epoch  0, batch   223 | loss: 3.2202296
MixupTrain:  epoch  0, batch   224 | loss: 3.4866600
MixupTrain:  epoch  0, batch   225 | loss: 3.1513634
MixupTrain:  epoch  0, batch   226 | loss: 3.3202615
MixupTrain:  epoch  0, batch   227 | loss: 3.6834660
MixupTrain:  epoch  0, batch   228 | loss: 3.0228643
MixupTrain:  epoch  0, batch   229 | loss: 3.1594057
MixupTrain:  epoch  0, batch   230 | loss: 3.5937362
MixupTrain:  epoch  0, batch   231 | loss: 3.9809217
MixupTrain:  epoch  0, batch   232 | loss: 3.5065110
MixupTrain:  epoch  0, batch   233 | loss: 2.4120507
MixupTrain:  epoch  0, batch   234 | loss: 3.1535048
MixupTrain:  epoch  0, batch   235 | loss: 2.5762596
MixupTrain:  epoch  0, batch   236 | loss: 3.9088168
MixupTrain:  epoch  0, batch   237 | loss: 2.6488614
MixupTrain:  epoch  0, batch   238 | loss: 3.3104367
MixupTrain:  epoch  0, batch   239 | loss: 3.0533881
MixupTrain:  epoch  0, batch   240 | loss: 3.3934507
MixupTrain:  epoch  0, batch   241 | loss: 2.7078714
MixupTrain:  epoch  0, batch   242 | loss: 3.4840155
MixupTrain:  epoch  0, batch   243 | loss: 2.4990814
MixupTrain:  epoch  0, batch   244 | loss: 3.3653417
MixupTrain:  epoch  0, batch   245 | loss: 3.6814861
MixupTrain:  epoch  0, batch   246 | loss: 2.6801133
MixupTrain:  epoch  0, batch   247 | loss: 3.6718667
MixupTrain:  epoch  0, batch   248 | loss: 3.7586751
MixupTrain:  epoch  0, batch   249 | loss: 3.3141241
MixupTrain:  epoch  0, batch   250 | loss: 3.4224887
MixupTrain:  epoch  0, batch   251 | loss: 3.2935288
MixupTrain:  epoch  0, batch   252 | loss: 2.4610510
MixupTrain:  epoch  0, batch   253 | loss: 3.4716203
MixupTrain:  epoch  0, batch   254 | loss: 3.0757029
MixupTrain:  epoch  0, batch   255 | loss: 2.8767576
MixupTrain:  epoch  0, batch   256 | loss: 2.5063782
MixupTrain:  epoch  0, batch   257 | loss: 3.4191289
MixupTrain:  epoch  0, batch   258 | loss: 2.6731400
MixupTrain:  epoch  0, batch   259 | loss: 2.9155893
MixupTrain:  epoch  0, batch   260 | loss: 3.2754402
MixupTrain:  epoch  0, batch   261 | loss: 2.8510115
MixupTrain:  epoch  0, batch   262 | loss: 3.1023669
MixupTrain:  epoch  0, batch   263 | loss: 2.6235080
MixupTrain:  epoch  0, batch   264 | loss: 3.5310326
MixupTrain:  epoch  0, batch   265 | loss: 2.9983845
MixupTrain:  epoch  0, batch   266 | loss: 3.1915417
MixupTrain:  epoch  0, batch   267 | loss: 2.9137750
MixupTrain:  epoch  0, batch   268 | loss: 3.0336418
MixupTrain:  epoch  0, batch   269 | loss: 3.6068215
MixupTrain:  epoch  0, batch   270 | loss: 2.9492621
MixupTrain:  epoch  0, batch   271 | loss: 2.9595537
MixupTrain:  epoch  0, batch   272 | loss: 2.6454349
MixupTrain:  epoch  0, batch   273 | loss: 2.8745403
MixupTrain:  epoch  0, batch   274 | loss: 2.6783352
MixupTrain:  epoch  0, batch   275 | loss: 3.5359912
MixupTrain:  epoch  0, batch   276 | loss: 3.3108306
MixupTrain:  epoch  0, batch   277 | loss: 3.4484816
MixupTrain:  epoch  0, batch   278 | loss: 2.3897243
MixupTrain:  epoch  0, batch   279 | loss: 3.3794370
MixupTrain:  epoch  0, batch   280 | loss: 2.8764687
MixupTrain:  epoch  0, batch   281 | loss: 3.7122798
MixupTrain:  epoch  0, batch   282 | loss: 2.8616652
MixupTrain:  epoch  0, batch   283 | loss: 3.1997516
MixupTrain:  epoch  0, batch   284 | loss: 2.6075721
MixupTrain:  epoch  0, batch   285 | loss: 2.7773490
MixupTrain:  epoch  0, batch   286 | loss: 2.9179482
MixupTrain:  epoch  0, batch   287 | loss: 2.7627218
MixupTrain:  epoch  0, batch   288 | loss: 3.5598478
MixupTrain:  epoch  0, batch   289 | loss: 2.8126123
MixupTrain:  epoch  0, batch   290 | loss: 2.9049649
MixupTrain:  epoch  0, batch   291 | loss: 3.6246457
MixupTrain:  epoch  0, batch   292 | loss: 2.9790347
MixupTrain:  epoch  0, batch   293 | loss: 3.3204381
MixupTrain:  epoch  0, batch   294 | loss: 2.8636467
MixupTrain:  epoch  0, batch   295 | loss: 2.5753222
MixupTrain:  epoch  0, batch   296 | loss: 3.4402714
MixupTrain:  epoch  0, batch   297 | loss: 2.9288144
MixupTrain:  epoch  0, batch   298 | loss: 3.2648141
MixupTrain:  epoch  0, batch   299 | loss: 2.8041849
MixupTrain:  epoch  0, batch   300 | loss: 2.9824953
MixupTrain:  epoch  0, batch   301 | loss: 3.0417409
MixupTrain:  epoch  0, batch   302 | loss: 3.0973341
MixupTrain:  epoch  0, batch   303 | loss: 2.9484897
MixupTrain:  epoch  0, batch   304 | loss: 3.5260510
MixupTrain:  epoch  0, batch   305 | loss: 3.5772877
MixupTrain:  epoch  0, batch   306 | loss: 2.9716432
MixupTrain:  epoch  0, batch   307 | loss: 3.6464617
MixupTrain:  epoch  0, batch   308 | loss: 3.0348804
MixupTrain:  epoch  0, batch   309 | loss: 2.7898316
MixupTrain:  epoch  0, batch   310 | loss: 3.1403282
MixupTrain:  epoch  0, batch   311 | loss: 3.2397733
MixupTrain:  epoch  0, batch   312 | loss: 2.7700586
MixupTrain:  epoch  0, batch   313 | loss: 2.3891594
MixupTrain:  epoch  0, batch   314 | loss: 2.8344631
MixupTrain:  epoch  0, batch   315 | loss: 2.8129537
MixupTrain:  epoch  0, batch   316 | loss: 2.8430734
MixupTrain:  epoch  0, batch   317 | loss: 2.5719748
MixupTrain:  epoch  0, batch   318 | loss: 3.1569614
MixupTrain:  epoch  0, batch   319 | loss: 3.0422564
MixupTrain:  epoch  0, batch   320 | loss: 2.7233000
MixupTrain:  epoch  0, batch   321 | loss: 3.6192799
MixupTrain:  epoch  0, batch   322 | loss: 3.0429416
MixupTrain:  epoch  0, batch   323 | loss: 2.7966719
MixupTrain:  epoch  0, batch   324 | loss: 2.4808266
MixupTrain:  epoch  0, batch   325 | loss: 2.6244073
MixupTrain:  epoch  0, batch   326 | loss: 2.9450164
MixupTrain:  epoch  0, batch   327 | loss: 3.0338387
MixupTrain:  epoch  0, batch   328 | loss: 2.6951389
MixupTrain:  epoch  0, batch   329 | loss: 2.8517127
MixupTrain:  epoch  0, batch   330 | loss: 2.8506751
MixupTrain:  epoch  0, batch   331 | loss: 3.2009346
MixupTrain:  epoch  0, batch   332 | loss: 3.7770646
MixupTrain:  epoch  0, batch   333 | loss: 3.3659563
MixupTrain:  epoch  0, batch   334 | loss: 3.2269797
MixupTrain:  epoch  0, batch   335 | loss: 2.6926510
MixupTrain:  epoch  0, batch   336 | loss: 3.1652093
MixupTrain:  epoch  0, batch   337 | loss: 3.3266525
MixupTrain:  epoch  0, batch   338 | loss: 3.3281469
MixupTrain:  epoch  0, batch   339 | loss: 2.7977819
MixupTrain:  epoch  0, batch   340 | loss: 3.1894107
MixupTrain:  epoch  0, batch   341 | loss: 3.1704013
MixupTrain:  epoch  0, batch   342 | loss: 2.9395461
MixupTrain:  epoch  0, batch   343 | loss: 2.8018043
MixupTrain:  epoch  0, batch   344 | loss: 2.7405946
MixupTrain:  epoch  0, batch   345 | loss: 3.4636385
MixupTrain:  epoch  0, batch   346 | loss: 2.4445176
MixupTrain:  epoch  0, batch   347 | loss: 2.8930964
MixupTrain:  epoch  0, batch   348 | loss: 2.6978583
MixupTrain:  epoch  0, batch   349 | loss: 3.0646036
MixupTrain:  epoch  0, batch   350 | loss: 3.6493583
MixupTrain:  epoch  0, batch   351 | loss: 3.1233535
MixupTrain:  epoch  0, batch   352 | loss: 3.4783936
MixupTrain:  epoch  0, batch   353 | loss: 3.1407547
MixupTrain:  epoch  0, batch   354 | loss: 2.8574791
MixupTrain:  epoch  0, batch   355 | loss: 2.8691702
MixupTrain:  epoch  0, batch   356 | loss: 3.0388024
MixupTrain:  epoch  0, batch   357 | loss: 2.4644570
MixupTrain:  epoch  0, batch   358 | loss: 3.3237696
MixupTrain:  epoch  0, batch   359 | loss: 2.6004395
MixupTrain:  epoch  0, batch   360 | loss: 3.6069000
MixupTrain:  epoch  0, batch   361 | loss: 3.0320570
MixupTrain:  epoch  0, batch   362 | loss: 2.9182439
MixupTrain:  epoch  0, batch   363 | loss: 2.4834177
MixupTrain:  epoch  0, batch   364 | loss: 3.4435577
MixupTrain:  epoch  0, batch   365 | loss: 3.1728477
MixupTrain:  epoch  0, batch   366 | loss: 2.6512413
MixupTrain:  epoch  0, batch   367 | loss: 3.7352195
MixupTrain:  epoch  0, batch   368 | loss: 2.8720245
MixupTrain:  epoch  0, batch   369 | loss: 2.3108864
MixupTrain:  epoch  0, batch   370 | loss: 2.7075827
MixupTrain:  epoch  0, batch   371 | loss: 2.6975007
MixupTrain:  epoch  0, batch   372 | loss: 3.1641080
MixupTrain:  epoch  0, batch   373 | loss: 3.3998022
MixupTrain:  epoch  0, batch   374 | loss: 3.4601479
MixupTrain:  epoch  0, batch   375 | loss: 2.9216795
MixupTrain:  epoch  0, batch   376 | loss: 2.4798412
MixupTrain:  epoch  0, batch   377 | loss: 2.6064246
MixupTrain:  epoch  0, batch   378 | loss: 2.9111991
MixupTrain:  epoch  0, batch   379 | loss: 3.0952206
MixupTrain:  epoch  0, batch   380 | loss: 3.2031705
MixupTrain:  epoch  0, batch   381 | loss: 2.7232323
MixupTrain:  epoch  0, batch   382 | loss: 3.2616863
MixupTrain:  epoch  0, batch   383 | loss: 3.5828321
MixupTrain:  epoch  0, batch   384 | loss: 2.6170044
MixupTrain:  epoch  0, batch   385 | loss: 2.9477148
MixupTrain:  epoch  0, batch   386 | loss: 3.3596468
MixupTrain:  epoch  0, batch   387 | loss: 2.6694584
MixupTrain:  epoch  0, batch   388 | loss: 2.7072134
MixupTrain:  epoch  0, batch   389 | loss: 3.1998677
MixupTrain:  epoch  0, batch   390 | loss: 3.1832066
MixupTrain:  epoch  0, batch   391 | loss: 2.4883857
MixupTrain:  epoch  0, batch   392 | loss: 2.7605121
MixupTrain:  epoch  0, batch   393 | loss: 2.7630131
MixupTrain:  epoch  0, batch   394 | loss: 2.2934151
MixupTrain:  epoch  0, batch   395 | loss: 2.9273100
MixupTrain:  epoch  0, batch   396 | loss: 3.4912505
MixupTrain:  epoch  0, batch   397 | loss: 3.3060350
MixupTrain:  epoch  0, batch   398 | loss: 3.0180984
MixupTrain:  epoch  0, batch   399 | loss: 3.4735847
MixupTrain:  epoch  0, batch   400 | loss: 2.9970760
MixupTrain:  epoch  0, batch   401 | loss: 2.8472066
MixupTrain:  epoch  0, batch   402 | loss: 2.8886070
MixupTrain:  epoch  0, batch   403 | loss: 2.7971032
MixupTrain:  epoch  0, batch   404 | loss: 2.8023329
MixupTrain:  epoch  0, batch   405 | loss: 2.5814748
MixupTrain:  epoch  0, batch   406 | loss: 3.0906420
MixupTrain:  epoch  0, batch   407 | loss: 2.8479934
MixupTrain:  epoch  0, batch   408 | loss: 2.7210219
MixupTrain:  epoch  0, batch   409 | loss: 2.8060682
MixupTrain:  epoch  0, batch   410 | loss: 3.0022783
MixupTrain:  epoch  0, batch   411 | loss: 3.3986063
MixupTrain:  epoch  0, batch   412 | loss: 2.9282091
MixupTrain:  epoch  0, batch   413 | loss: 3.3580165
MixupTrain:  epoch  0, batch   414 | loss: 2.8574233
MixupTrain:  epoch  0, batch   415 | loss: 2.7419815
MixupTrain:  epoch  0, batch   416 | loss: 3.2411628
MixupTrain:  epoch  0, batch   417 | loss: 3.2586162
MixupTrain:  epoch  0, batch   418 | loss: 2.4228034
MixupTrain:  epoch  0, batch   419 | loss: 2.6140137
MixupTrain:  epoch  0, batch   420 | loss: 2.8764868
MixupTrain:  epoch  0, batch   421 | loss: 2.6302810
MixupTrain:  epoch  0, batch   422 | loss: 3.5026877
MixupTrain:  epoch  0, batch   423 | loss: 3.1376035
MixupTrain:  epoch  0, batch   424 | loss: 3.0136247
MixupTrain:  epoch  0, batch   425 | loss: 2.9881425
MixupTrain:  epoch  0, batch   426 | loss: 3.1026371
MixupTrain:  epoch  0, batch   427 | loss: 2.8291769
MixupTrain:  epoch  0, batch   428 | loss: 3.1172614
MixupTrain:  epoch  0, batch   429 | loss: 3.5538898
MixupTrain:  epoch  0, batch   430 | loss: 3.0933251
MixupTrain:  epoch  0, batch   431 | loss: 2.9816060
MixupTrain:  epoch  0, batch   432 | loss: 2.9537559
MixupTrain:  epoch  0, batch   433 | loss: 2.9880915
MixupTrain:  epoch  0, batch   434 | loss: 3.1529880
MixupTrain:  epoch  0, batch   435 | loss: 3.4566154
MixupTrain:  epoch  0, batch   436 | loss: 3.3249388
MixupTrain:  epoch  0, batch   437 | loss: 2.8304865
MixupTrain:  epoch  0, batch   438 | loss: 2.7275748
MixupTrain:  epoch  0, batch   439 | loss: 2.6293068
MixupTrain:  epoch  0, batch   440 | loss: 2.6853502
MixupTrain:  epoch  0, batch   441 | loss: 2.7527475
MixupTrain:  epoch  0, batch   442 | loss: 3.1636028
MixupTrain:  epoch  0, batch   443 | loss: 3.0156765
MixupTrain:  epoch  0, batch   444 | loss: 2.9328749
MixupTrain:  epoch  0, batch   445 | loss: 2.6709723
MixupTrain:  epoch  0, batch   446 | loss: 2.6951141
MixupTrain:  epoch  0, batch   447 | loss: 3.1865296
MixupTrain:  epoch  0, batch   448 | loss: 2.6698580
MixupTrain:  epoch  0, batch   449 | loss: 3.1440639
MixupTrain:  epoch  0, batch   450 | loss: 3.5671411
MixupTrain:  epoch  0, batch   451 | loss: 3.1500282
MixupTrain:  epoch  0, batch   452 | loss: 2.8315620
MixupTrain:  epoch  0, batch   453 | loss: 2.6799636
MixupTrain:  epoch  0, batch   454 | loss: 2.7059257
MixupTrain:  epoch  0, batch   455 | loss: 3.0561228
MixupTrain:  epoch  0, batch   456 | loss: 2.5091162
MixupTrain:  epoch  0, batch   457 | loss: 2.9688101
MixupTrain:  epoch  0, batch   458 | loss: 2.7079802
MixupTrain:  epoch  0, batch   459 | loss: 2.9927564
MixupTrain:  epoch  0, batch   460 | loss: 3.1693215
MixupTrain:  epoch  0, batch   461 | loss: 3.2134113
MixupTrain:  epoch  0, batch   462 | loss: 3.1798623
MixupTrain:  epoch  0, batch   463 | loss: 3.2725186
MixupTrain:  epoch  0, batch   464 | loss: 2.3722296
MixupTrain:  epoch  0, batch   465 | loss: 3.1641107
MixupTrain:  epoch  0, batch   466 | loss: 3.6026864
MixupTrain:  epoch  0, batch   467 | loss: 3.2775321
MixupTrain:  epoch  0, batch   468 | loss: 2.6346483
MixupTrain:  epoch  0, batch   469 | loss: 3.3331804
MixupTrain:  epoch  0, batch   470 | loss: 2.6905532
MixupTrain:  epoch  0, batch   471 | loss: 2.9105258
MixupTrain:  epoch  0, batch   472 | loss: 2.9375648
MixupTrain:  epoch  0, batch   473 | loss: 3.4930758
MixupTrain:  epoch  0, batch   474 | loss: 2.8948376
MixupTrain:  epoch  0, batch   475 | loss: 2.7748981
MixupTrain:  epoch  0, batch   476 | loss: 2.9990573
MixupTrain:  epoch  0, batch   477 | loss: 3.2307589
MixupTrain:  epoch  0, batch   478 | loss: 3.3907917
MixupTrain:  epoch  0, batch   479 | loss: 3.0525584
MixupTrain:  epoch  0, batch   480 | loss: 2.8747811
MixupTrain:  epoch  0, batch   481 | loss: 3.0570271
MixupTrain:  epoch  0, batch   482 | loss: 3.2706032
MixupTrain:  epoch  0, batch   483 | loss: 3.1295600
MixupTrain:  epoch  0, batch   484 | loss: 3.1472232
MixupTrain:  epoch  0, batch   485 | loss: 3.0631042
MixupTrain:  epoch  0, batch   486 | loss: 2.1785488
MixupTrain:  epoch  0, batch   487 | loss: 3.2348852
MixupTrain:  epoch  0, batch   488 | loss: 3.2356396
MixupTrain:  epoch  0, batch   489 | loss: 2.9241135
MixupTrain:  epoch  0, batch   490 | loss: 2.7270937
MixupTrain:  epoch  0, batch   491 | loss: 2.9051595
MixupTrain:  epoch  0, batch   492 | loss: 3.0001273
MixupTrain:  epoch  0, batch   493 | loss: 2.9844556
MixupTrain:  epoch  0, batch   494 | loss: 3.4152381
MixupTrain:  epoch  0, batch   495 | loss: 3.1474776
MixupTrain:  epoch  0, batch   496 | loss: 3.5264392
MixupTrain:  epoch  0, batch   497 | loss: 2.7425599
MixupTrain:  epoch  0, batch   498 | loss: 2.8517079
MixupTrain:  epoch  0, batch   499 | loss: 2.7738988
MixupTrain:  epoch  0, batch   500 | loss: 2.8524895
MixupTrain:  epoch  0, batch   501 | loss: 3.2269464
MixupTrain:  epoch  0, batch   502 | loss: 2.9676921
MixupTrain:  epoch  0, batch   503 | loss: 2.5842731
MixupTrain:  epoch  0, batch   504 | loss: 3.2724133
MixupTrain:  epoch  0, batch   505 | loss: 3.0860603
MixupTrain:  epoch  0, batch   506 | loss: 3.2303820
MixupTrain:  epoch  0, batch   507 | loss: 2.8898387
MixupTrain:  epoch  0, batch   508 | loss: 3.0362191
MixupTrain:  epoch  0, batch   509 | loss: 2.9733829
MixupTrain:  epoch  0, batch   510 | loss: 2.8693810
MixupTrain:  epoch  0, batch   511 | loss: 2.9681358
MixupTrain:  epoch  0, batch   512 | loss: 3.0002441
MixupTrain:  epoch  0, batch   513 | loss: 2.9020038
MixupTrain:  epoch  0, batch   514 | loss: 3.1340780
MixupTrain:  epoch  0, batch   515 | loss: 3.3390017
MixupTrain:  epoch  0, batch   516 | loss: 2.8669152
MixupTrain:  epoch  0, batch   517 | loss: 2.8780227
MixupTrain:  epoch  0, batch   518 | loss: 2.5719676
MixupTrain:  epoch  0, batch   519 | loss: 3.6849890
MixupTrain:  epoch  0, batch   520 | loss: 3.2918854
MixupTrain:  epoch  0, batch   521 | loss: 2.8085084
MixupTrain:  epoch  0, batch   522 | loss: 3.3841352
MixupTrain:  epoch  0, batch   523 | loss: 2.8306913
MixupTrain:  epoch  0, batch   524 | loss: 2.4453075
MixupTrain:  epoch  0, batch   525 | loss: 3.3417120
MixupTrain:  epoch  0, batch   526 | loss: 2.8710747
MixupTrain:  epoch  0, batch   527 | loss: 3.0839942
MixupTrain:  epoch  0, batch   528 | loss: 2.8589368
MixupTrain:  epoch  0, batch   529 | loss: 3.0419025
MixupTrain:  epoch  0, batch   530 | loss: 3.1012325
MixupTrain:  epoch  0, batch   531 | loss: 3.0596697
MixupTrain:  epoch  0, batch   532 | loss: 2.9643555
MixupTrain:  epoch  0, batch   533 | loss: 2.7477806
MixupTrain:  epoch  0, batch   534 | loss: 3.4540553
MixupTrain:  epoch  0, batch   535 | loss: 3.0380595
MixupTrain:  epoch  0, batch   536 | loss: 2.8375528
MixupTrain:  epoch  0, batch   537 | loss: 2.7482677
MixupTrain:  epoch  0, batch   538 | loss: 3.4091537
MixupTrain:  epoch  0, batch   539 | loss: 2.5077105
MixupTrain:  epoch  0, batch   540 | loss: 2.5349352
MixupTrain:  epoch  0, batch   541 | loss: 2.8103423
MixupTrain:  epoch  0, batch   542 | loss: 2.8312397
MixupTrain:  epoch  0, batch   543 | loss: 3.0713825
MixupTrain:  epoch  0, batch   544 | loss: 2.9828169
MixupTrain:  epoch  0, batch   545 | loss: 2.9041185
MixupTrain:  epoch  0, batch   546 | loss: 2.6550858
MixupTrain:  epoch  0, batch   547 | loss: 2.8920135
MixupTrain:  epoch  0, batch   548 | loss: 2.9496942
MixupTrain:  epoch  0, batch   549 | loss: 2.8259072
MixupTrain:  epoch  0, batch   550 | loss: 2.7725782
MixupTrain:  epoch  0, batch   551 | loss: 3.0165343
MixupTrain:  epoch  0, batch   552 | loss: 2.7394505
MixupTrain:  epoch  0, batch   553 | loss: 3.8407655
MixupTrain:  epoch  0, batch   554 | loss: 2.6613379
MixupTrain:  epoch  0, batch   555 | loss: 3.1697807
MixupTrain:  epoch  0, batch   556 | loss: 3.0078919
MixupTrain:  epoch  0, batch   557 | loss: 3.3382492
MixupTrain:  epoch  0, batch   558 | loss: 3.1980410
MixupTrain:  epoch  0, batch   559 | loss: 2.8787794
MixupTrain:  epoch  0, batch   560 | loss: 3.9112277
MixupTrain:  epoch  0, batch   561 | loss: 2.5915990
MixupTrain:  epoch  0, batch   562 | loss: 2.9056282
MixupTrain:  epoch  0, batch   563 | loss: 2.8544378
MixupTrain:  epoch  0, batch   564 | loss: 3.2325964
MixupTrain:  epoch  0, batch   565 | loss: 3.0342836
MixupTrain:  epoch  0, batch   566 | loss: 2.7132864
MixupTrain:  epoch  0, batch   567 | loss: 2.8351014
MixupTrain:  epoch  0, batch   568 | loss: 2.8116698
MixupTrain:  epoch  0, batch   569 | loss: 3.3158875
MixupTrain:  epoch  0, batch   570 | loss: 2.7630782
MixupTrain:  epoch  0, batch   571 | loss: 2.9975953
MixupTrain:  epoch  0, batch   572 | loss: 3.2161319
MixupTrain:  epoch  0, batch   573 | loss: 3.3447218
MixupTrain:  epoch  0, batch   574 | loss: 2.6744516
MixupTrain:  epoch  0, batch   575 | loss: 3.1273024
MixupTrain:  epoch  0, batch   576 | loss: 2.7559962
MixupTrain:  epoch  0, batch   577 | loss: 3.0195391
MixupTrain:  epoch  0, batch   578 | loss: 2.9347882
MixupTrain:  epoch  0, batch   579 | loss: 3.1746147
MixupTrain:  epoch  0, batch   580 | loss: 2.4994147
MixupTrain:  epoch  0, batch   581 | loss: 2.9217393
MixupTrain:  epoch  0, batch   582 | loss: 3.2839074
MixupTrain:  epoch  0, batch   583 | loss: 2.6850574
MixupTrain:  epoch  0, batch   584 | loss: 3.5014563
MixupTrain:  epoch  0, batch   585 | loss: 2.8419213
MixupTrain:  epoch  0, batch   586 | loss: 2.8522890
MixupTrain:  epoch  0, batch   587 | loss: 2.6503825
MixupTrain:  epoch  0, batch   588 | loss: 3.1127639
MixupTrain:  epoch  0, batch   589 | loss: 3.1194663
MixupTrain:  epoch  0, batch   590 | loss: 2.7204976
MixupTrain:  epoch  0, batch   591 | loss: 2.9445319
MixupTrain:  epoch  0, batch   592 | loss: 2.6634598
MixupTrain:  epoch  0, batch   593 | loss: 3.1544914
MixupTrain:  epoch  0, batch   594 | loss: 2.6155770
MixupTrain:  epoch  0, batch   595 | loss: 3.4037485
MixupTrain:  epoch  0, batch   596 | loss: 3.0048032
MixupTrain:  epoch  0, batch   597 | loss: 3.1405854
MixupTrain:  epoch  0, batch   598 | loss: 2.9622223
MixupTrain:  epoch  0, batch   599 | loss: 2.3563085
MixupTrain:  epoch  0, batch   600 | loss: 2.6678009
MixupTrain:  epoch  0, batch   601 | loss: 2.7511508
MixupTrain:  epoch  0, batch   602 | loss: 2.9391026
MixupTrain:  epoch  0, batch   603 | loss: 2.4510727
MixupTrain:  epoch  0, batch   604 | loss: 3.5261073
MixupTrain:  epoch  0, batch   605 | loss: 2.8108442
MixupTrain:  epoch  0, batch   606 | loss: 3.4505007
MixupTrain:  epoch  0, batch   607 | loss: 3.0179052
MixupTrain:  epoch  0, batch   608 | loss: 3.2207870
MixupTrain:  epoch  0, batch   609 | loss: 2.0718393
MixupTrain:  epoch  0, batch   610 | loss: 3.2265115
MixupTrain:  epoch  0, batch   611 | loss: 2.7914996
MixupTrain:  epoch  0, batch   612 | loss: 2.8824930
MixupTrain:  epoch  0, batch   613 | loss: 2.5690019
MixupTrain:  epoch  0, batch   614 | loss: 2.7654881
MixupTrain:  epoch  0, batch   615 | loss: 2.8684659
MixupTrain:  epoch  0, batch   616 | loss: 2.5682020
MixupTrain:  epoch  0, batch   617 | loss: 2.8473120
MixupTrain:  epoch  0, batch   618 | loss: 3.2752895
MixupTrain:  epoch  0, batch   619 | loss: 2.7934034
MixupTrain:  epoch  0, batch   620 | loss: 3.2785830
MixupTrain:  epoch  0, batch   621 | loss: 2.7108588
MixupTrain:  epoch  0, batch   622 | loss: 2.9019763
MixupTrain:  epoch  0, batch   623 | loss: 3.3820238
MixupTrain:  epoch  0, batch   624 | loss: 3.0161777
MixupTrain:  epoch  0, batch   625 | loss: 3.2765317
MixupTrain:  epoch  0, batch   626 | loss: 2.5276775
MixupTrain:  epoch  0, batch   627 | loss: 3.4623961
MixupTrain:  epoch  0, batch   628 | loss: 2.9453800
MixupTrain:  epoch  0, batch   629 | loss: 3.1612945
MixupTrain:  epoch  0, batch   630 | loss: 2.7840710
MixupTrain:  epoch  0, batch   631 | loss: 2.3943675
MixupTrain:  epoch  0, batch   632 | loss: 3.3798618
MixupTrain:  epoch  0, batch   633 | loss: 2.5072162
MixupTrain:  epoch  0, batch   634 | loss: 2.8330827
MixupTrain:  epoch  0, batch   635 | loss: 2.8221912
MixupTrain:  epoch  0, batch   636 | loss: 3.1510668
MixupTrain:  epoch  0, batch   637 | loss: 2.5859380
MixupTrain:  epoch  0, batch   638 | loss: 2.9004228
MixupTrain:  epoch  0, batch   639 | loss: 2.7537112
MixupTrain:  epoch  0, batch   640 | loss: 2.6501391
MixupTrain:  epoch  0, batch   641 | loss: 3.1894126
MixupTrain:  epoch  0, batch   642 | loss: 3.0590286
MixupTrain:  epoch  0, batch   643 | loss: 2.8705790
MixupTrain:  epoch  0, batch   644 | loss: 2.9251428
MixupTrain:  epoch  0, batch   645 | loss: 2.8592949
MixupTrain:  epoch  0, batch   646 | loss: 3.1758215
MixupTrain:  epoch  0, batch   647 | loss: 3.0268397
MixupTrain:  epoch  0, batch   648 | loss: 2.8343518
MixupTrain:  epoch  0, batch   649 | loss: 3.4551604
MixupTrain:  epoch  0, batch   650 | loss: 3.6380861
MixupTrain:  epoch  0, batch   651 | loss: 3.2806053
MixupTrain:  epoch  0, batch   652 | loss: 3.3518322
MixupTrain:  epoch  0, batch   653 | loss: 2.8602319
MixupTrain:  epoch  0, batch   654 | loss: 2.9400966
MixupTrain:  epoch  0, batch   655 | loss: 3.0801852
MixupTrain:  epoch  0, batch   656 | loss: 2.6405523
MixupTrain:  epoch  0, batch   657 | loss: 2.8844807
MixupTrain:  epoch  0, batch   658 | loss: 2.5972950
MixupTrain:  epoch  0, batch   659 | loss: 2.9229069
MixupTrain:  epoch  0, batch   660 | loss: 2.7804613
MixupTrain:  epoch  0, batch   661 | loss: 3.3951554
MixupTrain:  epoch  0, batch   662 | loss: 2.9699681
MixupTrain:  epoch  0, batch   663 | loss: 2.5347564
MixupTrain:  epoch  0, batch   664 | loss: 2.9457040
MixupTrain:  epoch  0, batch   665 | loss: 3.2040854
MixupTrain:  epoch  0, batch   666 | loss: 2.9536452
MixupTrain:  epoch  0, batch   667 | loss: 3.2861416
MixupTrain:  epoch  0, batch   668 | loss: 2.9450924
MixupTrain:  epoch  0, batch   669 | loss: 2.9272647
MixupTrain:  epoch  0, batch   670 | loss: 2.8185067
MixupTrain:  epoch  0, batch   671 | loss: 2.6045094
MixupTrain:  epoch  0, batch   672 | loss: 2.8283343
MixupTrain:  epoch  0, batch   673 | loss: 3.2159081
MixupTrain:  epoch  0, batch   674 | loss: 3.8905787
MixupTrain:  epoch  0, batch   675 | loss: 2.6423786
MixupTrain:  epoch  0, batch   676 | loss: 2.7274997
MixupTrain:  epoch  0, batch   677 | loss: 2.8761187
MixupTrain:  epoch  0, batch   678 | loss: 2.5223591
MixupTrain:  epoch  0, batch   679 | loss: 3.0169058
MixupTrain:  epoch  0, batch   680 | loss: 2.4509330
MixupTrain:  epoch  0, batch   681 | loss: 2.8048723
MixupTrain:  epoch  0, batch   682 | loss: 2.1119506
MixupTrain:  epoch  0, batch   683 | loss: 3.1728010
MixupTrain:  epoch  0, batch   684 | loss: 2.9831536
MixupTrain:  epoch  0, batch   685 | loss: 2.6944170
MixupTrain:  epoch  0, batch   686 | loss: 3.5225801
MixupTrain:  epoch  0, batch   687 | loss: 3.1805906
MixupTrain:  epoch  0, batch   688 | loss: 2.6786473
MixupTrain:  epoch  0, batch   689 | loss: 3.0249982
MixupTrain:  epoch  0, batch   690 | loss: 3.2027216
MixupTrain:  epoch  0, batch   691 | loss: 2.6424627
MixupTrain:  epoch  0, batch   692 | loss: 2.6220739
MixupTrain:  epoch  0, batch   693 | loss: 2.8301549
MixupTrain:  epoch  0, batch   694 | loss: 2.3505821
MixupTrain:  epoch  0, batch   695 | loss: 3.7175274
MixupTrain:  epoch  0, batch   696 | loss: 3.0525651
MixupTrain:  epoch  0, batch   697 | loss: 2.8845236
MixupTrain:  epoch  0, batch   698 | loss: 2.1664829
MixupTrain:  epoch  0, batch   699 | loss: 3.2056108
MixupTrain:  epoch  0, batch   700 | loss: 3.2729301
MixupTrain:  epoch  0, batch   701 | loss: 2.8263667
MixupTrain:  epoch  0, batch   702 | loss: 3.1743813
MixupTrain:  epoch  0, batch   703 | loss: 2.6023099
MixupTrain:  epoch  0, batch   704 | loss: 2.3475504
MixupTrain:  epoch  0, batch   705 | loss: 2.7203803
MixupTrain:  epoch  0, batch   706 | loss: 2.9248791
MixupTrain:  epoch  0, batch   707 | loss: 2.7370045
MixupTrain:  epoch  0, batch   708 | loss: 2.7012343
MixupTrain:  epoch  0, batch   709 | loss: 2.7714691
MixupTrain:  epoch  0, batch   710 | loss: 2.7988305
MixupTrain:  epoch  0, batch   711 | loss: 2.4754124
MixupTrain:  epoch  0, batch   712 | loss: 2.7820201
MixupTrain:  epoch  0, batch   713 | loss: 3.0990391
MixupTrain:  epoch  0, batch   714 | loss: 3.0483248
MixupTrain:  epoch  0, batch   715 | loss: 3.0246172
MixupTrain:  epoch  0, batch   716 | loss: 3.2386045
MixupTrain:  epoch  0, batch   717 | loss: 3.0869198
MixupTrain:  epoch  0, batch   718 | loss: 3.3248978
MixupTrain:  epoch  0, batch   719 | loss: 2.5874372
MixupTrain:  epoch  0, batch   720 | loss: 2.8298631
MixupTrain:  epoch  0, batch   721 | loss: 3.0843363
MixupTrain:  epoch  0, batch   722 | loss: 3.1752124
MixupTrain:  epoch  0, batch   723 | loss: 3.3003917
MixupTrain:  epoch  0, batch   724 | loss: 3.2775784
MixupTrain:  epoch  0, batch   725 | loss: 2.8308918
MixupTrain:  epoch  0, batch   726 | loss: 3.1937394
MixupTrain:  epoch  0, batch   727 | loss: 2.8038540
MixupTrain:  epoch  0, batch   728 | loss: 3.0541136
MixupTrain:  epoch  0, batch   729 | loss: 2.7106996
MixupTrain:  epoch  0, batch   730 | loss: 2.6048546
MixupTrain:  epoch  0, batch   731 | loss: 2.8352964
MixupTrain:  epoch  0, batch   732 | loss: 2.8351054
MixupTrain:  epoch  0, batch   733 | loss: 3.1186905
MixupTrain:  epoch  0, batch   734 | loss: 2.7917356
MixupTrain:  epoch  0, batch   735 | loss: 2.7227495
MixupTrain:  epoch  0, batch   736 | loss: 3.1436281
MixupTrain:  epoch  0, batch   737 | loss: 2.6805878
MixupTrain:  epoch  0, batch   738 | loss: 3.1195858
MixupTrain:  epoch  0, batch   739 | loss: 2.4906209
MixupTrain:  epoch  0, batch   740 | loss: 2.8280447
MixupTrain:  epoch  0, batch   741 | loss: 3.1833675
MixupTrain:  epoch  0, batch   742 | loss: 3.1076298
MixupTrain:  epoch  0, batch   743 | loss: 3.0483346
MixupTrain:  epoch  0, batch   744 | loss: 2.9172854
MixupTrain:  epoch  0, batch   745 | loss: 3.4030099
MixupTrain:  epoch  0, batch   746 | loss: 2.5521154
MixupTrain:  epoch  0, batch   747 | loss: 3.0741956
MixupTrain:  epoch  0, batch   748 | loss: 3.3010011
MixupTrain:  epoch  0, batch   749 | loss: 2.9206765
MixupTrain:  epoch  0, batch   750 | loss: 3.2956820
MixupTrain:  epoch  0, batch   751 | loss: 2.8122721
MixupTrain:  epoch  0, batch   752 | loss: 2.7707930
MixupTrain:  epoch  0, batch   753 | loss: 2.8903692
MixupTrain:  epoch  0, batch   754 | loss: 2.7926831
MixupTrain:  epoch  0, batch   755 | loss: 2.6602898
MixupTrain:  epoch  0, batch   756 | loss: 2.4845724
MixupTrain:  epoch  0, batch   757 | loss: 2.9330974
MixupTrain:  epoch  0, batch   758 | loss: 2.5239501
MixupTrain:  epoch  0, batch   759 | loss: 3.1494770
MixupTrain:  epoch  0, batch   760 | loss: 2.8362021
MixupTrain:  epoch  0, batch   761 | loss: 2.3535008
MixupTrain:  epoch  0, batch   762 | loss: 3.0974267
MixupTrain:  epoch  0, batch   763 | loss: 3.0846982
MixupTrain:  epoch  0, batch   764 | loss: 2.6791003
MixupTrain:  epoch  0, batch   765 | loss: 2.7735674
MixupTrain:  epoch  0, batch   766 | loss: 3.0819669
MixupTrain:  epoch  0, batch   767 | loss: 2.7803793
MixupTrain:  epoch  0, batch   768 | loss: 2.5254259
MixupTrain:  epoch  0, batch   769 | loss: 2.8793530
MixupTrain:  epoch  0, batch   770 | loss: 2.7315099
MixupTrain:  epoch  0, batch   771 | loss: 3.1358371
MixupTrain:  epoch  0, batch   772 | loss: 2.7000539
MixupTrain:  epoch  0, batch   773 | loss: 3.4370284
MixupTrain:  epoch  0, batch   774 | loss: 2.9618421
MixupTrain:  epoch  0, batch   775 | loss: 2.6108866
MixupTrain:  epoch  0, batch   776 | loss: 2.5161672
MixupTrain:  epoch  0, batch   777 | loss: 2.5670137
MixupTrain:  epoch  0, batch   778 | loss: 2.6566091
MixupTrain:  epoch  0, batch   779 | loss: 2.9962959
MixupTrain:  epoch  0, batch   780 | loss: 3.6581106
MixupTrain:  epoch  0, batch   781 | loss: 3.1074052
MixupTrain:  epoch  0, batch   782 | loss: 2.6506500
MixupTrain:  epoch  0, batch   783 | loss: 2.6898925
MixupTrain:  epoch  0, batch   784 | loss: 3.1992280
MixupTrain:  epoch  0, batch   785 | loss: 2.9332967
MixupTrain:  epoch  0, batch   786 | loss: 3.2586386
MixupTrain:  epoch  0, batch   787 | loss: 3.1210549
MixupTrain:  epoch  0, batch   788 | loss: 3.1468477
MixupTrain:  epoch  0, batch   789 | loss: 2.4160664
MixupTrain:  epoch  0, batch   790 | loss: 3.7482381
MixupTrain:  epoch  0, batch   791 | loss: 2.9352326
MixupTrain:  epoch  0, batch   792 | loss: 2.7092285
MixupTrain:  epoch  0, batch   793 | loss: 2.9673238
MixupTrain:  epoch  0, batch   794 | loss: 2.8940430
MixupTrain:  epoch  0, batch   795 | loss: 2.8880785
MixupTrain:  epoch  0, batch   796 | loss: 2.9233360
MixupTrain:  epoch  0, batch   797 | loss: 3.0542107
MixupTrain:  epoch  0, batch   798 | loss: 2.5347083
MixupTrain:  epoch  0, batch   799 | loss: 2.3496203
MixupTrain:  epoch  0, batch   800 | loss: 3.4993339
MixupTrain:  epoch  0, batch   801 | loss: 2.6454306
MixupTrain:  epoch  0, batch   802 | loss: 3.0793736
MixupTrain:  epoch  0, batch   803 | loss: 2.5303025
MixupTrain:  epoch  0, batch   804 | loss: 2.4443767
MixupTrain:  epoch  0, batch   805 | loss: 2.8045216
MixupTrain:  epoch  0, batch   806 | loss: 2.8459883
MixupTrain:  epoch  0, batch   807 | loss: 3.0021095
MixupTrain:  epoch  0, batch   808 | loss: 2.7280135
MixupTrain:  epoch  0, batch   809 | loss: 3.0061584
MixupTrain:  epoch  0, batch   810 | loss: 2.8210468
MixupTrain:  epoch  0, batch   811 | loss: 2.8812442
MixupTrain:  epoch  0, batch   812 | loss: 3.4343474
MixupTrain:  epoch  0, batch   813 | loss: 3.0894415
MixupTrain:  epoch  0, batch   814 | loss: 3.1341002
MixupTrain:  epoch  0, batch   815 | loss: 3.2443995
MixupTrain:  epoch  0, batch   816 | loss: 2.7139912
MixupTrain:  epoch  0, batch   817 | loss: 3.0550318
MixupTrain:  epoch  0, batch   818 | loss: 2.4221025
MixupTrain:  epoch  0, batch   819 | loss: 2.8739371
MixupTrain:  epoch  0, batch   820 | loss: 2.8640575
MixupTrain:  epoch  0, batch   821 | loss: 2.7024438
MixupTrain:  epoch  0, batch   822 | loss: 2.8203077
MixupTrain:  epoch  0, batch   823 | loss: 2.4193208
MixupTrain:  epoch  0, batch   824 | loss: 3.2599239
MixupTrain:  epoch  0, batch   825 | loss: 2.9283230
MixupTrain:  epoch  0, batch   826 | loss: 2.5986249
MixupTrain:  epoch  0, batch   827 | loss: 2.6480217
MixupTrain:  epoch  0, batch   828 | loss: 2.6133099
MixupTrain:  epoch  0, batch   829 | loss: 2.9332895
MixupTrain:  epoch  0, batch   830 | loss: 3.0574226
MixupTrain:  epoch  0, batch   831 | loss: 2.5039637
MixupTrain:  epoch  0, batch   832 | loss: 3.1092801
MixupTrain:  epoch  0, batch   833 | loss: 3.2301278
MixupTrain:  epoch  0, batch   834 | loss: 2.9725728
MixupTrain:  epoch  0, batch   835 | loss: 2.9507558
MixupTrain:  epoch  0, batch   836 | loss: 3.1669903
MixupTrain:  epoch  0, batch   837 | loss: 3.1020861
MixupTrain:  epoch  0, batch   838 | loss: 2.5486956
MixupTrain:  epoch  0, batch   839 | loss: 3.1897635
MixupTrain:  epoch  0, batch   840 | loss: 2.5443308
MixupTrain:  epoch  0, batch   841 | loss: 2.4380374
MixupTrain:  epoch  0, batch   842 | loss: 3.3710146
MixupTrain:  epoch  0, batch   843 | loss: 3.0107388
MixupTrain:  epoch  0, batch   844 | loss: 2.7319858
MixupTrain:  epoch  0, batch   845 | loss: 3.2526021
MixupTrain:  epoch  0, batch   846 | loss: 2.9762883
MixupTrain:  epoch  0, batch   847 | loss: 3.0255578
MixupTrain:  epoch  0, batch   848 | loss: 3.0870266
MixupTrain:  epoch  0, batch   849 | loss: 2.7643819
MixupTrain:  epoch  0, batch   850 | loss: 2.7977581
MixupTrain:  epoch  0, batch   851 | loss: 2.9511585
MixupTrain:  epoch  0, batch   852 | loss: 2.6734309
MixupTrain:  epoch  0, batch   853 | loss: 3.1146173
MixupTrain:  epoch  0, batch   854 | loss: 3.1224265
MixupTrain:  epoch  0, batch   855 | loss: 3.0657754
MixupTrain:  epoch  0, batch   856 | loss: 2.8404055
MixupTrain:  epoch  0, batch   857 | loss: 3.0702894
MixupTrain:  epoch  0, batch   858 | loss: 3.1086569
MixupTrain:  epoch  0, batch   859 | loss: 3.2141926
MixupTrain:  epoch  0, batch   860 | loss: 3.1901202
MixupTrain:  epoch  0, batch   861 | loss: 3.6611073
MixupTrain:  epoch  0, batch   862 | loss: 2.4231439
MixupTrain:  epoch  0, batch   863 | loss: 2.9659710
MixupTrain:  epoch  0, batch   864 | loss: 2.8893347
MixupTrain:  epoch  0, batch   865 | loss: 2.9107957
MixupTrain:  epoch  0, batch   866 | loss: 3.1239896
MixupTrain:  epoch  0, batch   867 | loss: 2.6481495
MixupTrain:  epoch  0, batch   868 | loss: 2.8883429
MixupTrain:  epoch  0, batch   869 | loss: 2.7459664
MixupTrain:  epoch  0, batch   870 | loss: 2.9147253
MixupTrain:  epoch  0, batch   871 | loss: 2.3725617
MixupTrain:  epoch  0, batch   872 | loss: 2.9351311
MixupTrain:  epoch  0, batch   873 | loss: 3.1085382
MixupTrain:  epoch  0, batch   874 | loss: 2.7299948
MixupTrain:  epoch  0, batch   875 | loss: 2.8702574
MixupTrain:  epoch  0, batch   876 | loss: 3.5126669
MixupTrain:  epoch  0, batch   877 | loss: 2.9745111
MixupTrain:  epoch  0, batch   878 | loss: 3.2977133
MixupTrain:  epoch  0, batch   879 | loss: 2.5681508
MixupTrain:  epoch  0, batch   880 | loss: 2.9500766
MixupTrain:  epoch  0, batch   881 | loss: 3.0006490
MixupTrain:  epoch  0, batch   882 | loss: 3.3118498
MixupTrain:  epoch  0, batch   883 | loss: 2.4757991
MixupTrain:  epoch  0, batch   884 | loss: 2.7623405
MixupTrain:  epoch  0, batch   885 | loss: 2.8127227
MixupTrain:  epoch  0, batch   886 | loss: 3.0427368
MixupTrain:  epoch  0, batch   887 | loss: 2.4252267
MixupTrain:  epoch  0, batch   888 | loss: 2.9086232
MixupTrain:  epoch  0, batch   889 | loss: 3.0306168
MixupTrain:  epoch  0, batch   890 | loss: 3.3489447
MixupTrain:  epoch  0, batch   891 | loss: 3.2410369
MixupTrain:  epoch  0, batch   892 | loss: 2.3279746
MixupTrain:  epoch  0, batch   893 | loss: 3.6381807
MixupTrain:  epoch  0, batch   894 | loss: 2.7173991
MixupTrain:  epoch  0, batch   895 | loss: 2.6515942
MixupTrain:  epoch  0, batch   896 | loss: 3.0355587
MixupTrain:  epoch  0, batch   897 | loss: 2.5646691
MixupTrain:  epoch  0, batch   898 | loss: 2.7020841
MixupTrain:  epoch  0, batch   899 | loss: 2.9110806
MixupTrain:  epoch  0, batch   900 | loss: 3.1597092
MixupTrain:  epoch  0, batch   901 | loss: 2.8729534
MixupTrain:  epoch  0, batch   902 | loss: 2.5383496
MixupTrain:  epoch  0, batch   903 | loss: 2.5867391
MixupTrain:  epoch  0, batch   904 | loss: 2.5611475
MixupTrain:  epoch  0, batch   905 | loss: 2.7017221
MixupTrain:  epoch  0, batch   906 | loss: 2.5683179
MixupTrain:  epoch  0, batch   907 | loss: 2.9673686
MixupTrain:  epoch  0, batch   908 | loss: 2.9500608
MixupTrain:  epoch  0, batch   909 | loss: 3.1555448
MixupTrain:  epoch  0, batch   910 | loss: 3.0427310
MixupTrain:  epoch  0, batch   911 | loss: 2.9366064
MixupTrain:  epoch  0, batch   912 | loss: 2.9105401
MixupTrain:  epoch  0, batch   913 | loss: 3.1096823
MixupTrain:  epoch  0, batch   914 | loss: 2.4530151
MixupTrain:  epoch  0, batch   915 | loss: 2.8268480
MixupTrain:  epoch  0, batch   916 | loss: 2.9310832
MixupTrain:  epoch  0, batch   917 | loss: 2.8198373
MixupTrain:  epoch  0, batch   918 | loss: 2.7393718
MixupTrain:  epoch  0, batch   919 | loss: 2.7510226
MixupTrain:  epoch  0, batch   920 | loss: 2.6398356
MixupTrain:  epoch  0, batch   921 | loss: 3.1606345
MixupTrain:  epoch  0, batch   922 | loss: 2.5948043
MixupTrain:  epoch  0, batch   923 | loss: 2.9627693
MixupTrain:  epoch  0, batch   924 | loss: 2.5391018
MixupTrain:  epoch  0, batch   925 | loss: 3.1199956
MixupTrain:  epoch  0, batch   926 | loss: 3.0781965
MixupTrain:  epoch  0, batch   927 | loss: 2.5272648
MixupTrain:  epoch  0, batch   928 | loss: 2.7366505
MixupTrain:  epoch  0, batch   929 | loss: 2.6271198
MixupTrain:  epoch  0, batch   930 | loss: 3.1193318
MixupTrain:  epoch  0, batch   931 | loss: 3.6002476
MixupTrain:  epoch  0, batch   932 | loss: 3.0174308
MixupTrain:  epoch  0, batch   933 | loss: 2.3959532
MixupTrain:  epoch  0, batch   934 | loss: 3.2138057
MixupTrain:  epoch  0, batch   935 | loss: 2.5571022
MixupTrain:  epoch  0, batch   936 | loss: 3.3068440
MixupTrain:  epoch  0, batch   937 | loss: 3.2699296
MixupTrain:  epoch  0, batch   938 | loss: 3.0573492
MixupTrain:  epoch  0, batch   939 | loss: 3.6210418
MixupTrain:  epoch  0, batch   940 | loss: 3.0721915
MixupTrain:  epoch  0, batch   941 | loss: 2.6501284
MixupTrain:  epoch  0, batch   942 | loss: 3.7676933
MixupTrain:  epoch  0, batch   943 | loss: 2.5275769
MixupTrain:  epoch  0, batch   944 | loss: 2.7769823
MixupTrain:  epoch  0, batch   945 | loss: 2.7549849
MixupTrain:  epoch  0, batch   946 | loss: 2.7825236
MixupTrain:  epoch  0, batch   947 | loss: 2.6060793
MixupTrain:  epoch  0, batch   948 | loss: 2.8904729
MixupTrain:  epoch  0, batch   949 | loss: 2.9976652
MixupTrain:  epoch  0, batch   950 | loss: 3.4045272
MixupTrain:  epoch  0, batch   951 | loss: 2.4950070
MixupTrain:  epoch  0, batch   952 | loss: 3.1835890
MixupTrain:  epoch  0, batch   953 | loss: 3.2460866
MixupTrain:  epoch  0, batch   954 | loss: 2.9683940
MixupTrain:  epoch  0, batch   955 | loss: 3.1459770
MixupTrain:  epoch  0, batch   956 | loss: 2.7266510
MixupTrain:  epoch  0, batch   957 | loss: 3.1876678
MixupTrain:  epoch  0, batch   958 | loss: 2.7644243
MixupTrain:  epoch  0, batch   959 | loss: 2.9094572
MixupTrain:  epoch  0, batch   960 | loss: 2.6569188
MixupTrain:  epoch  0, batch   961 | loss: 2.8313961
MixupTrain:  epoch  0, batch   962 | loss: 3.0536051
MixupTrain:  epoch  0, batch   963 | loss: 2.9942577
MixupTrain:  epoch  0, batch   964 | loss: 2.8682275
MixupTrain:  epoch  0, batch   965 | loss: 2.6960559
MixupTrain:  epoch  0, batch   966 | loss: 3.0820827
MixupTrain:  epoch  0, batch   967 | loss: 2.9518700
MixupTrain:  epoch  0, batch   968 | loss: 2.5877542
MixupTrain:  epoch  0, batch   969 | loss: 3.0007339
MixupTrain:  epoch  0, batch   970 | loss: 2.9542561
MixupTrain:  epoch  0, batch   971 | loss: 3.1852093
MixupTrain:  epoch  0, batch   972 | loss: 3.3350201
MixupTrain:  epoch  0, batch   973 | loss: 3.0265312
MixupTrain:  epoch  0, batch   974 | loss: 2.4749246
MixupTrain:  epoch  0, batch   975 | loss: 3.2430358
MixupTrain:  epoch  0, batch   976 | loss: 2.8553965
MixupTrain:  epoch  0, batch   977 | loss: 2.7715573
MixupTrain:  epoch  0, batch   978 | loss: 3.1029644
MixupTrain:  epoch  0, batch   979 | loss: 2.9230850
MixupTrain:  epoch  0, batch   980 | loss: 2.7198167
MixupTrain:  epoch  0, batch   981 | loss: 2.4952981
MemoryTrain:  epoch  0, batch     0 | loss: 2.7586446
MemoryTrain:  epoch  0, batch     1 | loss: 4.4314966
MemoryTrain:  epoch  0, batch     2 | loss: 3.7907193
MemoryTrain:  epoch  0, batch     3 | loss: 4.0906763
MemoryTrain:  epoch  0, batch     4 | loss: 2.7817140
MemoryTrain:  epoch  0, batch     5 | loss: 2.5373669
MemoryTrain:  epoch  0, batch     6 | loss: 2.6421328
MemoryTrain:  epoch  0, batch     7 | loss: 5.2903552
MemoryTrain:  epoch  0, batch     8 | loss: 4.3910432
MemoryTrain:  epoch  0, batch     9 | loss: 2.1332421
MemoryTrain:  epoch  1, batch     0 | loss: 2.6822796
MemoryTrain:  epoch  1, batch     1 | loss: 2.6606660
MemoryTrain:  epoch  1, batch     2 | loss: 1.8484358
MemoryTrain:  epoch  1, batch     3 | loss: 1.8497888
MemoryTrain:  epoch  1, batch     4 | loss: 2.8237753
MemoryTrain:  epoch  1, batch     5 | loss: 2.6256239
MemoryTrain:  epoch  1, batch     6 | loss: 2.3874955
MemoryTrain:  epoch  1, batch     7 | loss: 1.8388740
MemoryTrain:  epoch  1, batch     8 | loss: 2.5924456
MemoryTrain:  epoch  1, batch     9 | loss: 2.2850909
MemoryTrain:  epoch  2, batch     0 | loss: 1.8211371
MemoryTrain:  epoch  2, batch     1 | loss: 2.3365300
MemoryTrain:  epoch  2, batch     2 | loss: 2.2088525
MemoryTrain:  epoch  2, batch     3 | loss: 1.8099535
MemoryTrain:  epoch  2, batch     4 | loss: 3.7228749
MemoryTrain:  epoch  2, batch     5 | loss: 2.5949445
MemoryTrain:  epoch  2, batch     6 | loss: 1.8136694
MemoryTrain:  epoch  2, batch     7 | loss: 1.8268014
MemoryTrain:  epoch  2, batch     8 | loss: 1.8144202
MemoryTrain:  epoch  2, batch     9 | loss: 2.8891439
MemoryTrain:  epoch  3, batch     0 | loss: 2.2086773
MemoryTrain:  epoch  3, batch     1 | loss: 2.1393156
MemoryTrain:  epoch  3, batch     2 | loss: 2.7754662
MemoryTrain:  epoch  3, batch     3 | loss: 2.4530301
MemoryTrain:  epoch  3, batch     4 | loss: 1.8113877
MemoryTrain:  epoch  3, batch     5 | loss: 2.1678729
MemoryTrain:  epoch  3, batch     6 | loss: 2.1309943
MemoryTrain:  epoch  3, batch     7 | loss: 1.8166804
MemoryTrain:  epoch  3, batch     8 | loss: 2.7090175
MemoryTrain:  epoch  3, batch     9 | loss: 1.8144015
MemoryTrain:  epoch  4, batch     0 | loss: 1.8277792
MemoryTrain:  epoch  4, batch     1 | loss: 2.8076956
MemoryTrain:  epoch  4, batch     2 | loss: 2.1429539
MemoryTrain:  epoch  4, batch     3 | loss: 2.4064386
MemoryTrain:  epoch  4, batch     4 | loss: 2.1005690
MemoryTrain:  epoch  4, batch     5 | loss: 1.8265259
MemoryTrain:  epoch  4, batch     6 | loss: 1.8148479
MemoryTrain:  epoch  4, batch     7 | loss: 1.8236431
MemoryTrain:  epoch  4, batch     8 | loss: 2.2640896
MemoryTrain:  epoch  4, batch     9 | loss: 2.5275128
MemoryTrain:  epoch  5, batch     0 | loss: 2.4633946
MemoryTrain:  epoch  5, batch     1 | loss: 2.0916245
MemoryTrain:  epoch  5, batch     2 | loss: 2.8831835
MemoryTrain:  epoch  5, batch     3 | loss: 1.8469748
MemoryTrain:  epoch  5, batch     4 | loss: 1.9443212
MemoryTrain:  epoch  5, batch     5 | loss: 1.8431518
MemoryTrain:  epoch  5, batch     6 | loss: 1.8608189
MemoryTrain:  epoch  5, batch     7 | loss: 1.8908610
MemoryTrain:  epoch  5, batch     8 | loss: 1.8375359
MemoryTrain:  epoch  5, batch     9 | loss: 2.0466685
MemoryTrain:  epoch  6, batch     0 | loss: 1.9141051
MemoryTrain:  epoch  6, batch     1 | loss: 2.0251284
MemoryTrain:  epoch  6, batch     2 | loss: 2.2772622
MemoryTrain:  epoch  6, batch     3 | loss: 1.9692878
MemoryTrain:  epoch  6, batch     4 | loss: 2.4079034
MemoryTrain:  epoch  6, batch     5 | loss: 1.9064895
MemoryTrain:  epoch  6, batch     6 | loss: 2.0510006
MemoryTrain:  epoch  6, batch     7 | loss: 1.8959059
MemoryTrain:  epoch  6, batch     8 | loss: 1.9352456
MemoryTrain:  epoch  6, batch     9 | loss: 1.8176427
MemoryTrain:  epoch  7, batch     0 | loss: 2.1044159
MemoryTrain:  epoch  7, batch     1 | loss: 1.9527708
MemoryTrain:  epoch  7, batch     2 | loss: 1.8862578
MemoryTrain:  epoch  7, batch     3 | loss: 2.0015302
MemoryTrain:  epoch  7, batch     4 | loss: 1.8824326
MemoryTrain:  epoch  7, batch     5 | loss: 2.1851010
MemoryTrain:  epoch  7, batch     6 | loss: 1.8252665
MemoryTrain:  epoch  7, batch     7 | loss: 1.8380785
MemoryTrain:  epoch  7, batch     8 | loss: 1.8693352
MemoryTrain:  epoch  7, batch     9 | loss: 1.8199091
MemoryTrain:  epoch  8, batch     0 | loss: 1.9288642
MemoryTrain:  epoch  8, batch     1 | loss: 1.8483639
MemoryTrain:  epoch  8, batch     2 | loss: 1.8340375
MemoryTrain:  epoch  8, batch     3 | loss: 1.8194942
MemoryTrain:  epoch  8, batch     4 | loss: 1.8345381
MemoryTrain:  epoch  8, batch     5 | loss: 2.8319907
MemoryTrain:  epoch  8, batch     6 | loss: 2.0419083
MemoryTrain:  epoch  8, batch     7 | loss: 2.0591283
MemoryTrain:  epoch  8, batch     8 | loss: 2.2597647
MemoryTrain:  epoch  8, batch     9 | loss: 1.8161892
MemoryTrain:  epoch  9, batch     0 | loss: 2.3247480
MemoryTrain:  epoch  9, batch     1 | loss: 1.9446943
MemoryTrain:  epoch  9, batch     2 | loss: 1.9046156
MemoryTrain:  epoch  9, batch     3 | loss: 2.1618912
MemoryTrain:  epoch  9, batch     4 | loss: 1.8132558
MemoryTrain:  epoch  9, batch     5 | loss: 1.8205178
MemoryTrain:  epoch  9, batch     6 | loss: 2.2142417
MemoryTrain:  epoch  9, batch     7 | loss: 2.0813918
MemoryTrain:  epoch  9, batch     8 | loss: 1.8243529
MemoryTrain:  epoch  9, batch     9 | loss: 2.8413091
[EVAL] batch:    0 | acc: 0.00%,  total acc: 0.00%   
[EVAL] batch:    1 | acc: 12.50%,  total acc: 6.25%   
[EVAL] batch:    2 | acc: 18.75%,  total acc: 10.42%   
[EVAL] batch:    3 | acc: 81.25%,  total acc: 28.12%   
[EVAL] batch:    4 | acc: 81.25%,  total acc: 38.75%   
[EVAL] batch:    5 | acc: 93.75%,  total acc: 47.92%   
[EVAL] batch:    6 | acc: 56.25%,  total acc: 49.11%   
[EVAL] batch:    7 | acc: 31.25%,  total acc: 46.88%   
[EVAL] batch:    8 | acc: 25.00%,  total acc: 44.44%   
[EVAL] batch:    9 | acc: 43.75%,  total acc: 44.38%   
[EVAL] batch:   10 | acc: 37.50%,  total acc: 43.75%   
[EVAL] batch:   11 | acc: 43.75%,  total acc: 43.75%   
[EVAL] batch:   12 | acc: 31.25%,  total acc: 42.79%   
[EVAL] batch:   13 | acc: 100.00%,  total acc: 46.88%   
[EVAL] batch:   14 | acc: 100.00%,  total acc: 50.42%   
[EVAL] batch:   15 | acc: 100.00%,  total acc: 53.52%   
[EVAL] batch:   16 | acc: 100.00%,  total acc: 56.25%   
[EVAL] batch:   17 | acc: 87.50%,  total acc: 57.99%   
[EVAL] batch:   18 | acc: 50.00%,  total acc: 57.57%   
[EVAL] batch:   19 | acc: 75.00%,  total acc: 58.44%   
[EVAL] batch:   20 | acc: 62.50%,  total acc: 58.63%   
[EVAL] batch:   21 | acc: 31.25%,  total acc: 57.39%   
[EVAL] batch:    0 | acc: 12.50%,  total acc: 12.50%   
[EVAL] batch:    1 | acc: 56.25%,  total acc: 34.38%   
[EVAL] batch:    2 | acc: 37.50%,  total acc: 35.42%   
[EVAL] batch:    3 | acc: 12.50%,  total acc: 29.69%   
[EVAL] batch:    4 | acc: 37.50%,  total acc: 31.25%   
[EVAL] batch:    5 | acc: 31.25%,  total acc: 31.25%   
[EVAL] batch:    6 | acc: 50.00%,  total acc: 33.93%   
[EVAL] batch:    7 | acc: 37.50%,  total acc: 34.38%   
[EVAL] batch:    8 | acc: 43.75%,  total acc: 35.42%   
[EVAL] batch:    9 | acc: 37.50%,  total acc: 35.62%   
[EVAL] batch:   10 | acc: 31.25%,  total acc: 35.23%   
[EVAL] batch:   11 | acc: 50.00%,  total acc: 36.46%   
[EVAL] batch:   12 | acc: 18.75%,  total acc: 35.10%   
[EVAL] batch:   13 | acc: 25.00%,  total acc: 34.38%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 37.08%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 38.28%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 40.44%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 41.67%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 42.76%   
[EVAL] batch:   19 | acc: 87.50%,  total acc: 45.00%   
[EVAL] batch:   20 | acc: 87.50%,  total acc: 47.02%   
[EVAL] batch:   21 | acc: 93.75%,  total acc: 49.15%   
[EVAL] batch:   22 | acc: 93.75%,  total acc: 51.09%   
[EVAL] batch:   23 | acc: 93.75%,  total acc: 52.86%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 54.75%   
[EVAL] batch:   25 | acc: 87.50%,  total acc: 56.01%   
[EVAL] batch:   26 | acc: 18.75%,  total acc: 54.63%   
[EVAL] batch:   27 | acc: 18.75%,  total acc: 53.35%   
[EVAL] batch:   28 | acc: 0.00%,  total acc: 51.51%   
[EVAL] batch:   29 | acc: 18.75%,  total acc: 50.42%   
[EVAL] batch:   30 | acc: 12.50%,  total acc: 49.19%   
[EVAL] batch:   31 | acc: 12.50%,  total acc: 48.05%   
[EVAL] batch:   32 | acc: 62.50%,  total acc: 48.48%   
[EVAL] batch:   33 | acc: 43.75%,  total acc: 48.35%   
[EVAL] batch:   34 | acc: 25.00%,  total acc: 47.68%   
[EVAL] batch:   35 | acc: 12.50%,  total acc: 46.70%   
[EVAL] batch:   36 | acc: 0.00%,  total acc: 45.44%   
[EVAL] batch:   37 | acc: 18.75%,  total acc: 44.74%   
[EVAL] batch:   38 | acc: 18.75%,  total acc: 44.07%   
[EVAL] batch:   39 | acc: 75.00%,  total acc: 44.84%   
[EVAL] batch:   40 | acc: 93.75%,  total acc: 46.04%   
[EVAL] batch:   41 | acc: 75.00%,  total acc: 46.73%   
[EVAL] batch:   42 | acc: 93.75%,  total acc: 47.82%   
[EVAL] batch:   43 | acc: 81.25%,  total acc: 48.58%   
[EVAL] batch:   44 | acc: 93.75%,  total acc: 49.58%   
[EVAL] batch:   45 | acc: 31.25%,  total acc: 49.18%   
[EVAL] batch:   46 | acc: 68.75%,  total acc: 49.60%   
[EVAL] batch:   47 | acc: 87.50%,  total acc: 50.39%   
[EVAL] batch:   48 | acc: 25.00%,  total acc: 49.87%   
[EVAL] batch:   49 | acc: 68.75%,  total acc: 50.25%   
[EVAL] batch:   50 | acc: 37.50%,  total acc: 50.00%   
[EVAL] batch:   51 | acc: 62.50%,  total acc: 50.24%   
[EVAL] batch:   52 | acc: 62.50%,  total acc: 50.47%   
[EVAL] batch:   53 | acc: 100.00%,  total acc: 51.39%   
[EVAL] batch:   54 | acc: 81.25%,  total acc: 51.93%   
[EVAL] batch:   55 | acc: 100.00%,  total acc: 52.79%   
[EVAL] batch:   56 | acc: 87.50%,  total acc: 53.40%   
[EVAL] batch:   57 | acc: 75.00%,  total acc: 53.77%   
[EVAL] batch:   58 | acc: 87.50%,  total acc: 54.34%   
[EVAL] batch:   59 | acc: 81.25%,  total acc: 54.79%   
[EVAL] batch:   60 | acc: 43.75%,  total acc: 54.61%   
[EVAL] batch:   61 | acc: 12.50%,  total acc: 53.93%   
[EVAL] batch:   62 | acc: 12.50%,  total acc: 53.27%   
[EVAL] batch:   63 | acc: 37.50%,  total acc: 53.03%   
[EVAL] batch:   64 | acc: 93.75%,  total acc: 53.65%   
[EVAL] batch:   65 | acc: 62.50%,  total acc: 53.79%   
[EVAL] batch:   66 | acc: 0.00%,  total acc: 52.99%   
[EVAL] batch:   67 | acc: 12.50%,  total acc: 52.39%   
[EVAL] batch:   68 | acc: 37.50%,  total acc: 52.17%   
[EVAL] batch:   69 | acc: 81.25%,  total acc: 52.59%   
[EVAL] batch:   70 | acc: 87.50%,  total acc: 53.08%   
[EVAL] batch:   71 | acc: 87.50%,  total acc: 53.56%   
[EVAL] batch:   72 | acc: 50.00%,  total acc: 53.51%   
[EVAL] batch:   73 | acc: 18.75%,  total acc: 53.04%   
[EVAL] batch:   74 | acc: 25.00%,  total acc: 52.67%   
[EVAL] batch:   75 | acc: 50.00%,  total acc: 52.63%   
[EVAL] batch:   76 | acc: 31.25%,  total acc: 52.35%   
[EVAL] batch:   77 | acc: 50.00%,  total acc: 52.32%   
[EVAL] batch:   78 | acc: 50.00%,  total acc: 52.29%   
[EVAL] batch:   79 | acc: 100.00%,  total acc: 52.89%   
[EVAL] batch:   80 | acc: 100.00%,  total acc: 53.47%   
[EVAL] batch:   81 | acc: 100.00%,  total acc: 54.04%   
[EVAL] batch:   82 | acc: 93.75%,  total acc: 54.52%   
[EVAL] batch:   83 | acc: 81.25%,  total acc: 54.84%   
[EVAL] batch:   84 | acc: 56.25%,  total acc: 54.85%   
[EVAL] batch:   85 | acc: 75.00%,  total acc: 55.09%   
[EVAL] batch:   86 | acc: 56.25%,  total acc: 55.10%   
[EVAL] batch:   87 | acc: 18.75%,  total acc: 54.69%   
cur_acc:  ['0.8712', '0.8705', '0.7266', '0.8990', '0.5739']
his_acc:  ['0.8712', '0.8564', '0.6238', '0.6241', '0.5469']
CurrentTrain: epoch  0, batch     0 | loss: 4.1770973
CurrentTrain: epoch  0, batch     1 | loss: 3.8860800
CurrentTrain: epoch  1, batch     0 | loss: 3.0049567
CurrentTrain: epoch  1, batch     1 | loss: 3.4644234
CurrentTrain: epoch  2, batch     0 | loss: 3.0551476
CurrentTrain: epoch  2, batch     1 | loss: 2.3850660
CurrentTrain: epoch  3, batch     0 | loss: 2.3917115
CurrentTrain: epoch  3, batch     1 | loss: 2.7467618
CurrentTrain: epoch  4, batch     0 | loss: 2.4566340
CurrentTrain: epoch  4, batch     1 | loss: 2.1182425
CurrentTrain: epoch  5, batch     0 | loss: 2.2284937
CurrentTrain: epoch  5, batch     1 | loss: 2.0392277
CurrentTrain: epoch  6, batch     0 | loss: 1.9473161
CurrentTrain: epoch  6, batch     1 | loss: 2.2719760
CurrentTrain: epoch  7, batch     0 | loss: 1.8153825
CurrentTrain: epoch  7, batch     1 | loss: 2.2335680
CurrentTrain: epoch  8, batch     0 | loss: 1.8160174
CurrentTrain: epoch  8, batch     1 | loss: 2.0310826
CurrentTrain: epoch  9, batch     0 | loss: 1.7879729
CurrentTrain: epoch  9, batch     1 | loss: 2.0311263
#### organization founded ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization founded" means an organization was found in a date.
Here is an example:
Relation: organization founded
Context: pandit worked at the brokerage morgan stanley for about 11 years until 2005 , when he and some morgan stanley colleagues quit and later founded the hedge fund old lane partners .
Head Entity: old lane partners
Tail Entity: 2005
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization founded":
Relation: organization founded  
Context: In 1998, a group of engineers and entrepreneurs came together to establish the tech startup, Innovatech Solutions, which has since become a leader in software development.  
Head Entity: Innovatech Solutions  
Tail Entity: 1998  

Relation: organization founded  
Context: The non-profit organization Green Earth Initiative was established in 2010 to promote environmental awareness and sustainability practices across communities.  
Head Entity: Green Earth Initiative  
Tail Entity: 2010  

Relation: organization founded  
Context: After years of research and development, the pharmaceutical company HealthPlus was founded in 2015 to focus on innovative healthcare solutions.  
Head Entity: HealthPlus  
Tail Entity: 2015  

Relation: organization founded  
Context: In 2001, the educational institution Future Leaders Academy was founded to provide quality education and leadership training to young students.  
Head Entity: Future Leaders Academy  
Tail Entity: 2001  

Relation: organization founded  
Context: The fashion brand EcoWear was founded in 2020 with a mission to create sustainable clothing using recycled materials.  
Head Entity: EcoWear  
Tail Entity: 2020  
#### person age ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person age" means a person 's age is a number.
Here is an example:
Relation: person age
Context: virginia republican jo ann davis passed away on saturday at the age of 57 .
Head Entity: jo ann davis
Tail Entity: 57
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person age":
Relation: person age  
Context: the famous actor robert downey jr. celebrated his 56th birthday last week.  
Head Entity: robert downey jr.  
Tail Entity: 56  

Relation: person age  
Context: on her 30th birthday, emily decided to throw a big party for her friends.  
Head Entity: emily  
Tail Entity: 30  

Relation: person age  
Context: the renowned scientist dr. jane goodall is currently 89 years old.  
Head Entity: dr. jane goodall  
Tail Entity: 89  

Relation: person age  
Context: last year, my grandfather turned 85, and we had a family gathering to celebrate.  
Head Entity: my grandfather  
Tail Entity: 85  

Relation: person age  
Context: the youngest member of the team, 22-year-old sarah, impressed everyone with her skills.  
Head Entity: sarah  
Tail Entity: 22  
#### person city of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person city of birth" means a person was born in a city.
Here is an example:
Relation: person city of birth
Context: forsberg was born in 1943 in huntsville , ala. , and grew up on long island in new york .
Head Entity: forsberg
Tail Entity: huntsville
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person city of birth":
Relation: person city of birth  
Context: elena was born in 1990 in barcelona, spain, where she spent her childhood.  
Head Entity: elena  
Tail Entity: barcelona  

Relation: person city of birth  
Context: during a recent interview, john revealed that he was born in 1985 in a small town called springfield.  
Head Entity: john  
Tail Entity: springfield  

Relation: person city of birth  
Context: the famous artist pablo picasso was born in 1881 in málaga, a coastal city in southern spain.  
Head Entity: pablo picasso  
Tail Entity: málaga  

Relation: person city of birth  
Context: after moving to new york, sarah often reminisced about her birthplace, which is the vibrant city of los angeles.  
Head Entity: sarah  
Tail Entity: los angeles  

Relation: person city of birth  
Context: in his autobiography, the actor shared that he was born in 1975 in the bustling city of chicago.  
Head Entity: the actor  
Tail Entity: chicago  
#### organization members ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization members" means an organization 's member is an organization.
Here is an example:
Relation: organization members
Context: it was berger who made clarke a member of the white house principals committee when it met to discuss terrorist threats , allowing an otherwise middle-ranking nsc bureaucrat to treat tenet and secretary of state madeleine albright as equals -lrb- which the empire-building clarke was pleased to do -rrb- .
Head Entity: nsc
Tail Entity: white house principals committee
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization members":
1. Relation: organization members  
   Context: The board of directors at Tech Innovations Inc. decided to appoint Sarah as a member of the advisory committee to enhance their strategic planning.  
   Head Entity: Tech Innovations Inc.  
   Tail Entity: advisory committee  

2. Relation: organization members  
   Context: During the annual conference, the president of the National Wildlife Federation announced that John would be joining as a member of the conservation team.  
   Head Entity: National Wildlife Federation  
   Tail Entity: conservation team  

3. Relation: organization members  
   Context: The United Nations welcomed several new representatives, including Maria, who became a member of the Human Rights Council.  
   Head Entity: United Nations  
   Tail Entity: Human Rights Council  

4. Relation: organization members  
   Context: After a rigorous selection process, the CEO of Green Energy Solutions introduced Alex as the newest member of the sustainability task force.  
   Head Entity: Green Energy Solutions  
   Tail Entity: sustainability task force  

5. Relation: organization members  
   Context: The local chapter of the Red Cross proudly announced that Emily has been accepted as a member of the emergency response team.  
   Head Entity: Red Cross  
   Tail Entity: emergency response team  
#### person religion ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person religion" means an person is the member of a religion.
Here is an example:
Relation: person religion
Context: the pope defended his action on the grounds that he could not refuse an audience to a head of state from a country with a strong catholic tradition unless he had clear-cut proof of the allegations against him .
Head Entity: he
Tail Entity: catholic
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person religion":
Relation: person religion  
Context: During the ceremony, the rabbi spoke about the importance of faith and community in Judaism, emphasizing how every member plays a vital role.  
Head Entity: rabbi  
Tail Entity: Judaism  

Relation: person religion  
Context: The imam led the prayers at the mosque, reminding the congregation of their duties as followers of Islam and the significance of their beliefs.  
Head Entity: imam  
Tail Entity: Islam  

Relation: person religion  
Context: As a devout follower, she often shared her experiences in the church, highlighting how her Christian faith guided her through difficult times.  
Head Entity: she  
Tail Entity: Christian  

Relation: person religion  
Context: The monk dedicated his life to Buddhism, practicing meditation and teaching others about the path to enlightenment.  
Head Entity: monk  
Tail Entity: Buddhism  

Relation: person religion  
Context: He often participated in community events organized by the Hindu temple, celebrating festivals that reflect his deep commitment to his faith.  
Head Entity: he  
Tail Entity: Hindu
Mixup data size:  21490
MixupTrain:  epoch  0, batch     0 | loss: 5.0313921
MixupTrain:  epoch  0, batch     1 | loss: 3.9570174
MixupTrain:  epoch  0, batch     2 | loss: 4.0430222
MixupTrain:  epoch  0, batch     3 | loss: 4.0200510
MixupTrain:  epoch  0, batch     4 | loss: 3.4810486
MixupTrain:  epoch  0, batch     5 | loss: 3.6637776
MixupTrain:  epoch  0, batch     6 | loss: 3.8469474
MixupTrain:  epoch  0, batch     7 | loss: 3.5762248
MixupTrain:  epoch  0, batch     8 | loss: 2.8387458
MixupTrain:  epoch  0, batch     9 | loss: 3.3846068
MixupTrain:  epoch  0, batch    10 | loss: 3.5277958
MixupTrain:  epoch  0, batch    11 | loss: 3.5173392
MixupTrain:  epoch  0, batch    12 | loss: 3.8154140
MixupTrain:  epoch  0, batch    13 | loss: 3.8175957
MixupTrain:  epoch  0, batch    14 | loss: 3.8915801
MixupTrain:  epoch  0, batch    15 | loss: 3.4789493
MixupTrain:  epoch  0, batch    16 | loss: 3.8209252
MixupTrain:  epoch  0, batch    17 | loss: 4.4747171
MixupTrain:  epoch  0, batch    18 | loss: 3.2512324
MixupTrain:  epoch  0, batch    19 | loss: 3.7045960
MixupTrain:  epoch  0, batch    20 | loss: 3.7726784
MixupTrain:  epoch  0, batch    21 | loss: 3.0847673
MixupTrain:  epoch  0, batch    22 | loss: 2.7648888
MixupTrain:  epoch  0, batch    23 | loss: 3.5694814
MixupTrain:  epoch  0, batch    24 | loss: 4.3264561
MixupTrain:  epoch  0, batch    25 | loss: 3.3570271
MixupTrain:  epoch  0, batch    26 | loss: 3.6872988
MixupTrain:  epoch  0, batch    27 | loss: 3.6980996
MixupTrain:  epoch  0, batch    28 | loss: 3.4232221
MixupTrain:  epoch  0, batch    29 | loss: 3.8132212
MixupTrain:  epoch  0, batch    30 | loss: 3.2991982
MixupTrain:  epoch  0, batch    31 | loss: 3.1808786
MixupTrain:  epoch  0, batch    32 | loss: 3.3641469
MixupTrain:  epoch  0, batch    33 | loss: 3.7325220
MixupTrain:  epoch  0, batch    34 | loss: 3.7347775
MixupTrain:  epoch  0, batch    35 | loss: 3.0221820
MixupTrain:  epoch  0, batch    36 | loss: 3.2229986
MixupTrain:  epoch  0, batch    37 | loss: 3.2585225
MixupTrain:  epoch  0, batch    38 | loss: 3.0350280
MixupTrain:  epoch  0, batch    39 | loss: 2.8650737
MixupTrain:  epoch  0, batch    40 | loss: 3.5399797
MixupTrain:  epoch  0, batch    41 | loss: 3.2256312
MixupTrain:  epoch  0, batch    42 | loss: 2.4845829
MixupTrain:  epoch  0, batch    43 | loss: 3.0816879
MixupTrain:  epoch  0, batch    44 | loss: 2.6792290
MixupTrain:  epoch  0, batch    45 | loss: 3.2500327
MixupTrain:  epoch  0, batch    46 | loss: 2.6322799
MixupTrain:  epoch  0, batch    47 | loss: 2.9711876
MixupTrain:  epoch  0, batch    48 | loss: 3.3191323
MixupTrain:  epoch  0, batch    49 | loss: 2.9820476
MixupTrain:  epoch  0, batch    50 | loss: 2.9602830
MixupTrain:  epoch  0, batch    51 | loss: 3.6518402
MixupTrain:  epoch  0, batch    52 | loss: 3.2064047
MixupTrain:  epoch  0, batch    53 | loss: 2.9156518
MixupTrain:  epoch  0, batch    54 | loss: 3.5961137
MixupTrain:  epoch  0, batch    55 | loss: 2.8993287
MixupTrain:  epoch  0, batch    56 | loss: 3.0212855
MixupTrain:  epoch  0, batch    57 | loss: 2.5675747
MixupTrain:  epoch  0, batch    58 | loss: 2.5845532
MixupTrain:  epoch  0, batch    59 | loss: 3.3716745
MixupTrain:  epoch  0, batch    60 | loss: 2.8448918
MixupTrain:  epoch  0, batch    61 | loss: 2.9512825
MixupTrain:  epoch  0, batch    62 | loss: 2.8159537
MixupTrain:  epoch  0, batch    63 | loss: 3.4183030
MixupTrain:  epoch  0, batch    64 | loss: 3.7438450
MixupTrain:  epoch  0, batch    65 | loss: 2.9008946
MixupTrain:  epoch  0, batch    66 | loss: 3.4271016
MixupTrain:  epoch  0, batch    67 | loss: 3.3241558
MixupTrain:  epoch  0, batch    68 | loss: 3.0014977
MixupTrain:  epoch  0, batch    69 | loss: 3.0090227
MixupTrain:  epoch  0, batch    70 | loss: 2.6959956
MixupTrain:  epoch  0, batch    71 | loss: 2.6198773
MixupTrain:  epoch  0, batch    72 | loss: 2.7381740
MixupTrain:  epoch  0, batch    73 | loss: 2.6691687
MixupTrain:  epoch  0, batch    74 | loss: 3.2246256
MixupTrain:  epoch  0, batch    75 | loss: 2.5343089
MixupTrain:  epoch  0, batch    76 | loss: 2.7812572
MixupTrain:  epoch  0, batch    77 | loss: 2.5836966
MixupTrain:  epoch  0, batch    78 | loss: 2.8146112
MixupTrain:  epoch  0, batch    79 | loss: 2.5178490
MixupTrain:  epoch  0, batch    80 | loss: 3.4459395
MixupTrain:  epoch  0, batch    81 | loss: 2.9798265
MixupTrain:  epoch  0, batch    82 | loss: 2.6712761
MixupTrain:  epoch  0, batch    83 | loss: 2.9887767
MixupTrain:  epoch  0, batch    84 | loss: 3.0129428
MixupTrain:  epoch  0, batch    85 | loss: 2.2378554
MixupTrain:  epoch  0, batch    86 | loss: 2.7891040
MixupTrain:  epoch  0, batch    87 | loss: 3.0121903
MixupTrain:  epoch  0, batch    88 | loss: 2.9735370
MixupTrain:  epoch  0, batch    89 | loss: 2.9451876
MixupTrain:  epoch  0, batch    90 | loss: 2.8169546
MixupTrain:  epoch  0, batch    91 | loss: 2.6624696
MixupTrain:  epoch  0, batch    92 | loss: 2.8779197
MixupTrain:  epoch  0, batch    93 | loss: 2.2571154
MixupTrain:  epoch  0, batch    94 | loss: 2.6544290
MixupTrain:  epoch  0, batch    95 | loss: 2.7538290
MixupTrain:  epoch  0, batch    96 | loss: 2.6732464
MixupTrain:  epoch  0, batch    97 | loss: 2.7552805
MixupTrain:  epoch  0, batch    98 | loss: 2.7567084
MixupTrain:  epoch  0, batch    99 | loss: 2.8267252
MixupTrain:  epoch  0, batch   100 | loss: 2.4255857
MixupTrain:  epoch  0, batch   101 | loss: 2.4271748
MixupTrain:  epoch  0, batch   102 | loss: 2.5585296
MixupTrain:  epoch  0, batch   103 | loss: 2.4468112
MixupTrain:  epoch  0, batch   104 | loss: 2.5356112
MixupTrain:  epoch  0, batch   105 | loss: 2.7393637
MixupTrain:  epoch  0, batch   106 | loss: 2.6041739
MixupTrain:  epoch  0, batch   107 | loss: 2.6464655
MixupTrain:  epoch  0, batch   108 | loss: 2.8179541
MixupTrain:  epoch  0, batch   109 | loss: 2.5289783
MixupTrain:  epoch  0, batch   110 | loss: 2.6922872
MixupTrain:  epoch  0, batch   111 | loss: 2.8488710
MixupTrain:  epoch  0, batch   112 | loss: 2.6982176
MixupTrain:  epoch  0, batch   113 | loss: 2.8832517
MixupTrain:  epoch  0, batch   114 | loss: 2.3317981
MixupTrain:  epoch  0, batch   115 | loss: 2.6945112
MixupTrain:  epoch  0, batch   116 | loss: 2.6924670
MixupTrain:  epoch  0, batch   117 | loss: 2.6292927
MixupTrain:  epoch  0, batch   118 | loss: 2.7053013
MixupTrain:  epoch  0, batch   119 | loss: 3.0818462
MixupTrain:  epoch  0, batch   120 | loss: 2.3540549
MixupTrain:  epoch  0, batch   121 | loss: 2.5274158
MixupTrain:  epoch  0, batch   122 | loss: 2.5278740
MixupTrain:  epoch  0, batch   123 | loss: 2.5963309
MixupTrain:  epoch  0, batch   124 | loss: 2.2018747
MixupTrain:  epoch  0, batch   125 | loss: 2.4212475
MixupTrain:  epoch  0, batch   126 | loss: 2.5291042
MixupTrain:  epoch  0, batch   127 | loss: 2.2393036
MixupTrain:  epoch  0, batch   128 | loss: 2.5081034
MixupTrain:  epoch  0, batch   129 | loss: 2.4866962
MixupTrain:  epoch  0, batch   130 | loss: 2.5609910
MixupTrain:  epoch  0, batch   131 | loss: 2.3996038
MixupTrain:  epoch  0, batch   132 | loss: 2.8268657
MixupTrain:  epoch  0, batch   133 | loss: 2.4803500
MixupTrain:  epoch  0, batch   134 | loss: 2.6606314
MixupTrain:  epoch  0, batch   135 | loss: 2.5327206
MixupTrain:  epoch  0, batch   136 | loss: 2.6405244
MixupTrain:  epoch  0, batch   137 | loss: 2.5530686
MixupTrain:  epoch  0, batch   138 | loss: 2.6138487
MixupTrain:  epoch  0, batch   139 | loss: 2.4113083
MixupTrain:  epoch  0, batch   140 | loss: 2.4505136
MixupTrain:  epoch  0, batch   141 | loss: 2.3601537
MixupTrain:  epoch  0, batch   142 | loss: 2.8298411
MixupTrain:  epoch  0, batch   143 | loss: 2.6852119
MixupTrain:  epoch  0, batch   144 | loss: 2.4272830
MixupTrain:  epoch  0, batch   145 | loss: 2.4258380
MixupTrain:  epoch  0, batch   146 | loss: 2.4106889
MixupTrain:  epoch  0, batch   147 | loss: 2.5011730
MixupTrain:  epoch  0, batch   148 | loss: 2.4981775
MixupTrain:  epoch  0, batch   149 | loss: 2.3711872
MixupTrain:  epoch  0, batch   150 | loss: 2.4524672
MixupTrain:  epoch  0, batch   151 | loss: 2.3608553
MixupTrain:  epoch  0, batch   152 | loss: 2.2768545
MixupTrain:  epoch  0, batch   153 | loss: 2.6236587
MixupTrain:  epoch  0, batch   154 | loss: 2.3200376
MixupTrain:  epoch  0, batch   155 | loss: 2.3617904
MixupTrain:  epoch  0, batch   156 | loss: 2.2496767
MixupTrain:  epoch  0, batch   157 | loss: 2.5447745
MixupTrain:  epoch  0, batch   158 | loss: 2.8642228
MixupTrain:  epoch  0, batch   159 | loss: 2.3654704
MixupTrain:  epoch  0, batch   160 | loss: 2.3821332
MixupTrain:  epoch  0, batch   161 | loss: 2.2758698
MixupTrain:  epoch  0, batch   162 | loss: 2.2831800
MixupTrain:  epoch  0, batch   163 | loss: 2.4528639
MixupTrain:  epoch  0, batch   164 | loss: 2.4473271
MixupTrain:  epoch  0, batch   165 | loss: 2.7584386
MixupTrain:  epoch  0, batch   166 | loss: 2.8940349
MixupTrain:  epoch  0, batch   167 | loss: 2.0358162
MixupTrain:  epoch  0, batch   168 | loss: 2.2727432
MixupTrain:  epoch  0, batch   169 | loss: 2.3751979
MixupTrain:  epoch  0, batch   170 | loss: 2.8626785
MixupTrain:  epoch  0, batch   171 | loss: 2.2769330
MixupTrain:  epoch  0, batch   172 | loss: 2.7749612
MixupTrain:  epoch  0, batch   173 | loss: 2.6293633
MixupTrain:  epoch  0, batch   174 | loss: 2.4681525
MixupTrain:  epoch  0, batch   175 | loss: 2.6172891
MixupTrain:  epoch  0, batch   176 | loss: 2.5160937
MixupTrain:  epoch  0, batch   177 | loss: 2.2137105
MixupTrain:  epoch  0, batch   178 | loss: 2.5799055
MixupTrain:  epoch  0, batch   179 | loss: 2.7380919
MixupTrain:  epoch  0, batch   180 | loss: 2.7537446
MixupTrain:  epoch  0, batch   181 | loss: 2.3787365
MixupTrain:  epoch  0, batch   182 | loss: 2.4643524
MixupTrain:  epoch  0, batch   183 | loss: 2.4717398
MixupTrain:  epoch  0, batch   184 | loss: 2.4372115
MixupTrain:  epoch  0, batch   185 | loss: 2.6006513
MixupTrain:  epoch  0, batch   186 | loss: 2.5115061
MixupTrain:  epoch  0, batch   187 | loss: 2.2345815
MixupTrain:  epoch  0, batch   188 | loss: 2.3808551
MixupTrain:  epoch  0, batch   189 | loss: 2.7233522
MixupTrain:  epoch  0, batch   190 | loss: 2.3576770
MixupTrain:  epoch  0, batch   191 | loss: 2.4600389
MixupTrain:  epoch  0, batch   192 | loss: 2.2173727
MixupTrain:  epoch  0, batch   193 | loss: 2.3678124
MixupTrain:  epoch  0, batch   194 | loss: 2.4851892
MixupTrain:  epoch  0, batch   195 | loss: 2.5012746
MixupTrain:  epoch  0, batch   196 | loss: 2.1172733
MixupTrain:  epoch  0, batch   197 | loss: 2.1985416
MixupTrain:  epoch  0, batch   198 | loss: 2.5525901
MixupTrain:  epoch  0, batch   199 | loss: 2.3196025
MixupTrain:  epoch  0, batch   200 | loss: 2.5088401
MixupTrain:  epoch  0, batch   201 | loss: 2.4327910
MixupTrain:  epoch  0, batch   202 | loss: 2.4275680
MixupTrain:  epoch  0, batch   203 | loss: 2.5609043
MixupTrain:  epoch  0, batch   204 | loss: 2.4946473
MixupTrain:  epoch  0, batch   205 | loss: 2.4471028
MixupTrain:  epoch  0, batch   206 | loss: 2.5484421
MixupTrain:  epoch  0, batch   207 | loss: 2.6248674
MixupTrain:  epoch  0, batch   208 | loss: 2.3410935
MixupTrain:  epoch  0, batch   209 | loss: 2.5912461
MixupTrain:  epoch  0, batch   210 | loss: 2.3055668
MixupTrain:  epoch  0, batch   211 | loss: 2.3661141
MixupTrain:  epoch  0, batch   212 | loss: 2.2785358
MixupTrain:  epoch  0, batch   213 | loss: 2.6477916
MixupTrain:  epoch  0, batch   214 | loss: 2.6397519
MixupTrain:  epoch  0, batch   215 | loss: 2.4429207
MixupTrain:  epoch  0, batch   216 | loss: 2.3348546
MixupTrain:  epoch  0, batch   217 | loss: 2.1502209
MixupTrain:  epoch  0, batch   218 | loss: 2.6686897
MixupTrain:  epoch  0, batch   219 | loss: 2.3806388
MixupTrain:  epoch  0, batch   220 | loss: 2.7428961
MixupTrain:  epoch  0, batch   221 | loss: 2.4555135
MixupTrain:  epoch  0, batch   222 | loss: 2.5428543
MixupTrain:  epoch  0, batch   223 | loss: 2.5065928
MixupTrain:  epoch  0, batch   224 | loss: 2.6145382
MixupTrain:  epoch  0, batch   225 | loss: 2.4841182
MixupTrain:  epoch  0, batch   226 | loss: 2.5424099
MixupTrain:  epoch  0, batch   227 | loss: 2.3664043
MixupTrain:  epoch  0, batch   228 | loss: 2.5046983
MixupTrain:  epoch  0, batch   229 | loss: 2.5818803
MixupTrain:  epoch  0, batch   230 | loss: 2.2318187
MixupTrain:  epoch  0, batch   231 | loss: 2.4169304
MixupTrain:  epoch  0, batch   232 | loss: 2.4279356
MixupTrain:  epoch  0, batch   233 | loss: 2.3901706
MixupTrain:  epoch  0, batch   234 | loss: 2.3106232
MixupTrain:  epoch  0, batch   235 | loss: 2.2120085
MixupTrain:  epoch  0, batch   236 | loss: 2.4876285
MixupTrain:  epoch  0, batch   237 | loss: 2.7063441
MixupTrain:  epoch  0, batch   238 | loss: 2.2000566
MixupTrain:  epoch  0, batch   239 | loss: 2.4427493
MixupTrain:  epoch  0, batch   240 | loss: 2.1869123
MixupTrain:  epoch  0, batch   241 | loss: 2.4813833
MixupTrain:  epoch  0, batch   242 | loss: 2.1045496
MixupTrain:  epoch  0, batch   243 | loss: 2.4887204
MixupTrain:  epoch  0, batch   244 | loss: 2.2923508
MixupTrain:  epoch  0, batch   245 | loss: 2.3997641
MixupTrain:  epoch  0, batch   246 | loss: 2.5254211
MixupTrain:  epoch  0, batch   247 | loss: 2.3097608
MixupTrain:  epoch  0, batch   248 | loss: 2.2946630
MixupTrain:  epoch  0, batch   249 | loss: 2.6353750
MixupTrain:  epoch  0, batch   250 | loss: 2.4978676
MixupTrain:  epoch  0, batch   251 | loss: 2.4147773
MixupTrain:  epoch  0, batch   252 | loss: 2.3744421
MixupTrain:  epoch  0, batch   253 | loss: 2.4407005
MixupTrain:  epoch  0, batch   254 | loss: 2.4617937
MixupTrain:  epoch  0, batch   255 | loss: 2.2187934
MixupTrain:  epoch  0, batch   256 | loss: 2.4306500
MixupTrain:  epoch  0, batch   257 | loss: 2.1957703
MixupTrain:  epoch  0, batch   258 | loss: 2.6144505
MixupTrain:  epoch  0, batch   259 | loss: 2.2563071
MixupTrain:  epoch  0, batch   260 | loss: 2.2787685
MixupTrain:  epoch  0, batch   261 | loss: 2.3243699
MixupTrain:  epoch  0, batch   262 | loss: 2.4543412
MixupTrain:  epoch  0, batch   263 | loss: 2.3413787
MixupTrain:  epoch  0, batch   264 | loss: 2.3478069
MixupTrain:  epoch  0, batch   265 | loss: 2.3888559
MixupTrain:  epoch  0, batch   266 | loss: 2.5718291
MixupTrain:  epoch  0, batch   267 | loss: 2.4207520
MixupTrain:  epoch  0, batch   268 | loss: 2.3443155
MixupTrain:  epoch  0, batch   269 | loss: 2.4333014
MixupTrain:  epoch  0, batch   270 | loss: 2.2040195
MixupTrain:  epoch  0, batch   271 | loss: 2.5018287
MixupTrain:  epoch  0, batch   272 | loss: 2.5521965
MixupTrain:  epoch  0, batch   273 | loss: 2.3876362
MixupTrain:  epoch  0, batch   274 | loss: 2.1239524
MixupTrain:  epoch  0, batch   275 | loss: 2.2761445
MixupTrain:  epoch  0, batch   276 | loss: 2.4206436
MixupTrain:  epoch  0, batch   277 | loss: 2.0402899
MixupTrain:  epoch  0, batch   278 | loss: 2.5134330
MixupTrain:  epoch  0, batch   279 | loss: 2.5814805
MixupTrain:  epoch  0, batch   280 | loss: 2.3925667
MixupTrain:  epoch  0, batch   281 | loss: 2.6022751
MixupTrain:  epoch  0, batch   282 | loss: 2.3350060
MixupTrain:  epoch  0, batch   283 | loss: 2.2172501
MixupTrain:  epoch  0, batch   284 | loss: 2.3480601
MixupTrain:  epoch  0, batch   285 | loss: 2.3874135
MixupTrain:  epoch  0, batch   286 | loss: 2.1070111
MixupTrain:  epoch  0, batch   287 | loss: 2.2327077
MixupTrain:  epoch  0, batch   288 | loss: 2.3879635
MixupTrain:  epoch  0, batch   289 | loss: 2.7125769
MixupTrain:  epoch  0, batch   290 | loss: 2.0287890
MixupTrain:  epoch  0, batch   291 | loss: 2.5087342
MixupTrain:  epoch  0, batch   292 | loss: 2.3942747
MixupTrain:  epoch  0, batch   293 | loss: 2.6176171
MixupTrain:  epoch  0, batch   294 | loss: 2.3383515
MixupTrain:  epoch  0, batch   295 | loss: 2.3338900
MixupTrain:  epoch  0, batch   296 | loss: 2.5956631
MixupTrain:  epoch  0, batch   297 | loss: 2.0218837
MixupTrain:  epoch  0, batch   298 | loss: 2.0695293
MixupTrain:  epoch  0, batch   299 | loss: 2.1655207
MixupTrain:  epoch  0, batch   300 | loss: 2.5106704
MixupTrain:  epoch  0, batch   301 | loss: 2.3096037
MixupTrain:  epoch  0, batch   302 | loss: 2.2254055
MixupTrain:  epoch  0, batch   303 | loss: 2.5069041
MixupTrain:  epoch  0, batch   304 | loss: 2.4028690
MixupTrain:  epoch  0, batch   305 | loss: 2.2578471
MixupTrain:  epoch  0, batch   306 | loss: 2.3363354
MixupTrain:  epoch  0, batch   307 | loss: 2.2443132
MixupTrain:  epoch  0, batch   308 | loss: 2.2795892
MixupTrain:  epoch  0, batch   309 | loss: 2.1748333
MixupTrain:  epoch  0, batch   310 | loss: 2.2541447
MixupTrain:  epoch  0, batch   311 | loss: 2.3564572
MixupTrain:  epoch  0, batch   312 | loss: 2.6597526
MixupTrain:  epoch  0, batch   313 | loss: 2.3673115
MixupTrain:  epoch  0, batch   314 | loss: 2.1979618
MixupTrain:  epoch  0, batch   315 | loss: 2.2654700
MixupTrain:  epoch  0, batch   316 | loss: 2.3228419
MixupTrain:  epoch  0, batch   317 | loss: 2.2827771
MixupTrain:  epoch  0, batch   318 | loss: 2.3993206
MixupTrain:  epoch  0, batch   319 | loss: 2.3445582
MixupTrain:  epoch  0, batch   320 | loss: 2.3853979
MixupTrain:  epoch  0, batch   321 | loss: 2.4375687
MixupTrain:  epoch  0, batch   322 | loss: 2.4196265
MixupTrain:  epoch  0, batch   323 | loss: 2.3826036
MixupTrain:  epoch  0, batch   324 | loss: 2.4176295
MixupTrain:  epoch  0, batch   325 | loss: 2.3040209
MixupTrain:  epoch  0, batch   326 | loss: 2.3971300
MixupTrain:  epoch  0, batch   327 | loss: 2.3686347
MixupTrain:  epoch  0, batch   328 | loss: 2.5867243
MixupTrain:  epoch  0, batch   329 | loss: 2.3840079
MixupTrain:  epoch  0, batch   330 | loss: 2.5190978
MixupTrain:  epoch  0, batch   331 | loss: 2.3138518
MixupTrain:  epoch  0, batch   332 | loss: 2.4465995
MixupTrain:  epoch  0, batch   333 | loss: 2.2455802
MixupTrain:  epoch  0, batch   334 | loss: 2.2472823
MixupTrain:  epoch  0, batch   335 | loss: 2.1958752
MixupTrain:  epoch  0, batch   336 | loss: 2.2295032
MixupTrain:  epoch  0, batch   337 | loss: 2.2481213
MixupTrain:  epoch  0, batch   338 | loss: 2.3165226
MixupTrain:  epoch  0, batch   339 | loss: 2.5398326
MixupTrain:  epoch  0, batch   340 | loss: 2.5353980
MixupTrain:  epoch  0, batch   341 | loss: 2.3113117
MixupTrain:  epoch  0, batch   342 | loss: 2.4500093
MixupTrain:  epoch  0, batch   343 | loss: 2.3380795
MixupTrain:  epoch  0, batch   344 | loss: 2.4031026
MixupTrain:  epoch  0, batch   345 | loss: 2.3399465
MixupTrain:  epoch  0, batch   346 | loss: 2.4101672
MixupTrain:  epoch  0, batch   347 | loss: 2.5031781
MixupTrain:  epoch  0, batch   348 | loss: 2.0340605
MixupTrain:  epoch  0, batch   349 | loss: 2.2368207
MixupTrain:  epoch  0, batch   350 | loss: 2.3376312
MixupTrain:  epoch  0, batch   351 | loss: 2.4554491
MixupTrain:  epoch  0, batch   352 | loss: 2.5606651
MixupTrain:  epoch  0, batch   353 | loss: 2.1601038
MixupTrain:  epoch  0, batch   354 | loss: 2.2548790
MixupTrain:  epoch  0, batch   355 | loss: 2.3551393
MixupTrain:  epoch  0, batch   356 | loss: 2.3304415
MixupTrain:  epoch  0, batch   357 | loss: 2.0209873
MixupTrain:  epoch  0, batch   358 | loss: 2.2471452
MixupTrain:  epoch  0, batch   359 | loss: 2.1900277
MixupTrain:  epoch  0, batch   360 | loss: 2.2657106
MixupTrain:  epoch  0, batch   361 | loss: 2.2853806
MixupTrain:  epoch  0, batch   362 | loss: 2.3891566
MixupTrain:  epoch  0, batch   363 | loss: 2.5220227
MixupTrain:  epoch  0, batch   364 | loss: 2.2659395
MixupTrain:  epoch  0, batch   365 | loss: 2.2449455
MixupTrain:  epoch  0, batch   366 | loss: 2.2286749
MixupTrain:  epoch  0, batch   367 | loss: 2.3090072
MixupTrain:  epoch  0, batch   368 | loss: 2.1978254
MixupTrain:  epoch  0, batch   369 | loss: 2.4613681
MixupTrain:  epoch  0, batch   370 | loss: 2.2427378
MixupTrain:  epoch  0, batch   371 | loss: 2.2879009
MixupTrain:  epoch  0, batch   372 | loss: 2.2160399
MixupTrain:  epoch  0, batch   373 | loss: 2.2844496
MixupTrain:  epoch  0, batch   374 | loss: 2.3589253
MixupTrain:  epoch  0, batch   375 | loss: 2.3404396
MixupTrain:  epoch  0, batch   376 | loss: 2.4454834
MixupTrain:  epoch  0, batch   377 | loss: 2.4260368
MixupTrain:  epoch  0, batch   378 | loss: 2.2250509
MixupTrain:  epoch  0, batch   379 | loss: 2.5520630
MixupTrain:  epoch  0, batch   380 | loss: 2.2806704
MixupTrain:  epoch  0, batch   381 | loss: 2.3780944
MixupTrain:  epoch  0, batch   382 | loss: 2.3902731
MixupTrain:  epoch  0, batch   383 | loss: 2.2130547
MixupTrain:  epoch  0, batch   384 | loss: 2.3139918
MixupTrain:  epoch  0, batch   385 | loss: 2.4851127
MixupTrain:  epoch  0, batch   386 | loss: 2.2515888
MixupTrain:  epoch  0, batch   387 | loss: 2.2163260
MixupTrain:  epoch  0, batch   388 | loss: 2.4976885
MixupTrain:  epoch  0, batch   389 | loss: 2.4503868
MixupTrain:  epoch  0, batch   390 | loss: 2.4646616
MixupTrain:  epoch  0, batch   391 | loss: 2.3476315
MixupTrain:  epoch  0, batch   392 | loss: 2.2667179
MixupTrain:  epoch  0, batch   393 | loss: 2.5562954
MixupTrain:  epoch  0, batch   394 | loss: 2.2700539
MixupTrain:  epoch  0, batch   395 | loss: 2.3126466
MixupTrain:  epoch  0, batch   396 | loss: 2.3083565
MixupTrain:  epoch  0, batch   397 | loss: 2.0155408
MixupTrain:  epoch  0, batch   398 | loss: 2.3483534
MixupTrain:  epoch  0, batch   399 | loss: 2.2906129
MixupTrain:  epoch  0, batch   400 | loss: 2.2369184
MixupTrain:  epoch  0, batch   401 | loss: 2.5446355
MixupTrain:  epoch  0, batch   402 | loss: 2.2042553
MixupTrain:  epoch  0, batch   403 | loss: 2.1751835
MixupTrain:  epoch  0, batch   404 | loss: 2.4875588
MixupTrain:  epoch  0, batch   405 | loss: 2.7299490
MixupTrain:  epoch  0, batch   406 | loss: 2.2331536
MixupTrain:  epoch  0, batch   407 | loss: 2.5638695
MixupTrain:  epoch  0, batch   408 | loss: 2.1405180
MixupTrain:  epoch  0, batch   409 | loss: 1.9604335
MixupTrain:  epoch  0, batch   410 | loss: 2.1638668
MixupTrain:  epoch  0, batch   411 | loss: 2.3495152
MixupTrain:  epoch  0, batch   412 | loss: 2.2852426
MixupTrain:  epoch  0, batch   413 | loss: 2.4927678
MixupTrain:  epoch  0, batch   414 | loss: 2.2895703
MixupTrain:  epoch  0, batch   415 | loss: 2.6106036
MixupTrain:  epoch  0, batch   416 | loss: 2.2733254
MixupTrain:  epoch  0, batch   417 | loss: 2.2607560
MixupTrain:  epoch  0, batch   418 | loss: 2.1969733
MixupTrain:  epoch  0, batch   419 | loss: 2.3631244
MixupTrain:  epoch  0, batch   420 | loss: 2.5542979
MixupTrain:  epoch  0, batch   421 | loss: 2.3376191
MixupTrain:  epoch  0, batch   422 | loss: 2.5305476
MixupTrain:  epoch  0, batch   423 | loss: 2.2173409
MixupTrain:  epoch  0, batch   424 | loss: 2.6634786
MixupTrain:  epoch  0, batch   425 | loss: 2.3506029
MixupTrain:  epoch  0, batch   426 | loss: 2.5135043
MixupTrain:  epoch  0, batch   427 | loss: 2.4309368
MixupTrain:  epoch  0, batch   428 | loss: 2.3101616
MixupTrain:  epoch  0, batch   429 | loss: 2.6492100
MixupTrain:  epoch  0, batch   430 | loss: 2.2427185
MixupTrain:  epoch  0, batch   431 | loss: 2.3788748
MixupTrain:  epoch  0, batch   432 | loss: 2.0772676
MixupTrain:  epoch  0, batch   433 | loss: 2.4548042
MixupTrain:  epoch  0, batch   434 | loss: 2.4694843
MixupTrain:  epoch  0, batch   435 | loss: 2.2395272
MixupTrain:  epoch  0, batch   436 | loss: 2.2898545
MixupTrain:  epoch  0, batch   437 | loss: 2.4918885
MixupTrain:  epoch  0, batch   438 | loss: 2.3527634
MixupTrain:  epoch  0, batch   439 | loss: 2.2464468
MixupTrain:  epoch  0, batch   440 | loss: 2.1626592
MixupTrain:  epoch  0, batch   441 | loss: 2.1935010
MixupTrain:  epoch  0, batch   442 | loss: 2.0823946
MixupTrain:  epoch  0, batch   443 | loss: 2.1274939
MixupTrain:  epoch  0, batch   444 | loss: 2.5069094
MixupTrain:  epoch  0, batch   445 | loss: 2.5096397
MixupTrain:  epoch  0, batch   446 | loss: 2.6076393
MixupTrain:  epoch  0, batch   447 | loss: 2.3000069
MixupTrain:  epoch  0, batch   448 | loss: 2.3328516
MixupTrain:  epoch  0, batch   449 | loss: 2.3041916
MixupTrain:  epoch  0, batch   450 | loss: 2.2646575
MixupTrain:  epoch  0, batch   451 | loss: 2.4987154
MixupTrain:  epoch  0, batch   452 | loss: 2.3998437
MixupTrain:  epoch  0, batch   453 | loss: 2.3060975
MixupTrain:  epoch  0, batch   454 | loss: 2.3820858
MixupTrain:  epoch  0, batch   455 | loss: 2.4375844
MixupTrain:  epoch  0, batch   456 | loss: 2.2088180
MixupTrain:  epoch  0, batch   457 | loss: 2.2242270
MixupTrain:  epoch  0, batch   458 | loss: 2.2977943
MixupTrain:  epoch  0, batch   459 | loss: 2.0103793
MixupTrain:  epoch  0, batch   460 | loss: 2.5708518
MixupTrain:  epoch  0, batch   461 | loss: 2.0661259
MixupTrain:  epoch  0, batch   462 | loss: 2.1438763
MixupTrain:  epoch  0, batch   463 | loss: 2.4243808
MixupTrain:  epoch  0, batch   464 | loss: 2.6062341
MixupTrain:  epoch  0, batch   465 | loss: 2.3768888
MixupTrain:  epoch  0, batch   466 | loss: 2.3001847
MixupTrain:  epoch  0, batch   467 | loss: 2.2405968
MixupTrain:  epoch  0, batch   468 | loss: 2.6096525
MixupTrain:  epoch  0, batch   469 | loss: 2.3245015
MixupTrain:  epoch  0, batch   470 | loss: 2.3769217
MixupTrain:  epoch  0, batch   471 | loss: 2.2579825
MixupTrain:  epoch  0, batch   472 | loss: 2.3210325
MixupTrain:  epoch  0, batch   473 | loss: 2.4193940
MixupTrain:  epoch  0, batch   474 | loss: 1.9858072
MixupTrain:  epoch  0, batch   475 | loss: 2.2279186
MixupTrain:  epoch  0, batch   476 | loss: 2.2743192
MixupTrain:  epoch  0, batch   477 | loss: 2.4697015
MixupTrain:  epoch  0, batch   478 | loss: 2.2873390
MixupTrain:  epoch  0, batch   479 | loss: 2.1917553
MixupTrain:  epoch  0, batch   480 | loss: 2.3123040
MixupTrain:  epoch  0, batch   481 | loss: 1.9774077
MixupTrain:  epoch  0, batch   482 | loss: 2.2993305
MixupTrain:  epoch  0, batch   483 | loss: 2.4542875
MixupTrain:  epoch  0, batch   484 | loss: 2.1629386
MixupTrain:  epoch  0, batch   485 | loss: 2.5142138
MixupTrain:  epoch  0, batch   486 | loss: 2.5572667
MixupTrain:  epoch  0, batch   487 | loss: 2.1879203
MixupTrain:  epoch  0, batch   488 | loss: 2.3391287
MixupTrain:  epoch  0, batch   489 | loss: 2.2677188
MixupTrain:  epoch  0, batch   490 | loss: 2.3637614
MixupTrain:  epoch  0, batch   491 | loss: 2.1096234
MixupTrain:  epoch  0, batch   492 | loss: 2.2993069
MixupTrain:  epoch  0, batch   493 | loss: 2.3224564
MixupTrain:  epoch  0, batch   494 | loss: 2.3261399
MixupTrain:  epoch  0, batch   495 | loss: 2.4288859
MixupTrain:  epoch  0, batch   496 | loss: 2.4123528
MixupTrain:  epoch  0, batch   497 | loss: 2.2692389
MixupTrain:  epoch  0, batch   498 | loss: 2.3788304
MixupTrain:  epoch  0, batch   499 | loss: 2.1401434
MixupTrain:  epoch  0, batch   500 | loss: 2.0659022
MixupTrain:  epoch  0, batch   501 | loss: 2.2500219
MixupTrain:  epoch  0, batch   502 | loss: 2.3967414
MixupTrain:  epoch  0, batch   503 | loss: 2.3218822
MixupTrain:  epoch  0, batch   504 | loss: 2.3788424
MixupTrain:  epoch  0, batch   505 | loss: 2.2445180
MixupTrain:  epoch  0, batch   506 | loss: 2.6558208
MixupTrain:  epoch  0, batch   507 | loss: 2.4255557
MixupTrain:  epoch  0, batch   508 | loss: 2.5283504
MixupTrain:  epoch  0, batch   509 | loss: 2.4888229
MixupTrain:  epoch  0, batch   510 | loss: 2.2075720
MixupTrain:  epoch  0, batch   511 | loss: 2.2009404
MixupTrain:  epoch  0, batch   512 | loss: 2.3274174
MixupTrain:  epoch  0, batch   513 | loss: 2.9940245
MixupTrain:  epoch  0, batch   514 | loss: 2.3890536
MixupTrain:  epoch  0, batch   515 | loss: 2.6151955
MixupTrain:  epoch  0, batch   516 | loss: 2.3935792
MixupTrain:  epoch  0, batch   517 | loss: 2.5085707
MixupTrain:  epoch  0, batch   518 | loss: 2.3232591
MixupTrain:  epoch  0, batch   519 | loss: 2.4265254
MixupTrain:  epoch  0, batch   520 | loss: 2.1888113
MixupTrain:  epoch  0, batch   521 | loss: 2.2379112
MixupTrain:  epoch  0, batch   522 | loss: 2.2529063
MixupTrain:  epoch  0, batch   523 | loss: 2.3437440
MixupTrain:  epoch  0, batch   524 | loss: 2.3615043
MixupTrain:  epoch  0, batch   525 | loss: 2.2180390
MixupTrain:  epoch  0, batch   526 | loss: 2.4144144
MixupTrain:  epoch  0, batch   527 | loss: 2.3323305
MixupTrain:  epoch  0, batch   528 | loss: 2.2732623
MixupTrain:  epoch  0, batch   529 | loss: 2.4266753
MixupTrain:  epoch  0, batch   530 | loss: 2.3109176
MixupTrain:  epoch  0, batch   531 | loss: 2.2774572
MixupTrain:  epoch  0, batch   532 | loss: 2.1627717
MixupTrain:  epoch  0, batch   533 | loss: 2.4009554
MixupTrain:  epoch  0, batch   534 | loss: 2.2254696
MixupTrain:  epoch  0, batch   535 | loss: 2.3452129
MixupTrain:  epoch  0, batch   536 | loss: 2.3927164
MixupTrain:  epoch  0, batch   537 | loss: 2.2279427
MixupTrain:  epoch  0, batch   538 | loss: 2.5732136
MixupTrain:  epoch  0, batch   539 | loss: 2.3302460
MixupTrain:  epoch  0, batch   540 | loss: 2.1944683
MixupTrain:  epoch  0, batch   541 | loss: 2.1990755
MixupTrain:  epoch  0, batch   542 | loss: 2.3918562
MixupTrain:  epoch  0, batch   543 | loss: 2.2328687
MixupTrain:  epoch  0, batch   544 | loss: 1.9969586
MixupTrain:  epoch  0, batch   545 | loss: 2.4202108
MixupTrain:  epoch  0, batch   546 | loss: 2.1832390
MixupTrain:  epoch  0, batch   547 | loss: 2.2346411
MixupTrain:  epoch  0, batch   548 | loss: 2.3054810
MixupTrain:  epoch  0, batch   549 | loss: 2.2701058
MixupTrain:  epoch  0, batch   550 | loss: 2.1467016
MixupTrain:  epoch  0, batch   551 | loss: 2.4265752
MixupTrain:  epoch  0, batch   552 | loss: 2.3552499
MixupTrain:  epoch  0, batch   553 | loss: 2.2019343
MixupTrain:  epoch  0, batch   554 | loss: 2.3379068
MixupTrain:  epoch  0, batch   555 | loss: 2.2721381
MixupTrain:  epoch  0, batch   556 | loss: 2.4183249
MixupTrain:  epoch  0, batch   557 | loss: 2.3814850
MixupTrain:  epoch  0, batch   558 | loss: 2.3079591
MixupTrain:  epoch  0, batch   559 | loss: 2.1374326
MixupTrain:  epoch  0, batch   560 | loss: 2.3128805
MixupTrain:  epoch  0, batch   561 | loss: 2.3511574
MixupTrain:  epoch  0, batch   562 | loss: 2.0754316
MixupTrain:  epoch  0, batch   563 | loss: 2.3747017
MixupTrain:  epoch  0, batch   564 | loss: 2.1151862
MixupTrain:  epoch  0, batch   565 | loss: 2.0110469
MixupTrain:  epoch  0, batch   566 | loss: 2.2990711
MixupTrain:  epoch  0, batch   567 | loss: 2.3731110
MixupTrain:  epoch  0, batch   568 | loss: 2.3016515
MixupTrain:  epoch  0, batch   569 | loss: 2.2178054
MixupTrain:  epoch  0, batch   570 | loss: 2.1466031
MixupTrain:  epoch  0, batch   571 | loss: 1.8399014
MixupTrain:  epoch  0, batch   572 | loss: 2.4171841
MixupTrain:  epoch  0, batch   573 | loss: 2.3979950
MixupTrain:  epoch  0, batch   574 | loss: 2.5644772
MixupTrain:  epoch  0, batch   575 | loss: 2.3380504
MixupTrain:  epoch  0, batch   576 | loss: 2.1872399
MixupTrain:  epoch  0, batch   577 | loss: 2.0995336
MixupTrain:  epoch  0, batch   578 | loss: 2.3903558
MixupTrain:  epoch  0, batch   579 | loss: 2.3327379
MixupTrain:  epoch  0, batch   580 | loss: 2.3734913
MixupTrain:  epoch  0, batch   581 | loss: 2.4843016
MixupTrain:  epoch  0, batch   582 | loss: 2.1496882
MixupTrain:  epoch  0, batch   583 | loss: 2.2916570
MixupTrain:  epoch  0, batch   584 | loss: 2.2787132
MixupTrain:  epoch  0, batch   585 | loss: 2.1721864
MixupTrain:  epoch  0, batch   586 | loss: 2.1053572
MixupTrain:  epoch  0, batch   587 | loss: 2.2440982
MixupTrain:  epoch  0, batch   588 | loss: 2.3863451
MixupTrain:  epoch  0, batch   589 | loss: 2.0869555
MixupTrain:  epoch  0, batch   590 | loss: 2.4437122
MixupTrain:  epoch  0, batch   591 | loss: 2.3266425
MixupTrain:  epoch  0, batch   592 | loss: 2.1791244
MixupTrain:  epoch  0, batch   593 | loss: 2.1497464
MixupTrain:  epoch  0, batch   594 | loss: 2.2106450
MixupTrain:  epoch  0, batch   595 | loss: 2.3336320
MixupTrain:  epoch  0, batch   596 | loss: 2.2751167
MixupTrain:  epoch  0, batch   597 | loss: 2.5213149
MixupTrain:  epoch  0, batch   598 | loss: 2.3867903
MixupTrain:  epoch  0, batch   599 | loss: 2.2239113
MixupTrain:  epoch  0, batch   600 | loss: 2.2872515
MixupTrain:  epoch  0, batch   601 | loss: 2.2989564
MixupTrain:  epoch  0, batch   602 | loss: 2.2670069
MixupTrain:  epoch  0, batch   603 | loss: 2.4357245
MixupTrain:  epoch  0, batch   604 | loss: 2.4806266
MixupTrain:  epoch  0, batch   605 | loss: 2.3338728
MixupTrain:  epoch  0, batch   606 | loss: 2.2714503
MixupTrain:  epoch  0, batch   607 | loss: 2.1586180
MixupTrain:  epoch  0, batch   608 | loss: 2.1826158
MixupTrain:  epoch  0, batch   609 | loss: 2.2211959
MixupTrain:  epoch  0, batch   610 | loss: 2.4873905
MixupTrain:  epoch  0, batch   611 | loss: 2.0205233
MixupTrain:  epoch  0, batch   612 | loss: 2.1502542
MixupTrain:  epoch  0, batch   613 | loss: 2.4389751
MixupTrain:  epoch  0, batch   614 | loss: 2.1499443
MixupTrain:  epoch  0, batch   615 | loss: 2.2537651
MixupTrain:  epoch  0, batch   616 | loss: 2.3810182
MixupTrain:  epoch  0, batch   617 | loss: 2.2528377
MixupTrain:  epoch  0, batch   618 | loss: 2.0707972
MixupTrain:  epoch  0, batch   619 | loss: 2.3318076
MixupTrain:  epoch  0, batch   620 | loss: 2.3954177
MixupTrain:  epoch  0, batch   621 | loss: 2.4032114
MixupTrain:  epoch  0, batch   622 | loss: 2.2288556
MixupTrain:  epoch  0, batch   623 | loss: 2.1471186
MixupTrain:  epoch  0, batch   624 | loss: 2.5255063
MixupTrain:  epoch  0, batch   625 | loss: 2.2809343
MixupTrain:  epoch  0, batch   626 | loss: 2.0873780
MixupTrain:  epoch  0, batch   627 | loss: 2.6706543
MixupTrain:  epoch  0, batch   628 | loss: 1.9822252
MixupTrain:  epoch  0, batch   629 | loss: 2.0953476
MixupTrain:  epoch  0, batch   630 | loss: 2.0395596
MixupTrain:  epoch  0, batch   631 | loss: 2.2548056
MixupTrain:  epoch  0, batch   632 | loss: 2.0664558
MixupTrain:  epoch  0, batch   633 | loss: 2.2805119
MixupTrain:  epoch  0, batch   634 | loss: 2.3156390
MixupTrain:  epoch  0, batch   635 | loss: 2.0753684
MixupTrain:  epoch  0, batch   636 | loss: 2.3435817
MixupTrain:  epoch  0, batch   637 | loss: 2.3793473
MixupTrain:  epoch  0, batch   638 | loss: 2.4562249
MixupTrain:  epoch  0, batch   639 | loss: 2.3068614
MixupTrain:  epoch  0, batch   640 | loss: 2.4851804
MixupTrain:  epoch  0, batch   641 | loss: 2.5371046
MixupTrain:  epoch  0, batch   642 | loss: 2.2033901
MixupTrain:  epoch  0, batch   643 | loss: 2.1377912
MixupTrain:  epoch  0, batch   644 | loss: 2.4543128
MixupTrain:  epoch  0, batch   645 | loss: 2.2635880
MixupTrain:  epoch  0, batch   646 | loss: 2.3539779
MixupTrain:  epoch  0, batch   647 | loss: 2.1789050
MixupTrain:  epoch  0, batch   648 | loss: 2.3899221
MixupTrain:  epoch  0, batch   649 | loss: 2.4042149
MixupTrain:  epoch  0, batch   650 | loss: 2.0291719
MixupTrain:  epoch  0, batch   651 | loss: 2.4351225
MixupTrain:  epoch  0, batch   652 | loss: 2.3515892
MixupTrain:  epoch  0, batch   653 | loss: 2.2986734
MixupTrain:  epoch  0, batch   654 | loss: 2.6465948
MixupTrain:  epoch  0, batch   655 | loss: 2.1559060
MixupTrain:  epoch  0, batch   656 | loss: 2.3712795
MixupTrain:  epoch  0, batch   657 | loss: 2.4101140
MixupTrain:  epoch  0, batch   658 | loss: 2.1902411
MixupTrain:  epoch  0, batch   659 | loss: 2.4218655
MixupTrain:  epoch  0, batch   660 | loss: 2.0711963
MixupTrain:  epoch  0, batch   661 | loss: 2.0531192
MixupTrain:  epoch  0, batch   662 | loss: 2.4134202
MixupTrain:  epoch  0, batch   663 | loss: 2.2593458
MixupTrain:  epoch  0, batch   664 | loss: 2.9557149
MixupTrain:  epoch  0, batch   665 | loss: 2.5512822
MixupTrain:  epoch  0, batch   666 | loss: 2.3034964
MixupTrain:  epoch  0, batch   667 | loss: 2.5882430
MixupTrain:  epoch  0, batch   668 | loss: 2.3850298
MixupTrain:  epoch  0, batch   669 | loss: 2.3087809
MixupTrain:  epoch  0, batch   670 | loss: 2.2239585
MixupTrain:  epoch  0, batch   671 | loss: 2.1370440
MixupTrain:  epoch  0, batch   672 | loss: 2.2754278
MixupTrain:  epoch  0, batch   673 | loss: 2.4828417
MixupTrain:  epoch  0, batch   674 | loss: 2.1907821
MixupTrain:  epoch  0, batch   675 | loss: 2.3904514
MixupTrain:  epoch  0, batch   676 | loss: 2.0491033
MixupTrain:  epoch  0, batch   677 | loss: 2.1302087
MixupTrain:  epoch  0, batch   678 | loss: 2.5412970
MixupTrain:  epoch  0, batch   679 | loss: 2.2146051
MixupTrain:  epoch  0, batch   680 | loss: 2.3245287
MixupTrain:  epoch  0, batch   681 | loss: 2.0746355
MixupTrain:  epoch  0, batch   682 | loss: 2.1381984
MixupTrain:  epoch  0, batch   683 | loss: 2.2435846
MixupTrain:  epoch  0, batch   684 | loss: 2.1841543
MixupTrain:  epoch  0, batch   685 | loss: 2.4582663
MixupTrain:  epoch  0, batch   686 | loss: 2.1644154
MixupTrain:  epoch  0, batch   687 | loss: 2.2908378
MixupTrain:  epoch  0, batch   688 | loss: 2.1201262
MixupTrain:  epoch  0, batch   689 | loss: 2.3087497
MixupTrain:  epoch  0, batch   690 | loss: 2.1004000
MixupTrain:  epoch  0, batch   691 | loss: 2.6773529
MixupTrain:  epoch  0, batch   692 | loss: 2.3618977
MixupTrain:  epoch  0, batch   693 | loss: 2.3587954
MixupTrain:  epoch  0, batch   694 | loss: 2.2226927
MixupTrain:  epoch  0, batch   695 | loss: 2.3316355
MixupTrain:  epoch  0, batch   696 | loss: 2.4117343
MixupTrain:  epoch  0, batch   697 | loss: 2.0827708
MixupTrain:  epoch  0, batch   698 | loss: 2.2021813
MixupTrain:  epoch  0, batch   699 | loss: 2.4692438
MixupTrain:  epoch  0, batch   700 | loss: 2.6436911
MixupTrain:  epoch  0, batch   701 | loss: 2.5856624
MixupTrain:  epoch  0, batch   702 | loss: 2.3804235
MixupTrain:  epoch  0, batch   703 | loss: 2.2561169
MixupTrain:  epoch  0, batch   704 | loss: 2.0870774
MixupTrain:  epoch  0, batch   705 | loss: 2.3266678
MixupTrain:  epoch  0, batch   706 | loss: 2.1535347
MixupTrain:  epoch  0, batch   707 | loss: 2.2752824
MixupTrain:  epoch  0, batch   708 | loss: 2.3288500
MixupTrain:  epoch  0, batch   709 | loss: 2.3754225
MixupTrain:  epoch  0, batch   710 | loss: 2.4958935
MixupTrain:  epoch  0, batch   711 | loss: 2.2106056
MixupTrain:  epoch  0, batch   712 | loss: 2.3464108
MixupTrain:  epoch  0, batch   713 | loss: 2.3249297
MixupTrain:  epoch  0, batch   714 | loss: 2.1687675
MixupTrain:  epoch  0, batch   715 | loss: 2.1496685
MixupTrain:  epoch  0, batch   716 | loss: 2.1697242
MixupTrain:  epoch  0, batch   717 | loss: 2.1300936
MixupTrain:  epoch  0, batch   718 | loss: 2.3381224
MixupTrain:  epoch  0, batch   719 | loss: 2.1942930
MixupTrain:  epoch  0, batch   720 | loss: 2.2443695
MixupTrain:  epoch  0, batch   721 | loss: 2.0784197
MixupTrain:  epoch  0, batch   722 | loss: 2.3689756
MixupTrain:  epoch  0, batch   723 | loss: 2.2825804
MixupTrain:  epoch  0, batch   724 | loss: 2.0715108
MixupTrain:  epoch  0, batch   725 | loss: 2.2540348
MixupTrain:  epoch  0, batch   726 | loss: 2.2155302
MixupTrain:  epoch  0, batch   727 | loss: 2.4481726
MixupTrain:  epoch  0, batch   728 | loss: 2.3128238
MixupTrain:  epoch  0, batch   729 | loss: 2.4670506
MixupTrain:  epoch  0, batch   730 | loss: 2.3223052
MixupTrain:  epoch  0, batch   731 | loss: 2.1181874
MixupTrain:  epoch  0, batch   732 | loss: 2.2470834
MixupTrain:  epoch  0, batch   733 | loss: 2.2304626
MixupTrain:  epoch  0, batch   734 | loss: 2.4360290
MixupTrain:  epoch  0, batch   735 | loss: 2.1160769
MixupTrain:  epoch  0, batch   736 | loss: 2.4167912
MixupTrain:  epoch  0, batch   737 | loss: 2.6295958
MixupTrain:  epoch  0, batch   738 | loss: 2.0829682
MixupTrain:  epoch  0, batch   739 | loss: 2.0236745
MixupTrain:  epoch  0, batch   740 | loss: 2.2299838
MixupTrain:  epoch  0, batch   741 | loss: 2.4678435
MixupTrain:  epoch  0, batch   742 | loss: 2.1021008
MixupTrain:  epoch  0, batch   743 | loss: 2.1967821
MixupTrain:  epoch  0, batch   744 | loss: 2.3129187
MixupTrain:  epoch  0, batch   745 | loss: 2.2703326
MixupTrain:  epoch  0, batch   746 | loss: 2.1367583
MixupTrain:  epoch  0, batch   747 | loss: 2.2873721
MixupTrain:  epoch  0, batch   748 | loss: 2.1708922
MixupTrain:  epoch  0, batch   749 | loss: 2.2464004
MixupTrain:  epoch  0, batch   750 | loss: 2.0428054
MixupTrain:  epoch  0, batch   751 | loss: 2.4090481
MixupTrain:  epoch  0, batch   752 | loss: 2.4263630
MixupTrain:  epoch  0, batch   753 | loss: 2.1947813
MixupTrain:  epoch  0, batch   754 | loss: 2.5535207
MixupTrain:  epoch  0, batch   755 | loss: 2.3051944
MixupTrain:  epoch  0, batch   756 | loss: 2.1889219
MixupTrain:  epoch  0, batch   757 | loss: 2.4476278
MixupTrain:  epoch  0, batch   758 | loss: 2.4236155
MixupTrain:  epoch  0, batch   759 | loss: 2.1835103
MixupTrain:  epoch  0, batch   760 | loss: 2.3778825
MixupTrain:  epoch  0, batch   761 | loss: 2.3695130
MixupTrain:  epoch  0, batch   762 | loss: 2.2106194
MixupTrain:  epoch  0, batch   763 | loss: 2.1452413
MixupTrain:  epoch  0, batch   764 | loss: 2.0482335
MixupTrain:  epoch  0, batch   765 | loss: 2.4094880
MixupTrain:  epoch  0, batch   766 | loss: 2.3478549
MixupTrain:  epoch  0, batch   767 | loss: 2.4893911
MixupTrain:  epoch  0, batch   768 | loss: 2.0153456
MixupTrain:  epoch  0, batch   769 | loss: 2.3316398
MixupTrain:  epoch  0, batch   770 | loss: 2.1579185
MixupTrain:  epoch  0, batch   771 | loss: 2.1207209
MixupTrain:  epoch  0, batch   772 | loss: 2.2205791
MixupTrain:  epoch  0, batch   773 | loss: 2.4620912
MixupTrain:  epoch  0, batch   774 | loss: 2.3049817
MixupTrain:  epoch  0, batch   775 | loss: 2.3714657
MixupTrain:  epoch  0, batch   776 | loss: 2.1608651
MixupTrain:  epoch  0, batch   777 | loss: 2.4529626
MixupTrain:  epoch  0, batch   778 | loss: 2.3483548
MixupTrain:  epoch  0, batch   779 | loss: 2.2077458
MixupTrain:  epoch  0, batch   780 | loss: 2.2865391
MixupTrain:  epoch  0, batch   781 | loss: 2.1288779
MixupTrain:  epoch  0, batch   782 | loss: 2.0770986
MixupTrain:  epoch  0, batch   783 | loss: 2.2785106
MixupTrain:  epoch  0, batch   784 | loss: 2.1151371
MixupTrain:  epoch  0, batch   785 | loss: 2.1906059
MixupTrain:  epoch  0, batch   786 | loss: 2.4253993
MixupTrain:  epoch  0, batch   787 | loss: 2.5633173
MixupTrain:  epoch  0, batch   788 | loss: 2.1754985
MixupTrain:  epoch  0, batch   789 | loss: 2.1658056
MixupTrain:  epoch  0, batch   790 | loss: 2.5797038
MixupTrain:  epoch  0, batch   791 | loss: 2.3259397
MixupTrain:  epoch  0, batch   792 | loss: 2.3200235
MixupTrain:  epoch  0, batch   793 | loss: 2.3140898
MixupTrain:  epoch  0, batch   794 | loss: 2.1123681
MixupTrain:  epoch  0, batch   795 | loss: 2.3829145
MixupTrain:  epoch  0, batch   796 | loss: 2.3939681
MixupTrain:  epoch  0, batch   797 | loss: 2.4045057
MixupTrain:  epoch  0, batch   798 | loss: 2.2450628
MixupTrain:  epoch  0, batch   799 | loss: 2.0711589
MixupTrain:  epoch  0, batch   800 | loss: 1.9629873
MixupTrain:  epoch  0, batch   801 | loss: 2.2883098
MixupTrain:  epoch  0, batch   802 | loss: 2.2502348
MixupTrain:  epoch  0, batch   803 | loss: 2.3044727
MixupTrain:  epoch  0, batch   804 | loss: 2.4105518
MixupTrain:  epoch  0, batch   805 | loss: 2.1001563
MixupTrain:  epoch  0, batch   806 | loss: 2.3011029
MixupTrain:  epoch  0, batch   807 | loss: 1.9831824
MixupTrain:  epoch  0, batch   808 | loss: 2.5299940
MixupTrain:  epoch  0, batch   809 | loss: 2.4794545
MixupTrain:  epoch  0, batch   810 | loss: 2.1657424
MixupTrain:  epoch  0, batch   811 | loss: 2.1527405
MixupTrain:  epoch  0, batch   812 | loss: 2.4791408
MixupTrain:  epoch  0, batch   813 | loss: 2.0571733
MixupTrain:  epoch  0, batch   814 | loss: 2.1565366
MixupTrain:  epoch  0, batch   815 | loss: 2.2452910
MixupTrain:  epoch  0, batch   816 | loss: 2.1244557
MixupTrain:  epoch  0, batch   817 | loss: 2.3134627
MixupTrain:  epoch  0, batch   818 | loss: 2.4706616
MixupTrain:  epoch  0, batch   819 | loss: 2.5633044
MixupTrain:  epoch  0, batch   820 | loss: 2.3312235
MixupTrain:  epoch  0, batch   821 | loss: 2.3103566
MixupTrain:  epoch  0, batch   822 | loss: 2.6694901
MixupTrain:  epoch  0, batch   823 | loss: 2.4055467
MixupTrain:  epoch  0, batch   824 | loss: 2.1251101
MixupTrain:  epoch  0, batch   825 | loss: 2.3663335
MixupTrain:  epoch  0, batch   826 | loss: 2.4773738
MixupTrain:  epoch  0, batch   827 | loss: 2.3255334
MixupTrain:  epoch  0, batch   828 | loss: 2.1669347
MixupTrain:  epoch  0, batch   829 | loss: 2.1468964
MixupTrain:  epoch  0, batch   830 | loss: 2.1900342
MixupTrain:  epoch  0, batch   831 | loss: 2.4426789
MixupTrain:  epoch  0, batch   832 | loss: 2.2779937
MixupTrain:  epoch  0, batch   833 | loss: 2.2394590
MixupTrain:  epoch  0, batch   834 | loss: 1.9700770
MixupTrain:  epoch  0, batch   835 | loss: 2.3922577
MixupTrain:  epoch  0, batch   836 | loss: 2.2522264
MixupTrain:  epoch  0, batch   837 | loss: 2.1093454
MixupTrain:  epoch  0, batch   838 | loss: 2.1755111
MixupTrain:  epoch  0, batch   839 | loss: 2.3452806
MixupTrain:  epoch  0, batch   840 | loss: 2.3354256
MixupTrain:  epoch  0, batch   841 | loss: 2.1626687
MixupTrain:  epoch  0, batch   842 | loss: 2.1508231
MixupTrain:  epoch  0, batch   843 | loss: 2.4584253
MixupTrain:  epoch  0, batch   844 | loss: 2.2305899
MixupTrain:  epoch  0, batch   845 | loss: 2.2496133
MixupTrain:  epoch  0, batch   846 | loss: 2.4183526
MixupTrain:  epoch  0, batch   847 | loss: 2.3496549
MixupTrain:  epoch  0, batch   848 | loss: 2.3300095
MixupTrain:  epoch  0, batch   849 | loss: 1.9729801
MixupTrain:  epoch  0, batch   850 | loss: 2.3383172
MixupTrain:  epoch  0, batch   851 | loss: 2.2849536
MixupTrain:  epoch  0, batch   852 | loss: 2.2474604
MixupTrain:  epoch  0, batch   853 | loss: 2.3599007
MixupTrain:  epoch  0, batch   854 | loss: 1.9311416
MixupTrain:  epoch  0, batch   855 | loss: 2.3009679
MixupTrain:  epoch  0, batch   856 | loss: 2.3536422
MixupTrain:  epoch  0, batch   857 | loss: 2.3013940
MixupTrain:  epoch  0, batch   858 | loss: 2.2206841
MixupTrain:  epoch  0, batch   859 | loss: 2.5252752
MixupTrain:  epoch  0, batch   860 | loss: 2.3899746
MixupTrain:  epoch  0, batch   861 | loss: 2.1506839
MixupTrain:  epoch  0, batch   862 | loss: 2.3311992
MixupTrain:  epoch  0, batch   863 | loss: 2.3117137
MixupTrain:  epoch  0, batch   864 | loss: 2.2311172
MixupTrain:  epoch  0, batch   865 | loss: 1.9915806
MixupTrain:  epoch  0, batch   866 | loss: 2.2636318
MixupTrain:  epoch  0, batch   867 | loss: 2.2008910
MixupTrain:  epoch  0, batch   868 | loss: 2.3833623
MixupTrain:  epoch  0, batch   869 | loss: 2.3383853
MixupTrain:  epoch  0, batch   870 | loss: 2.5592771
MixupTrain:  epoch  0, batch   871 | loss: 2.2886648
MixupTrain:  epoch  0, batch   872 | loss: 2.1057065
MixupTrain:  epoch  0, batch   873 | loss: 2.3231509
MixupTrain:  epoch  0, batch   874 | loss: 2.2659013
MixupTrain:  epoch  0, batch   875 | loss: 2.2047071
MixupTrain:  epoch  0, batch   876 | loss: 2.4269507
MixupTrain:  epoch  0, batch   877 | loss: 2.2118487
MixupTrain:  epoch  0, batch   878 | loss: 2.5496182
MixupTrain:  epoch  0, batch   879 | loss: 2.2509441
MixupTrain:  epoch  0, batch   880 | loss: 2.1908548
MixupTrain:  epoch  0, batch   881 | loss: 2.3566499
MixupTrain:  epoch  0, batch   882 | loss: 2.2886164
MixupTrain:  epoch  0, batch   883 | loss: 2.2592173
MixupTrain:  epoch  0, batch   884 | loss: 2.1287496
MixupTrain:  epoch  0, batch   885 | loss: 2.2204921
MixupTrain:  epoch  0, batch   886 | loss: 2.2546625
MixupTrain:  epoch  0, batch   887 | loss: 2.0949690
MixupTrain:  epoch  0, batch   888 | loss: 2.0416589
MixupTrain:  epoch  0, batch   889 | loss: 2.2318645
MixupTrain:  epoch  0, batch   890 | loss: 2.4250572
MixupTrain:  epoch  0, batch   891 | loss: 2.3180890
MixupTrain:  epoch  0, batch   892 | loss: 2.0000789
MixupTrain:  epoch  0, batch   893 | loss: 2.1844339
MixupTrain:  epoch  0, batch   894 | loss: 2.3563881
MixupTrain:  epoch  0, batch   895 | loss: 2.5554118
MixupTrain:  epoch  0, batch   896 | loss: 2.1314721
MixupTrain:  epoch  0, batch   897 | loss: 2.1917050
MixupTrain:  epoch  0, batch   898 | loss: 2.3513274
MixupTrain:  epoch  0, batch   899 | loss: 2.6317003
MixupTrain:  epoch  0, batch   900 | loss: 2.1934347
MixupTrain:  epoch  0, batch   901 | loss: 2.1302419
MixupTrain:  epoch  0, batch   902 | loss: 2.4904468
MixupTrain:  epoch  0, batch   903 | loss: 2.1033683
MixupTrain:  epoch  0, batch   904 | loss: 2.1179435
MixupTrain:  epoch  0, batch   905 | loss: 2.3380830
MixupTrain:  epoch  0, batch   906 | loss: 2.4309773
MixupTrain:  epoch  0, batch   907 | loss: 2.7041361
MixupTrain:  epoch  0, batch   908 | loss: 2.2149806
MixupTrain:  epoch  0, batch   909 | loss: 2.3055370
MixupTrain:  epoch  0, batch   910 | loss: 2.1447375
MixupTrain:  epoch  0, batch   911 | loss: 2.4664984
MixupTrain:  epoch  0, batch   912 | loss: 2.1743302
MixupTrain:  epoch  0, batch   913 | loss: 2.0601571
MixupTrain:  epoch  0, batch   914 | loss: 2.1253946
MixupTrain:  epoch  0, batch   915 | loss: 2.3914244
MixupTrain:  epoch  0, batch   916 | loss: 2.1137967
MixupTrain:  epoch  0, batch   917 | loss: 2.0288382
MixupTrain:  epoch  0, batch   918 | loss: 2.0249224
MixupTrain:  epoch  0, batch   919 | loss: 2.3500130
MixupTrain:  epoch  0, batch   920 | loss: 2.2556233
MixupTrain:  epoch  0, batch   921 | loss: 2.3340397
MixupTrain:  epoch  0, batch   922 | loss: 2.3558240
MixupTrain:  epoch  0, batch   923 | loss: 2.1328654
MixupTrain:  epoch  0, batch   924 | loss: 2.2399812
MixupTrain:  epoch  0, batch   925 | loss: 2.1684988
MixupTrain:  epoch  0, batch   926 | loss: 2.2125504
MixupTrain:  epoch  0, batch   927 | loss: 2.2353690
MixupTrain:  epoch  0, batch   928 | loss: 2.0116498
MixupTrain:  epoch  0, batch   929 | loss: 2.4993911
MixupTrain:  epoch  0, batch   930 | loss: 2.0548007
MixupTrain:  epoch  0, batch   931 | loss: 2.1944599
MixupTrain:  epoch  0, batch   932 | loss: 2.3957705
MixupTrain:  epoch  0, batch   933 | loss: 2.3038192
MixupTrain:  epoch  0, batch   934 | loss: 2.4587436
MixupTrain:  epoch  0, batch   935 | loss: 2.0646248
MixupTrain:  epoch  0, batch   936 | loss: 2.1449745
MixupTrain:  epoch  0, batch   937 | loss: 2.3078210
MixupTrain:  epoch  0, batch   938 | loss: 2.3968585
MixupTrain:  epoch  0, batch   939 | loss: 1.9740875
MixupTrain:  epoch  0, batch   940 | loss: 2.4424458
MixupTrain:  epoch  0, batch   941 | loss: 2.1307638
MixupTrain:  epoch  0, batch   942 | loss: 2.3528180
MixupTrain:  epoch  0, batch   943 | loss: 2.1966519
MixupTrain:  epoch  0, batch   944 | loss: 2.2636561
MixupTrain:  epoch  0, batch   945 | loss: 2.3778505
MixupTrain:  epoch  0, batch   946 | loss: 2.1563132
MixupTrain:  epoch  0, batch   947 | loss: 2.4722476
MixupTrain:  epoch  0, batch   948 | loss: 2.6427655
MixupTrain:  epoch  0, batch   949 | loss: 2.3286524
MixupTrain:  epoch  0, batch   950 | loss: 2.0491891
MixupTrain:  epoch  0, batch   951 | loss: 2.1867943
MixupTrain:  epoch  0, batch   952 | loss: 2.1236215
MixupTrain:  epoch  0, batch   953 | loss: 2.3015146
MixupTrain:  epoch  0, batch   954 | loss: 2.1520743
MixupTrain:  epoch  0, batch   955 | loss: 2.2231867
MixupTrain:  epoch  0, batch   956 | loss: 2.4107676
MixupTrain:  epoch  0, batch   957 | loss: 2.2184148
MixupTrain:  epoch  0, batch   958 | loss: 2.4036822
MixupTrain:  epoch  0, batch   959 | loss: 2.2763400
MixupTrain:  epoch  0, batch   960 | loss: 2.3904521
MixupTrain:  epoch  0, batch   961 | loss: 2.0963001
MixupTrain:  epoch  0, batch   962 | loss: 1.9968286
MixupTrain:  epoch  0, batch   963 | loss: 2.0526750
MixupTrain:  epoch  0, batch   964 | loss: 2.4779317
MixupTrain:  epoch  0, batch   965 | loss: 2.2573724
MixupTrain:  epoch  0, batch   966 | loss: 2.4775596
MixupTrain:  epoch  0, batch   967 | loss: 2.4570549
MixupTrain:  epoch  0, batch   968 | loss: 2.4865050
MixupTrain:  epoch  0, batch   969 | loss: 2.3807783
MixupTrain:  epoch  0, batch   970 | loss: 2.4679623
MixupTrain:  epoch  0, batch   971 | loss: 2.3166237
MixupTrain:  epoch  0, batch   972 | loss: 1.9497197
MixupTrain:  epoch  0, batch   973 | loss: 2.3745506
MixupTrain:  epoch  0, batch   974 | loss: 2.1387663
MixupTrain:  epoch  0, batch   975 | loss: 2.3692086
MixupTrain:  epoch  0, batch   976 | loss: 2.2963862
MixupTrain:  epoch  0, batch   977 | loss: 2.3689489
MixupTrain:  epoch  0, batch   978 | loss: 2.1832595
MixupTrain:  epoch  0, batch   979 | loss: 1.9847316
MixupTrain:  epoch  0, batch   980 | loss: 2.3064566
MixupTrain:  epoch  0, batch   981 | loss: 2.3463378
MixupTrain:  epoch  0, batch   982 | loss: 2.3545251
MixupTrain:  epoch  0, batch   983 | loss: 2.2478566
MixupTrain:  epoch  0, batch   984 | loss: 2.2188249
MixupTrain:  epoch  0, batch   985 | loss: 2.3432288
MixupTrain:  epoch  0, batch   986 | loss: 2.1535137
MixupTrain:  epoch  0, batch   987 | loss: 2.2753928
MixupTrain:  epoch  0, batch   988 | loss: 2.1598985
MixupTrain:  epoch  0, batch   989 | loss: 2.4102726
MixupTrain:  epoch  0, batch   990 | loss: 2.4552178
MixupTrain:  epoch  0, batch   991 | loss: 2.3663149
MixupTrain:  epoch  0, batch   992 | loss: 2.2752285
MixupTrain:  epoch  0, batch   993 | loss: 2.1497657
MixupTrain:  epoch  0, batch   994 | loss: 2.6169624
MixupTrain:  epoch  0, batch   995 | loss: 1.9731477
MixupTrain:  epoch  0, batch   996 | loss: 2.0541584
MixupTrain:  epoch  0, batch   997 | loss: 2.2283604
MixupTrain:  epoch  0, batch   998 | loss: 2.1313672
MixupTrain:  epoch  0, batch   999 | loss: 2.1003687
MixupTrain:  epoch  0, batch  1000 | loss: 2.0701814
MixupTrain:  epoch  0, batch  1001 | loss: 2.2472649
MixupTrain:  epoch  0, batch  1002 | loss: 2.5820646
MixupTrain:  epoch  0, batch  1003 | loss: 2.2144244
MixupTrain:  epoch  0, batch  1004 | loss: 1.9378756
MixupTrain:  epoch  0, batch  1005 | loss: 2.2195895
MixupTrain:  epoch  0, batch  1006 | loss: 2.3422952
MixupTrain:  epoch  0, batch  1007 | loss: 2.1699076
MixupTrain:  epoch  0, batch  1008 | loss: 2.4288592
MixupTrain:  epoch  0, batch  1009 | loss: 2.4721863
MixupTrain:  epoch  0, batch  1010 | loss: 2.2989280
MixupTrain:  epoch  0, batch  1011 | loss: 2.2599669
MixupTrain:  epoch  0, batch  1012 | loss: 2.2947659
MixupTrain:  epoch  0, batch  1013 | loss: 2.2685690
MixupTrain:  epoch  0, batch  1014 | loss: 2.3631010
MixupTrain:  epoch  0, batch  1015 | loss: 2.3730302
MixupTrain:  epoch  0, batch  1016 | loss: 2.3300974
MixupTrain:  epoch  0, batch  1017 | loss: 2.3199346
MixupTrain:  epoch  0, batch  1018 | loss: 2.1259766
MixupTrain:  epoch  0, batch  1019 | loss: 2.4345446
MixupTrain:  epoch  0, batch  1020 | loss: 2.2463303
MixupTrain:  epoch  0, batch  1021 | loss: 2.4515495
MixupTrain:  epoch  0, batch  1022 | loss: 2.3326125
MixupTrain:  epoch  0, batch  1023 | loss: 2.2007270
MixupTrain:  epoch  0, batch  1024 | loss: 2.2312772
MixupTrain:  epoch  0, batch  1025 | loss: 2.2167239
MixupTrain:  epoch  0, batch  1026 | loss: 2.5666158
MixupTrain:  epoch  0, batch  1027 | loss: 2.1719613
MixupTrain:  epoch  0, batch  1028 | loss: 2.3385179
MixupTrain:  epoch  0, batch  1029 | loss: 2.1357253
MixupTrain:  epoch  0, batch  1030 | loss: 2.3755867
MixupTrain:  epoch  0, batch  1031 | loss: 2.3456218
MixupTrain:  epoch  0, batch  1032 | loss: 2.2096033
MixupTrain:  epoch  0, batch  1033 | loss: 2.1919661
MixupTrain:  epoch  0, batch  1034 | loss: 2.3303590
MixupTrain:  epoch  0, batch  1035 | loss: 2.1846173
MixupTrain:  epoch  0, batch  1036 | loss: 2.3576183
MixupTrain:  epoch  0, batch  1037 | loss: 2.4716294
MixupTrain:  epoch  0, batch  1038 | loss: 2.1839130
MixupTrain:  epoch  0, batch  1039 | loss: 2.2251787
MixupTrain:  epoch  0, batch  1040 | loss: 2.4721498
MixupTrain:  epoch  0, batch  1041 | loss: 2.3472073
MixupTrain:  epoch  0, batch  1042 | loss: 2.5274820
MixupTrain:  epoch  0, batch  1043 | loss: 2.3710287
MixupTrain:  epoch  0, batch  1044 | loss: 2.1356082
MixupTrain:  epoch  0, batch  1045 | loss: 2.3337159
MixupTrain:  epoch  0, batch  1046 | loss: 2.2868631
MixupTrain:  epoch  0, batch  1047 | loss: 2.2086060
MixupTrain:  epoch  0, batch  1048 | loss: 2.5048981
MixupTrain:  epoch  0, batch  1049 | loss: 2.3798332
MixupTrain:  epoch  0, batch  1050 | loss: 2.1651726
MixupTrain:  epoch  0, batch  1051 | loss: 2.4041746
MixupTrain:  epoch  0, batch  1052 | loss: 2.3808198
MixupTrain:  epoch  0, batch  1053 | loss: 2.1177721
MixupTrain:  epoch  0, batch  1054 | loss: 2.2737746
MixupTrain:  epoch  0, batch  1055 | loss: 2.5084827
MixupTrain:  epoch  0, batch  1056 | loss: 2.2574351
MixupTrain:  epoch  0, batch  1057 | loss: 2.3099928
MixupTrain:  epoch  0, batch  1058 | loss: 2.3415570
MixupTrain:  epoch  0, batch  1059 | loss: 2.6310058
MixupTrain:  epoch  0, batch  1060 | loss: 2.0739076
MixupTrain:  epoch  0, batch  1061 | loss: 2.1855388
MixupTrain:  epoch  0, batch  1062 | loss: 2.1771452
MixupTrain:  epoch  0, batch  1063 | loss: 2.2926726
MixupTrain:  epoch  0, batch  1064 | loss: 2.2014513
MixupTrain:  epoch  0, batch  1065 | loss: 2.2859211
MixupTrain:  epoch  0, batch  1066 | loss: 2.3784862
MixupTrain:  epoch  0, batch  1067 | loss: 2.3801928
MixupTrain:  epoch  0, batch  1068 | loss: 2.0772867
MixupTrain:  epoch  0, batch  1069 | loss: 2.3321147
MixupTrain:  epoch  0, batch  1070 | loss: 2.2675295
MixupTrain:  epoch  0, batch  1071 | loss: 2.2052200
MixupTrain:  epoch  0, batch  1072 | loss: 2.1087048
MixupTrain:  epoch  0, batch  1073 | loss: 2.1678705
MixupTrain:  epoch  0, batch  1074 | loss: 2.1077895
MixupTrain:  epoch  0, batch  1075 | loss: 2.3460073
MixupTrain:  epoch  0, batch  1076 | loss: 2.3638778
MixupTrain:  epoch  0, batch  1077 | loss: 2.3983932
MixupTrain:  epoch  0, batch  1078 | loss: 2.2159631
MixupTrain:  epoch  0, batch  1079 | loss: 2.0629437
MixupTrain:  epoch  0, batch  1080 | loss: 2.3968644
MixupTrain:  epoch  0, batch  1081 | loss: 2.3815160
MixupTrain:  epoch  0, batch  1082 | loss: 2.1665761
MixupTrain:  epoch  0, batch  1083 | loss: 2.0560012
MixupTrain:  epoch  0, batch  1084 | loss: 2.5121233
MixupTrain:  epoch  0, batch  1085 | loss: 2.4562101
MixupTrain:  epoch  0, batch  1086 | loss: 2.3760662
MixupTrain:  epoch  0, batch  1087 | loss: 2.3906841
MixupTrain:  epoch  0, batch  1088 | loss: 2.4121985
MixupTrain:  epoch  0, batch  1089 | loss: 2.1470060
MixupTrain:  epoch  0, batch  1090 | loss: 2.3532324
MixupTrain:  epoch  0, batch  1091 | loss: 2.1564465
MixupTrain:  epoch  0, batch  1092 | loss: 2.2065856
MixupTrain:  epoch  0, batch  1093 | loss: 2.3827362
MixupTrain:  epoch  0, batch  1094 | loss: 2.1798239
MixupTrain:  epoch  0, batch  1095 | loss: 2.3283701
MixupTrain:  epoch  0, batch  1096 | loss: 2.3145502
MixupTrain:  epoch  0, batch  1097 | loss: 2.2415018
MixupTrain:  epoch  0, batch  1098 | loss: 2.1821256
MixupTrain:  epoch  0, batch  1099 | loss: 2.0377707
MixupTrain:  epoch  0, batch  1100 | loss: 2.4691677
MixupTrain:  epoch  0, batch  1101 | loss: 2.5063074
MixupTrain:  epoch  0, batch  1102 | loss: 2.1214099
MixupTrain:  epoch  0, batch  1103 | loss: 2.2774923
MixupTrain:  epoch  0, batch  1104 | loss: 2.3233936
MixupTrain:  epoch  0, batch  1105 | loss: 2.4800713
MixupTrain:  epoch  0, batch  1106 | loss: 2.2860115
MixupTrain:  epoch  0, batch  1107 | loss: 2.3592334
MixupTrain:  epoch  0, batch  1108 | loss: 2.0519114
MixupTrain:  epoch  0, batch  1109 | loss: 2.3504646
MixupTrain:  epoch  0, batch  1110 | loss: 2.1622012
MixupTrain:  epoch  0, batch  1111 | loss: 2.3565886
MixupTrain:  epoch  0, batch  1112 | loss: 2.2835457
MixupTrain:  epoch  0, batch  1113 | loss: 2.2158198
MixupTrain:  epoch  0, batch  1114 | loss: 2.3335552
MixupTrain:  epoch  0, batch  1115 | loss: 2.3186302
MixupTrain:  epoch  0, batch  1116 | loss: 2.2912288
MixupTrain:  epoch  0, batch  1117 | loss: 2.3230047
MixupTrain:  epoch  0, batch  1118 | loss: 2.1418982
MixupTrain:  epoch  0, batch  1119 | loss: 2.3280756
MixupTrain:  epoch  0, batch  1120 | loss: 2.3457460
MixupTrain:  epoch  0, batch  1121 | loss: 2.0877509
MixupTrain:  epoch  0, batch  1122 | loss: 2.3531084
MixupTrain:  epoch  0, batch  1123 | loss: 2.0949292
MixupTrain:  epoch  0, batch  1124 | loss: 2.2130470
MixupTrain:  epoch  0, batch  1125 | loss: 2.1906190
MixupTrain:  epoch  0, batch  1126 | loss: 2.4566245
MixupTrain:  epoch  0, batch  1127 | loss: 2.1165016
MixupTrain:  epoch  0, batch  1128 | loss: 2.1344080
MixupTrain:  epoch  0, batch  1129 | loss: 1.9998984
MixupTrain:  epoch  0, batch  1130 | loss: 2.1341984
MixupTrain:  epoch  0, batch  1131 | loss: 2.0095892
MixupTrain:  epoch  0, batch  1132 | loss: 2.3621149
MixupTrain:  epoch  0, batch  1133 | loss: 2.2998168
MixupTrain:  epoch  0, batch  1134 | loss: 2.7542574
MixupTrain:  epoch  0, batch  1135 | loss: 2.2444472
MixupTrain:  epoch  0, batch  1136 | loss: 2.2413039
MixupTrain:  epoch  0, batch  1137 | loss: 2.1443152
MixupTrain:  epoch  0, batch  1138 | loss: 2.1843226
MixupTrain:  epoch  0, batch  1139 | loss: 2.0774224
MixupTrain:  epoch  0, batch  1140 | loss: 2.1213489
MixupTrain:  epoch  0, batch  1141 | loss: 2.1130195
MixupTrain:  epoch  0, batch  1142 | loss: 2.4349048
MixupTrain:  epoch  0, batch  1143 | loss: 2.3369143
MixupTrain:  epoch  0, batch  1144 | loss: 2.1144557
MixupTrain:  epoch  0, batch  1145 | loss: 2.5638957
MixupTrain:  epoch  0, batch  1146 | loss: 2.3945599
MixupTrain:  epoch  0, batch  1147 | loss: 2.3463991
MixupTrain:  epoch  0, batch  1148 | loss: 2.2788315
MixupTrain:  epoch  0, batch  1149 | loss: 2.1608069
MixupTrain:  epoch  0, batch  1150 | loss: 2.4253068
MixupTrain:  epoch  0, batch  1151 | loss: 2.2147765
MixupTrain:  epoch  0, batch  1152 | loss: 2.1243265
MixupTrain:  epoch  0, batch  1153 | loss: 2.3307056
MixupTrain:  epoch  0, batch  1154 | loss: 2.3162992
MixupTrain:  epoch  0, batch  1155 | loss: 2.4276838
MixupTrain:  epoch  0, batch  1156 | loss: 2.3648148
MixupTrain:  epoch  0, batch  1157 | loss: 2.2024164
MixupTrain:  epoch  0, batch  1158 | loss: 1.9504361
MixupTrain:  epoch  0, batch  1159 | loss: 2.5797043
MixupTrain:  epoch  0, batch  1160 | loss: 2.3327827
MixupTrain:  epoch  0, batch  1161 | loss: 2.0107305
MixupTrain:  epoch  0, batch  1162 | loss: 2.0929639
MixupTrain:  epoch  0, batch  1163 | loss: 2.1232729
MixupTrain:  epoch  0, batch  1164 | loss: 2.1056094
MixupTrain:  epoch  0, batch  1165 | loss: 2.3994431
MixupTrain:  epoch  0, batch  1166 | loss: 2.0708308
MixupTrain:  epoch  0, batch  1167 | loss: 2.4332867
MixupTrain:  epoch  0, batch  1168 | loss: 2.0448186
MixupTrain:  epoch  0, batch  1169 | loss: 2.2442999
MixupTrain:  epoch  0, batch  1170 | loss: 2.3524425
MixupTrain:  epoch  0, batch  1171 | loss: 2.2173433
MixupTrain:  epoch  0, batch  1172 | loss: 2.1184800
MixupTrain:  epoch  0, batch  1173 | loss: 2.3576756
MixupTrain:  epoch  0, batch  1174 | loss: 2.0476162
MixupTrain:  epoch  0, batch  1175 | loss: 2.1266639
MixupTrain:  epoch  0, batch  1176 | loss: 2.5222096
MixupTrain:  epoch  0, batch  1177 | loss: 2.1195383
MixupTrain:  epoch  0, batch  1178 | loss: 2.1889267
MixupTrain:  epoch  0, batch  1179 | loss: 2.0754614
MixupTrain:  epoch  0, batch  1180 | loss: 2.2906873
MixupTrain:  epoch  0, batch  1181 | loss: 2.1616962
MixupTrain:  epoch  0, batch  1182 | loss: 2.0022655
MixupTrain:  epoch  0, batch  1183 | loss: 2.2004955
MixupTrain:  epoch  0, batch  1184 | loss: 2.2255638
MixupTrain:  epoch  0, batch  1185 | loss: 2.1008224
MixupTrain:  epoch  0, batch  1186 | loss: 2.0654678
MixupTrain:  epoch  0, batch  1187 | loss: 2.3479459
MixupTrain:  epoch  0, batch  1188 | loss: 2.0250978
MixupTrain:  epoch  0, batch  1189 | loss: 2.4566903
MixupTrain:  epoch  0, batch  1190 | loss: 2.2787979
MixupTrain:  epoch  0, batch  1191 | loss: 2.0897698
MixupTrain:  epoch  0, batch  1192 | loss: 2.3567863
MixupTrain:  epoch  0, batch  1193 | loss: 2.3393650
MixupTrain:  epoch  0, batch  1194 | loss: 2.2104528
MixupTrain:  epoch  0, batch  1195 | loss: 2.3183236
MixupTrain:  epoch  0, batch  1196 | loss: 2.1879220
MixupTrain:  epoch  0, batch  1197 | loss: 2.2424984
MixupTrain:  epoch  0, batch  1198 | loss: 2.1685846
MixupTrain:  epoch  0, batch  1199 | loss: 2.2103491
MixupTrain:  epoch  0, batch  1200 | loss: 2.1927872
MixupTrain:  epoch  0, batch  1201 | loss: 2.1803157
MixupTrain:  epoch  0, batch  1202 | loss: 2.1527190
MixupTrain:  epoch  0, batch  1203 | loss: 2.0469174
MixupTrain:  epoch  0, batch  1204 | loss: 2.0728035
MixupTrain:  epoch  0, batch  1205 | loss: 2.0860884
MixupTrain:  epoch  0, batch  1206 | loss: 2.5446296
MixupTrain:  epoch  0, batch  1207 | loss: 2.3605678
MixupTrain:  epoch  0, batch  1208 | loss: 2.2192466
MixupTrain:  epoch  0, batch  1209 | loss: 2.3700507
MixupTrain:  epoch  0, batch  1210 | loss: 2.4813120
MixupTrain:  epoch  0, batch  1211 | loss: 2.2908068
MixupTrain:  epoch  0, batch  1212 | loss: 2.1599152
MixupTrain:  epoch  0, batch  1213 | loss: 2.1680436
MixupTrain:  epoch  0, batch  1214 | loss: 2.4975343
MixupTrain:  epoch  0, batch  1215 | loss: 2.2404032
MixupTrain:  epoch  0, batch  1216 | loss: 2.1158035
MixupTrain:  epoch  0, batch  1217 | loss: 2.1716981
MixupTrain:  epoch  0, batch  1218 | loss: 2.0054431
MixupTrain:  epoch  0, batch  1219 | loss: 2.1341069
MixupTrain:  epoch  0, batch  1220 | loss: 2.3071871
MixupTrain:  epoch  0, batch  1221 | loss: 2.2788291
MixupTrain:  epoch  0, batch  1222 | loss: 2.1896040
MixupTrain:  epoch  0, batch  1223 | loss: 2.3949540
MixupTrain:  epoch  0, batch  1224 | loss: 2.3842549
MixupTrain:  epoch  0, batch  1225 | loss: 2.1351008
MixupTrain:  epoch  0, batch  1226 | loss: 2.1832228
MixupTrain:  epoch  0, batch  1227 | loss: 2.1874948
MixupTrain:  epoch  0, batch  1228 | loss: 2.1738162
MixupTrain:  epoch  0, batch  1229 | loss: 2.2177534
MixupTrain:  epoch  0, batch  1230 | loss: 2.5155134
MixupTrain:  epoch  0, batch  1231 | loss: 2.1953678
MixupTrain:  epoch  0, batch  1232 | loss: 2.2674742
MixupTrain:  epoch  0, batch  1233 | loss: 2.0424287
MixupTrain:  epoch  0, batch  1234 | loss: 2.5303407
MixupTrain:  epoch  0, batch  1235 | loss: 2.4063520
MixupTrain:  epoch  0, batch  1236 | loss: 2.2138684
MixupTrain:  epoch  0, batch  1237 | loss: 2.1797748
MixupTrain:  epoch  0, batch  1238 | loss: 2.3463831
MixupTrain:  epoch  0, batch  1239 | loss: 2.2953715
MixupTrain:  epoch  0, batch  1240 | loss: 2.2962599
MixupTrain:  epoch  0, batch  1241 | loss: 2.3955345
MixupTrain:  epoch  0, batch  1242 | loss: 2.1677437
MixupTrain:  epoch  0, batch  1243 | loss: 2.3654776
MixupTrain:  epoch  0, batch  1244 | loss: 2.1886775
MixupTrain:  epoch  0, batch  1245 | loss: 2.2725177
MixupTrain:  epoch  0, batch  1246 | loss: 2.2988539
MixupTrain:  epoch  0, batch  1247 | loss: 2.4903316
MixupTrain:  epoch  0, batch  1248 | loss: 2.3491290
MixupTrain:  epoch  0, batch  1249 | loss: 2.1363742
MixupTrain:  epoch  0, batch  1250 | loss: 2.1182909
MixupTrain:  epoch  0, batch  1251 | loss: 2.3489010
MixupTrain:  epoch  0, batch  1252 | loss: 2.5163264
MixupTrain:  epoch  0, batch  1253 | loss: 2.5947161
MixupTrain:  epoch  0, batch  1254 | loss: 2.5448785
MixupTrain:  epoch  0, batch  1255 | loss: 2.3307440
MixupTrain:  epoch  0, batch  1256 | loss: 2.1378846
MixupTrain:  epoch  0, batch  1257 | loss: 2.1710134
MixupTrain:  epoch  0, batch  1258 | loss: 2.0546942
MixupTrain:  epoch  0, batch  1259 | loss: 2.2226620
MixupTrain:  epoch  0, batch  1260 | loss: 2.0922623
MixupTrain:  epoch  0, batch  1261 | loss: 2.4152005
MixupTrain:  epoch  0, batch  1262 | loss: 2.2379146
MixupTrain:  epoch  0, batch  1263 | loss: 2.1663837
MixupTrain:  epoch  0, batch  1264 | loss: 2.1741254
MixupTrain:  epoch  0, batch  1265 | loss: 2.1606843
MixupTrain:  epoch  0, batch  1266 | loss: 2.1447537
MixupTrain:  epoch  0, batch  1267 | loss: 2.2154429
MixupTrain:  epoch  0, batch  1268 | loss: 2.3493505
MixupTrain:  epoch  0, batch  1269 | loss: 2.2019172
MixupTrain:  epoch  0, batch  1270 | loss: 2.3812723
MixupTrain:  epoch  0, batch  1271 | loss: 2.3131576
MixupTrain:  epoch  0, batch  1272 | loss: 2.4600906
MixupTrain:  epoch  0, batch  1273 | loss: 2.1103077
MixupTrain:  epoch  0, batch  1274 | loss: 2.1663890
MixupTrain:  epoch  0, batch  1275 | loss: 2.3557935
MixupTrain:  epoch  0, batch  1276 | loss: 1.9768441
MixupTrain:  epoch  0, batch  1277 | loss: 2.3270226
MixupTrain:  epoch  0, batch  1278 | loss: 2.3961782
MixupTrain:  epoch  0, batch  1279 | loss: 2.4142895
MixupTrain:  epoch  0, batch  1280 | loss: 2.1319022
MixupTrain:  epoch  0, batch  1281 | loss: 2.1485996
MixupTrain:  epoch  0, batch  1282 | loss: 2.3173285
MixupTrain:  epoch  0, batch  1283 | loss: 2.5925241
MixupTrain:  epoch  0, batch  1284 | loss: 2.3057780
MixupTrain:  epoch  0, batch  1285 | loss: 2.3819070
MixupTrain:  epoch  0, batch  1286 | loss: 2.5041678
MixupTrain:  epoch  0, batch  1287 | loss: 2.2856569
MixupTrain:  epoch  0, batch  1288 | loss: 2.5194657
MixupTrain:  epoch  0, batch  1289 | loss: 2.2024696
MixupTrain:  epoch  0, batch  1290 | loss: 2.1291180
MixupTrain:  epoch  0, batch  1291 | loss: 2.2704823
MixupTrain:  epoch  0, batch  1292 | loss: 2.4367526
MixupTrain:  epoch  0, batch  1293 | loss: 2.4321771
MixupTrain:  epoch  0, batch  1294 | loss: 2.3252299
MixupTrain:  epoch  0, batch  1295 | loss: 2.2130284
MixupTrain:  epoch  0, batch  1296 | loss: 2.1194229
MixupTrain:  epoch  0, batch  1297 | loss: 2.4246798
MixupTrain:  epoch  0, batch  1298 | loss: 2.3603292
MixupTrain:  epoch  0, batch  1299 | loss: 2.1320982
MixupTrain:  epoch  0, batch  1300 | loss: 2.3298967
MixupTrain:  epoch  0, batch  1301 | loss: 2.1700180
MixupTrain:  epoch  0, batch  1302 | loss: 2.4830141
MixupTrain:  epoch  0, batch  1303 | loss: 2.4749908
MixupTrain:  epoch  0, batch  1304 | loss: 2.4375510
MixupTrain:  epoch  0, batch  1305 | loss: 2.3905444
MixupTrain:  epoch  0, batch  1306 | loss: 2.3150411
MixupTrain:  epoch  0, batch  1307 | loss: 2.0852580
MixupTrain:  epoch  0, batch  1308 | loss: 2.2640927
MixupTrain:  epoch  0, batch  1309 | loss: 2.6362658
MixupTrain:  epoch  0, batch  1310 | loss: 2.2705016
MixupTrain:  epoch  0, batch  1311 | loss: 2.3138552
MixupTrain:  epoch  0, batch  1312 | loss: 2.1364260
MixupTrain:  epoch  0, batch  1313 | loss: 2.3036721
MixupTrain:  epoch  0, batch  1314 | loss: 2.3850925
MixupTrain:  epoch  0, batch  1315 | loss: 2.1297848
MixupTrain:  epoch  0, batch  1316 | loss: 2.2643790
MixupTrain:  epoch  0, batch  1317 | loss: 2.2520792
MixupTrain:  epoch  0, batch  1318 | loss: 2.2664161
MixupTrain:  epoch  0, batch  1319 | loss: 2.1365814
MixupTrain:  epoch  0, batch  1320 | loss: 2.4280925
MixupTrain:  epoch  0, batch  1321 | loss: 2.0226603
MixupTrain:  epoch  0, batch  1322 | loss: 2.2956948
MixupTrain:  epoch  0, batch  1323 | loss: 2.2679789
MixupTrain:  epoch  0, batch  1324 | loss: 2.2955456
MixupTrain:  epoch  0, batch  1325 | loss: 2.0405626
MixupTrain:  epoch  0, batch  1326 | loss: 2.3383718
MixupTrain:  epoch  0, batch  1327 | loss: 2.4921644
MixupTrain:  epoch  0, batch  1328 | loss: 2.2166820
MixupTrain:  epoch  0, batch  1329 | loss: 2.3941185
MixupTrain:  epoch  0, batch  1330 | loss: 2.2457366
MixupTrain:  epoch  0, batch  1331 | loss: 2.3005714
MixupTrain:  epoch  0, batch  1332 | loss: 2.3073742
MixupTrain:  epoch  0, batch  1333 | loss: 2.4223108
MixupTrain:  epoch  0, batch  1334 | loss: 2.3001938
MixupTrain:  epoch  0, batch  1335 | loss: 2.2669966
MixupTrain:  epoch  0, batch  1336 | loss: 1.9472255
MixupTrain:  epoch  0, batch  1337 | loss: 2.4175978
MixupTrain:  epoch  0, batch  1338 | loss: 2.4724865
MixupTrain:  epoch  0, batch  1339 | loss: 2.2054763
MixupTrain:  epoch  0, batch  1340 | loss: 2.1964583
MixupTrain:  epoch  0, batch  1341 | loss: 2.1821637
MixupTrain:  epoch  0, batch  1342 | loss: 2.1779771
MixupTrain:  epoch  0, batch  1343 | loss: 2.4785581
MemoryTrain:  epoch  0, batch     0 | loss: 2.1930904
MemoryTrain:  epoch  0, batch     1 | loss: 2.7041192
MemoryTrain:  epoch  0, batch     2 | loss: 2.6263385
MemoryTrain:  epoch  0, batch     3 | loss: 2.3731704
MemoryTrain:  epoch  0, batch     4 | loss: 2.3320198
MemoryTrain:  epoch  0, batch     5 | loss: 2.3650620
MemoryTrain:  epoch  0, batch     6 | loss: 3.0732095
MemoryTrain:  epoch  0, batch     7 | loss: 2.5691900
MemoryTrain:  epoch  0, batch     8 | loss: 2.1459260
MemoryTrain:  epoch  0, batch     9 | loss: 2.5785193
MemoryTrain:  epoch  0, batch    10 | loss: 2.0232739
MemoryTrain:  epoch  0, batch    11 | loss: 1.9492264
MemoryTrain:  epoch  1, batch     0 | loss: 1.8320695
MemoryTrain:  epoch  1, batch     1 | loss: 1.8316785
MemoryTrain:  epoch  1, batch     2 | loss: 2.4663818
MemoryTrain:  epoch  1, batch     3 | loss: 2.1482327
MemoryTrain:  epoch  1, batch     4 | loss: 1.9739182
MemoryTrain:  epoch  1, batch     5 | loss: 1.8504965
MemoryTrain:  epoch  1, batch     6 | loss: 1.8477832
MemoryTrain:  epoch  1, batch     7 | loss: 1.8875760
MemoryTrain:  epoch  1, batch     8 | loss: 1.8408442
MemoryTrain:  epoch  1, batch     9 | loss: 1.8660604
MemoryTrain:  epoch  1, batch    10 | loss: 2.7962365
MemoryTrain:  epoch  1, batch    11 | loss: 1.9325222
MemoryTrain:  epoch  2, batch     0 | loss: 1.9860102
MemoryTrain:  epoch  2, batch     1 | loss: 2.0779254
MemoryTrain:  epoch  2, batch     2 | loss: 2.0511305
MemoryTrain:  epoch  2, batch     3 | loss: 2.0639403
MemoryTrain:  epoch  2, batch     4 | loss: 1.8583211
MemoryTrain:  epoch  2, batch     5 | loss: 2.1952085
MemoryTrain:  epoch  2, batch     6 | loss: 1.8472201
MemoryTrain:  epoch  2, batch     7 | loss: 1.8685094
MemoryTrain:  epoch  2, batch     8 | loss: 1.8455286
MemoryTrain:  epoch  2, batch     9 | loss: 1.9032110
MemoryTrain:  epoch  2, batch    10 | loss: 1.8385375
MemoryTrain:  epoch  2, batch    11 | loss: 1.8194851
MemoryTrain:  epoch  3, batch     0 | loss: 1.8171974
MemoryTrain:  epoch  3, batch     1 | loss: 1.8194287
MemoryTrain:  epoch  3, batch     2 | loss: 1.8116837
MemoryTrain:  epoch  3, batch     3 | loss: 1.8412981
MemoryTrain:  epoch  3, batch     4 | loss: 1.8142679
MemoryTrain:  epoch  3, batch     5 | loss: 1.8107569
MemoryTrain:  epoch  3, batch     6 | loss: 1.8105378
MemoryTrain:  epoch  3, batch     7 | loss: 1.8128196
MemoryTrain:  epoch  3, batch     8 | loss: 1.8153520
MemoryTrain:  epoch  3, batch     9 | loss: 1.8131680
MemoryTrain:  epoch  3, batch    10 | loss: 1.8139470
MemoryTrain:  epoch  3, batch    11 | loss: 1.8146333
MemoryTrain:  epoch  4, batch     0 | loss: 1.8062160
MemoryTrain:  epoch  4, batch     1 | loss: 1.8103716
MemoryTrain:  epoch  4, batch     2 | loss: 1.8165753
MemoryTrain:  epoch  4, batch     3 | loss: 1.8137424
MemoryTrain:  epoch  4, batch     4 | loss: 1.8182323
MemoryTrain:  epoch  4, batch     5 | loss: 1.8182361
MemoryTrain:  epoch  4, batch     6 | loss: 1.8209321
MemoryTrain:  epoch  4, batch     7 | loss: 1.8110566
MemoryTrain:  epoch  4, batch     8 | loss: 1.8133047
MemoryTrain:  epoch  4, batch     9 | loss: 1.8141898
MemoryTrain:  epoch  4, batch    10 | loss: 1.8311749
MemoryTrain:  epoch  4, batch    11 | loss: 1.8150911
MemoryTrain:  epoch  5, batch     0 | loss: 1.8289174
MemoryTrain:  epoch  5, batch     1 | loss: 1.8336312
MemoryTrain:  epoch  5, batch     2 | loss: 1.8213608
MemoryTrain:  epoch  5, batch     3 | loss: 1.8306158
MemoryTrain:  epoch  5, batch     4 | loss: 1.8088807
MemoryTrain:  epoch  5, batch     5 | loss: 1.8145572
MemoryTrain:  epoch  5, batch     6 | loss: 1.8084512
MemoryTrain:  epoch  5, batch     7 | loss: 1.8111075
MemoryTrain:  epoch  5, batch     8 | loss: 1.8129619
MemoryTrain:  epoch  5, batch     9 | loss: 1.8177829
MemoryTrain:  epoch  5, batch    10 | loss: 1.8238398
MemoryTrain:  epoch  5, batch    11 | loss: 1.8216736
MemoryTrain:  epoch  6, batch     0 | loss: 1.8152306
MemoryTrain:  epoch  6, batch     1 | loss: 1.8171794
MemoryTrain:  epoch  6, batch     2 | loss: 1.8082377
MemoryTrain:  epoch  6, batch     3 | loss: 1.8102041
MemoryTrain:  epoch  6, batch     4 | loss: 1.8081598
MemoryTrain:  epoch  6, batch     5 | loss: 1.8099248
MemoryTrain:  epoch  6, batch     6 | loss: 1.8158475
MemoryTrain:  epoch  6, batch     7 | loss: 1.8084052
MemoryTrain:  epoch  6, batch     8 | loss: 1.8168517
MemoryTrain:  epoch  6, batch     9 | loss: 1.8132232
MemoryTrain:  epoch  6, batch    10 | loss: 1.8179586
MemoryTrain:  epoch  6, batch    11 | loss: 1.8269989
MemoryTrain:  epoch  7, batch     0 | loss: 1.8187976
MemoryTrain:  epoch  7, batch     1 | loss: 1.8266609
MemoryTrain:  epoch  7, batch     2 | loss: 1.8174442
MemoryTrain:  epoch  7, batch     3 | loss: 1.8111544
MemoryTrain:  epoch  7, batch     4 | loss: 1.8122711
MemoryTrain:  epoch  7, batch     5 | loss: 1.8234837
MemoryTrain:  epoch  7, batch     6 | loss: 1.8124602
MemoryTrain:  epoch  7, batch     7 | loss: 1.8077219
MemoryTrain:  epoch  7, batch     8 | loss: 1.8132088
MemoryTrain:  epoch  7, batch     9 | loss: 1.8086405
MemoryTrain:  epoch  7, batch    10 | loss: 1.8137925
MemoryTrain:  epoch  7, batch    11 | loss: 1.8116188
MemoryTrain:  epoch  8, batch     0 | loss: 1.8154762
MemoryTrain:  epoch  8, batch     1 | loss: 1.8140554
MemoryTrain:  epoch  8, batch     2 | loss: 1.8217938
MemoryTrain:  epoch  8, batch     3 | loss: 1.8120077
MemoryTrain:  epoch  8, batch     4 | loss: 1.8186721
MemoryTrain:  epoch  8, batch     5 | loss: 1.8175678
MemoryTrain:  epoch  8, batch     6 | loss: 1.8220406
MemoryTrain:  epoch  8, batch     7 | loss: 1.8435644
MemoryTrain:  epoch  8, batch     8 | loss: 1.8072350
MemoryTrain:  epoch  8, batch     9 | loss: 1.8195792
MemoryTrain:  epoch  8, batch    10 | loss: 1.8217971
MemoryTrain:  epoch  8, batch    11 | loss: 1.8275856
MemoryTrain:  epoch  9, batch     0 | loss: 1.8207724
MemoryTrain:  epoch  9, batch     1 | loss: 1.8117467
MemoryTrain:  epoch  9, batch     2 | loss: 1.8061954
MemoryTrain:  epoch  9, batch     3 | loss: 1.8126401
MemoryTrain:  epoch  9, batch     4 | loss: 1.8121542
MemoryTrain:  epoch  9, batch     5 | loss: 1.8149809
MemoryTrain:  epoch  9, batch     6 | loss: 1.8084909
MemoryTrain:  epoch  9, batch     7 | loss: 1.8094397
MemoryTrain:  epoch  9, batch     8 | loss: 1.8132710
MemoryTrain:  epoch  9, batch     9 | loss: 1.8085409
MemoryTrain:  epoch  9, batch    10 | loss: 1.8113277
MemoryTrain:  epoch  9, batch    11 | loss: 1.8085998
[EVAL] batch:    0 | acc: 100.00%,  total acc: 100.00%   
[EVAL] batch:    1 | acc: 93.75%,  total acc: 96.88%   
[EVAL] batch:    2 | acc: 93.75%,  total acc: 95.83%   
[EVAL] batch:    3 | acc: 100.00%,  total acc: 96.88%   
[EVAL] batch:    4 | acc: 100.00%,  total acc: 97.50%   
[EVAL] batch:    5 | acc: 100.00%,  total acc: 97.92%   
[EVAL] batch:    6 | acc: 100.00%,  total acc: 98.21%   
[EVAL] batch:    7 | acc: 100.00%,  total acc: 98.44%   
[EVAL] batch:    8 | acc: 75.00%,  total acc: 95.83%   
[EVAL] batch:    9 | acc: 43.75%,  total acc: 90.62%   
[EVAL] batch:   10 | acc: 87.50%,  total acc: 90.34%   
[EVAL] batch:   11 | acc: 100.00%,  total acc: 91.15%   
[EVAL] batch:   12 | acc: 100.00%,  total acc: 91.83%   
[EVAL] batch:   13 | acc: 75.00%,  total acc: 90.62%   
[EVAL] batch:    0 | acc: 25.00%,  total acc: 25.00%   
[EVAL] batch:    1 | acc: 43.75%,  total acc: 34.38%   
[EVAL] batch:    2 | acc: 43.75%,  total acc: 37.50%   
[EVAL] batch:    3 | acc: 18.75%,  total acc: 32.81%   
[EVAL] batch:    4 | acc: 31.25%,  total acc: 32.50%   
[EVAL] batch:    5 | acc: 43.75%,  total acc: 34.38%   
[EVAL] batch:    6 | acc: 43.75%,  total acc: 35.71%   
[EVAL] batch:    7 | acc: 25.00%,  total acc: 34.38%   
[EVAL] batch:    8 | acc: 37.50%,  total acc: 34.72%   
[EVAL] batch:    9 | acc: 37.50%,  total acc: 35.00%   
[EVAL] batch:   10 | acc: 31.25%,  total acc: 34.66%   
[EVAL] batch:   11 | acc: 43.75%,  total acc: 35.42%   
[EVAL] batch:   12 | acc: 18.75%,  total acc: 34.13%   
[EVAL] batch:   13 | acc: 25.00%,  total acc: 33.48%   
[EVAL] batch:   14 | acc: 37.50%,  total acc: 33.75%   
[EVAL] batch:   15 | acc: 43.75%,  total acc: 34.38%   
[EVAL] batch:   16 | acc: 56.25%,  total acc: 35.66%   
[EVAL] batch:   17 | acc: 56.25%,  total acc: 36.81%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 38.16%   
[EVAL] batch:   19 | acc: 56.25%,  total acc: 39.06%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 41.96%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 44.60%   
[EVAL] batch:   22 | acc: 93.75%,  total acc: 46.74%   
[EVAL] batch:   23 | acc: 93.75%,  total acc: 48.70%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 50.75%   
[EVAL] batch:   25 | acc: 93.75%,  total acc: 52.40%   
[EVAL] batch:   26 | acc: 43.75%,  total acc: 52.08%   
[EVAL] batch:   27 | acc: 31.25%,  total acc: 51.34%   
[EVAL] batch:   28 | acc: 37.50%,  total acc: 50.86%   
[EVAL] batch:   29 | acc: 50.00%,  total acc: 50.83%   
[EVAL] batch:   30 | acc: 43.75%,  total acc: 50.60%   
[EVAL] batch:   31 | acc: 37.50%,  total acc: 50.20%   
[EVAL] batch:   32 | acc: 75.00%,  total acc: 50.95%   
[EVAL] batch:   33 | acc: 25.00%,  total acc: 50.18%   
[EVAL] batch:   34 | acc: 25.00%,  total acc: 49.46%   
[EVAL] batch:   35 | acc: 0.00%,  total acc: 48.09%   
[EVAL] batch:   36 | acc: 0.00%,  total acc: 46.79%   
[EVAL] batch:   37 | acc: 6.25%,  total acc: 45.72%   
[EVAL] batch:   38 | acc: 12.50%,  total acc: 44.87%   
[EVAL] batch:   39 | acc: 68.75%,  total acc: 45.47%   
[EVAL] batch:   40 | acc: 87.50%,  total acc: 46.49%   
[EVAL] batch:   41 | acc: 75.00%,  total acc: 47.17%   
[EVAL] batch:   42 | acc: 93.75%,  total acc: 48.26%   
[EVAL] batch:   43 | acc: 68.75%,  total acc: 48.72%   
[EVAL] batch:   44 | acc: 68.75%,  total acc: 49.17%   
[EVAL] batch:   45 | acc: 25.00%,  total acc: 48.64%   
[EVAL] batch:   46 | acc: 68.75%,  total acc: 49.07%   
[EVAL] batch:   47 | acc: 87.50%,  total acc: 49.87%   
[EVAL] batch:   48 | acc: 18.75%,  total acc: 49.23%   
[EVAL] batch:   49 | acc: 68.75%,  total acc: 49.62%   
[EVAL] batch:   50 | acc: 56.25%,  total acc: 49.75%   
[EVAL] batch:   51 | acc: 75.00%,  total acc: 50.24%   
[EVAL] batch:   52 | acc: 62.50%,  total acc: 50.47%   
[EVAL] batch:   53 | acc: 100.00%,  total acc: 51.39%   
[EVAL] batch:   54 | acc: 100.00%,  total acc: 52.27%   
[EVAL] batch:   55 | acc: 100.00%,  total acc: 53.12%   
[EVAL] batch:   56 | acc: 93.75%,  total acc: 53.84%   
[EVAL] batch:   57 | acc: 62.50%,  total acc: 53.99%   
[EVAL] batch:   58 | acc: 87.50%,  total acc: 54.56%   
[EVAL] batch:   59 | acc: 75.00%,  total acc: 54.90%   
[EVAL] batch:   60 | acc: 75.00%,  total acc: 55.23%   
[EVAL] batch:   61 | acc: 18.75%,  total acc: 54.64%   
[EVAL] batch:   62 | acc: 43.75%,  total acc: 54.46%   
[EVAL] batch:   63 | acc: 75.00%,  total acc: 54.79%   
[EVAL] batch:   64 | acc: 93.75%,  total acc: 55.38%   
[EVAL] batch:   65 | acc: 68.75%,  total acc: 55.59%   
[EVAL] batch:   66 | acc: 0.00%,  total acc: 54.76%   
[EVAL] batch:   67 | acc: 25.00%,  total acc: 54.32%   
[EVAL] batch:   68 | acc: 6.25%,  total acc: 53.62%   
[EVAL] batch:   69 | acc: 6.25%,  total acc: 52.95%   
[EVAL] batch:   70 | acc: 18.75%,  total acc: 52.46%   
[EVAL] batch:   71 | acc: 18.75%,  total acc: 52.00%   
[EVAL] batch:   72 | acc: 25.00%,  total acc: 51.63%   
[EVAL] batch:   73 | acc: 0.00%,  total acc: 50.93%   
[EVAL] batch:   74 | acc: 0.00%,  total acc: 50.25%   
[EVAL] batch:   75 | acc: 0.00%,  total acc: 49.59%   
[EVAL] batch:   76 | acc: 0.00%,  total acc: 48.94%   
[EVAL] batch:   77 | acc: 0.00%,  total acc: 48.32%   
[EVAL] batch:   78 | acc: 31.25%,  total acc: 48.10%   
[EVAL] batch:   79 | acc: 100.00%,  total acc: 48.75%   
[EVAL] batch:   80 | acc: 100.00%,  total acc: 49.38%   
[EVAL] batch:   81 | acc: 93.75%,  total acc: 49.92%   
[EVAL] batch:   82 | acc: 87.50%,  total acc: 50.38%   
[EVAL] batch:   83 | acc: 81.25%,  total acc: 50.74%   
[EVAL] batch:   84 | acc: 31.25%,  total acc: 50.51%   
[EVAL] batch:   85 | acc: 31.25%,  total acc: 50.29%   
[EVAL] batch:   86 | acc: 50.00%,  total acc: 50.29%   
[EVAL] batch:   87 | acc: 93.75%,  total acc: 50.78%   
[EVAL] batch:   88 | acc: 93.75%,  total acc: 51.26%   
[EVAL] batch:   89 | acc: 93.75%,  total acc: 51.74%   
[EVAL] batch:   90 | acc: 100.00%,  total acc: 52.27%   
[EVAL] batch:   91 | acc: 100.00%,  total acc: 52.79%   
[EVAL] batch:   92 | acc: 100.00%,  total acc: 53.29%   
[EVAL] batch:   93 | acc: 100.00%,  total acc: 53.79%   
[EVAL] batch:   94 | acc: 100.00%,  total acc: 54.28%   
[EVAL] batch:   95 | acc: 81.25%,  total acc: 54.56%   
[EVAL] batch:   96 | acc: 50.00%,  total acc: 54.51%   
[EVAL] batch:   97 | acc: 75.00%,  total acc: 54.72%   
[EVAL] batch:   98 | acc: 100.00%,  total acc: 55.18%   
[EVAL] batch:   99 | acc: 100.00%,  total acc: 55.62%   
[EVAL] batch:  100 | acc: 93.75%,  total acc: 56.00%   
cur_acc:  ['0.8712', '0.8705', '0.7266', '0.8990', '0.5739', '0.9062']
his_acc:  ['0.8712', '0.8564', '0.6238', '0.6241', '0.5469', '0.5600']
CurrentTrain: epoch  0, batch     0 | loss: 6.7325282
CurrentTrain: epoch  0, batch     1 | loss: 6.6598425
CurrentTrain: epoch  1, batch     0 | loss: 5.9152756
CurrentTrain: epoch  1, batch     1 | loss: 6.8263178
CurrentTrain: epoch  2, batch     0 | loss: 6.4278584
CurrentTrain: epoch  2, batch     1 | loss: 6.3015995
CurrentTrain: epoch  3, batch     0 | loss: 5.2658253
CurrentTrain: epoch  3, batch     1 | loss: 5.9231477
CurrentTrain: epoch  4, batch     0 | loss: 4.9131289
CurrentTrain: epoch  4, batch     1 | loss: 4.9187512
CurrentTrain: epoch  5, batch     0 | loss: 4.7845721
CurrentTrain: epoch  5, batch     1 | loss: 3.0901639
CurrentTrain: epoch  6, batch     0 | loss: 3.4204884
CurrentTrain: epoch  6, batch     1 | loss: 3.9330869
CurrentTrain: epoch  7, batch     0 | loss: 3.1185193
CurrentTrain: epoch  7, batch     1 | loss: 4.2933259
CurrentTrain: epoch  8, batch     0 | loss: 4.0967865
CurrentTrain: epoch  8, batch     1 | loss: 2.7239294
CurrentTrain: epoch  9, batch     0 | loss: 3.6254091
CurrentTrain: epoch  9, batch     1 | loss: 2.9338222
#### person stateorprovinces of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovinces of residence" means a person is living in a state or province.
Here is an example:
Relation: person stateorprovinces of residence
Context: the chairman of the senate foreign relations committee , massachusetts democrat john kerry , and the panel 's top republican , richard lugar of indiana , were at the white house meeting , which was led by vice president joe biden , a former chairman of the foreign relations panel .
Head Entity: john kerry
Tail Entity: massachusetts
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovinces of residence":
Relation: person stateorprovinces of residence  
Context: After moving to California for his new job, Michael found himself enjoying the sunny weather and vibrant culture of Los Angeles.  
Head Entity: Michael  
Tail Entity: California  

Relation: person stateorprovinces of residence  
Context: During her time in New York City, Sarah developed a passion for the arts and frequently visited the Metropolitan Museum of Art.  
Head Entity: Sarah  
Tail Entity: New York  

Relation: person stateorprovinces of residence  
Context: Following his retirement, David decided to settle down in Florida, where he could enjoy the warm climate and beautiful beaches.  
Head Entity: David  
Tail Entity: Florida  

Relation: person stateorprovinces of residence  
Context: Growing up in Texas, Emily often reminisced about the vast landscapes and friendly communities that shaped her childhood.  
Head Entity: Emily  
Tail Entity: Texas  

Relation: person stateorprovinces of residence  
Context: After completing her studies in Illinois, Jessica moved to Washington, D.C. to pursue a career in politics.  
Head Entity: Jessica  
Tail Entity: Illinois  
#### person date of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person date of death" means a person was died on a date.
Here is an example:
Relation: person date of death
Context: he passed away on saturday .
Head Entity: he
Tail Entity: saturday
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person date of death":
Relation: person date of death  
Context: John Smith died on March 15, 2020.  
Head Entity: John Smith  
Tail Entity: March 15, 2020  

Relation: person date of death  
Context: The famous author passed away in 1995.  
Head Entity: The famous author  
Tail Entity: 1995  

Relation: person date of death  
Context: She left this world on New Year's Eve.  
Head Entity: She  
Tail Entity: New Year's Eve  

Relation: person date of death  
Context: The scientist's life ended on July 4th, 2018.  
Head Entity: The scientist  
Tail Entity: July 4th, 2018  

Relation: person date of death  
Context: He was reported dead on the morning of February 2nd.  
Head Entity: He  
Tail Entity: February 2nd  
#### organization number of employees members ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization number of employees members" means the number of an organization 's employees is a number.
Here is an example:
Relation: organization number of employees members
Context: mcgovern wants to make the red cross , with 30,000 employees and 700 chapters , more efficient .
Head Entity: red cross
Tail Entity: 30,000
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization number of employees members":
1. Relation: organization number of employees members  
   Context: The tech giant Google boasts a workforce of over 150,000 employees worldwide.  
   Head Entity: Google  
   Tail Entity: 150,000  

2. Relation: organization number of employees members  
   Context: With a dedicated team of 5,000 staff, the nonprofit organization Habitat for Humanity continues to build homes for those in need.  
   Head Entity: Habitat for Humanity  
   Tail Entity: 5,000  

3. Relation: organization number of employees members  
   Context: Amazon has expanded rapidly, now employing more than 1,000,000 people across its various divisions.  
   Head Entity: Amazon  
   Tail Entity: 1,000,000  

4. Relation: organization number of employees members  
   Context: The local university has a total of 2,500 employees, including faculty and administrative staff.  
   Head Entity: local university  
   Tail Entity: 2,500  

5. Relation: organization number of employees members  
   Context: The charity organization Save the Children operates with a workforce of approximately 15,000 individuals globally.  
   Head Entity: Save the Children  
   Tail Entity: 15,000  
#### person alternate names ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person alternate names" means a person 's alias is a person.
Here is an example:
Relation: person alternate names
Context: they represent a continuation of the company 's jerome robbins celebration that began in the spring at lincoln center to mark the 10th anniversary of robbins ' death .
Head Entity: jerome robbins
Tail Entity: robbins
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person alternate names":
Relation: person alternate names  
Context: The famous author Samuel Langhorne Clemens is better known by his pen name, Mark Twain, which he adopted during his writing career.  
Head Entity: Samuel Langhorne Clemens  
Tail Entity: Mark Twain  

Relation: person alternate names  
Context: The musician known as Prince was born as Prince Rogers Nelson, a name that reflects his heritage and family background.  
Head Entity: Prince Rogers Nelson  
Tail Entity: Prince  

Relation: person alternate names  
Context: The legendary basketball player Michael Jordan is often referred to simply as "MJ" by fans and commentators alike.  
Head Entity: Michael Jordan  
Tail Entity: MJ  

Relation: person alternate names  
Context: The actress and singer known as Lady Gaga was born Stefani Joanne Angelina Germanotta, a name that showcases her Italian roots.  
Head Entity: Stefani Joanne Angelina Germanotta  
Tail Entity: Lady Gaga  

Relation: person alternate names  
Context: The famous physicist Albert Einstein is often referred to as the "father of modern physics" due to his groundbreaking theories.  
Head Entity: Albert Einstein  
Tail Entity: father of modern physics  
#### person spouse ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person spouse" means a person 's spouse is a person.
Here is an example:
Relation: person spouse
Context: smits stands at the center of this multigenerational saga as alex vega , the adopted son of rum and sugar baron pancho duque -lrb- elizondo -rrb- and his wife , amalia -lrb- moreno -rrb- .
Head Entity: elizondo
Tail Entity: moreno
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person spouse":
Relation: person spouse  
Context: After years of friendship, Sarah finally married her college sweetheart, John, who has always been her biggest supporter.  
Head Entity: Sarah  
Tail Entity: John  

Relation: person spouse  
Context: In the small town of Maplewood, everyone knows that Linda and Tom have been inseparable since high school, and they recently celebrated their 25th wedding anniversary.  
Head Entity: Linda  
Tail Entity: Tom  

Relation: person spouse  
Context: The famous actor, Robert, often credits his wife, Emily, for his success, stating that her unwavering belief in him has been a driving force in his career.  
Head Entity: Robert  
Tail Entity: Emily  

Relation: person spouse  
Context: During the gala, Jessica introduced her husband, Michael, to her colleagues, highlighting their journey together from college friends to life partners.  
Head Entity: Jessica  
Tail Entity: Michael  

Relation: person spouse  
Context: As the family gathered for the holidays, it was clear that Maria and her husband, Carlos, were the heart of the celebration, bringing everyone together with their warmth.  
Head Entity: Maria  
Tail Entity: Carlos  
Mixup data size:  28180
MixupTrain:  epoch  0, batch     0 | loss: 2.7928901
MixupTrain:  epoch  0, batch     1 | loss: 2.7281704
MixupTrain:  epoch  0, batch     2 | loss: 3.5406408
MixupTrain:  epoch  0, batch     3 | loss: 3.3252587
MixupTrain:  epoch  0, batch     4 | loss: 3.4954782
MixupTrain:  epoch  0, batch     5 | loss: 3.9319036
MixupTrain:  epoch  0, batch     6 | loss: 3.1447625
MixupTrain:  epoch  0, batch     7 | loss: 3.5695965
MixupTrain:  epoch  0, batch     8 | loss: 3.3017135
MixupTrain:  epoch  0, batch     9 | loss: 4.1250110
MixupTrain:  epoch  0, batch    10 | loss: 3.3973744
MixupTrain:  epoch  0, batch    11 | loss: 2.5108190
MixupTrain:  epoch  0, batch    12 | loss: 3.7200675
MixupTrain:  epoch  0, batch    13 | loss: 3.5487514
MixupTrain:  epoch  0, batch    14 | loss: 2.9009728
MixupTrain:  epoch  0, batch    15 | loss: 2.6912878
MixupTrain:  epoch  0, batch    16 | loss: 3.2583320
MixupTrain:  epoch  0, batch    17 | loss: 3.3116417
MixupTrain:  epoch  0, batch    18 | loss: 4.2229962
MixupTrain:  epoch  0, batch    19 | loss: 3.1694164
MixupTrain:  epoch  0, batch    20 | loss: 2.5800683
MixupTrain:  epoch  0, batch    21 | loss: 2.9000380
MixupTrain:  epoch  0, batch    22 | loss: 2.8017137
MixupTrain:  epoch  0, batch    23 | loss: 3.6626124
MixupTrain:  epoch  0, batch    24 | loss: 3.2001991
MixupTrain:  epoch  0, batch    25 | loss: 3.2142005
MixupTrain:  epoch  0, batch    26 | loss: 2.7556119
MixupTrain:  epoch  0, batch    27 | loss: 3.1923990
MixupTrain:  epoch  0, batch    28 | loss: 3.2844789
MixupTrain:  epoch  0, batch    29 | loss: 2.7546282
MixupTrain:  epoch  0, batch    30 | loss: 3.3969188
MixupTrain:  epoch  0, batch    31 | loss: 3.1447332
MixupTrain:  epoch  0, batch    32 | loss: 4.1780539
MixupTrain:  epoch  0, batch    33 | loss: 3.0816603
MixupTrain:  epoch  0, batch    34 | loss: 3.8073394
MixupTrain:  epoch  0, batch    35 | loss: 3.0500135
MixupTrain:  epoch  0, batch    36 | loss: 3.0018244
MixupTrain:  epoch  0, batch    37 | loss: 3.4362893
MixupTrain:  epoch  0, batch    38 | loss: 2.5123453
MixupTrain:  epoch  0, batch    39 | loss: 3.7374964
MixupTrain:  epoch  0, batch    40 | loss: 3.5641675
MixupTrain:  epoch  0, batch    41 | loss: 3.3416531
MixupTrain:  epoch  0, batch    42 | loss: 2.8997991
MixupTrain:  epoch  0, batch    43 | loss: 2.8753021
MixupTrain:  epoch  0, batch    44 | loss: 2.6775024
MixupTrain:  epoch  0, batch    45 | loss: 3.7398965
MixupTrain:  epoch  0, batch    46 | loss: 3.1637993
MixupTrain:  epoch  0, batch    47 | loss: 2.8101971
MixupTrain:  epoch  0, batch    48 | loss: 2.5619216
MixupTrain:  epoch  0, batch    49 | loss: 3.1900649
MixupTrain:  epoch  0, batch    50 | loss: 2.4719040
MixupTrain:  epoch  0, batch    51 | loss: 2.6553466
MixupTrain:  epoch  0, batch    52 | loss: 3.2261209
MixupTrain:  epoch  0, batch    53 | loss: 2.7946615
MixupTrain:  epoch  0, batch    54 | loss: 3.0015945
MixupTrain:  epoch  0, batch    55 | loss: 2.3559055
MixupTrain:  epoch  0, batch    56 | loss: 2.8691022
MixupTrain:  epoch  0, batch    57 | loss: 3.5645089
MixupTrain:  epoch  0, batch    58 | loss: 3.1204588
MixupTrain:  epoch  0, batch    59 | loss: 2.4549563
MixupTrain:  epoch  0, batch    60 | loss: 2.4760361
MixupTrain:  epoch  0, batch    61 | loss: 3.0671835
MixupTrain:  epoch  0, batch    62 | loss: 2.9515181
MixupTrain:  epoch  0, batch    63 | loss: 3.5977693
MixupTrain:  epoch  0, batch    64 | loss: 2.5162327
MixupTrain:  epoch  0, batch    65 | loss: 3.0692329
MixupTrain:  epoch  0, batch    66 | loss: 3.3393757
MixupTrain:  epoch  0, batch    67 | loss: 3.0484669
MixupTrain:  epoch  0, batch    68 | loss: 2.6131001
MixupTrain:  epoch  0, batch    69 | loss: 2.2133203
MixupTrain:  epoch  0, batch    70 | loss: 2.4552240
MixupTrain:  epoch  0, batch    71 | loss: 3.0658674
MixupTrain:  epoch  0, batch    72 | loss: 2.7997165
MixupTrain:  epoch  0, batch    73 | loss: 2.6736045
MixupTrain:  epoch  0, batch    74 | loss: 3.0343127
MixupTrain:  epoch  0, batch    75 | loss: 2.3427029
MixupTrain:  epoch  0, batch    76 | loss: 2.5864079
MixupTrain:  epoch  0, batch    77 | loss: 2.2159595
MixupTrain:  epoch  0, batch    78 | loss: 2.7453938
MixupTrain:  epoch  0, batch    79 | loss: 2.5632417
MixupTrain:  epoch  0, batch    80 | loss: 3.1254354
MixupTrain:  epoch  0, batch    81 | loss: 2.5222661
MixupTrain:  epoch  0, batch    82 | loss: 2.3393602
MixupTrain:  epoch  0, batch    83 | loss: 2.9044495
MixupTrain:  epoch  0, batch    84 | loss: 2.7388208
MixupTrain:  epoch  0, batch    85 | loss: 2.7282531
MixupTrain:  epoch  0, batch    86 | loss: 2.3839664
MixupTrain:  epoch  0, batch    87 | loss: 2.7853971
MixupTrain:  epoch  0, batch    88 | loss: 2.5043454
MixupTrain:  epoch  0, batch    89 | loss: 2.6698368
MixupTrain:  epoch  0, batch    90 | loss: 2.4527290
MixupTrain:  epoch  0, batch    91 | loss: 2.9509101
MixupTrain:  epoch  0, batch    92 | loss: 2.0924323
MixupTrain:  epoch  0, batch    93 | loss: 2.5858147
MixupTrain:  epoch  0, batch    94 | loss: 2.5333867
MixupTrain:  epoch  0, batch    95 | loss: 2.9403491
MixupTrain:  epoch  0, batch    96 | loss: 2.8116989
MixupTrain:  epoch  0, batch    97 | loss: 2.3341990
MixupTrain:  epoch  0, batch    98 | loss: 2.7945385
MixupTrain:  epoch  0, batch    99 | loss: 2.6589303
MixupTrain:  epoch  0, batch   100 | loss: 3.0809944
MixupTrain:  epoch  0, batch   101 | loss: 2.5487657
MixupTrain:  epoch  0, batch   102 | loss: 2.2020645
MixupTrain:  epoch  0, batch   103 | loss: 2.3926265
MixupTrain:  epoch  0, batch   104 | loss: 2.3998179
MixupTrain:  epoch  0, batch   105 | loss: 2.3504026
MixupTrain:  epoch  0, batch   106 | loss: 2.5006971
MixupTrain:  epoch  0, batch   107 | loss: 2.5189736
MixupTrain:  epoch  0, batch   108 | loss: 2.5314415
MixupTrain:  epoch  0, batch   109 | loss: 2.4112380
MixupTrain:  epoch  0, batch   110 | loss: 2.1410275
MixupTrain:  epoch  0, batch   111 | loss: 2.4162731
MixupTrain:  epoch  0, batch   112 | loss: 2.3103819
MixupTrain:  epoch  0, batch   113 | loss: 2.2452087
MixupTrain:  epoch  0, batch   114 | loss: 2.5698235
MixupTrain:  epoch  0, batch   115 | loss: 2.4315667
MixupTrain:  epoch  0, batch   116 | loss: 2.3696809
MixupTrain:  epoch  0, batch   117 | loss: 2.5544715
MixupTrain:  epoch  0, batch   118 | loss: 2.7357626
MixupTrain:  epoch  0, batch   119 | loss: 2.7555304
MixupTrain:  epoch  0, batch   120 | loss: 2.2823682
MixupTrain:  epoch  0, batch   121 | loss: 2.9176192
MixupTrain:  epoch  0, batch   122 | loss: 2.3660479
MixupTrain:  epoch  0, batch   123 | loss: 2.6322799
MixupTrain:  epoch  0, batch   124 | loss: 2.3239162
MixupTrain:  epoch  0, batch   125 | loss: 2.0984142
MixupTrain:  epoch  0, batch   126 | loss: 2.5398269
MixupTrain:  epoch  0, batch   127 | loss: 2.0631723
MixupTrain:  epoch  0, batch   128 | loss: 2.6545510
MixupTrain:  epoch  0, batch   129 | loss: 2.3252795
MixupTrain:  epoch  0, batch   130 | loss: 2.6544912
MixupTrain:  epoch  0, batch   131 | loss: 2.1663477
MixupTrain:  epoch  0, batch   132 | loss: 2.4268148
MixupTrain:  epoch  0, batch   133 | loss: 2.7106514
MixupTrain:  epoch  0, batch   134 | loss: 2.0530477
MixupTrain:  epoch  0, batch   135 | loss: 2.6288831
MixupTrain:  epoch  0, batch   136 | loss: 2.5851521
MixupTrain:  epoch  0, batch   137 | loss: 2.2450643
MixupTrain:  epoch  0, batch   138 | loss: 2.6068535
MixupTrain:  epoch  0, batch   139 | loss: 2.6836414
MixupTrain:  epoch  0, batch   140 | loss: 2.6388791
MixupTrain:  epoch  0, batch   141 | loss: 2.5056541
MixupTrain:  epoch  0, batch   142 | loss: 2.2000327
MixupTrain:  epoch  0, batch   143 | loss: 2.4308619
MixupTrain:  epoch  0, batch   144 | loss: 2.3551581
MixupTrain:  epoch  0, batch   145 | loss: 2.7666783
MixupTrain:  epoch  0, batch   146 | loss: 2.5174382
MixupTrain:  epoch  0, batch   147 | loss: 2.2140787
MixupTrain:  epoch  0, batch   148 | loss: 2.4389348
MixupTrain:  epoch  0, batch   149 | loss: 2.7752616
MixupTrain:  epoch  0, batch   150 | loss: 2.4964702
MixupTrain:  epoch  0, batch   151 | loss: 2.9072733
MixupTrain:  epoch  0, batch   152 | loss: 2.2919977
MixupTrain:  epoch  0, batch   153 | loss: 2.3170605
MixupTrain:  epoch  0, batch   154 | loss: 2.7945271
MixupTrain:  epoch  0, batch   155 | loss: 2.3540835
MixupTrain:  epoch  0, batch   156 | loss: 2.3851635
MixupTrain:  epoch  0, batch   157 | loss: 2.2157140
MixupTrain:  epoch  0, batch   158 | loss: 2.6215072
MixupTrain:  epoch  0, batch   159 | loss: 2.7088566
MixupTrain:  epoch  0, batch   160 | loss: 2.5655849
MixupTrain:  epoch  0, batch   161 | loss: 2.3683722
MixupTrain:  epoch  0, batch   162 | loss: 2.0556157
MixupTrain:  epoch  0, batch   163 | loss: 2.6107297
MixupTrain:  epoch  0, batch   164 | loss: 2.8222995
MixupTrain:  epoch  0, batch   165 | loss: 2.5365844
MixupTrain:  epoch  0, batch   166 | loss: 2.6613216
MixupTrain:  epoch  0, batch   167 | loss: 2.2252703
MixupTrain:  epoch  0, batch   168 | loss: 2.5316885
MixupTrain:  epoch  0, batch   169 | loss: 2.1440737
MixupTrain:  epoch  0, batch   170 | loss: 2.5080481
MixupTrain:  epoch  0, batch   171 | loss: 3.1210256
MixupTrain:  epoch  0, batch   172 | loss: 2.5243325
MixupTrain:  epoch  0, batch   173 | loss: 2.3727379
MixupTrain:  epoch  0, batch   174 | loss: 2.4476104
MixupTrain:  epoch  0, batch   175 | loss: 2.4015331
MixupTrain:  epoch  0, batch   176 | loss: 2.2777870
MixupTrain:  epoch  0, batch   177 | loss: 2.4245496
MixupTrain:  epoch  0, batch   178 | loss: 2.1693642
MixupTrain:  epoch  0, batch   179 | loss: 2.3366098
MixupTrain:  epoch  0, batch   180 | loss: 2.8447397
MixupTrain:  epoch  0, batch   181 | loss: 2.3861318
MixupTrain:  epoch  0, batch   182 | loss: 2.2393923
MixupTrain:  epoch  0, batch   183 | loss: 2.4767270
MixupTrain:  epoch  0, batch   184 | loss: 2.0094576
MixupTrain:  epoch  0, batch   185 | loss: 2.5266461
MixupTrain:  epoch  0, batch   186 | loss: 2.5319219
MixupTrain:  epoch  0, batch   187 | loss: 2.4294169
MixupTrain:  epoch  0, batch   188 | loss: 2.5094123
MixupTrain:  epoch  0, batch   189 | loss: 2.3335223
MixupTrain:  epoch  0, batch   190 | loss: 2.5577233
MixupTrain:  epoch  0, batch   191 | loss: 2.3260238
MixupTrain:  epoch  0, batch   192 | loss: 3.3046434
MixupTrain:  epoch  0, batch   193 | loss: 2.7358971
MixupTrain:  epoch  0, batch   194 | loss: 2.8626804
MixupTrain:  epoch  0, batch   195 | loss: 2.4446778
MixupTrain:  epoch  0, batch   196 | loss: 2.4416761
MixupTrain:  epoch  0, batch   197 | loss: 2.6771770
MixupTrain:  epoch  0, batch   198 | loss: 2.5331759
MixupTrain:  epoch  0, batch   199 | loss: 2.6030543
MixupTrain:  epoch  0, batch   200 | loss: 2.7085607
MixupTrain:  epoch  0, batch   201 | loss: 2.1209586
MixupTrain:  epoch  0, batch   202 | loss: 2.4147010
MixupTrain:  epoch  0, batch   203 | loss: 2.5509944
MixupTrain:  epoch  0, batch   204 | loss: 2.5828638
MixupTrain:  epoch  0, batch   205 | loss: 2.0840559
MixupTrain:  epoch  0, batch   206 | loss: 2.0923929
MixupTrain:  epoch  0, batch   207 | loss: 2.1212087
MixupTrain:  epoch  0, batch   208 | loss: 2.1773086
MixupTrain:  epoch  0, batch   209 | loss: 2.5177789
MixupTrain:  epoch  0, batch   210 | loss: 2.3788424
MixupTrain:  epoch  0, batch   211 | loss: 2.6375294
MixupTrain:  epoch  0, batch   212 | loss: 2.7159591
MixupTrain:  epoch  0, batch   213 | loss: 2.4309740
MixupTrain:  epoch  0, batch   214 | loss: 2.1006827
MixupTrain:  epoch  0, batch   215 | loss: 1.9857767
MixupTrain:  epoch  0, batch   216 | loss: 3.0598540
MixupTrain:  epoch  0, batch   217 | loss: 2.1297450
MixupTrain:  epoch  0, batch   218 | loss: 2.0258143
MixupTrain:  epoch  0, batch   219 | loss: 2.5415454
MixupTrain:  epoch  0, batch   220 | loss: 2.4285607
MixupTrain:  epoch  0, batch   221 | loss: 2.4738016
MixupTrain:  epoch  0, batch   222 | loss: 2.1979437
MixupTrain:  epoch  0, batch   223 | loss: 2.4712033
MixupTrain:  epoch  0, batch   224 | loss: 2.2739186
MixupTrain:  epoch  0, batch   225 | loss: 2.2740920
MixupTrain:  epoch  0, batch   226 | loss: 2.5282288
MixupTrain:  epoch  0, batch   227 | loss: 2.6534288
MixupTrain:  epoch  0, batch   228 | loss: 2.1574440
MixupTrain:  epoch  0, batch   229 | loss: 2.4106507
MixupTrain:  epoch  0, batch   230 | loss: 2.1469159
MixupTrain:  epoch  0, batch   231 | loss: 2.4182706
MixupTrain:  epoch  0, batch   232 | loss: 2.6316719
MixupTrain:  epoch  0, batch   233 | loss: 2.8802433
MixupTrain:  epoch  0, batch   234 | loss: 2.7788174
MixupTrain:  epoch  0, batch   235 | loss: 2.2061739
MixupTrain:  epoch  0, batch   236 | loss: 2.4302299
MixupTrain:  epoch  0, batch   237 | loss: 2.5974493
MixupTrain:  epoch  0, batch   238 | loss: 2.4791219
MixupTrain:  epoch  0, batch   239 | loss: 2.0366745
MixupTrain:  epoch  0, batch   240 | loss: 2.2554512
MixupTrain:  epoch  0, batch   241 | loss: 2.2868066
MixupTrain:  epoch  0, batch   242 | loss: 2.0261407
MixupTrain:  epoch  0, batch   243 | loss: 2.4869785
MixupTrain:  epoch  0, batch   244 | loss: 2.2982082
MixupTrain:  epoch  0, batch   245 | loss: 2.3360672
MixupTrain:  epoch  0, batch   246 | loss: 2.2319424
MixupTrain:  epoch  0, batch   247 | loss: 2.1215029
MixupTrain:  epoch  0, batch   248 | loss: 2.2775028
MixupTrain:  epoch  0, batch   249 | loss: 2.6460404
MixupTrain:  epoch  0, batch   250 | loss: 2.1777711
MixupTrain:  epoch  0, batch   251 | loss: 2.5887737
MixupTrain:  epoch  0, batch   252 | loss: 2.5157180
MixupTrain:  epoch  0, batch   253 | loss: 2.2265272
MixupTrain:  epoch  0, batch   254 | loss: 2.0776148
MixupTrain:  epoch  0, batch   255 | loss: 2.4045753
MixupTrain:  epoch  0, batch   256 | loss: 2.4793057
MixupTrain:  epoch  0, batch   257 | loss: 2.1049132
MixupTrain:  epoch  0, batch   258 | loss: 2.2151375
MixupTrain:  epoch  0, batch   259 | loss: 2.1712732
MixupTrain:  epoch  0, batch   260 | loss: 2.3185079
MixupTrain:  epoch  0, batch   261 | loss: 2.6998639
MixupTrain:  epoch  0, batch   262 | loss: 2.3567214
MixupTrain:  epoch  0, batch   263 | loss: 2.3018389
MixupTrain:  epoch  0, batch   264 | loss: 2.4589908
MixupTrain:  epoch  0, batch   265 | loss: 2.3016324
MixupTrain:  epoch  0, batch   266 | loss: 2.4304664
MixupTrain:  epoch  0, batch   267 | loss: 2.3785100
MixupTrain:  epoch  0, batch   268 | loss: 2.3072138
MixupTrain:  epoch  0, batch   269 | loss: 2.2854514
MixupTrain:  epoch  0, batch   270 | loss: 2.3344941
MixupTrain:  epoch  0, batch   271 | loss: 2.5183303
MixupTrain:  epoch  0, batch   272 | loss: 2.3838248
MixupTrain:  epoch  0, batch   273 | loss: 2.2075181
MixupTrain:  epoch  0, batch   274 | loss: 2.5495639
MixupTrain:  epoch  0, batch   275 | loss: 2.4174962
MixupTrain:  epoch  0, batch   276 | loss: 2.1548843
MixupTrain:  epoch  0, batch   277 | loss: 2.2744823
MixupTrain:  epoch  0, batch   278 | loss: 2.0393603
MixupTrain:  epoch  0, batch   279 | loss: 2.0669627
MixupTrain:  epoch  0, batch   280 | loss: 2.1980205
MixupTrain:  epoch  0, batch   281 | loss: 2.0767639
MixupTrain:  epoch  0, batch   282 | loss: 2.0320683
MixupTrain:  epoch  0, batch   283 | loss: 2.1451359
MixupTrain:  epoch  0, batch   284 | loss: 2.6098108
MixupTrain:  epoch  0, batch   285 | loss: 2.2965045
MixupTrain:  epoch  0, batch   286 | loss: 2.6591232
MixupTrain:  epoch  0, batch   287 | loss: 2.1610270
MixupTrain:  epoch  0, batch   288 | loss: 2.8807254
MixupTrain:  epoch  0, batch   289 | loss: 2.0685272
MixupTrain:  epoch  0, batch   290 | loss: 2.6900935
MixupTrain:  epoch  0, batch   291 | loss: 2.2803710
MixupTrain:  epoch  0, batch   292 | loss: 2.4541478
MixupTrain:  epoch  0, batch   293 | loss: 2.0163364
MixupTrain:  epoch  0, batch   294 | loss: 2.2127967
MixupTrain:  epoch  0, batch   295 | loss: 2.5121579
MixupTrain:  epoch  0, batch   296 | loss: 2.5822835
MixupTrain:  epoch  0, batch   297 | loss: 2.1988826
MixupTrain:  epoch  0, batch   298 | loss: 2.1508877
MixupTrain:  epoch  0, batch   299 | loss: 2.3526702
MixupTrain:  epoch  0, batch   300 | loss: 2.1957827
MixupTrain:  epoch  0, batch   301 | loss: 2.0207205
MixupTrain:  epoch  0, batch   302 | loss: 2.1300788
MixupTrain:  epoch  0, batch   303 | loss: 2.3497553
MixupTrain:  epoch  0, batch   304 | loss: 2.2332928
MixupTrain:  epoch  0, batch   305 | loss: 2.4375315
MixupTrain:  epoch  0, batch   306 | loss: 2.3948638
MixupTrain:  epoch  0, batch   307 | loss: 2.5536895
MixupTrain:  epoch  0, batch   308 | loss: 2.2189643
MixupTrain:  epoch  0, batch   309 | loss: 2.4728701
MixupTrain:  epoch  0, batch   310 | loss: 2.3706689
MixupTrain:  epoch  0, batch   311 | loss: 2.2668352
MixupTrain:  epoch  0, batch   312 | loss: 2.5340109
MixupTrain:  epoch  0, batch   313 | loss: 2.4185386
MixupTrain:  epoch  0, batch   314 | loss: 2.4728079
MixupTrain:  epoch  0, batch   315 | loss: 2.0984876
MixupTrain:  epoch  0, batch   316 | loss: 2.3416667
MixupTrain:  epoch  0, batch   317 | loss: 2.5929790
MixupTrain:  epoch  0, batch   318 | loss: 2.1349063
MixupTrain:  epoch  0, batch   319 | loss: 2.6635418
MixupTrain:  epoch  0, batch   320 | loss: 2.1138074
MixupTrain:  epoch  0, batch   321 | loss: 2.1555176
MixupTrain:  epoch  0, batch   322 | loss: 2.3732147
MixupTrain:  epoch  0, batch   323 | loss: 2.1141465
MixupTrain:  epoch  0, batch   324 | loss: 2.2008686
MixupTrain:  epoch  0, batch   325 | loss: 2.5888906
MixupTrain:  epoch  0, batch   326 | loss: 2.2123408
MixupTrain:  epoch  0, batch   327 | loss: 2.9059443
MixupTrain:  epoch  0, batch   328 | loss: 2.2609448
MixupTrain:  epoch  0, batch   329 | loss: 2.2810111
MixupTrain:  epoch  0, batch   330 | loss: 2.3393450
MixupTrain:  epoch  0, batch   331 | loss: 2.5412595
MixupTrain:  epoch  0, batch   332 | loss: 2.0656109
MixupTrain:  epoch  0, batch   333 | loss: 2.0621071
MixupTrain:  epoch  0, batch   334 | loss: 2.6840386
MixupTrain:  epoch  0, batch   335 | loss: 2.0448508
MixupTrain:  epoch  0, batch   336 | loss: 2.7999644
MixupTrain:  epoch  0, batch   337 | loss: 2.2185338
MixupTrain:  epoch  0, batch   338 | loss: 2.3029482
MixupTrain:  epoch  0, batch   339 | loss: 2.3831964
MixupTrain:  epoch  0, batch   340 | loss: 2.1078930
MixupTrain:  epoch  0, batch   341 | loss: 2.3664212
MixupTrain:  epoch  0, batch   342 | loss: 2.3355110
MixupTrain:  epoch  0, batch   343 | loss: 2.1447423
MixupTrain:  epoch  0, batch   344 | loss: 2.0899844
MixupTrain:  epoch  0, batch   345 | loss: 2.5874710
MixupTrain:  epoch  0, batch   346 | loss: 2.1060863
MixupTrain:  epoch  0, batch   347 | loss: 2.3659067
MixupTrain:  epoch  0, batch   348 | loss: 2.3725417
MixupTrain:  epoch  0, batch   349 | loss: 2.3770010
MixupTrain:  epoch  0, batch   350 | loss: 2.0559716
MixupTrain:  epoch  0, batch   351 | loss: 2.1792231
MixupTrain:  epoch  0, batch   352 | loss: 2.0026476
MixupTrain:  epoch  0, batch   353 | loss: 2.1494460
MixupTrain:  epoch  0, batch   354 | loss: 2.2650115
MixupTrain:  epoch  0, batch   355 | loss: 2.6018939
MixupTrain:  epoch  0, batch   356 | loss: 2.5010209
MixupTrain:  epoch  0, batch   357 | loss: 2.5833049
MixupTrain:  epoch  0, batch   358 | loss: 2.0899582
MixupTrain:  epoch  0, batch   359 | loss: 2.1975255
MixupTrain:  epoch  0, batch   360 | loss: 2.3825805
MixupTrain:  epoch  0, batch   361 | loss: 2.1389155
MixupTrain:  epoch  0, batch   362 | loss: 2.0878997
MixupTrain:  epoch  0, batch   363 | loss: 2.1795521
MixupTrain:  epoch  0, batch   364 | loss: 2.5687866
MixupTrain:  epoch  0, batch   365 | loss: 2.1578901
MixupTrain:  epoch  0, batch   366 | loss: 2.2113323
MixupTrain:  epoch  0, batch   367 | loss: 2.5074365
MixupTrain:  epoch  0, batch   368 | loss: 1.9662464
MixupTrain:  epoch  0, batch   369 | loss: 2.1949458
MixupTrain:  epoch  0, batch   370 | loss: 2.4354639
MixupTrain:  epoch  0, batch   371 | loss: 2.3073516
MixupTrain:  epoch  0, batch   372 | loss: 2.3993397
MixupTrain:  epoch  0, batch   373 | loss: 2.0274670
MixupTrain:  epoch  0, batch   374 | loss: 2.2143950
MixupTrain:  epoch  0, batch   375 | loss: 2.5841441
MixupTrain:  epoch  0, batch   376 | loss: 2.3271403
MixupTrain:  epoch  0, batch   377 | loss: 2.0679209
MixupTrain:  epoch  0, batch   378 | loss: 2.1755302
MixupTrain:  epoch  0, batch   379 | loss: 2.3031464
MixupTrain:  epoch  0, batch   380 | loss: 2.2155371
MixupTrain:  epoch  0, batch   381 | loss: 2.0512249
MixupTrain:  epoch  0, batch   382 | loss: 2.2157803
MixupTrain:  epoch  0, batch   383 | loss: 2.1484175
MixupTrain:  epoch  0, batch   384 | loss: 2.4638402
MixupTrain:  epoch  0, batch   385 | loss: 2.1450820
MixupTrain:  epoch  0, batch   386 | loss: 2.2723205
MixupTrain:  epoch  0, batch   387 | loss: 2.2247164
MixupTrain:  epoch  0, batch   388 | loss: 2.2027514
MixupTrain:  epoch  0, batch   389 | loss: 2.5872660
MixupTrain:  epoch  0, batch   390 | loss: 2.4553351
MixupTrain:  epoch  0, batch   391 | loss: 2.2487378
MixupTrain:  epoch  0, batch   392 | loss: 2.3117502
MixupTrain:  epoch  0, batch   393 | loss: 2.4851284
MixupTrain:  epoch  0, batch   394 | loss: 2.3322487
MixupTrain:  epoch  0, batch   395 | loss: 2.2717826
MixupTrain:  epoch  0, batch   396 | loss: 2.2714539
MixupTrain:  epoch  0, batch   397 | loss: 2.2287574
MixupTrain:  epoch  0, batch   398 | loss: 2.3521862
MixupTrain:  epoch  0, batch   399 | loss: 2.4309440
MixupTrain:  epoch  0, batch   400 | loss: 2.3021743
MixupTrain:  epoch  0, batch   401 | loss: 2.1958065
MixupTrain:  epoch  0, batch   402 | loss: 2.4669085
MixupTrain:  epoch  0, batch   403 | loss: 2.3877873
MixupTrain:  epoch  0, batch   404 | loss: 2.2052748
MixupTrain:  epoch  0, batch   405 | loss: 1.9499900
MixupTrain:  epoch  0, batch   406 | loss: 2.3571491
MixupTrain:  epoch  0, batch   407 | loss: 2.4157634
MixupTrain:  epoch  0, batch   408 | loss: 2.5768266
MixupTrain:  epoch  0, batch   409 | loss: 2.0971177
MixupTrain:  epoch  0, batch   410 | loss: 2.1313472
MixupTrain:  epoch  0, batch   411 | loss: 2.3063035
MixupTrain:  epoch  0, batch   412 | loss: 2.1148157
MixupTrain:  epoch  0, batch   413 | loss: 2.5902910
MixupTrain:  epoch  0, batch   414 | loss: 2.2368512
MixupTrain:  epoch  0, batch   415 | loss: 2.5646465
MixupTrain:  epoch  0, batch   416 | loss: 2.1734703
MixupTrain:  epoch  0, batch   417 | loss: 2.4093518
MixupTrain:  epoch  0, batch   418 | loss: 2.1114993
MixupTrain:  epoch  0, batch   419 | loss: 2.1670580
MixupTrain:  epoch  0, batch   420 | loss: 2.6223793
MixupTrain:  epoch  0, batch   421 | loss: 2.2264240
MixupTrain:  epoch  0, batch   422 | loss: 2.2641218
MixupTrain:  epoch  0, batch   423 | loss: 2.3803480
MixupTrain:  epoch  0, batch   424 | loss: 2.1605287
MixupTrain:  epoch  0, batch   425 | loss: 2.5410116
MixupTrain:  epoch  0, batch   426 | loss: 2.0484314
MixupTrain:  epoch  0, batch   427 | loss: 1.9958515
MixupTrain:  epoch  0, batch   428 | loss: 2.1769261
MixupTrain:  epoch  0, batch   429 | loss: 2.0388889
MixupTrain:  epoch  0, batch   430 | loss: 2.3189325
MixupTrain:  epoch  0, batch   431 | loss: 2.0770326
MixupTrain:  epoch  0, batch   432 | loss: 2.3253455
MixupTrain:  epoch  0, batch   433 | loss: 2.0428598
MixupTrain:  epoch  0, batch   434 | loss: 2.3607864
MixupTrain:  epoch  0, batch   435 | loss: 2.0030427
MixupTrain:  epoch  0, batch   436 | loss: 2.4324288
MixupTrain:  epoch  0, batch   437 | loss: 2.3556044
MixupTrain:  epoch  0, batch   438 | loss: 2.0303748
MixupTrain:  epoch  0, batch   439 | loss: 2.2619998
MixupTrain:  epoch  0, batch   440 | loss: 2.4956303
MixupTrain:  epoch  0, batch   441 | loss: 2.0881343
MixupTrain:  epoch  0, batch   442 | loss: 2.3644011
MixupTrain:  epoch  0, batch   443 | loss: 2.2095032
MixupTrain:  epoch  0, batch   444 | loss: 2.5597606
MixupTrain:  epoch  0, batch   445 | loss: 2.3621345
MixupTrain:  epoch  0, batch   446 | loss: 2.2187545
MixupTrain:  epoch  0, batch   447 | loss: 2.6619699
MixupTrain:  epoch  0, batch   448 | loss: 2.4870658
MixupTrain:  epoch  0, batch   449 | loss: 2.1581521
MixupTrain:  epoch  0, batch   450 | loss: 2.4654920
MixupTrain:  epoch  0, batch   451 | loss: 2.3348365
MixupTrain:  epoch  0, batch   452 | loss: 2.1192591
MixupTrain:  epoch  0, batch   453 | loss: 2.2032723
MixupTrain:  epoch  0, batch   454 | loss: 2.2261930
MixupTrain:  epoch  0, batch   455 | loss: 2.1881595
MixupTrain:  epoch  0, batch   456 | loss: 2.1169600
MixupTrain:  epoch  0, batch   457 | loss: 2.2039235
MixupTrain:  epoch  0, batch   458 | loss: 2.2957544
MixupTrain:  epoch  0, batch   459 | loss: 2.4569731
MixupTrain:  epoch  0, batch   460 | loss: 2.0310605
MixupTrain:  epoch  0, batch   461 | loss: 2.4669456
MixupTrain:  epoch  0, batch   462 | loss: 2.5052767
MixupTrain:  epoch  0, batch   463 | loss: 2.2197700
MixupTrain:  epoch  0, batch   464 | loss: 2.3373122
MixupTrain:  epoch  0, batch   465 | loss: 2.4959893
MixupTrain:  epoch  0, batch   466 | loss: 2.3865499
MixupTrain:  epoch  0, batch   467 | loss: 2.4073958
MixupTrain:  epoch  0, batch   468 | loss: 2.4947135
MixupTrain:  epoch  0, batch   469 | loss: 2.1088591
MixupTrain:  epoch  0, batch   470 | loss: 2.0721471
MixupTrain:  epoch  0, batch   471 | loss: 2.0656226
MixupTrain:  epoch  0, batch   472 | loss: 2.1545460
MixupTrain:  epoch  0, batch   473 | loss: 2.3495119
MixupTrain:  epoch  0, batch   474 | loss: 2.2560830
MixupTrain:  epoch  0, batch   475 | loss: 2.1421573
MixupTrain:  epoch  0, batch   476 | loss: 2.1992469
MixupTrain:  epoch  0, batch   477 | loss: 2.2657671
MixupTrain:  epoch  0, batch   478 | loss: 2.2464542
MixupTrain:  epoch  0, batch   479 | loss: 2.3591170
MixupTrain:  epoch  0, batch   480 | loss: 2.5103383
MixupTrain:  epoch  0, batch   481 | loss: 2.2163582
MixupTrain:  epoch  0, batch   482 | loss: 2.1706190
MixupTrain:  epoch  0, batch   483 | loss: 2.1576409
MixupTrain:  epoch  0, batch   484 | loss: 2.4131141
MixupTrain:  epoch  0, batch   485 | loss: 2.0523078
MixupTrain:  epoch  0, batch   486 | loss: 2.3767953
MixupTrain:  epoch  0, batch   487 | loss: 2.1596940
MixupTrain:  epoch  0, batch   488 | loss: 2.5439687
MixupTrain:  epoch  0, batch   489 | loss: 2.1580303
MixupTrain:  epoch  0, batch   490 | loss: 2.3371468
MixupTrain:  epoch  0, batch   491 | loss: 2.4025512
MixupTrain:  epoch  0, batch   492 | loss: 2.3564739
MixupTrain:  epoch  0, batch   493 | loss: 2.3870797
MixupTrain:  epoch  0, batch   494 | loss: 2.2176638
MixupTrain:  epoch  0, batch   495 | loss: 2.6077499
MixupTrain:  epoch  0, batch   496 | loss: 2.0785146
MixupTrain:  epoch  0, batch   497 | loss: 2.2118523
MixupTrain:  epoch  0, batch   498 | loss: 2.1590500
MixupTrain:  epoch  0, batch   499 | loss: 2.5388665
MixupTrain:  epoch  0, batch   500 | loss: 2.4338980
MixupTrain:  epoch  0, batch   501 | loss: 2.5759232
MixupTrain:  epoch  0, batch   502 | loss: 1.9969510
MixupTrain:  epoch  0, batch   503 | loss: 1.9802417
MixupTrain:  epoch  0, batch   504 | loss: 2.5415702
MixupTrain:  epoch  0, batch   505 | loss: 2.1907778
MixupTrain:  epoch  0, batch   506 | loss: 2.3623328
MixupTrain:  epoch  0, batch   507 | loss: 2.1533334
MixupTrain:  epoch  0, batch   508 | loss: 2.1403399
MixupTrain:  epoch  0, batch   509 | loss: 2.5794683
MixupTrain:  epoch  0, batch   510 | loss: 2.3438277
MixupTrain:  epoch  0, batch   511 | loss: 2.3073933
MixupTrain:  epoch  0, batch   512 | loss: 2.6908913
MixupTrain:  epoch  0, batch   513 | loss: 2.1151142
MixupTrain:  epoch  0, batch   514 | loss: 2.6020722
MixupTrain:  epoch  0, batch   515 | loss: 2.2776887
MixupTrain:  epoch  0, batch   516 | loss: 2.1740973
MixupTrain:  epoch  0, batch   517 | loss: 2.3892787
MixupTrain:  epoch  0, batch   518 | loss: 2.3523576
MixupTrain:  epoch  0, batch   519 | loss: 1.9567635
MixupTrain:  epoch  0, batch   520 | loss: 2.3125372
MixupTrain:  epoch  0, batch   521 | loss: 2.0883594
MixupTrain:  epoch  0, batch   522 | loss: 2.1509807
MixupTrain:  epoch  0, batch   523 | loss: 2.3289919
MixupTrain:  epoch  0, batch   524 | loss: 2.2438536
MixupTrain:  epoch  0, batch   525 | loss: 2.4113603
MixupTrain:  epoch  0, batch   526 | loss: 2.3722951
MixupTrain:  epoch  0, batch   527 | loss: 2.4747598
MixupTrain:  epoch  0, batch   528 | loss: 2.0850582
MixupTrain:  epoch  0, batch   529 | loss: 2.3350422
MixupTrain:  epoch  0, batch   530 | loss: 2.0989583
MixupTrain:  epoch  0, batch   531 | loss: 2.4205906
MixupTrain:  epoch  0, batch   532 | loss: 2.2434354
MixupTrain:  epoch  0, batch   533 | loss: 2.0500515
MixupTrain:  epoch  0, batch   534 | loss: 2.1854215
MixupTrain:  epoch  0, batch   535 | loss: 2.3342066
MixupTrain:  epoch  0, batch   536 | loss: 2.3471854
MixupTrain:  epoch  0, batch   537 | loss: 2.3477209
MixupTrain:  epoch  0, batch   538 | loss: 2.0125389
MixupTrain:  epoch  0, batch   539 | loss: 2.4232011
MixupTrain:  epoch  0, batch   540 | loss: 2.0582225
MixupTrain:  epoch  0, batch   541 | loss: 2.1759782
MixupTrain:  epoch  0, batch   542 | loss: 2.0559778
MixupTrain:  epoch  0, batch   543 | loss: 2.3052125
MixupTrain:  epoch  0, batch   544 | loss: 2.3219309
MixupTrain:  epoch  0, batch   545 | loss: 2.0432806
MixupTrain:  epoch  0, batch   546 | loss: 2.1322169
MixupTrain:  epoch  0, batch   547 | loss: 2.0121107
MixupTrain:  epoch  0, batch   548 | loss: 2.3723741
MixupTrain:  epoch  0, batch   549 | loss: 2.6198030
MixupTrain:  epoch  0, batch   550 | loss: 2.0457406
MixupTrain:  epoch  0, batch   551 | loss: 2.1222916
MixupTrain:  epoch  0, batch   552 | loss: 2.6035328
MixupTrain:  epoch  0, batch   553 | loss: 2.0971265
MixupTrain:  epoch  0, batch   554 | loss: 1.9827629
MixupTrain:  epoch  0, batch   555 | loss: 2.0486274
MixupTrain:  epoch  0, batch   556 | loss: 2.3626146
MixupTrain:  epoch  0, batch   557 | loss: 2.2904556
MixupTrain:  epoch  0, batch   558 | loss: 2.4116936
MixupTrain:  epoch  0, batch   559 | loss: 2.1678350
MixupTrain:  epoch  0, batch   560 | loss: 2.1173959
MixupTrain:  epoch  0, batch   561 | loss: 2.0343137
MixupTrain:  epoch  0, batch   562 | loss: 2.3164654
MixupTrain:  epoch  0, batch   563 | loss: 2.1517420
MixupTrain:  epoch  0, batch   564 | loss: 2.3616114
MixupTrain:  epoch  0, batch   565 | loss: 2.2172456
MixupTrain:  epoch  0, batch   566 | loss: 2.4505787
MixupTrain:  epoch  0, batch   567 | loss: 1.9594903
MixupTrain:  epoch  0, batch   568 | loss: 2.4271235
MixupTrain:  epoch  0, batch   569 | loss: 2.2241852
MixupTrain:  epoch  0, batch   570 | loss: 2.2997336
MixupTrain:  epoch  0, batch   571 | loss: 2.3186855
MixupTrain:  epoch  0, batch   572 | loss: 2.2446918
MixupTrain:  epoch  0, batch   573 | loss: 2.2167845
MixupTrain:  epoch  0, batch   574 | loss: 1.9892441
MixupTrain:  epoch  0, batch   575 | loss: 2.1737876
MixupTrain:  epoch  0, batch   576 | loss: 2.2552147
MixupTrain:  epoch  0, batch   577 | loss: 2.0070999
MixupTrain:  epoch  0, batch   578 | loss: 2.1204453
MixupTrain:  epoch  0, batch   579 | loss: 2.5473793
MixupTrain:  epoch  0, batch   580 | loss: 2.3614440
MixupTrain:  epoch  0, batch   581 | loss: 2.2231386
MixupTrain:  epoch  0, batch   582 | loss: 2.5188842
MixupTrain:  epoch  0, batch   583 | loss: 2.1883969
MixupTrain:  epoch  0, batch   584 | loss: 2.1888268
MixupTrain:  epoch  0, batch   585 | loss: 2.0770626
MixupTrain:  epoch  0, batch   586 | loss: 2.3699334
MixupTrain:  epoch  0, batch   587 | loss: 2.0963202
MixupTrain:  epoch  0, batch   588 | loss: 2.4275825
MixupTrain:  epoch  0, batch   589 | loss: 2.4483724
MixupTrain:  epoch  0, batch   590 | loss: 2.3561101
MixupTrain:  epoch  0, batch   591 | loss: 2.1999710
MixupTrain:  epoch  0, batch   592 | loss: 2.5265331
MixupTrain:  epoch  0, batch   593 | loss: 2.0422859
MixupTrain:  epoch  0, batch   594 | loss: 2.4635754
MixupTrain:  epoch  0, batch   595 | loss: 2.1003003
MixupTrain:  epoch  0, batch   596 | loss: 2.0969915
MixupTrain:  epoch  0, batch   597 | loss: 2.2012470
MixupTrain:  epoch  0, batch   598 | loss: 2.0390782
MixupTrain:  epoch  0, batch   599 | loss: 2.3458188
MixupTrain:  epoch  0, batch   600 | loss: 2.4033260
MixupTrain:  epoch  0, batch   601 | loss: 2.2286220
MixupTrain:  epoch  0, batch   602 | loss: 2.0859237
MixupTrain:  epoch  0, batch   603 | loss: 2.5444779
MixupTrain:  epoch  0, batch   604 | loss: 2.0479488
MixupTrain:  epoch  0, batch   605 | loss: 2.3487587
MixupTrain:  epoch  0, batch   606 | loss: 2.2703605
MixupTrain:  epoch  0, batch   607 | loss: 2.3162210
MixupTrain:  epoch  0, batch   608 | loss: 2.3142667
MixupTrain:  epoch  0, batch   609 | loss: 2.1590505
MixupTrain:  epoch  0, batch   610 | loss: 2.2434218
MixupTrain:  epoch  0, batch   611 | loss: 2.1515682
MixupTrain:  epoch  0, batch   612 | loss: 2.2032819
MixupTrain:  epoch  0, batch   613 | loss: 2.1436536
MixupTrain:  epoch  0, batch   614 | loss: 2.2297075
MixupTrain:  epoch  0, batch   615 | loss: 2.3708732
MixupTrain:  epoch  0, batch   616 | loss: 2.2063007
MixupTrain:  epoch  0, batch   617 | loss: 2.1453524
MixupTrain:  epoch  0, batch   618 | loss: 2.2255878
MixupTrain:  epoch  0, batch   619 | loss: 2.2882767
MixupTrain:  epoch  0, batch   620 | loss: 2.1077991
MixupTrain:  epoch  0, batch   621 | loss: 2.0440555
MixupTrain:  epoch  0, batch   622 | loss: 2.2607379
MixupTrain:  epoch  0, batch   623 | loss: 2.1835530
MixupTrain:  epoch  0, batch   624 | loss: 2.0883620
MixupTrain:  epoch  0, batch   625 | loss: 2.2529912
MixupTrain:  epoch  0, batch   626 | loss: 2.4271176
MixupTrain:  epoch  0, batch   627 | loss: 2.5394549
MixupTrain:  epoch  0, batch   628 | loss: 2.2387004
MixupTrain:  epoch  0, batch   629 | loss: 2.6346700
MixupTrain:  epoch  0, batch   630 | loss: 2.2742772
MixupTrain:  epoch  0, batch   631 | loss: 2.3401842
MixupTrain:  epoch  0, batch   632 | loss: 2.2541761
MixupTrain:  epoch  0, batch   633 | loss: 2.1450868
MixupTrain:  epoch  0, batch   634 | loss: 1.9829042
MixupTrain:  epoch  0, batch   635 | loss: 2.0101781
MixupTrain:  epoch  0, batch   636 | loss: 2.1295252
MixupTrain:  epoch  0, batch   637 | loss: 2.1729190
MixupTrain:  epoch  0, batch   638 | loss: 2.0005951
MixupTrain:  epoch  0, batch   639 | loss: 2.3210144
MixupTrain:  epoch  0, batch   640 | loss: 2.3498495
MixupTrain:  epoch  0, batch   641 | loss: 2.1545055
MixupTrain:  epoch  0, batch   642 | loss: 2.4624410
MixupTrain:  epoch  0, batch   643 | loss: 2.0281553
MixupTrain:  epoch  0, batch   644 | loss: 2.1162176
MixupTrain:  epoch  0, batch   645 | loss: 2.2062950
MixupTrain:  epoch  0, batch   646 | loss: 2.4284089
MixupTrain:  epoch  0, batch   647 | loss: 2.1975560
MixupTrain:  epoch  0, batch   648 | loss: 2.1808233
MixupTrain:  epoch  0, batch   649 | loss: 2.0490324
MixupTrain:  epoch  0, batch   650 | loss: 2.5171368
MixupTrain:  epoch  0, batch   651 | loss: 2.1386476
MixupTrain:  epoch  0, batch   652 | loss: 2.1284425
MixupTrain:  epoch  0, batch   653 | loss: 2.1429386
MixupTrain:  epoch  0, batch   654 | loss: 2.2020607
MixupTrain:  epoch  0, batch   655 | loss: 2.1979818
MixupTrain:  epoch  0, batch   656 | loss: 2.0395622
MixupTrain:  epoch  0, batch   657 | loss: 2.2916327
MixupTrain:  epoch  0, batch   658 | loss: 2.6247721
MixupTrain:  epoch  0, batch   659 | loss: 2.4940562
MixupTrain:  epoch  0, batch   660 | loss: 2.1830215
MixupTrain:  epoch  0, batch   661 | loss: 1.9837865
MixupTrain:  epoch  0, batch   662 | loss: 2.2398086
MixupTrain:  epoch  0, batch   663 | loss: 2.2066135
MixupTrain:  epoch  0, batch   664 | loss: 1.9471306
MixupTrain:  epoch  0, batch   665 | loss: 2.3550293
MixupTrain:  epoch  0, batch   666 | loss: 2.1175687
MixupTrain:  epoch  0, batch   667 | loss: 2.3365538
MixupTrain:  epoch  0, batch   668 | loss: 2.4409404
MixupTrain:  epoch  0, batch   669 | loss: 2.2659926
MixupTrain:  epoch  0, batch   670 | loss: 1.9590104
MixupTrain:  epoch  0, batch   671 | loss: 2.3233023
MixupTrain:  epoch  0, batch   672 | loss: 2.0626545
MixupTrain:  epoch  0, batch   673 | loss: 2.0304089
MixupTrain:  epoch  0, batch   674 | loss: 2.2381206
MixupTrain:  epoch  0, batch   675 | loss: 2.4766915
MixupTrain:  epoch  0, batch   676 | loss: 2.2301974
MixupTrain:  epoch  0, batch   677 | loss: 2.1399388
MixupTrain:  epoch  0, batch   678 | loss: 2.3208084
MixupTrain:  epoch  0, batch   679 | loss: 2.2568750
MixupTrain:  epoch  0, batch   680 | loss: 2.0107651
MixupTrain:  epoch  0, batch   681 | loss: 2.4244590
MixupTrain:  epoch  0, batch   682 | loss: 1.9624628
MixupTrain:  epoch  0, batch   683 | loss: 2.2404492
MixupTrain:  epoch  0, batch   684 | loss: 2.2356474
MixupTrain:  epoch  0, batch   685 | loss: 2.3216884
MixupTrain:  epoch  0, batch   686 | loss: 2.5066819
MixupTrain:  epoch  0, batch   687 | loss: 2.1373260
MixupTrain:  epoch  0, batch   688 | loss: 2.0770748
MixupTrain:  epoch  0, batch   689 | loss: 2.1871686
MixupTrain:  epoch  0, batch   690 | loss: 2.2577817
MixupTrain:  epoch  0, batch   691 | loss: 2.1822302
MixupTrain:  epoch  0, batch   692 | loss: 2.1243749
MixupTrain:  epoch  0, batch   693 | loss: 2.0886943
MixupTrain:  epoch  0, batch   694 | loss: 2.2299459
MixupTrain:  epoch  0, batch   695 | loss: 2.1679378
MixupTrain:  epoch  0, batch   696 | loss: 2.1904464
MixupTrain:  epoch  0, batch   697 | loss: 2.4735801
MixupTrain:  epoch  0, batch   698 | loss: 2.0578752
MixupTrain:  epoch  0, batch   699 | loss: 2.2690308
MixupTrain:  epoch  0, batch   700 | loss: 2.3832505
MixupTrain:  epoch  0, batch   701 | loss: 2.1799765
MixupTrain:  epoch  0, batch   702 | loss: 2.1516397
MixupTrain:  epoch  0, batch   703 | loss: 2.2625086
MixupTrain:  epoch  0, batch   704 | loss: 2.4394994
MixupTrain:  epoch  0, batch   705 | loss: 2.0950985
MixupTrain:  epoch  0, batch   706 | loss: 2.1978936
MixupTrain:  epoch  0, batch   707 | loss: 2.4302750
MixupTrain:  epoch  0, batch   708 | loss: 2.0631728
MixupTrain:  epoch  0, batch   709 | loss: 2.2460852
MixupTrain:  epoch  0, batch   710 | loss: 2.3014398
MixupTrain:  epoch  0, batch   711 | loss: 2.5142653
MixupTrain:  epoch  0, batch   712 | loss: 2.4955773
MixupTrain:  epoch  0, batch   713 | loss: 2.0069337
MixupTrain:  epoch  0, batch   714 | loss: 2.3637433
MixupTrain:  epoch  0, batch   715 | loss: 2.7489834
MixupTrain:  epoch  0, batch   716 | loss: 2.0491455
MixupTrain:  epoch  0, batch   717 | loss: 2.1843958
MixupTrain:  epoch  0, batch   718 | loss: 2.0367422
MixupTrain:  epoch  0, batch   719 | loss: 2.2749090
MixupTrain:  epoch  0, batch   720 | loss: 2.2861943
MixupTrain:  epoch  0, batch   721 | loss: 2.3180799
MixupTrain:  epoch  0, batch   722 | loss: 2.4279251
MixupTrain:  epoch  0, batch   723 | loss: 2.5322230
MixupTrain:  epoch  0, batch   724 | loss: 2.3861465
MixupTrain:  epoch  0, batch   725 | loss: 2.3518696
MixupTrain:  epoch  0, batch   726 | loss: 2.3342986
MixupTrain:  epoch  0, batch   727 | loss: 2.1098461
MixupTrain:  epoch  0, batch   728 | loss: 2.3682160
MixupTrain:  epoch  0, batch   729 | loss: 2.1224737
MixupTrain:  epoch  0, batch   730 | loss: 2.0979152
MixupTrain:  epoch  0, batch   731 | loss: 2.6360474
MixupTrain:  epoch  0, batch   732 | loss: 2.3920951
MixupTrain:  epoch  0, batch   733 | loss: 2.1758399
MixupTrain:  epoch  0, batch   734 | loss: 2.3172488
MixupTrain:  epoch  0, batch   735 | loss: 1.9604297
MixupTrain:  epoch  0, batch   736 | loss: 2.4850695
MixupTrain:  epoch  0, batch   737 | loss: 2.1179996
MixupTrain:  epoch  0, batch   738 | loss: 2.2983670
MixupTrain:  epoch  0, batch   739 | loss: 2.0981011
MixupTrain:  epoch  0, batch   740 | loss: 1.9561313
MixupTrain:  epoch  0, batch   741 | loss: 2.4562340
MixupTrain:  epoch  0, batch   742 | loss: 2.3289256
MixupTrain:  epoch  0, batch   743 | loss: 2.0425451
MixupTrain:  epoch  0, batch   744 | loss: 2.1397603
MixupTrain:  epoch  0, batch   745 | loss: 2.1241159
MixupTrain:  epoch  0, batch   746 | loss: 2.0723290
MixupTrain:  epoch  0, batch   747 | loss: 2.3808551
MixupTrain:  epoch  0, batch   748 | loss: 2.3575642
MixupTrain:  epoch  0, batch   749 | loss: 2.2365174
MixupTrain:  epoch  0, batch   750 | loss: 1.9037240
MixupTrain:  epoch  0, batch   751 | loss: 2.2988424
MixupTrain:  epoch  0, batch   752 | loss: 2.2908406
MixupTrain:  epoch  0, batch   753 | loss: 2.1120524
MixupTrain:  epoch  0, batch   754 | loss: 2.1685438
MixupTrain:  epoch  0, batch   755 | loss: 2.4155707
MixupTrain:  epoch  0, batch   756 | loss: 1.9817737
MixupTrain:  epoch  0, batch   757 | loss: 2.2978158
MixupTrain:  epoch  0, batch   758 | loss: 2.0259800
MixupTrain:  epoch  0, batch   759 | loss: 1.9175134
MixupTrain:  epoch  0, batch   760 | loss: 2.2236814
MixupTrain:  epoch  0, batch   761 | loss: 2.2119164
MixupTrain:  epoch  0, batch   762 | loss: 2.1364038
MixupTrain:  epoch  0, batch   763 | loss: 2.3389049
MixupTrain:  epoch  0, batch   764 | loss: 2.0270662
MixupTrain:  epoch  0, batch   765 | loss: 2.1238172
MixupTrain:  epoch  0, batch   766 | loss: 2.2150416
MixupTrain:  epoch  0, batch   767 | loss: 2.2364807
MixupTrain:  epoch  0, batch   768 | loss: 2.4133549
MixupTrain:  epoch  0, batch   769 | loss: 2.1943290
MixupTrain:  epoch  0, batch   770 | loss: 2.3392882
MixupTrain:  epoch  0, batch   771 | loss: 2.1773422
MixupTrain:  epoch  0, batch   772 | loss: 2.6042972
MixupTrain:  epoch  0, batch   773 | loss: 2.3235686
MixupTrain:  epoch  0, batch   774 | loss: 2.0311599
MixupTrain:  epoch  0, batch   775 | loss: 2.2188902
MixupTrain:  epoch  0, batch   776 | loss: 2.0111346
MixupTrain:  epoch  0, batch   777 | loss: 2.3816991
MixupTrain:  epoch  0, batch   778 | loss: 2.6029100
MixupTrain:  epoch  0, batch   779 | loss: 2.0098548
MixupTrain:  epoch  0, batch   780 | loss: 2.1839778
MixupTrain:  epoch  0, batch   781 | loss: 2.2761133
MixupTrain:  epoch  0, batch   782 | loss: 2.1675014
MixupTrain:  epoch  0, batch   783 | loss: 2.2917047
MixupTrain:  epoch  0, batch   784 | loss: 2.1447010
MixupTrain:  epoch  0, batch   785 | loss: 2.3038571
MixupTrain:  epoch  0, batch   786 | loss: 2.0496292
MixupTrain:  epoch  0, batch   787 | loss: 2.3064418
MixupTrain:  epoch  0, batch   788 | loss: 2.7480576
MixupTrain:  epoch  0, batch   789 | loss: 2.1335635
MixupTrain:  epoch  0, batch   790 | loss: 2.1004980
MixupTrain:  epoch  0, batch   791 | loss: 1.9505751
MixupTrain:  epoch  0, batch   792 | loss: 2.1999578
MixupTrain:  epoch  0, batch   793 | loss: 2.2519593
MixupTrain:  epoch  0, batch   794 | loss: 2.2193484
MixupTrain:  epoch  0, batch   795 | loss: 2.2244031
MixupTrain:  epoch  0, batch   796 | loss: 2.0472097
MixupTrain:  epoch  0, batch   797 | loss: 2.1988897
MixupTrain:  epoch  0, batch   798 | loss: 2.2892084
MixupTrain:  epoch  0, batch   799 | loss: 2.3577805
MixupTrain:  epoch  0, batch   800 | loss: 2.0397387
MixupTrain:  epoch  0, batch   801 | loss: 2.1333108
MixupTrain:  epoch  0, batch   802 | loss: 2.2605970
MixupTrain:  epoch  0, batch   803 | loss: 2.0253944
MixupTrain:  epoch  0, batch   804 | loss: 2.2974246
MixupTrain:  epoch  0, batch   805 | loss: 2.1578596
MixupTrain:  epoch  0, batch   806 | loss: 2.2920465
MixupTrain:  epoch  0, batch   807 | loss: 2.2587273
MixupTrain:  epoch  0, batch   808 | loss: 2.2932832
MixupTrain:  epoch  0, batch   809 | loss: 1.8864326
MixupTrain:  epoch  0, batch   810 | loss: 2.1286731
MixupTrain:  epoch  0, batch   811 | loss: 2.0596213
MixupTrain:  epoch  0, batch   812 | loss: 2.2568800
MixupTrain:  epoch  0, batch   813 | loss: 1.9671373
MixupTrain:  epoch  0, batch   814 | loss: 2.2095518
MixupTrain:  epoch  0, batch   815 | loss: 2.4058673
MixupTrain:  epoch  0, batch   816 | loss: 2.1844473
MixupTrain:  epoch  0, batch   817 | loss: 2.1110921
MixupTrain:  epoch  0, batch   818 | loss: 2.4023471
MixupTrain:  epoch  0, batch   819 | loss: 2.0060270
MixupTrain:  epoch  0, batch   820 | loss: 2.1410875
MixupTrain:  epoch  0, batch   821 | loss: 2.1328964
MixupTrain:  epoch  0, batch   822 | loss: 2.2736888
MixupTrain:  epoch  0, batch   823 | loss: 2.2081728
MixupTrain:  epoch  0, batch   824 | loss: 2.0370092
MixupTrain:  epoch  0, batch   825 | loss: 2.1245065
MixupTrain:  epoch  0, batch   826 | loss: 2.3169081
MixupTrain:  epoch  0, batch   827 | loss: 1.9619521
MixupTrain:  epoch  0, batch   828 | loss: 2.7226186
MixupTrain:  epoch  0, batch   829 | loss: 2.3444195
MixupTrain:  epoch  0, batch   830 | loss: 2.1318488
MixupTrain:  epoch  0, batch   831 | loss: 2.2877970
MixupTrain:  epoch  0, batch   832 | loss: 2.1230290
MixupTrain:  epoch  0, batch   833 | loss: 2.2446158
MixupTrain:  epoch  0, batch   834 | loss: 2.2609177
MixupTrain:  epoch  0, batch   835 | loss: 2.4315844
MixupTrain:  epoch  0, batch   836 | loss: 2.5360792
MixupTrain:  epoch  0, batch   837 | loss: 2.3721263
MixupTrain:  epoch  0, batch   838 | loss: 2.2570846
MixupTrain:  epoch  0, batch   839 | loss: 2.3191986
MixupTrain:  epoch  0, batch   840 | loss: 2.2143457
MixupTrain:  epoch  0, batch   841 | loss: 2.2936807
MixupTrain:  epoch  0, batch   842 | loss: 2.3107440
MixupTrain:  epoch  0, batch   843 | loss: 2.0704656
MixupTrain:  epoch  0, batch   844 | loss: 1.9869418
MixupTrain:  epoch  0, batch   845 | loss: 2.1370964
MixupTrain:  epoch  0, batch   846 | loss: 2.1288810
MixupTrain:  epoch  0, batch   847 | loss: 2.0480750
MixupTrain:  epoch  0, batch   848 | loss: 1.9827120
MixupTrain:  epoch  0, batch   849 | loss: 2.2512448
MixupTrain:  epoch  0, batch   850 | loss: 2.0897207
MixupTrain:  epoch  0, batch   851 | loss: 2.0789361
MixupTrain:  epoch  0, batch   852 | loss: 2.2080574
MixupTrain:  epoch  0, batch   853 | loss: 2.0051031
MixupTrain:  epoch  0, batch   854 | loss: 2.4027920
MixupTrain:  epoch  0, batch   855 | loss: 2.2349076
MixupTrain:  epoch  0, batch   856 | loss: 2.3316388
MixupTrain:  epoch  0, batch   857 | loss: 2.2609878
MixupTrain:  epoch  0, batch   858 | loss: 2.1488733
MixupTrain:  epoch  0, batch   859 | loss: 2.3292556
MixupTrain:  epoch  0, batch   860 | loss: 2.5084660
MixupTrain:  epoch  0, batch   861 | loss: 2.2230620
MixupTrain:  epoch  0, batch   862 | loss: 2.3864717
MixupTrain:  epoch  0, batch   863 | loss: 2.2317181
MixupTrain:  epoch  0, batch   864 | loss: 2.2787514
MixupTrain:  epoch  0, batch   865 | loss: 2.2393608
MixupTrain:  epoch  0, batch   866 | loss: 2.2645888
MixupTrain:  epoch  0, batch   867 | loss: 2.3512263
MixupTrain:  epoch  0, batch   868 | loss: 2.4870429
MixupTrain:  epoch  0, batch   869 | loss: 2.5322859
MixupTrain:  epoch  0, batch   870 | loss: 2.1269922
MixupTrain:  epoch  0, batch   871 | loss: 2.0893903
MixupTrain:  epoch  0, batch   872 | loss: 2.3813009
MixupTrain:  epoch  0, batch   873 | loss: 2.3426504
MixupTrain:  epoch  0, batch   874 | loss: 2.1844375
MixupTrain:  epoch  0, batch   875 | loss: 2.1329136
MixupTrain:  epoch  0, batch   876 | loss: 2.1391947
MixupTrain:  epoch  0, batch   877 | loss: 2.4743710
MixupTrain:  epoch  0, batch   878 | loss: 2.2714651
MixupTrain:  epoch  0, batch   879 | loss: 2.4092753
MixupTrain:  epoch  0, batch   880 | loss: 2.3051291
MixupTrain:  epoch  0, batch   881 | loss: 2.1826196
MixupTrain:  epoch  0, batch   882 | loss: 2.3485889
MixupTrain:  epoch  0, batch   883 | loss: 2.2051871
MixupTrain:  epoch  0, batch   884 | loss: 2.2275736
MixupTrain:  epoch  0, batch   885 | loss: 2.2762399
MixupTrain:  epoch  0, batch   886 | loss: 2.4469452
MixupTrain:  epoch  0, batch   887 | loss: 2.2284939
MixupTrain:  epoch  0, batch   888 | loss: 2.1480937
MixupTrain:  epoch  0, batch   889 | loss: 2.2218351
MixupTrain:  epoch  0, batch   890 | loss: 2.1557479
MixupTrain:  epoch  0, batch   891 | loss: 2.1389956
MixupTrain:  epoch  0, batch   892 | loss: 2.1766400
MixupTrain:  epoch  0, batch   893 | loss: 2.1903603
MixupTrain:  epoch  0, batch   894 | loss: 2.2766047
MixupTrain:  epoch  0, batch   895 | loss: 2.3390794
MixupTrain:  epoch  0, batch   896 | loss: 2.2518990
MixupTrain:  epoch  0, batch   897 | loss: 2.2710443
MixupTrain:  epoch  0, batch   898 | loss: 2.4783499
MixupTrain:  epoch  0, batch   899 | loss: 2.3696327
MixupTrain:  epoch  0, batch   900 | loss: 1.9728510
MixupTrain:  epoch  0, batch   901 | loss: 2.3240175
MixupTrain:  epoch  0, batch   902 | loss: 2.3220339
MixupTrain:  epoch  0, batch   903 | loss: 2.2589767
MixupTrain:  epoch  0, batch   904 | loss: 2.3853216
MixupTrain:  epoch  0, batch   905 | loss: 2.1477947
MixupTrain:  epoch  0, batch   906 | loss: 2.2279794
MixupTrain:  epoch  0, batch   907 | loss: 2.2939081
MixupTrain:  epoch  0, batch   908 | loss: 2.1054816
MixupTrain:  epoch  0, batch   909 | loss: 2.1390142
MixupTrain:  epoch  0, batch   910 | loss: 2.0412207
MixupTrain:  epoch  0, batch   911 | loss: 2.2029712
MixupTrain:  epoch  0, batch   912 | loss: 2.0770574
MixupTrain:  epoch  0, batch   913 | loss: 2.2716088
MixupTrain:  epoch  0, batch   914 | loss: 2.1380391
MixupTrain:  epoch  0, batch   915 | loss: 2.0745208
MixupTrain:  epoch  0, batch   916 | loss: 2.1256499
MixupTrain:  epoch  0, batch   917 | loss: 2.4727376
MixupTrain:  epoch  0, batch   918 | loss: 2.1373932
MixupTrain:  epoch  0, batch   919 | loss: 2.1258810
MixupTrain:  epoch  0, batch   920 | loss: 2.0516109
MixupTrain:  epoch  0, batch   921 | loss: 2.3514242
MixupTrain:  epoch  0, batch   922 | loss: 1.9966650
MixupTrain:  epoch  0, batch   923 | loss: 2.4539492
MixupTrain:  epoch  0, batch   924 | loss: 1.9582958
MixupTrain:  epoch  0, batch   925 | loss: 2.0406733
MixupTrain:  epoch  0, batch   926 | loss: 2.4157150
MixupTrain:  epoch  0, batch   927 | loss: 2.3506868
MixupTrain:  epoch  0, batch   928 | loss: 2.1059170
MixupTrain:  epoch  0, batch   929 | loss: 2.4309335
MixupTrain:  epoch  0, batch   930 | loss: 2.2139068
MixupTrain:  epoch  0, batch   931 | loss: 2.3046222
MixupTrain:  epoch  0, batch   932 | loss: 2.6895080
MixupTrain:  epoch  0, batch   933 | loss: 2.3177299
MixupTrain:  epoch  0, batch   934 | loss: 2.1699915
MixupTrain:  epoch  0, batch   935 | loss: 2.3339882
MixupTrain:  epoch  0, batch   936 | loss: 2.0508149
MixupTrain:  epoch  0, batch   937 | loss: 2.3033829
MixupTrain:  epoch  0, batch   938 | loss: 2.1388795
MixupTrain:  epoch  0, batch   939 | loss: 2.3528318
MixupTrain:  epoch  0, batch   940 | loss: 1.9756773
MixupTrain:  epoch  0, batch   941 | loss: 2.4256287
MixupTrain:  epoch  0, batch   942 | loss: 2.0267520
MixupTrain:  epoch  0, batch   943 | loss: 2.1831374
MixupTrain:  epoch  0, batch   944 | loss: 1.8840131
MixupTrain:  epoch  0, batch   945 | loss: 2.0853300
MixupTrain:  epoch  0, batch   946 | loss: 2.3228402
MixupTrain:  epoch  0, batch   947 | loss: 2.0543261
MixupTrain:  epoch  0, batch   948 | loss: 2.2711751
MixupTrain:  epoch  0, batch   949 | loss: 1.9989458
MixupTrain:  epoch  0, batch   950 | loss: 2.0115986
MixupTrain:  epoch  0, batch   951 | loss: 2.1260006
MixupTrain:  epoch  0, batch   952 | loss: 2.3817348
MixupTrain:  epoch  0, batch   953 | loss: 1.9845037
MixupTrain:  epoch  0, batch   954 | loss: 2.7625799
MixupTrain:  epoch  0, batch   955 | loss: 2.1592684
MixupTrain:  epoch  0, batch   956 | loss: 2.2946682
MixupTrain:  epoch  0, batch   957 | loss: 2.3759060
MixupTrain:  epoch  0, batch   958 | loss: 2.1348729
MixupTrain:  epoch  0, batch   959 | loss: 2.1736007
MixupTrain:  epoch  0, batch   960 | loss: 2.3144712
MixupTrain:  epoch  0, batch   961 | loss: 2.0965462
MixupTrain:  epoch  0, batch   962 | loss: 2.0571251
MixupTrain:  epoch  0, batch   963 | loss: 2.4065413
MixupTrain:  epoch  0, batch   964 | loss: 2.2755663
MixupTrain:  epoch  0, batch   965 | loss: 2.1256986
MixupTrain:  epoch  0, batch   966 | loss: 2.4228926
MixupTrain:  epoch  0, batch   967 | loss: 2.2006640
MixupTrain:  epoch  0, batch   968 | loss: 2.1631913
MixupTrain:  epoch  0, batch   969 | loss: 2.1083865
MixupTrain:  epoch  0, batch   970 | loss: 2.1047430
MixupTrain:  epoch  0, batch   971 | loss: 2.3250737
MixupTrain:  epoch  0, batch   972 | loss: 2.2738435
MixupTrain:  epoch  0, batch   973 | loss: 2.0863285
MixupTrain:  epoch  0, batch   974 | loss: 2.2858987
MixupTrain:  epoch  0, batch   975 | loss: 2.4642949
MixupTrain:  epoch  0, batch   976 | loss: 2.2335298
MixupTrain:  epoch  0, batch   977 | loss: 2.3910608
MixupTrain:  epoch  0, batch   978 | loss: 2.4665232
MixupTrain:  epoch  0, batch   979 | loss: 2.3876801
MixupTrain:  epoch  0, batch   980 | loss: 2.4099598
MixupTrain:  epoch  0, batch   981 | loss: 2.3926249
MixupTrain:  epoch  0, batch   982 | loss: 2.1295857
MixupTrain:  epoch  0, batch   983 | loss: 2.3768828
MixupTrain:  epoch  0, batch   984 | loss: 2.3515182
MixupTrain:  epoch  0, batch   985 | loss: 2.1922886
MixupTrain:  epoch  0, batch   986 | loss: 2.2651472
MixupTrain:  epoch  0, batch   987 | loss: 2.2085881
MixupTrain:  epoch  0, batch   988 | loss: 2.2914340
MixupTrain:  epoch  0, batch   989 | loss: 2.2172410
MixupTrain:  epoch  0, batch   990 | loss: 2.3116391
MixupTrain:  epoch  0, batch   991 | loss: 2.3268590
MixupTrain:  epoch  0, batch   992 | loss: 2.1494145
MixupTrain:  epoch  0, batch   993 | loss: 2.3008821
MixupTrain:  epoch  0, batch   994 | loss: 1.9750404
MixupTrain:  epoch  0, batch   995 | loss: 2.0204401
MixupTrain:  epoch  0, batch   996 | loss: 2.1781266
MixupTrain:  epoch  0, batch   997 | loss: 2.1014321
MixupTrain:  epoch  0, batch   998 | loss: 2.2023382
MixupTrain:  epoch  0, batch   999 | loss: 2.1615252
MixupTrain:  epoch  0, batch  1000 | loss: 2.2900949
MixupTrain:  epoch  0, batch  1001 | loss: 2.3131638
MixupTrain:  epoch  0, batch  1002 | loss: 2.2481327
MixupTrain:  epoch  0, batch  1003 | loss: 2.3771348
MixupTrain:  epoch  0, batch  1004 | loss: 2.1014090
MixupTrain:  epoch  0, batch  1005 | loss: 2.3761292
MixupTrain:  epoch  0, batch  1006 | loss: 2.1467285
MixupTrain:  epoch  0, batch  1007 | loss: 2.2538357
MixupTrain:  epoch  0, batch  1008 | loss: 2.2389693
MixupTrain:  epoch  0, batch  1009 | loss: 2.1375608
MixupTrain:  epoch  0, batch  1010 | loss: 2.3851533
MixupTrain:  epoch  0, batch  1011 | loss: 1.9351072
MixupTrain:  epoch  0, batch  1012 | loss: 2.2370691
MixupTrain:  epoch  0, batch  1013 | loss: 2.4037395
MixupTrain:  epoch  0, batch  1014 | loss: 2.2313199
MixupTrain:  epoch  0, batch  1015 | loss: 2.3194549
MixupTrain:  epoch  0, batch  1016 | loss: 2.2332375
MixupTrain:  epoch  0, batch  1017 | loss: 2.1638541
MixupTrain:  epoch  0, batch  1018 | loss: 2.5616071
MixupTrain:  epoch  0, batch  1019 | loss: 2.0229900
MixupTrain:  epoch  0, batch  1020 | loss: 2.4089231
MixupTrain:  epoch  0, batch  1021 | loss: 2.2364576
MixupTrain:  epoch  0, batch  1022 | loss: 2.7252951
MixupTrain:  epoch  0, batch  1023 | loss: 2.4832952
MixupTrain:  epoch  0, batch  1024 | loss: 2.2266741
MixupTrain:  epoch  0, batch  1025 | loss: 2.2012055
MixupTrain:  epoch  0, batch  1026 | loss: 2.1829381
MixupTrain:  epoch  0, batch  1027 | loss: 2.4010320
MixupTrain:  epoch  0, batch  1028 | loss: 2.1181774
MixupTrain:  epoch  0, batch  1029 | loss: 2.5592842
MixupTrain:  epoch  0, batch  1030 | loss: 2.3176165
MixupTrain:  epoch  0, batch  1031 | loss: 2.1413908
MixupTrain:  epoch  0, batch  1032 | loss: 2.0243831
MixupTrain:  epoch  0, batch  1033 | loss: 2.2219963
MixupTrain:  epoch  0, batch  1034 | loss: 2.3562398
MixupTrain:  epoch  0, batch  1035 | loss: 2.1833854
MixupTrain:  epoch  0, batch  1036 | loss: 2.1247134
MixupTrain:  epoch  0, batch  1037 | loss: 2.1743464
MixupTrain:  epoch  0, batch  1038 | loss: 2.2762735
MixupTrain:  epoch  0, batch  1039 | loss: 2.1129091
MixupTrain:  epoch  0, batch  1040 | loss: 2.2073908
MixupTrain:  epoch  0, batch  1041 | loss: 2.3798041
MixupTrain:  epoch  0, batch  1042 | loss: 2.2307005
MixupTrain:  epoch  0, batch  1043 | loss: 2.4144220
MixupTrain:  epoch  0, batch  1044 | loss: 2.2449765
MixupTrain:  epoch  0, batch  1045 | loss: 1.9633536
MixupTrain:  epoch  0, batch  1046 | loss: 2.3124509
MixupTrain:  epoch  0, batch  1047 | loss: 2.2078149
MixupTrain:  epoch  0, batch  1048 | loss: 2.0074430
MixupTrain:  epoch  0, batch  1049 | loss: 2.1068225
MixupTrain:  epoch  0, batch  1050 | loss: 2.0030403
MixupTrain:  epoch  0, batch  1051 | loss: 2.2143116
MixupTrain:  epoch  0, batch  1052 | loss: 1.9929640
MixupTrain:  epoch  0, batch  1053 | loss: 2.1383443
MixupTrain:  epoch  0, batch  1054 | loss: 2.3213220
MixupTrain:  epoch  0, batch  1055 | loss: 2.1063390
MixupTrain:  epoch  0, batch  1056 | loss: 2.0919306
MixupTrain:  epoch  0, batch  1057 | loss: 2.4655361
MixupTrain:  epoch  0, batch  1058 | loss: 2.1779191
MixupTrain:  epoch  0, batch  1059 | loss: 2.2601914
MixupTrain:  epoch  0, batch  1060 | loss: 2.4777436
MixupTrain:  epoch  0, batch  1061 | loss: 2.5676608
MixupTrain:  epoch  0, batch  1062 | loss: 2.1569200
MixupTrain:  epoch  0, batch  1063 | loss: 1.9593260
MixupTrain:  epoch  0, batch  1064 | loss: 2.2472835
MixupTrain:  epoch  0, batch  1065 | loss: 2.0987787
MixupTrain:  epoch  0, batch  1066 | loss: 2.3176732
MixupTrain:  epoch  0, batch  1067 | loss: 2.0668378
MixupTrain:  epoch  0, batch  1068 | loss: 2.2298408
MixupTrain:  epoch  0, batch  1069 | loss: 2.1052909
MixupTrain:  epoch  0, batch  1070 | loss: 2.2989554
MixupTrain:  epoch  0, batch  1071 | loss: 2.2884665
MixupTrain:  epoch  0, batch  1072 | loss: 2.0379906
MixupTrain:  epoch  0, batch  1073 | loss: 2.2933493
MixupTrain:  epoch  0, batch  1074 | loss: 2.3702691
MixupTrain:  epoch  0, batch  1075 | loss: 2.2146237
MixupTrain:  epoch  0, batch  1076 | loss: 2.0484564
MixupTrain:  epoch  0, batch  1077 | loss: 2.2363520
MixupTrain:  epoch  0, batch  1078 | loss: 2.1697083
MixupTrain:  epoch  0, batch  1079 | loss: 2.1347413
MixupTrain:  epoch  0, batch  1080 | loss: 2.2739203
MixupTrain:  epoch  0, batch  1081 | loss: 2.1019001
MixupTrain:  epoch  0, batch  1082 | loss: 2.0529895
MixupTrain:  epoch  0, batch  1083 | loss: 2.3384576
MixupTrain:  epoch  0, batch  1084 | loss: 2.2742276
MixupTrain:  epoch  0, batch  1085 | loss: 2.2394383
MixupTrain:  epoch  0, batch  1086 | loss: 2.5134716
MixupTrain:  epoch  0, batch  1087 | loss: 2.2695417
MixupTrain:  epoch  0, batch  1088 | loss: 1.8713802
MixupTrain:  epoch  0, batch  1089 | loss: 2.1032612
MixupTrain:  epoch  0, batch  1090 | loss: 2.2263436
MixupTrain:  epoch  0, batch  1091 | loss: 2.3300886
MixupTrain:  epoch  0, batch  1092 | loss: 2.4281988
MixupTrain:  epoch  0, batch  1093 | loss: 2.1487007
MixupTrain:  epoch  0, batch  1094 | loss: 2.2402611
MixupTrain:  epoch  0, batch  1095 | loss: 2.1760607
MixupTrain:  epoch  0, batch  1096 | loss: 2.1228509
MixupTrain:  epoch  0, batch  1097 | loss: 2.1892514
MixupTrain:  epoch  0, batch  1098 | loss: 2.4120617
MixupTrain:  epoch  0, batch  1099 | loss: 2.2275209
MixupTrain:  epoch  0, batch  1100 | loss: 2.2493455
MixupTrain:  epoch  0, batch  1101 | loss: 2.0792251
MixupTrain:  epoch  0, batch  1102 | loss: 2.3422632
MixupTrain:  epoch  0, batch  1103 | loss: 2.0737951
MixupTrain:  epoch  0, batch  1104 | loss: 2.4808455
MixupTrain:  epoch  0, batch  1105 | loss: 2.3715847
MixupTrain:  epoch  0, batch  1106 | loss: 2.2718122
MixupTrain:  epoch  0, batch  1107 | loss: 2.2839348
MixupTrain:  epoch  0, batch  1108 | loss: 2.0556755
MixupTrain:  epoch  0, batch  1109 | loss: 2.2352467
MixupTrain:  epoch  0, batch  1110 | loss: 2.3704977
MixupTrain:  epoch  0, batch  1111 | loss: 2.1488774
MixupTrain:  epoch  0, batch  1112 | loss: 2.0716846
MixupTrain:  epoch  0, batch  1113 | loss: 2.3084950
MixupTrain:  epoch  0, batch  1114 | loss: 2.2409344
MixupTrain:  epoch  0, batch  1115 | loss: 2.1741595
MixupTrain:  epoch  0, batch  1116 | loss: 2.0899975
MixupTrain:  epoch  0, batch  1117 | loss: 2.5230527
MixupTrain:  epoch  0, batch  1118 | loss: 2.5841208
MixupTrain:  epoch  0, batch  1119 | loss: 2.0529799
MixupTrain:  epoch  0, batch  1120 | loss: 2.3098059
MixupTrain:  epoch  0, batch  1121 | loss: 2.2650726
MixupTrain:  epoch  0, batch  1122 | loss: 2.2349873
MixupTrain:  epoch  0, batch  1123 | loss: 2.1879654
MixupTrain:  epoch  0, batch  1124 | loss: 2.3158951
MixupTrain:  epoch  0, batch  1125 | loss: 2.2543554
MixupTrain:  epoch  0, batch  1126 | loss: 2.2850516
MixupTrain:  epoch  0, batch  1127 | loss: 2.2546406
MixupTrain:  epoch  0, batch  1128 | loss: 2.1757233
MixupTrain:  epoch  0, batch  1129 | loss: 2.7655764
MixupTrain:  epoch  0, batch  1130 | loss: 2.0770292
MixupTrain:  epoch  0, batch  1131 | loss: 2.0322437
MixupTrain:  epoch  0, batch  1132 | loss: 2.0607488
MixupTrain:  epoch  0, batch  1133 | loss: 2.2194128
MixupTrain:  epoch  0, batch  1134 | loss: 2.3795841
MixupTrain:  epoch  0, batch  1135 | loss: 2.0120139
MixupTrain:  epoch  0, batch  1136 | loss: 2.1773987
MixupTrain:  epoch  0, batch  1137 | loss: 2.3893411
MixupTrain:  epoch  0, batch  1138 | loss: 2.1522577
MixupTrain:  epoch  0, batch  1139 | loss: 2.0193534
MixupTrain:  epoch  0, batch  1140 | loss: 2.2270999
MixupTrain:  epoch  0, batch  1141 | loss: 2.2085469
MixupTrain:  epoch  0, batch  1142 | loss: 2.2783556
MixupTrain:  epoch  0, batch  1143 | loss: 2.0789597
MixupTrain:  epoch  0, batch  1144 | loss: 2.3252816
MixupTrain:  epoch  0, batch  1145 | loss: 2.3484094
MixupTrain:  epoch  0, batch  1146 | loss: 2.4299879
MixupTrain:  epoch  0, batch  1147 | loss: 2.2151649
MixupTrain:  epoch  0, batch  1148 | loss: 1.9825124
MixupTrain:  epoch  0, batch  1149 | loss: 2.2506852
MixupTrain:  epoch  0, batch  1150 | loss: 2.0243323
MixupTrain:  epoch  0, batch  1151 | loss: 2.1439772
MixupTrain:  epoch  0, batch  1152 | loss: 2.3132420
MixupTrain:  epoch  0, batch  1153 | loss: 2.2136483
MixupTrain:  epoch  0, batch  1154 | loss: 2.1118548
MixupTrain:  epoch  0, batch  1155 | loss: 2.1753354
MixupTrain:  epoch  0, batch  1156 | loss: 2.3180895
MixupTrain:  epoch  0, batch  1157 | loss: 2.3562815
MixupTrain:  epoch  0, batch  1158 | loss: 2.0666280
MixupTrain:  epoch  0, batch  1159 | loss: 2.0135155
MixupTrain:  epoch  0, batch  1160 | loss: 2.0015571
MixupTrain:  epoch  0, batch  1161 | loss: 2.0642645
MixupTrain:  epoch  0, batch  1162 | loss: 2.0801296
MixupTrain:  epoch  0, batch  1163 | loss: 2.5127029
MixupTrain:  epoch  0, batch  1164 | loss: 2.2499421
MixupTrain:  epoch  0, batch  1165 | loss: 2.1098154
MixupTrain:  epoch  0, batch  1166 | loss: 2.1867251
MixupTrain:  epoch  0, batch  1167 | loss: 2.1504011
MixupTrain:  epoch  0, batch  1168 | loss: 2.3364596
MixupTrain:  epoch  0, batch  1169 | loss: 2.1708062
MixupTrain:  epoch  0, batch  1170 | loss: 2.3797112
MixupTrain:  epoch  0, batch  1171 | loss: 2.1661968
MixupTrain:  epoch  0, batch  1172 | loss: 2.3891318
MixupTrain:  epoch  0, batch  1173 | loss: 2.0045793
MixupTrain:  epoch  0, batch  1174 | loss: 2.6092360
MixupTrain:  epoch  0, batch  1175 | loss: 2.4086995
MixupTrain:  epoch  0, batch  1176 | loss: 2.2206872
MixupTrain:  epoch  0, batch  1177 | loss: 2.1846294
MixupTrain:  epoch  0, batch  1178 | loss: 1.9789644
MixupTrain:  epoch  0, batch  1179 | loss: 2.4321749
MixupTrain:  epoch  0, batch  1180 | loss: 2.3883405
MixupTrain:  epoch  0, batch  1181 | loss: 1.9382243
MixupTrain:  epoch  0, batch  1182 | loss: 2.1517808
MixupTrain:  epoch  0, batch  1183 | loss: 2.0714087
MixupTrain:  epoch  0, batch  1184 | loss: 2.2903666
MixupTrain:  epoch  0, batch  1185 | loss: 2.1938620
MixupTrain:  epoch  0, batch  1186 | loss: 2.2830133
MixupTrain:  epoch  0, batch  1187 | loss: 2.1835821
MixupTrain:  epoch  0, batch  1188 | loss: 2.2099888
MixupTrain:  epoch  0, batch  1189 | loss: 2.0251546
MixupTrain:  epoch  0, batch  1190 | loss: 2.2001126
MixupTrain:  epoch  0, batch  1191 | loss: 2.0799308
MixupTrain:  epoch  0, batch  1192 | loss: 2.3222692
MixupTrain:  epoch  0, batch  1193 | loss: 2.2613914
MixupTrain:  epoch  0, batch  1194 | loss: 1.8888500
MixupTrain:  epoch  0, batch  1195 | loss: 2.2523561
MixupTrain:  epoch  0, batch  1196 | loss: 2.2701030
MixupTrain:  epoch  0, batch  1197 | loss: 2.3932638
MixupTrain:  epoch  0, batch  1198 | loss: 2.2002544
MixupTrain:  epoch  0, batch  1199 | loss: 2.3154502
MixupTrain:  epoch  0, batch  1200 | loss: 2.1546121
MixupTrain:  epoch  0, batch  1201 | loss: 2.3856654
MixupTrain:  epoch  0, batch  1202 | loss: 2.0605288
MixupTrain:  epoch  0, batch  1203 | loss: 2.1978383
MixupTrain:  epoch  0, batch  1204 | loss: 2.3056674
MixupTrain:  epoch  0, batch  1205 | loss: 1.9892347
MixupTrain:  epoch  0, batch  1206 | loss: 2.2885003
MixupTrain:  epoch  0, batch  1207 | loss: 2.3102250
MixupTrain:  epoch  0, batch  1208 | loss: 2.0558498
MixupTrain:  epoch  0, batch  1209 | loss: 2.0295181
MixupTrain:  epoch  0, batch  1210 | loss: 2.3027377
MixupTrain:  epoch  0, batch  1211 | loss: 2.2529044
MixupTrain:  epoch  0, batch  1212 | loss: 2.2607026
MixupTrain:  epoch  0, batch  1213 | loss: 2.3059454
MixupTrain:  epoch  0, batch  1214 | loss: 2.6663828
MixupTrain:  epoch  0, batch  1215 | loss: 2.3663630
MixupTrain:  epoch  0, batch  1216 | loss: 2.3732691
MixupTrain:  epoch  0, batch  1217 | loss: 2.1080437
MixupTrain:  epoch  0, batch  1218 | loss: 2.1844869
MixupTrain:  epoch  0, batch  1219 | loss: 2.0559435
MixupTrain:  epoch  0, batch  1220 | loss: 2.2816887
MixupTrain:  epoch  0, batch  1221 | loss: 2.0014625
MixupTrain:  epoch  0, batch  1222 | loss: 2.3818347
MixupTrain:  epoch  0, batch  1223 | loss: 2.3592849
MixupTrain:  epoch  0, batch  1224 | loss: 2.1573727
MixupTrain:  epoch  0, batch  1225 | loss: 2.2460942
MixupTrain:  epoch  0, batch  1226 | loss: 2.1423182
MixupTrain:  epoch  0, batch  1227 | loss: 2.1625948
MixupTrain:  epoch  0, batch  1228 | loss: 2.1794395
MixupTrain:  epoch  0, batch  1229 | loss: 2.3668675
MixupTrain:  epoch  0, batch  1230 | loss: 1.9943755
MixupTrain:  epoch  0, batch  1231 | loss: 2.1526663
MixupTrain:  epoch  0, batch  1232 | loss: 2.1815805
MixupTrain:  epoch  0, batch  1233 | loss: 1.9299943
MixupTrain:  epoch  0, batch  1234 | loss: 2.2343297
MixupTrain:  epoch  0, batch  1235 | loss: 2.2780743
MixupTrain:  epoch  0, batch  1236 | loss: 2.0887430
MixupTrain:  epoch  0, batch  1237 | loss: 2.0002022
MixupTrain:  epoch  0, batch  1238 | loss: 2.3226182
MixupTrain:  epoch  0, batch  1239 | loss: 2.3351603
MixupTrain:  epoch  0, batch  1240 | loss: 2.3727422
MixupTrain:  epoch  0, batch  1241 | loss: 2.2545347
MixupTrain:  epoch  0, batch  1242 | loss: 2.1427898
MixupTrain:  epoch  0, batch  1243 | loss: 2.1872711
MixupTrain:  epoch  0, batch  1244 | loss: 2.5009193
MixupTrain:  epoch  0, batch  1245 | loss: 2.1782453
MixupTrain:  epoch  0, batch  1246 | loss: 2.2259309
MixupTrain:  epoch  0, batch  1247 | loss: 2.2419181
MixupTrain:  epoch  0, batch  1248 | loss: 2.5985146
MixupTrain:  epoch  0, batch  1249 | loss: 2.0796084
MixupTrain:  epoch  0, batch  1250 | loss: 2.5188153
MixupTrain:  epoch  0, batch  1251 | loss: 2.3297477
MixupTrain:  epoch  0, batch  1252 | loss: 2.3172007
MixupTrain:  epoch  0, batch  1253 | loss: 2.1598277
MixupTrain:  epoch  0, batch  1254 | loss: 2.0838089
MixupTrain:  epoch  0, batch  1255 | loss: 2.4383526
MixupTrain:  epoch  0, batch  1256 | loss: 2.0787485
MixupTrain:  epoch  0, batch  1257 | loss: 2.1704221
MixupTrain:  epoch  0, batch  1258 | loss: 2.4842837
MixupTrain:  epoch  0, batch  1259 | loss: 2.1960704
MixupTrain:  epoch  0, batch  1260 | loss: 2.1280138
MixupTrain:  epoch  0, batch  1261 | loss: 2.1973097
MixupTrain:  epoch  0, batch  1262 | loss: 2.0582514
MixupTrain:  epoch  0, batch  1263 | loss: 2.0583789
MixupTrain:  epoch  0, batch  1264 | loss: 2.4409466
MixupTrain:  epoch  0, batch  1265 | loss: 2.1789405
MixupTrain:  epoch  0, batch  1266 | loss: 2.4973969
MixupTrain:  epoch  0, batch  1267 | loss: 2.1361995
MixupTrain:  epoch  0, batch  1268 | loss: 2.1855080
MixupTrain:  epoch  0, batch  1269 | loss: 2.1442156
MixupTrain:  epoch  0, batch  1270 | loss: 2.2313952
MixupTrain:  epoch  0, batch  1271 | loss: 2.0927999
MixupTrain:  epoch  0, batch  1272 | loss: 2.3408015
MixupTrain:  epoch  0, batch  1273 | loss: 2.3180320
MixupTrain:  epoch  0, batch  1274 | loss: 2.2815528
MixupTrain:  epoch  0, batch  1275 | loss: 2.1919377
MixupTrain:  epoch  0, batch  1276 | loss: 2.1530385
MixupTrain:  epoch  0, batch  1277 | loss: 2.4883416
MixupTrain:  epoch  0, batch  1278 | loss: 2.1665339
MixupTrain:  epoch  0, batch  1279 | loss: 2.1770945
MixupTrain:  epoch  0, batch  1280 | loss: 2.2710819
MixupTrain:  epoch  0, batch  1281 | loss: 2.1232343
MixupTrain:  epoch  0, batch  1282 | loss: 2.3485441
MixupTrain:  epoch  0, batch  1283 | loss: 2.3470984
MixupTrain:  epoch  0, batch  1284 | loss: 2.2985334
MixupTrain:  epoch  0, batch  1285 | loss: 2.1458547
MixupTrain:  epoch  0, batch  1286 | loss: 2.3327770
MixupTrain:  epoch  0, batch  1287 | loss: 2.2753599
MixupTrain:  epoch  0, batch  1288 | loss: 2.2933793
MixupTrain:  epoch  0, batch  1289 | loss: 2.2179065
MixupTrain:  epoch  0, batch  1290 | loss: 2.1220989
MixupTrain:  epoch  0, batch  1291 | loss: 2.4643407
MixupTrain:  epoch  0, batch  1292 | loss: 2.4717808
MixupTrain:  epoch  0, batch  1293 | loss: 2.3926802
MixupTrain:  epoch  0, batch  1294 | loss: 2.2609332
MixupTrain:  epoch  0, batch  1295 | loss: 2.1913750
MixupTrain:  epoch  0, batch  1296 | loss: 2.0856090
MixupTrain:  epoch  0, batch  1297 | loss: 2.3723881
MixupTrain:  epoch  0, batch  1298 | loss: 2.2696950
MixupTrain:  epoch  0, batch  1299 | loss: 2.1736450
MixupTrain:  epoch  0, batch  1300 | loss: 2.0709743
MixupTrain:  epoch  0, batch  1301 | loss: 2.4447989
MixupTrain:  epoch  0, batch  1302 | loss: 2.2791815
MixupTrain:  epoch  0, batch  1303 | loss: 2.2710857
MixupTrain:  epoch  0, batch  1304 | loss: 2.3871989
MixupTrain:  epoch  0, batch  1305 | loss: 2.4323516
MixupTrain:  epoch  0, batch  1306 | loss: 2.1950831
MixupTrain:  epoch  0, batch  1307 | loss: 1.9655215
MixupTrain:  epoch  0, batch  1308 | loss: 2.3776152
MixupTrain:  epoch  0, batch  1309 | loss: 2.6293297
MixupTrain:  epoch  0, batch  1310 | loss: 2.2994566
MixupTrain:  epoch  0, batch  1311 | loss: 2.4183276
MixupTrain:  epoch  0, batch  1312 | loss: 2.0965662
MixupTrain:  epoch  0, batch  1313 | loss: 2.0008926
MixupTrain:  epoch  0, batch  1314 | loss: 2.0305507
MixupTrain:  epoch  0, batch  1315 | loss: 2.2798228
MixupTrain:  epoch  0, batch  1316 | loss: 2.5722945
MixupTrain:  epoch  0, batch  1317 | loss: 2.2541032
MixupTrain:  epoch  0, batch  1318 | loss: 2.2201552
MixupTrain:  epoch  0, batch  1319 | loss: 2.1854024
MixupTrain:  epoch  0, batch  1320 | loss: 2.6623583
MixupTrain:  epoch  0, batch  1321 | loss: 1.9555666
MixupTrain:  epoch  0, batch  1322 | loss: 1.9750547
MixupTrain:  epoch  0, batch  1323 | loss: 2.2088308
MixupTrain:  epoch  0, batch  1324 | loss: 2.1084354
MixupTrain:  epoch  0, batch  1325 | loss: 2.0642593
MixupTrain:  epoch  0, batch  1326 | loss: 2.0431082
MixupTrain:  epoch  0, batch  1327 | loss: 2.2161541
MixupTrain:  epoch  0, batch  1328 | loss: 2.4249990
MixupTrain:  epoch  0, batch  1329 | loss: 2.0439143
MixupTrain:  epoch  0, batch  1330 | loss: 2.0513515
MixupTrain:  epoch  0, batch  1331 | loss: 2.1072197
MixupTrain:  epoch  0, batch  1332 | loss: 2.1511676
MixupTrain:  epoch  0, batch  1333 | loss: 2.4096417
MixupTrain:  epoch  0, batch  1334 | loss: 2.0251122
MixupTrain:  epoch  0, batch  1335 | loss: 2.0322051
MixupTrain:  epoch  0, batch  1336 | loss: 2.0245728
MixupTrain:  epoch  0, batch  1337 | loss: 2.1048360
MixupTrain:  epoch  0, batch  1338 | loss: 2.1033940
MixupTrain:  epoch  0, batch  1339 | loss: 2.2621098
MixupTrain:  epoch  0, batch  1340 | loss: 2.2120309
MixupTrain:  epoch  0, batch  1341 | loss: 2.2480040
MixupTrain:  epoch  0, batch  1342 | loss: 2.1821942
MixupTrain:  epoch  0, batch  1343 | loss: 2.2083783
MixupTrain:  epoch  0, batch  1344 | loss: 2.2289722
MixupTrain:  epoch  0, batch  1345 | loss: 2.2496550
MixupTrain:  epoch  0, batch  1346 | loss: 2.5134068
MixupTrain:  epoch  0, batch  1347 | loss: 2.3637023
MixupTrain:  epoch  0, batch  1348 | loss: 2.1024683
MixupTrain:  epoch  0, batch  1349 | loss: 2.1142011
MixupTrain:  epoch  0, batch  1350 | loss: 2.2915208
MixupTrain:  epoch  0, batch  1351 | loss: 2.1105254
MixupTrain:  epoch  0, batch  1352 | loss: 2.4092875
MixupTrain:  epoch  0, batch  1353 | loss: 2.1451385
MixupTrain:  epoch  0, batch  1354 | loss: 1.9555253
MixupTrain:  epoch  0, batch  1355 | loss: 2.0510676
MixupTrain:  epoch  0, batch  1356 | loss: 2.1485105
MixupTrain:  epoch  0, batch  1357 | loss: 2.1273727
MixupTrain:  epoch  0, batch  1358 | loss: 2.5109949
MixupTrain:  epoch  0, batch  1359 | loss: 2.2986588
MixupTrain:  epoch  0, batch  1360 | loss: 2.5995347
MixupTrain:  epoch  0, batch  1361 | loss: 2.2542267
MixupTrain:  epoch  0, batch  1362 | loss: 2.3227558
MixupTrain:  epoch  0, batch  1363 | loss: 2.0640323
MixupTrain:  epoch  0, batch  1364 | loss: 2.1074843
MixupTrain:  epoch  0, batch  1365 | loss: 1.9494621
MixupTrain:  epoch  0, batch  1366 | loss: 2.0868764
MixupTrain:  epoch  0, batch  1367 | loss: 2.3573496
MixupTrain:  epoch  0, batch  1368 | loss: 2.4900489
MixupTrain:  epoch  0, batch  1369 | loss: 2.3775427
MixupTrain:  epoch  0, batch  1370 | loss: 2.4967995
MixupTrain:  epoch  0, batch  1371 | loss: 2.4702325
MixupTrain:  epoch  0, batch  1372 | loss: 2.4534631
MixupTrain:  epoch  0, batch  1373 | loss: 2.3483887
MixupTrain:  epoch  0, batch  1374 | loss: 1.9893479
MixupTrain:  epoch  0, batch  1375 | loss: 2.3901138
MixupTrain:  epoch  0, batch  1376 | loss: 2.3700716
MixupTrain:  epoch  0, batch  1377 | loss: 2.0023575
MixupTrain:  epoch  0, batch  1378 | loss: 2.4884686
MixupTrain:  epoch  0, batch  1379 | loss: 2.2411444
MixupTrain:  epoch  0, batch  1380 | loss: 2.3808217
MixupTrain:  epoch  0, batch  1381 | loss: 2.1988580
MixupTrain:  epoch  0, batch  1382 | loss: 2.0845585
MixupTrain:  epoch  0, batch  1383 | loss: 2.3609085
MixupTrain:  epoch  0, batch  1384 | loss: 2.1616516
MixupTrain:  epoch  0, batch  1385 | loss: 2.2070172
MixupTrain:  epoch  0, batch  1386 | loss: 2.0311558
MixupTrain:  epoch  0, batch  1387 | loss: 2.1339197
MixupTrain:  epoch  0, batch  1388 | loss: 2.2815623
MixupTrain:  epoch  0, batch  1389 | loss: 1.9842378
MixupTrain:  epoch  0, batch  1390 | loss: 2.5843623
MixupTrain:  epoch  0, batch  1391 | loss: 2.1850224
MixupTrain:  epoch  0, batch  1392 | loss: 2.0440717
MixupTrain:  epoch  0, batch  1393 | loss: 2.1038461
MixupTrain:  epoch  0, batch  1394 | loss: 2.1817844
MixupTrain:  epoch  0, batch  1395 | loss: 2.1055694
MixupTrain:  epoch  0, batch  1396 | loss: 2.3421817
MixupTrain:  epoch  0, batch  1397 | loss: 2.1660295
MixupTrain:  epoch  0, batch  1398 | loss: 2.2242386
MixupTrain:  epoch  0, batch  1399 | loss: 2.0145316
MixupTrain:  epoch  0, batch  1400 | loss: 1.9787889
MixupTrain:  epoch  0, batch  1401 | loss: 2.4323578
MixupTrain:  epoch  0, batch  1402 | loss: 2.2554722
MixupTrain:  epoch  0, batch  1403 | loss: 2.0828972
MixupTrain:  epoch  0, batch  1404 | loss: 2.6615887
MixupTrain:  epoch  0, batch  1405 | loss: 2.2661111
MixupTrain:  epoch  0, batch  1406 | loss: 1.8964293
MixupTrain:  epoch  0, batch  1407 | loss: 2.3322275
MixupTrain:  epoch  0, batch  1408 | loss: 2.1706009
MixupTrain:  epoch  0, batch  1409 | loss: 2.0950527
MixupTrain:  epoch  0, batch  1410 | loss: 2.2822585
MixupTrain:  epoch  0, batch  1411 | loss: 2.3879244
MixupTrain:  epoch  0, batch  1412 | loss: 2.1574616
MixupTrain:  epoch  0, batch  1413 | loss: 2.6555846
MixupTrain:  epoch  0, batch  1414 | loss: 2.1742105
MixupTrain:  epoch  0, batch  1415 | loss: 2.2220757
MixupTrain:  epoch  0, batch  1416 | loss: 1.9922237
MixupTrain:  epoch  0, batch  1417 | loss: 2.3081398
MixupTrain:  epoch  0, batch  1418 | loss: 2.5439162
MixupTrain:  epoch  0, batch  1419 | loss: 2.3073852
MixupTrain:  epoch  0, batch  1420 | loss: 1.9610043
MixupTrain:  epoch  0, batch  1421 | loss: 2.2783113
MixupTrain:  epoch  0, batch  1422 | loss: 2.4372058
MixupTrain:  epoch  0, batch  1423 | loss: 1.9271162
MixupTrain:  epoch  0, batch  1424 | loss: 2.1444044
MixupTrain:  epoch  0, batch  1425 | loss: 2.1333761
MixupTrain:  epoch  0, batch  1426 | loss: 2.4510257
MixupTrain:  epoch  0, batch  1427 | loss: 2.1814666
MixupTrain:  epoch  0, batch  1428 | loss: 2.3885293
MixupTrain:  epoch  0, batch  1429 | loss: 2.1067998
MixupTrain:  epoch  0, batch  1430 | loss: 2.5210254
MixupTrain:  epoch  0, batch  1431 | loss: 1.9777373
MixupTrain:  epoch  0, batch  1432 | loss: 2.3361363
MixupTrain:  epoch  0, batch  1433 | loss: 2.1608276
MixupTrain:  epoch  0, batch  1434 | loss: 2.3697491
MixupTrain:  epoch  0, batch  1435 | loss: 1.9522367
MixupTrain:  epoch  0, batch  1436 | loss: 2.1998634
MixupTrain:  epoch  0, batch  1437 | loss: 2.2967510
MixupTrain:  epoch  0, batch  1438 | loss: 2.3468242
MixupTrain:  epoch  0, batch  1439 | loss: 2.0060570
MixupTrain:  epoch  0, batch  1440 | loss: 2.1554964
MixupTrain:  epoch  0, batch  1441 | loss: 2.3211823
MixupTrain:  epoch  0, batch  1442 | loss: 1.9488230
MixupTrain:  epoch  0, batch  1443 | loss: 2.2101784
MixupTrain:  epoch  0, batch  1444 | loss: 1.9277338
MixupTrain:  epoch  0, batch  1445 | loss: 2.5081892
MixupTrain:  epoch  0, batch  1446 | loss: 2.1092134
MixupTrain:  epoch  0, batch  1447 | loss: 2.2876024
MixupTrain:  epoch  0, batch  1448 | loss: 2.1474223
MixupTrain:  epoch  0, batch  1449 | loss: 2.1593292
MixupTrain:  epoch  0, batch  1450 | loss: 2.4433515
MixupTrain:  epoch  0, batch  1451 | loss: 2.4331157
MixupTrain:  epoch  0, batch  1452 | loss: 2.1213951
MixupTrain:  epoch  0, batch  1453 | loss: 1.9290886
MixupTrain:  epoch  0, batch  1454 | loss: 2.3763323
MixupTrain:  epoch  0, batch  1455 | loss: 2.2350187
MixupTrain:  epoch  0, batch  1456 | loss: 2.0033777
MixupTrain:  epoch  0, batch  1457 | loss: 2.2842059
MixupTrain:  epoch  0, batch  1458 | loss: 2.3267171
MixupTrain:  epoch  0, batch  1459 | loss: 2.2333331
MixupTrain:  epoch  0, batch  1460 | loss: 2.0973251
MixupTrain:  epoch  0, batch  1461 | loss: 2.2861161
MixupTrain:  epoch  0, batch  1462 | loss: 1.9643188
MixupTrain:  epoch  0, batch  1463 | loss: 2.0072470
MixupTrain:  epoch  0, batch  1464 | loss: 2.3362036
MixupTrain:  epoch  0, batch  1465 | loss: 1.9617447
MixupTrain:  epoch  0, batch  1466 | loss: 2.1694069
MixupTrain:  epoch  0, batch  1467 | loss: 2.2906213
MixupTrain:  epoch  0, batch  1468 | loss: 2.1236944
MixupTrain:  epoch  0, batch  1469 | loss: 2.5674508
MixupTrain:  epoch  0, batch  1470 | loss: 2.1136365
MixupTrain:  epoch  0, batch  1471 | loss: 2.3315310
MixupTrain:  epoch  0, batch  1472 | loss: 1.9623451
MixupTrain:  epoch  0, batch  1473 | loss: 2.0176649
MixupTrain:  epoch  0, batch  1474 | loss: 2.0448108
MixupTrain:  epoch  0, batch  1475 | loss: 1.9578412
MixupTrain:  epoch  0, batch  1476 | loss: 1.9915130
MixupTrain:  epoch  0, batch  1477 | loss: 1.9738969
MixupTrain:  epoch  0, batch  1478 | loss: 2.0061686
MixupTrain:  epoch  0, batch  1479 | loss: 2.2367935
MixupTrain:  epoch  0, batch  1480 | loss: 2.2276013
MixupTrain:  epoch  0, batch  1481 | loss: 2.1674175
MixupTrain:  epoch  0, batch  1482 | loss: 2.3768742
MixupTrain:  epoch  0, batch  1483 | loss: 2.0980773
MixupTrain:  epoch  0, batch  1484 | loss: 2.0416675
MixupTrain:  epoch  0, batch  1485 | loss: 1.9099309
MixupTrain:  epoch  0, batch  1486 | loss: 2.2324975
MixupTrain:  epoch  0, batch  1487 | loss: 2.3734109
MixupTrain:  epoch  0, batch  1488 | loss: 2.1025665
MixupTrain:  epoch  0, batch  1489 | loss: 2.1046376
MixupTrain:  epoch  0, batch  1490 | loss: 2.0762405
MixupTrain:  epoch  0, batch  1491 | loss: 1.9209764
MixupTrain:  epoch  0, batch  1492 | loss: 2.2307413
MixupTrain:  epoch  0, batch  1493 | loss: 2.3408527
MixupTrain:  epoch  0, batch  1494 | loss: 1.8491719
MixupTrain:  epoch  0, batch  1495 | loss: 2.2129014
MixupTrain:  epoch  0, batch  1496 | loss: 2.1816409
MixupTrain:  epoch  0, batch  1497 | loss: 2.4046273
MixupTrain:  epoch  0, batch  1498 | loss: 2.1265092
MixupTrain:  epoch  0, batch  1499 | loss: 2.3696527
MixupTrain:  epoch  0, batch  1500 | loss: 2.2992582
MixupTrain:  epoch  0, batch  1501 | loss: 2.1968176
MixupTrain:  epoch  0, batch  1502 | loss: 2.2561474
MixupTrain:  epoch  0, batch  1503 | loss: 2.1364269
MixupTrain:  epoch  0, batch  1504 | loss: 2.1583767
MixupTrain:  epoch  0, batch  1505 | loss: 2.0808272
MixupTrain:  epoch  0, batch  1506 | loss: 2.1838293
MixupTrain:  epoch  0, batch  1507 | loss: 2.3789966
MixupTrain:  epoch  0, batch  1508 | loss: 2.0884519
MixupTrain:  epoch  0, batch  1509 | loss: 2.4152820
MixupTrain:  epoch  0, batch  1510 | loss: 2.3054976
MixupTrain:  epoch  0, batch  1511 | loss: 1.9714253
MixupTrain:  epoch  0, batch  1512 | loss: 2.4943712
MixupTrain:  epoch  0, batch  1513 | loss: 2.2703962
MixupTrain:  epoch  0, batch  1514 | loss: 2.1879649
MixupTrain:  epoch  0, batch  1515 | loss: 2.0490723
MixupTrain:  epoch  0, batch  1516 | loss: 2.1183109
MixupTrain:  epoch  0, batch  1517 | loss: 2.2736168
MixupTrain:  epoch  0, batch  1518 | loss: 2.2248049
MixupTrain:  epoch  0, batch  1519 | loss: 2.3179336
MixupTrain:  epoch  0, batch  1520 | loss: 2.2246087
MixupTrain:  epoch  0, batch  1521 | loss: 2.2044845
MixupTrain:  epoch  0, batch  1522 | loss: 2.0466838
MixupTrain:  epoch  0, batch  1523 | loss: 1.9255338
MixupTrain:  epoch  0, batch  1524 | loss: 2.2711959
MixupTrain:  epoch  0, batch  1525 | loss: 2.0329225
MixupTrain:  epoch  0, batch  1526 | loss: 2.1374331
MixupTrain:  epoch  0, batch  1527 | loss: 1.9714835
MixupTrain:  epoch  0, batch  1528 | loss: 1.9051259
MixupTrain:  epoch  0, batch  1529 | loss: 2.3082526
MixupTrain:  epoch  0, batch  1530 | loss: 2.1044436
MixupTrain:  epoch  0, batch  1531 | loss: 2.1887631
MixupTrain:  epoch  0, batch  1532 | loss: 2.3175712
MixupTrain:  epoch  0, batch  1533 | loss: 2.2536287
MixupTrain:  epoch  0, batch  1534 | loss: 2.0071998
MixupTrain:  epoch  0, batch  1535 | loss: 2.3293519
MixupTrain:  epoch  0, batch  1536 | loss: 2.0746109
MixupTrain:  epoch  0, batch  1537 | loss: 2.1637111
MixupTrain:  epoch  0, batch  1538 | loss: 2.2203336
MixupTrain:  epoch  0, batch  1539 | loss: 1.8593374
MixupTrain:  epoch  0, batch  1540 | loss: 2.3606217
MixupTrain:  epoch  0, batch  1541 | loss: 1.9777815
MixupTrain:  epoch  0, batch  1542 | loss: 2.0886393
MixupTrain:  epoch  0, batch  1543 | loss: 2.1754375
MixupTrain:  epoch  0, batch  1544 | loss: 2.0547385
MixupTrain:  epoch  0, batch  1545 | loss: 2.0116639
MixupTrain:  epoch  0, batch  1546 | loss: 2.1818423
MixupTrain:  epoch  0, batch  1547 | loss: 2.1653407
MixupTrain:  epoch  0, batch  1548 | loss: 2.1925075
MixupTrain:  epoch  0, batch  1549 | loss: 2.0652328
MixupTrain:  epoch  0, batch  1550 | loss: 2.1593847
MixupTrain:  epoch  0, batch  1551 | loss: 2.2976162
MixupTrain:  epoch  0, batch  1552 | loss: 2.2422781
MixupTrain:  epoch  0, batch  1553 | loss: 2.2298896
MixupTrain:  epoch  0, batch  1554 | loss: 2.2591321
MixupTrain:  epoch  0, batch  1555 | loss: 1.8954471
MixupTrain:  epoch  0, batch  1556 | loss: 2.2792227
MixupTrain:  epoch  0, batch  1557 | loss: 2.3756199
MixupTrain:  epoch  0, batch  1558 | loss: 2.1392944
MixupTrain:  epoch  0, batch  1559 | loss: 2.2871280
MixupTrain:  epoch  0, batch  1560 | loss: 2.2452412
MixupTrain:  epoch  0, batch  1561 | loss: 2.2125025
MixupTrain:  epoch  0, batch  1562 | loss: 1.9505115
MixupTrain:  epoch  0, batch  1563 | loss: 1.8906171
MixupTrain:  epoch  0, batch  1564 | loss: 2.2125065
MixupTrain:  epoch  0, batch  1565 | loss: 2.4523063
MixupTrain:  epoch  0, batch  1566 | loss: 2.1538434
MixupTrain:  epoch  0, batch  1567 | loss: 2.1791720
MixupTrain:  epoch  0, batch  1568 | loss: 2.2833314
MixupTrain:  epoch  0, batch  1569 | loss: 2.1475394
MixupTrain:  epoch  0, batch  1570 | loss: 2.2023742
MixupTrain:  epoch  0, batch  1571 | loss: 2.3472176
MixupTrain:  epoch  0, batch  1572 | loss: 2.3751040
MixupTrain:  epoch  0, batch  1573 | loss: 2.0778108
MixupTrain:  epoch  0, batch  1574 | loss: 2.0151963
MixupTrain:  epoch  0, batch  1575 | loss: 2.2492051
MixupTrain:  epoch  0, batch  1576 | loss: 2.1232111
MixupTrain:  epoch  0, batch  1577 | loss: 2.2120433
MixupTrain:  epoch  0, batch  1578 | loss: 2.4453821
MixupTrain:  epoch  0, batch  1579 | loss: 2.3008435
MixupTrain:  epoch  0, batch  1580 | loss: 2.0084593
MixupTrain:  epoch  0, batch  1581 | loss: 2.3258381
MixupTrain:  epoch  0, batch  1582 | loss: 2.0426779
MixupTrain:  epoch  0, batch  1583 | loss: 2.5028126
MixupTrain:  epoch  0, batch  1584 | loss: 2.0021439
MixupTrain:  epoch  0, batch  1585 | loss: 2.1880536
MixupTrain:  epoch  0, batch  1586 | loss: 2.1455188
MixupTrain:  epoch  0, batch  1587 | loss: 2.2870665
MixupTrain:  epoch  0, batch  1588 | loss: 1.9178766
MixupTrain:  epoch  0, batch  1589 | loss: 2.3275433
MixupTrain:  epoch  0, batch  1590 | loss: 2.3646250
MixupTrain:  epoch  0, batch  1591 | loss: 2.1504688
MixupTrain:  epoch  0, batch  1592 | loss: 2.0887182
MixupTrain:  epoch  0, batch  1593 | loss: 2.0372219
MixupTrain:  epoch  0, batch  1594 | loss: 2.3526216
MixupTrain:  epoch  0, batch  1595 | loss: 2.3045578
MixupTrain:  epoch  0, batch  1596 | loss: 2.1083803
MixupTrain:  epoch  0, batch  1597 | loss: 2.3011222
MixupTrain:  epoch  0, batch  1598 | loss: 2.0915070
MixupTrain:  epoch  0, batch  1599 | loss: 2.4525807
MixupTrain:  epoch  0, batch  1600 | loss: 1.9723241
MixupTrain:  epoch  0, batch  1601 | loss: 1.9614596
MixupTrain:  epoch  0, batch  1602 | loss: 2.0284209
MixupTrain:  epoch  0, batch  1603 | loss: 2.1519694
MixupTrain:  epoch  0, batch  1604 | loss: 2.1955466
MixupTrain:  epoch  0, batch  1605 | loss: 1.9751718
MixupTrain:  epoch  0, batch  1606 | loss: 2.3821149
MixupTrain:  epoch  0, batch  1607 | loss: 2.1178000
MixupTrain:  epoch  0, batch  1608 | loss: 2.0966883
MixupTrain:  epoch  0, batch  1609 | loss: 2.0993233
MixupTrain:  epoch  0, batch  1610 | loss: 2.2347832
MixupTrain:  epoch  0, batch  1611 | loss: 2.3775840
MixupTrain:  epoch  0, batch  1612 | loss: 2.5391424
MixupTrain:  epoch  0, batch  1613 | loss: 2.0812020
MixupTrain:  epoch  0, batch  1614 | loss: 1.9307189
MixupTrain:  epoch  0, batch  1615 | loss: 2.0867443
MixupTrain:  epoch  0, batch  1616 | loss: 2.1686149
MixupTrain:  epoch  0, batch  1617 | loss: 2.2250624
MixupTrain:  epoch  0, batch  1618 | loss: 1.9944156
MixupTrain:  epoch  0, batch  1619 | loss: 2.0634723
MixupTrain:  epoch  0, batch  1620 | loss: 2.2312047
MixupTrain:  epoch  0, batch  1621 | loss: 2.0983744
MixupTrain:  epoch  0, batch  1622 | loss: 2.4584932
MixupTrain:  epoch  0, batch  1623 | loss: 2.1468625
MixupTrain:  epoch  0, batch  1624 | loss: 2.3086030
MixupTrain:  epoch  0, batch  1625 | loss: 1.9789047
MixupTrain:  epoch  0, batch  1626 | loss: 2.3112864
MixupTrain:  epoch  0, batch  1627 | loss: 2.2271934
MixupTrain:  epoch  0, batch  1628 | loss: 2.0366249
MixupTrain:  epoch  0, batch  1629 | loss: 2.1764996
MixupTrain:  epoch  0, batch  1630 | loss: 2.1579421
MixupTrain:  epoch  0, batch  1631 | loss: 2.3060887
MixupTrain:  epoch  0, batch  1632 | loss: 2.5633836
MixupTrain:  epoch  0, batch  1633 | loss: 1.9924793
MixupTrain:  epoch  0, batch  1634 | loss: 1.9715633
MixupTrain:  epoch  0, batch  1635 | loss: 1.9653834
MixupTrain:  epoch  0, batch  1636 | loss: 2.1586742
MixupTrain:  epoch  0, batch  1637 | loss: 2.2601585
MixupTrain:  epoch  0, batch  1638 | loss: 2.3275969
MixupTrain:  epoch  0, batch  1639 | loss: 2.3063431
MixupTrain:  epoch  0, batch  1640 | loss: 2.1952548
MixupTrain:  epoch  0, batch  1641 | loss: 2.2429104
MixupTrain:  epoch  0, batch  1642 | loss: 2.2464681
MixupTrain:  epoch  0, batch  1643 | loss: 2.0241575
MixupTrain:  epoch  0, batch  1644 | loss: 2.4108207
MixupTrain:  epoch  0, batch  1645 | loss: 1.9884633
MixupTrain:  epoch  0, batch  1646 | loss: 2.1267118
MixupTrain:  epoch  0, batch  1647 | loss: 2.2949483
MixupTrain:  epoch  0, batch  1648 | loss: 1.8925641
MixupTrain:  epoch  0, batch  1649 | loss: 2.2613547
MixupTrain:  epoch  0, batch  1650 | loss: 2.2338591
MixupTrain:  epoch  0, batch  1651 | loss: 2.4700799
MixupTrain:  epoch  0, batch  1652 | loss: 2.2016978
MixupTrain:  epoch  0, batch  1653 | loss: 2.0534155
MixupTrain:  epoch  0, batch  1654 | loss: 2.3459916
MixupTrain:  epoch  0, batch  1655 | loss: 2.2931991
MixupTrain:  epoch  0, batch  1656 | loss: 1.9102529
MixupTrain:  epoch  0, batch  1657 | loss: 2.0942376
MixupTrain:  epoch  0, batch  1658 | loss: 1.9405744
MixupTrain:  epoch  0, batch  1659 | loss: 2.4293411
MixupTrain:  epoch  0, batch  1660 | loss: 1.9881589
MixupTrain:  epoch  0, batch  1661 | loss: 2.0426724
MixupTrain:  epoch  0, batch  1662 | loss: 2.0050397
MixupTrain:  epoch  0, batch  1663 | loss: 2.1073546
MixupTrain:  epoch  0, batch  1664 | loss: 2.3041191
MixupTrain:  epoch  0, batch  1665 | loss: 1.9910991
MixupTrain:  epoch  0, batch  1666 | loss: 2.1597431
MixupTrain:  epoch  0, batch  1667 | loss: 2.1276603
MixupTrain:  epoch  0, batch  1668 | loss: 2.0091095
MixupTrain:  epoch  0, batch  1669 | loss: 2.4139366
MixupTrain:  epoch  0, batch  1670 | loss: 2.2055254
MixupTrain:  epoch  0, batch  1671 | loss: 2.5199385
MixupTrain:  epoch  0, batch  1672 | loss: 2.1411524
MixupTrain:  epoch  0, batch  1673 | loss: 2.2071147
MixupTrain:  epoch  0, batch  1674 | loss: 2.1418989
MixupTrain:  epoch  0, batch  1675 | loss: 2.1957655
MixupTrain:  epoch  0, batch  1676 | loss: 2.1056955
MixupTrain:  epoch  0, batch  1677 | loss: 2.3629105
MixupTrain:  epoch  0, batch  1678 | loss: 1.9778907
MixupTrain:  epoch  0, batch  1679 | loss: 2.1516752
MixupTrain:  epoch  0, batch  1680 | loss: 2.1956096
MixupTrain:  epoch  0, batch  1681 | loss: 2.2912884
MixupTrain:  epoch  0, batch  1682 | loss: 2.3582337
MixupTrain:  epoch  0, batch  1683 | loss: 2.2171645
MixupTrain:  epoch  0, batch  1684 | loss: 2.5740817
MixupTrain:  epoch  0, batch  1685 | loss: 2.2932920
MixupTrain:  epoch  0, batch  1686 | loss: 2.2470281
MixupTrain:  epoch  0, batch  1687 | loss: 2.2886131
MixupTrain:  epoch  0, batch  1688 | loss: 2.1808419
MixupTrain:  epoch  0, batch  1689 | loss: 2.1266387
MixupTrain:  epoch  0, batch  1690 | loss: 2.2703183
MixupTrain:  epoch  0, batch  1691 | loss: 2.2737763
MixupTrain:  epoch  0, batch  1692 | loss: 2.0137420
MixupTrain:  epoch  0, batch  1693 | loss: 2.2115970
MixupTrain:  epoch  0, batch  1694 | loss: 2.5385690
MixupTrain:  epoch  0, batch  1695 | loss: 2.1253309
MixupTrain:  epoch  0, batch  1696 | loss: 2.2005365
MixupTrain:  epoch  0, batch  1697 | loss: 2.3710151
MixupTrain:  epoch  0, batch  1698 | loss: 2.1497624
MixupTrain:  epoch  0, batch  1699 | loss: 2.3359849
MixupTrain:  epoch  0, batch  1700 | loss: 2.4074335
MixupTrain:  epoch  0, batch  1701 | loss: 2.0505855
MixupTrain:  epoch  0, batch  1702 | loss: 2.0342135
MixupTrain:  epoch  0, batch  1703 | loss: 2.0360610
MixupTrain:  epoch  0, batch  1704 | loss: 2.3494895
MixupTrain:  epoch  0, batch  1705 | loss: 2.1279495
MixupTrain:  epoch  0, batch  1706 | loss: 2.4864299
MixupTrain:  epoch  0, batch  1707 | loss: 2.0077264
MixupTrain:  epoch  0, batch  1708 | loss: 2.3805718
MixupTrain:  epoch  0, batch  1709 | loss: 2.1845384
MixupTrain:  epoch  0, batch  1710 | loss: 2.3513265
MixupTrain:  epoch  0, batch  1711 | loss: 2.1094456
MixupTrain:  epoch  0, batch  1712 | loss: 2.1365309
MixupTrain:  epoch  0, batch  1713 | loss: 2.1125588
MixupTrain:  epoch  0, batch  1714 | loss: 2.0577121
MixupTrain:  epoch  0, batch  1715 | loss: 2.3359437
MixupTrain:  epoch  0, batch  1716 | loss: 2.2031353
MixupTrain:  epoch  0, batch  1717 | loss: 2.1446249
MixupTrain:  epoch  0, batch  1718 | loss: 2.0986667
MixupTrain:  epoch  0, batch  1719 | loss: 2.2242956
MixupTrain:  epoch  0, batch  1720 | loss: 2.4444127
MixupTrain:  epoch  0, batch  1721 | loss: 2.0756717
MixupTrain:  epoch  0, batch  1722 | loss: 2.3526082
MixupTrain:  epoch  0, batch  1723 | loss: 2.1912451
MixupTrain:  epoch  0, batch  1724 | loss: 2.1934223
MixupTrain:  epoch  0, batch  1725 | loss: 2.1255376
MixupTrain:  epoch  0, batch  1726 | loss: 2.1904321
MixupTrain:  epoch  0, batch  1727 | loss: 2.1615958
MixupTrain:  epoch  0, batch  1728 | loss: 2.1126375
MixupTrain:  epoch  0, batch  1729 | loss: 2.2889414
MixupTrain:  epoch  0, batch  1730 | loss: 2.3724079
MixupTrain:  epoch  0, batch  1731 | loss: 1.8756979
MixupTrain:  epoch  0, batch  1732 | loss: 2.4757500
MixupTrain:  epoch  0, batch  1733 | loss: 2.6654792
MixupTrain:  epoch  0, batch  1734 | loss: 2.3189402
MixupTrain:  epoch  0, batch  1735 | loss: 2.3597224
MixupTrain:  epoch  0, batch  1736 | loss: 2.0618405
MixupTrain:  epoch  0, batch  1737 | loss: 2.1343076
MixupTrain:  epoch  0, batch  1738 | loss: 2.1363723
MixupTrain:  epoch  0, batch  1739 | loss: 2.1880574
MixupTrain:  epoch  0, batch  1740 | loss: 2.0586462
MixupTrain:  epoch  0, batch  1741 | loss: 2.0836897
MixupTrain:  epoch  0, batch  1742 | loss: 2.2986097
MixupTrain:  epoch  0, batch  1743 | loss: 2.3634086
MixupTrain:  epoch  0, batch  1744 | loss: 2.0613225
MixupTrain:  epoch  0, batch  1745 | loss: 2.1786499
MixupTrain:  epoch  0, batch  1746 | loss: 2.2152815
MixupTrain:  epoch  0, batch  1747 | loss: 2.1330202
MixupTrain:  epoch  0, batch  1748 | loss: 2.1298280
MixupTrain:  epoch  0, batch  1749 | loss: 2.0752583
MixupTrain:  epoch  0, batch  1750 | loss: 2.1069586
MixupTrain:  epoch  0, batch  1751 | loss: 2.6518297
MixupTrain:  epoch  0, batch  1752 | loss: 2.1649628
MixupTrain:  epoch  0, batch  1753 | loss: 2.3364196
MixupTrain:  epoch  0, batch  1754 | loss: 2.1274190
MixupTrain:  epoch  0, batch  1755 | loss: 2.1884060
MixupTrain:  epoch  0, batch  1756 | loss: 1.9831474
MixupTrain:  epoch  0, batch  1757 | loss: 2.3247280
MixupTrain:  epoch  0, batch  1758 | loss: 2.2620051
MixupTrain:  epoch  0, batch  1759 | loss: 2.1182086
MixupTrain:  epoch  0, batch  1760 | loss: 2.5027003
MixupTrain:  epoch  0, batch  1761 | loss: 2.5725975
MemoryTrain:  epoch  0, batch     0 | loss: 1.9830716
MemoryTrain:  epoch  0, batch     1 | loss: 2.5074000
MemoryTrain:  epoch  0, batch     2 | loss: 2.6229732
MemoryTrain:  epoch  0, batch     3 | loss: 2.4805939
MemoryTrain:  epoch  0, batch     4 | loss: 2.4753413
MemoryTrain:  epoch  0, batch     5 | loss: 2.3072388
MemoryTrain:  epoch  0, batch     6 | loss: 2.4794452
MemoryTrain:  epoch  0, batch     7 | loss: 2.2996578
MemoryTrain:  epoch  0, batch     8 | loss: 2.4911895
MemoryTrain:  epoch  0, batch     9 | loss: 1.9457581
MemoryTrain:  epoch  0, batch    10 | loss: 1.9916000
MemoryTrain:  epoch  0, batch    11 | loss: 2.1011348
MemoryTrain:  epoch  0, batch    12 | loss: 1.9266143
MemoryTrain:  epoch  0, batch    13 | loss: 1.9099309
MemoryTrain:  epoch  1, batch     0 | loss: 1.8196549
MemoryTrain:  epoch  1, batch     1 | loss: 1.8172629
MemoryTrain:  epoch  1, batch     2 | loss: 2.4227688
MemoryTrain:  epoch  1, batch     3 | loss: 1.9426942
MemoryTrain:  epoch  1, batch     4 | loss: 1.8457541
MemoryTrain:  epoch  1, batch     5 | loss: 1.8308300
MemoryTrain:  epoch  1, batch     6 | loss: 1.8422606
MemoryTrain:  epoch  1, batch     7 | loss: 1.8257780
MemoryTrain:  epoch  1, batch     8 | loss: 1.8575077
MemoryTrain:  epoch  1, batch     9 | loss: 1.8579953
MemoryTrain:  epoch  1, batch    10 | loss: 1.8705218
MemoryTrain:  epoch  1, batch    11 | loss: 1.8263624
MemoryTrain:  epoch  1, batch    12 | loss: 1.9009671
MemoryTrain:  epoch  1, batch    13 | loss: 1.8138794
MemoryTrain:  epoch  2, batch     0 | loss: 1.8656553
MemoryTrain:  epoch  2, batch     1 | loss: 1.8136573
MemoryTrain:  epoch  2, batch     2 | loss: 1.8065928
MemoryTrain:  epoch  2, batch     3 | loss: 1.8442405
MemoryTrain:  epoch  2, batch     4 | loss: 1.8111405
MemoryTrain:  epoch  2, batch     5 | loss: 1.8505759
MemoryTrain:  epoch  2, batch     6 | loss: 1.8334755
MemoryTrain:  epoch  2, batch     7 | loss: 1.8787031
MemoryTrain:  epoch  2, batch     8 | loss: 1.8059539
MemoryTrain:  epoch  2, batch     9 | loss: 1.9385343
MemoryTrain:  epoch  2, batch    10 | loss: 1.8079616
MemoryTrain:  epoch  2, batch    11 | loss: 1.8069055
MemoryTrain:  epoch  2, batch    12 | loss: 1.8147538
MemoryTrain:  epoch  2, batch    13 | loss: 1.8100481
MemoryTrain:  epoch  3, batch     0 | loss: 1.8099798
MemoryTrain:  epoch  3, batch     1 | loss: 1.8088789
MemoryTrain:  epoch  3, batch     2 | loss: 1.8092606
MemoryTrain:  epoch  3, batch     3 | loss: 1.8135672
MemoryTrain:  epoch  3, batch     4 | loss: 1.8092761
MemoryTrain:  epoch  3, batch     5 | loss: 1.8203275
MemoryTrain:  epoch  3, batch     6 | loss: 1.8103392
MemoryTrain:  epoch  3, batch     7 | loss: 1.8229873
MemoryTrain:  epoch  3, batch     8 | loss: 1.8071426
MemoryTrain:  epoch  3, batch     9 | loss: 1.8046453
MemoryTrain:  epoch  3, batch    10 | loss: 1.8055844
MemoryTrain:  epoch  3, batch    11 | loss: 1.8134654
MemoryTrain:  epoch  3, batch    12 | loss: 1.8068850
MemoryTrain:  epoch  3, batch    13 | loss: 1.8086479
MemoryTrain:  epoch  4, batch     0 | loss: 1.8067081
MemoryTrain:  epoch  4, batch     1 | loss: 1.8079178
MemoryTrain:  epoch  4, batch     2 | loss: 1.8251199
MemoryTrain:  epoch  4, batch     3 | loss: 1.8068004
MemoryTrain:  epoch  4, batch     4 | loss: 1.8119971
MemoryTrain:  epoch  4, batch     5 | loss: 1.8119533
MemoryTrain:  epoch  4, batch     6 | loss: 1.8083512
MemoryTrain:  epoch  4, batch     7 | loss: 1.8100247
MemoryTrain:  epoch  4, batch     8 | loss: 1.8212950
MemoryTrain:  epoch  4, batch     9 | loss: 1.8134367
MemoryTrain:  epoch  4, batch    10 | loss: 1.8206408
MemoryTrain:  epoch  4, batch    11 | loss: 1.8152292
MemoryTrain:  epoch  4, batch    12 | loss: 1.8116134
MemoryTrain:  epoch  4, batch    13 | loss: 1.8138838
MemoryTrain:  epoch  5, batch     0 | loss: 1.8095239
MemoryTrain:  epoch  5, batch     1 | loss: 1.8142599
MemoryTrain:  epoch  5, batch     2 | loss: 1.8111107
MemoryTrain:  epoch  5, batch     3 | loss: 1.8080148
MemoryTrain:  epoch  5, batch     4 | loss: 1.8114470
MemoryTrain:  epoch  5, batch     5 | loss: 1.8124553
MemoryTrain:  epoch  5, batch     6 | loss: 1.8084369
MemoryTrain:  epoch  5, batch     7 | loss: 1.8088659
MemoryTrain:  epoch  5, batch     8 | loss: 1.8118744
MemoryTrain:  epoch  5, batch     9 | loss: 1.8087115
MemoryTrain:  epoch  5, batch    10 | loss: 1.8080385
MemoryTrain:  epoch  5, batch    11 | loss: 1.8085093
MemoryTrain:  epoch  5, batch    12 | loss: 1.8074511
MemoryTrain:  epoch  5, batch    13 | loss: 1.8080791
MemoryTrain:  epoch  6, batch     0 | loss: 1.8099320
MemoryTrain:  epoch  6, batch     1 | loss: 1.8069348
MemoryTrain:  epoch  6, batch     2 | loss: 1.8045597
MemoryTrain:  epoch  6, batch     3 | loss: 1.8081675
MemoryTrain:  epoch  6, batch     4 | loss: 1.8161490
MemoryTrain:  epoch  6, batch     5 | loss: 1.8073819
MemoryTrain:  epoch  6, batch     6 | loss: 1.8091395
MemoryTrain:  epoch  6, batch     7 | loss: 1.8141638
MemoryTrain:  epoch  6, batch     8 | loss: 1.8099087
MemoryTrain:  epoch  6, batch     9 | loss: 1.8085971
MemoryTrain:  epoch  6, batch    10 | loss: 1.8125744
MemoryTrain:  epoch  6, batch    11 | loss: 1.8121247
MemoryTrain:  epoch  6, batch    12 | loss: 1.8114641
MemoryTrain:  epoch  6, batch    13 | loss: 1.8172430
MemoryTrain:  epoch  7, batch     0 | loss: 1.8113396
MemoryTrain:  epoch  7, batch     1 | loss: 1.8082489
MemoryTrain:  epoch  7, batch     2 | loss: 1.8137631
MemoryTrain:  epoch  7, batch     3 | loss: 1.8182486
MemoryTrain:  epoch  7, batch     4 | loss: 1.8123868
MemoryTrain:  epoch  7, batch     5 | loss: 1.8129873
MemoryTrain:  epoch  7, batch     6 | loss: 1.8180473
MemoryTrain:  epoch  7, batch     7 | loss: 1.8082261
MemoryTrain:  epoch  7, batch     8 | loss: 1.8088608
MemoryTrain:  epoch  7, batch     9 | loss: 1.8055741
MemoryTrain:  epoch  7, batch    10 | loss: 1.8084769
MemoryTrain:  epoch  7, batch    11 | loss: 1.8065938
MemoryTrain:  epoch  7, batch    12 | loss: 1.8139821
MemoryTrain:  epoch  7, batch    13 | loss: 1.8187675
MemoryTrain:  epoch  8, batch     0 | loss: 1.8083109
MemoryTrain:  epoch  8, batch     1 | loss: 1.8113978
MemoryTrain:  epoch  8, batch     2 | loss: 1.8090698
MemoryTrain:  epoch  8, batch     3 | loss: 1.8100319
MemoryTrain:  epoch  8, batch     4 | loss: 1.8119478
MemoryTrain:  epoch  8, batch     5 | loss: 1.8126923
MemoryTrain:  epoch  8, batch     6 | loss: 1.8079691
MemoryTrain:  epoch  8, batch     7 | loss: 1.8051671
MemoryTrain:  epoch  8, batch     8 | loss: 1.8078265
MemoryTrain:  epoch  8, batch     9 | loss: 1.8115089
MemoryTrain:  epoch  8, batch    10 | loss: 1.8023164
MemoryTrain:  epoch  8, batch    11 | loss: 1.8072947
MemoryTrain:  epoch  8, batch    12 | loss: 1.8069539
MemoryTrain:  epoch  8, batch    13 | loss: 1.8083581
MemoryTrain:  epoch  9, batch     0 | loss: 1.8054821
MemoryTrain:  epoch  9, batch     1 | loss: 1.8083477
MemoryTrain:  epoch  9, batch     2 | loss: 1.8097788
MemoryTrain:  epoch  9, batch     3 | loss: 1.8090074
MemoryTrain:  epoch  9, batch     4 | loss: 1.8061115
MemoryTrain:  epoch  9, batch     5 | loss: 1.8085785
MemoryTrain:  epoch  9, batch     6 | loss: 1.8089929
MemoryTrain:  epoch  9, batch     7 | loss: 1.8038191
MemoryTrain:  epoch  9, batch     8 | loss: 1.8083785
MemoryTrain:  epoch  9, batch     9 | loss: 1.8091661
MemoryTrain:  epoch  9, batch    10 | loss: 1.8062520
MemoryTrain:  epoch  9, batch    11 | loss: 1.8069944
MemoryTrain:  epoch  9, batch    12 | loss: 1.8100634
MemoryTrain:  epoch  9, batch    13 | loss: 1.8055272
[EVAL] batch:    0 | acc: 87.50%,  total acc: 87.50%   
[EVAL] batch:    1 | acc: 81.25%,  total acc: 84.38%   
[EVAL] batch:    2 | acc: 81.25%,  total acc: 83.33%   
[EVAL] batch:    3 | acc: 93.75%,  total acc: 85.94%   
[EVAL] batch:    4 | acc: 100.00%,  total acc: 88.75%   
[EVAL] batch:    5 | acc: 93.75%,  total acc: 89.58%   
[EVAL] batch:    6 | acc: 93.75%,  total acc: 90.18%   
[EVAL] batch:    7 | acc: 93.75%,  total acc: 90.62%   
[EVAL] batch:    8 | acc: 81.25%,  total acc: 89.58%   
[EVAL] batch:    9 | acc: 81.25%,  total acc: 88.75%   
[EVAL] batch:   10 | acc: 75.00%,  total acc: 87.50%   
[EVAL] batch:   11 | acc: 81.25%,  total acc: 86.98%   
[EVAL] batch:   12 | acc: 75.00%,  total acc: 86.06%   
[EVAL] batch:   13 | acc: 93.75%,  total acc: 86.61%   
[EVAL] batch:   14 | acc: 31.25%,  total acc: 82.92%   
[EVAL] batch:    0 | acc: 18.75%,  total acc: 18.75%   
[EVAL] batch:    1 | acc: 18.75%,  total acc: 18.75%   
[EVAL] batch:    2 | acc: 18.75%,  total acc: 18.75%   
[EVAL] batch:    3 | acc: 12.50%,  total acc: 17.19%   
[EVAL] batch:    4 | acc: 18.75%,  total acc: 17.50%   
[EVAL] batch:    5 | acc: 37.50%,  total acc: 20.83%   
[EVAL] batch:    6 | acc: 37.50%,  total acc: 23.21%   
[EVAL] batch:    7 | acc: 25.00%,  total acc: 23.44%   
[EVAL] batch:    8 | acc: 31.25%,  total acc: 24.31%   
[EVAL] batch:    9 | acc: 31.25%,  total acc: 25.00%   
[EVAL] batch:   10 | acc: 37.50%,  total acc: 26.14%   
[EVAL] batch:   11 | acc: 37.50%,  total acc: 27.08%   
[EVAL] batch:   12 | acc: 6.25%,  total acc: 25.48%   
[EVAL] batch:   13 | acc: 25.00%,  total acc: 25.45%   
[EVAL] batch:   14 | acc: 43.75%,  total acc: 26.67%   
[EVAL] batch:   15 | acc: 50.00%,  total acc: 28.12%   
[EVAL] batch:   16 | acc: 68.75%,  total acc: 30.51%   
[EVAL] batch:   17 | acc: 56.25%,  total acc: 31.94%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 33.55%   
[EVAL] batch:   19 | acc: 56.25%,  total acc: 34.69%   
[EVAL] batch:   20 | acc: 62.50%,  total acc: 36.01%   
[EVAL] batch:   21 | acc: 50.00%,  total acc: 36.65%   
[EVAL] batch:   22 | acc: 50.00%,  total acc: 37.23%   
[EVAL] batch:   23 | acc: 81.25%,  total acc: 39.06%   
[EVAL] batch:   24 | acc: 87.50%,  total acc: 41.00%   
[EVAL] batch:   25 | acc: 75.00%,  total acc: 42.31%   
[EVAL] batch:   26 | acc: 62.50%,  total acc: 43.06%   
[EVAL] batch:   27 | acc: 62.50%,  total acc: 43.75%   
[EVAL] batch:   28 | acc: 62.50%,  total acc: 44.40%   
[EVAL] batch:   29 | acc: 62.50%,  total acc: 45.00%   
[EVAL] batch:   30 | acc: 68.75%,  total acc: 45.77%   
[EVAL] batch:   31 | acc: 43.75%,  total acc: 45.70%   
[EVAL] batch:   32 | acc: 87.50%,  total acc: 46.97%   
[EVAL] batch:   33 | acc: 12.50%,  total acc: 45.96%   
[EVAL] batch:   34 | acc: 0.00%,  total acc: 44.64%   
[EVAL] batch:   35 | acc: 0.00%,  total acc: 43.40%   
[EVAL] batch:   36 | acc: 0.00%,  total acc: 42.23%   
[EVAL] batch:   37 | acc: 6.25%,  total acc: 41.28%   
[EVAL] batch:   38 | acc: 6.25%,  total acc: 40.38%   
[EVAL] batch:   39 | acc: 68.75%,  total acc: 41.09%   
[EVAL] batch:   40 | acc: 87.50%,  total acc: 42.23%   
[EVAL] batch:   41 | acc: 75.00%,  total acc: 43.01%   
[EVAL] batch:   42 | acc: 87.50%,  total acc: 44.04%   
[EVAL] batch:   43 | acc: 68.75%,  total acc: 44.60%   
[EVAL] batch:   44 | acc: 68.75%,  total acc: 45.14%   
[EVAL] batch:   45 | acc: 18.75%,  total acc: 44.57%   
[EVAL] batch:   46 | acc: 31.25%,  total acc: 44.28%   
[EVAL] batch:   47 | acc: 68.75%,  total acc: 44.79%   
[EVAL] batch:   48 | acc: 25.00%,  total acc: 44.39%   
[EVAL] batch:   49 | acc: 81.25%,  total acc: 45.12%   
[EVAL] batch:   50 | acc: 56.25%,  total acc: 45.34%   
[EVAL] batch:   51 | acc: 62.50%,  total acc: 45.67%   
[EVAL] batch:   52 | acc: 62.50%,  total acc: 45.99%   
[EVAL] batch:   53 | acc: 93.75%,  total acc: 46.88%   
[EVAL] batch:   54 | acc: 87.50%,  total acc: 47.61%   
[EVAL] batch:   55 | acc: 93.75%,  total acc: 48.44%   
[EVAL] batch:   56 | acc: 87.50%,  total acc: 49.12%   
[EVAL] batch:   57 | acc: 68.75%,  total acc: 49.46%   
[EVAL] batch:   58 | acc: 87.50%,  total acc: 50.11%   
[EVAL] batch:   59 | acc: 81.25%,  total acc: 50.62%   
[EVAL] batch:   60 | acc: 18.75%,  total acc: 50.10%   
[EVAL] batch:   61 | acc: 6.25%,  total acc: 49.40%   
[EVAL] batch:   62 | acc: 6.25%,  total acc: 48.71%   
[EVAL] batch:   63 | acc: 0.00%,  total acc: 47.95%   
[EVAL] batch:   64 | acc: 56.25%,  total acc: 48.08%   
[EVAL] batch:   65 | acc: 56.25%,  total acc: 48.20%   
[EVAL] batch:   66 | acc: 0.00%,  total acc: 47.48%   
[EVAL] batch:   67 | acc: 12.50%,  total acc: 46.97%   
[EVAL] batch:   68 | acc: 12.50%,  total acc: 46.47%   
[EVAL] batch:   69 | acc: 6.25%,  total acc: 45.89%   
[EVAL] batch:   70 | acc: 25.00%,  total acc: 45.60%   
[EVAL] batch:   71 | acc: 25.00%,  total acc: 45.31%   
[EVAL] batch:   72 | acc: 25.00%,  total acc: 45.03%   
[EVAL] batch:   73 | acc: 0.00%,  total acc: 44.43%   
[EVAL] batch:   74 | acc: 0.00%,  total acc: 43.83%   
[EVAL] batch:   75 | acc: 0.00%,  total acc: 43.26%   
[EVAL] batch:   76 | acc: 0.00%,  total acc: 42.69%   
[EVAL] batch:   77 | acc: 0.00%,  total acc: 42.15%   
[EVAL] batch:   78 | acc: 31.25%,  total acc: 42.01%   
[EVAL] batch:   79 | acc: 100.00%,  total acc: 42.73%   
[EVAL] batch:   80 | acc: 100.00%,  total acc: 43.44%   
[EVAL] batch:   81 | acc: 100.00%,  total acc: 44.13%   
[EVAL] batch:   82 | acc: 87.50%,  total acc: 44.65%   
[EVAL] batch:   83 | acc: 68.75%,  total acc: 44.94%   
[EVAL] batch:   84 | acc: 12.50%,  total acc: 44.56%   
[EVAL] batch:   85 | acc: 12.50%,  total acc: 44.19%   
[EVAL] batch:   86 | acc: 18.75%,  total acc: 43.89%   
[EVAL] batch:   87 | acc: 93.75%,  total acc: 44.46%   
[EVAL] batch:   88 | acc: 87.50%,  total acc: 44.94%   
[EVAL] batch:   89 | acc: 93.75%,  total acc: 45.49%   
[EVAL] batch:   90 | acc: 100.00%,  total acc: 46.09%   
[EVAL] batch:   91 | acc: 100.00%,  total acc: 46.67%   
[EVAL] batch:   92 | acc: 100.00%,  total acc: 47.24%   
[EVAL] batch:   93 | acc: 100.00%,  total acc: 47.81%   
[EVAL] batch:   94 | acc: 100.00%,  total acc: 48.36%   
[EVAL] batch:   95 | acc: 81.25%,  total acc: 48.70%   
[EVAL] batch:   96 | acc: 43.75%,  total acc: 48.65%   
[EVAL] batch:   97 | acc: 68.75%,  total acc: 48.85%   
[EVAL] batch:   98 | acc: 87.50%,  total acc: 49.24%   
[EVAL] batch:   99 | acc: 100.00%,  total acc: 49.75%   
[EVAL] batch:  100 | acc: 100.00%,  total acc: 50.25%   
[EVAL] batch:  101 | acc: 81.25%,  total acc: 50.55%   
[EVAL] batch:  102 | acc: 87.50%,  total acc: 50.91%   
[EVAL] batch:  103 | acc: 81.25%,  total acc: 51.20%   
[EVAL] batch:  104 | acc: 93.75%,  total acc: 51.61%   
[EVAL] batch:  105 | acc: 100.00%,  total acc: 52.06%   
[EVAL] batch:  106 | acc: 93.75%,  total acc: 52.45%   
[EVAL] batch:  107 | acc: 93.75%,  total acc: 52.84%   
[EVAL] batch:  108 | acc: 93.75%,  total acc: 53.21%   
[EVAL] batch:  109 | acc: 81.25%,  total acc: 53.47%   
[EVAL] batch:  110 | acc: 81.25%,  total acc: 53.72%   
[EVAL] batch:  111 | acc: 75.00%,  total acc: 53.91%   
[EVAL] batch:  112 | acc: 81.25%,  total acc: 54.15%   
[EVAL] batch:  113 | acc: 75.00%,  total acc: 54.33%   
[EVAL] batch:  114 | acc: 93.75%,  total acc: 54.67%   
[EVAL] batch:  115 | acc: 25.00%,  total acc: 54.42%   
cur_acc:  ['0.8712', '0.8705', '0.7266', '0.8990', '0.5739', '0.9062', '0.8292']
his_acc:  ['0.8712', '0.8564', '0.6238', '0.6241', '0.5469', '0.5600', '0.5442']
CurrentTrain: epoch  0, batch     0 | loss: 6.4814796
CurrentTrain: epoch  0, batch     1 | loss: 5.1768503
CurrentTrain: epoch  1, batch     0 | loss: 5.2880926
CurrentTrain: epoch  1, batch     1 | loss: 5.9988022
CurrentTrain: epoch  2, batch     0 | loss: 4.9259987
CurrentTrain: epoch  2, batch     1 | loss: 4.2863655
CurrentTrain: epoch  3, batch     0 | loss: 3.7887733
CurrentTrain: epoch  3, batch     1 | loss: 3.3217630
CurrentTrain: epoch  4, batch     0 | loss: 3.4953060
CurrentTrain: epoch  4, batch     1 | loss: 2.9375644
CurrentTrain: epoch  5, batch     0 | loss: 3.0210347
CurrentTrain: epoch  5, batch     1 | loss: 3.0954978
CurrentTrain: epoch  6, batch     0 | loss: 3.0171213
CurrentTrain: epoch  6, batch     1 | loss: 2.2145042
CurrentTrain: epoch  7, batch     0 | loss: 3.0301037
CurrentTrain: epoch  7, batch     1 | loss: 2.3175821
CurrentTrain: epoch  8, batch     0 | loss: 2.8889961
CurrentTrain: epoch  8, batch     1 | loss: 1.9431792
CurrentTrain: epoch  9, batch     0 | loss: 2.6498616
CurrentTrain: epoch  9, batch     1 | loss: 2.0703042
#### person cities of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person cities of residence" means a person is living in a city.
Here is an example:
Relation: person cities of residence
Context: in 1974 , divorced and the mother of a 5-year-old , forsberg moved to boston and began studying arms control at mit ; she received her ph.d. in 1980 .
Head Entity: forsberg
Tail Entity: boston
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person cities of residence":
Relation: person cities of residence  
Context: After years of living in New York, she decided to relocate to San Francisco to pursue her career in tech.  
Head Entity: she  
Tail Entity: San Francisco  

Relation: person cities of residence  
Context: Following his retirement, John moved from Chicago to Miami, where he enjoys the warm weather and beaches.  
Head Entity: John  
Tail Entity: Miami  

Relation: person cities of residence  
Context: The famous author spent most of her life in Paris, drawing inspiration from the city's vibrant culture and history.  
Head Entity: The famous author  
Tail Entity: Paris  

Relation: person cities of residence  
Context: After graduating from college, Mark settled in Seattle, where he found a job in the aerospace industry.  
Head Entity: Mark  
Tail Entity: Seattle  

Relation: person cities of residence  
Context: She was born in Los Angeles but later moved to Austin, where she became involved in the local music scene.  
Head Entity: She  
Tail Entity: Austin  
#### person schools attended ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person schools attended" means a person 's school is an organization.
Here is an example:
Relation: person schools attended
Context: born in baltimore in 1922 , parren mitchell was a graduate of morgan state college and earned a master 's degree from the university of maryland , according to biographical information supplied by cummings ' office .
Head Entity: parren mitchell
Tail Entity: university of maryland
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person schools attended":
Relation: person schools attended  
Context: After completing high school, Sarah Johnson went on to study at Stanford University, where she earned her degree in computer science.  
Head Entity: Sarah Johnson  
Tail Entity: Stanford University  

Relation: person schools attended  
Context: Mark Thompson, a renowned physicist, received his education at the Massachusetts Institute of Technology, where he developed a passion for quantum mechanics.  
Head Entity: Mark Thompson  
Tail Entity: Massachusetts Institute of Technology  

Relation: person schools attended  
Context: Growing up in a small town, Emily Davis attended the University of California, Berkeley, which greatly influenced her career in environmental science.  
Head Entity: Emily Davis  
Tail Entity: University of California, Berkeley  

Relation: person schools attended  
Context: James Lee graduated from Harvard Law School, where he was recognized for his outstanding contributions to legal research and advocacy.  
Head Entity: James Lee  
Tail Entity: Harvard Law School  

Relation: person schools attended  
Context: After moving to New York, Rachel Green enrolled at the Fashion Institute of Technology, where she honed her skills in fashion design.  
Head Entity: Rachel Green  
Tail Entity: Fashion Institute of Technology  
#### person country of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person country of death" means a person was died in a country.
Here is an example:
Relation: person country of death
Context: us republican congresswoman jo ann davis dies after fight with breast cancer
Head Entity: jo ann davis
Tail Entity: us
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person country of death":
Relation: person country of death  
Context: renowned physicist stephen hawking passed away in cambridge, england  
Head Entity: stephen hawking  
Tail Entity: england  

Relation: person country of death  
Context: famous author agatha christie died in her home in wallingford, england  
Head Entity: agatha christie  
Tail Entity: england  

Relation: person country of death  
Context: legendary musician freddie mercury succumbed to aids in london, united kingdom  
Head Entity: freddie mercury  
Tail Entity: united kingdom  

Relation: person country of death  
Context: beloved actor robin williams was found dead in his home in california, usa  
Head Entity: robin williams  
Tail Entity: usa  

Relation: person country of death  
Context: influential civil rights leader martin luther king jr. was assassinated in memphis, tennessee, usa  
Head Entity: martin luther king jr.  
Tail Entity: usa  
#### person children ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person children" means a person 's children is a person.
Here is an example:
Relation: person children
Context: he is survived by his wife of 63 years , josephine robinson mcnair , of columbia ; a son , robert e. jr. , of columbia ; three daughters , robin lee howell and corinne godshall , of myrtle beach , s.c. , and claudia crawford mcnair , of jamestown , s.c. ; six grandchildren ; and one great-grandchild .
Head Entity: he
Tail Entity: claudia crawford mcnair
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person children":
Relation: person children  
Context: After the passing of her husband, she dedicated her life to raising their three children, ensuring they had a bright future ahead. Her eldest son, Michael, now works as a doctor, while her daughters, Sarah and Emily, are both pursuing careers in education.  
Head Entity: she  
Tail Entity: Sarah  

Relation: person children  
Context: The famous actor often shares stories about his childhood and the lessons he learned from his parents, especially about the importance of family. His daughter, Lily, has already started her own acting career, following in his footsteps.  
Head Entity: he  
Tail Entity: Lily  

Relation: person children  
Context: During the family reunion, he proudly introduced his grandchildren to everyone, highlighting their achievements in school and sports. His youngest grandchild, Jake, is particularly talented in soccer and dreams of playing professionally one day.  
Head Entity: he  
Tail Entity: Jake  

Relation: person children  
Context: As a single mother, she worked tirelessly to provide for her two children, often sacrificing her own needs for their well-being. Her son, Alex, recently graduated from college, while her daughter, Mia, is still in high school.  
Head Entity: she  
Tail Entity: Mia  

Relation: person children  
Context: The renowned scientist often credits his parents for instilling a love of learning in him and his siblings. His brother, Tom, is also a scientist, while his sister, Anna, has taken a different path and is now a successful artist.  
Head Entity: he  
Tail Entity: Anna  
#### person charges ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person charges" means a person was charged with an event.
Here is an example:
Relation: person charges
Context: flowers always contended politics was behind the extortion investigation , but appeals courts ruled against him .
Head Entity: him
Tail Entity: extortion
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person charges":
Relation: person charges  
Context: The prosecutor announced that the former mayor was facing serious allegations related to corruption.  
Head Entity: former mayor  
Tail Entity: corruption  

Relation: person charges  
Context: After a lengthy investigation, the authorities confirmed that the celebrity was implicated in a major fraud scheme.  
Head Entity: celebrity  
Tail Entity: fraud scheme  

Relation: person charges  
Context: The police reported that the activist was charged with inciting violence during the protest last week.  
Head Entity: activist  
Tail Entity: violence  

Relation: person charges  
Context: Following the scandal, the businessman was officially charged with embezzlement and money laundering.  
Head Entity: businessman  
Tail Entity: embezzlement  

Relation: person charges  
Context: The court documents revealed that the teacher was charged with inappropriate conduct involving a student.  
Head Entity: teacher  
Tail Entity: inappropriate conduct  
Mixup data size:  35770
MixupTrain:  epoch  0, batch     0 | loss: 3.8469076
MixupTrain:  epoch  0, batch     1 | loss: 3.2914987
MixupTrain:  epoch  0, batch     2 | loss: 3.4354646
MixupTrain:  epoch  0, batch     3 | loss: 3.2295330
MixupTrain:  epoch  0, batch     4 | loss: 4.5712662
MixupTrain:  epoch  0, batch     5 | loss: 4.0639863
MixupTrain:  epoch  0, batch     6 | loss: 4.1629128
MixupTrain:  epoch  0, batch     7 | loss: 3.9515057
MixupTrain:  epoch  0, batch     8 | loss: 3.3539333
MixupTrain:  epoch  0, batch     9 | loss: 4.2609744
MixupTrain:  epoch  0, batch    10 | loss: 3.7148466
MixupTrain:  epoch  0, batch    11 | loss: 3.3517959
MixupTrain:  epoch  0, batch    12 | loss: 3.2805605
MixupTrain:  epoch  0, batch    13 | loss: 3.5629754
MixupTrain:  epoch  0, batch    14 | loss: 3.5890238
MixupTrain:  epoch  0, batch    15 | loss: 3.4542286
MixupTrain:  epoch  0, batch    16 | loss: 3.2910941
MixupTrain:  epoch  0, batch    17 | loss: 4.4106126
MixupTrain:  epoch  0, batch    18 | loss: 3.4454982
MixupTrain:  epoch  0, batch    19 | loss: 3.8444140
MixupTrain:  epoch  0, batch    20 | loss: 3.9262853
MixupTrain:  epoch  0, batch    21 | loss: 2.6571376
MixupTrain:  epoch  0, batch    22 | loss: 4.0668273
MixupTrain:  epoch  0, batch    23 | loss: 2.8934493
MixupTrain:  epoch  0, batch    24 | loss: 3.7305312
MixupTrain:  epoch  0, batch    25 | loss: 3.5548756
MixupTrain:  epoch  0, batch    26 | loss: 3.0179448
MixupTrain:  epoch  0, batch    27 | loss: 3.9251342
MixupTrain:  epoch  0, batch    28 | loss: 3.1661520
MixupTrain:  epoch  0, batch    29 | loss: 3.5822182
MixupTrain:  epoch  0, batch    30 | loss: 3.6077058
MixupTrain:  epoch  0, batch    31 | loss: 3.6944640
MixupTrain:  epoch  0, batch    32 | loss: 3.0237417
MixupTrain:  epoch  0, batch    33 | loss: 3.2218323
MixupTrain:  epoch  0, batch    34 | loss: 3.5464172
MixupTrain:  epoch  0, batch    35 | loss: 3.3920975
MixupTrain:  epoch  0, batch    36 | loss: 3.2609365
MixupTrain:  epoch  0, batch    37 | loss: 3.8454268
MixupTrain:  epoch  0, batch    38 | loss: 2.8708558
MixupTrain:  epoch  0, batch    39 | loss: 3.1112580
MixupTrain:  epoch  0, batch    40 | loss: 2.7919221
MixupTrain:  epoch  0, batch    41 | loss: 3.1789412
MixupTrain:  epoch  0, batch    42 | loss: 2.4073048
MixupTrain:  epoch  0, batch    43 | loss: 3.3382878
MixupTrain:  epoch  0, batch    44 | loss: 3.3446522
MixupTrain:  epoch  0, batch    45 | loss: 3.2482636
MixupTrain:  epoch  0, batch    46 | loss: 3.3433747
MixupTrain:  epoch  0, batch    47 | loss: 3.4449716
MixupTrain:  epoch  0, batch    48 | loss: 3.3288212
MixupTrain:  epoch  0, batch    49 | loss: 3.3947315
MixupTrain:  epoch  0, batch    50 | loss: 3.1320200
MixupTrain:  epoch  0, batch    51 | loss: 3.1625280
MixupTrain:  epoch  0, batch    52 | loss: 3.0992990
MixupTrain:  epoch  0, batch    53 | loss: 3.5530348
MixupTrain:  epoch  0, batch    54 | loss: 3.7371240
MixupTrain:  epoch  0, batch    55 | loss: 3.2889252
MixupTrain:  epoch  0, batch    56 | loss: 2.7215970
MixupTrain:  epoch  0, batch    57 | loss: 2.9066489
MixupTrain:  epoch  0, batch    58 | loss: 2.6080246
MixupTrain:  epoch  0, batch    59 | loss: 3.4783306
MixupTrain:  epoch  0, batch    60 | loss: 3.0993924
MixupTrain:  epoch  0, batch    61 | loss: 2.9002700
MixupTrain:  epoch  0, batch    62 | loss: 3.2373090
MixupTrain:  epoch  0, batch    63 | loss: 3.0322840
MixupTrain:  epoch  0, batch    64 | loss: 3.0535417
MixupTrain:  epoch  0, batch    65 | loss: 2.9339576
MixupTrain:  epoch  0, batch    66 | loss: 2.5375001
MixupTrain:  epoch  0, batch    67 | loss: 2.8150077
MixupTrain:  epoch  0, batch    68 | loss: 2.5273898
MixupTrain:  epoch  0, batch    69 | loss: 3.1654072
MixupTrain:  epoch  0, batch    70 | loss: 2.8823874
MixupTrain:  epoch  0, batch    71 | loss: 2.8294234
MixupTrain:  epoch  0, batch    72 | loss: 2.6186690
MixupTrain:  epoch  0, batch    73 | loss: 2.9407029
MixupTrain:  epoch  0, batch    74 | loss: 2.5886950
MixupTrain:  epoch  0, batch    75 | loss: 2.8907843
MixupTrain:  epoch  0, batch    76 | loss: 3.1692188
MixupTrain:  epoch  0, batch    77 | loss: 2.5528953
MixupTrain:  epoch  0, batch    78 | loss: 2.8677859
MixupTrain:  epoch  0, batch    79 | loss: 2.5529528
MixupTrain:  epoch  0, batch    80 | loss: 2.9622359
MixupTrain:  epoch  0, batch    81 | loss: 2.7055161
MixupTrain:  epoch  0, batch    82 | loss: 2.8776360
MixupTrain:  epoch  0, batch    83 | loss: 2.7130837
MixupTrain:  epoch  0, batch    84 | loss: 2.8000631
MixupTrain:  epoch  0, batch    85 | loss: 2.8261809
MixupTrain:  epoch  0, batch    86 | loss: 3.5243258
MixupTrain:  epoch  0, batch    87 | loss: 3.1777816
MixupTrain:  epoch  0, batch    88 | loss: 2.9108467
MixupTrain:  epoch  0, batch    89 | loss: 2.4951277
MixupTrain:  epoch  0, batch    90 | loss: 2.8906429
MixupTrain:  epoch  0, batch    91 | loss: 2.9190845
MixupTrain:  epoch  0, batch    92 | loss: 2.8544891
MixupTrain:  epoch  0, batch    93 | loss: 2.9780557
MixupTrain:  epoch  0, batch    94 | loss: 3.0968308
MixupTrain:  epoch  0, batch    95 | loss: 3.1152306
MixupTrain:  epoch  0, batch    96 | loss: 2.7830954
MixupTrain:  epoch  0, batch    97 | loss: 2.5444889
MixupTrain:  epoch  0, batch    98 | loss: 2.8763170
MixupTrain:  epoch  0, batch    99 | loss: 2.6038489
MixupTrain:  epoch  0, batch   100 | loss: 3.2602019
MixupTrain:  epoch  0, batch   101 | loss: 2.5381875
MixupTrain:  epoch  0, batch   102 | loss: 2.8834052
MixupTrain:  epoch  0, batch   103 | loss: 2.7977450
MixupTrain:  epoch  0, batch   104 | loss: 2.8443236
MixupTrain:  epoch  0, batch   105 | loss: 2.6177139
MixupTrain:  epoch  0, batch   106 | loss: 2.7556915
MixupTrain:  epoch  0, batch   107 | loss: 3.4075034
MixupTrain:  epoch  0, batch   108 | loss: 2.7747097
MixupTrain:  epoch  0, batch   109 | loss: 2.3855629
MixupTrain:  epoch  0, batch   110 | loss: 2.2226386
MixupTrain:  epoch  0, batch   111 | loss: 2.5320749
MixupTrain:  epoch  0, batch   112 | loss: 3.1182833
MixupTrain:  epoch  0, batch   113 | loss: 2.3524790
MixupTrain:  epoch  0, batch   114 | loss: 2.5101581
MixupTrain:  epoch  0, batch   115 | loss: 2.9198096
MixupTrain:  epoch  0, batch   116 | loss: 2.9945350
MixupTrain:  epoch  0, batch   117 | loss: 2.6764038
MixupTrain:  epoch  0, batch   118 | loss: 3.1161828
MixupTrain:  epoch  0, batch   119 | loss: 2.5669305
MixupTrain:  epoch  0, batch   120 | loss: 2.7680440
MixupTrain:  epoch  0, batch   121 | loss: 2.5609813
MixupTrain:  epoch  0, batch   122 | loss: 2.8022811
MixupTrain:  epoch  0, batch   123 | loss: 2.7422733
MixupTrain:  epoch  0, batch   124 | loss: 2.4068489
MixupTrain:  epoch  0, batch   125 | loss: 2.8348854
MixupTrain:  epoch  0, batch   126 | loss: 2.4344151
MixupTrain:  epoch  0, batch   127 | loss: 2.7529640
MixupTrain:  epoch  0, batch   128 | loss: 2.2232611
MixupTrain:  epoch  0, batch   129 | loss: 2.7708147
MixupTrain:  epoch  0, batch   130 | loss: 2.7395101
MixupTrain:  epoch  0, batch   131 | loss: 2.7685804
MixupTrain:  epoch  0, batch   132 | loss: 3.4360523
MixupTrain:  epoch  0, batch   133 | loss: 3.0445342
MixupTrain:  epoch  0, batch   134 | loss: 2.5673542
MixupTrain:  epoch  0, batch   135 | loss: 2.4162135
MixupTrain:  epoch  0, batch   136 | loss: 2.6647382
MixupTrain:  epoch  0, batch   137 | loss: 2.7536564
MixupTrain:  epoch  0, batch   138 | loss: 2.5188141
MixupTrain:  epoch  0, batch   139 | loss: 2.3271239
MixupTrain:  epoch  0, batch   140 | loss: 2.0594423
MixupTrain:  epoch  0, batch   141 | loss: 2.9279785
MixupTrain:  epoch  0, batch   142 | loss: 2.4558923
MixupTrain:  epoch  0, batch   143 | loss: 2.6018975
MixupTrain:  epoch  0, batch   144 | loss: 2.9888463
MixupTrain:  epoch  0, batch   145 | loss: 2.0846233
MixupTrain:  epoch  0, batch   146 | loss: 2.7254846
MixupTrain:  epoch  0, batch   147 | loss: 2.4788651
MixupTrain:  epoch  0, batch   148 | loss: 2.6624246
MixupTrain:  epoch  0, batch   149 | loss: 2.9088001
MixupTrain:  epoch  0, batch   150 | loss: 2.1898243
MixupTrain:  epoch  0, batch   151 | loss: 2.3876081
MixupTrain:  epoch  0, batch   152 | loss: 2.8680689
MixupTrain:  epoch  0, batch   153 | loss: 2.9432173
MixupTrain:  epoch  0, batch   154 | loss: 2.9528956
MixupTrain:  epoch  0, batch   155 | loss: 2.3196721
MixupTrain:  epoch  0, batch   156 | loss: 2.3849404
MixupTrain:  epoch  0, batch   157 | loss: 2.4185679
MixupTrain:  epoch  0, batch   158 | loss: 2.6674941
MixupTrain:  epoch  0, batch   159 | loss: 2.6649182
MixupTrain:  epoch  0, batch   160 | loss: 2.4580538
MixupTrain:  epoch  0, batch   161 | loss: 2.7762201
MixupTrain:  epoch  0, batch   162 | loss: 3.0888338
MixupTrain:  epoch  0, batch   163 | loss: 2.5717533
MixupTrain:  epoch  0, batch   164 | loss: 2.4783349
MixupTrain:  epoch  0, batch   165 | loss: 2.5761280
MixupTrain:  epoch  0, batch   166 | loss: 3.3345950
MixupTrain:  epoch  0, batch   167 | loss: 2.6957757
MixupTrain:  epoch  0, batch   168 | loss: 2.2689965
MixupTrain:  epoch  0, batch   169 | loss: 2.6562595
MixupTrain:  epoch  0, batch   170 | loss: 2.5342278
MixupTrain:  epoch  0, batch   171 | loss: 2.9445405
MixupTrain:  epoch  0, batch   172 | loss: 2.4737103
MixupTrain:  epoch  0, batch   173 | loss: 2.3191948
MixupTrain:  epoch  0, batch   174 | loss: 2.4478827
MixupTrain:  epoch  0, batch   175 | loss: 2.5873322
MixupTrain:  epoch  0, batch   176 | loss: 2.5576527
MixupTrain:  epoch  0, batch   177 | loss: 2.3553715
MixupTrain:  epoch  0, batch   178 | loss: 2.2872503
MixupTrain:  epoch  0, batch   179 | loss: 2.4113488
MixupTrain:  epoch  0, batch   180 | loss: 2.2033291
MixupTrain:  epoch  0, batch   181 | loss: 2.3152871
MixupTrain:  epoch  0, batch   182 | loss: 1.9952073
MixupTrain:  epoch  0, batch   183 | loss: 2.4155836
MixupTrain:  epoch  0, batch   184 | loss: 2.4765272
MixupTrain:  epoch  0, batch   185 | loss: 2.5225940
MixupTrain:  epoch  0, batch   186 | loss: 2.4706163
MixupTrain:  epoch  0, batch   187 | loss: 2.5535607
MixupTrain:  epoch  0, batch   188 | loss: 2.8948073
MixupTrain:  epoch  0, batch   189 | loss: 2.4385953
MixupTrain:  epoch  0, batch   190 | loss: 2.5067844
MixupTrain:  epoch  0, batch   191 | loss: 2.3482881
MixupTrain:  epoch  0, batch   192 | loss: 2.4461606
MixupTrain:  epoch  0, batch   193 | loss: 2.3307893
MixupTrain:  epoch  0, batch   194 | loss: 2.0978961
MixupTrain:  epoch  0, batch   195 | loss: 2.4878566
MixupTrain:  epoch  0, batch   196 | loss: 2.1415937
MixupTrain:  epoch  0, batch   197 | loss: 2.5690582
MixupTrain:  epoch  0, batch   198 | loss: 2.5911531
MixupTrain:  epoch  0, batch   199 | loss: 2.7389927
MixupTrain:  epoch  0, batch   200 | loss: 2.9165292
MixupTrain:  epoch  0, batch   201 | loss: 2.6322825
MixupTrain:  epoch  0, batch   202 | loss: 2.3377082
MixupTrain:  epoch  0, batch   203 | loss: 2.8305230
MixupTrain:  epoch  0, batch   204 | loss: 2.5560617
MixupTrain:  epoch  0, batch   205 | loss: 2.2615197
MixupTrain:  epoch  0, batch   206 | loss: 2.3060088
MixupTrain:  epoch  0, batch   207 | loss: 2.5896192
MixupTrain:  epoch  0, batch   208 | loss: 2.4430494
MixupTrain:  epoch  0, batch   209 | loss: 2.6895084
MixupTrain:  epoch  0, batch   210 | loss: 2.3995883
MixupTrain:  epoch  0, batch   211 | loss: 2.1981237
MixupTrain:  epoch  0, batch   212 | loss: 2.5299101
MixupTrain:  epoch  0, batch   213 | loss: 2.5263028
MixupTrain:  epoch  0, batch   214 | loss: 2.5503337
MixupTrain:  epoch  0, batch   215 | loss: 2.4844916
MixupTrain:  epoch  0, batch   216 | loss: 2.6475086
MixupTrain:  epoch  0, batch   217 | loss: 2.7183423
MixupTrain:  epoch  0, batch   218 | loss: 2.3767769
MixupTrain:  epoch  0, batch   219 | loss: 2.2256360
MixupTrain:  epoch  0, batch   220 | loss: 2.3571787
MixupTrain:  epoch  0, batch   221 | loss: 2.1496797
MixupTrain:  epoch  0, batch   222 | loss: 2.6259902
MixupTrain:  epoch  0, batch   223 | loss: 2.7694423
MixupTrain:  epoch  0, batch   224 | loss: 2.1485744
MixupTrain:  epoch  0, batch   225 | loss: 2.6167750
MixupTrain:  epoch  0, batch   226 | loss: 2.3467884
MixupTrain:  epoch  0, batch   227 | loss: 2.4452610
MixupTrain:  epoch  0, batch   228 | loss: 2.7451410
MixupTrain:  epoch  0, batch   229 | loss: 2.4419129
MixupTrain:  epoch  0, batch   230 | loss: 2.1129730
MixupTrain:  epoch  0, batch   231 | loss: 2.5125148
MixupTrain:  epoch  0, batch   232 | loss: 2.3416860
MixupTrain:  epoch  0, batch   233 | loss: 2.2744355
MixupTrain:  epoch  0, batch   234 | loss: 2.1688275
MixupTrain:  epoch  0, batch   235 | loss: 2.4114728
MixupTrain:  epoch  0, batch   236 | loss: 2.7334042
MixupTrain:  epoch  0, batch   237 | loss: 2.5598116
MixupTrain:  epoch  0, batch   238 | loss: 2.4446347
MixupTrain:  epoch  0, batch   239 | loss: 2.0860140
MixupTrain:  epoch  0, batch   240 | loss: 2.3278847
MixupTrain:  epoch  0, batch   241 | loss: 2.2144394
MixupTrain:  epoch  0, batch   242 | loss: 2.3759704
MixupTrain:  epoch  0, batch   243 | loss: 2.2828264
MixupTrain:  epoch  0, batch   244 | loss: 2.4669340
MixupTrain:  epoch  0, batch   245 | loss: 2.1789067
MixupTrain:  epoch  0, batch   246 | loss: 2.4083319
MixupTrain:  epoch  0, batch   247 | loss: 2.5239906
MixupTrain:  epoch  0, batch   248 | loss: 2.6775723
MixupTrain:  epoch  0, batch   249 | loss: 2.5343776
MixupTrain:  epoch  0, batch   250 | loss: 2.2931654
MixupTrain:  epoch  0, batch   251 | loss: 2.3195713
MixupTrain:  epoch  0, batch   252 | loss: 2.1011055
MixupTrain:  epoch  0, batch   253 | loss: 2.2051220
MixupTrain:  epoch  0, batch   254 | loss: 2.6283886
MixupTrain:  epoch  0, batch   255 | loss: 2.0598094
MixupTrain:  epoch  0, batch   256 | loss: 2.5164518
MixupTrain:  epoch  0, batch   257 | loss: 2.2292905
MixupTrain:  epoch  0, batch   258 | loss: 2.4256504
MixupTrain:  epoch  0, batch   259 | loss: 2.2059312
MixupTrain:  epoch  0, batch   260 | loss: 2.3827195
MixupTrain:  epoch  0, batch   261 | loss: 2.6533933
MixupTrain:  epoch  0, batch   262 | loss: 2.7671483
MixupTrain:  epoch  0, batch   263 | loss: 2.4801898
MixupTrain:  epoch  0, batch   264 | loss: 2.3872042
MixupTrain:  epoch  0, batch   265 | loss: 2.5124793
MixupTrain:  epoch  0, batch   266 | loss: 2.3866477
MixupTrain:  epoch  0, batch   267 | loss: 2.2258382
MixupTrain:  epoch  0, batch   268 | loss: 2.1214395
MixupTrain:  epoch  0, batch   269 | loss: 2.2227409
MixupTrain:  epoch  0, batch   270 | loss: 2.5014579
MixupTrain:  epoch  0, batch   271 | loss: 2.5174396
MixupTrain:  epoch  0, batch   272 | loss: 2.2221236
MixupTrain:  epoch  0, batch   273 | loss: 2.4773655
MixupTrain:  epoch  0, batch   274 | loss: 2.1606059
MixupTrain:  epoch  0, batch   275 | loss: 2.3343549
MixupTrain:  epoch  0, batch   276 | loss: 2.0770850
MixupTrain:  epoch  0, batch   277 | loss: 2.4899521
MixupTrain:  epoch  0, batch   278 | loss: 2.3356302
MixupTrain:  epoch  0, batch   279 | loss: 2.4213390
MixupTrain:  epoch  0, batch   280 | loss: 2.4899571
MixupTrain:  epoch  0, batch   281 | loss: 2.3319170
MixupTrain:  epoch  0, batch   282 | loss: 2.7157755
MixupTrain:  epoch  0, batch   283 | loss: 2.6685913
MixupTrain:  epoch  0, batch   284 | loss: 2.3123891
MixupTrain:  epoch  0, batch   285 | loss: 2.2383313
MixupTrain:  epoch  0, batch   286 | loss: 2.2022986
MixupTrain:  epoch  0, batch   287 | loss: 2.4730496
MixupTrain:  epoch  0, batch   288 | loss: 2.2673995
MixupTrain:  epoch  0, batch   289 | loss: 2.5291886
MixupTrain:  epoch  0, batch   290 | loss: 2.5492122
MixupTrain:  epoch  0, batch   291 | loss: 2.3539076
MixupTrain:  epoch  0, batch   292 | loss: 2.2742975
MixupTrain:  epoch  0, batch   293 | loss: 2.2632730
MixupTrain:  epoch  0, batch   294 | loss: 2.4782505
MixupTrain:  epoch  0, batch   295 | loss: 2.5735219
MixupTrain:  epoch  0, batch   296 | loss: 2.3701172
MixupTrain:  epoch  0, batch   297 | loss: 2.3374343
MixupTrain:  epoch  0, batch   298 | loss: 2.9044213
MixupTrain:  epoch  0, batch   299 | loss: 2.3231769
MixupTrain:  epoch  0, batch   300 | loss: 2.4237337
MixupTrain:  epoch  0, batch   301 | loss: 2.3908243
MixupTrain:  epoch  0, batch   302 | loss: 2.4911346
MixupTrain:  epoch  0, batch   303 | loss: 2.2074337
MixupTrain:  epoch  0, batch   304 | loss: 2.8619604
MixupTrain:  epoch  0, batch   305 | loss: 2.2391462
MixupTrain:  epoch  0, batch   306 | loss: 2.2649746
MixupTrain:  epoch  0, batch   307 | loss: 2.5272427
MixupTrain:  epoch  0, batch   308 | loss: 1.9642166
MixupTrain:  epoch  0, batch   309 | loss: 2.4860547
MixupTrain:  epoch  0, batch   310 | loss: 2.3428667
MixupTrain:  epoch  0, batch   311 | loss: 2.4519801
MixupTrain:  epoch  0, batch   312 | loss: 2.5531182
MixupTrain:  epoch  0, batch   313 | loss: 2.5849447
MixupTrain:  epoch  0, batch   314 | loss: 2.4263334
MixupTrain:  epoch  0, batch   315 | loss: 2.5904665
MixupTrain:  epoch  0, batch   316 | loss: 2.4969931
MixupTrain:  epoch  0, batch   317 | loss: 2.1785648
MixupTrain:  epoch  0, batch   318 | loss: 2.5500817
MixupTrain:  epoch  0, batch   319 | loss: 2.2840812
MixupTrain:  epoch  0, batch   320 | loss: 2.3580928
MixupTrain:  epoch  0, batch   321 | loss: 2.6021550
MixupTrain:  epoch  0, batch   322 | loss: 2.3316972
MixupTrain:  epoch  0, batch   323 | loss: 2.3924000
MixupTrain:  epoch  0, batch   324 | loss: 2.3487155
MixupTrain:  epoch  0, batch   325 | loss: 2.3586931
MixupTrain:  epoch  0, batch   326 | loss: 2.5777464
MixupTrain:  epoch  0, batch   327 | loss: 2.1695700
MixupTrain:  epoch  0, batch   328 | loss: 2.2193508
MixupTrain:  epoch  0, batch   329 | loss: 2.3846848
MixupTrain:  epoch  0, batch   330 | loss: 2.3676839
MixupTrain:  epoch  0, batch   331 | loss: 2.2532597
MixupTrain:  epoch  0, batch   332 | loss: 2.3362153
MixupTrain:  epoch  0, batch   333 | loss: 2.2497482
MixupTrain:  epoch  0, batch   334 | loss: 2.4564261
MixupTrain:  epoch  0, batch   335 | loss: 2.5085516
MixupTrain:  epoch  0, batch   336 | loss: 2.6055598
MixupTrain:  epoch  0, batch   337 | loss: 2.2122922
MixupTrain:  epoch  0, batch   338 | loss: 2.3405738
MixupTrain:  epoch  0, batch   339 | loss: 2.5364876
MixupTrain:  epoch  0, batch   340 | loss: 2.0852060
MixupTrain:  epoch  0, batch   341 | loss: 2.3195748
MixupTrain:  epoch  0, batch   342 | loss: 2.5027342
MixupTrain:  epoch  0, batch   343 | loss: 2.2128377
MixupTrain:  epoch  0, batch   344 | loss: 2.5621963
MixupTrain:  epoch  0, batch   345 | loss: 2.0933316
MixupTrain:  epoch  0, batch   346 | loss: 2.3405852
MixupTrain:  epoch  0, batch   347 | loss: 2.4200919
MixupTrain:  epoch  0, batch   348 | loss: 2.4223394
MixupTrain:  epoch  0, batch   349 | loss: 2.4533081
MixupTrain:  epoch  0, batch   350 | loss: 2.1628134
MixupTrain:  epoch  0, batch   351 | loss: 2.3075454
MixupTrain:  epoch  0, batch   352 | loss: 2.5752714
MixupTrain:  epoch  0, batch   353 | loss: 2.4804044
MixupTrain:  epoch  0, batch   354 | loss: 2.5027323
MixupTrain:  epoch  0, batch   355 | loss: 2.3657782
MixupTrain:  epoch  0, batch   356 | loss: 2.8488278
MixupTrain:  epoch  0, batch   357 | loss: 2.4351890
MixupTrain:  epoch  0, batch   358 | loss: 2.2970698
MixupTrain:  epoch  0, batch   359 | loss: 2.2897415
MixupTrain:  epoch  0, batch   360 | loss: 2.6396537
MixupTrain:  epoch  0, batch   361 | loss: 2.2966471
MixupTrain:  epoch  0, batch   362 | loss: 2.3460939
MixupTrain:  epoch  0, batch   363 | loss: 2.6143000
MixupTrain:  epoch  0, batch   364 | loss: 2.4699521
MixupTrain:  epoch  0, batch   365 | loss: 2.2578979
MixupTrain:  epoch  0, batch   366 | loss: 2.5242240
MixupTrain:  epoch  0, batch   367 | loss: 2.4838915
MixupTrain:  epoch  0, batch   368 | loss: 2.5294986
MixupTrain:  epoch  0, batch   369 | loss: 2.3577914
MixupTrain:  epoch  0, batch   370 | loss: 2.4051914
MixupTrain:  epoch  0, batch   371 | loss: 2.3170896
MixupTrain:  epoch  0, batch   372 | loss: 2.1485276
MixupTrain:  epoch  0, batch   373 | loss: 2.3550696
MixupTrain:  epoch  0, batch   374 | loss: 2.5638995
MixupTrain:  epoch  0, batch   375 | loss: 2.4378290
MixupTrain:  epoch  0, batch   376 | loss: 2.3164754
MixupTrain:  epoch  0, batch   377 | loss: 2.3171055
MixupTrain:  epoch  0, batch   378 | loss: 2.4235001
MixupTrain:  epoch  0, batch   379 | loss: 2.2499766
MixupTrain:  epoch  0, batch   380 | loss: 2.8380656
MixupTrain:  epoch  0, batch   381 | loss: 2.3173904
MixupTrain:  epoch  0, batch   382 | loss: 2.2556825
MixupTrain:  epoch  0, batch   383 | loss: 2.4728699
MixupTrain:  epoch  0, batch   384 | loss: 2.3387704
MixupTrain:  epoch  0, batch   385 | loss: 2.3867977
MixupTrain:  epoch  0, batch   386 | loss: 2.2190533
MixupTrain:  epoch  0, batch   387 | loss: 2.4545193
MixupTrain:  epoch  0, batch   388 | loss: 2.2109473
MixupTrain:  epoch  0, batch   389 | loss: 1.9076338
MixupTrain:  epoch  0, batch   390 | loss: 2.2124205
MixupTrain:  epoch  0, batch   391 | loss: 2.3358431
MixupTrain:  epoch  0, batch   392 | loss: 2.5061955
MixupTrain:  epoch  0, batch   393 | loss: 2.2137198
MixupTrain:  epoch  0, batch   394 | loss: 2.8477614
MixupTrain:  epoch  0, batch   395 | loss: 2.4750736
MixupTrain:  epoch  0, batch   396 | loss: 1.8988997
MixupTrain:  epoch  0, batch   397 | loss: 2.3205159
MixupTrain:  epoch  0, batch   398 | loss: 2.4579871
MixupTrain:  epoch  0, batch   399 | loss: 2.3368120
MixupTrain:  epoch  0, batch   400 | loss: 2.4882503
MixupTrain:  epoch  0, batch   401 | loss: 2.4305103
MixupTrain:  epoch  0, batch   402 | loss: 2.4497995
MixupTrain:  epoch  0, batch   403 | loss: 2.4415684
MixupTrain:  epoch  0, batch   404 | loss: 2.2368689
MixupTrain:  epoch  0, batch   405 | loss: 2.3209531
MixupTrain:  epoch  0, batch   406 | loss: 2.2057202
MixupTrain:  epoch  0, batch   407 | loss: 2.0944614
MixupTrain:  epoch  0, batch   408 | loss: 2.5177355
MixupTrain:  epoch  0, batch   409 | loss: 2.3612232
MixupTrain:  epoch  0, batch   410 | loss: 2.1731958
MixupTrain:  epoch  0, batch   411 | loss: 2.1658008
MixupTrain:  epoch  0, batch   412 | loss: 2.3280299
MixupTrain:  epoch  0, batch   413 | loss: 2.2741601
MixupTrain:  epoch  0, batch   414 | loss: 2.2729034
MixupTrain:  epoch  0, batch   415 | loss: 2.1890259
MixupTrain:  epoch  0, batch   416 | loss: 2.4298675
MixupTrain:  epoch  0, batch   417 | loss: 2.5070727
MixupTrain:  epoch  0, batch   418 | loss: 2.4069324
MixupTrain:  epoch  0, batch   419 | loss: 2.1389542
MixupTrain:  epoch  0, batch   420 | loss: 2.2728918
MixupTrain:  epoch  0, batch   421 | loss: 2.2972152
MixupTrain:  epoch  0, batch   422 | loss: 2.2320981
MixupTrain:  epoch  0, batch   423 | loss: 2.4722466
MixupTrain:  epoch  0, batch   424 | loss: 2.4682345
MixupTrain:  epoch  0, batch   425 | loss: 2.3007164
MixupTrain:  epoch  0, batch   426 | loss: 2.4844530
MixupTrain:  epoch  0, batch   427 | loss: 2.3272216
MixupTrain:  epoch  0, batch   428 | loss: 2.3619251
MixupTrain:  epoch  0, batch   429 | loss: 2.1547863
MixupTrain:  epoch  0, batch   430 | loss: 2.3540492
MixupTrain:  epoch  0, batch   431 | loss: 2.0674558
MixupTrain:  epoch  0, batch   432 | loss: 2.2696242
MixupTrain:  epoch  0, batch   433 | loss: 2.1549973
MixupTrain:  epoch  0, batch   434 | loss: 2.5895505
MixupTrain:  epoch  0, batch   435 | loss: 2.2400241
MixupTrain:  epoch  0, batch   436 | loss: 2.2496035
MixupTrain:  epoch  0, batch   437 | loss: 2.0433788
MixupTrain:  epoch  0, batch   438 | loss: 2.5982599
MixupTrain:  epoch  0, batch   439 | loss: 2.1908121
MixupTrain:  epoch  0, batch   440 | loss: 2.3600562
MixupTrain:  epoch  0, batch   441 | loss: 2.0740180
MixupTrain:  epoch  0, batch   442 | loss: 2.4195096
MixupTrain:  epoch  0, batch   443 | loss: 2.4790964
MixupTrain:  epoch  0, batch   444 | loss: 2.2173672
MixupTrain:  epoch  0, batch   445 | loss: 2.3984194
MixupTrain:  epoch  0, batch   446 | loss: 2.3753099
MixupTrain:  epoch  0, batch   447 | loss: 2.3569205
MixupTrain:  epoch  0, batch   448 | loss: 2.0582795
MixupTrain:  epoch  0, batch   449 | loss: 2.3978829
MixupTrain:  epoch  0, batch   450 | loss: 2.4309156
MixupTrain:  epoch  0, batch   451 | loss: 2.3041403
MixupTrain:  epoch  0, batch   452 | loss: 2.3843508
MixupTrain:  epoch  0, batch   453 | loss: 2.2914398
MixupTrain:  epoch  0, batch   454 | loss: 2.2539921
MixupTrain:  epoch  0, batch   455 | loss: 1.9982824
MixupTrain:  epoch  0, batch   456 | loss: 2.3287222
MixupTrain:  epoch  0, batch   457 | loss: 2.1224217
MixupTrain:  epoch  0, batch   458 | loss: 2.2816958
MixupTrain:  epoch  0, batch   459 | loss: 2.5543780
MixupTrain:  epoch  0, batch   460 | loss: 2.4300671
MixupTrain:  epoch  0, batch   461 | loss: 2.4946337
MixupTrain:  epoch  0, batch   462 | loss: 2.4742603
MixupTrain:  epoch  0, batch   463 | loss: 2.4735298
MixupTrain:  epoch  0, batch   464 | loss: 2.5217333
MixupTrain:  epoch  0, batch   465 | loss: 2.1716657
MixupTrain:  epoch  0, batch   466 | loss: 2.3353598
MixupTrain:  epoch  0, batch   467 | loss: 2.3971431
MixupTrain:  epoch  0, batch   468 | loss: 2.3913012
MixupTrain:  epoch  0, batch   469 | loss: 2.3041897
MixupTrain:  epoch  0, batch   470 | loss: 2.3389728
MixupTrain:  epoch  0, batch   471 | loss: 2.4808285
MixupTrain:  epoch  0, batch   472 | loss: 2.2548962
MixupTrain:  epoch  0, batch   473 | loss: 2.3747005
MixupTrain:  epoch  0, batch   474 | loss: 2.2801404
MixupTrain:  epoch  0, batch   475 | loss: 2.4881442
MixupTrain:  epoch  0, batch   476 | loss: 2.4431863
MixupTrain:  epoch  0, batch   477 | loss: 2.5344114
MixupTrain:  epoch  0, batch   478 | loss: 2.4385250
MixupTrain:  epoch  0, batch   479 | loss: 2.2058163
MixupTrain:  epoch  0, batch   480 | loss: 2.4441447
MixupTrain:  epoch  0, batch   481 | loss: 2.5009089
MixupTrain:  epoch  0, batch   482 | loss: 2.0917702
MixupTrain:  epoch  0, batch   483 | loss: 2.1515543
MixupTrain:  epoch  0, batch   484 | loss: 2.4558887
MixupTrain:  epoch  0, batch   485 | loss: 2.3023272
MixupTrain:  epoch  0, batch   486 | loss: 2.0641718
MixupTrain:  epoch  0, batch   487 | loss: 2.4589710
MixupTrain:  epoch  0, batch   488 | loss: 2.6146376
MixupTrain:  epoch  0, batch   489 | loss: 2.1710663
MixupTrain:  epoch  0, batch   490 | loss: 2.0577614
MixupTrain:  epoch  0, batch   491 | loss: 2.4867613
MixupTrain:  epoch  0, batch   492 | loss: 2.3718073
MixupTrain:  epoch  0, batch   493 | loss: 2.3830476
MixupTrain:  epoch  0, batch   494 | loss: 2.3261232
MixupTrain:  epoch  0, batch   495 | loss: 2.3915076
MixupTrain:  epoch  0, batch   496 | loss: 2.2695227
MixupTrain:  epoch  0, batch   497 | loss: 2.1110153
MixupTrain:  epoch  0, batch   498 | loss: 2.3519483
MixupTrain:  epoch  0, batch   499 | loss: 2.2112737
MixupTrain:  epoch  0, batch   500 | loss: 2.4769704
MixupTrain:  epoch  0, batch   501 | loss: 2.3412058
MixupTrain:  epoch  0, batch   502 | loss: 2.2276239
MixupTrain:  epoch  0, batch   503 | loss: 2.3226779
MixupTrain:  epoch  0, batch   504 | loss: 2.2654424
MixupTrain:  epoch  0, batch   505 | loss: 2.1614616
MixupTrain:  epoch  0, batch   506 | loss: 2.3323278
MixupTrain:  epoch  0, batch   507 | loss: 2.5344133
MixupTrain:  epoch  0, batch   508 | loss: 2.1542881
MixupTrain:  epoch  0, batch   509 | loss: 2.5275288
MixupTrain:  epoch  0, batch   510 | loss: 2.3021843
MixupTrain:  epoch  0, batch   511 | loss: 2.1655903
MixupTrain:  epoch  0, batch   512 | loss: 2.3471329
MixupTrain:  epoch  0, batch   513 | loss: 2.1548574
MixupTrain:  epoch  0, batch   514 | loss: 2.3236613
MixupTrain:  epoch  0, batch   515 | loss: 2.3198977
MixupTrain:  epoch  0, batch   516 | loss: 2.4049063
MixupTrain:  epoch  0, batch   517 | loss: 2.5122185
MixupTrain:  epoch  0, batch   518 | loss: 2.1445215
MixupTrain:  epoch  0, batch   519 | loss: 2.4242430
MixupTrain:  epoch  0, batch   520 | loss: 2.4460640
MixupTrain:  epoch  0, batch   521 | loss: 2.2057931
MixupTrain:  epoch  0, batch   522 | loss: 2.6688168
MixupTrain:  epoch  0, batch   523 | loss: 2.4388289
MixupTrain:  epoch  0, batch   524 | loss: 2.3096859
MixupTrain:  epoch  0, batch   525 | loss: 2.5280194
MixupTrain:  epoch  0, batch   526 | loss: 2.3375239
MixupTrain:  epoch  0, batch   527 | loss: 2.2984810
MixupTrain:  epoch  0, batch   528 | loss: 2.1098404
MixupTrain:  epoch  0, batch   529 | loss: 2.1515791
MixupTrain:  epoch  0, batch   530 | loss: 2.3521028
MixupTrain:  epoch  0, batch   531 | loss: 2.0312829
MixupTrain:  epoch  0, batch   532 | loss: 2.3930550
MixupTrain:  epoch  0, batch   533 | loss: 2.4252341
MixupTrain:  epoch  0, batch   534 | loss: 2.1253715
MixupTrain:  epoch  0, batch   535 | loss: 2.0232112
MixupTrain:  epoch  0, batch   536 | loss: 2.3025527
MixupTrain:  epoch  0, batch   537 | loss: 2.2153244
MixupTrain:  epoch  0, batch   538 | loss: 2.3506188
MixupTrain:  epoch  0, batch   539 | loss: 2.2023797
MixupTrain:  epoch  0, batch   540 | loss: 2.5628266
MixupTrain:  epoch  0, batch   541 | loss: 2.0548515
MixupTrain:  epoch  0, batch   542 | loss: 2.4687333
MixupTrain:  epoch  0, batch   543 | loss: 2.5783079
MixupTrain:  epoch  0, batch   544 | loss: 2.3137569
MixupTrain:  epoch  0, batch   545 | loss: 2.4169393
MixupTrain:  epoch  0, batch   546 | loss: 2.1025267
MixupTrain:  epoch  0, batch   547 | loss: 2.1764753
MixupTrain:  epoch  0, batch   548 | loss: 2.4684181
MixupTrain:  epoch  0, batch   549 | loss: 2.4502017
MixupTrain:  epoch  0, batch   550 | loss: 2.6584353
MixupTrain:  epoch  0, batch   551 | loss: 2.2822003
MixupTrain:  epoch  0, batch   552 | loss: 2.3069456
MixupTrain:  epoch  0, batch   553 | loss: 2.3684676
MixupTrain:  epoch  0, batch   554 | loss: 2.3379207
MixupTrain:  epoch  0, batch   555 | loss: 2.0108430
MixupTrain:  epoch  0, batch   556 | loss: 2.4400253
MixupTrain:  epoch  0, batch   557 | loss: 2.3960934
MixupTrain:  epoch  0, batch   558 | loss: 2.4724498
MixupTrain:  epoch  0, batch   559 | loss: 1.9927266
MixupTrain:  epoch  0, batch   560 | loss: 2.5380635
MixupTrain:  epoch  0, batch   561 | loss: 2.3140359
MixupTrain:  epoch  0, batch   562 | loss: 2.2207670
MixupTrain:  epoch  0, batch   563 | loss: 2.3541329
MixupTrain:  epoch  0, batch   564 | loss: 2.4287271
MixupTrain:  epoch  0, batch   565 | loss: 2.2408710
MixupTrain:  epoch  0, batch   566 | loss: 2.2726741
MixupTrain:  epoch  0, batch   567 | loss: 2.6222262
MixupTrain:  epoch  0, batch   568 | loss: 2.2722540
MixupTrain:  epoch  0, batch   569 | loss: 2.2209034
MixupTrain:  epoch  0, batch   570 | loss: 2.5742366
MixupTrain:  epoch  0, batch   571 | loss: 2.2560177
MixupTrain:  epoch  0, batch   572 | loss: 2.1779685
MixupTrain:  epoch  0, batch   573 | loss: 2.2467606
MixupTrain:  epoch  0, batch   574 | loss: 2.3942480
MixupTrain:  epoch  0, batch   575 | loss: 2.3409016
MixupTrain:  epoch  0, batch   576 | loss: 2.3432214
MixupTrain:  epoch  0, batch   577 | loss: 2.3033991
MixupTrain:  epoch  0, batch   578 | loss: 2.6487222
MixupTrain:  epoch  0, batch   579 | loss: 2.1975369
MixupTrain:  epoch  0, batch   580 | loss: 2.4736876
MixupTrain:  epoch  0, batch   581 | loss: 2.0874524
MixupTrain:  epoch  0, batch   582 | loss: 2.2795489
MixupTrain:  epoch  0, batch   583 | loss: 2.2389464
MixupTrain:  epoch  0, batch   584 | loss: 2.1651416
MixupTrain:  epoch  0, batch   585 | loss: 2.3702242
MixupTrain:  epoch  0, batch   586 | loss: 2.1250863
MixupTrain:  epoch  0, batch   587 | loss: 2.3446612
MixupTrain:  epoch  0, batch   588 | loss: 2.2084224
MixupTrain:  epoch  0, batch   589 | loss: 2.3507347
MixupTrain:  epoch  0, batch   590 | loss: 2.4274812
MixupTrain:  epoch  0, batch   591 | loss: 2.2228854
MixupTrain:  epoch  0, batch   592 | loss: 2.1562500
MixupTrain:  epoch  0, batch   593 | loss: 2.0131021
MixupTrain:  epoch  0, batch   594 | loss: 2.5049374
MixupTrain:  epoch  0, batch   595 | loss: 2.2138114
MixupTrain:  epoch  0, batch   596 | loss: 2.4397583
MixupTrain:  epoch  0, batch   597 | loss: 2.1057320
MixupTrain:  epoch  0, batch   598 | loss: 2.4227738
MixupTrain:  epoch  0, batch   599 | loss: 2.1228077
MixupTrain:  epoch  0, batch   600 | loss: 2.3041105
MixupTrain:  epoch  0, batch   601 | loss: 2.0936117
MixupTrain:  epoch  0, batch   602 | loss: 2.1299651
MixupTrain:  epoch  0, batch   603 | loss: 2.2219806
MixupTrain:  epoch  0, batch   604 | loss: 2.3953166
MixupTrain:  epoch  0, batch   605 | loss: 2.1741195
MixupTrain:  epoch  0, batch   606 | loss: 2.5435605
MixupTrain:  epoch  0, batch   607 | loss: 2.1110125
MixupTrain:  epoch  0, batch   608 | loss: 2.3029261
MixupTrain:  epoch  0, batch   609 | loss: 2.0820312
MixupTrain:  epoch  0, batch   610 | loss: 2.2120883
MixupTrain:  epoch  0, batch   611 | loss: 2.3782897
MixupTrain:  epoch  0, batch   612 | loss: 2.2343435
MixupTrain:  epoch  0, batch   613 | loss: 2.2600529
MixupTrain:  epoch  0, batch   614 | loss: 2.2528689
MixupTrain:  epoch  0, batch   615 | loss: 2.2862000
MixupTrain:  epoch  0, batch   616 | loss: 2.5093412
MixupTrain:  epoch  0, batch   617 | loss: 2.2836304
MixupTrain:  epoch  0, batch   618 | loss: 2.4592607
MixupTrain:  epoch  0, batch   619 | loss: 2.5880702
MixupTrain:  epoch  0, batch   620 | loss: 2.4188576
MixupTrain:  epoch  0, batch   621 | loss: 2.3853898
MixupTrain:  epoch  0, batch   622 | loss: 2.3711205
MixupTrain:  epoch  0, batch   623 | loss: 2.1804175
MixupTrain:  epoch  0, batch   624 | loss: 2.3749547
MixupTrain:  epoch  0, batch   625 | loss: 2.1708984
MixupTrain:  epoch  0, batch   626 | loss: 2.4053035
MixupTrain:  epoch  0, batch   627 | loss: 2.6104064
MixupTrain:  epoch  0, batch   628 | loss: 2.2339547
MixupTrain:  epoch  0, batch   629 | loss: 2.0709465
MixupTrain:  epoch  0, batch   630 | loss: 2.0704861
MixupTrain:  epoch  0, batch   631 | loss: 2.3793316
MixupTrain:  epoch  0, batch   632 | loss: 2.3775702
MixupTrain:  epoch  0, batch   633 | loss: 2.1562848
MixupTrain:  epoch  0, batch   634 | loss: 2.2729955
MixupTrain:  epoch  0, batch   635 | loss: 2.4428923
MixupTrain:  epoch  0, batch   636 | loss: 2.4189172
MixupTrain:  epoch  0, batch   637 | loss: 2.4239526
MixupTrain:  epoch  0, batch   638 | loss: 2.2609835
MixupTrain:  epoch  0, batch   639 | loss: 2.4012158
MixupTrain:  epoch  0, batch   640 | loss: 2.0780308
MixupTrain:  epoch  0, batch   641 | loss: 2.2965047
MixupTrain:  epoch  0, batch   642 | loss: 2.0352697
MixupTrain:  epoch  0, batch   643 | loss: 2.3667297
MixupTrain:  epoch  0, batch   644 | loss: 2.4440112
MixupTrain:  epoch  0, batch   645 | loss: 2.4070001
MixupTrain:  epoch  0, batch   646 | loss: 2.4922018
MixupTrain:  epoch  0, batch   647 | loss: 2.3480997
MixupTrain:  epoch  0, batch   648 | loss: 2.1730118
MixupTrain:  epoch  0, batch   649 | loss: 2.2970405
MixupTrain:  epoch  0, batch   650 | loss: 2.2012124
MixupTrain:  epoch  0, batch   651 | loss: 2.3941429
MixupTrain:  epoch  0, batch   652 | loss: 2.4880381
MixupTrain:  epoch  0, batch   653 | loss: 2.5116920
MixupTrain:  epoch  0, batch   654 | loss: 2.5444436
MixupTrain:  epoch  0, batch   655 | loss: 2.2838185
MixupTrain:  epoch  0, batch   656 | loss: 2.2999332
MixupTrain:  epoch  0, batch   657 | loss: 2.4214337
MixupTrain:  epoch  0, batch   658 | loss: 2.3330209
MixupTrain:  epoch  0, batch   659 | loss: 2.4562421
MixupTrain:  epoch  0, batch   660 | loss: 2.3167872
MixupTrain:  epoch  0, batch   661 | loss: 2.0257778
MixupTrain:  epoch  0, batch   662 | loss: 2.2211287
MixupTrain:  epoch  0, batch   663 | loss: 2.3786058
MixupTrain:  epoch  0, batch   664 | loss: 2.2166154
MixupTrain:  epoch  0, batch   665 | loss: 2.3354762
MixupTrain:  epoch  0, batch   666 | loss: 2.6083519
MixupTrain:  epoch  0, batch   667 | loss: 2.3704507
MixupTrain:  epoch  0, batch   668 | loss: 2.5114732
MixupTrain:  epoch  0, batch   669 | loss: 2.3490310
MixupTrain:  epoch  0, batch   670 | loss: 2.1086822
MixupTrain:  epoch  0, batch   671 | loss: 2.3393373
MixupTrain:  epoch  0, batch   672 | loss: 2.3306653
MixupTrain:  epoch  0, batch   673 | loss: 2.2464542
MixupTrain:  epoch  0, batch   674 | loss: 2.2824073
MixupTrain:  epoch  0, batch   675 | loss: 2.2804587
MixupTrain:  epoch  0, batch   676 | loss: 2.2242565
MixupTrain:  epoch  0, batch   677 | loss: 2.2089987
MixupTrain:  epoch  0, batch   678 | loss: 2.3878896
MixupTrain:  epoch  0, batch   679 | loss: 2.3163397
MixupTrain:  epoch  0, batch   680 | loss: 2.4064696
MixupTrain:  epoch  0, batch   681 | loss: 2.3046675
MixupTrain:  epoch  0, batch   682 | loss: 2.1387768
MixupTrain:  epoch  0, batch   683 | loss: 2.2155116
MixupTrain:  epoch  0, batch   684 | loss: 2.5473187
MixupTrain:  epoch  0, batch   685 | loss: 2.1527030
MixupTrain:  epoch  0, batch   686 | loss: 2.3666515
MixupTrain:  epoch  0, batch   687 | loss: 2.4259357
MixupTrain:  epoch  0, batch   688 | loss: 2.2385702
MixupTrain:  epoch  0, batch   689 | loss: 2.3798797
MixupTrain:  epoch  0, batch   690 | loss: 2.2990119
MixupTrain:  epoch  0, batch   691 | loss: 2.1541452
MixupTrain:  epoch  0, batch   692 | loss: 2.3155169
MixupTrain:  epoch  0, batch   693 | loss: 2.1961460
MixupTrain:  epoch  0, batch   694 | loss: 2.0409818
MixupTrain:  epoch  0, batch   695 | loss: 2.1464100
MixupTrain:  epoch  0, batch   696 | loss: 2.3416815
MixupTrain:  epoch  0, batch   697 | loss: 2.2389960
MixupTrain:  epoch  0, batch   698 | loss: 2.2869525
MixupTrain:  epoch  0, batch   699 | loss: 2.2795680
MixupTrain:  epoch  0, batch   700 | loss: 2.2499371
MixupTrain:  epoch  0, batch   701 | loss: 2.3685982
MixupTrain:  epoch  0, batch   702 | loss: 2.2009149
MixupTrain:  epoch  0, batch   703 | loss: 2.2442660
MixupTrain:  epoch  0, batch   704 | loss: 2.5237584
MixupTrain:  epoch  0, batch   705 | loss: 2.5003283
MixupTrain:  epoch  0, batch   706 | loss: 2.3496649
MixupTrain:  epoch  0, batch   707 | loss: 2.1135616
MixupTrain:  epoch  0, batch   708 | loss: 2.0801492
MixupTrain:  epoch  0, batch   709 | loss: 2.1560307
MixupTrain:  epoch  0, batch   710 | loss: 2.3892610
MixupTrain:  epoch  0, batch   711 | loss: 2.5463781
MixupTrain:  epoch  0, batch   712 | loss: 2.3103266
MixupTrain:  epoch  0, batch   713 | loss: 2.5185313
MixupTrain:  epoch  0, batch   714 | loss: 2.2993803
MixupTrain:  epoch  0, batch   715 | loss: 2.1831586
MixupTrain:  epoch  0, batch   716 | loss: 2.0697582
MixupTrain:  epoch  0, batch   717 | loss: 2.1603999
MixupTrain:  epoch  0, batch   718 | loss: 2.2428265
MixupTrain:  epoch  0, batch   719 | loss: 2.5130813
MixupTrain:  epoch  0, batch   720 | loss: 2.1059008
MixupTrain:  epoch  0, batch   721 | loss: 2.2244501
MixupTrain:  epoch  0, batch   722 | loss: 2.2057920
MixupTrain:  epoch  0, batch   723 | loss: 2.0850601
MixupTrain:  epoch  0, batch   724 | loss: 2.2614007
MixupTrain:  epoch  0, batch   725 | loss: 2.2492952
MixupTrain:  epoch  0, batch   726 | loss: 2.3955038
MixupTrain:  epoch  0, batch   727 | loss: 2.4778466
MixupTrain:  epoch  0, batch   728 | loss: 2.3788819
MixupTrain:  epoch  0, batch   729 | loss: 2.4224691
MixupTrain:  epoch  0, batch   730 | loss: 2.1694176
MixupTrain:  epoch  0, batch   731 | loss: 2.2087154
MixupTrain:  epoch  0, batch   732 | loss: 2.0406833
MixupTrain:  epoch  0, batch   733 | loss: 2.1261716
MixupTrain:  epoch  0, batch   734 | loss: 2.2608876
MixupTrain:  epoch  0, batch   735 | loss: 2.2084513
MixupTrain:  epoch  0, batch   736 | loss: 2.2445440
MixupTrain:  epoch  0, batch   737 | loss: 2.2220082
MixupTrain:  epoch  0, batch   738 | loss: 2.2635398
MixupTrain:  epoch  0, batch   739 | loss: 2.7191353
MixupTrain:  epoch  0, batch   740 | loss: 2.1931934
MixupTrain:  epoch  0, batch   741 | loss: 2.3392267
MixupTrain:  epoch  0, batch   742 | loss: 2.5107374
MixupTrain:  epoch  0, batch   743 | loss: 2.2596507
MixupTrain:  epoch  0, batch   744 | loss: 2.3177731
MixupTrain:  epoch  0, batch   745 | loss: 2.3816025
MixupTrain:  epoch  0, batch   746 | loss: 2.3113942
MixupTrain:  epoch  0, batch   747 | loss: 2.4419281
MixupTrain:  epoch  0, batch   748 | loss: 2.2773962
MixupTrain:  epoch  0, batch   749 | loss: 2.6457129
MixupTrain:  epoch  0, batch   750 | loss: 2.4277577
MixupTrain:  epoch  0, batch   751 | loss: 2.0307455
MixupTrain:  epoch  0, batch   752 | loss: 2.1572199
MixupTrain:  epoch  0, batch   753 | loss: 2.5059001
MixupTrain:  epoch  0, batch   754 | loss: 2.0794289
MixupTrain:  epoch  0, batch   755 | loss: 2.6795797
MixupTrain:  epoch  0, batch   756 | loss: 2.1385303
MixupTrain:  epoch  0, batch   757 | loss: 2.1561720
MixupTrain:  epoch  0, batch   758 | loss: 2.1398087
MixupTrain:  epoch  0, batch   759 | loss: 2.1665897
MixupTrain:  epoch  0, batch   760 | loss: 2.4719248
MixupTrain:  epoch  0, batch   761 | loss: 2.0819063
MixupTrain:  epoch  0, batch   762 | loss: 2.3278675
MixupTrain:  epoch  0, batch   763 | loss: 2.3293731
MixupTrain:  epoch  0, batch   764 | loss: 2.1206274
MixupTrain:  epoch  0, batch   765 | loss: 2.3503969
MixupTrain:  epoch  0, batch   766 | loss: 2.1553423
MixupTrain:  epoch  0, batch   767 | loss: 2.4252968
MixupTrain:  epoch  0, batch   768 | loss: 2.2895789
MixupTrain:  epoch  0, batch   769 | loss: 2.4847999
MixupTrain:  epoch  0, batch   770 | loss: 2.4087729
MixupTrain:  epoch  0, batch   771 | loss: 2.4015360
MixupTrain:  epoch  0, batch   772 | loss: 2.2243752
MixupTrain:  epoch  0, batch   773 | loss: 2.5053656
MixupTrain:  epoch  0, batch   774 | loss: 2.4506197
MixupTrain:  epoch  0, batch   775 | loss: 2.2222762
MixupTrain:  epoch  0, batch   776 | loss: 2.7365060
MixupTrain:  epoch  0, batch   777 | loss: 2.1957839
MixupTrain:  epoch  0, batch   778 | loss: 2.1829627
MixupTrain:  epoch  0, batch   779 | loss: 2.3910038
MixupTrain:  epoch  0, batch   780 | loss: 2.4376116
MixupTrain:  epoch  0, batch   781 | loss: 2.2506795
MixupTrain:  epoch  0, batch   782 | loss: 2.2383590
MixupTrain:  epoch  0, batch   783 | loss: 2.2061827
MixupTrain:  epoch  0, batch   784 | loss: 2.1340220
MixupTrain:  epoch  0, batch   785 | loss: 2.2860003
MixupTrain:  epoch  0, batch   786 | loss: 2.3554950
MixupTrain:  epoch  0, batch   787 | loss: 2.1165891
MixupTrain:  epoch  0, batch   788 | loss: 2.2355061
MixupTrain:  epoch  0, batch   789 | loss: 2.1767712
MixupTrain:  epoch  0, batch   790 | loss: 2.2234600
MixupTrain:  epoch  0, batch   791 | loss: 2.3134394
MixupTrain:  epoch  0, batch   792 | loss: 2.3361502
MixupTrain:  epoch  0, batch   793 | loss: 2.3661628
MixupTrain:  epoch  0, batch   794 | loss: 2.5470800
MixupTrain:  epoch  0, batch   795 | loss: 2.1782033
MixupTrain:  epoch  0, batch   796 | loss: 2.2526941
MixupTrain:  epoch  0, batch   797 | loss: 2.0974655
MixupTrain:  epoch  0, batch   798 | loss: 2.2523513
MixupTrain:  epoch  0, batch   799 | loss: 2.3023179
MixupTrain:  epoch  0, batch   800 | loss: 2.5234184
MixupTrain:  epoch  0, batch   801 | loss: 2.2428493
MixupTrain:  epoch  0, batch   802 | loss: 2.3401513
MixupTrain:  epoch  0, batch   803 | loss: 1.9772354
MixupTrain:  epoch  0, batch   804 | loss: 2.0409858
MixupTrain:  epoch  0, batch   805 | loss: 2.1187110
MixupTrain:  epoch  0, batch   806 | loss: 2.1572034
MixupTrain:  epoch  0, batch   807 | loss: 2.3126884
MixupTrain:  epoch  0, batch   808 | loss: 2.5093684
MixupTrain:  epoch  0, batch   809 | loss: 2.2485173
MixupTrain:  epoch  0, batch   810 | loss: 2.5504282
MixupTrain:  epoch  0, batch   811 | loss: 2.4061260
MixupTrain:  epoch  0, batch   812 | loss: 2.3361845
MixupTrain:  epoch  0, batch   813 | loss: 2.4817669
MixupTrain:  epoch  0, batch   814 | loss: 2.4031274
MixupTrain:  epoch  0, batch   815 | loss: 2.1579037
MixupTrain:  epoch  0, batch   816 | loss: 2.2435338
MixupTrain:  epoch  0, batch   817 | loss: 2.2868793
MixupTrain:  epoch  0, batch   818 | loss: 2.1047442
MixupTrain:  epoch  0, batch   819 | loss: 2.2815099
MixupTrain:  epoch  0, batch   820 | loss: 2.0934730
MixupTrain:  epoch  0, batch   821 | loss: 2.4205766
MixupTrain:  epoch  0, batch   822 | loss: 2.2739835
MixupTrain:  epoch  0, batch   823 | loss: 2.0699635
MixupTrain:  epoch  0, batch   824 | loss: 2.3801837
MixupTrain:  epoch  0, batch   825 | loss: 2.4257636
MixupTrain:  epoch  0, batch   826 | loss: 2.3083682
MixupTrain:  epoch  0, batch   827 | loss: 2.2702365
MixupTrain:  epoch  0, batch   828 | loss: 2.5062141
MixupTrain:  epoch  0, batch   829 | loss: 2.0053427
MixupTrain:  epoch  0, batch   830 | loss: 2.5309241
MixupTrain:  epoch  0, batch   831 | loss: 2.3125277
MixupTrain:  epoch  0, batch   832 | loss: 2.4302754
MixupTrain:  epoch  0, batch   833 | loss: 2.2082860
MixupTrain:  epoch  0, batch   834 | loss: 2.2043567
MixupTrain:  epoch  0, batch   835 | loss: 2.2116318
MixupTrain:  epoch  0, batch   836 | loss: 2.2414436
MixupTrain:  epoch  0, batch   837 | loss: 2.2084739
MixupTrain:  epoch  0, batch   838 | loss: 2.2401061
MixupTrain:  epoch  0, batch   839 | loss: 2.3166227
MixupTrain:  epoch  0, batch   840 | loss: 2.3147507
MixupTrain:  epoch  0, batch   841 | loss: 2.4404998
MixupTrain:  epoch  0, batch   842 | loss: 2.2080650
MixupTrain:  epoch  0, batch   843 | loss: 2.5247638
MixupTrain:  epoch  0, batch   844 | loss: 2.4504366
MixupTrain:  epoch  0, batch   845 | loss: 2.2514813
MixupTrain:  epoch  0, batch   846 | loss: 2.2022614
MixupTrain:  epoch  0, batch   847 | loss: 2.3018918
MixupTrain:  epoch  0, batch   848 | loss: 2.0507941
MixupTrain:  epoch  0, batch   849 | loss: 2.2331858
MixupTrain:  epoch  0, batch   850 | loss: 2.2150216
MixupTrain:  epoch  0, batch   851 | loss: 2.4330785
MixupTrain:  epoch  0, batch   852 | loss: 2.0166821
MixupTrain:  epoch  0, batch   853 | loss: 2.3574960
MixupTrain:  epoch  0, batch   854 | loss: 2.3407874
MixupTrain:  epoch  0, batch   855 | loss: 2.2343953
MixupTrain:  epoch  0, batch   856 | loss: 2.3104231
MixupTrain:  epoch  0, batch   857 | loss: 2.4981267
MixupTrain:  epoch  0, batch   858 | loss: 2.3788886
MixupTrain:  epoch  0, batch   859 | loss: 2.2371650
MixupTrain:  epoch  0, batch   860 | loss: 2.1741190
MixupTrain:  epoch  0, batch   861 | loss: 2.3877249
MixupTrain:  epoch  0, batch   862 | loss: 2.1936340
MixupTrain:  epoch  0, batch   863 | loss: 2.4911895
MixupTrain:  epoch  0, batch   864 | loss: 2.4921217
MixupTrain:  epoch  0, batch   865 | loss: 2.5053689
MixupTrain:  epoch  0, batch   866 | loss: 2.0155077
MixupTrain:  epoch  0, batch   867 | loss: 2.1794403
MixupTrain:  epoch  0, batch   868 | loss: 2.3283262
MixupTrain:  epoch  0, batch   869 | loss: 2.2724688
MixupTrain:  epoch  0, batch   870 | loss: 2.2780735
MixupTrain:  epoch  0, batch   871 | loss: 2.2834752
MixupTrain:  epoch  0, batch   872 | loss: 2.1040077
MixupTrain:  epoch  0, batch   873 | loss: 2.4741523
MixupTrain:  epoch  0, batch   874 | loss: 2.1442864
MixupTrain:  epoch  0, batch   875 | loss: 2.7385306
MixupTrain:  epoch  0, batch   876 | loss: 2.4279618
MixupTrain:  epoch  0, batch   877 | loss: 2.6907787
MixupTrain:  epoch  0, batch   878 | loss: 2.1886454
MixupTrain:  epoch  0, batch   879 | loss: 2.1999691
MixupTrain:  epoch  0, batch   880 | loss: 2.5525370
MixupTrain:  epoch  0, batch   881 | loss: 2.1082273
MixupTrain:  epoch  0, batch   882 | loss: 2.3091192
MixupTrain:  epoch  0, batch   883 | loss: 2.1747918
MixupTrain:  epoch  0, batch   884 | loss: 2.1713891
MixupTrain:  epoch  0, batch   885 | loss: 2.2359488
MixupTrain:  epoch  0, batch   886 | loss: 2.2794302
MixupTrain:  epoch  0, batch   887 | loss: 2.4568672
MixupTrain:  epoch  0, batch   888 | loss: 2.1683950
MixupTrain:  epoch  0, batch   889 | loss: 2.0812531
MixupTrain:  epoch  0, batch   890 | loss: 2.1798198
MixupTrain:  epoch  0, batch   891 | loss: 2.3356781
MixupTrain:  epoch  0, batch   892 | loss: 2.3836951
MixupTrain:  epoch  0, batch   893 | loss: 2.2148421
MixupTrain:  epoch  0, batch   894 | loss: 2.3983836
MixupTrain:  epoch  0, batch   895 | loss: 2.1287315
MixupTrain:  epoch  0, batch   896 | loss: 2.4137077
MixupTrain:  epoch  0, batch   897 | loss: 2.2036924
MixupTrain:  epoch  0, batch   898 | loss: 2.4052827
MixupTrain:  epoch  0, batch   899 | loss: 2.2734494
MixupTrain:  epoch  0, batch   900 | loss: 2.3489428
MixupTrain:  epoch  0, batch   901 | loss: 2.2968276
MixupTrain:  epoch  0, batch   902 | loss: 2.1439559
MixupTrain:  epoch  0, batch   903 | loss: 2.1786246
MixupTrain:  epoch  0, batch   904 | loss: 2.2427814
MixupTrain:  epoch  0, batch   905 | loss: 2.3887987
MixupTrain:  epoch  0, batch   906 | loss: 2.2666922
MixupTrain:  epoch  0, batch   907 | loss: 2.1712997
MixupTrain:  epoch  0, batch   908 | loss: 2.4074469
MixupTrain:  epoch  0, batch   909 | loss: 2.2371230
MixupTrain:  epoch  0, batch   910 | loss: 2.3314466
MixupTrain:  epoch  0, batch   911 | loss: 2.3181112
MixupTrain:  epoch  0, batch   912 | loss: 2.1334226
MixupTrain:  epoch  0, batch   913 | loss: 2.3163314
MixupTrain:  epoch  0, batch   914 | loss: 2.4003115
MixupTrain:  epoch  0, batch   915 | loss: 2.4550433
MixupTrain:  epoch  0, batch   916 | loss: 2.2471716
MixupTrain:  epoch  0, batch   917 | loss: 2.4110541
MixupTrain:  epoch  0, batch   918 | loss: 2.2081430
MixupTrain:  epoch  0, batch   919 | loss: 2.1862981
MixupTrain:  epoch  0, batch   920 | loss: 2.1345866
MixupTrain:  epoch  0, batch   921 | loss: 2.7025905
MixupTrain:  epoch  0, batch   922 | loss: 2.3607602
MixupTrain:  epoch  0, batch   923 | loss: 2.3426921
MixupTrain:  epoch  0, batch   924 | loss: 2.2438827
MixupTrain:  epoch  0, batch   925 | loss: 2.2442861
MixupTrain:  epoch  0, batch   926 | loss: 2.2282844
MixupTrain:  epoch  0, batch   927 | loss: 2.3875895
MixupTrain:  epoch  0, batch   928 | loss: 2.1590564
MixupTrain:  epoch  0, batch   929 | loss: 2.3417971
MixupTrain:  epoch  0, batch   930 | loss: 2.5416269
MixupTrain:  epoch  0, batch   931 | loss: 2.1804218
MixupTrain:  epoch  0, batch   932 | loss: 2.4758325
MixupTrain:  epoch  0, batch   933 | loss: 2.1973290
MixupTrain:  epoch  0, batch   934 | loss: 2.1578712
MixupTrain:  epoch  0, batch   935 | loss: 2.2664175
MixupTrain:  epoch  0, batch   936 | loss: 2.0805349
MixupTrain:  epoch  0, batch   937 | loss: 2.3584270
MixupTrain:  epoch  0, batch   938 | loss: 2.1892695
MixupTrain:  epoch  0, batch   939 | loss: 2.2247028
MixupTrain:  epoch  0, batch   940 | loss: 2.4880581
MixupTrain:  epoch  0, batch   941 | loss: 2.2707500
MixupTrain:  epoch  0, batch   942 | loss: 2.1904635
MixupTrain:  epoch  0, batch   943 | loss: 2.1851165
MixupTrain:  epoch  0, batch   944 | loss: 2.3877115
MixupTrain:  epoch  0, batch   945 | loss: 2.0159125
MixupTrain:  epoch  0, batch   946 | loss: 2.1000669
MixupTrain:  epoch  0, batch   947 | loss: 2.2961535
MixupTrain:  epoch  0, batch   948 | loss: 2.0529165
MixupTrain:  epoch  0, batch   949 | loss: 2.0016346
MixupTrain:  epoch  0, batch   950 | loss: 2.4109001
MixupTrain:  epoch  0, batch   951 | loss: 2.2918968
MixupTrain:  epoch  0, batch   952 | loss: 2.1776810
MixupTrain:  epoch  0, batch   953 | loss: 2.5718498
MixupTrain:  epoch  0, batch   954 | loss: 2.1319687
MixupTrain:  epoch  0, batch   955 | loss: 2.2731633
MixupTrain:  epoch  0, batch   956 | loss: 2.2391415
MixupTrain:  epoch  0, batch   957 | loss: 2.2081571
MixupTrain:  epoch  0, batch   958 | loss: 2.0045798
MixupTrain:  epoch  0, batch   959 | loss: 2.1391311
MixupTrain:  epoch  0, batch   960 | loss: 2.2939825
MixupTrain:  epoch  0, batch   961 | loss: 2.0276468
MixupTrain:  epoch  0, batch   962 | loss: 2.4219508
MixupTrain:  epoch  0, batch   963 | loss: 2.4858181
MixupTrain:  epoch  0, batch   964 | loss: 2.0281801
MixupTrain:  epoch  0, batch   965 | loss: 2.1842217
MixupTrain:  epoch  0, batch   966 | loss: 2.0387108
MixupTrain:  epoch  0, batch   967 | loss: 2.3478751
MixupTrain:  epoch  0, batch   968 | loss: 2.6141210
MixupTrain:  epoch  0, batch   969 | loss: 2.2018096
MixupTrain:  epoch  0, batch   970 | loss: 2.4258170
MixupTrain:  epoch  0, batch   971 | loss: 2.1000051
MixupTrain:  epoch  0, batch   972 | loss: 2.2730231
MixupTrain:  epoch  0, batch   973 | loss: 2.2923002
MixupTrain:  epoch  0, batch   974 | loss: 2.3486309
MixupTrain:  epoch  0, batch   975 | loss: 2.0894775
MixupTrain:  epoch  0, batch   976 | loss: 2.1624823
MixupTrain:  epoch  0, batch   977 | loss: 2.3144085
MixupTrain:  epoch  0, batch   978 | loss: 2.4185157
MixupTrain:  epoch  0, batch   979 | loss: 2.5149951
MixupTrain:  epoch  0, batch   980 | loss: 2.2479215
MixupTrain:  epoch  0, batch   981 | loss: 2.3516293
MixupTrain:  epoch  0, batch   982 | loss: 2.0646932
MixupTrain:  epoch  0, batch   983 | loss: 2.0547924
MixupTrain:  epoch  0, batch   984 | loss: 1.9860742
MixupTrain:  epoch  0, batch   985 | loss: 2.2083092
MixupTrain:  epoch  0, batch   986 | loss: 2.4372485
MixupTrain:  epoch  0, batch   987 | loss: 2.1672466
MixupTrain:  epoch  0, batch   988 | loss: 2.2713752
MixupTrain:  epoch  0, batch   989 | loss: 2.3002896
MixupTrain:  epoch  0, batch   990 | loss: 2.0389214
MixupTrain:  epoch  0, batch   991 | loss: 2.1805792
MixupTrain:  epoch  0, batch   992 | loss: 2.3382516
MixupTrain:  epoch  0, batch   993 | loss: 2.3620532
MixupTrain:  epoch  0, batch   994 | loss: 2.2006063
MixupTrain:  epoch  0, batch   995 | loss: 2.4408715
MixupTrain:  epoch  0, batch   996 | loss: 2.4249070
MixupTrain:  epoch  0, batch   997 | loss: 2.2967787
MixupTrain:  epoch  0, batch   998 | loss: 2.0987585
MixupTrain:  epoch  0, batch   999 | loss: 2.2359269
MixupTrain:  epoch  0, batch  1000 | loss: 2.0602956
MixupTrain:  epoch  0, batch  1001 | loss: 2.3823731
MixupTrain:  epoch  0, batch  1002 | loss: 2.0888419
MixupTrain:  epoch  0, batch  1003 | loss: 2.5332506
MixupTrain:  epoch  0, batch  1004 | loss: 2.3589916
MixupTrain:  epoch  0, batch  1005 | loss: 2.2996476
MixupTrain:  epoch  0, batch  1006 | loss: 2.2873774
MixupTrain:  epoch  0, batch  1007 | loss: 2.2052577
MixupTrain:  epoch  0, batch  1008 | loss: 2.2363224
MixupTrain:  epoch  0, batch  1009 | loss: 2.4578428
MixupTrain:  epoch  0, batch  1010 | loss: 2.2136388
MixupTrain:  epoch  0, batch  1011 | loss: 2.2044010
MixupTrain:  epoch  0, batch  1012 | loss: 2.3330352
MixupTrain:  epoch  0, batch  1013 | loss: 2.1839943
MixupTrain:  epoch  0, batch  1014 | loss: 2.0213196
MixupTrain:  epoch  0, batch  1015 | loss: 2.4393179
MixupTrain:  epoch  0, batch  1016 | loss: 2.4190097
MixupTrain:  epoch  0, batch  1017 | loss: 2.1836998
MixupTrain:  epoch  0, batch  1018 | loss: 2.5328805
MixupTrain:  epoch  0, batch  1019 | loss: 2.3814740
MixupTrain:  epoch  0, batch  1020 | loss: 2.0885980
MixupTrain:  epoch  0, batch  1021 | loss: 2.3408537
MixupTrain:  epoch  0, batch  1022 | loss: 2.2868104
MixupTrain:  epoch  0, batch  1023 | loss: 2.4251225
MixupTrain:  epoch  0, batch  1024 | loss: 2.1749461
MixupTrain:  epoch  0, batch  1025 | loss: 2.2238481
MixupTrain:  epoch  0, batch  1026 | loss: 2.3060014
MixupTrain:  epoch  0, batch  1027 | loss: 2.1996682
MixupTrain:  epoch  0, batch  1028 | loss: 2.4318147
MixupTrain:  epoch  0, batch  1029 | loss: 2.4581466
MixupTrain:  epoch  0, batch  1030 | loss: 2.2241721
MixupTrain:  epoch  0, batch  1031 | loss: 2.3984995
MixupTrain:  epoch  0, batch  1032 | loss: 1.9950643
MixupTrain:  epoch  0, batch  1033 | loss: 2.2374213
MixupTrain:  epoch  0, batch  1034 | loss: 2.3701639
MixupTrain:  epoch  0, batch  1035 | loss: 2.1222601
MixupTrain:  epoch  0, batch  1036 | loss: 2.3280020
MixupTrain:  epoch  0, batch  1037 | loss: 2.3673639
MixupTrain:  epoch  0, batch  1038 | loss: 2.1428585
MixupTrain:  epoch  0, batch  1039 | loss: 2.3582649
MixupTrain:  epoch  0, batch  1040 | loss: 2.5459456
MixupTrain:  epoch  0, batch  1041 | loss: 2.2114940
MixupTrain:  epoch  0, batch  1042 | loss: 2.2561219
MixupTrain:  epoch  0, batch  1043 | loss: 2.4111080
MixupTrain:  epoch  0, batch  1044 | loss: 2.3381052
MixupTrain:  epoch  0, batch  1045 | loss: 2.5189400
MixupTrain:  epoch  0, batch  1046 | loss: 2.3560615
MixupTrain:  epoch  0, batch  1047 | loss: 2.2931218
MixupTrain:  epoch  0, batch  1048 | loss: 2.3036363
MixupTrain:  epoch  0, batch  1049 | loss: 1.9993582
MixupTrain:  epoch  0, batch  1050 | loss: 2.2907755
MixupTrain:  epoch  0, batch  1051 | loss: 2.2384603
MixupTrain:  epoch  0, batch  1052 | loss: 2.3446603
MixupTrain:  epoch  0, batch  1053 | loss: 2.1774099
MixupTrain:  epoch  0, batch  1054 | loss: 2.3446107
MixupTrain:  epoch  0, batch  1055 | loss: 2.3080692
MixupTrain:  epoch  0, batch  1056 | loss: 2.1959338
MixupTrain:  epoch  0, batch  1057 | loss: 2.4422050
MixupTrain:  epoch  0, batch  1058 | loss: 2.1666503
MixupTrain:  epoch  0, batch  1059 | loss: 2.4103508
MixupTrain:  epoch  0, batch  1060 | loss: 2.0953853
MixupTrain:  epoch  0, batch  1061 | loss: 2.0409200
MixupTrain:  epoch  0, batch  1062 | loss: 2.3209238
MixupTrain:  epoch  0, batch  1063 | loss: 2.6643004
MixupTrain:  epoch  0, batch  1064 | loss: 2.2199240
MixupTrain:  epoch  0, batch  1065 | loss: 2.3489790
MixupTrain:  epoch  0, batch  1066 | loss: 2.3672199
MixupTrain:  epoch  0, batch  1067 | loss: 2.2540381
MixupTrain:  epoch  0, batch  1068 | loss: 2.2304459
MixupTrain:  epoch  0, batch  1069 | loss: 2.2783856
MixupTrain:  epoch  0, batch  1070 | loss: 2.2950640
MixupTrain:  epoch  0, batch  1071 | loss: 2.3635640
MixupTrain:  epoch  0, batch  1072 | loss: 2.4343691
MixupTrain:  epoch  0, batch  1073 | loss: 2.2422295
MixupTrain:  epoch  0, batch  1074 | loss: 2.2078533
MixupTrain:  epoch  0, batch  1075 | loss: 2.3288479
MixupTrain:  epoch  0, batch  1076 | loss: 2.1273024
MixupTrain:  epoch  0, batch  1077 | loss: 2.0476031
MixupTrain:  epoch  0, batch  1078 | loss: 2.4208422
MixupTrain:  epoch  0, batch  1079 | loss: 2.4477451
MixupTrain:  epoch  0, batch  1080 | loss: 2.6077366
MixupTrain:  epoch  0, batch  1081 | loss: 2.5186911
MixupTrain:  epoch  0, batch  1082 | loss: 2.5085990
MixupTrain:  epoch  0, batch  1083 | loss: 2.0082812
MixupTrain:  epoch  0, batch  1084 | loss: 2.6557021
MixupTrain:  epoch  0, batch  1085 | loss: 2.5149946
MixupTrain:  epoch  0, batch  1086 | loss: 2.1339436
MixupTrain:  epoch  0, batch  1087 | loss: 2.7167768
MixupTrain:  epoch  0, batch  1088 | loss: 2.0114264
MixupTrain:  epoch  0, batch  1089 | loss: 2.3741755
MixupTrain:  epoch  0, batch  1090 | loss: 2.0764248
MixupTrain:  epoch  0, batch  1091 | loss: 2.3119147
MixupTrain:  epoch  0, batch  1092 | loss: 2.0570450
MixupTrain:  epoch  0, batch  1093 | loss: 2.3208580
MixupTrain:  epoch  0, batch  1094 | loss: 2.0551453
MixupTrain:  epoch  0, batch  1095 | loss: 2.1355498
MixupTrain:  epoch  0, batch  1096 | loss: 2.2837973
MixupTrain:  epoch  0, batch  1097 | loss: 2.3567641
MixupTrain:  epoch  0, batch  1098 | loss: 2.2002668
MixupTrain:  epoch  0, batch  1099 | loss: 2.3452954
MixupTrain:  epoch  0, batch  1100 | loss: 2.2653954
MixupTrain:  epoch  0, batch  1101 | loss: 2.3813632
MixupTrain:  epoch  0, batch  1102 | loss: 2.2378855
MixupTrain:  epoch  0, batch  1103 | loss: 2.2684541
MixupTrain:  epoch  0, batch  1104 | loss: 2.3889894
MixupTrain:  epoch  0, batch  1105 | loss: 2.3190358
MixupTrain:  epoch  0, batch  1106 | loss: 2.2431972
MixupTrain:  epoch  0, batch  1107 | loss: 2.4934313
MixupTrain:  epoch  0, batch  1108 | loss: 2.2802322
MixupTrain:  epoch  0, batch  1109 | loss: 2.3909726
MixupTrain:  epoch  0, batch  1110 | loss: 2.2859106
MixupTrain:  epoch  0, batch  1111 | loss: 2.1576343
MixupTrain:  epoch  0, batch  1112 | loss: 2.2973514
MixupTrain:  epoch  0, batch  1113 | loss: 2.1557622
MixupTrain:  epoch  0, batch  1114 | loss: 2.1349001
MixupTrain:  epoch  0, batch  1115 | loss: 2.3162413
MixupTrain:  epoch  0, batch  1116 | loss: 2.3728652
MixupTrain:  epoch  0, batch  1117 | loss: 2.3276398
MixupTrain:  epoch  0, batch  1118 | loss: 2.2972414
MixupTrain:  epoch  0, batch  1119 | loss: 2.2483239
MixupTrain:  epoch  0, batch  1120 | loss: 1.9931271
MixupTrain:  epoch  0, batch  1121 | loss: 2.2071466
MixupTrain:  epoch  0, batch  1122 | loss: 2.5154047
MixupTrain:  epoch  0, batch  1123 | loss: 2.3305945
MixupTrain:  epoch  0, batch  1124 | loss: 2.4994321
MixupTrain:  epoch  0, batch  1125 | loss: 2.4364364
MixupTrain:  epoch  0, batch  1126 | loss: 2.2505777
MixupTrain:  epoch  0, batch  1127 | loss: 2.3373451
MixupTrain:  epoch  0, batch  1128 | loss: 2.3050985
MixupTrain:  epoch  0, batch  1129 | loss: 2.2619157
MixupTrain:  epoch  0, batch  1130 | loss: 2.2889986
MixupTrain:  epoch  0, batch  1131 | loss: 2.3164725
MixupTrain:  epoch  0, batch  1132 | loss: 2.3258562
MixupTrain:  epoch  0, batch  1133 | loss: 2.1869383
MixupTrain:  epoch  0, batch  1134 | loss: 2.1602921
MixupTrain:  epoch  0, batch  1135 | loss: 2.1339221
MixupTrain:  epoch  0, batch  1136 | loss: 2.3419151
MixupTrain:  epoch  0, batch  1137 | loss: 2.3798003
MixupTrain:  epoch  0, batch  1138 | loss: 2.3181591
MixupTrain:  epoch  0, batch  1139 | loss: 2.2636757
MixupTrain:  epoch  0, batch  1140 | loss: 2.2098732
MixupTrain:  epoch  0, batch  1141 | loss: 2.1038709
MixupTrain:  epoch  0, batch  1142 | loss: 2.5744867
MixupTrain:  epoch  0, batch  1143 | loss: 2.2996702
MixupTrain:  epoch  0, batch  1144 | loss: 2.2507181
MixupTrain:  epoch  0, batch  1145 | loss: 2.5469894
MixupTrain:  epoch  0, batch  1146 | loss: 2.1134224
MixupTrain:  epoch  0, batch  1147 | loss: 2.5819092
MixupTrain:  epoch  0, batch  1148 | loss: 2.0387764
MixupTrain:  epoch  0, batch  1149 | loss: 2.4639180
MixupTrain:  epoch  0, batch  1150 | loss: 2.3626337
MixupTrain:  epoch  0, batch  1151 | loss: 2.3952231
MixupTrain:  epoch  0, batch  1152 | loss: 2.1161525
MixupTrain:  epoch  0, batch  1153 | loss: 2.5279238
MixupTrain:  epoch  0, batch  1154 | loss: 2.0199928
MixupTrain:  epoch  0, batch  1155 | loss: 2.6238687
MixupTrain:  epoch  0, batch  1156 | loss: 1.9972301
MixupTrain:  epoch  0, batch  1157 | loss: 2.2835832
MixupTrain:  epoch  0, batch  1158 | loss: 2.2214856
MixupTrain:  epoch  0, batch  1159 | loss: 2.1581352
MixupTrain:  epoch  0, batch  1160 | loss: 2.0646524
MixupTrain:  epoch  0, batch  1161 | loss: 2.5437589
MixupTrain:  epoch  0, batch  1162 | loss: 2.2104332
MixupTrain:  epoch  0, batch  1163 | loss: 2.2019639
MixupTrain:  epoch  0, batch  1164 | loss: 2.3218839
MixupTrain:  epoch  0, batch  1165 | loss: 2.3530488
MixupTrain:  epoch  0, batch  1166 | loss: 2.1797342
MixupTrain:  epoch  0, batch  1167 | loss: 2.5854723
MixupTrain:  epoch  0, batch  1168 | loss: 2.4803462
MixupTrain:  epoch  0, batch  1169 | loss: 1.9715421
MixupTrain:  epoch  0, batch  1170 | loss: 2.2545180
MixupTrain:  epoch  0, batch  1171 | loss: 2.3021545
MixupTrain:  epoch  0, batch  1172 | loss: 2.1942832
MixupTrain:  epoch  0, batch  1173 | loss: 2.3927112
MixupTrain:  epoch  0, batch  1174 | loss: 2.1640410
MixupTrain:  epoch  0, batch  1175 | loss: 2.2645745
MixupTrain:  epoch  0, batch  1176 | loss: 2.4387128
MixupTrain:  epoch  0, batch  1177 | loss: 2.2699633
MixupTrain:  epoch  0, batch  1178 | loss: 2.4250805
MixupTrain:  epoch  0, batch  1179 | loss: 2.4458172
MixupTrain:  epoch  0, batch  1180 | loss: 1.9957416
MixupTrain:  epoch  0, batch  1181 | loss: 2.2573886
MixupTrain:  epoch  0, batch  1182 | loss: 2.2477665
MixupTrain:  epoch  0, batch  1183 | loss: 2.2924094
MixupTrain:  epoch  0, batch  1184 | loss: 2.5248773
MixupTrain:  epoch  0, batch  1185 | loss: 2.1734042
MixupTrain:  epoch  0, batch  1186 | loss: 2.0564594
MixupTrain:  epoch  0, batch  1187 | loss: 2.1562769
MixupTrain:  epoch  0, batch  1188 | loss: 2.3523865
MixupTrain:  epoch  0, batch  1189 | loss: 2.4250226
MixupTrain:  epoch  0, batch  1190 | loss: 2.2286043
MixupTrain:  epoch  0, batch  1191 | loss: 2.3549180
MixupTrain:  epoch  0, batch  1192 | loss: 2.2738333
MixupTrain:  epoch  0, batch  1193 | loss: 2.1149573
MixupTrain:  epoch  0, batch  1194 | loss: 2.3546901
MixupTrain:  epoch  0, batch  1195 | loss: 2.1499715
MixupTrain:  epoch  0, batch  1196 | loss: 2.2353048
MixupTrain:  epoch  0, batch  1197 | loss: 2.4334822
MixupTrain:  epoch  0, batch  1198 | loss: 1.9882505
MixupTrain:  epoch  0, batch  1199 | loss: 1.9759318
MixupTrain:  epoch  0, batch  1200 | loss: 2.2242124
MixupTrain:  epoch  0, batch  1201 | loss: 2.2116218
MixupTrain:  epoch  0, batch  1202 | loss: 2.3046446
MixupTrain:  epoch  0, batch  1203 | loss: 2.0045028
MixupTrain:  epoch  0, batch  1204 | loss: 2.2560723
MixupTrain:  epoch  0, batch  1205 | loss: 2.0767899
MixupTrain:  epoch  0, batch  1206 | loss: 2.2172515
MixupTrain:  epoch  0, batch  1207 | loss: 2.3271334
MixupTrain:  epoch  0, batch  1208 | loss: 2.4557846
MixupTrain:  epoch  0, batch  1209 | loss: 2.1960378
MixupTrain:  epoch  0, batch  1210 | loss: 2.0036578
MixupTrain:  epoch  0, batch  1211 | loss: 2.5443640
MixupTrain:  epoch  0, batch  1212 | loss: 2.3513241
MixupTrain:  epoch  0, batch  1213 | loss: 2.3089967
MixupTrain:  epoch  0, batch  1214 | loss: 2.1680450
MixupTrain:  epoch  0, batch  1215 | loss: 2.1345804
MixupTrain:  epoch  0, batch  1216 | loss: 2.3777895
MixupTrain:  epoch  0, batch  1217 | loss: 2.0292468
MixupTrain:  epoch  0, batch  1218 | loss: 2.2195988
MixupTrain:  epoch  0, batch  1219 | loss: 2.2266569
MixupTrain:  epoch  0, batch  1220 | loss: 2.2012150
MixupTrain:  epoch  0, batch  1221 | loss: 2.3472223
MixupTrain:  epoch  0, batch  1222 | loss: 2.2512617
MixupTrain:  epoch  0, batch  1223 | loss: 2.1237965
MixupTrain:  epoch  0, batch  1224 | loss: 2.2778466
MixupTrain:  epoch  0, batch  1225 | loss: 2.2711079
MixupTrain:  epoch  0, batch  1226 | loss: 2.1215844
MixupTrain:  epoch  0, batch  1227 | loss: 2.1511230
MixupTrain:  epoch  0, batch  1228 | loss: 2.1581049
MixupTrain:  epoch  0, batch  1229 | loss: 2.3101335
MixupTrain:  epoch  0, batch  1230 | loss: 2.2005978
MixupTrain:  epoch  0, batch  1231 | loss: 2.2930298
MixupTrain:  epoch  0, batch  1232 | loss: 2.3388386
MixupTrain:  epoch  0, batch  1233 | loss: 2.2550454
MixupTrain:  epoch  0, batch  1234 | loss: 2.1450765
MixupTrain:  epoch  0, batch  1235 | loss: 2.2819357
MixupTrain:  epoch  0, batch  1236 | loss: 2.2550521
MixupTrain:  epoch  0, batch  1237 | loss: 2.2490363
MixupTrain:  epoch  0, batch  1238 | loss: 2.1234581
MixupTrain:  epoch  0, batch  1239 | loss: 2.4303260
MixupTrain:  epoch  0, batch  1240 | loss: 2.1530423
MixupTrain:  epoch  0, batch  1241 | loss: 2.1203849
MixupTrain:  epoch  0, batch  1242 | loss: 2.1420360
MixupTrain:  epoch  0, batch  1243 | loss: 2.3444190
MixupTrain:  epoch  0, batch  1244 | loss: 2.3960714
MixupTrain:  epoch  0, batch  1245 | loss: 2.1347613
MixupTrain:  epoch  0, batch  1246 | loss: 2.4327195
MixupTrain:  epoch  0, batch  1247 | loss: 2.2431369
MixupTrain:  epoch  0, batch  1248 | loss: 2.3554914
MixupTrain:  epoch  0, batch  1249 | loss: 2.1156392
MixupTrain:  epoch  0, batch  1250 | loss: 2.3965931
MixupTrain:  epoch  0, batch  1251 | loss: 2.1562023
MixupTrain:  epoch  0, batch  1252 | loss: 2.3260953
MixupTrain:  epoch  0, batch  1253 | loss: 2.2926054
MixupTrain:  epoch  0, batch  1254 | loss: 2.2008739
MixupTrain:  epoch  0, batch  1255 | loss: 2.3417656
MixupTrain:  epoch  0, batch  1256 | loss: 2.2793722
MixupTrain:  epoch  0, batch  1257 | loss: 2.4989254
MixupTrain:  epoch  0, batch  1258 | loss: 2.4567928
MixupTrain:  epoch  0, batch  1259 | loss: 2.3185396
MixupTrain:  epoch  0, batch  1260 | loss: 2.2311883
MixupTrain:  epoch  0, batch  1261 | loss: 2.2909675
MixupTrain:  epoch  0, batch  1262 | loss: 2.4090810
MixupTrain:  epoch  0, batch  1263 | loss: 2.1837053
MixupTrain:  epoch  0, batch  1264 | loss: 2.2085276
MixupTrain:  epoch  0, batch  1265 | loss: 2.2821553
MixupTrain:  epoch  0, batch  1266 | loss: 2.4612374
MixupTrain:  epoch  0, batch  1267 | loss: 2.2318764
MixupTrain:  epoch  0, batch  1268 | loss: 2.1153886
MixupTrain:  epoch  0, batch  1269 | loss: 2.3954840
MixupTrain:  epoch  0, batch  1270 | loss: 2.3999872
MixupTrain:  epoch  0, batch  1271 | loss: 2.1159296
MixupTrain:  epoch  0, batch  1272 | loss: 2.4991243
MixupTrain:  epoch  0, batch  1273 | loss: 2.2696354
MixupTrain:  epoch  0, batch  1274 | loss: 2.6422932
MixupTrain:  epoch  0, batch  1275 | loss: 2.1736648
MixupTrain:  epoch  0, batch  1276 | loss: 2.4532166
MixupTrain:  epoch  0, batch  1277 | loss: 2.1891787
MixupTrain:  epoch  0, batch  1278 | loss: 2.1870809
MixupTrain:  epoch  0, batch  1279 | loss: 2.2104254
MixupTrain:  epoch  0, batch  1280 | loss: 2.6355715
MixupTrain:  epoch  0, batch  1281 | loss: 2.3434453
MixupTrain:  epoch  0, batch  1282 | loss: 2.1809731
MixupTrain:  epoch  0, batch  1283 | loss: 2.5279346
MixupTrain:  epoch  0, batch  1284 | loss: 2.3874571
MixupTrain:  epoch  0, batch  1285 | loss: 2.2336826
MixupTrain:  epoch  0, batch  1286 | loss: 2.4330578
MixupTrain:  epoch  0, batch  1287 | loss: 2.2819171
MixupTrain:  epoch  0, batch  1288 | loss: 2.2712746
MixupTrain:  epoch  0, batch  1289 | loss: 2.3736792
MixupTrain:  epoch  0, batch  1290 | loss: 2.3179998
MixupTrain:  epoch  0, batch  1291 | loss: 2.2376413
MixupTrain:  epoch  0, batch  1292 | loss: 2.1235499
MixupTrain:  epoch  0, batch  1293 | loss: 2.2730494
MixupTrain:  epoch  0, batch  1294 | loss: 2.2212279
MixupTrain:  epoch  0, batch  1295 | loss: 2.3295641
MixupTrain:  epoch  0, batch  1296 | loss: 2.1856127
MixupTrain:  epoch  0, batch  1297 | loss: 2.5895991
MixupTrain:  epoch  0, batch  1298 | loss: 2.3622365
MixupTrain:  epoch  0, batch  1299 | loss: 2.1987877
MixupTrain:  epoch  0, batch  1300 | loss: 2.3408527
MixupTrain:  epoch  0, batch  1301 | loss: 2.2556059
MixupTrain:  epoch  0, batch  1302 | loss: 2.4592400
MixupTrain:  epoch  0, batch  1303 | loss: 2.4622703
MixupTrain:  epoch  0, batch  1304 | loss: 2.0921869
MixupTrain:  epoch  0, batch  1305 | loss: 2.3286750
MixupTrain:  epoch  0, batch  1306 | loss: 2.3240514
MixupTrain:  epoch  0, batch  1307 | loss: 2.3946104
MixupTrain:  epoch  0, batch  1308 | loss: 2.3652871
MixupTrain:  epoch  0, batch  1309 | loss: 2.1106541
MixupTrain:  epoch  0, batch  1310 | loss: 2.1231008
MixupTrain:  epoch  0, batch  1311 | loss: 2.4592237
MixupTrain:  epoch  0, batch  1312 | loss: 2.2663269
MixupTrain:  epoch  0, batch  1313 | loss: 2.1680312
MixupTrain:  epoch  0, batch  1314 | loss: 2.4636807
MixupTrain:  epoch  0, batch  1315 | loss: 2.3205807
MixupTrain:  epoch  0, batch  1316 | loss: 2.3850765
MixupTrain:  epoch  0, batch  1317 | loss: 2.0016384
MixupTrain:  epoch  0, batch  1318 | loss: 2.0360849
MixupTrain:  epoch  0, batch  1319 | loss: 2.2817445
MixupTrain:  epoch  0, batch  1320 | loss: 2.3391118
MixupTrain:  epoch  0, batch  1321 | loss: 2.3794460
MixupTrain:  epoch  0, batch  1322 | loss: 2.0471356
MixupTrain:  epoch  0, batch  1323 | loss: 2.4884763
MixupTrain:  epoch  0, batch  1324 | loss: 2.4536631
MixupTrain:  epoch  0, batch  1325 | loss: 2.2008071
MixupTrain:  epoch  0, batch  1326 | loss: 2.2357945
MixupTrain:  epoch  0, batch  1327 | loss: 2.4056637
MixupTrain:  epoch  0, batch  1328 | loss: 2.3430068
MixupTrain:  epoch  0, batch  1329 | loss: 2.5590298
MixupTrain:  epoch  0, batch  1330 | loss: 2.2036648
MixupTrain:  epoch  0, batch  1331 | loss: 2.0909684
MixupTrain:  epoch  0, batch  1332 | loss: 2.1847801
MixupTrain:  epoch  0, batch  1333 | loss: 2.5716736
MixupTrain:  epoch  0, batch  1334 | loss: 2.3307829
MixupTrain:  epoch  0, batch  1335 | loss: 2.1950946
MixupTrain:  epoch  0, batch  1336 | loss: 2.1190057
MixupTrain:  epoch  0, batch  1337 | loss: 2.0817375
MixupTrain:  epoch  0, batch  1338 | loss: 2.2574906
MixupTrain:  epoch  0, batch  1339 | loss: 2.3775835
MixupTrain:  epoch  0, batch  1340 | loss: 2.2098379
MixupTrain:  epoch  0, batch  1341 | loss: 2.4849138
MixupTrain:  epoch  0, batch  1342 | loss: 2.4347486
MixupTrain:  epoch  0, batch  1343 | loss: 2.3789878
MixupTrain:  epoch  0, batch  1344 | loss: 2.4577894
MixupTrain:  epoch  0, batch  1345 | loss: 2.0722883
MixupTrain:  epoch  0, batch  1346 | loss: 2.1990471
MixupTrain:  epoch  0, batch  1347 | loss: 2.5159640
MixupTrain:  epoch  0, batch  1348 | loss: 2.3299317
MixupTrain:  epoch  0, batch  1349 | loss: 2.5624995
MixupTrain:  epoch  0, batch  1350 | loss: 2.4835680
MixupTrain:  epoch  0, batch  1351 | loss: 2.2469459
MixupTrain:  epoch  0, batch  1352 | loss: 2.2729945
MixupTrain:  epoch  0, batch  1353 | loss: 2.2424300
MixupTrain:  epoch  0, batch  1354 | loss: 2.3489621
MixupTrain:  epoch  0, batch  1355 | loss: 2.3434758
MixupTrain:  epoch  0, batch  1356 | loss: 2.2494719
MixupTrain:  epoch  0, batch  1357 | loss: 2.5275512
MixupTrain:  epoch  0, batch  1358 | loss: 2.1590769
MixupTrain:  epoch  0, batch  1359 | loss: 2.4289813
MixupTrain:  epoch  0, batch  1360 | loss: 2.3488460
MixupTrain:  epoch  0, batch  1361 | loss: 2.3061233
MixupTrain:  epoch  0, batch  1362 | loss: 2.3295953
MixupTrain:  epoch  0, batch  1363 | loss: 2.1409259
MixupTrain:  epoch  0, batch  1364 | loss: 2.0623415
MixupTrain:  epoch  0, batch  1365 | loss: 2.3974953
MixupTrain:  epoch  0, batch  1366 | loss: 2.2513189
MixupTrain:  epoch  0, batch  1367 | loss: 2.2002950
MixupTrain:  epoch  0, batch  1368 | loss: 2.1813912
MixupTrain:  epoch  0, batch  1369 | loss: 1.9798491
MixupTrain:  epoch  0, batch  1370 | loss: 2.1381040
MixupTrain:  epoch  0, batch  1371 | loss: 2.3181307
MixupTrain:  epoch  0, batch  1372 | loss: 2.1914797
MixupTrain:  epoch  0, batch  1373 | loss: 2.0931940
MixupTrain:  epoch  0, batch  1374 | loss: 2.2744846
MixupTrain:  epoch  0, batch  1375 | loss: 2.1964107
MixupTrain:  epoch  0, batch  1376 | loss: 2.3705516
MixupTrain:  epoch  0, batch  1377 | loss: 2.1454115
MixupTrain:  epoch  0, batch  1378 | loss: 2.2304697
MixupTrain:  epoch  0, batch  1379 | loss: 2.4802132
MixupTrain:  epoch  0, batch  1380 | loss: 2.2885251
MixupTrain:  epoch  0, batch  1381 | loss: 2.2252040
MixupTrain:  epoch  0, batch  1382 | loss: 2.1965032
MixupTrain:  epoch  0, batch  1383 | loss: 2.4287543
MixupTrain:  epoch  0, batch  1384 | loss: 2.3167667
MixupTrain:  epoch  0, batch  1385 | loss: 2.3699679
MixupTrain:  epoch  0, batch  1386 | loss: 2.4156609
MixupTrain:  epoch  0, batch  1387 | loss: 2.2672868
MixupTrain:  epoch  0, batch  1388 | loss: 2.2760711
MixupTrain:  epoch  0, batch  1389 | loss: 2.2160637
MixupTrain:  epoch  0, batch  1390 | loss: 2.0339000
MixupTrain:  epoch  0, batch  1391 | loss: 2.4610319
MixupTrain:  epoch  0, batch  1392 | loss: 1.9878560
MixupTrain:  epoch  0, batch  1393 | loss: 2.1421032
MixupTrain:  epoch  0, batch  1394 | loss: 2.1080995
MixupTrain:  epoch  0, batch  1395 | loss: 2.1380403
MixupTrain:  epoch  0, batch  1396 | loss: 2.3040879
MixupTrain:  epoch  0, batch  1397 | loss: 2.1797385
MixupTrain:  epoch  0, batch  1398 | loss: 2.3944330
MixupTrain:  epoch  0, batch  1399 | loss: 2.4645238
MixupTrain:  epoch  0, batch  1400 | loss: 2.2345753
MixupTrain:  epoch  0, batch  1401 | loss: 2.4444015
MixupTrain:  epoch  0, batch  1402 | loss: 2.4099150
MixupTrain:  epoch  0, batch  1403 | loss: 2.4093542
MixupTrain:  epoch  0, batch  1404 | loss: 2.2999387
MixupTrain:  epoch  0, batch  1405 | loss: 2.3205616
MixupTrain:  epoch  0, batch  1406 | loss: 2.2382643
MixupTrain:  epoch  0, batch  1407 | loss: 2.1006050
MixupTrain:  epoch  0, batch  1408 | loss: 2.5824537
MixupTrain:  epoch  0, batch  1409 | loss: 2.2363594
MixupTrain:  epoch  0, batch  1410 | loss: 2.3178961
MixupTrain:  epoch  0, batch  1411 | loss: 2.1897614
MixupTrain:  epoch  0, batch  1412 | loss: 2.4366548
MixupTrain:  epoch  0, batch  1413 | loss: 2.5221491
MixupTrain:  epoch  0, batch  1414 | loss: 2.3105783
MixupTrain:  epoch  0, batch  1415 | loss: 2.2847731
MixupTrain:  epoch  0, batch  1416 | loss: 2.1689303
MixupTrain:  epoch  0, batch  1417 | loss: 2.4302282
MixupTrain:  epoch  0, batch  1418 | loss: 2.1666245
MixupTrain:  epoch  0, batch  1419 | loss: 2.4003131
MixupTrain:  epoch  0, batch  1420 | loss: 2.2549150
MixupTrain:  epoch  0, batch  1421 | loss: 2.4394934
MixupTrain:  epoch  0, batch  1422 | loss: 2.3068337
MixupTrain:  epoch  0, batch  1423 | loss: 2.2963772
MixupTrain:  epoch  0, batch  1424 | loss: 2.1712909
MixupTrain:  epoch  0, batch  1425 | loss: 2.2384362
MixupTrain:  epoch  0, batch  1426 | loss: 2.3765178
MixupTrain:  epoch  0, batch  1427 | loss: 2.4659503
MixupTrain:  epoch  0, batch  1428 | loss: 2.2012610
MixupTrain:  epoch  0, batch  1429 | loss: 2.5601962
MixupTrain:  epoch  0, batch  1430 | loss: 2.2154560
MixupTrain:  epoch  0, batch  1431 | loss: 1.9403751
MixupTrain:  epoch  0, batch  1432 | loss: 2.4429691
MixupTrain:  epoch  0, batch  1433 | loss: 2.2932115
MixupTrain:  epoch  0, batch  1434 | loss: 2.1852608
MixupTrain:  epoch  0, batch  1435 | loss: 2.2569144
MixupTrain:  epoch  0, batch  1436 | loss: 2.3510380
MixupTrain:  epoch  0, batch  1437 | loss: 2.1720524
MixupTrain:  epoch  0, batch  1438 | loss: 2.5058255
MixupTrain:  epoch  0, batch  1439 | loss: 2.1961346
MixupTrain:  epoch  0, batch  1440 | loss: 2.1804762
MixupTrain:  epoch  0, batch  1441 | loss: 2.0031404
MixupTrain:  epoch  0, batch  1442 | loss: 2.2522025
MixupTrain:  epoch  0, batch  1443 | loss: 2.1379080
MixupTrain:  epoch  0, batch  1444 | loss: 2.4133863
MixupTrain:  epoch  0, batch  1445 | loss: 2.1625509
MixupTrain:  epoch  0, batch  1446 | loss: 2.1967959
MixupTrain:  epoch  0, batch  1447 | loss: 2.3074217
MixupTrain:  epoch  0, batch  1448 | loss: 2.4498703
MixupTrain:  epoch  0, batch  1449 | loss: 2.2381048
MixupTrain:  epoch  0, batch  1450 | loss: 2.1719208
MixupTrain:  epoch  0, batch  1451 | loss: 2.4503126
MixupTrain:  epoch  0, batch  1452 | loss: 2.5573030
MixupTrain:  epoch  0, batch  1453 | loss: 2.4144127
MixupTrain:  epoch  0, batch  1454 | loss: 2.0378566
MixupTrain:  epoch  0, batch  1455 | loss: 2.0769284
MixupTrain:  epoch  0, batch  1456 | loss: 2.3866827
MixupTrain:  epoch  0, batch  1457 | loss: 2.4816113
MixupTrain:  epoch  0, batch  1458 | loss: 2.1010499
MixupTrain:  epoch  0, batch  1459 | loss: 2.3665695
MixupTrain:  epoch  0, batch  1460 | loss: 2.0006366
MixupTrain:  epoch  0, batch  1461 | loss: 2.1632919
MixupTrain:  epoch  0, batch  1462 | loss: 2.4894350
MixupTrain:  epoch  0, batch  1463 | loss: 2.3561091
MixupTrain:  epoch  0, batch  1464 | loss: 2.3544106
MixupTrain:  epoch  0, batch  1465 | loss: 2.1855993
MixupTrain:  epoch  0, batch  1466 | loss: 2.2468033
MixupTrain:  epoch  0, batch  1467 | loss: 2.4964499
MixupTrain:  epoch  0, batch  1468 | loss: 2.1708975
MixupTrain:  epoch  0, batch  1469 | loss: 2.2494240
MixupTrain:  epoch  0, batch  1470 | loss: 2.2366524
MixupTrain:  epoch  0, batch  1471 | loss: 2.4122360
MixupTrain:  epoch  0, batch  1472 | loss: 2.0269961
MixupTrain:  epoch  0, batch  1473 | loss: 2.1199811
MixupTrain:  epoch  0, batch  1474 | loss: 2.0909243
MixupTrain:  epoch  0, batch  1475 | loss: 2.2285819
MixupTrain:  epoch  0, batch  1476 | loss: 2.3754814
MixupTrain:  epoch  0, batch  1477 | loss: 2.4319057
MixupTrain:  epoch  0, batch  1478 | loss: 2.3692746
MixupTrain:  epoch  0, batch  1479 | loss: 1.9570496
MixupTrain:  epoch  0, batch  1480 | loss: 2.2137403
MixupTrain:  epoch  0, batch  1481 | loss: 2.2729490
MixupTrain:  epoch  0, batch  1482 | loss: 2.5573175
MixupTrain:  epoch  0, batch  1483 | loss: 2.0039175
MixupTrain:  epoch  0, batch  1484 | loss: 2.4341695
MixupTrain:  epoch  0, batch  1485 | loss: 2.1723773
MixupTrain:  epoch  0, batch  1486 | loss: 2.0394602
MixupTrain:  epoch  0, batch  1487 | loss: 2.1274815
MixupTrain:  epoch  0, batch  1488 | loss: 2.1339908
MixupTrain:  epoch  0, batch  1489 | loss: 2.5215406
MixupTrain:  epoch  0, batch  1490 | loss: 2.1769738
MixupTrain:  epoch  0, batch  1491 | loss: 2.1312294
MixupTrain:  epoch  0, batch  1492 | loss: 2.4120131
MixupTrain:  epoch  0, batch  1493 | loss: 2.2138343
MixupTrain:  epoch  0, batch  1494 | loss: 2.2051544
MixupTrain:  epoch  0, batch  1495 | loss: 2.1847553
MixupTrain:  epoch  0, batch  1496 | loss: 2.2245955
MixupTrain:  epoch  0, batch  1497 | loss: 2.1305218
MixupTrain:  epoch  0, batch  1498 | loss: 2.3305688
MixupTrain:  epoch  0, batch  1499 | loss: 2.3045268
MixupTrain:  epoch  0, batch  1500 | loss: 2.3564134
MixupTrain:  epoch  0, batch  1501 | loss: 2.4432824
MixupTrain:  epoch  0, batch  1502 | loss: 1.9818194
MixupTrain:  epoch  0, batch  1503 | loss: 2.1544724
MixupTrain:  epoch  0, batch  1504 | loss: 2.1568992
MixupTrain:  epoch  0, batch  1505 | loss: 2.2649198
MixupTrain:  epoch  0, batch  1506 | loss: 2.3280656
MixupTrain:  epoch  0, batch  1507 | loss: 2.3182659
MixupTrain:  epoch  0, batch  1508 | loss: 2.1678767
MixupTrain:  epoch  0, batch  1509 | loss: 2.3353257
MixupTrain:  epoch  0, batch  1510 | loss: 2.4239633
MixupTrain:  epoch  0, batch  1511 | loss: 2.4276433
MixupTrain:  epoch  0, batch  1512 | loss: 2.1266961
MixupTrain:  epoch  0, batch  1513 | loss: 2.2885084
MixupTrain:  epoch  0, batch  1514 | loss: 2.3425794
MixupTrain:  epoch  0, batch  1515 | loss: 2.3345146
MixupTrain:  epoch  0, batch  1516 | loss: 2.2071788
MixupTrain:  epoch  0, batch  1517 | loss: 2.5857713
MixupTrain:  epoch  0, batch  1518 | loss: 2.4025981
MixupTrain:  epoch  0, batch  1519 | loss: 2.2596824
MixupTrain:  epoch  0, batch  1520 | loss: 2.1703343
MixupTrain:  epoch  0, batch  1521 | loss: 2.2293444
MixupTrain:  epoch  0, batch  1522 | loss: 2.2503133
MixupTrain:  epoch  0, batch  1523 | loss: 2.2225037
MixupTrain:  epoch  0, batch  1524 | loss: 2.2953389
MixupTrain:  epoch  0, batch  1525 | loss: 2.5482206
MixupTrain:  epoch  0, batch  1526 | loss: 2.2481482
MixupTrain:  epoch  0, batch  1527 | loss: 2.2850394
MixupTrain:  epoch  0, batch  1528 | loss: 2.3432565
MixupTrain:  epoch  0, batch  1529 | loss: 2.1706510
MixupTrain:  epoch  0, batch  1530 | loss: 2.3882980
MixupTrain:  epoch  0, batch  1531 | loss: 2.1740675
MixupTrain:  epoch  0, batch  1532 | loss: 2.3414936
MixupTrain:  epoch  0, batch  1533 | loss: 2.1755903
MixupTrain:  epoch  0, batch  1534 | loss: 2.0943513
MixupTrain:  epoch  0, batch  1535 | loss: 2.2163019
MixupTrain:  epoch  0, batch  1536 | loss: 2.1260617
MixupTrain:  epoch  0, batch  1537 | loss: 2.3109555
MixupTrain:  epoch  0, batch  1538 | loss: 2.2842376
MixupTrain:  epoch  0, batch  1539 | loss: 1.9430724
MixupTrain:  epoch  0, batch  1540 | loss: 2.2127509
MixupTrain:  epoch  0, batch  1541 | loss: 2.0818167
MixupTrain:  epoch  0, batch  1542 | loss: 2.3599100
MixupTrain:  epoch  0, batch  1543 | loss: 2.2896798
MixupTrain:  epoch  0, batch  1544 | loss: 2.2345245
MixupTrain:  epoch  0, batch  1545 | loss: 2.3113832
MixupTrain:  epoch  0, batch  1546 | loss: 2.1843500
MixupTrain:  epoch  0, batch  1547 | loss: 2.1304674
MixupTrain:  epoch  0, batch  1548 | loss: 2.3496759
MixupTrain:  epoch  0, batch  1549 | loss: 2.4685702
MixupTrain:  epoch  0, batch  1550 | loss: 2.2069798
MixupTrain:  epoch  0, batch  1551 | loss: 2.2085915
MixupTrain:  epoch  0, batch  1552 | loss: 2.3232369
MixupTrain:  epoch  0, batch  1553 | loss: 2.0370235
MixupTrain:  epoch  0, batch  1554 | loss: 2.1506763
MixupTrain:  epoch  0, batch  1555 | loss: 2.2366381
MixupTrain:  epoch  0, batch  1556 | loss: 2.2620888
MixupTrain:  epoch  0, batch  1557 | loss: 2.4464483
MixupTrain:  epoch  0, batch  1558 | loss: 2.1355331
MixupTrain:  epoch  0, batch  1559 | loss: 1.9359651
MixupTrain:  epoch  0, batch  1560 | loss: 2.3664150
MixupTrain:  epoch  0, batch  1561 | loss: 2.2800918
MixupTrain:  epoch  0, batch  1562 | loss: 2.3329797
MixupTrain:  epoch  0, batch  1563 | loss: 2.2929268
MixupTrain:  epoch  0, batch  1564 | loss: 2.0712743
MixupTrain:  epoch  0, batch  1565 | loss: 2.3157601
MixupTrain:  epoch  0, batch  1566 | loss: 2.1638248
MixupTrain:  epoch  0, batch  1567 | loss: 2.6342924
MixupTrain:  epoch  0, batch  1568 | loss: 2.4021263
MixupTrain:  epoch  0, batch  1569 | loss: 2.3319237
MixupTrain:  epoch  0, batch  1570 | loss: 1.9985751
MixupTrain:  epoch  0, batch  1571 | loss: 2.4308584
MixupTrain:  epoch  0, batch  1572 | loss: 2.2815747
MixupTrain:  epoch  0, batch  1573 | loss: 2.3665516
MixupTrain:  epoch  0, batch  1574 | loss: 2.4866185
MixupTrain:  epoch  0, batch  1575 | loss: 2.3705478
MixupTrain:  epoch  0, batch  1576 | loss: 2.1423216
MixupTrain:  epoch  0, batch  1577 | loss: 2.1938615
MixupTrain:  epoch  0, batch  1578 | loss: 2.3140273
MixupTrain:  epoch  0, batch  1579 | loss: 2.3826385
MixupTrain:  epoch  0, batch  1580 | loss: 2.0265706
MixupTrain:  epoch  0, batch  1581 | loss: 2.1858411
MixupTrain:  epoch  0, batch  1582 | loss: 2.2633014
MixupTrain:  epoch  0, batch  1583 | loss: 2.2181354
MixupTrain:  epoch  0, batch  1584 | loss: 1.9674392
MixupTrain:  epoch  0, batch  1585 | loss: 2.1346674
MixupTrain:  epoch  0, batch  1586 | loss: 2.2394848
MixupTrain:  epoch  0, batch  1587 | loss: 2.5022590
MixupTrain:  epoch  0, batch  1588 | loss: 2.0916424
MixupTrain:  epoch  0, batch  1589 | loss: 2.2997122
MixupTrain:  epoch  0, batch  1590 | loss: 2.2859344
MixupTrain:  epoch  0, batch  1591 | loss: 2.3051240
MixupTrain:  epoch  0, batch  1592 | loss: 2.2218671
MixupTrain:  epoch  0, batch  1593 | loss: 2.2216549
MixupTrain:  epoch  0, batch  1594 | loss: 2.0156982
MixupTrain:  epoch  0, batch  1595 | loss: 2.2576175
MixupTrain:  epoch  0, batch  1596 | loss: 2.1853490
MixupTrain:  epoch  0, batch  1597 | loss: 2.1484816
MixupTrain:  epoch  0, batch  1598 | loss: 2.4810109
MixupTrain:  epoch  0, batch  1599 | loss: 2.1751270
MixupTrain:  epoch  0, batch  1600 | loss: 2.2269177
MixupTrain:  epoch  0, batch  1601 | loss: 2.3637435
MixupTrain:  epoch  0, batch  1602 | loss: 2.0656991
MixupTrain:  epoch  0, batch  1603 | loss: 2.4042871
MixupTrain:  epoch  0, batch  1604 | loss: 2.4083652
MixupTrain:  epoch  0, batch  1605 | loss: 2.2011359
MixupTrain:  epoch  0, batch  1606 | loss: 2.3305407
MixupTrain:  epoch  0, batch  1607 | loss: 2.4291878
MixupTrain:  epoch  0, batch  1608 | loss: 2.3023953
MixupTrain:  epoch  0, batch  1609 | loss: 2.3333778
MixupTrain:  epoch  0, batch  1610 | loss: 2.2850604
MixupTrain:  epoch  0, batch  1611 | loss: 2.3680038
MixupTrain:  epoch  0, batch  1612 | loss: 2.4872513
MixupTrain:  epoch  0, batch  1613 | loss: 2.2370336
MixupTrain:  epoch  0, batch  1614 | loss: 2.5472541
MixupTrain:  epoch  0, batch  1615 | loss: 2.1847548
MixupTrain:  epoch  0, batch  1616 | loss: 2.2629035
MixupTrain:  epoch  0, batch  1617 | loss: 2.3196511
MixupTrain:  epoch  0, batch  1618 | loss: 2.4623575
MixupTrain:  epoch  0, batch  1619 | loss: 2.5079899
MixupTrain:  epoch  0, batch  1620 | loss: 2.0606418
MixupTrain:  epoch  0, batch  1621 | loss: 2.1501188
MixupTrain:  epoch  0, batch  1622 | loss: 2.1320434
MixupTrain:  epoch  0, batch  1623 | loss: 2.4400611
MixupTrain:  epoch  0, batch  1624 | loss: 2.1028867
MixupTrain:  epoch  0, batch  1625 | loss: 2.4694512
MixupTrain:  epoch  0, batch  1626 | loss: 2.3178816
MixupTrain:  epoch  0, batch  1627 | loss: 2.3697438
MixupTrain:  epoch  0, batch  1628 | loss: 2.2764306
MixupTrain:  epoch  0, batch  1629 | loss: 2.1420512
MixupTrain:  epoch  0, batch  1630 | loss: 2.4197578
MixupTrain:  epoch  0, batch  1631 | loss: 2.4960871
MixupTrain:  epoch  0, batch  1632 | loss: 2.0932679
MixupTrain:  epoch  0, batch  1633 | loss: 2.1510673
MixupTrain:  epoch  0, batch  1634 | loss: 2.1358581
MixupTrain:  epoch  0, batch  1635 | loss: 2.2897358
MixupTrain:  epoch  0, batch  1636 | loss: 2.3362327
MixupTrain:  epoch  0, batch  1637 | loss: 2.1669822
MixupTrain:  epoch  0, batch  1638 | loss: 2.0097361
MixupTrain:  epoch  0, batch  1639 | loss: 2.3496811
MixupTrain:  epoch  0, batch  1640 | loss: 2.3333900
MixupTrain:  epoch  0, batch  1641 | loss: 2.2667589
MixupTrain:  epoch  0, batch  1642 | loss: 2.2467790
MixupTrain:  epoch  0, batch  1643 | loss: 2.2261064
MixupTrain:  epoch  0, batch  1644 | loss: 2.2916265
MixupTrain:  epoch  0, batch  1645 | loss: 2.2682362
MixupTrain:  epoch  0, batch  1646 | loss: 2.5008466
MixupTrain:  epoch  0, batch  1647 | loss: 2.2503963
MixupTrain:  epoch  0, batch  1648 | loss: 2.3401694
MixupTrain:  epoch  0, batch  1649 | loss: 2.1127267
MixupTrain:  epoch  0, batch  1650 | loss: 2.4398019
MixupTrain:  epoch  0, batch  1651 | loss: 2.2123868
MixupTrain:  epoch  0, batch  1652 | loss: 2.3407593
MixupTrain:  epoch  0, batch  1653 | loss: 2.3739533
MixupTrain:  epoch  0, batch  1654 | loss: 2.0742049
MixupTrain:  epoch  0, batch  1655 | loss: 2.2683635
MixupTrain:  epoch  0, batch  1656 | loss: 2.5593286
MixupTrain:  epoch  0, batch  1657 | loss: 2.1970172
MixupTrain:  epoch  0, batch  1658 | loss: 2.3120995
MixupTrain:  epoch  0, batch  1659 | loss: 2.1246405
MixupTrain:  epoch  0, batch  1660 | loss: 2.0047224
MixupTrain:  epoch  0, batch  1661 | loss: 2.4328489
MixupTrain:  epoch  0, batch  1662 | loss: 2.0317161
MixupTrain:  epoch  0, batch  1663 | loss: 2.2704203
MixupTrain:  epoch  0, batch  1664 | loss: 2.1640491
MixupTrain:  epoch  0, batch  1665 | loss: 2.0448148
MixupTrain:  epoch  0, batch  1666 | loss: 2.2378457
MixupTrain:  epoch  0, batch  1667 | loss: 2.2747183
MixupTrain:  epoch  0, batch  1668 | loss: 2.2240305
MixupTrain:  epoch  0, batch  1669 | loss: 2.3854945
MixupTrain:  epoch  0, batch  1670 | loss: 2.3402565
MixupTrain:  epoch  0, batch  1671 | loss: 2.0684538
MixupTrain:  epoch  0, batch  1672 | loss: 2.6008892
MixupTrain:  epoch  0, batch  1673 | loss: 2.4595737
MixupTrain:  epoch  0, batch  1674 | loss: 2.2107239
MixupTrain:  epoch  0, batch  1675 | loss: 2.1963906
MixupTrain:  epoch  0, batch  1676 | loss: 2.4127550
MixupTrain:  epoch  0, batch  1677 | loss: 2.1638539
MixupTrain:  epoch  0, batch  1678 | loss: 2.2947197
MixupTrain:  epoch  0, batch  1679 | loss: 2.0231154
MixupTrain:  epoch  0, batch  1680 | loss: 2.4430609
MixupTrain:  epoch  0, batch  1681 | loss: 2.4157777
MixupTrain:  epoch  0, batch  1682 | loss: 2.4357200
MixupTrain:  epoch  0, batch  1683 | loss: 2.4834230
MixupTrain:  epoch  0, batch  1684 | loss: 2.4405708
MixupTrain:  epoch  0, batch  1685 | loss: 2.3198395
MixupTrain:  epoch  0, batch  1686 | loss: 2.1990113
MixupTrain:  epoch  0, batch  1687 | loss: 2.0157204
MixupTrain:  epoch  0, batch  1688 | loss: 2.5110435
MixupTrain:  epoch  0, batch  1689 | loss: 2.3712196
MixupTrain:  epoch  0, batch  1690 | loss: 2.2878056
MixupTrain:  epoch  0, batch  1691 | loss: 2.2178402
MixupTrain:  epoch  0, batch  1692 | loss: 2.3731179
MixupTrain:  epoch  0, batch  1693 | loss: 2.1824617
MixupTrain:  epoch  0, batch  1694 | loss: 2.3932123
MixupTrain:  epoch  0, batch  1695 | loss: 2.3467426
MixupTrain:  epoch  0, batch  1696 | loss: 2.0721073
MixupTrain:  epoch  0, batch  1697 | loss: 2.3499255
MixupTrain:  epoch  0, batch  1698 | loss: 2.2243059
MixupTrain:  epoch  0, batch  1699 | loss: 2.2690442
MixupTrain:  epoch  0, batch  1700 | loss: 2.3270011
MixupTrain:  epoch  0, batch  1701 | loss: 2.1231775
MixupTrain:  epoch  0, batch  1702 | loss: 2.4008098
MixupTrain:  epoch  0, batch  1703 | loss: 2.3202765
MixupTrain:  epoch  0, batch  1704 | loss: 2.1702480
MixupTrain:  epoch  0, batch  1705 | loss: 2.0830526
MixupTrain:  epoch  0, batch  1706 | loss: 1.9503566
MixupTrain:  epoch  0, batch  1707 | loss: 2.0939322
MixupTrain:  epoch  0, batch  1708 | loss: 2.2918234
MixupTrain:  epoch  0, batch  1709 | loss: 2.2376690
MixupTrain:  epoch  0, batch  1710 | loss: 2.4496551
MixupTrain:  epoch  0, batch  1711 | loss: 2.5610843
MixupTrain:  epoch  0, batch  1712 | loss: 2.4540162
MixupTrain:  epoch  0, batch  1713 | loss: 2.3453879
MixupTrain:  epoch  0, batch  1714 | loss: 2.3343844
MixupTrain:  epoch  0, batch  1715 | loss: 2.1768994
MixupTrain:  epoch  0, batch  1716 | loss: 2.1761708
MixupTrain:  epoch  0, batch  1717 | loss: 2.2075686
MixupTrain:  epoch  0, batch  1718 | loss: 2.3619378
MixupTrain:  epoch  0, batch  1719 | loss: 2.2298515
MixupTrain:  epoch  0, batch  1720 | loss: 2.0768566
MixupTrain:  epoch  0, batch  1721 | loss: 2.0977001
MixupTrain:  epoch  0, batch  1722 | loss: 2.2038031
MixupTrain:  epoch  0, batch  1723 | loss: 2.1187301
MixupTrain:  epoch  0, batch  1724 | loss: 2.4245114
MixupTrain:  epoch  0, batch  1725 | loss: 2.5656419
MixupTrain:  epoch  0, batch  1726 | loss: 2.1710944
MixupTrain:  epoch  0, batch  1727 | loss: 2.2042532
MixupTrain:  epoch  0, batch  1728 | loss: 2.2836280
MixupTrain:  epoch  0, batch  1729 | loss: 2.2786832
MixupTrain:  epoch  0, batch  1730 | loss: 2.1552329
MixupTrain:  epoch  0, batch  1731 | loss: 2.2124147
MixupTrain:  epoch  0, batch  1732 | loss: 2.2145905
MixupTrain:  epoch  0, batch  1733 | loss: 2.2754607
MixupTrain:  epoch  0, batch  1734 | loss: 2.0968356
MixupTrain:  epoch  0, batch  1735 | loss: 2.1688070
MixupTrain:  epoch  0, batch  1736 | loss: 2.2556176
MixupTrain:  epoch  0, batch  1737 | loss: 2.3800237
MixupTrain:  epoch  0, batch  1738 | loss: 2.4700525
MixupTrain:  epoch  0, batch  1739 | loss: 2.2101164
MixupTrain:  epoch  0, batch  1740 | loss: 2.1728153
MixupTrain:  epoch  0, batch  1741 | loss: 2.0857635
MixupTrain:  epoch  0, batch  1742 | loss: 2.3793087
MixupTrain:  epoch  0, batch  1743 | loss: 2.2511692
MixupTrain:  epoch  0, batch  1744 | loss: 2.3167200
MixupTrain:  epoch  0, batch  1745 | loss: 2.3996677
MixupTrain:  epoch  0, batch  1746 | loss: 2.3506174
MixupTrain:  epoch  0, batch  1747 | loss: 2.3469241
MixupTrain:  epoch  0, batch  1748 | loss: 2.5314741
MixupTrain:  epoch  0, batch  1749 | loss: 2.0775771
MixupTrain:  epoch  0, batch  1750 | loss: 2.3518898
MixupTrain:  epoch  0, batch  1751 | loss: 2.0222173
MixupTrain:  epoch  0, batch  1752 | loss: 2.3616657
MixupTrain:  epoch  0, batch  1753 | loss: 2.4356604
MixupTrain:  epoch  0, batch  1754 | loss: 2.1752610
MixupTrain:  epoch  0, batch  1755 | loss: 2.3482993
MixupTrain:  epoch  0, batch  1756 | loss: 2.2949440
MixupTrain:  epoch  0, batch  1757 | loss: 2.3041158
MixupTrain:  epoch  0, batch  1758 | loss: 2.4191437
MixupTrain:  epoch  0, batch  1759 | loss: 2.2266984
MixupTrain:  epoch  0, batch  1760 | loss: 2.3393145
MixupTrain:  epoch  0, batch  1761 | loss: 2.2883513
MixupTrain:  epoch  0, batch  1762 | loss: 2.3781877
MixupTrain:  epoch  0, batch  1763 | loss: 2.3064930
MixupTrain:  epoch  0, batch  1764 | loss: 2.2830303
MixupTrain:  epoch  0, batch  1765 | loss: 2.3634927
MixupTrain:  epoch  0, batch  1766 | loss: 2.3231745
MixupTrain:  epoch  0, batch  1767 | loss: 2.4943643
MixupTrain:  epoch  0, batch  1768 | loss: 2.0945742
MixupTrain:  epoch  0, batch  1769 | loss: 2.0328777
MixupTrain:  epoch  0, batch  1770 | loss: 2.3942766
MixupTrain:  epoch  0, batch  1771 | loss: 2.2455399
MixupTrain:  epoch  0, batch  1772 | loss: 2.1015086
MixupTrain:  epoch  0, batch  1773 | loss: 2.0741506
MixupTrain:  epoch  0, batch  1774 | loss: 2.2949712
MixupTrain:  epoch  0, batch  1775 | loss: 2.1735461
MixupTrain:  epoch  0, batch  1776 | loss: 2.4453471
MixupTrain:  epoch  0, batch  1777 | loss: 2.1912355
MixupTrain:  epoch  0, batch  1778 | loss: 2.5585985
MixupTrain:  epoch  0, batch  1779 | loss: 2.6173229
MixupTrain:  epoch  0, batch  1780 | loss: 2.2788277
MixupTrain:  epoch  0, batch  1781 | loss: 2.2273161
MixupTrain:  epoch  0, batch  1782 | loss: 2.4441578
MixupTrain:  epoch  0, batch  1783 | loss: 2.1794393
MixupTrain:  epoch  0, batch  1784 | loss: 2.4758785
MixupTrain:  epoch  0, batch  1785 | loss: 2.1878071
MixupTrain:  epoch  0, batch  1786 | loss: 2.1848826
MixupTrain:  epoch  0, batch  1787 | loss: 2.2223396
MixupTrain:  epoch  0, batch  1788 | loss: 2.1014299
MixupTrain:  epoch  0, batch  1789 | loss: 2.0693121
MixupTrain:  epoch  0, batch  1790 | loss: 2.0758190
MixupTrain:  epoch  0, batch  1791 | loss: 2.1435442
MixupTrain:  epoch  0, batch  1792 | loss: 2.1878188
MixupTrain:  epoch  0, batch  1793 | loss: 2.2426646
MixupTrain:  epoch  0, batch  1794 | loss: 2.4040370
MixupTrain:  epoch  0, batch  1795 | loss: 2.3234873
MixupTrain:  epoch  0, batch  1796 | loss: 2.1271300
MixupTrain:  epoch  0, batch  1797 | loss: 2.1626623
MixupTrain:  epoch  0, batch  1798 | loss: 2.4471545
MixupTrain:  epoch  0, batch  1799 | loss: 2.1881752
MixupTrain:  epoch  0, batch  1800 | loss: 2.3034487
MixupTrain:  epoch  0, batch  1801 | loss: 2.1582770
MixupTrain:  epoch  0, batch  1802 | loss: 2.5492492
MixupTrain:  epoch  0, batch  1803 | loss: 2.2147784
MixupTrain:  epoch  0, batch  1804 | loss: 2.2709589
MixupTrain:  epoch  0, batch  1805 | loss: 2.2069511
MixupTrain:  epoch  0, batch  1806 | loss: 2.4366720
MixupTrain:  epoch  0, batch  1807 | loss: 2.2664530
MixupTrain:  epoch  0, batch  1808 | loss: 2.1225944
MixupTrain:  epoch  0, batch  1809 | loss: 2.5323868
MixupTrain:  epoch  0, batch  1810 | loss: 2.2101822
MixupTrain:  epoch  0, batch  1811 | loss: 2.3109853
MixupTrain:  epoch  0, batch  1812 | loss: 2.2021897
MixupTrain:  epoch  0, batch  1813 | loss: 2.3519144
MixupTrain:  epoch  0, batch  1814 | loss: 2.2217479
MixupTrain:  epoch  0, batch  1815 | loss: 2.2881668
MixupTrain:  epoch  0, batch  1816 | loss: 2.4744575
MixupTrain:  epoch  0, batch  1817 | loss: 2.4048839
MixupTrain:  epoch  0, batch  1818 | loss: 2.4354687
MixupTrain:  epoch  0, batch  1819 | loss: 2.2527299
MixupTrain:  epoch  0, batch  1820 | loss: 2.2495568
MixupTrain:  epoch  0, batch  1821 | loss: 2.6177974
MixupTrain:  epoch  0, batch  1822 | loss: 2.2295756
MixupTrain:  epoch  0, batch  1823 | loss: 2.1108530
MixupTrain:  epoch  0, batch  1824 | loss: 2.2814927
MixupTrain:  epoch  0, batch  1825 | loss: 2.4111223
MixupTrain:  epoch  0, batch  1826 | loss: 2.2512496
MixupTrain:  epoch  0, batch  1827 | loss: 2.4830837
MixupTrain:  epoch  0, batch  1828 | loss: 2.3611696
MixupTrain:  epoch  0, batch  1829 | loss: 2.2324657
MixupTrain:  epoch  0, batch  1830 | loss: 2.4061022
MixupTrain:  epoch  0, batch  1831 | loss: 2.2184212
MixupTrain:  epoch  0, batch  1832 | loss: 2.4348173
MixupTrain:  epoch  0, batch  1833 | loss: 2.3708172
MixupTrain:  epoch  0, batch  1834 | loss: 2.2784126
MixupTrain:  epoch  0, batch  1835 | loss: 2.2982769
MixupTrain:  epoch  0, batch  1836 | loss: 2.4162078
MixupTrain:  epoch  0, batch  1837 | loss: 2.2755122
MixupTrain:  epoch  0, batch  1838 | loss: 2.3714993
MixupTrain:  epoch  0, batch  1839 | loss: 2.3744001
MixupTrain:  epoch  0, batch  1840 | loss: 2.2470827
MixupTrain:  epoch  0, batch  1841 | loss: 2.5893531
MixupTrain:  epoch  0, batch  1842 | loss: 2.1222196
MixupTrain:  epoch  0, batch  1843 | loss: 2.1059673
MixupTrain:  epoch  0, batch  1844 | loss: 2.2026839
MixupTrain:  epoch  0, batch  1845 | loss: 2.1939096
MixupTrain:  epoch  0, batch  1846 | loss: 2.3156924
MixupTrain:  epoch  0, batch  1847 | loss: 2.5145345
MixupTrain:  epoch  0, batch  1848 | loss: 2.2534077
MixupTrain:  epoch  0, batch  1849 | loss: 2.2896919
MixupTrain:  epoch  0, batch  1850 | loss: 2.3049488
MixupTrain:  epoch  0, batch  1851 | loss: 2.5098379
MixupTrain:  epoch  0, batch  1852 | loss: 2.3209362
MixupTrain:  epoch  0, batch  1853 | loss: 2.2126417
MixupTrain:  epoch  0, batch  1854 | loss: 2.1417675
MixupTrain:  epoch  0, batch  1855 | loss: 2.1822596
MixupTrain:  epoch  0, batch  1856 | loss: 2.2321587
MixupTrain:  epoch  0, batch  1857 | loss: 2.0326426
MixupTrain:  epoch  0, batch  1858 | loss: 2.4430940
MixupTrain:  epoch  0, batch  1859 | loss: 2.1356208
MixupTrain:  epoch  0, batch  1860 | loss: 2.3952973
MixupTrain:  epoch  0, batch  1861 | loss: 2.6275270
MixupTrain:  epoch  0, batch  1862 | loss: 2.1359205
MixupTrain:  epoch  0, batch  1863 | loss: 2.2400851
MixupTrain:  epoch  0, batch  1864 | loss: 2.2877059
MixupTrain:  epoch  0, batch  1865 | loss: 2.3404078
MixupTrain:  epoch  0, batch  1866 | loss: 2.2877336
MixupTrain:  epoch  0, batch  1867 | loss: 2.2009072
MixupTrain:  epoch  0, batch  1868 | loss: 2.2848423
MixupTrain:  epoch  0, batch  1869 | loss: 2.0650854
MixupTrain:  epoch  0, batch  1870 | loss: 2.4160419
MixupTrain:  epoch  0, batch  1871 | loss: 2.3582144
MixupTrain:  epoch  0, batch  1872 | loss: 2.3096151
MixupTrain:  epoch  0, batch  1873 | loss: 2.4779181
MixupTrain:  epoch  0, batch  1874 | loss: 2.4225163
MixupTrain:  epoch  0, batch  1875 | loss: 2.4625227
MixupTrain:  epoch  0, batch  1876 | loss: 2.1501634
MixupTrain:  epoch  0, batch  1877 | loss: 2.2050562
MixupTrain:  epoch  0, batch  1878 | loss: 2.0713608
MixupTrain:  epoch  0, batch  1879 | loss: 2.4933953
MixupTrain:  epoch  0, batch  1880 | loss: 1.9447212
MixupTrain:  epoch  0, batch  1881 | loss: 2.3292646
MixupTrain:  epoch  0, batch  1882 | loss: 2.2442656
MixupTrain:  epoch  0, batch  1883 | loss: 2.1975791
MixupTrain:  epoch  0, batch  1884 | loss: 2.2382493
MixupTrain:  epoch  0, batch  1885 | loss: 2.2267947
MixupTrain:  epoch  0, batch  1886 | loss: 2.3880458
MixupTrain:  epoch  0, batch  1887 | loss: 2.2171888
MixupTrain:  epoch  0, batch  1888 | loss: 2.2225788
MixupTrain:  epoch  0, batch  1889 | loss: 2.1738527
MixupTrain:  epoch  0, batch  1890 | loss: 2.2715912
MixupTrain:  epoch  0, batch  1891 | loss: 2.1766901
MixupTrain:  epoch  0, batch  1892 | loss: 2.2133069
MixupTrain:  epoch  0, batch  1893 | loss: 2.2598195
MixupTrain:  epoch  0, batch  1894 | loss: 2.4290981
MixupTrain:  epoch  0, batch  1895 | loss: 2.2961302
MixupTrain:  epoch  0, batch  1896 | loss: 2.2078528
MixupTrain:  epoch  0, batch  1897 | loss: 2.3915665
MixupTrain:  epoch  0, batch  1898 | loss: 2.3038006
MixupTrain:  epoch  0, batch  1899 | loss: 1.9238077
MixupTrain:  epoch  0, batch  1900 | loss: 2.3642144
MixupTrain:  epoch  0, batch  1901 | loss: 2.3074615
MixupTrain:  epoch  0, batch  1902 | loss: 2.3877218
MixupTrain:  epoch  0, batch  1903 | loss: 2.3042955
MixupTrain:  epoch  0, batch  1904 | loss: 2.5072088
MixupTrain:  epoch  0, batch  1905 | loss: 2.2799418
MixupTrain:  epoch  0, batch  1906 | loss: 2.4373932
MixupTrain:  epoch  0, batch  1907 | loss: 2.1067410
MixupTrain:  epoch  0, batch  1908 | loss: 2.1958666
MixupTrain:  epoch  0, batch  1909 | loss: 2.1090794
MixupTrain:  epoch  0, batch  1910 | loss: 2.4545250
MixupTrain:  epoch  0, batch  1911 | loss: 2.0546947
MixupTrain:  epoch  0, batch  1912 | loss: 2.3173614
MixupTrain:  epoch  0, batch  1913 | loss: 2.2686720
MixupTrain:  epoch  0, batch  1914 | loss: 2.3600192
MixupTrain:  epoch  0, batch  1915 | loss: 2.4575734
MixupTrain:  epoch  0, batch  1916 | loss: 2.3271148
MixupTrain:  epoch  0, batch  1917 | loss: 2.2592077
MixupTrain:  epoch  0, batch  1918 | loss: 2.1807208
MixupTrain:  epoch  0, batch  1919 | loss: 2.2548637
MixupTrain:  epoch  0, batch  1920 | loss: 2.3434896
MixupTrain:  epoch  0, batch  1921 | loss: 2.1053207
MixupTrain:  epoch  0, batch  1922 | loss: 2.1574602
MixupTrain:  epoch  0, batch  1923 | loss: 2.4032326
MixupTrain:  epoch  0, batch  1924 | loss: 2.4476905
MixupTrain:  epoch  0, batch  1925 | loss: 2.0236204
MixupTrain:  epoch  0, batch  1926 | loss: 2.2916346
MixupTrain:  epoch  0, batch  1927 | loss: 2.0646915
MixupTrain:  epoch  0, batch  1928 | loss: 2.2892971
MixupTrain:  epoch  0, batch  1929 | loss: 2.0762963
MixupTrain:  epoch  0, batch  1930 | loss: 2.2337170
MixupTrain:  epoch  0, batch  1931 | loss: 2.3566308
MixupTrain:  epoch  0, batch  1932 | loss: 2.0989671
MixupTrain:  epoch  0, batch  1933 | loss: 2.1800697
MixupTrain:  epoch  0, batch  1934 | loss: 2.3011944
MixupTrain:  epoch  0, batch  1935 | loss: 2.3017230
MixupTrain:  epoch  0, batch  1936 | loss: 2.3975055
MixupTrain:  epoch  0, batch  1937 | loss: 2.1496613
MixupTrain:  epoch  0, batch  1938 | loss: 2.2569866
MixupTrain:  epoch  0, batch  1939 | loss: 2.3271532
MixupTrain:  epoch  0, batch  1940 | loss: 2.2677155
MixupTrain:  epoch  0, batch  1941 | loss: 2.2619550
MixupTrain:  epoch  0, batch  1942 | loss: 2.3031762
MixupTrain:  epoch  0, batch  1943 | loss: 2.2339058
MixupTrain:  epoch  0, batch  1944 | loss: 2.4243331
MixupTrain:  epoch  0, batch  1945 | loss: 2.3311734
MixupTrain:  epoch  0, batch  1946 | loss: 2.2674286
MixupTrain:  epoch  0, batch  1947 | loss: 2.4294009
MixupTrain:  epoch  0, batch  1948 | loss: 2.1262803
MixupTrain:  epoch  0, batch  1949 | loss: 2.3834853
MixupTrain:  epoch  0, batch  1950 | loss: 2.1802812
MixupTrain:  epoch  0, batch  1951 | loss: 2.4532552
MixupTrain:  epoch  0, batch  1952 | loss: 2.0391598
MixupTrain:  epoch  0, batch  1953 | loss: 2.1368978
MixupTrain:  epoch  0, batch  1954 | loss: 2.1031272
MixupTrain:  epoch  0, batch  1955 | loss: 2.3293581
MixupTrain:  epoch  0, batch  1956 | loss: 2.2258887
MixupTrain:  epoch  0, batch  1957 | loss: 2.4571159
MixupTrain:  epoch  0, batch  1958 | loss: 2.4717746
MixupTrain:  epoch  0, batch  1959 | loss: 2.4551935
MixupTrain:  epoch  0, batch  1960 | loss: 2.2688935
MixupTrain:  epoch  0, batch  1961 | loss: 2.1067882
MixupTrain:  epoch  0, batch  1962 | loss: 2.2518201
MixupTrain:  epoch  0, batch  1963 | loss: 2.4070716
MixupTrain:  epoch  0, batch  1964 | loss: 2.3144226
MixupTrain:  epoch  0, batch  1965 | loss: 2.2798853
MixupTrain:  epoch  0, batch  1966 | loss: 2.1669874
MixupTrain:  epoch  0, batch  1967 | loss: 2.1218548
MixupTrain:  epoch  0, batch  1968 | loss: 2.1145673
MixupTrain:  epoch  0, batch  1969 | loss: 2.1336679
MixupTrain:  epoch  0, batch  1970 | loss: 2.0685065
MixupTrain:  epoch  0, batch  1971 | loss: 2.1128535
MixupTrain:  epoch  0, batch  1972 | loss: 2.1150041
MixupTrain:  epoch  0, batch  1973 | loss: 2.1357422
MixupTrain:  epoch  0, batch  1974 | loss: 2.1990066
MixupTrain:  epoch  0, batch  1975 | loss: 2.2937648
MixupTrain:  epoch  0, batch  1976 | loss: 2.0702889
MixupTrain:  epoch  0, batch  1977 | loss: 2.3746905
MixupTrain:  epoch  0, batch  1978 | loss: 2.3402073
MixupTrain:  epoch  0, batch  1979 | loss: 2.3965435
MixupTrain:  epoch  0, batch  1980 | loss: 2.5136027
MixupTrain:  epoch  0, batch  1981 | loss: 2.2525148
MixupTrain:  epoch  0, batch  1982 | loss: 2.1717565
MixupTrain:  epoch  0, batch  1983 | loss: 2.0889511
MixupTrain:  epoch  0, batch  1984 | loss: 2.3073134
MixupTrain:  epoch  0, batch  1985 | loss: 2.3323734
MixupTrain:  epoch  0, batch  1986 | loss: 2.2697766
MixupTrain:  epoch  0, batch  1987 | loss: 2.1671796
MixupTrain:  epoch  0, batch  1988 | loss: 2.1449757
MixupTrain:  epoch  0, batch  1989 | loss: 2.4741967
MixupTrain:  epoch  0, batch  1990 | loss: 2.2047744
MixupTrain:  epoch  0, batch  1991 | loss: 2.1072218
MixupTrain:  epoch  0, batch  1992 | loss: 2.3591695
MixupTrain:  epoch  0, batch  1993 | loss: 2.2434728
MixupTrain:  epoch  0, batch  1994 | loss: 2.1846285
MixupTrain:  epoch  0, batch  1995 | loss: 2.1674547
MixupTrain:  epoch  0, batch  1996 | loss: 2.2404394
MixupTrain:  epoch  0, batch  1997 | loss: 2.2585630
MixupTrain:  epoch  0, batch  1998 | loss: 2.2935333
MixupTrain:  epoch  0, batch  1999 | loss: 2.5631280
MixupTrain:  epoch  0, batch  2000 | loss: 2.2129374
MixupTrain:  epoch  0, batch  2001 | loss: 2.0272200
MixupTrain:  epoch  0, batch  2002 | loss: 2.1146672
MixupTrain:  epoch  0, batch  2003 | loss: 2.2414744
MixupTrain:  epoch  0, batch  2004 | loss: 2.4142306
MixupTrain:  epoch  0, batch  2005 | loss: 2.0897560
MixupTrain:  epoch  0, batch  2006 | loss: 2.2825174
MixupTrain:  epoch  0, batch  2007 | loss: 2.2917490
MixupTrain:  epoch  0, batch  2008 | loss: 2.2351124
MixupTrain:  epoch  0, batch  2009 | loss: 2.3337941
MixupTrain:  epoch  0, batch  2010 | loss: 2.1816926
MixupTrain:  epoch  0, batch  2011 | loss: 2.0915213
MixupTrain:  epoch  0, batch  2012 | loss: 2.3436422
MixupTrain:  epoch  0, batch  2013 | loss: 2.2803078
MixupTrain:  epoch  0, batch  2014 | loss: 2.2078907
MixupTrain:  epoch  0, batch  2015 | loss: 2.4289975
MixupTrain:  epoch  0, batch  2016 | loss: 2.4073565
MixupTrain:  epoch  0, batch  2017 | loss: 2.5418024
MixupTrain:  epoch  0, batch  2018 | loss: 2.3148406
MixupTrain:  epoch  0, batch  2019 | loss: 1.9346341
MixupTrain:  epoch  0, batch  2020 | loss: 2.3166313
MixupTrain:  epoch  0, batch  2021 | loss: 2.4160089
MixupTrain:  epoch  0, batch  2022 | loss: 2.3533363
MixupTrain:  epoch  0, batch  2023 | loss: 2.2986133
MixupTrain:  epoch  0, batch  2024 | loss: 2.1569562
MixupTrain:  epoch  0, batch  2025 | loss: 2.2327414
MixupTrain:  epoch  0, batch  2026 | loss: 2.3876784
MixupTrain:  epoch  0, batch  2027 | loss: 2.4319336
MixupTrain:  epoch  0, batch  2028 | loss: 2.3861527
MixupTrain:  epoch  0, batch  2029 | loss: 2.2237248
MixupTrain:  epoch  0, batch  2030 | loss: 2.4333909
MixupTrain:  epoch  0, batch  2031 | loss: 2.2585268
MixupTrain:  epoch  0, batch  2032 | loss: 2.4606953
MixupTrain:  epoch  0, batch  2033 | loss: 2.5202937
MixupTrain:  epoch  0, batch  2034 | loss: 2.2460034
MixupTrain:  epoch  0, batch  2035 | loss: 2.3960121
MixupTrain:  epoch  0, batch  2036 | loss: 2.3935854
MixupTrain:  epoch  0, batch  2037 | loss: 2.2597046
MixupTrain:  epoch  0, batch  2038 | loss: 2.0975454
MixupTrain:  epoch  0, batch  2039 | loss: 2.1483238
MixupTrain:  epoch  0, batch  2040 | loss: 1.9535673
MixupTrain:  epoch  0, batch  2041 | loss: 2.3204145
MixupTrain:  epoch  0, batch  2042 | loss: 2.2989874
MixupTrain:  epoch  0, batch  2043 | loss: 2.0511563
MixupTrain:  epoch  0, batch  2044 | loss: 2.3652434
MixupTrain:  epoch  0, batch  2045 | loss: 2.2982254
MixupTrain:  epoch  0, batch  2046 | loss: 1.9864047
MixupTrain:  epoch  0, batch  2047 | loss: 2.2123182
MixupTrain:  epoch  0, batch  2048 | loss: 2.2009015
MixupTrain:  epoch  0, batch  2049 | loss: 2.6665621
MixupTrain:  epoch  0, batch  2050 | loss: 2.3327518
MixupTrain:  epoch  0, batch  2051 | loss: 2.3585515
MixupTrain:  epoch  0, batch  2052 | loss: 2.3268499
MixupTrain:  epoch  0, batch  2053 | loss: 2.1557078
MixupTrain:  epoch  0, batch  2054 | loss: 2.0535920
MixupTrain:  epoch  0, batch  2055 | loss: 2.3337185
MixupTrain:  epoch  0, batch  2056 | loss: 2.2333026
MixupTrain:  epoch  0, batch  2057 | loss: 2.0816760
MixupTrain:  epoch  0, batch  2058 | loss: 2.5719254
MixupTrain:  epoch  0, batch  2059 | loss: 2.2020340
MixupTrain:  epoch  0, batch  2060 | loss: 2.3537345
MixupTrain:  epoch  0, batch  2061 | loss: 2.2446194
MixupTrain:  epoch  0, batch  2062 | loss: 2.1706290
MixupTrain:  epoch  0, batch  2063 | loss: 2.2395949
MixupTrain:  epoch  0, batch  2064 | loss: 2.5466752
MixupTrain:  epoch  0, batch  2065 | loss: 2.3154151
MixupTrain:  epoch  0, batch  2066 | loss: 2.4122014
MixupTrain:  epoch  0, batch  2067 | loss: 2.3055024
MixupTrain:  epoch  0, batch  2068 | loss: 2.0723424
MixupTrain:  epoch  0, batch  2069 | loss: 2.3108063
MixupTrain:  epoch  0, batch  2070 | loss: 2.3074152
MixupTrain:  epoch  0, batch  2071 | loss: 2.4324336
MixupTrain:  epoch  0, batch  2072 | loss: 2.3119991
MixupTrain:  epoch  0, batch  2073 | loss: 2.3226936
MixupTrain:  epoch  0, batch  2074 | loss: 2.0706377
MixupTrain:  epoch  0, batch  2075 | loss: 2.0840149
MixupTrain:  epoch  0, batch  2076 | loss: 2.2028220
MixupTrain:  epoch  0, batch  2077 | loss: 2.2713642
MixupTrain:  epoch  0, batch  2078 | loss: 2.3432145
MixupTrain:  epoch  0, batch  2079 | loss: 2.1674244
MixupTrain:  epoch  0, batch  2080 | loss: 2.2778027
MixupTrain:  epoch  0, batch  2081 | loss: 2.3789437
MixupTrain:  epoch  0, batch  2082 | loss: 2.0740604
MixupTrain:  epoch  0, batch  2083 | loss: 2.3874316
MixupTrain:  epoch  0, batch  2084 | loss: 2.3575482
MixupTrain:  epoch  0, batch  2085 | loss: 2.1226077
MixupTrain:  epoch  0, batch  2086 | loss: 2.0915878
MixupTrain:  epoch  0, batch  2087 | loss: 2.1700139
MixupTrain:  epoch  0, batch  2088 | loss: 2.4426622
MixupTrain:  epoch  0, batch  2089 | loss: 2.4381509
MixupTrain:  epoch  0, batch  2090 | loss: 2.2903514
MixupTrain:  epoch  0, batch  2091 | loss: 2.2357905
MixupTrain:  epoch  0, batch  2092 | loss: 2.3172998
MixupTrain:  epoch  0, batch  2093 | loss: 2.4990251
MixupTrain:  epoch  0, batch  2094 | loss: 2.1939907
MixupTrain:  epoch  0, batch  2095 | loss: 2.1705830
MixupTrain:  epoch  0, batch  2096 | loss: 2.3531075
MixupTrain:  epoch  0, batch  2097 | loss: 2.6605749
MixupTrain:  epoch  0, batch  2098 | loss: 2.3063800
MixupTrain:  epoch  0, batch  2099 | loss: 2.4644060
MixupTrain:  epoch  0, batch  2100 | loss: 2.0704427
MixupTrain:  epoch  0, batch  2101 | loss: 2.0597439
MixupTrain:  epoch  0, batch  2102 | loss: 2.0839343
MixupTrain:  epoch  0, batch  2103 | loss: 2.3593929
MixupTrain:  epoch  0, batch  2104 | loss: 2.2782910
MixupTrain:  epoch  0, batch  2105 | loss: 2.4648194
MixupTrain:  epoch  0, batch  2106 | loss: 2.2066507
MixupTrain:  epoch  0, batch  2107 | loss: 2.2543221
MixupTrain:  epoch  0, batch  2108 | loss: 2.1408548
MixupTrain:  epoch  0, batch  2109 | loss: 2.5981092
MixupTrain:  epoch  0, batch  2110 | loss: 2.3111792
MixupTrain:  epoch  0, batch  2111 | loss: 2.5025880
MixupTrain:  epoch  0, batch  2112 | loss: 2.2698429
MixupTrain:  epoch  0, batch  2113 | loss: 2.2683456
MixupTrain:  epoch  0, batch  2114 | loss: 2.1890306
MixupTrain:  epoch  0, batch  2115 | loss: 2.0676312
MixupTrain:  epoch  0, batch  2116 | loss: 2.2952387
MixupTrain:  epoch  0, batch  2117 | loss: 2.3002472
MixupTrain:  epoch  0, batch  2118 | loss: 2.1889977
MixupTrain:  epoch  0, batch  2119 | loss: 2.5469000
MixupTrain:  epoch  0, batch  2120 | loss: 2.3282254
MixupTrain:  epoch  0, batch  2121 | loss: 2.1864233
MixupTrain:  epoch  0, batch  2122 | loss: 2.4128561
MixupTrain:  epoch  0, batch  2123 | loss: 2.1906059
MixupTrain:  epoch  0, batch  2124 | loss: 2.4876771
MixupTrain:  epoch  0, batch  2125 | loss: 2.0576036
MixupTrain:  epoch  0, batch  2126 | loss: 2.1406350
MixupTrain:  epoch  0, batch  2127 | loss: 2.1743889
MixupTrain:  epoch  0, batch  2128 | loss: 2.2369289
MixupTrain:  epoch  0, batch  2129 | loss: 2.3548753
MixupTrain:  epoch  0, batch  2130 | loss: 2.0510793
MixupTrain:  epoch  0, batch  2131 | loss: 2.0980744
MixupTrain:  epoch  0, batch  2132 | loss: 2.1955905
MixupTrain:  epoch  0, batch  2133 | loss: 2.3346758
MixupTrain:  epoch  0, batch  2134 | loss: 2.1011109
MixupTrain:  epoch  0, batch  2135 | loss: 2.0859272
MixupTrain:  epoch  0, batch  2136 | loss: 2.2487633
MixupTrain:  epoch  0, batch  2137 | loss: 2.2771025
MixupTrain:  epoch  0, batch  2138 | loss: 2.2538147
MixupTrain:  epoch  0, batch  2139 | loss: 2.0405943
MixupTrain:  epoch  0, batch  2140 | loss: 2.1616371
MixupTrain:  epoch  0, batch  2141 | loss: 2.3750732
MixupTrain:  epoch  0, batch  2142 | loss: 2.2702138
MixupTrain:  epoch  0, batch  2143 | loss: 2.1091185
MixupTrain:  epoch  0, batch  2144 | loss: 2.4809771
MixupTrain:  epoch  0, batch  2145 | loss: 2.0670538
MixupTrain:  epoch  0, batch  2146 | loss: 2.1165566
MixupTrain:  epoch  0, batch  2147 | loss: 2.3181841
MixupTrain:  epoch  0, batch  2148 | loss: 2.3381314
MixupTrain:  epoch  0, batch  2149 | loss: 2.1806507
MixupTrain:  epoch  0, batch  2150 | loss: 2.2377019
MixupTrain:  epoch  0, batch  2151 | loss: 2.2882907
MixupTrain:  epoch  0, batch  2152 | loss: 2.3720255
MixupTrain:  epoch  0, batch  2153 | loss: 2.1647186
MixupTrain:  epoch  0, batch  2154 | loss: 2.1767740
MixupTrain:  epoch  0, batch  2155 | loss: 2.3450670
MixupTrain:  epoch  0, batch  2156 | loss: 2.3283341
MixupTrain:  epoch  0, batch  2157 | loss: 2.1031208
MixupTrain:  epoch  0, batch  2158 | loss: 2.4453387
MixupTrain:  epoch  0, batch  2159 | loss: 2.2324979
MixupTrain:  epoch  0, batch  2160 | loss: 2.3849120
MixupTrain:  epoch  0, batch  2161 | loss: 2.5242820
MixupTrain:  epoch  0, batch  2162 | loss: 2.2958100
MixupTrain:  epoch  0, batch  2163 | loss: 2.6538136
MixupTrain:  epoch  0, batch  2164 | loss: 2.1985221
MixupTrain:  epoch  0, batch  2165 | loss: 2.3243256
MixupTrain:  epoch  0, batch  2166 | loss: 2.1322732
MixupTrain:  epoch  0, batch  2167 | loss: 2.1487122
MixupTrain:  epoch  0, batch  2168 | loss: 2.0600820
MixupTrain:  epoch  0, batch  2169 | loss: 2.3335168
MixupTrain:  epoch  0, batch  2170 | loss: 2.3243380
MixupTrain:  epoch  0, batch  2171 | loss: 2.4046664
MixupTrain:  epoch  0, batch  2172 | loss: 2.4785633
MixupTrain:  epoch  0, batch  2173 | loss: 2.4445548
MixupTrain:  epoch  0, batch  2174 | loss: 2.4015479
MixupTrain:  epoch  0, batch  2175 | loss: 2.3842716
MixupTrain:  epoch  0, batch  2176 | loss: 2.5228224
MixupTrain:  epoch  0, batch  2177 | loss: 2.1560981
MixupTrain:  epoch  0, batch  2178 | loss: 2.1716564
MixupTrain:  epoch  0, batch  2179 | loss: 2.1882453
MixupTrain:  epoch  0, batch  2180 | loss: 2.3585513
MixupTrain:  epoch  0, batch  2181 | loss: 2.0597415
MixupTrain:  epoch  0, batch  2182 | loss: 2.5779243
MixupTrain:  epoch  0, batch  2183 | loss: 2.2339292
MixupTrain:  epoch  0, batch  2184 | loss: 2.1585529
MixupTrain:  epoch  0, batch  2185 | loss: 2.4238350
MixupTrain:  epoch  0, batch  2186 | loss: 2.2254288
MixupTrain:  epoch  0, batch  2187 | loss: 2.2151031
MixupTrain:  epoch  0, batch  2188 | loss: 2.0866702
MixupTrain:  epoch  0, batch  2189 | loss: 2.2830486
MixupTrain:  epoch  0, batch  2190 | loss: 2.4444203
MixupTrain:  epoch  0, batch  2191 | loss: 2.0143471
MixupTrain:  epoch  0, batch  2192 | loss: 2.1084940
MixupTrain:  epoch  0, batch  2193 | loss: 2.3672318
MixupTrain:  epoch  0, batch  2194 | loss: 2.2458515
MixupTrain:  epoch  0, batch  2195 | loss: 2.3611023
MixupTrain:  epoch  0, batch  2196 | loss: 2.3722796
MixupTrain:  epoch  0, batch  2197 | loss: 2.2595892
MixupTrain:  epoch  0, batch  2198 | loss: 2.1550691
MixupTrain:  epoch  0, batch  2199 | loss: 2.5867155
MixupTrain:  epoch  0, batch  2200 | loss: 2.4595456
MixupTrain:  epoch  0, batch  2201 | loss: 2.2826862
MixupTrain:  epoch  0, batch  2202 | loss: 2.2054336
MixupTrain:  epoch  0, batch  2203 | loss: 2.2357354
MixupTrain:  epoch  0, batch  2204 | loss: 2.0169120
MixupTrain:  epoch  0, batch  2205 | loss: 2.2423975
MixupTrain:  epoch  0, batch  2206 | loss: 2.1381478
MixupTrain:  epoch  0, batch  2207 | loss: 2.4961786
MixupTrain:  epoch  0, batch  2208 | loss: 2.2545478
MixupTrain:  epoch  0, batch  2209 | loss: 2.2860441
MixupTrain:  epoch  0, batch  2210 | loss: 2.3269062
MixupTrain:  epoch  0, batch  2211 | loss: 2.2288423
MixupTrain:  epoch  0, batch  2212 | loss: 2.1992650
MixupTrain:  epoch  0, batch  2213 | loss: 2.1130588
MixupTrain:  epoch  0, batch  2214 | loss: 2.1418962
MixupTrain:  epoch  0, batch  2215 | loss: 2.3902745
MixupTrain:  epoch  0, batch  2216 | loss: 2.2192578
MixupTrain:  epoch  0, batch  2217 | loss: 2.3239734
MixupTrain:  epoch  0, batch  2218 | loss: 2.3607576
MixupTrain:  epoch  0, batch  2219 | loss: 2.4023085
MixupTrain:  epoch  0, batch  2220 | loss: 2.1835828
MixupTrain:  epoch  0, batch  2221 | loss: 2.1776400
MixupTrain:  epoch  0, batch  2222 | loss: 1.9076023
MixupTrain:  epoch  0, batch  2223 | loss: 2.2364049
MixupTrain:  epoch  0, batch  2224 | loss: 2.5309627
MixupTrain:  epoch  0, batch  2225 | loss: 2.2327719
MixupTrain:  epoch  0, batch  2226 | loss: 2.1780825
MixupTrain:  epoch  0, batch  2227 | loss: 2.3238358
MixupTrain:  epoch  0, batch  2228 | loss: 2.3362799
MixupTrain:  epoch  0, batch  2229 | loss: 2.1809611
MixupTrain:  epoch  0, batch  2230 | loss: 2.2292385
MixupTrain:  epoch  0, batch  2231 | loss: 2.5099359
MixupTrain:  epoch  0, batch  2232 | loss: 2.4054701
MixupTrain:  epoch  0, batch  2233 | loss: 2.2460403
MixupTrain:  epoch  0, batch  2234 | loss: 2.3195944
MixupTrain:  epoch  0, batch  2235 | loss: 2.3942468
MemoryTrain:  epoch  0, batch     0 | loss: 1.8042344
MemoryTrain:  epoch  0, batch     1 | loss: 2.1779504
MemoryTrain:  epoch  0, batch     2 | loss: 2.2958908
MemoryTrain:  epoch  0, batch     3 | loss: 2.3681178
MemoryTrain:  epoch  0, batch     4 | loss: 2.9827285
MemoryTrain:  epoch  0, batch     5 | loss: 2.7813315
MemoryTrain:  epoch  0, batch     6 | loss: 2.6035187
MemoryTrain:  epoch  0, batch     7 | loss: 3.3512139
MemoryTrain:  epoch  0, batch     8 | loss: 2.2646446
MemoryTrain:  epoch  0, batch     9 | loss: 2.3895812
MemoryTrain:  epoch  0, batch    10 | loss: 2.4435005
MemoryTrain:  epoch  0, batch    11 | loss: 2.3237023
MemoryTrain:  epoch  0, batch    12 | loss: 2.1476209
MemoryTrain:  epoch  0, batch    13 | loss: 2.1650577
MemoryTrain:  epoch  0, batch    14 | loss: 2.0562701
MemoryTrain:  epoch  0, batch    15 | loss: 1.8949418
MemoryTrain:  epoch  1, batch     0 | loss: 1.8238962
MemoryTrain:  epoch  1, batch     1 | loss: 1.8199378
MemoryTrain:  epoch  1, batch     2 | loss: 1.8215357
MemoryTrain:  epoch  1, batch     3 | loss: 1.8134235
MemoryTrain:  epoch  1, batch     4 | loss: 1.8128430
MemoryTrain:  epoch  1, batch     5 | loss: 1.8400954
MemoryTrain:  epoch  1, batch     6 | loss: 1.8133562
MemoryTrain:  epoch  1, batch     7 | loss: 1.8118852
MemoryTrain:  epoch  1, batch     8 | loss: 1.8182745
MemoryTrain:  epoch  1, batch     9 | loss: 1.8215947
MemoryTrain:  epoch  1, batch    10 | loss: 1.8090562
MemoryTrain:  epoch  1, batch    11 | loss: 1.8387201
MemoryTrain:  epoch  1, batch    12 | loss: 1.8245230
MemoryTrain:  epoch  1, batch    13 | loss: 1.8313050
MemoryTrain:  epoch  1, batch    14 | loss: 1.8274391
MemoryTrain:  epoch  1, batch    15 | loss: 1.8150542
MemoryTrain:  epoch  2, batch     0 | loss: 1.8095551
MemoryTrain:  epoch  2, batch     1 | loss: 1.8100116
MemoryTrain:  epoch  2, batch     2 | loss: 1.8142776
MemoryTrain:  epoch  2, batch     3 | loss: 1.8037717
MemoryTrain:  epoch  2, batch     4 | loss: 1.8091271
MemoryTrain:  epoch  2, batch     5 | loss: 1.8080559
MemoryTrain:  epoch  2, batch     6 | loss: 1.8137703
MemoryTrain:  epoch  2, batch     7 | loss: 1.8060055
MemoryTrain:  epoch  2, batch     8 | loss: 1.8066452
MemoryTrain:  epoch  2, batch     9 | loss: 1.8067749
MemoryTrain:  epoch  2, batch    10 | loss: 1.8121955
MemoryTrain:  epoch  2, batch    11 | loss: 1.8042080
MemoryTrain:  epoch  2, batch    12 | loss: 1.8145090
MemoryTrain:  epoch  2, batch    13 | loss: 1.8024238
MemoryTrain:  epoch  2, batch    14 | loss: 1.8188537
MemoryTrain:  epoch  2, batch    15 | loss: 1.8004389
MemoryTrain:  epoch  3, batch     0 | loss: 1.8070143
MemoryTrain:  epoch  3, batch     1 | loss: 1.8152372
MemoryTrain:  epoch  3, batch     2 | loss: 1.8088307
MemoryTrain:  epoch  3, batch     3 | loss: 1.8101368
MemoryTrain:  epoch  3, batch     4 | loss: 1.8064859
MemoryTrain:  epoch  3, batch     5 | loss: 1.8065841
MemoryTrain:  epoch  3, batch     6 | loss: 1.8063902
MemoryTrain:  epoch  3, batch     7 | loss: 1.8026907
MemoryTrain:  epoch  3, batch     8 | loss: 1.8047104
MemoryTrain:  epoch  3, batch     9 | loss: 1.8057066
MemoryTrain:  epoch  3, batch    10 | loss: 1.8083773
MemoryTrain:  epoch  3, batch    11 | loss: 1.8028607
MemoryTrain:  epoch  3, batch    12 | loss: 1.8018919
MemoryTrain:  epoch  3, batch    13 | loss: 1.8025264
MemoryTrain:  epoch  3, batch    14 | loss: 1.8061084
MemoryTrain:  epoch  3, batch    15 | loss: 1.8077071
MemoryTrain:  epoch  4, batch     0 | loss: 1.8015640
MemoryTrain:  epoch  4, batch     1 | loss: 1.8046796
MemoryTrain:  epoch  4, batch     2 | loss: 1.8055644
MemoryTrain:  epoch  4, batch     3 | loss: 1.8068047
MemoryTrain:  epoch  4, batch     4 | loss: 1.8112183
MemoryTrain:  epoch  4, batch     5 | loss: 1.8049664
MemoryTrain:  epoch  4, batch     6 | loss: 1.8079154
MemoryTrain:  epoch  4, batch     7 | loss: 1.8070496
MemoryTrain:  epoch  4, batch     8 | loss: 1.8069426
MemoryTrain:  epoch  4, batch     9 | loss: 1.8081343
MemoryTrain:  epoch  4, batch    10 | loss: 1.8044497
MemoryTrain:  epoch  4, batch    11 | loss: 1.8061196
MemoryTrain:  epoch  4, batch    12 | loss: 1.8099667
MemoryTrain:  epoch  4, batch    13 | loss: 1.8064862
MemoryTrain:  epoch  4, batch    14 | loss: 1.8069146
MemoryTrain:  epoch  4, batch    15 | loss: 1.8141520
MemoryTrain:  epoch  5, batch     0 | loss: 1.8109350
MemoryTrain:  epoch  5, batch     1 | loss: 1.8055310
MemoryTrain:  epoch  5, batch     2 | loss: 1.8084955
MemoryTrain:  epoch  5, batch     3 | loss: 1.8084852
MemoryTrain:  epoch  5, batch     4 | loss: 1.8083055
MemoryTrain:  epoch  5, batch     5 | loss: 1.8094965
MemoryTrain:  epoch  5, batch     6 | loss: 1.8097458
MemoryTrain:  epoch  5, batch     7 | loss: 1.8057494
MemoryTrain:  epoch  5, batch     8 | loss: 1.8039985
MemoryTrain:  epoch  5, batch     9 | loss: 1.8060985
MemoryTrain:  epoch  5, batch    10 | loss: 1.8036129
MemoryTrain:  epoch  5, batch    11 | loss: 1.8065218
MemoryTrain:  epoch  5, batch    12 | loss: 1.8060448
MemoryTrain:  epoch  5, batch    13 | loss: 1.8113182
MemoryTrain:  epoch  5, batch    14 | loss: 1.8040841
MemoryTrain:  epoch  5, batch    15 | loss: 1.8111982
MemoryTrain:  epoch  6, batch     0 | loss: 1.8126711
MemoryTrain:  epoch  6, batch     1 | loss: 1.8084381
MemoryTrain:  epoch  6, batch     2 | loss: 1.8119566
MemoryTrain:  epoch  6, batch     3 | loss: 1.8072562
MemoryTrain:  epoch  6, batch     4 | loss: 1.8071911
MemoryTrain:  epoch  6, batch     5 | loss: 1.8074999
MemoryTrain:  epoch  6, batch     6 | loss: 1.8052138
MemoryTrain:  epoch  6, batch     7 | loss: 1.8051139
MemoryTrain:  epoch  6, batch     8 | loss: 1.8076922
MemoryTrain:  epoch  6, batch     9 | loss: 1.8084382
MemoryTrain:  epoch  6, batch    10 | loss: 1.8058076
MemoryTrain:  epoch  6, batch    11 | loss: 1.8275369
MemoryTrain:  epoch  6, batch    12 | loss: 1.8051710
MemoryTrain:  epoch  6, batch    13 | loss: 1.8103777
MemoryTrain:  epoch  6, batch    14 | loss: 1.8069561
MemoryTrain:  epoch  6, batch    15 | loss: 1.8163832
MemoryTrain:  epoch  7, batch     0 | loss: 1.8122872
MemoryTrain:  epoch  7, batch     1 | loss: 1.8214875
MemoryTrain:  epoch  7, batch     2 | loss: 1.8112215
MemoryTrain:  epoch  7, batch     3 | loss: 1.8311332
MemoryTrain:  epoch  7, batch     4 | loss: 1.8073940
MemoryTrain:  epoch  7, batch     5 | loss: 1.8452331
MemoryTrain:  epoch  7, batch     6 | loss: 1.8006078
MemoryTrain:  epoch  7, batch     7 | loss: 1.8057501
MemoryTrain:  epoch  7, batch     8 | loss: 1.8149692
MemoryTrain:  epoch  7, batch     9 | loss: 1.8111827
MemoryTrain:  epoch  7, batch    10 | loss: 1.8047061
MemoryTrain:  epoch  7, batch    11 | loss: 1.8029978
MemoryTrain:  epoch  7, batch    12 | loss: 1.8042988
MemoryTrain:  epoch  7, batch    13 | loss: 1.8172230
MemoryTrain:  epoch  7, batch    14 | loss: 1.8112097
MemoryTrain:  epoch  7, batch    15 | loss: 1.8739680
MemoryTrain:  epoch  8, batch     0 | loss: 1.8101003
MemoryTrain:  epoch  8, batch     1 | loss: 1.8119243
MemoryTrain:  epoch  8, batch     2 | loss: 1.8065231
MemoryTrain:  epoch  8, batch     3 | loss: 1.8069159
MemoryTrain:  epoch  8, batch     4 | loss: 1.8087289
MemoryTrain:  epoch  8, batch     5 | loss: 1.8139729
MemoryTrain:  epoch  8, batch     6 | loss: 1.8044645
MemoryTrain:  epoch  8, batch     7 | loss: 1.8016825
MemoryTrain:  epoch  8, batch     8 | loss: 1.8084178
MemoryTrain:  epoch  8, batch     9 | loss: 1.8153646
MemoryTrain:  epoch  8, batch    10 | loss: 1.8045738
MemoryTrain:  epoch  8, batch    11 | loss: 1.8046792
MemoryTrain:  epoch  8, batch    12 | loss: 1.8022847
MemoryTrain:  epoch  8, batch    13 | loss: 1.8105896
MemoryTrain:  epoch  8, batch    14 | loss: 1.8039160
MemoryTrain:  epoch  8, batch    15 | loss: 1.8015239
MemoryTrain:  epoch  9, batch     0 | loss: 1.8075149
MemoryTrain:  epoch  9, batch     1 | loss: 1.8080139
MemoryTrain:  epoch  9, batch     2 | loss: 1.8019850
MemoryTrain:  epoch  9, batch     3 | loss: 1.8050249
MemoryTrain:  epoch  9, batch     4 | loss: 1.8072150
MemoryTrain:  epoch  9, batch     5 | loss: 1.8055356
MemoryTrain:  epoch  9, batch     6 | loss: 1.8060017
MemoryTrain:  epoch  9, batch     7 | loss: 1.8079767
MemoryTrain:  epoch  9, batch     8 | loss: 1.8058850
MemoryTrain:  epoch  9, batch     9 | loss: 1.8058147
MemoryTrain:  epoch  9, batch    10 | loss: 1.8070245
MemoryTrain:  epoch  9, batch    11 | loss: 1.8047612
MemoryTrain:  epoch  9, batch    12 | loss: 1.8091271
MemoryTrain:  epoch  9, batch    13 | loss: 1.8067265
MemoryTrain:  epoch  9, batch    14 | loss: 1.8027532
MemoryTrain:  epoch  9, batch    15 | loss: 1.8058413
[EVAL] batch:    0 | acc: 100.00%,  total acc: 100.00%   
[EVAL] batch:    1 | acc: 93.75%,  total acc: 96.88%   
[EVAL] batch:    2 | acc: 87.50%,  total acc: 93.75%   
[EVAL] batch:    3 | acc: 93.75%,  total acc: 93.75%   
[EVAL] batch:    4 | acc: 81.25%,  total acc: 91.25%   
[EVAL] batch:    5 | acc: 68.75%,  total acc: 87.50%   
[EVAL] batch:    6 | acc: 87.50%,  total acc: 87.50%   
[EVAL] batch:    7 | acc: 87.50%,  total acc: 87.50%   
[EVAL] batch:    8 | acc: 93.75%,  total acc: 88.19%   
[EVAL] batch:    9 | acc: 93.75%,  total acc: 88.75%   
[EVAL] batch:   10 | acc: 87.50%,  total acc: 88.64%   
[EVAL] batch:   11 | acc: 100.00%,  total acc: 89.58%   
[EVAL] batch:   12 | acc: 100.00%,  total acc: 90.38%   
[EVAL] batch:   13 | acc: 100.00%,  total acc: 91.07%   
[EVAL] batch:   14 | acc: 100.00%,  total acc: 91.67%   
[EVAL] batch:   15 | acc: 100.00%,  total acc: 92.19%   
[EVAL] batch:   16 | acc: 100.00%,  total acc: 92.65%   
[EVAL] batch:   17 | acc: 25.00%,  total acc: 88.89%   
[EVAL] batch:    0 | acc: 0.00%,  total acc: 0.00%   
[EVAL] batch:    1 | acc: 18.75%,  total acc: 9.38%   
[EVAL] batch:    2 | acc: 12.50%,  total acc: 10.42%   
[EVAL] batch:    3 | acc: 0.00%,  total acc: 7.81%   
[EVAL] batch:    4 | acc: 12.50%,  total acc: 8.75%   
[EVAL] batch:    5 | acc: 12.50%,  total acc: 9.38%   
[EVAL] batch:    6 | acc: 43.75%,  total acc: 14.29%   
[EVAL] batch:    7 | acc: 25.00%,  total acc: 15.62%   
[EVAL] batch:    8 | acc: 37.50%,  total acc: 18.06%   
[EVAL] batch:    9 | acc: 31.25%,  total acc: 19.38%   
[EVAL] batch:   10 | acc: 37.50%,  total acc: 21.02%   
[EVAL] batch:   11 | acc: 37.50%,  total acc: 22.40%   
[EVAL] batch:   12 | acc: 6.25%,  total acc: 21.15%   
[EVAL] batch:   13 | acc: 25.00%,  total acc: 21.43%   
[EVAL] batch:   14 | acc: 68.75%,  total acc: 24.58%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 26.56%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 29.41%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 31.25%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 32.89%   
[EVAL] batch:   19 | acc: 81.25%,  total acc: 35.31%   
[EVAL] batch:   20 | acc: 81.25%,  total acc: 37.50%   
[EVAL] batch:   21 | acc: 62.50%,  total acc: 38.64%   
[EVAL] batch:   22 | acc: 62.50%,  total acc: 39.67%   
[EVAL] batch:   23 | acc: 93.75%,  total acc: 41.93%   
[EVAL] batch:   24 | acc: 93.75%,  total acc: 44.00%   
[EVAL] batch:   25 | acc: 81.25%,  total acc: 45.43%   
[EVAL] batch:   26 | acc: 75.00%,  total acc: 46.53%   
[EVAL] batch:   27 | acc: 81.25%,  total acc: 47.77%   
[EVAL] batch:   28 | acc: 68.75%,  total acc: 48.49%   
[EVAL] batch:   29 | acc: 68.75%,  total acc: 49.17%   
[EVAL] batch:   30 | acc: 93.75%,  total acc: 50.60%   
[EVAL] batch:   31 | acc: 68.75%,  total acc: 51.17%   
[EVAL] batch:   32 | acc: 87.50%,  total acc: 52.27%   
[EVAL] batch:   33 | acc: 6.25%,  total acc: 50.92%   
[EVAL] batch:   34 | acc: 0.00%,  total acc: 49.46%   
[EVAL] batch:   35 | acc: 0.00%,  total acc: 48.09%   
[EVAL] batch:   36 | acc: 0.00%,  total acc: 46.79%   
[EVAL] batch:   37 | acc: 0.00%,  total acc: 45.56%   
[EVAL] batch:   38 | acc: 6.25%,  total acc: 44.55%   
[EVAL] batch:   39 | acc: 56.25%,  total acc: 44.84%   
[EVAL] batch:   40 | acc: 56.25%,  total acc: 45.12%   
[EVAL] batch:   41 | acc: 62.50%,  total acc: 45.54%   
[EVAL] batch:   42 | acc: 50.00%,  total acc: 45.64%   
[EVAL] batch:   43 | acc: 37.50%,  total acc: 45.45%   
[EVAL] batch:   44 | acc: 43.75%,  total acc: 45.42%   
[EVAL] batch:   45 | acc: 18.75%,  total acc: 44.84%   
[EVAL] batch:   46 | acc: 43.75%,  total acc: 44.81%   
[EVAL] batch:   47 | acc: 93.75%,  total acc: 45.83%   
[EVAL] batch:   48 | acc: 25.00%,  total acc: 45.41%   
[EVAL] batch:   49 | acc: 75.00%,  total acc: 46.00%   
[EVAL] batch:   50 | acc: 50.00%,  total acc: 46.08%   
[EVAL] batch:   51 | acc: 62.50%,  total acc: 46.39%   
[EVAL] batch:   52 | acc: 62.50%,  total acc: 46.70%   
[EVAL] batch:   53 | acc: 31.25%,  total acc: 46.41%   
[EVAL] batch:   54 | acc: 37.50%,  total acc: 46.25%   
[EVAL] batch:   55 | acc: 43.75%,  total acc: 46.21%   
[EVAL] batch:   56 | acc: 62.50%,  total acc: 46.49%   
[EVAL] batch:   57 | acc: 75.00%,  total acc: 46.98%   
[EVAL] batch:   58 | acc: 100.00%,  total acc: 47.88%   
[EVAL] batch:   59 | acc: 81.25%,  total acc: 48.44%   
[EVAL] batch:   60 | acc: 25.00%,  total acc: 48.05%   
[EVAL] batch:   61 | acc: 0.00%,  total acc: 47.28%   
[EVAL] batch:   62 | acc: 0.00%,  total acc: 46.53%   
[EVAL] batch:   63 | acc: 0.00%,  total acc: 45.80%   
[EVAL] batch:   64 | acc: 31.25%,  total acc: 45.58%   
[EVAL] batch:   65 | acc: 25.00%,  total acc: 45.27%   
[EVAL] batch:   66 | acc: 0.00%,  total acc: 44.59%   
[EVAL] batch:   67 | acc: 25.00%,  total acc: 44.30%   
[EVAL] batch:   68 | acc: 6.25%,  total acc: 43.75%   
[EVAL] batch:   69 | acc: 6.25%,  total acc: 43.21%   
[EVAL] batch:   70 | acc: 25.00%,  total acc: 42.96%   
[EVAL] batch:   71 | acc: 25.00%,  total acc: 42.71%   
[EVAL] batch:   72 | acc: 25.00%,  total acc: 42.47%   
[EVAL] batch:   73 | acc: 0.00%,  total acc: 41.89%   
[EVAL] batch:   74 | acc: 0.00%,  total acc: 41.33%   
[EVAL] batch:   75 | acc: 0.00%,  total acc: 40.79%   
[EVAL] batch:   76 | acc: 0.00%,  total acc: 40.26%   
[EVAL] batch:   77 | acc: 0.00%,  total acc: 39.74%   
[EVAL] batch:   78 | acc: 31.25%,  total acc: 39.64%   
[EVAL] batch:   79 | acc: 93.75%,  total acc: 40.31%   
[EVAL] batch:   80 | acc: 100.00%,  total acc: 41.05%   
[EVAL] batch:   81 | acc: 100.00%,  total acc: 41.77%   
[EVAL] batch:   82 | acc: 87.50%,  total acc: 42.32%   
[EVAL] batch:   83 | acc: 62.50%,  total acc: 42.56%   
[EVAL] batch:   84 | acc: 6.25%,  total acc: 42.13%   
[EVAL] batch:   85 | acc: 6.25%,  total acc: 41.72%   
[EVAL] batch:   86 | acc: 18.75%,  total acc: 41.45%   
[EVAL] batch:   87 | acc: 87.50%,  total acc: 41.97%   
[EVAL] batch:   88 | acc: 87.50%,  total acc: 42.49%   
[EVAL] batch:   89 | acc: 93.75%,  total acc: 43.06%   
[EVAL] batch:   90 | acc: 100.00%,  total acc: 43.68%   
[EVAL] batch:   91 | acc: 100.00%,  total acc: 44.29%   
[EVAL] batch:   92 | acc: 93.75%,  total acc: 44.83%   
[EVAL] batch:   93 | acc: 100.00%,  total acc: 45.41%   
[EVAL] batch:   94 | acc: 100.00%,  total acc: 45.99%   
[EVAL] batch:   95 | acc: 81.25%,  total acc: 46.35%   
[EVAL] batch:   96 | acc: 37.50%,  total acc: 46.26%   
[EVAL] batch:   97 | acc: 56.25%,  total acc: 46.36%   
[EVAL] batch:   98 | acc: 93.75%,  total acc: 46.84%   
[EVAL] batch:   99 | acc: 100.00%,  total acc: 47.38%   
[EVAL] batch:  100 | acc: 81.25%,  total acc: 47.71%   
[EVAL] batch:  101 | acc: 56.25%,  total acc: 47.79%   
[EVAL] batch:  102 | acc: 68.75%,  total acc: 48.00%   
[EVAL] batch:  103 | acc: 68.75%,  total acc: 48.20%   
[EVAL] batch:  104 | acc: 87.50%,  total acc: 48.57%   
[EVAL] batch:  105 | acc: 56.25%,  total acc: 48.64%   
[EVAL] batch:  106 | acc: 93.75%,  total acc: 49.07%   
[EVAL] batch:  107 | acc: 93.75%,  total acc: 49.48%   
[EVAL] batch:  108 | acc: 93.75%,  total acc: 49.89%   
[EVAL] batch:  109 | acc: 81.25%,  total acc: 50.17%   
[EVAL] batch:  110 | acc: 75.00%,  total acc: 50.39%   
[EVAL] batch:  111 | acc: 25.00%,  total acc: 50.17%   
[EVAL] batch:  112 | acc: 43.75%,  total acc: 50.11%   
[EVAL] batch:  113 | acc: 25.00%,  total acc: 49.89%   
[EVAL] batch:  114 | acc: 12.50%,  total acc: 49.57%   
[EVAL] batch:  115 | acc: 75.00%,  total acc: 49.78%   
[EVAL] batch:  116 | acc: 93.75%,  total acc: 50.16%   
[EVAL] batch:  117 | acc: 87.50%,  total acc: 50.48%   
[EVAL] batch:  118 | acc: 93.75%,  total acc: 50.84%   
[EVAL] batch:  119 | acc: 87.50%,  total acc: 51.15%   
[EVAL] batch:  120 | acc: 68.75%,  total acc: 51.29%   
[EVAL] batch:  121 | acc: 81.25%,  total acc: 51.54%   
[EVAL] batch:  122 | acc: 100.00%,  total acc: 51.93%   
[EVAL] batch:  123 | acc: 87.50%,  total acc: 52.22%   
[EVAL] batch:  124 | acc: 93.75%,  total acc: 52.55%   
[EVAL] batch:  125 | acc: 81.25%,  total acc: 52.78%   
[EVAL] batch:  126 | acc: 100.00%,  total acc: 53.15%   
[EVAL] batch:  127 | acc: 100.00%,  total acc: 53.52%   
[EVAL] batch:  128 | acc: 100.00%,  total acc: 53.88%   
[EVAL] batch:  129 | acc: 100.00%,  total acc: 54.23%   
[EVAL] batch:  130 | acc: 100.00%,  total acc: 54.58%   
[EVAL] batch:  131 | acc: 100.00%,  total acc: 54.92%   
[EVAL] batch:  132 | acc: 62.50%,  total acc: 54.98%   
cur_acc:  ['0.8712', '0.8705', '0.7266', '0.8990', '0.5739', '0.9062', '0.8292', '0.8889']
his_acc:  ['0.8712', '0.8564', '0.6238', '0.6241', '0.5469', '0.5600', '0.5442', '0.5498']
--------Round  1
seed:  200
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 6 3 2 4 0 5 1]
prepared data!
CurrentTrain: epoch  0, batch     0 | loss: 11.9064808
CurrentTrain: epoch  0, batch     1 | loss: 11.8639908
CurrentTrain: epoch  0, batch     2 | loss: 11.6686869
CurrentTrain: epoch  0, batch     3 | loss: 11.3898478
CurrentTrain: epoch  0, batch     4 | loss: 11.2384148
CurrentTrain: epoch  0, batch     5 | loss: 11.5131741
CurrentTrain: epoch  0, batch     6 | loss: 10.5715294
CurrentTrain: epoch  0, batch     7 | loss: 11.7395077
CurrentTrain: epoch  0, batch     8 | loss: 10.9299088
CurrentTrain: epoch  0, batch     9 | loss: 10.5581970
CurrentTrain: epoch  0, batch    10 | loss: 11.2648773
CurrentTrain: epoch  0, batch    11 | loss: 9.8903036
CurrentTrain: epoch  0, batch    12 | loss: 10.1122046
CurrentTrain: epoch  0, batch    13 | loss: 10.2800989
CurrentTrain: epoch  0, batch    14 | loss: 10.7658176
CurrentTrain: epoch  0, batch    15 | loss: 10.3615494
CurrentTrain: epoch  0, batch    16 | loss: 10.3035555
CurrentTrain: epoch  0, batch    17 | loss: 10.1106558
CurrentTrain: epoch  0, batch    18 | loss: 10.7182112
CurrentTrain: epoch  0, batch    19 | loss: 9.6667042
CurrentTrain: epoch  0, batch    20 | loss: 10.2518864
CurrentTrain: epoch  0, batch    21 | loss: 9.7331753
CurrentTrain: epoch  0, batch    22 | loss: 10.6861439
CurrentTrain: epoch  0, batch    23 | loss: 9.8792610
CurrentTrain: epoch  0, batch    24 | loss: 10.8179436
CurrentTrain: epoch  0, batch    25 | loss: 11.5640221
CurrentTrain: epoch  0, batch    26 | loss: 10.7134571
CurrentTrain: epoch  0, batch    27 | loss: 10.6837177
CurrentTrain: epoch  0, batch    28 | loss: 9.3518066
CurrentTrain: epoch  0, batch    29 | loss: 9.9948711
CurrentTrain: epoch  0, batch    30 | loss: 9.9478245
CurrentTrain: epoch  0, batch    31 | loss: 10.1619425
CurrentTrain: epoch  0, batch    32 | loss: 9.7000504
CurrentTrain: epoch  0, batch    33 | loss: 9.6447287
CurrentTrain: epoch  0, batch    34 | loss: 10.7425289
CurrentTrain: epoch  0, batch    35 | loss: 9.7948847
CurrentTrain: epoch  0, batch    36 | loss: 9.2492085
CurrentTrain: epoch  0, batch    37 | loss: 9.3026276
CurrentTrain: epoch  1, batch     0 | loss: 9.5663080
CurrentTrain: epoch  1, batch     1 | loss: 9.5871611
CurrentTrain: epoch  1, batch     2 | loss: 9.9005070
CurrentTrain: epoch  1, batch     3 | loss: 9.2229910
CurrentTrain: epoch  1, batch     4 | loss: 9.2252159
CurrentTrain: epoch  1, batch     5 | loss: 8.9243259
CurrentTrain: epoch  1, batch     6 | loss: 9.7689514
CurrentTrain: epoch  1, batch     7 | loss: 9.0011845
CurrentTrain: epoch  1, batch     8 | loss: 9.4780025
CurrentTrain: epoch  1, batch     9 | loss: 9.7024422
CurrentTrain: epoch  1, batch    10 | loss: 9.3921900
CurrentTrain: epoch  1, batch    11 | loss: 8.6413784
CurrentTrain: epoch  1, batch    12 | loss: 9.5185490
CurrentTrain: epoch  1, batch    13 | loss: 8.9300442
CurrentTrain: epoch  1, batch    14 | loss: 8.6783543
CurrentTrain: epoch  1, batch    15 | loss: 8.2205715
CurrentTrain: epoch  1, batch    16 | loss: 8.9082623
CurrentTrain: epoch  1, batch    17 | loss: 9.2133713
CurrentTrain: epoch  1, batch    18 | loss: 9.4490070
CurrentTrain: epoch  1, batch    19 | loss: 9.1847372
CurrentTrain: epoch  1, batch    20 | loss: 8.6000519
CurrentTrain: epoch  1, batch    21 | loss: 8.8166924
CurrentTrain: epoch  1, batch    22 | loss: 8.2471504
CurrentTrain: epoch  1, batch    23 | loss: 9.1752682
CurrentTrain: epoch  1, batch    24 | loss: 9.8275108
CurrentTrain: epoch  1, batch    25 | loss: 9.4409180
CurrentTrain: epoch  1, batch    26 | loss: 8.3519344
CurrentTrain: epoch  1, batch    27 | loss: 8.7478647
CurrentTrain: epoch  1, batch    28 | loss: 8.4379835
CurrentTrain: epoch  1, batch    29 | loss: 7.9573488
CurrentTrain: epoch  1, batch    30 | loss: 8.1854134
CurrentTrain: epoch  1, batch    31 | loss: 8.2743721
CurrentTrain: epoch  1, batch    32 | loss: 8.3680534
CurrentTrain: epoch  1, batch    33 | loss: 8.1743135
CurrentTrain: epoch  1, batch    34 | loss: 8.1293726
CurrentTrain: epoch  1, batch    35 | loss: 8.6553345
CurrentTrain: epoch  1, batch    36 | loss: 6.6446667
CurrentTrain: epoch  1, batch    37 | loss: 8.5239735
CurrentTrain: epoch  2, batch     0 | loss: 8.6418219
CurrentTrain: epoch  2, batch     1 | loss: 8.5288544
CurrentTrain: epoch  2, batch     2 | loss: 8.5434828
CurrentTrain: epoch  2, batch     3 | loss: 7.6401129
CurrentTrain: epoch  2, batch     4 | loss: 8.1322889
CurrentTrain: epoch  2, batch     5 | loss: 8.4838715
CurrentTrain: epoch  2, batch     6 | loss: 7.2681999
CurrentTrain: epoch  2, batch     7 | loss: 8.8652420
CurrentTrain: epoch  2, batch     8 | loss: 9.0236025
CurrentTrain: epoch  2, batch     9 | loss: 8.0297508
CurrentTrain: epoch  2, batch    10 | loss: 8.5988731
CurrentTrain: epoch  2, batch    11 | loss: 8.0089378
CurrentTrain: epoch  2, batch    12 | loss: 8.2127523
CurrentTrain: epoch  2, batch    13 | loss: 7.4162140
CurrentTrain: epoch  2, batch    14 | loss: 8.0555706
CurrentTrain: epoch  2, batch    15 | loss: 8.8997393
CurrentTrain: epoch  2, batch    16 | loss: 7.9635892
CurrentTrain: epoch  2, batch    17 | loss: 8.2252798
CurrentTrain: epoch  2, batch    18 | loss: 7.4898324
CurrentTrain: epoch  2, batch    19 | loss: 7.1995196
CurrentTrain: epoch  2, batch    20 | loss: 7.5344925
CurrentTrain: epoch  2, batch    21 | loss: 6.7465911
CurrentTrain: epoch  2, batch    22 | loss: 7.2857418
CurrentTrain: epoch  2, batch    23 | loss: 7.1610880
CurrentTrain: epoch  2, batch    24 | loss: 8.1104984
CurrentTrain: epoch  2, batch    25 | loss: 7.1133165
CurrentTrain: epoch  2, batch    26 | loss: 8.2817297
CurrentTrain: epoch  2, batch    27 | loss: 7.3768797
CurrentTrain: epoch  2, batch    28 | loss: 7.6859946
CurrentTrain: epoch  2, batch    29 | loss: 7.4639368
CurrentTrain: epoch  2, batch    30 | loss: 7.0119128
CurrentTrain: epoch  2, batch    31 | loss: 7.1889853
CurrentTrain: epoch  2, batch    32 | loss: 6.2050524
CurrentTrain: epoch  2, batch    33 | loss: 7.9729528
CurrentTrain: epoch  2, batch    34 | loss: 6.9446855
CurrentTrain: epoch  2, batch    35 | loss: 8.4130459
CurrentTrain: epoch  2, batch    36 | loss: 7.1561933
CurrentTrain: epoch  2, batch    37 | loss: 6.8447828
CurrentTrain: epoch  3, batch     0 | loss: 6.7495227
CurrentTrain: epoch  3, batch     1 | loss: 6.9528170
CurrentTrain: epoch  3, batch     2 | loss: 7.0266762
CurrentTrain: epoch  3, batch     3 | loss: 7.4576664
CurrentTrain: epoch  3, batch     4 | loss: 7.7823663
CurrentTrain: epoch  3, batch     5 | loss: 7.3614683
CurrentTrain: epoch  3, batch     6 | loss: 7.6086850
CurrentTrain: epoch  3, batch     7 | loss: 7.1865511
CurrentTrain: epoch  3, batch     8 | loss: 7.2221293
CurrentTrain: epoch  3, batch     9 | loss: 7.5208106
CurrentTrain: epoch  3, batch    10 | loss: 6.9016519
CurrentTrain: epoch  3, batch    11 | loss: 6.3317561
CurrentTrain: epoch  3, batch    12 | loss: 7.7344618
CurrentTrain: epoch  3, batch    13 | loss: 6.3138847
CurrentTrain: epoch  3, batch    14 | loss: 7.1450872
CurrentTrain: epoch  3, batch    15 | loss: 6.4472275
CurrentTrain: epoch  3, batch    16 | loss: 6.9890342
CurrentTrain: epoch  3, batch    17 | loss: 7.4970107
CurrentTrain: epoch  3, batch    18 | loss: 8.1890793
CurrentTrain: epoch  3, batch    19 | loss: 7.8152542
CurrentTrain: epoch  3, batch    20 | loss: 7.4739895
CurrentTrain: epoch  3, batch    21 | loss: 6.6493039
CurrentTrain: epoch  3, batch    22 | loss: 7.1213384
CurrentTrain: epoch  3, batch    23 | loss: 6.7685652
CurrentTrain: epoch  3, batch    24 | loss: 7.3915896
CurrentTrain: epoch  3, batch    25 | loss: 6.2554574
CurrentTrain: epoch  3, batch    26 | loss: 7.2128763
CurrentTrain: epoch  3, batch    27 | loss: 6.4449058
CurrentTrain: epoch  3, batch    28 | loss: 7.5262570
CurrentTrain: epoch  3, batch    29 | loss: 5.9755230
CurrentTrain: epoch  3, batch    30 | loss: 6.0571299
CurrentTrain: epoch  3, batch    31 | loss: 7.2888994
CurrentTrain: epoch  3, batch    32 | loss: 6.3508625
CurrentTrain: epoch  3, batch    33 | loss: 7.6665173
CurrentTrain: epoch  3, batch    34 | loss: 7.0020676
CurrentTrain: epoch  3, batch    35 | loss: 7.5473609
CurrentTrain: epoch  3, batch    36 | loss: 7.3324122
CurrentTrain: epoch  3, batch    37 | loss: 6.7194386
CurrentTrain: epoch  4, batch     0 | loss: 6.0571728
CurrentTrain: epoch  4, batch     1 | loss: 6.1627150
CurrentTrain: epoch  4, batch     2 | loss: 6.6914129
CurrentTrain: epoch  4, batch     3 | loss: 6.8920460
CurrentTrain: epoch  4, batch     4 | loss: 6.9788218
CurrentTrain: epoch  4, batch     5 | loss: 7.2339997
CurrentTrain: epoch  4, batch     6 | loss: 6.4948444
CurrentTrain: epoch  4, batch     7 | loss: 6.4131460
CurrentTrain: epoch  4, batch     8 | loss: 6.7899566
CurrentTrain: epoch  4, batch     9 | loss: 7.0256414
CurrentTrain: epoch  4, batch    10 | loss: 6.7346134
CurrentTrain: epoch  4, batch    11 | loss: 6.5827975
CurrentTrain: epoch  4, batch    12 | loss: 6.4463873
CurrentTrain: epoch  4, batch    13 | loss: 6.3268151
CurrentTrain: epoch  4, batch    14 | loss: 6.5156827
CurrentTrain: epoch  4, batch    15 | loss: 6.3504243
CurrentTrain: epoch  4, batch    16 | loss: 6.5187144
CurrentTrain: epoch  4, batch    17 | loss: 5.8663487
CurrentTrain: epoch  4, batch    18 | loss: 6.1711483
CurrentTrain: epoch  4, batch    19 | loss: 5.9027481
CurrentTrain: epoch  4, batch    20 | loss: 6.2850847
CurrentTrain: epoch  4, batch    21 | loss: 6.4187317
CurrentTrain: epoch  4, batch    22 | loss: 6.0069075
CurrentTrain: epoch  4, batch    23 | loss: 5.5508299
CurrentTrain: epoch  4, batch    24 | loss: 6.9908743
CurrentTrain: epoch  4, batch    25 | loss: 6.6414485
CurrentTrain: epoch  4, batch    26 | loss: 6.4339542
CurrentTrain: epoch  4, batch    27 | loss: 6.6451874
CurrentTrain: epoch  4, batch    28 | loss: 5.6742845
CurrentTrain: epoch  4, batch    29 | loss: 6.3257389
CurrentTrain: epoch  4, batch    30 | loss: 5.5072227
CurrentTrain: epoch  4, batch    31 | loss: 6.4055357
CurrentTrain: epoch  4, batch    32 | loss: 6.1860771
CurrentTrain: epoch  4, batch    33 | loss: 6.6413870
CurrentTrain: epoch  4, batch    34 | loss: 6.5381842
CurrentTrain: epoch  4, batch    35 | loss: 6.7196550
CurrentTrain: epoch  4, batch    36 | loss: 7.5713263
CurrentTrain: epoch  4, batch    37 | loss: 6.6564274
CurrentTrain: epoch  5, batch     0 | loss: 6.5840187
CurrentTrain: epoch  5, batch     1 | loss: 6.4031744
CurrentTrain: epoch  5, batch     2 | loss: 6.2873006
CurrentTrain: epoch  5, batch     3 | loss: 5.8160934
CurrentTrain: epoch  5, batch     4 | loss: 6.9405022
CurrentTrain: epoch  5, batch     5 | loss: 5.9566231
CurrentTrain: epoch  5, batch     6 | loss: 6.1983652
CurrentTrain: epoch  5, batch     7 | loss: 6.1707544
CurrentTrain: epoch  5, batch     8 | loss: 5.6008940
CurrentTrain: epoch  5, batch     9 | loss: 5.7568002
CurrentTrain: epoch  5, batch    10 | loss: 5.7476816
CurrentTrain: epoch  5, batch    11 | loss: 5.6207447
CurrentTrain: epoch  5, batch    12 | loss: 5.3938837
CurrentTrain: epoch  5, batch    13 | loss: 6.6529388
CurrentTrain: epoch  5, batch    14 | loss: 5.7307138
CurrentTrain: epoch  5, batch    15 | loss: 6.5193539
CurrentTrain: epoch  5, batch    16 | loss: 5.5883303
CurrentTrain: epoch  5, batch    17 | loss: 5.4248271
CurrentTrain: epoch  5, batch    18 | loss: 5.5615034
CurrentTrain: epoch  5, batch    19 | loss: 5.8241124
CurrentTrain: epoch  5, batch    20 | loss: 6.1206055
CurrentTrain: epoch  5, batch    21 | loss: 6.2259789
CurrentTrain: epoch  5, batch    22 | loss: 5.6477871
CurrentTrain: epoch  5, batch    23 | loss: 5.4727840
CurrentTrain: epoch  5, batch    24 | loss: 5.4866171
CurrentTrain: epoch  5, batch    25 | loss: 5.5415888
CurrentTrain: epoch  5, batch    26 | loss: 5.7948484
CurrentTrain: epoch  5, batch    27 | loss: 5.7870722
CurrentTrain: epoch  5, batch    28 | loss: 6.2736969
CurrentTrain: epoch  5, batch    29 | loss: 6.0339255
CurrentTrain: epoch  5, batch    30 | loss: 6.2272387
CurrentTrain: epoch  5, batch    31 | loss: 5.3462749
CurrentTrain: epoch  5, batch    32 | loss: 5.7553940
CurrentTrain: epoch  5, batch    33 | loss: 5.8332000
CurrentTrain: epoch  5, batch    34 | loss: 6.1867008
CurrentTrain: epoch  5, batch    35 | loss: 5.6188583
CurrentTrain: epoch  5, batch    36 | loss: 6.2444763
CurrentTrain: epoch  5, batch    37 | loss: 5.8725929
CurrentTrain: epoch  6, batch     0 | loss: 5.3010335
CurrentTrain: epoch  6, batch     1 | loss: 5.4931574
CurrentTrain: epoch  6, batch     2 | loss: 5.6910830
CurrentTrain: epoch  6, batch     3 | loss: 5.3188133
CurrentTrain: epoch  6, batch     4 | loss: 5.4453125
CurrentTrain: epoch  6, batch     5 | loss: 6.4954033
CurrentTrain: epoch  6, batch     6 | loss: 5.9821987
CurrentTrain: epoch  6, batch     7 | loss: 5.6164637
CurrentTrain: epoch  6, batch     8 | loss: 5.4422541
CurrentTrain: epoch  6, batch     9 | loss: 5.6210084
CurrentTrain: epoch  6, batch    10 | loss: 5.3405476
CurrentTrain: epoch  6, batch    11 | loss: 5.4095764
CurrentTrain: epoch  6, batch    12 | loss: 6.1398926
CurrentTrain: epoch  6, batch    13 | loss: 5.3313117
CurrentTrain: epoch  6, batch    14 | loss: 5.4866314
CurrentTrain: epoch  6, batch    15 | loss: 5.4870987
CurrentTrain: epoch  6, batch    16 | loss: 5.6315546
CurrentTrain: epoch  6, batch    17 | loss: 5.4794703
CurrentTrain: epoch  6, batch    18 | loss: 5.8820772
CurrentTrain: epoch  6, batch    19 | loss: 5.2790232
CurrentTrain: epoch  6, batch    20 | loss: 5.5286484
CurrentTrain: epoch  6, batch    21 | loss: 5.8117561
CurrentTrain: epoch  6, batch    22 | loss: 5.3503380
CurrentTrain: epoch  6, batch    23 | loss: 5.5888100
CurrentTrain: epoch  6, batch    24 | loss: 5.1943645
CurrentTrain: epoch  6, batch    25 | loss: 5.3826480
CurrentTrain: epoch  6, batch    26 | loss: 5.8224969
CurrentTrain: epoch  6, batch    27 | loss: 5.2258439
CurrentTrain: epoch  6, batch    28 | loss: 5.9251251
CurrentTrain: epoch  6, batch    29 | loss: 5.5664501
CurrentTrain: epoch  6, batch    30 | loss: 5.1986237
CurrentTrain: epoch  6, batch    31 | loss: 5.5570021
CurrentTrain: epoch  6, batch    32 | loss: 5.6298800
CurrentTrain: epoch  6, batch    33 | loss: 5.3771567
CurrentTrain: epoch  6, batch    34 | loss: 5.1547303
CurrentTrain: epoch  6, batch    35 | loss: 6.8778944
CurrentTrain: epoch  6, batch    36 | loss: 5.4354906
CurrentTrain: epoch  6, batch    37 | loss: 5.1339173
CurrentTrain: epoch  7, batch     0 | loss: 5.9270163
CurrentTrain: epoch  7, batch     1 | loss: 5.2945518
CurrentTrain: epoch  7, batch     2 | loss: 5.4929323
CurrentTrain: epoch  7, batch     3 | loss: 5.6739607
CurrentTrain: epoch  7, batch     4 | loss: 5.5321198
CurrentTrain: epoch  7, batch     5 | loss: 5.0773592
CurrentTrain: epoch  7, batch     6 | loss: 5.2525492
CurrentTrain: epoch  7, batch     7 | loss: 5.5019832
CurrentTrain: epoch  7, batch     8 | loss: 5.2937627
CurrentTrain: epoch  7, batch     9 | loss: 5.3627739
CurrentTrain: epoch  7, batch    10 | loss: 5.2142000
CurrentTrain: epoch  7, batch    11 | loss: 5.6258545
CurrentTrain: epoch  7, batch    12 | loss: 5.2338476
CurrentTrain: epoch  7, batch    13 | loss: 5.1276741
CurrentTrain: epoch  7, batch    14 | loss: 5.1862192
CurrentTrain: epoch  7, batch    15 | loss: 5.1541343
CurrentTrain: epoch  7, batch    16 | loss: 5.0780206
CurrentTrain: epoch  7, batch    17 | loss: 5.1797934
CurrentTrain: epoch  7, batch    18 | loss: 5.0497112
CurrentTrain: epoch  7, batch    19 | loss: 5.5578184
CurrentTrain: epoch  7, batch    20 | loss: 5.2192492
CurrentTrain: epoch  7, batch    21 | loss: 5.0138302
CurrentTrain: epoch  7, batch    22 | loss: 5.0398245
CurrentTrain: epoch  7, batch    23 | loss: 5.3075180
CurrentTrain: epoch  7, batch    24 | loss: 5.5747881
CurrentTrain: epoch  7, batch    25 | loss: 5.7899647
CurrentTrain: epoch  7, batch    26 | loss: 6.2777462
CurrentTrain: epoch  7, batch    27 | loss: 5.2148914
CurrentTrain: epoch  7, batch    28 | loss: 5.6571684
CurrentTrain: epoch  7, batch    29 | loss: 5.1465120
CurrentTrain: epoch  7, batch    30 | loss: 5.2829056
CurrentTrain: epoch  7, batch    31 | loss: 5.6718292
CurrentTrain: epoch  7, batch    32 | loss: 5.1619697
CurrentTrain: epoch  7, batch    33 | loss: 5.4023733
CurrentTrain: epoch  7, batch    34 | loss: 4.9272323
CurrentTrain: epoch  7, batch    35 | loss: 4.9698181
CurrentTrain: epoch  7, batch    36 | loss: 5.3510857
CurrentTrain: epoch  7, batch    37 | loss: 4.9231505
CurrentTrain: epoch  8, batch     0 | loss: 5.0168490
CurrentTrain: epoch  8, batch     1 | loss: 5.7203670
CurrentTrain: epoch  8, batch     2 | loss: 5.1069555
CurrentTrain: epoch  8, batch     3 | loss: 5.0367193
CurrentTrain: epoch  8, batch     4 | loss: 5.1187487
CurrentTrain: epoch  8, batch     5 | loss: 5.2751055
CurrentTrain: epoch  8, batch     6 | loss: 5.2564802
CurrentTrain: epoch  8, batch     7 | loss: 5.1886358
CurrentTrain: epoch  8, batch     8 | loss: 5.1485648
CurrentTrain: epoch  8, batch     9 | loss: 5.0792675
CurrentTrain: epoch  8, batch    10 | loss: 5.1419654
CurrentTrain: epoch  8, batch    11 | loss: 5.0674562
CurrentTrain: epoch  8, batch    12 | loss: 5.5903296
CurrentTrain: epoch  8, batch    13 | loss: 5.8417959
CurrentTrain: epoch  8, batch    14 | loss: 5.4350700
CurrentTrain: epoch  8, batch    15 | loss: 5.3679256
CurrentTrain: epoch  8, batch    16 | loss: 5.0566044
CurrentTrain: epoch  8, batch    17 | loss: 5.3173237
CurrentTrain: epoch  8, batch    18 | loss: 5.5487547
CurrentTrain: epoch  8, batch    19 | loss: 5.2379770
CurrentTrain: epoch  8, batch    20 | loss: 4.9534917
CurrentTrain: epoch  8, batch    21 | loss: 4.8841858
CurrentTrain: epoch  8, batch    22 | loss: 5.1473827
CurrentTrain: epoch  8, batch    23 | loss: 5.3952498
CurrentTrain: epoch  8, batch    24 | loss: 5.1771555
CurrentTrain: epoch  8, batch    25 | loss: 5.0638285
CurrentTrain: epoch  8, batch    26 | loss: 5.1669555
CurrentTrain: epoch  8, batch    27 | loss: 5.3729167
CurrentTrain: epoch  8, batch    28 | loss: 4.9587555
CurrentTrain: epoch  8, batch    29 | loss: 5.0554094
CurrentTrain: epoch  8, batch    30 | loss: 5.2200031
CurrentTrain: epoch  8, batch    31 | loss: 5.0288730
CurrentTrain: epoch  8, batch    32 | loss: 4.9527378
CurrentTrain: epoch  8, batch    33 | loss: 5.1584873
CurrentTrain: epoch  8, batch    34 | loss: 5.2792559
CurrentTrain: epoch  8, batch    35 | loss: 4.8034377
CurrentTrain: epoch  8, batch    36 | loss: 4.9449039
CurrentTrain: epoch  8, batch    37 | loss: 5.7673888
CurrentTrain: epoch  9, batch     0 | loss: 5.1609888
CurrentTrain: epoch  9, batch     1 | loss: 5.1186104
CurrentTrain: epoch  9, batch     2 | loss: 5.0379229
CurrentTrain: epoch  9, batch     3 | loss: 5.0181837
CurrentTrain: epoch  9, batch     4 | loss: 5.2383504
CurrentTrain: epoch  9, batch     5 | loss: 5.0184493
CurrentTrain: epoch  9, batch     6 | loss: 5.0556164
CurrentTrain: epoch  9, batch     7 | loss: 5.1890631
CurrentTrain: epoch  9, batch     8 | loss: 4.8221893
CurrentTrain: epoch  9, batch     9 | loss: 5.0642529
CurrentTrain: epoch  9, batch    10 | loss: 5.0238991
CurrentTrain: epoch  9, batch    11 | loss: 5.1607494
CurrentTrain: epoch  9, batch    12 | loss: 4.9301300
CurrentTrain: epoch  9, batch    13 | loss: 4.7900143
CurrentTrain: epoch  9, batch    14 | loss: 4.9786668
CurrentTrain: epoch  9, batch    15 | loss: 4.9626470
CurrentTrain: epoch  9, batch    16 | loss: 4.8003244
CurrentTrain: epoch  9, batch    17 | loss: 5.2744021
CurrentTrain: epoch  9, batch    18 | loss: 5.0633698
CurrentTrain: epoch  9, batch    19 | loss: 5.4749088
CurrentTrain: epoch  9, batch    20 | loss: 5.0396085
CurrentTrain: epoch  9, batch    21 | loss: 5.0676537
CurrentTrain: epoch  9, batch    22 | loss: 4.8501654
CurrentTrain: epoch  9, batch    23 | loss: 4.9025450
CurrentTrain: epoch  9, batch    24 | loss: 5.0321131
CurrentTrain: epoch  9, batch    25 | loss: 4.9086208
CurrentTrain: epoch  9, batch    26 | loss: 4.8878736
CurrentTrain: epoch  9, batch    27 | loss: 4.9245768
CurrentTrain: epoch  9, batch    28 | loss: 5.0031362
CurrentTrain: epoch  9, batch    29 | loss: 5.0245047
CurrentTrain: epoch  9, batch    30 | loss: 4.8237190
CurrentTrain: epoch  9, batch    31 | loss: 4.8577032
CurrentTrain: epoch  9, batch    32 | loss: 4.8946056
CurrentTrain: epoch  9, batch    33 | loss: 5.0990329
CurrentTrain: epoch  9, batch    34 | loss: 4.8800640
CurrentTrain: epoch  9, batch    35 | loss: 5.0227580
CurrentTrain: epoch  9, batch    36 | loss: 4.9584923
CurrentTrain: epoch  9, batch    37 | loss: 5.0068731
#### person countries of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person countries of residence" means a person is living in a country.
Here is an example:
Relation: person countries of residence
Context: embattled us attorney general alberto gonzales formally announced his resignation on monday , after months at the center of a raging political storm .
Head Entity: alberto gonzales
Tail Entity: us
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person countries of residence":
Relation: person countries of residence  
Context: After years of living in Paris, the renowned artist decided to return to his hometown in Italy.  
Head Entity: the renowned artist  
Tail Entity: Italy  

Relation: person countries of residence  
Context: Following her studies in London, she moved to Canada to start her career in technology.  
Head Entity: she  
Tail Entity: Canada  

Relation: person countries of residence  
Context: The famous actor has been residing in Australia for the past few years while filming his latest movie.  
Head Entity: The famous actor  
Tail Entity: Australia  

Relation: person countries of residence  
Context: After spending a decade in Japan, the scientist relocated to Germany for a new research opportunity.  
Head Entity: the scientist  
Tail Entity: Germany  

Relation: person countries of residence  
Context: He has lived in Brazil for most of his life, but recently he has been considering a move to Portugal.  
Head Entity: He  
Tail Entity: Brazil  
#### organization top members employees ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization top members employees" means an organization 's employer is a person.
Here is an example:
Relation: organization top members employees
Context: whether this means the country 's tense political situation will dissolve back into civil war is yet to be seen , said rinaldo depagne , a west africa analyst at the international crisis group .
Head Entity: international crisis group
Tail Entity: rinaldo depagne
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization top members employees":
Relation: organization top members employees  
Context: The CEO of the tech giant announced a new initiative to improve employee satisfaction during the annual company meeting.  
Head Entity: tech giant  
Tail Entity: CEO  

Relation: organization top members employees  
Context: During the charity event, the founder of the non-profit organization expressed gratitude towards the volunteers who dedicated their time to the cause.  
Head Entity: non-profit organization  
Tail Entity: founder  

Relation: organization top members employees  
Context: The board of directors met to discuss the future of the company and the role of the new marketing director in shaping its strategy.  
Head Entity: company  
Tail Entity: marketing director  

Relation: organization top members employees  
Context: At the annual conference, the president of the university highlighted the achievements of the faculty members in advancing research and education.  
Head Entity: university  
Tail Entity: president  

Relation: organization top members employees  
Context: The manager of the restaurant praised the head chef for creating a unique menu that has attracted many new customers.  
Head Entity: restaurant  
Tail Entity: head chef  
#### organization member of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization member of" means an organization is the member of an organization.
Here is an example:
Relation: organization member of
Context: rong lan , a teacher in tianjin , a city of more than 10 million people about 150 kilometers -lrb- 90 miles -rrb- southeast of beijing and home to the cbl 's tianjin lions , said the chinese just do n't get baseball .
Head Entity: tianjin lions
Tail Entity: cbl
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization member of":
Relation: organization member of  
Context: The New York Yankees, a professional baseball team based in the Bronx, are part of Major League Baseball and have a storied history in the sport.  
Head Entity: New York Yankees  
Tail Entity: Major League Baseball  

Relation: organization member of  
Context: The United Nations is an international organization founded in 1945, and the World Health Organization is one of its specialized agencies focused on global health issues.  
Head Entity: World Health Organization  
Tail Entity: United Nations  

Relation: organization member of  
Context: The European Union is a political and economic union of member states, and France is one of the founding members of this organization.  
Head Entity: France  
Tail Entity: European Union  

Relation: organization member of  
Context: The National Football League is a professional American football league, and the Dallas Cowboys are one of its most popular teams.  
Head Entity: Dallas Cowboys  
Tail Entity: National Football League  

Relation: organization member of  
Context: The International Olympic Committee is responsible for organizing the Olympic Games, and the United States Olympic and Paralympic Committee is a member organization that represents the U.S.  
Head Entity: United States Olympic and Paralympic Committee  
Tail Entity: International Olympic Committee  
#### person origin ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person origin" means a person 's nationality is a country.
Here is an example:
Relation: person origin
Context: urgent chadian pm dies in paris hospital chad 's prime minister pascal yoadimnadji has died from a cerebral hemorrhage in a paris hospital , the chadian ambassador said friday .
Head Entity: pascal yoadimnadji
Tail Entity: chadian
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person origin":
Relation: person origin  
Context: the renowned scientist albert einstein was born in ulm, germany, and later became a citizen of the united states.  
Head Entity: albert einstein  
Tail Entity: german  

Relation: person origin  
Context: the famous author chimamanda ngozi adichie hails from enugu, nigeria, where she developed her passion for storytelling.  
Head Entity: chimamanda ngozi adichie  
Tail Entity: nigerian  

Relation: person origin  
Context: the legendary musician bob marley was born in nine mile, jamaica, and is celebrated worldwide for his contributions to reggae music.  
Head Entity: bob marley  
Tail Entity: jamaican  

Relation: person origin  
Context: the acclaimed filmmaker akira kurosawa was born in tokyo, japan, and is known for his influential works in cinema.  
Head Entity: akira kurosawa  
Tail Entity: japanese  

Relation: person origin  
Context: the famous physicist stephen hawking was born in oxford, england, and made groundbreaking contributions to theoretical physics.  
Head Entity: stephen hawking  
Tail Entity: british  
#### person title ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person title" means a person 's title is a title.
Here is an example:
Relation: person title
Context: `` making the amendment retroactive will ... help repair the image of the sentencing guidelines in communities of color , '' naacp chairman julian bond wrote to the commission .
Head Entity: julian bond
Tail Entity: chairman
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person title":
Relation: person title  
Context: `` After years of dedicated service, the board recognized Dr. Emily Carter as the new president of the organization during the annual meeting. ''  
Head Entity: Dr. Emily Carter  
Tail Entity: president  

Relation: person title  
Context: `` In his acceptance speech, the newly elected mayor, John Smith, promised to focus on community development and public safety. ''  
Head Entity: John Smith  
Tail Entity: mayor  

Relation: person title  
Context: `` The renowned scientist, Dr. Alice Johnson, received the prestigious award for her groundbreaking research in renewable energy. ''  
Head Entity: Dr. Alice Johnson  
Tail Entity: scientist  

Relation: person title  
Context: `` As the chief executive officer of the company, Maria Lopez has implemented several innovative strategies to boost productivity. ''  
Head Entity: Maria Lopez  
Tail Entity: chief executive officer  

Relation: person title  
Context: `` During the ceremony, the principal, Mr. Robert Lee, announced the winners of the annual scholarship program. ''  
Head Entity: Mr. Robert Lee  
Tail Entity: principal  
#### organization country of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization country of headquarters" means an organization is located in a country.
Here is an example:
Relation: organization country of headquarters
Context: `` japan 's growth has yet to be sustained by domestic demand alone , '' said yoshimasa maruyama , a senior economist at itochu corp. in tokyo .
Head Entity: itochu corp.
Tail Entity: japan
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization country of headquarters":
Relation: organization country of headquarters  
Context: "The headquarters of Samsung Electronics is located in Suwon, South Korea, where it has been a leader in technology innovation."  
Head Entity: Samsung Electronics  
Tail Entity: South Korea  

Relation: organization country of headquarters  
Context: "Nestlé, the world's largest food and beverage company, has its headquarters in Vevey, Switzerland."  
Head Entity: Nestlé  
Tail Entity: Switzerland  

Relation: organization country of headquarters  
Context: "Volkswagen AG, a major automobile manufacturer, is headquartered in Wolfsburg, Germany."  
Head Entity: Volkswagen AG  
Tail Entity: Germany  

Relation: organization country of headquarters  
Context: "The multinational corporation Unilever has its headquarters in London, United Kingdom, and Rotterdam, Netherlands."  
Head Entity: Unilever  
Tail Entity: United Kingdom  

Relation: organization country of headquarters  
Context: "Sony Corporation, known for its electronics and entertainment products, is headquartered in Tokyo, Japan."  
Head Entity: Sony Corporation  
Tail Entity: Japan  
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    1 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    2 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    3 | acc: 62.50%,  total acc: 76.56%   
[EVAL] batch:    4 | acc: 68.75%,  total acc: 75.00%   
[EVAL] batch:    5 | acc: 75.00%,  total acc: 75.00%   
[EVAL] batch:    6 | acc: 100.00%,  total acc: 78.57%   
[EVAL] batch:    7 | acc: 100.00%,  total acc: 81.25%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 83.33%   
[EVAL] batch:    9 | acc: 93.75%,  total acc: 84.38%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 85.80%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 86.46%   
[EVAL] batch:   12 | acc: 93.75%,  total acc: 87.02%   
[EVAL] batch:   13 | acc: 68.75%,  total acc: 85.71%   
[EVAL] batch:   14 | acc: 81.25%,  total acc: 85.42%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 83.59%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 83.09%   
[EVAL] batch:   17 | acc: 68.75%,  total acc: 82.29%   
[EVAL] batch:   18 | acc: 75.00%,  total acc: 81.91%   
[EVAL] batch:   19 | acc: 75.00%,  total acc: 81.56%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 82.44%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 83.24%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 83.97%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 84.64%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 85.25%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 85.82%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 86.11%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 86.61%   
[EVAL] batch:   28 | acc: 100.00%,  total acc: 87.07%   
[EVAL] batch:   29 | acc: 87.50%,  total acc: 87.08%   
[EVAL] batch:   30 | acc: 87.50%,  total acc: 87.10%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 87.30%   
[EVAL] batch:   32 | acc: 37.50%,  total acc: 85.80%   
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    1 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    2 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    3 | acc: 62.50%,  total acc: 76.56%   
[EVAL] batch:    4 | acc: 68.75%,  total acc: 75.00%   
[EVAL] batch:    5 | acc: 75.00%,  total acc: 75.00%   
[EVAL] batch:    6 | acc: 100.00%,  total acc: 78.57%   
[EVAL] batch:    7 | acc: 100.00%,  total acc: 81.25%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 83.33%   
[EVAL] batch:    9 | acc: 93.75%,  total acc: 84.38%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 85.80%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 86.46%   
[EVAL] batch:   12 | acc: 93.75%,  total acc: 87.02%   
[EVAL] batch:   13 | acc: 68.75%,  total acc: 85.71%   
[EVAL] batch:   14 | acc: 81.25%,  total acc: 85.42%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 83.59%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 83.09%   
[EVAL] batch:   17 | acc: 68.75%,  total acc: 82.29%   
[EVAL] batch:   18 | acc: 75.00%,  total acc: 81.91%   
[EVAL] batch:   19 | acc: 75.00%,  total acc: 81.56%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 82.44%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 83.24%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 83.97%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 84.64%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 85.25%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 85.82%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 86.11%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 86.61%   
[EVAL] batch:   28 | acc: 100.00%,  total acc: 87.07%   
[EVAL] batch:   29 | acc: 87.50%,  total acc: 87.08%   
[EVAL] batch:   30 | acc: 87.50%,  total acc: 87.10%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 87.30%   
[EVAL] batch:   32 | acc: 37.50%,  total acc: 85.80%   
cur_acc:  ['0.8580']
his_acc:  ['0.8580']
CurrentTrain: epoch  0, batch     0 | loss: 6.2867098
CurrentTrain: epoch  0, batch     1 | loss: 7.0269647
CurrentTrain: epoch  1, batch     0 | loss: 5.8915138
CurrentTrain: epoch  1, batch     1 | loss: 5.8177638
CurrentTrain: epoch  2, batch     0 | loss: 5.5289679
CurrentTrain: epoch  2, batch     1 | loss: 5.0860114
CurrentTrain: epoch  3, batch     0 | loss: 4.8239474
CurrentTrain: epoch  3, batch     1 | loss: 5.5519061
CurrentTrain: epoch  4, batch     0 | loss: 4.8133054
CurrentTrain: epoch  4, batch     1 | loss: 4.4697552
CurrentTrain: epoch  5, batch     0 | loss: 4.4706869
CurrentTrain: epoch  5, batch     1 | loss: 4.4696045
CurrentTrain: epoch  6, batch     0 | loss: 4.1162949
CurrentTrain: epoch  6, batch     1 | loss: 4.6657844
CurrentTrain: epoch  7, batch     0 | loss: 4.0687127
CurrentTrain: epoch  7, batch     1 | loss: 4.2619200
CurrentTrain: epoch  8, batch     0 | loss: 3.9350581
CurrentTrain: epoch  8, batch     1 | loss: 3.8058641
CurrentTrain: epoch  9, batch     0 | loss: 3.5855842
CurrentTrain: epoch  9, batch     1 | loss: 3.6470973
#### person stateorprovinces of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovinces of residence" means a person is living in a state or province.
Here is an example:
Relation: person stateorprovinces of residence
Context: ny-schools-chief -lrb- new york -rrb- -- cathleen p. black , mayor michael r. bloomberg 's choice to be the next chancellor of new york city 's public-school system , has during more than 40 years in the media business broken numerous glass ceilings -- and amassed a fortune -- with quick and cold-blooded decision making , crystal-clear goal setting , and an all-surpassing attention to the bottom line .
Head Entity: cathleen p. black
Tail Entity: new york
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovinces of residence":
Relation: person stateorprovinces of residence  
Context: After years of living in the bustling city, actor Tom Hanks has decided to settle down in a quieter area, choosing to make his home in the picturesque state of California.  
Head Entity: Tom Hanks  
Tail Entity: California  

Relation: person stateorprovinces of residence  
Context: The renowned author J.K. Rowling has spent much of her life in Edinburgh, where she found inspiration for her beloved Harry Potter series.  
Head Entity: J.K. Rowling  
Tail Entity: Edinburgh  

Relation: person stateorprovinces of residence  
Context: Following his successful career in the tech industry, entrepreneur Elon Musk has moved to Texas, where he plans to expand his business ventures.  
Head Entity: Elon Musk  
Tail Entity: Texas  

Relation: person stateorprovinces of residence  
Context: After retiring from professional basketball, Michael Jordan chose to reside in North Carolina, where he continues to be involved in the local community.  
Head Entity: Michael Jordan  
Tail Entity: North Carolina  

Relation: person stateorprovinces of residence  
Context: The famous singer Taylor Swift has made her home in Nashville, Tennessee, where she began her music career and still finds creative inspiration.  
Head Entity: Taylor Swift  
Tail Entity: Nashville
#### person date of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person date of death" means a person was died on a date.
Here is an example:
Relation: person date of death
Context: he passed away on saturday .
Head Entity: he
Tail Entity: saturday
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person date of death":
Relation: person date of death  
Context: John Smith died on March 15, 2020.  
Head Entity: John Smith  
Tail Entity: March 15, 2020  

Relation: person date of death  
Context: The famous author passed away in 1995.  
Head Entity: The famous author  
Tail Entity: 1995  

Relation: person date of death  
Context: She left this world on New Year's Eve.  
Head Entity: She  
Tail Entity: New Year's Eve  

Relation: person date of death  
Context: The scientist's life ended on July 4th, 1987.  
Head Entity: The scientist  
Tail Entity: July 4th, 1987  

Relation: person date of death  
Context: He was reported dead on the evening of October 31.  
Head Entity: He  
Tail Entity: October 31  
#### organization number of employees members ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization number of employees members" means the number of an organization 's employees is a number.
Here is an example:
Relation: organization number of employees members
Context: covidien , which posted revenue of more than $ 10 billion last year , has about 42,000 employees worldwide .
Head Entity: covidien
Tail Entity: 42,000
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization number of employees members":
Relation: organization number of employees members  
Context: TechCorp, a leading software development company, employs approximately 5,500 people across its global offices.  
Head Entity: TechCorp  
Tail Entity: 5,500  

Relation: organization number of employees members  
Context: The nonprofit organization Helping Hands has grown significantly and now boasts a workforce of over 1,200 dedicated volunteers.  
Head Entity: Helping Hands  
Tail Entity: 1,200  

Relation: organization number of employees members  
Context: With a workforce of around 3,000, Green Energy Solutions is making strides in renewable energy initiatives.  
Head Entity: Green Energy Solutions  
Tail Entity: 3,000  

Relation: organization number of employees members  
Context: Last year, Global Finance reported a total of 10,000 employees, reflecting its expansion in the financial services sector.  
Head Entity: Global Finance  
Tail Entity: 10,000  

Relation: organization number of employees members  
Context: The startup InnovateTech has rapidly expanded and now has a team of 250 skilled professionals.  
Head Entity: InnovateTech  
Tail Entity: 250  
#### person alternate names ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person alternate names" means a person 's alias is a person.
Here is an example:
Relation: person alternate names
Context: a judge in new york city said remy ma , whose real name is remy smith , said thursday that the hip-hopper could not leave the united states for a five-country european concert tour .
Head Entity: remy smith
Tail Entity: remy ma
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person alternate names":
Relation: person alternate names  
Context: The famous author Samuel Langhorne Clemens, better known by his pen name Mark Twain, is celebrated for his novels like "The Adventures of Tom Sawyer."  
Head Entity: Samuel Langhorne Clemens  
Tail Entity: Mark Twain  

Relation: person alternate names  
Context: The musician Stefani Joanne Angelina Germanotta, who is widely recognized as Lady Gaga, has made a significant impact on the pop music scene.  
Head Entity: Stefani Joanne Angelina Germanotta  
Tail Entity: Lady Gaga  

Relation: person alternate names  
Context: The actor and filmmaker known as Orson Welles was born George Orson Welles and is famous for his groundbreaking work in cinema.  
Head Entity: George Orson Welles  
Tail Entity: Orson Welles  

Relation: person alternate names  
Context: The renowned physicist Albert Einstein, who is often referred to simply as Einstein, developed the theory of relativity.  
Head Entity: Albert Einstein  
Tail Entity: Einstein  

Relation: person alternate names  
Context: The pop star Robyn Rihanna Fenty, better known as Rihanna, has won numerous awards for her music and philanthropy.  
Head Entity: Robyn Rihanna Fenty  
Tail Entity: Rihanna  
#### person spouse ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person spouse" means a person 's spouse is a person.
Here is an example:
Relation: person spouse
Context: beverly hills , california 2008-08-17 21:15:39 utc ------ there was much dancing : ellen degeneres and portia de rossi are married , according to reports .
Head Entity: ellen degeneres
Tail Entity: portia de rossi
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person spouse":
Relation: person spouse  
Context: in a beautiful ceremony held in new york city, 2015-06-20 15:30:00 utc ------ the couple exchanged vows: john legend and chrissy teigen are now officially husband and wife.  
Head Entity: john legend  
Tail Entity: chrissy teigen  

Relation: person spouse  
Context: during the star-studded event in los angeles, 2019-05-01 18:45:00 utc ------ the couple celebrated their anniversary: blake lively and ryan reynolds have been happily married for several years.  
Head Entity: blake lively  
Tail Entity: ryan reynolds  

Relation: person spouse  
Context: at a private beach ceremony in hawaii, 2021-07-10 12:00:00 utc ------ they tied the knot: meghan markle and prince harry are now husband and wife.  
Head Entity: meghan markle  
Tail Entity: prince harry  

Relation: person spouse  
Context: in a lavish wedding in paris, 2018-09-15 14:00:00 utc ------ the couple said "I do": gigi hadid and zayn malik have officially become partners for life.  
Head Entity: gigi hadid  
Tail Entity: zayn malik  

Relation: person spouse  
Context: at a grand ceremony in rome, 2020-11-11 16:30:00 utc ------ they exchanged rings: sofia vergara and joe manganiello are now married.  
Head Entity: sofia vergara  
Tail Entity: joe manganiello  
Mixup data size:  3730
MixupTrain:  epoch  0, batch     0 | loss: 4.7066264
MixupTrain:  epoch  0, batch     1 | loss: 5.1801548
MixupTrain:  epoch  0, batch     2 | loss: 5.3466182
MixupTrain:  epoch  0, batch     3 | loss: 4.9331369
MixupTrain:  epoch  0, batch     4 | loss: 4.9293923
MixupTrain:  epoch  0, batch     5 | loss: 4.5437822
MixupTrain:  epoch  0, batch     6 | loss: 4.9885502
MixupTrain:  epoch  0, batch     7 | loss: 5.0662737
MixupTrain:  epoch  0, batch     8 | loss: 4.5992990
MixupTrain:  epoch  0, batch     9 | loss: 3.8048134
MixupTrain:  epoch  0, batch    10 | loss: 4.3223710
MixupTrain:  epoch  0, batch    11 | loss: 4.2077398
MixupTrain:  epoch  0, batch    12 | loss: 4.7268558
MixupTrain:  epoch  0, batch    13 | loss: 4.4972658
MixupTrain:  epoch  0, batch    14 | loss: 4.0388074
MixupTrain:  epoch  0, batch    15 | loss: 4.0314312
MixupTrain:  epoch  0, batch    16 | loss: 4.0643015
MixupTrain:  epoch  0, batch    17 | loss: 4.1628523
MixupTrain:  epoch  0, batch    18 | loss: 4.4588070
MixupTrain:  epoch  0, batch    19 | loss: 3.6532104
MixupTrain:  epoch  0, batch    20 | loss: 4.2137136
MixupTrain:  epoch  0, batch    21 | loss: 4.0008411
MixupTrain:  epoch  0, batch    22 | loss: 3.8313999
MixupTrain:  epoch  0, batch    23 | loss: 4.0755005
MixupTrain:  epoch  0, batch    24 | loss: 3.5411677
MixupTrain:  epoch  0, batch    25 | loss: 3.9116549
MixupTrain:  epoch  0, batch    26 | loss: 3.5960183
MixupTrain:  epoch  0, batch    27 | loss: 3.6854038
MixupTrain:  epoch  0, batch    28 | loss: 4.1145554
MixupTrain:  epoch  0, batch    29 | loss: 3.6228919
MixupTrain:  epoch  0, batch    30 | loss: 3.8112769
MixupTrain:  epoch  0, batch    31 | loss: 3.8788810
MixupTrain:  epoch  0, batch    32 | loss: 3.3583615
MixupTrain:  epoch  0, batch    33 | loss: 3.4993279
MixupTrain:  epoch  0, batch    34 | loss: 3.8049345
MixupTrain:  epoch  0, batch    35 | loss: 3.5615470
MixupTrain:  epoch  0, batch    36 | loss: 3.4797556
MixupTrain:  epoch  0, batch    37 | loss: 3.4045911
MixupTrain:  epoch  0, batch    38 | loss: 3.6163735
MixupTrain:  epoch  0, batch    39 | loss: 3.5697019
MixupTrain:  epoch  0, batch    40 | loss: 3.2388740
MixupTrain:  epoch  0, batch    41 | loss: 3.2717674
MixupTrain:  epoch  0, batch    42 | loss: 3.4110827
MixupTrain:  epoch  0, batch    43 | loss: 3.7738376
MixupTrain:  epoch  0, batch    44 | loss: 3.2562625
MixupTrain:  epoch  0, batch    45 | loss: 3.0908635
MixupTrain:  epoch  0, batch    46 | loss: 3.5553160
MixupTrain:  epoch  0, batch    47 | loss: 3.2822371
MixupTrain:  epoch  0, batch    48 | loss: 3.7697942
MixupTrain:  epoch  0, batch    49 | loss: 3.4949241
MixupTrain:  epoch  0, batch    50 | loss: 2.9874825
MixupTrain:  epoch  0, batch    51 | loss: 3.1480100
MixupTrain:  epoch  0, batch    52 | loss: 2.8316500
MixupTrain:  epoch  0, batch    53 | loss: 3.2280617
MixupTrain:  epoch  0, batch    54 | loss: 3.0980999
MixupTrain:  epoch  0, batch    55 | loss: 3.0376337
MixupTrain:  epoch  0, batch    56 | loss: 2.9111109
MixupTrain:  epoch  0, batch    57 | loss: 3.0057645
MixupTrain:  epoch  0, batch    58 | loss: 3.1560388
MixupTrain:  epoch  0, batch    59 | loss: 2.8564560
MixupTrain:  epoch  0, batch    60 | loss: 3.0786815
MixupTrain:  epoch  0, batch    61 | loss: 3.0322404
MixupTrain:  epoch  0, batch    62 | loss: 2.6527863
MixupTrain:  epoch  0, batch    63 | loss: 2.7278700
MixupTrain:  epoch  0, batch    64 | loss: 2.7113998
MixupTrain:  epoch  0, batch    65 | loss: 2.7054873
MixupTrain:  epoch  0, batch    66 | loss: 2.8154163
MixupTrain:  epoch  0, batch    67 | loss: 2.7400076
MixupTrain:  epoch  0, batch    68 | loss: 2.5242550
MixupTrain:  epoch  0, batch    69 | loss: 2.7755227
MixupTrain:  epoch  0, batch    70 | loss: 3.0844643
MixupTrain:  epoch  0, batch    71 | loss: 2.6478958
MixupTrain:  epoch  0, batch    72 | loss: 2.7770860
MixupTrain:  epoch  0, batch    73 | loss: 2.9479346
MixupTrain:  epoch  0, batch    74 | loss: 2.6166091
MixupTrain:  epoch  0, batch    75 | loss: 2.7492793
MixupTrain:  epoch  0, batch    76 | loss: 2.4912155
MixupTrain:  epoch  0, batch    77 | loss: 2.7840538
MixupTrain:  epoch  0, batch    78 | loss: 2.7957492
MixupTrain:  epoch  0, batch    79 | loss: 2.8440409
MixupTrain:  epoch  0, batch    80 | loss: 2.4086833
MixupTrain:  epoch  0, batch    81 | loss: 2.6389105
MixupTrain:  epoch  0, batch    82 | loss: 2.6598649
MixupTrain:  epoch  0, batch    83 | loss: 2.6201191
MixupTrain:  epoch  0, batch    84 | loss: 2.5115318
MixupTrain:  epoch  0, batch    85 | loss: 2.8092313
MixupTrain:  epoch  0, batch    86 | loss: 2.5059788
MixupTrain:  epoch  0, batch    87 | loss: 2.7751553
MixupTrain:  epoch  0, batch    88 | loss: 2.4200816
MixupTrain:  epoch  0, batch    89 | loss: 2.4194674
MixupTrain:  epoch  0, batch    90 | loss: 2.6503921
MixupTrain:  epoch  0, batch    91 | loss: 2.5376081
MixupTrain:  epoch  0, batch    92 | loss: 2.6552794
MixupTrain:  epoch  0, batch    93 | loss: 2.3818758
MixupTrain:  epoch  0, batch    94 | loss: 2.4470057
MixupTrain:  epoch  0, batch    95 | loss: 2.6034067
MixupTrain:  epoch  0, batch    96 | loss: 2.4979177
MixupTrain:  epoch  0, batch    97 | loss: 2.4400835
MixupTrain:  epoch  0, batch    98 | loss: 2.3803272
MixupTrain:  epoch  0, batch    99 | loss: 2.4203460
MixupTrain:  epoch  0, batch   100 | loss: 2.5323288
MixupTrain:  epoch  0, batch   101 | loss: 2.2194567
MixupTrain:  epoch  0, batch   102 | loss: 2.3241956
MixupTrain:  epoch  0, batch   103 | loss: 2.1595368
MixupTrain:  epoch  0, batch   104 | loss: 2.3899519
MixupTrain:  epoch  0, batch   105 | loss: 2.4417081
MixupTrain:  epoch  0, batch   106 | loss: 2.3196049
MixupTrain:  epoch  0, batch   107 | loss: 2.2972014
MixupTrain:  epoch  0, batch   108 | loss: 2.4055963
MixupTrain:  epoch  0, batch   109 | loss: 2.2415533
MixupTrain:  epoch  0, batch   110 | loss: 2.3746381
MixupTrain:  epoch  0, batch   111 | loss: 2.3449535
MixupTrain:  epoch  0, batch   112 | loss: 2.2034719
MixupTrain:  epoch  0, batch   113 | loss: 2.2168007
MixupTrain:  epoch  0, batch   114 | loss: 2.3990059
MixupTrain:  epoch  0, batch   115 | loss: 2.1974082
MixupTrain:  epoch  0, batch   116 | loss: 2.2772598
MixupTrain:  epoch  0, batch   117 | loss: 2.3482523
MixupTrain:  epoch  0, batch   118 | loss: 2.3431475
MixupTrain:  epoch  0, batch   119 | loss: 2.1096556
MixupTrain:  epoch  0, batch   120 | loss: 2.2737765
MixupTrain:  epoch  0, batch   121 | loss: 2.2705457
MixupTrain:  epoch  0, batch   122 | loss: 2.2987018
MixupTrain:  epoch  0, batch   123 | loss: 2.3889787
MixupTrain:  epoch  0, batch   124 | loss: 2.2439675
MixupTrain:  epoch  0, batch   125 | loss: 2.0650239
MixupTrain:  epoch  0, batch   126 | loss: 2.2766943
MixupTrain:  epoch  0, batch   127 | loss: 2.2797885
MixupTrain:  epoch  0, batch   128 | loss: 2.2997355
MixupTrain:  epoch  0, batch   129 | loss: 2.3562133
MixupTrain:  epoch  0, batch   130 | loss: 2.4428148
MixupTrain:  epoch  0, batch   131 | loss: 2.3756633
MixupTrain:  epoch  0, batch   132 | loss: 2.2502427
MixupTrain:  epoch  0, batch   133 | loss: 2.2412689
MixupTrain:  epoch  0, batch   134 | loss: 2.2248161
MixupTrain:  epoch  0, batch   135 | loss: 2.1531191
MixupTrain:  epoch  0, batch   136 | loss: 2.2924545
MixupTrain:  epoch  0, batch   137 | loss: 2.2288141
MixupTrain:  epoch  0, batch   138 | loss: 2.2061753
MixupTrain:  epoch  0, batch   139 | loss: 2.1884151
MixupTrain:  epoch  0, batch   140 | loss: 2.1848776
MixupTrain:  epoch  0, batch   141 | loss: 2.2459917
MixupTrain:  epoch  0, batch   142 | loss: 2.2066743
MixupTrain:  epoch  0, batch   143 | loss: 2.1567645
MixupTrain:  epoch  0, batch   144 | loss: 2.2797637
MixupTrain:  epoch  0, batch   145 | loss: 2.2583499
MixupTrain:  epoch  0, batch   146 | loss: 2.2592847
MixupTrain:  epoch  0, batch   147 | loss: 2.1732476
MixupTrain:  epoch  0, batch   148 | loss: 2.2141407
MixupTrain:  epoch  0, batch   149 | loss: 2.3560398
MixupTrain:  epoch  0, batch   150 | loss: 2.2049971
MixupTrain:  epoch  0, batch   151 | loss: 2.0632589
MixupTrain:  epoch  0, batch   152 | loss: 2.3270855
MixupTrain:  epoch  0, batch   153 | loss: 2.3076060
MixupTrain:  epoch  0, batch   154 | loss: 2.0962069
MixupTrain:  epoch  0, batch   155 | loss: 2.1478415
MixupTrain:  epoch  0, batch   156 | loss: 2.2479615
MixupTrain:  epoch  0, batch   157 | loss: 2.1908596
MixupTrain:  epoch  0, batch   158 | loss: 2.1718509
MixupTrain:  epoch  0, batch   159 | loss: 2.1620381
MixupTrain:  epoch  0, batch   160 | loss: 2.0764661
MixupTrain:  epoch  0, batch   161 | loss: 2.2670808
MixupTrain:  epoch  0, batch   162 | loss: 2.1203747
MixupTrain:  epoch  0, batch   163 | loss: 2.0998573
MixupTrain:  epoch  0, batch   164 | loss: 2.1766648
MixupTrain:  epoch  0, batch   165 | loss: 2.2060032
MixupTrain:  epoch  0, batch   166 | loss: 2.2864547
MixupTrain:  epoch  0, batch   167 | loss: 2.2653251
MixupTrain:  epoch  0, batch   168 | loss: 2.2391438
MixupTrain:  epoch  0, batch   169 | loss: 2.1401143
MixupTrain:  epoch  0, batch   170 | loss: 2.1884420
MixupTrain:  epoch  0, batch   171 | loss: 2.2083564
MixupTrain:  epoch  0, batch   172 | loss: 2.1059737
MixupTrain:  epoch  0, batch   173 | loss: 2.2767246
MixupTrain:  epoch  0, batch   174 | loss: 2.2473092
MixupTrain:  epoch  0, batch   175 | loss: 2.1181884
MixupTrain:  epoch  0, batch   176 | loss: 2.1865017
MixupTrain:  epoch  0, batch   177 | loss: 2.1927323
MixupTrain:  epoch  0, batch   178 | loss: 2.1415849
MixupTrain:  epoch  0, batch   179 | loss: 2.1081340
MixupTrain:  epoch  0, batch   180 | loss: 2.1103125
MixupTrain:  epoch  0, batch   181 | loss: 2.1347504
MixupTrain:  epoch  0, batch   182 | loss: 2.0363023
MixupTrain:  epoch  0, batch   183 | loss: 2.0272045
MixupTrain:  epoch  0, batch   184 | loss: 2.1475389
MixupTrain:  epoch  0, batch   185 | loss: 2.1729667
MixupTrain:  epoch  0, batch   186 | loss: 2.1221404
MixupTrain:  epoch  0, batch   187 | loss: 2.1406856
MixupTrain:  epoch  0, batch   188 | loss: 2.1434517
MixupTrain:  epoch  0, batch   189 | loss: 2.1164463
MixupTrain:  epoch  0, batch   190 | loss: 2.1437132
MixupTrain:  epoch  0, batch   191 | loss: 2.0782423
MixupTrain:  epoch  0, batch   192 | loss: 2.1240354
MixupTrain:  epoch  0, batch   193 | loss: 2.1565092
MixupTrain:  epoch  0, batch   194 | loss: 2.1571708
MixupTrain:  epoch  0, batch   195 | loss: 2.0667696
MixupTrain:  epoch  0, batch   196 | loss: 2.1436400
MixupTrain:  epoch  0, batch   197 | loss: 2.0580993
MixupTrain:  epoch  0, batch   198 | loss: 2.1447828
MixupTrain:  epoch  0, batch   199 | loss: 2.2825503
MixupTrain:  epoch  0, batch   200 | loss: 2.1423001
MixupTrain:  epoch  0, batch   201 | loss: 2.1034493
MixupTrain:  epoch  0, batch   202 | loss: 2.1438341
MixupTrain:  epoch  0, batch   203 | loss: 2.1500196
MixupTrain:  epoch  0, batch   204 | loss: 2.1940968
MixupTrain:  epoch  0, batch   205 | loss: 2.0575480
MixupTrain:  epoch  0, batch   206 | loss: 2.0524712
MixupTrain:  epoch  0, batch   207 | loss: 2.1240020
MixupTrain:  epoch  0, batch   208 | loss: 2.1131282
MixupTrain:  epoch  0, batch   209 | loss: 2.1003180
MixupTrain:  epoch  0, batch   210 | loss: 2.2550049
MixupTrain:  epoch  0, batch   211 | loss: 2.1141047
MixupTrain:  epoch  0, batch   212 | loss: 2.1622877
MixupTrain:  epoch  0, batch   213 | loss: 2.1489441
MixupTrain:  epoch  0, batch   214 | loss: 2.0949337
MixupTrain:  epoch  0, batch   215 | loss: 2.1589260
MixupTrain:  epoch  0, batch   216 | loss: 2.0831323
MixupTrain:  epoch  0, batch   217 | loss: 2.0556898
MixupTrain:  epoch  0, batch   218 | loss: 2.0686641
MixupTrain:  epoch  0, batch   219 | loss: 2.1167367
MixupTrain:  epoch  0, batch   220 | loss: 2.0718689
MixupTrain:  epoch  0, batch   221 | loss: 2.0675182
MixupTrain:  epoch  0, batch   222 | loss: 2.0960407
MixupTrain:  epoch  0, batch   223 | loss: 2.0985098
MixupTrain:  epoch  0, batch   224 | loss: 2.1920013
MixupTrain:  epoch  0, batch   225 | loss: 2.1386638
MixupTrain:  epoch  0, batch   226 | loss: 2.1297739
MixupTrain:  epoch  0, batch   227 | loss: 2.0628281
MixupTrain:  epoch  0, batch   228 | loss: 2.1227551
MixupTrain:  epoch  0, batch   229 | loss: 2.0577073
MixupTrain:  epoch  0, batch   230 | loss: 2.1817546
MixupTrain:  epoch  0, batch   231 | loss: 2.1304355
MixupTrain:  epoch  0, batch   232 | loss: 2.0574639
MixupTrain:  epoch  0, batch   233 | loss: 1.9899641
MemoryTrain:  epoch  0, batch     0 | loss: 1.9902973
MemoryTrain:  epoch  0, batch     1 | loss: 3.4257598
MemoryTrain:  epoch  0, batch     2 | loss: 2.5076380
MemoryTrain:  epoch  0, batch     3 | loss: 3.2114995
MemoryTrain:  epoch  0, batch     4 | loss: 2.3843122
MemoryTrain:  epoch  1, batch     0 | loss: 1.8709512
MemoryTrain:  epoch  1, batch     1 | loss: 1.8696759
MemoryTrain:  epoch  1, batch     2 | loss: 1.8366680
MemoryTrain:  epoch  1, batch     3 | loss: 1.8811402
MemoryTrain:  epoch  1, batch     4 | loss: 1.8414114
MemoryTrain:  epoch  2, batch     0 | loss: 1.8412440
MemoryTrain:  epoch  2, batch     1 | loss: 1.8490069
MemoryTrain:  epoch  2, batch     2 | loss: 1.8476033
MemoryTrain:  epoch  2, batch     3 | loss: 1.8471781
MemoryTrain:  epoch  2, batch     4 | loss: 1.8187698
MemoryTrain:  epoch  3, batch     0 | loss: 1.8400116
MemoryTrain:  epoch  3, batch     1 | loss: 1.8623590
MemoryTrain:  epoch  3, batch     2 | loss: 1.8835166
MemoryTrain:  epoch  3, batch     3 | loss: 1.8440259
MemoryTrain:  epoch  3, batch     4 | loss: 1.8197174
MemoryTrain:  epoch  4, batch     0 | loss: 1.8988597
MemoryTrain:  epoch  4, batch     1 | loss: 1.8488493
MemoryTrain:  epoch  4, batch     2 | loss: 1.8487911
MemoryTrain:  epoch  4, batch     3 | loss: 1.8497125
MemoryTrain:  epoch  4, batch     4 | loss: 1.8442260
MemoryTrain:  epoch  5, batch     0 | loss: 1.8535933
MemoryTrain:  epoch  5, batch     1 | loss: 1.8549207
MemoryTrain:  epoch  5, batch     2 | loss: 1.8697177
MemoryTrain:  epoch  5, batch     3 | loss: 1.8391726
MemoryTrain:  epoch  5, batch     4 | loss: 1.8216931
MemoryTrain:  epoch  6, batch     0 | loss: 1.8665738
MemoryTrain:  epoch  6, batch     1 | loss: 1.8464215
MemoryTrain:  epoch  6, batch     2 | loss: 1.8495209
MemoryTrain:  epoch  6, batch     3 | loss: 1.8576498
MemoryTrain:  epoch  6, batch     4 | loss: 1.8266399
MemoryTrain:  epoch  7, batch     0 | loss: 1.8563483
MemoryTrain:  epoch  7, batch     1 | loss: 1.8544674
MemoryTrain:  epoch  7, batch     2 | loss: 1.8443251
MemoryTrain:  epoch  7, batch     3 | loss: 1.8560430
MemoryTrain:  epoch  7, batch     4 | loss: 1.9294679
MemoryTrain:  epoch  8, batch     0 | loss: 1.8682096
MemoryTrain:  epoch  8, batch     1 | loss: 1.8652685
MemoryTrain:  epoch  8, batch     2 | loss: 1.8660839
MemoryTrain:  epoch  8, batch     3 | loss: 1.8567088
MemoryTrain:  epoch  8, batch     4 | loss: 1.8057640
MemoryTrain:  epoch  9, batch     0 | loss: 1.8578651
MemoryTrain:  epoch  9, batch     1 | loss: 1.8480961
MemoryTrain:  epoch  9, batch     2 | loss: 1.8533716
MemoryTrain:  epoch  9, batch     3 | loss: 1.8595212
MemoryTrain:  epoch  9, batch     4 | loss: 1.9112148
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   
[EVAL] batch:    1 | acc: 93.75%,  total acc: 87.50%   
[EVAL] batch:    2 | acc: 81.25%,  total acc: 85.42%   
[EVAL] batch:    3 | acc: 93.75%,  total acc: 87.50%   
[EVAL] batch:    4 | acc: 87.50%,  total acc: 87.50%   
[EVAL] batch:    5 | acc: 100.00%,  total acc: 89.58%   
[EVAL] batch:    6 | acc: 100.00%,  total acc: 91.07%   
[EVAL] batch:    7 | acc: 93.75%,  total acc: 91.41%   
[EVAL] batch:    8 | acc: 87.50%,  total acc: 90.97%   
[EVAL] batch:    9 | acc: 75.00%,  total acc: 89.38%   
[EVAL] batch:   10 | acc: 81.25%,  total acc: 88.64%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 89.06%   
[EVAL] batch:   12 | acc: 87.50%,  total acc: 88.94%   
[EVAL] batch:   13 | acc: 93.75%,  total acc: 89.29%   
[EVAL] batch:   14 | acc: 43.75%,  total acc: 86.25%   
[EVAL] batch:    0 | acc: 43.75%,  total acc: 43.75%   
[EVAL] batch:    1 | acc: 62.50%,  total acc: 53.12%   
[EVAL] batch:    2 | acc: 56.25%,  total acc: 54.17%   
[EVAL] batch:    3 | acc: 43.75%,  total acc: 51.56%   
[EVAL] batch:    4 | acc: 56.25%,  total acc: 52.50%   
[EVAL] batch:    5 | acc: 50.00%,  total acc: 52.08%   
[EVAL] batch:    6 | acc: 93.75%,  total acc: 58.04%   
[EVAL] batch:    7 | acc: 93.75%,  total acc: 62.50%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 66.67%   
[EVAL] batch:    9 | acc: 100.00%,  total acc: 70.00%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 72.73%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 74.48%   
[EVAL] batch:   12 | acc: 93.75%,  total acc: 75.96%   
[EVAL] batch:   13 | acc: 62.50%,  total acc: 75.00%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 75.00%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 73.83%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 73.90%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 73.26%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 72.70%   
[EVAL] batch:   19 | acc: 81.25%,  total acc: 73.12%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 74.40%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 75.57%   
[EVAL] batch:   22 | acc: 93.75%,  total acc: 76.36%   
[EVAL] batch:   23 | acc: 93.75%,  total acc: 77.08%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 78.00%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 78.85%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 79.40%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 80.13%   
[EVAL] batch:   28 | acc: 93.75%,  total acc: 80.60%   
[EVAL] batch:   29 | acc: 75.00%,  total acc: 80.42%   
[EVAL] batch:   30 | acc: 87.50%,  total acc: 80.65%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 81.05%   
[EVAL] batch:   32 | acc: 93.75%,  total acc: 81.44%   
[EVAL] batch:   33 | acc: 81.25%,  total acc: 81.43%   
[EVAL] batch:   34 | acc: 93.75%,  total acc: 81.79%   
[EVAL] batch:   35 | acc: 81.25%,  total acc: 81.77%   
[EVAL] batch:   36 | acc: 93.75%,  total acc: 82.09%   
[EVAL] batch:   37 | acc: 93.75%,  total acc: 82.40%   
[EVAL] batch:   38 | acc: 100.00%,  total acc: 82.85%   
[EVAL] batch:   39 | acc: 100.00%,  total acc: 83.28%   
[EVAL] batch:   40 | acc: 81.25%,  total acc: 83.23%   
[EVAL] batch:   41 | acc: 100.00%,  total acc: 83.63%   
[EVAL] batch:   42 | acc: 62.50%,  total acc: 83.14%   
[EVAL] batch:   43 | acc: 87.50%,  total acc: 83.24%   
[EVAL] batch:   44 | acc: 93.75%,  total acc: 83.47%   
[EVAL] batch:   45 | acc: 87.50%,  total acc: 83.56%   
[EVAL] batch:   46 | acc: 81.25%,  total acc: 83.51%   
cur_acc:  ['0.8580', '0.8625']
his_acc:  ['0.8580', '0.8351']
CurrentTrain: epoch  0, batch     0 | loss: 5.8775702
CurrentTrain: epoch  0, batch     1 | loss: 6.6631556
CurrentTrain: epoch  1, batch     0 | loss: 6.6007686
CurrentTrain: epoch  1, batch     1 | loss: 4.7525277
CurrentTrain: epoch  2, batch     0 | loss: 5.0144186
CurrentTrain: epoch  2, batch     1 | loss: 5.1446705
CurrentTrain: epoch  3, batch     0 | loss: 4.9163270
CurrentTrain: epoch  3, batch     1 | loss: 4.5195799
CurrentTrain: epoch  4, batch     0 | loss: 4.5597591
CurrentTrain: epoch  4, batch     1 | loss: 4.5942984
CurrentTrain: epoch  5, batch     0 | loss: 4.8489547
CurrentTrain: epoch  5, batch     1 | loss: 2.6637013
CurrentTrain: epoch  6, batch     0 | loss: 3.9159029
CurrentTrain: epoch  6, batch     1 | loss: 4.1897397
CurrentTrain: epoch  7, batch     0 | loss: 3.3747683
CurrentTrain: epoch  7, batch     1 | loss: 3.2930403
CurrentTrain: epoch  8, batch     0 | loss: 3.0561302
CurrentTrain: epoch  8, batch     1 | loss: 2.7201972
CurrentTrain: epoch  9, batch     0 | loss: 2.5224977
CurrentTrain: epoch  9, batch     1 | loss: 2.1343932
#### person date of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person date of birth" means a person was born in a date.
Here is an example:
Relation: person date of birth
Context: born of schoolteacher parents in the western town of sabaneta on july 28 , 1954 , chavez studied at the military academy of venezuela in caracas .
Head Entity: chavez
Tail Entity: july 28 , 1954
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person date of birth":
Relation: person date of birth  
Context: the famous physicist albert einstein was born in ulm, in the kingdom of wurttemberg in the german empire on march 14, 1879.  
Head Entity: albert einstein  
Tail Entity: march 14, 1879  

Relation: person date of birth  
Context: the renowned author jane austen was born on december 16, 1775, in steventon, hampshire, england.  
Head Entity: jane austen  
Tail Entity: december 16, 1775  

Relation: person date of birth  
Context: the legendary musician freddie mercury was born farrokh bulsara on september 5, 1946, in zanzibar, tanzania.  
Head Entity: freddie mercury  
Tail Entity: september 5, 1946  

Relation: person date of birth  
Context: the influential civil rights leader martin luther king jr. was born on january 15, 1929, in atlanta, georgia.  
Head Entity: martin luther king jr.  
Tail Entity: january 15, 1929  

Relation: person date of birth  
Context: the famous painter pablo picasso was born on october 25, 1881, in malaga, spain.  
Head Entity: pablo picasso  
Tail Entity: october 25, 1881  
#### person stateorprovince of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of birth" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of birth
Context: jane matilda bolin was born on april 11 , 1908 , in poughkeepsie , ny .
Head Entity: jane matilda bolin
Tail Entity: ny
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of birth":
Relation: person stateorprovince of birth  
Context: albert einstein was born on march 14, 1879, in ulm, württemberg, germany.  
Head Entity: albert einstein  
Tail Entity: württemberg  

Relation: person stateorprovince of birth  
Context: marilyn monroe was born on june 1, 1926, in los angeles, california.  
Head Entity: marilyn monroe  
Tail Entity: california  

Relation: person stateorprovince of birth  
Context: barack obama was born on august 4, 1961, in honolulu, hawaii.  
Head Entity: barack obama  
Tail Entity: hawaii  

Relation: person stateorprovince of birth  
Context: agatha christie was born on september 15, 1890, in torquay, devon.  
Head Entity: agatha christie  
Tail Entity: devon  

Relation: person stateorprovince of birth  
Context: nelson mandela was born on july 18, 1918, in mvezo, eastern cape.  
Head Entity: nelson mandela  
Tail Entity: eastern cape  
#### person parents ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person parents" means a person 's parent is a person.
Here is an example:
Relation: person parents
Context: lynne spears told the court that lutfi had treated her daughter like a hostage in her own home , drugged her and took over her finances .
Head Entity: her
Tail Entity: lynne spears
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person parents":
1. Relation: person parents  
   Context: After years of hard work, Sarah finally made her parents proud by graduating at the top of her class.  
   Head Entity: her  
   Tail Entity: parents  

2. Relation: person parents  
   Context: During the family reunion, Michael shared stories about how his father taught him valuable life lessons.  
   Head Entity: his  
   Tail Entity: father  

3. Relation: person parents  
   Context: Emily often reminisces about the summer vacations she spent with her mother at the beach.  
   Head Entity: her  
   Tail Entity: mother  

4. Relation: person parents  
   Context: The documentary highlighted how the struggles of his parents shaped his career as an artist.  
   Head Entity: his  
   Tail Entity: parents  

5. Relation: person parents  
   Context: Jessica credits her success to the unwavering support she received from her father throughout her life.  
   Head Entity: her  
   Tail Entity: father  
#### person employee of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person employee of" means a person is an employee of an organization.
Here is an example:
Relation: person employee of
Context: seeking revenge , axel reunites with old pal sgt. billy rosewood -lrb- judge reinhold -rrb- and jon flint -lrb- hector elizondo -rrb- of the beverly hills police department .
Head Entity: hector elizondo
Tail Entity: beverly hills police department
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person employee of":
Relation: person employee of  
Context: After years of hard work, Maria finally landed a job at the prestigious tech firm, where she would contribute to innovative projects.  
Head Entity: Maria  
Tail Entity: prestigious tech firm  

Relation: person employee of  
Context: John has been with the company for over a decade, climbing the ranks to become the lead engineer on several key projects.  
Head Entity: John  
Tail Entity: the company  

Relation: person employee of  
Context: As a talented chef, Lisa was thrilled to accept a position at the renowned restaurant, known for its exquisite cuisine.  
Head Entity: Lisa  
Tail Entity: renowned restaurant  

Relation: person employee of  
Context: After completing his internship, David was offered a full-time position at the marketing agency, where he could apply his skills.  
Head Entity: David  
Tail Entity: marketing agency  

Relation: person employee of  
Context: Emily's dedication and creativity earned her a spot at the leading fashion brand, where she would design the next collection.  
Head Entity: Emily  
Tail Entity: leading fashion brand  
#### person stateorprovince of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of death" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of death
Context: irene morgan kirkaldy , whose defiance of bus segregation laws more than a decade before rosa parks ' landmark case helped lay the foundation for later civil rights victories , died friday at her home in hayes , va. .
Head Entity: irene morgan kirkaldy
Tail Entity: va.
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of death":
Relation: person stateorprovince of death  
Context: john doe, a renowned author known for his thrilling novels, passed away peacefully in his sleep at his residence in los angeles, ca.  
Head Entity: john doe  
Tail Entity: ca.  

Relation: person stateorprovince of death  
Context: after a long battle with illness, elizabeth taylor, the iconic actress, died at the age of 79 in her home located in bel air, ca.  
Head Entity: elizabeth taylor  
Tail Entity: ca.  

Relation: person stateorprovince of death  
Context: the famous physicist, albert einstein, took his last breath in princeton, nj, where he had lived for many years.  
Head Entity: albert einstein  
Tail Entity: nj.  

Relation: person stateorprovince of death  
Context: the beloved musician, prince, was found unresponsive in his home in minneapolis, mn, leading to an outpouring of grief from fans worldwide.  
Head Entity: prince  
Tail Entity: mn.  

Relation: person stateorprovince of death  
Context: the celebrated civil rights leader, martin luther king jr., was assassinated in memphis, tn, a tragic event that shocked the nation.  
Head Entity: martin luther king jr.  
Tail Entity: tn.  
Mixup data size:  6820
MixupTrain:  epoch  0, batch     0 | loss: 4.7924795
MixupTrain:  epoch  0, batch     1 | loss: 5.5902605
MixupTrain:  epoch  0, batch     2 | loss: 5.4057646
MixupTrain:  epoch  0, batch     3 | loss: 5.2601161
MixupTrain:  epoch  0, batch     4 | loss: 4.8460269
MixupTrain:  epoch  0, batch     5 | loss: 3.9470356
MixupTrain:  epoch  0, batch     6 | loss: 4.9864635
MixupTrain:  epoch  0, batch     7 | loss: 4.6208529
MixupTrain:  epoch  0, batch     8 | loss: 4.4723177
MixupTrain:  epoch  0, batch     9 | loss: 4.4325852
MixupTrain:  epoch  0, batch    10 | loss: 4.1253357
MixupTrain:  epoch  0, batch    11 | loss: 4.1476126
MixupTrain:  epoch  0, batch    12 | loss: 3.6946611
MixupTrain:  epoch  0, batch    13 | loss: 3.7910414
MixupTrain:  epoch  0, batch    14 | loss: 3.8716290
MixupTrain:  epoch  0, batch    15 | loss: 3.9318266
MixupTrain:  epoch  0, batch    16 | loss: 3.6852560
MixupTrain:  epoch  0, batch    17 | loss: 4.1587543
MixupTrain:  epoch  0, batch    18 | loss: 4.2260389
MixupTrain:  epoch  0, batch    19 | loss: 3.6859784
MixupTrain:  epoch  0, batch    20 | loss: 3.4943831
MixupTrain:  epoch  0, batch    21 | loss: 3.0817976
MixupTrain:  epoch  0, batch    22 | loss: 3.3267431
MixupTrain:  epoch  0, batch    23 | loss: 3.7033033
MixupTrain:  epoch  0, batch    24 | loss: 3.0820918
MixupTrain:  epoch  0, batch    25 | loss: 3.1732135
MixupTrain:  epoch  0, batch    26 | loss: 3.1190088
MixupTrain:  epoch  0, batch    27 | loss: 3.7737899
MixupTrain:  epoch  0, batch    28 | loss: 3.0980763
MixupTrain:  epoch  0, batch    29 | loss: 3.6801291
MixupTrain:  epoch  0, batch    30 | loss: 3.3010583
MixupTrain:  epoch  0, batch    31 | loss: 3.3574293
MixupTrain:  epoch  0, batch    32 | loss: 3.1352909
MixupTrain:  epoch  0, batch    33 | loss: 2.8884039
MixupTrain:  epoch  0, batch    34 | loss: 2.6342523
MixupTrain:  epoch  0, batch    35 | loss: 2.9770398
MixupTrain:  epoch  0, batch    36 | loss: 3.3059609
MixupTrain:  epoch  0, batch    37 | loss: 3.0291309
MixupTrain:  epoch  0, batch    38 | loss: 2.8222437
MixupTrain:  epoch  0, batch    39 | loss: 3.1242061
MixupTrain:  epoch  0, batch    40 | loss: 3.3076985
MixupTrain:  epoch  0, batch    41 | loss: 2.9279475
MixupTrain:  epoch  0, batch    42 | loss: 3.5285444
MixupTrain:  epoch  0, batch    43 | loss: 3.2140849
MixupTrain:  epoch  0, batch    44 | loss: 2.8803966
MixupTrain:  epoch  0, batch    45 | loss: 3.0602970
MixupTrain:  epoch  0, batch    46 | loss: 3.5534205
MixupTrain:  epoch  0, batch    47 | loss: 2.9809871
MixupTrain:  epoch  0, batch    48 | loss: 3.1516089
MixupTrain:  epoch  0, batch    49 | loss: 2.9135411
MixupTrain:  epoch  0, batch    50 | loss: 2.3861156
MixupTrain:  epoch  0, batch    51 | loss: 2.9129694
MixupTrain:  epoch  0, batch    52 | loss: 2.5882516
MixupTrain:  epoch  0, batch    53 | loss: 2.6766193
MixupTrain:  epoch  0, batch    54 | loss: 3.3314586
MixupTrain:  epoch  0, batch    55 | loss: 2.8127928
MixupTrain:  epoch  0, batch    56 | loss: 2.2223988
MixupTrain:  epoch  0, batch    57 | loss: 2.6719437
MixupTrain:  epoch  0, batch    58 | loss: 2.7834444
MixupTrain:  epoch  0, batch    59 | loss: 3.2146635
MixupTrain:  epoch  0, batch    60 | loss: 2.7917190
MixupTrain:  epoch  0, batch    61 | loss: 2.6372237
MixupTrain:  epoch  0, batch    62 | loss: 2.8863025
MixupTrain:  epoch  0, batch    63 | loss: 2.7553496
MixupTrain:  epoch  0, batch    64 | loss: 2.6451378
MixupTrain:  epoch  0, batch    65 | loss: 2.5653017
MixupTrain:  epoch  0, batch    66 | loss: 2.7524242
MixupTrain:  epoch  0, batch    67 | loss: 2.5435638
MixupTrain:  epoch  0, batch    68 | loss: 2.7460737
MixupTrain:  epoch  0, batch    69 | loss: 2.5853612
MixupTrain:  epoch  0, batch    70 | loss: 2.2359366
MixupTrain:  epoch  0, batch    71 | loss: 2.3725758
MixupTrain:  epoch  0, batch    72 | loss: 2.5399053
MixupTrain:  epoch  0, batch    73 | loss: 2.3768559
MixupTrain:  epoch  0, batch    74 | loss: 2.5595479
MixupTrain:  epoch  0, batch    75 | loss: 2.3026104
MixupTrain:  epoch  0, batch    76 | loss: 2.5547123
MixupTrain:  epoch  0, batch    77 | loss: 2.3216588
MixupTrain:  epoch  0, batch    78 | loss: 2.5205493
MixupTrain:  epoch  0, batch    79 | loss: 2.5228744
MixupTrain:  epoch  0, batch    80 | loss: 2.5401778
MixupTrain:  epoch  0, batch    81 | loss: 2.4475570
MixupTrain:  epoch  0, batch    82 | loss: 2.3512478
MixupTrain:  epoch  0, batch    83 | loss: 2.5320699
MixupTrain:  epoch  0, batch    84 | loss: 2.7618699
MixupTrain:  epoch  0, batch    85 | loss: 2.4874909
MixupTrain:  epoch  0, batch    86 | loss: 2.5047023
MixupTrain:  epoch  0, batch    87 | loss: 2.2966440
MixupTrain:  epoch  0, batch    88 | loss: 2.5259848
MixupTrain:  epoch  0, batch    89 | loss: 2.6403337
MixupTrain:  epoch  0, batch    90 | loss: 2.5262287
MixupTrain:  epoch  0, batch    91 | loss: 2.3298988
MixupTrain:  epoch  0, batch    92 | loss: 2.3748457
MixupTrain:  epoch  0, batch    93 | loss: 2.4607668
MixupTrain:  epoch  0, batch    94 | loss: 2.4383311
MixupTrain:  epoch  0, batch    95 | loss: 2.4032977
MixupTrain:  epoch  0, batch    96 | loss: 2.6357775
MixupTrain:  epoch  0, batch    97 | loss: 2.3225536
MixupTrain:  epoch  0, batch    98 | loss: 2.2945180
MixupTrain:  epoch  0, batch    99 | loss: 2.3363075
MixupTrain:  epoch  0, batch   100 | loss: 2.2270355
MixupTrain:  epoch  0, batch   101 | loss: 2.5379863
MixupTrain:  epoch  0, batch   102 | loss: 2.3560243
MixupTrain:  epoch  0, batch   103 | loss: 2.3481755
MixupTrain:  epoch  0, batch   104 | loss: 2.1523390
MixupTrain:  epoch  0, batch   105 | loss: 2.2367139
MixupTrain:  epoch  0, batch   106 | loss: 2.2084885
MixupTrain:  epoch  0, batch   107 | loss: 2.5260520
MixupTrain:  epoch  0, batch   108 | loss: 2.4332819
MixupTrain:  epoch  0, batch   109 | loss: 2.3161273
MixupTrain:  epoch  0, batch   110 | loss: 2.1402125
MixupTrain:  epoch  0, batch   111 | loss: 2.2431364
MixupTrain:  epoch  0, batch   112 | loss: 2.4764082
MixupTrain:  epoch  0, batch   113 | loss: 2.2496538
MixupTrain:  epoch  0, batch   114 | loss: 2.2159095
MixupTrain:  epoch  0, batch   115 | loss: 2.4068894
MixupTrain:  epoch  0, batch   116 | loss: 2.4312396
MixupTrain:  epoch  0, batch   117 | loss: 2.3968549
MixupTrain:  epoch  0, batch   118 | loss: 2.3999352
MixupTrain:  epoch  0, batch   119 | loss: 2.1829922
MixupTrain:  epoch  0, batch   120 | loss: 2.3463404
MixupTrain:  epoch  0, batch   121 | loss: 2.2543716
MixupTrain:  epoch  0, batch   122 | loss: 2.3867579
MixupTrain:  epoch  0, batch   123 | loss: 2.3762701
MixupTrain:  epoch  0, batch   124 | loss: 2.2527595
MixupTrain:  epoch  0, batch   125 | loss: 2.2741904
MixupTrain:  epoch  0, batch   126 | loss: 2.2656763
MixupTrain:  epoch  0, batch   127 | loss: 2.2248683
MixupTrain:  epoch  0, batch   128 | loss: 2.4650741
MixupTrain:  epoch  0, batch   129 | loss: 2.2974150
MixupTrain:  epoch  0, batch   130 | loss: 2.3146753
MixupTrain:  epoch  0, batch   131 | loss: 2.2372003
MixupTrain:  epoch  0, batch   132 | loss: 2.3674197
MixupTrain:  epoch  0, batch   133 | loss: 2.1764784
MixupTrain:  epoch  0, batch   134 | loss: 2.4311459
MixupTrain:  epoch  0, batch   135 | loss: 2.1732073
MixupTrain:  epoch  0, batch   136 | loss: 2.1786842
MixupTrain:  epoch  0, batch   137 | loss: 2.2995052
MixupTrain:  epoch  0, batch   138 | loss: 2.1619349
MixupTrain:  epoch  0, batch   139 | loss: 2.2266612
MixupTrain:  epoch  0, batch   140 | loss: 2.1349757
MixupTrain:  epoch  0, batch   141 | loss: 2.1223354
MixupTrain:  epoch  0, batch   142 | loss: 2.3347747
MixupTrain:  epoch  0, batch   143 | loss: 2.0747080
MixupTrain:  epoch  0, batch   144 | loss: 2.2949920
MixupTrain:  epoch  0, batch   145 | loss: 2.3870690
MixupTrain:  epoch  0, batch   146 | loss: 2.2439024
MixupTrain:  epoch  0, batch   147 | loss: 2.3370008
MixupTrain:  epoch  0, batch   148 | loss: 2.2985475
MixupTrain:  epoch  0, batch   149 | loss: 2.1986666
MixupTrain:  epoch  0, batch   150 | loss: 2.2351098
MixupTrain:  epoch  0, batch   151 | loss: 2.1914859
MixupTrain:  epoch  0, batch   152 | loss: 2.2707071
MixupTrain:  epoch  0, batch   153 | loss: 2.1254411
MixupTrain:  epoch  0, batch   154 | loss: 2.1052577
MixupTrain:  epoch  0, batch   155 | loss: 2.2143354
MixupTrain:  epoch  0, batch   156 | loss: 2.1528258
MixupTrain:  epoch  0, batch   157 | loss: 2.1346874
MixupTrain:  epoch  0, batch   158 | loss: 2.2421346
MixupTrain:  epoch  0, batch   159 | loss: 2.1606956
MixupTrain:  epoch  0, batch   160 | loss: 2.1999111
MixupTrain:  epoch  0, batch   161 | loss: 2.1470604
MixupTrain:  epoch  0, batch   162 | loss: 2.1166739
MixupTrain:  epoch  0, batch   163 | loss: 2.1464055
MixupTrain:  epoch  0, batch   164 | loss: 2.3320563
MixupTrain:  epoch  0, batch   165 | loss: 2.2017155
MixupTrain:  epoch  0, batch   166 | loss: 2.1674562
MixupTrain:  epoch  0, batch   167 | loss: 2.2702699
MixupTrain:  epoch  0, batch   168 | loss: 2.1103053
MixupTrain:  epoch  0, batch   169 | loss: 2.1085413
MixupTrain:  epoch  0, batch   170 | loss: 2.1858137
MixupTrain:  epoch  0, batch   171 | loss: 2.1840301
MixupTrain:  epoch  0, batch   172 | loss: 2.1509700
MixupTrain:  epoch  0, batch   173 | loss: 2.2300782
MixupTrain:  epoch  0, batch   174 | loss: 2.2139893
MixupTrain:  epoch  0, batch   175 | loss: 2.1359444
MixupTrain:  epoch  0, batch   176 | loss: 2.2998538
MixupTrain:  epoch  0, batch   177 | loss: 2.2502117
MixupTrain:  epoch  0, batch   178 | loss: 2.1033096
MixupTrain:  epoch  0, batch   179 | loss: 2.2396460
MixupTrain:  epoch  0, batch   180 | loss: 2.2160282
MixupTrain:  epoch  0, batch   181 | loss: 2.2428455
MixupTrain:  epoch  0, batch   182 | loss: 2.0520198
MixupTrain:  epoch  0, batch   183 | loss: 2.2787352
MixupTrain:  epoch  0, batch   184 | loss: 2.1634998
MixupTrain:  epoch  0, batch   185 | loss: 2.1296320
MixupTrain:  epoch  0, batch   186 | loss: 2.2680371
MixupTrain:  epoch  0, batch   187 | loss: 2.1482756
MixupTrain:  epoch  0, batch   188 | loss: 2.1314888
MixupTrain:  epoch  0, batch   189 | loss: 2.2389293
MixupTrain:  epoch  0, batch   190 | loss: 2.2281218
MixupTrain:  epoch  0, batch   191 | loss: 2.3076873
MixupTrain:  epoch  0, batch   192 | loss: 2.0266991
MixupTrain:  epoch  0, batch   193 | loss: 2.3099399
MixupTrain:  epoch  0, batch   194 | loss: 2.1902709
MixupTrain:  epoch  0, batch   195 | loss: 2.0750906
MixupTrain:  epoch  0, batch   196 | loss: 2.0954671
MixupTrain:  epoch  0, batch   197 | loss: 2.2162309
MixupTrain:  epoch  0, batch   198 | loss: 2.1175153
MixupTrain:  epoch  0, batch   199 | loss: 2.0874171
MixupTrain:  epoch  0, batch   200 | loss: 2.2012455
MixupTrain:  epoch  0, batch   201 | loss: 2.1848884
MixupTrain:  epoch  0, batch   202 | loss: 2.1383002
MixupTrain:  epoch  0, batch   203 | loss: 2.1111336
MixupTrain:  epoch  0, batch   204 | loss: 2.1307406
MixupTrain:  epoch  0, batch   205 | loss: 2.2670624
MixupTrain:  epoch  0, batch   206 | loss: 2.0431247
MixupTrain:  epoch  0, batch   207 | loss: 2.0934312
MixupTrain:  epoch  0, batch   208 | loss: 2.0839953
MixupTrain:  epoch  0, batch   209 | loss: 2.0643013
MixupTrain:  epoch  0, batch   210 | loss: 2.0313540
MixupTrain:  epoch  0, batch   211 | loss: 2.1550932
MixupTrain:  epoch  0, batch   212 | loss: 2.2074151
MixupTrain:  epoch  0, batch   213 | loss: 2.3110514
MixupTrain:  epoch  0, batch   214 | loss: 2.2238665
MixupTrain:  epoch  0, batch   215 | loss: 2.1708579
MixupTrain:  epoch  0, batch   216 | loss: 2.1332135
MixupTrain:  epoch  0, batch   217 | loss: 2.1032667
MixupTrain:  epoch  0, batch   218 | loss: 2.0998952
MixupTrain:  epoch  0, batch   219 | loss: 2.1442375
MixupTrain:  epoch  0, batch   220 | loss: 2.2591410
MixupTrain:  epoch  0, batch   221 | loss: 2.2119713
MixupTrain:  epoch  0, batch   222 | loss: 2.1407163
MixupTrain:  epoch  0, batch   223 | loss: 1.9995821
MixupTrain:  epoch  0, batch   224 | loss: 2.1366558
MixupTrain:  epoch  0, batch   225 | loss: 2.0873880
MixupTrain:  epoch  0, batch   226 | loss: 2.0777493
MixupTrain:  epoch  0, batch   227 | loss: 2.2815394
MixupTrain:  epoch  0, batch   228 | loss: 2.2447345
MixupTrain:  epoch  0, batch   229 | loss: 2.0954483
MixupTrain:  epoch  0, batch   230 | loss: 2.2169442
MixupTrain:  epoch  0, batch   231 | loss: 2.1347501
MixupTrain:  epoch  0, batch   232 | loss: 2.1174154
MixupTrain:  epoch  0, batch   233 | loss: 2.1750233
MixupTrain:  epoch  0, batch   234 | loss: 2.1442423
MixupTrain:  epoch  0, batch   235 | loss: 2.1674032
MixupTrain:  epoch  0, batch   236 | loss: 2.0160680
MixupTrain:  epoch  0, batch   237 | loss: 2.1940303
MixupTrain:  epoch  0, batch   238 | loss: 2.2253528
MixupTrain:  epoch  0, batch   239 | loss: 2.1110485
MixupTrain:  epoch  0, batch   240 | loss: 2.0298114
MixupTrain:  epoch  0, batch   241 | loss: 2.1910052
MixupTrain:  epoch  0, batch   242 | loss: 2.1388807
MixupTrain:  epoch  0, batch   243 | loss: 2.1390290
MixupTrain:  epoch  0, batch   244 | loss: 2.1799855
MixupTrain:  epoch  0, batch   245 | loss: 2.0823538
MixupTrain:  epoch  0, batch   246 | loss: 2.0735435
MixupTrain:  epoch  0, batch   247 | loss: 2.0934196
MixupTrain:  epoch  0, batch   248 | loss: 2.0917335
MixupTrain:  epoch  0, batch   249 | loss: 2.0833795
MixupTrain:  epoch  0, batch   250 | loss: 2.1256104
MixupTrain:  epoch  0, batch   251 | loss: 2.1709547
MixupTrain:  epoch  0, batch   252 | loss: 2.1679885
MixupTrain:  epoch  0, batch   253 | loss: 2.1270330
MixupTrain:  epoch  0, batch   254 | loss: 2.0789826
MixupTrain:  epoch  0, batch   255 | loss: 2.0411382
MixupTrain:  epoch  0, batch   256 | loss: 2.0339119
MixupTrain:  epoch  0, batch   257 | loss: 2.1682653
MixupTrain:  epoch  0, batch   258 | loss: 2.0774515
MixupTrain:  epoch  0, batch   259 | loss: 2.1665523
MixupTrain:  epoch  0, batch   260 | loss: 2.0548167
MixupTrain:  epoch  0, batch   261 | loss: 2.1358809
MixupTrain:  epoch  0, batch   262 | loss: 2.0735261
MixupTrain:  epoch  0, batch   263 | loss: 2.0741730
MixupTrain:  epoch  0, batch   264 | loss: 2.0910559
MixupTrain:  epoch  0, batch   265 | loss: 2.1203241
MixupTrain:  epoch  0, batch   266 | loss: 2.0312674
MixupTrain:  epoch  0, batch   267 | loss: 2.2059755
MixupTrain:  epoch  0, batch   268 | loss: 2.0865021
MixupTrain:  epoch  0, batch   269 | loss: 2.0876989
MixupTrain:  epoch  0, batch   270 | loss: 2.1598649
MixupTrain:  epoch  0, batch   271 | loss: 2.0659699
MixupTrain:  epoch  0, batch   272 | loss: 2.0074086
MixupTrain:  epoch  0, batch   273 | loss: 2.1558847
MixupTrain:  epoch  0, batch   274 | loss: 2.0545700
MixupTrain:  epoch  0, batch   275 | loss: 2.1766338
MixupTrain:  epoch  0, batch   276 | loss: 2.0812914
MixupTrain:  epoch  0, batch   277 | loss: 2.0960503
MixupTrain:  epoch  0, batch   278 | loss: 2.1673825
MixupTrain:  epoch  0, batch   279 | loss: 2.0616660
MixupTrain:  epoch  0, batch   280 | loss: 2.1887660
MixupTrain:  epoch  0, batch   281 | loss: 2.0559196
MixupTrain:  epoch  0, batch   282 | loss: 2.0772719
MixupTrain:  epoch  0, batch   283 | loss: 2.0691111
MixupTrain:  epoch  0, batch   284 | loss: 2.1508319
MixupTrain:  epoch  0, batch   285 | loss: 2.1362834
MixupTrain:  epoch  0, batch   286 | loss: 2.1273804
MixupTrain:  epoch  0, batch   287 | loss: 2.0810502
MixupTrain:  epoch  0, batch   288 | loss: 2.1040778
MixupTrain:  epoch  0, batch   289 | loss: 2.1451516
MixupTrain:  epoch  0, batch   290 | loss: 2.1419344
MixupTrain:  epoch  0, batch   291 | loss: 2.0643702
MixupTrain:  epoch  0, batch   292 | loss: 2.0945566
MixupTrain:  epoch  0, batch   293 | loss: 2.0887680
MixupTrain:  epoch  0, batch   294 | loss: 2.1553423
MixupTrain:  epoch  0, batch   295 | loss: 2.1450949
MixupTrain:  epoch  0, batch   296 | loss: 2.0262113
MixupTrain:  epoch  0, batch   297 | loss: 2.1952395
MixupTrain:  epoch  0, batch   298 | loss: 2.1140721
MixupTrain:  epoch  0, batch   299 | loss: 2.0786085
MixupTrain:  epoch  0, batch   300 | loss: 1.9860439
MixupTrain:  epoch  0, batch   301 | loss: 2.0864620
MixupTrain:  epoch  0, batch   302 | loss: 2.0570874
MixupTrain:  epoch  0, batch   303 | loss: 2.0703979
MixupTrain:  epoch  0, batch   304 | loss: 2.0690198
MixupTrain:  epoch  0, batch   305 | loss: 2.1122947
MixupTrain:  epoch  0, batch   306 | loss: 2.0301642
MixupTrain:  epoch  0, batch   307 | loss: 2.1531765
MixupTrain:  epoch  0, batch   308 | loss: 2.1647835
MixupTrain:  epoch  0, batch   309 | loss: 2.0824142
MixupTrain:  epoch  0, batch   310 | loss: 2.0737445
MixupTrain:  epoch  0, batch   311 | loss: 2.1514659
MixupTrain:  epoch  0, batch   312 | loss: 1.9906046
MixupTrain:  epoch  0, batch   313 | loss: 2.2204351
MixupTrain:  epoch  0, batch   314 | loss: 1.9900765
MixupTrain:  epoch  0, batch   315 | loss: 2.0656266
MixupTrain:  epoch  0, batch   316 | loss: 2.0616570
MixupTrain:  epoch  0, batch   317 | loss: 2.1437001
MixupTrain:  epoch  0, batch   318 | loss: 2.0919728
MixupTrain:  epoch  0, batch   319 | loss: 2.1351211
MixupTrain:  epoch  0, batch   320 | loss: 2.1330299
MixupTrain:  epoch  0, batch   321 | loss: 2.1430044
MixupTrain:  epoch  0, batch   322 | loss: 2.0541260
MixupTrain:  epoch  0, batch   323 | loss: 2.0913019
MixupTrain:  epoch  0, batch   324 | loss: 2.1137571
MixupTrain:  epoch  0, batch   325 | loss: 2.1121819
MixupTrain:  epoch  0, batch   326 | loss: 2.0312896
MixupTrain:  epoch  0, batch   327 | loss: 2.1397476
MixupTrain:  epoch  0, batch   328 | loss: 2.0953054
MixupTrain:  epoch  0, batch   329 | loss: 2.1378591
MixupTrain:  epoch  0, batch   330 | loss: 2.0853238
MixupTrain:  epoch  0, batch   331 | loss: 2.0897779
MixupTrain:  epoch  0, batch   332 | loss: 2.1539533
MixupTrain:  epoch  0, batch   333 | loss: 2.1305285
MixupTrain:  epoch  0, batch   334 | loss: 2.0395703
MixupTrain:  epoch  0, batch   335 | loss: 2.0901237
MixupTrain:  epoch  0, batch   336 | loss: 2.0558195
MixupTrain:  epoch  0, batch   337 | loss: 2.0563886
MixupTrain:  epoch  0, batch   338 | loss: 2.1542876
MixupTrain:  epoch  0, batch   339 | loss: 2.0884380
MixupTrain:  epoch  0, batch   340 | loss: 2.1097741
MixupTrain:  epoch  0, batch   341 | loss: 2.0833786
MixupTrain:  epoch  0, batch   342 | loss: 1.9888847
MixupTrain:  epoch  0, batch   343 | loss: 2.0502284
MixupTrain:  epoch  0, batch   344 | loss: 2.0508480
MixupTrain:  epoch  0, batch   345 | loss: 2.1650739
MixupTrain:  epoch  0, batch   346 | loss: 2.0674076
MixupTrain:  epoch  0, batch   347 | loss: 2.0261462
MixupTrain:  epoch  0, batch   348 | loss: 1.9747156
MixupTrain:  epoch  0, batch   349 | loss: 2.0592594
MixupTrain:  epoch  0, batch   350 | loss: 2.0583394
MixupTrain:  epoch  0, batch   351 | loss: 2.0095639
MixupTrain:  epoch  0, batch   352 | loss: 2.0689979
MixupTrain:  epoch  0, batch   353 | loss: 2.0752397
MixupTrain:  epoch  0, batch   354 | loss: 2.0947878
MixupTrain:  epoch  0, batch   355 | loss: 2.1273623
MixupTrain:  epoch  0, batch   356 | loss: 2.0235639
MixupTrain:  epoch  0, batch   357 | loss: 2.0220520
MixupTrain:  epoch  0, batch   358 | loss: 2.0804591
MixupTrain:  epoch  0, batch   359 | loss: 2.1337500
MixupTrain:  epoch  0, batch   360 | loss: 2.0773511
MixupTrain:  epoch  0, batch   361 | loss: 2.1023412
MixupTrain:  epoch  0, batch   362 | loss: 2.1006746
MixupTrain:  epoch  0, batch   363 | loss: 2.0135264
MixupTrain:  epoch  0, batch   364 | loss: 2.1292853
MixupTrain:  epoch  0, batch   365 | loss: 2.1321278
MixupTrain:  epoch  0, batch   366 | loss: 2.1176481
MixupTrain:  epoch  0, batch   367 | loss: 2.1071982
MixupTrain:  epoch  0, batch   368 | loss: 2.1064301
MixupTrain:  epoch  0, batch   369 | loss: 2.0272214
MixupTrain:  epoch  0, batch   370 | loss: 2.0069366
MixupTrain:  epoch  0, batch   371 | loss: 2.0845916
MixupTrain:  epoch  0, batch   372 | loss: 2.0751710
MixupTrain:  epoch  0, batch   373 | loss: 2.1456397
MixupTrain:  epoch  0, batch   374 | loss: 2.1674967
MixupTrain:  epoch  0, batch   375 | loss: 2.0700636
MixupTrain:  epoch  0, batch   376 | loss: 2.1161270
MixupTrain:  epoch  0, batch   377 | loss: 2.0667005
MixupTrain:  epoch  0, batch   378 | loss: 2.0939157
MixupTrain:  epoch  0, batch   379 | loss: 2.0985508
MixupTrain:  epoch  0, batch   380 | loss: 1.9831619
MixupTrain:  epoch  0, batch   381 | loss: 2.0447459
MixupTrain:  epoch  0, batch   382 | loss: 2.0617905
MixupTrain:  epoch  0, batch   383 | loss: 1.9849951
MixupTrain:  epoch  0, batch   384 | loss: 2.0361316
MixupTrain:  epoch  0, batch   385 | loss: 2.0509593
MixupTrain:  epoch  0, batch   386 | loss: 2.0483608
MixupTrain:  epoch  0, batch   387 | loss: 2.0533381
MixupTrain:  epoch  0, batch   388 | loss: 2.0609660
MixupTrain:  epoch  0, batch   389 | loss: 2.0912247
MixupTrain:  epoch  0, batch   390 | loss: 1.9534943
MixupTrain:  epoch  0, batch   391 | loss: 1.9481025
MixupTrain:  epoch  0, batch   392 | loss: 2.0034652
MixupTrain:  epoch  0, batch   393 | loss: 1.9908018
MixupTrain:  epoch  0, batch   394 | loss: 2.0829163
MixupTrain:  epoch  0, batch   395 | loss: 2.0615628
MixupTrain:  epoch  0, batch   396 | loss: 2.0607371
MixupTrain:  epoch  0, batch   397 | loss: 2.1332397
MixupTrain:  epoch  0, batch   398 | loss: 2.0654199
MixupTrain:  epoch  0, batch   399 | loss: 1.9993725
MixupTrain:  epoch  0, batch   400 | loss: 2.0150537
MixupTrain:  epoch  0, batch   401 | loss: 2.0131118
MixupTrain:  epoch  0, batch   402 | loss: 2.0326092
MixupTrain:  epoch  0, batch   403 | loss: 2.1125231
MixupTrain:  epoch  0, batch   404 | loss: 2.1148088
MixupTrain:  epoch  0, batch   405 | loss: 2.0498714
MixupTrain:  epoch  0, batch   406 | loss: 2.0508578
MixupTrain:  epoch  0, batch   407 | loss: 2.1137524
MixupTrain:  epoch  0, batch   408 | loss: 2.0554743
MixupTrain:  epoch  0, batch   409 | loss: 2.0645142
MixupTrain:  epoch  0, batch   410 | loss: 1.9987706
MixupTrain:  epoch  0, batch   411 | loss: 2.1243367
MixupTrain:  epoch  0, batch   412 | loss: 1.9581074
MixupTrain:  epoch  0, batch   413 | loss: 2.0691850
MixupTrain:  epoch  0, batch   414 | loss: 2.1872988
MixupTrain:  epoch  0, batch   415 | loss: 2.0751419
MixupTrain:  epoch  0, batch   416 | loss: 2.0076127
MixupTrain:  epoch  0, batch   417 | loss: 2.0747085
MixupTrain:  epoch  0, batch   418 | loss: 2.0181663
MixupTrain:  epoch  0, batch   419 | loss: 2.0550904
MixupTrain:  epoch  0, batch   420 | loss: 2.0928874
MixupTrain:  epoch  0, batch   421 | loss: 2.0421181
MixupTrain:  epoch  0, batch   422 | loss: 1.9540007
MixupTrain:  epoch  0, batch   423 | loss: 2.0273654
MixupTrain:  epoch  0, batch   424 | loss: 2.0811887
MixupTrain:  epoch  0, batch   425 | loss: 2.1188354
MixupTrain:  epoch  0, batch   426 | loss: 1.9511833
MemoryTrain:  epoch  0, batch     0 | loss: 1.9545063
MemoryTrain:  epoch  0, batch     1 | loss: 3.0365560
MemoryTrain:  epoch  0, batch     2 | loss: 2.9801636
MemoryTrain:  epoch  0, batch     3 | loss: 2.6573663
MemoryTrain:  epoch  0, batch     4 | loss: 2.3698835
MemoryTrain:  epoch  0, batch     5 | loss: 2.4116917
MemoryTrain:  epoch  1, batch     0 | loss: 1.8386667
MemoryTrain:  epoch  1, batch     1 | loss: 1.8469446
MemoryTrain:  epoch  1, batch     2 | loss: 1.8504963
MemoryTrain:  epoch  1, batch     3 | loss: 1.9039587
MemoryTrain:  epoch  1, batch     4 | loss: 1.8818588
MemoryTrain:  epoch  1, batch     5 | loss: 1.8566451
MemoryTrain:  epoch  2, batch     0 | loss: 1.8405077
MemoryTrain:  epoch  2, batch     1 | loss: 1.8614671
MemoryTrain:  epoch  2, batch     2 | loss: 1.8454673
MemoryTrain:  epoch  2, batch     3 | loss: 1.8428307
MemoryTrain:  epoch  2, batch     4 | loss: 1.8728913
MemoryTrain:  epoch  2, batch     5 | loss: 1.8192087
MemoryTrain:  epoch  3, batch     0 | loss: 1.8226589
MemoryTrain:  epoch  3, batch     1 | loss: 1.8349572
MemoryTrain:  epoch  3, batch     2 | loss: 1.8841826
MemoryTrain:  epoch  3, batch     3 | loss: 1.8266606
MemoryTrain:  epoch  3, batch     4 | loss: 1.8678033
MemoryTrain:  epoch  3, batch     5 | loss: 1.8750592
MemoryTrain:  epoch  4, batch     0 | loss: 1.8724155
MemoryTrain:  epoch  4, batch     1 | loss: 1.8709655
MemoryTrain:  epoch  4, batch     2 | loss: 1.8640544
MemoryTrain:  epoch  4, batch     3 | loss: 1.8503717
MemoryTrain:  epoch  4, batch     4 | loss: 1.8443449
MemoryTrain:  epoch  4, batch     5 | loss: 1.8348771
MemoryTrain:  epoch  5, batch     0 | loss: 1.8361382
MemoryTrain:  epoch  5, batch     1 | loss: 1.8310823
MemoryTrain:  epoch  5, batch     2 | loss: 1.8522999
MemoryTrain:  epoch  5, batch     3 | loss: 1.8504591
MemoryTrain:  epoch  5, batch     4 | loss: 1.8436781
MemoryTrain:  epoch  5, batch     5 | loss: 1.8306134
MemoryTrain:  epoch  6, batch     0 | loss: 1.8424921
MemoryTrain:  epoch  6, batch     1 | loss: 1.8461666
MemoryTrain:  epoch  6, batch     2 | loss: 1.8558286
MemoryTrain:  epoch  6, batch     3 | loss: 1.8356731
MemoryTrain:  epoch  6, batch     4 | loss: 1.8251498
MemoryTrain:  epoch  6, batch     5 | loss: 1.8385379
MemoryTrain:  epoch  7, batch     0 | loss: 1.8343341
MemoryTrain:  epoch  7, batch     1 | loss: 1.8688335
MemoryTrain:  epoch  7, batch     2 | loss: 1.8437128
MemoryTrain:  epoch  7, batch     3 | loss: 1.8393431
MemoryTrain:  epoch  7, batch     4 | loss: 1.8242075
MemoryTrain:  epoch  7, batch     5 | loss: 1.8299119
MemoryTrain:  epoch  8, batch     0 | loss: 1.8335005
MemoryTrain:  epoch  8, batch     1 | loss: 1.8447242
MemoryTrain:  epoch  8, batch     2 | loss: 1.8280092
MemoryTrain:  epoch  8, batch     3 | loss: 1.8303605
MemoryTrain:  epoch  8, batch     4 | loss: 1.8318021
MemoryTrain:  epoch  8, batch     5 | loss: 1.8544649
MemoryTrain:  epoch  9, batch     0 | loss: 1.8591193
MemoryTrain:  epoch  9, batch     1 | loss: 1.8553777
MemoryTrain:  epoch  9, batch     2 | loss: 1.8301997
MemoryTrain:  epoch  9, batch     3 | loss: 1.8277819
MemoryTrain:  epoch  9, batch     4 | loss: 1.8443390
MemoryTrain:  epoch  9, batch     5 | loss: 1.8505882
[EVAL] batch:    0 | acc: 68.75%,  total acc: 68.75%   
[EVAL] batch:    1 | acc: 87.50%,  total acc: 78.12%   
[EVAL] batch:    2 | acc: 87.50%,  total acc: 81.25%   
[EVAL] batch:    3 | acc: 87.50%,  total acc: 82.81%   
[EVAL] batch:    4 | acc: 100.00%,  total acc: 86.25%   
[EVAL] batch:    5 | acc: 93.75%,  total acc: 87.50%   
[EVAL] batch:    6 | acc: 75.00%,  total acc: 85.71%   
[EVAL] batch:    7 | acc: 93.75%,  total acc: 86.72%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 88.19%   
[EVAL] batch:    9 | acc: 93.75%,  total acc: 88.75%   
[EVAL] batch:   10 | acc: 87.50%,  total acc: 88.64%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 89.06%   
[EVAL] batch:   12 | acc: 81.25%,  total acc: 88.46%   
[EVAL] batch:   13 | acc: 25.00%,  total acc: 83.93%   
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   
[EVAL] batch:    1 | acc: 62.50%,  total acc: 68.75%   
[EVAL] batch:    2 | acc: 62.50%,  total acc: 66.67%   
[EVAL] batch:    3 | acc: 56.25%,  total acc: 64.06%   
[EVAL] batch:    4 | acc: 75.00%,  total acc: 66.25%   
[EVAL] batch:    5 | acc: 68.75%,  total acc: 66.67%   
[EVAL] batch:    6 | acc: 93.75%,  total acc: 70.54%   
[EVAL] batch:    7 | acc: 87.50%,  total acc: 72.66%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 75.69%   
[EVAL] batch:    9 | acc: 100.00%,  total acc: 78.12%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 80.11%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 81.25%   
[EVAL] batch:   12 | acc: 87.50%,  total acc: 81.73%   
[EVAL] batch:   13 | acc: 62.50%,  total acc: 80.36%   
[EVAL] batch:   14 | acc: 68.75%,  total acc: 79.58%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 78.12%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 77.94%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 77.08%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 76.32%   
[EVAL] batch:   19 | acc: 75.00%,  total acc: 76.25%   
[EVAL] batch:   20 | acc: 93.75%,  total acc: 77.08%   
[EVAL] batch:   21 | acc: 93.75%,  total acc: 77.84%   
[EVAL] batch:   22 | acc: 81.25%,  total acc: 77.99%   
[EVAL] batch:   23 | acc: 93.75%,  total acc: 78.65%   
[EVAL] batch:   24 | acc: 93.75%,  total acc: 79.25%   
[EVAL] batch:   25 | acc: 87.50%,  total acc: 79.57%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 80.09%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 80.80%   
[EVAL] batch:   28 | acc: 93.75%,  total acc: 81.25%   
[EVAL] batch:   29 | acc: 75.00%,  total acc: 81.04%   
[EVAL] batch:   30 | acc: 75.00%,  total acc: 80.85%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 81.25%   
[EVAL] batch:   32 | acc: 87.50%,  total acc: 81.44%   
[EVAL] batch:   33 | acc: 62.50%,  total acc: 80.88%   
[EVAL] batch:   34 | acc: 81.25%,  total acc: 80.89%   
[EVAL] batch:   35 | acc: 43.75%,  total acc: 79.86%   
[EVAL] batch:   36 | acc: 81.25%,  total acc: 79.90%   
[EVAL] batch:   37 | acc: 81.25%,  total acc: 79.93%   
[EVAL] batch:   38 | acc: 62.50%,  total acc: 79.49%   
[EVAL] batch:   39 | acc: 93.75%,  total acc: 79.84%   
[EVAL] batch:   40 | acc: 62.50%,  total acc: 79.42%   
[EVAL] batch:   41 | acc: 100.00%,  total acc: 79.91%   
[EVAL] batch:   42 | acc: 31.25%,  total acc: 78.78%   
[EVAL] batch:   43 | acc: 6.25%,  total acc: 77.13%   
[EVAL] batch:   44 | acc: 0.00%,  total acc: 75.42%   
[EVAL] batch:   45 | acc: 0.00%,  total acc: 73.78%   
[EVAL] batch:   46 | acc: 18.75%,  total acc: 72.61%   
[EVAL] batch:   47 | acc: 56.25%,  total acc: 72.27%   
[EVAL] batch:   48 | acc: 100.00%,  total acc: 72.83%   
[EVAL] batch:   49 | acc: 87.50%,  total acc: 73.12%   
[EVAL] batch:   50 | acc: 87.50%,  total acc: 73.41%   
[EVAL] batch:   51 | acc: 100.00%,  total acc: 73.92%   
[EVAL] batch:   52 | acc: 93.75%,  total acc: 74.29%   
[EVAL] batch:   53 | acc: 75.00%,  total acc: 74.31%   
[EVAL] batch:   54 | acc: 93.75%,  total acc: 74.66%   
[EVAL] batch:   55 | acc: 100.00%,  total acc: 75.11%   
[EVAL] batch:   56 | acc: 93.75%,  total acc: 75.44%   
[EVAL] batch:   57 | acc: 81.25%,  total acc: 75.54%   
[EVAL] batch:   58 | acc: 100.00%,  total acc: 75.95%   
[EVAL] batch:   59 | acc: 68.75%,  total acc: 75.83%   
[EVAL] batch:   60 | acc: 18.75%,  total acc: 74.90%   
cur_acc:  ['0.8580', '0.8625', '0.8393']
his_acc:  ['0.8580', '0.8351', '0.7490']
CurrentTrain: epoch  0, batch     0 | loss: 5.4782858
CurrentTrain: epoch  0, batch     1 | loss: 5.4539075
CurrentTrain: epoch  1, batch     0 | loss: 4.6103992
CurrentTrain: epoch  1, batch     1 | loss: 3.8579912
CurrentTrain: epoch  2, batch     0 | loss: 3.5066288
CurrentTrain: epoch  2, batch     1 | loss: 2.5221281
CurrentTrain: epoch  3, batch     0 | loss: 2.8298635
CurrentTrain: epoch  3, batch     1 | loss: 2.2657673
CurrentTrain: epoch  4, batch     0 | loss: 2.3787699
CurrentTrain: epoch  4, batch     1 | loss: 2.6773140
CurrentTrain: epoch  5, batch     0 | loss: 2.2492766
CurrentTrain: epoch  5, batch     1 | loss: 2.0898621
CurrentTrain: epoch  6, batch     0 | loss: 2.0897970
CurrentTrain: epoch  6, batch     1 | loss: 2.1107731
CurrentTrain: epoch  7, batch     0 | loss: 1.9833289
CurrentTrain: epoch  7, batch     1 | loss: 1.9784733
CurrentTrain: epoch  8, batch     0 | loss: 2.0222611
CurrentTrain: epoch  8, batch     1 | loss: 2.0712214
CurrentTrain: epoch  9, batch     0 | loss: 1.9619943
CurrentTrain: epoch  9, batch     1 | loss: 1.8493201
#### person cities of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person cities of residence" means a person is living in a city.
Here is an example:
Relation: person cities of residence
Context: tv-idol-johns -- atlanta -- `` american idol '' finalist michael johns moved to los angeles several years ago , but his heart is still in atlanta .
Head Entity: his
Tail Entity: atlanta
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person cities of residence":
Relation: person cities of residence  
Context: after years of living in new york city, the famous author decided to return to her hometown of boston, where she feels most at home.  
Head Entity: she  
Tail Entity: boston  

Relation: person cities of residence  
Context: despite being a global superstar, the singer often reminisces about her childhood in nashville, where she first discovered her love for music.  
Head Entity: she  
Tail Entity: nashville  

Relation: person cities of residence  
Context: after completing his studies in san francisco, the tech entrepreneur moved back to his roots in seattle to start his new venture.  
Head Entity: he  
Tail Entity: seattle  

Relation: person cities of residence  
Context: the renowned chef, who gained fame in chicago, now runs a successful restaurant in miami, but he still considers chicago his true home.  
Head Entity: he  
Tail Entity: chicago  

Relation: person cities of residence  
Context: although she travels frequently for work, the actress always returns to her beloved los angeles, where she has lived for over a decade.  
Head Entity: she  
Tail Entity: los angeles  
#### person schools attended ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person schools attended" means a person 's school is an organization.
Here is an example:
Relation: person schools attended
Context: after world war ii , he attended the university of southern california , where he became editor of a college magazine .
Head Entity: he
Tail Entity: university of southern california
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person schools attended":
Relation: person schools attended  
Context: She graduated from Harvard University with a degree in psychology before pursuing her career in clinical research.  
Head Entity: She  
Tail Entity: Harvard University  

Relation: person schools attended  
Context: After completing his high school education, John enrolled at Stanford University to study computer science.  
Head Entity: John  
Tail Entity: Stanford University  

Relation: person schools attended  
Context: Maria attended the University of Oxford for her master's degree in literature, where she developed a passion for writing.  
Head Entity: Maria  
Tail Entity: University of Oxford  

Relation: person schools attended  
Context: Following his time in the military, David went to the Massachusetts Institute of Technology to study engineering.  
Head Entity: David  
Tail Entity: Massachusetts Institute of Technology  

Relation: person schools attended  
Context: Emily completed her undergraduate studies at the University of California, Berkeley, before moving on to a prestigious law school.  
Head Entity: Emily  
Tail Entity: University of California, Berkeley  
#### person country of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person country of death" means a person was died in a country.
Here is an example:
Relation: person country of death
Context: u.s. rep. parren mitchell , founding member of congressional black caucus , dies at 85
Head Entity: parren mitchell
Tail Entity: u.s.
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person country of death":
Relation: person country of death  
Context: renowned physicist stephen hawking passed away in cambridge, england at the age of 76  
Head Entity: stephen hawking  
Tail Entity: england  

Relation: person country of death  
Context: the famous author gabriel garcia marquez died in mexico city, mexico, leaving behind a legacy of magical realism  
Head Entity: gabriel garcia marquez  
Tail Entity: mexico  

Relation: person country of death  
Context: legendary musician freddie mercury succumbed to aids in london, united kingdom, at the age of 45  
Head Entity: freddie mercury  
Tail Entity: united kingdom  

Relation: person country of death  
Context: former south african president nelson mandela passed away peacefully in johannesburg, south africa  
Head Entity: nelson mandela  
Tail Entity: south africa  

Relation: person country of death  
Context: iconic actress audrey hepburn died in tolochenaz, switzerland, at the age of 63  
Head Entity: audrey hepburn  
Tail Entity: switzerland  
#### person children ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person children" means a person 's children is a person.
Here is an example:
Relation: person children
Context: he is survived by two stepdaughters , barbara a. hammond and brenda l. stevenson ; a stepson , michael a. taylor ; two grandchildren and one great-grandchild .
Head Entity: he
Tail Entity: brenda l. stevenson
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person children":
Relation: person children  
Context: she has three children, including her son, john, and her daughters, emily and sarah, who are both very talented.  
Head Entity: she  
Tail Entity: emily  

Relation: person children  
Context: after the divorce, he took custody of his two daughters, lily and rose, who are now thriving in school.  
Head Entity: he  
Tail Entity: rose  

Relation: person children  
Context: the famous actor is a proud father of four, with his youngest being a daughter named sophia.  
Head Entity: the famous actor  
Tail Entity: sophia  

Relation: person children  
Context: they often visit their grandparents, who love spending time with their grandchildren, including their grandson, max.  
Head Entity: they  
Tail Entity: max  

Relation: person children  
Context: she often shares stories about her two sons, alex and ben, who are both passionate about sports.  
Head Entity: she  
Tail Entity: ben  
#### person charges ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person charges" means a person was charged with an event.
Here is an example:
Relation: person charges
Context: ferrara said he was innocent of limoli 's slaying , but he pleaded guilty in 1992 to murder , along with racketeering charges , under a deal that sent him to prison for 22 years , rather than go to trial and risk a conviction that could lead to life in prison .
Head Entity: ferrara
Tail Entity: racketeering
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person charges":
Relation: person charges  
Context: After a lengthy investigation, the authorities announced that Johnson was charged with embezzlement, which shocked his colleagues at the firm.  
Head Entity: Johnson  
Tail Entity: embezzlement  

Relation: person charges  
Context: The district attorney confirmed that Smith was charged with assault following the altercation at the downtown bar last weekend.  
Head Entity: Smith  
Tail Entity: assault  

Relation: person charges  
Context: In a surprising turn of events, the police revealed that Martinez was charged with fraud after a series of complaints from local businesses.  
Head Entity: Martinez  
Tail Entity: fraud  

Relation: person charges  
Context: Following the incident, it was reported that Lee was charged with theft, leading to his immediate suspension from the university.  
Head Entity: Lee  
Tail Entity: theft  

Relation: person charges  
Context: The court documents indicated that Thompson was charged with drug possession, which could result in significant penalties if convicted.  
Head Entity: Thompson  
Tail Entity: drug possession  
Mixup data size:  10810
MixupTrain:  epoch  0, batch     0 | loss: 4.0146437
MixupTrain:  epoch  0, batch     1 | loss: 4.2075109
MixupTrain:  epoch  0, batch     2 | loss: 5.1296563
MixupTrain:  epoch  0, batch     3 | loss: 4.7763720
MixupTrain:  epoch  0, batch     4 | loss: 4.0956035
MixupTrain:  epoch  0, batch     5 | loss: 4.1059694
MixupTrain:  epoch  0, batch     6 | loss: 4.7451000
MixupTrain:  epoch  0, batch     7 | loss: 4.1555409
MixupTrain:  epoch  0, batch     8 | loss: 3.8133571
MixupTrain:  epoch  0, batch     9 | loss: 3.6945255
MixupTrain:  epoch  0, batch    10 | loss: 3.5659432
MixupTrain:  epoch  0, batch    11 | loss: 3.7428913
MixupTrain:  epoch  0, batch    12 | loss: 3.8860612
MixupTrain:  epoch  0, batch    13 | loss: 4.4798198
MixupTrain:  epoch  0, batch    14 | loss: 3.8089218
MixupTrain:  epoch  0, batch    15 | loss: 3.3985739
MixupTrain:  epoch  0, batch    16 | loss: 2.9315462
MixupTrain:  epoch  0, batch    17 | loss: 3.7744462
MixupTrain:  epoch  0, batch    18 | loss: 4.0291953
MixupTrain:  epoch  0, batch    19 | loss: 3.6065371
MixupTrain:  epoch  0, batch    20 | loss: 3.1298237
MixupTrain:  epoch  0, batch    21 | loss: 3.3990769
MixupTrain:  epoch  0, batch    22 | loss: 3.6639743
MixupTrain:  epoch  0, batch    23 | loss: 3.3757348
MixupTrain:  epoch  0, batch    24 | loss: 3.7511740
MixupTrain:  epoch  0, batch    25 | loss: 4.1147680
MixupTrain:  epoch  0, batch    26 | loss: 3.6149058
MixupTrain:  epoch  0, batch    27 | loss: 3.6215696
MixupTrain:  epoch  0, batch    28 | loss: 3.5859063
MixupTrain:  epoch  0, batch    29 | loss: 3.5140526
MixupTrain:  epoch  0, batch    30 | loss: 3.7454090
MixupTrain:  epoch  0, batch    31 | loss: 3.8962071
MixupTrain:  epoch  0, batch    32 | loss: 3.1367407
MixupTrain:  epoch  0, batch    33 | loss: 3.9605567
MixupTrain:  epoch  0, batch    34 | loss: 3.0579984
MixupTrain:  epoch  0, batch    35 | loss: 3.1381059
MixupTrain:  epoch  0, batch    36 | loss: 3.5417614
MixupTrain:  epoch  0, batch    37 | loss: 2.9030795
MixupTrain:  epoch  0, batch    38 | loss: 3.3681087
MixupTrain:  epoch  0, batch    39 | loss: 3.0896635
MixupTrain:  epoch  0, batch    40 | loss: 3.3838243
MixupTrain:  epoch  0, batch    41 | loss: 3.2569928
MixupTrain:  epoch  0, batch    42 | loss: 3.5263267
MixupTrain:  epoch  0, batch    43 | loss: 3.6150179
MixupTrain:  epoch  0, batch    44 | loss: 3.0923271
MixupTrain:  epoch  0, batch    45 | loss: 3.4202185
MixupTrain:  epoch  0, batch    46 | loss: 3.0060077
MixupTrain:  epoch  0, batch    47 | loss: 3.9247231
MixupTrain:  epoch  0, batch    48 | loss: 3.1732237
MixupTrain:  epoch  0, batch    49 | loss: 3.2792337
MixupTrain:  epoch  0, batch    50 | loss: 3.1908431
MixupTrain:  epoch  0, batch    51 | loss: 3.2967441
MixupTrain:  epoch  0, batch    52 | loss: 2.9163256
MixupTrain:  epoch  0, batch    53 | loss: 2.7766337
MixupTrain:  epoch  0, batch    54 | loss: 3.6029689
MixupTrain:  epoch  0, batch    55 | loss: 3.0999837
MixupTrain:  epoch  0, batch    56 | loss: 3.1518078
MixupTrain:  epoch  0, batch    57 | loss: 3.3746772
MixupTrain:  epoch  0, batch    58 | loss: 2.9029634
MixupTrain:  epoch  0, batch    59 | loss: 2.7261665
MixupTrain:  epoch  0, batch    60 | loss: 2.6315627
MixupTrain:  epoch  0, batch    61 | loss: 2.9539065
MixupTrain:  epoch  0, batch    62 | loss: 2.9011905
MixupTrain:  epoch  0, batch    63 | loss: 2.9352341
MixupTrain:  epoch  0, batch    64 | loss: 2.6844242
MixupTrain:  epoch  0, batch    65 | loss: 2.8245907
MixupTrain:  epoch  0, batch    66 | loss: 3.0942068
MixupTrain:  epoch  0, batch    67 | loss: 2.8548679
MixupTrain:  epoch  0, batch    68 | loss: 2.9497817
MixupTrain:  epoch  0, batch    69 | loss: 2.9475899
MixupTrain:  epoch  0, batch    70 | loss: 2.8392437
MixupTrain:  epoch  0, batch    71 | loss: 2.8340025
MixupTrain:  epoch  0, batch    72 | loss: 2.6326938
MixupTrain:  epoch  0, batch    73 | loss: 3.2592845
MixupTrain:  epoch  0, batch    74 | loss: 2.9145899
MixupTrain:  epoch  0, batch    75 | loss: 2.5478647
MixupTrain:  epoch  0, batch    76 | loss: 3.1211681
MixupTrain:  epoch  0, batch    77 | loss: 2.6770124
MixupTrain:  epoch  0, batch    78 | loss: 2.8286564
MixupTrain:  epoch  0, batch    79 | loss: 2.3311486
MixupTrain:  epoch  0, batch    80 | loss: 3.1349642
MixupTrain:  epoch  0, batch    81 | loss: 2.8645067
MixupTrain:  epoch  0, batch    82 | loss: 2.7762699
MixupTrain:  epoch  0, batch    83 | loss: 3.0430539
MixupTrain:  epoch  0, batch    84 | loss: 2.9394791
MixupTrain:  epoch  0, batch    85 | loss: 2.9463203
MixupTrain:  epoch  0, batch    86 | loss: 2.7671809
MixupTrain:  epoch  0, batch    87 | loss: 2.6209242
MixupTrain:  epoch  0, batch    88 | loss: 2.7816920
MixupTrain:  epoch  0, batch    89 | loss: 2.6626647
MixupTrain:  epoch  0, batch    90 | loss: 2.7498679
MixupTrain:  epoch  0, batch    91 | loss: 3.0159392
MixupTrain:  epoch  0, batch    92 | loss: 2.4190679
MixupTrain:  epoch  0, batch    93 | loss: 2.7560015
MixupTrain:  epoch  0, batch    94 | loss: 2.8562913
MixupTrain:  epoch  0, batch    95 | loss: 2.6322031
MixupTrain:  epoch  0, batch    96 | loss: 3.0702214
MixupTrain:  epoch  0, batch    97 | loss: 2.5384831
MixupTrain:  epoch  0, batch    98 | loss: 2.4989915
MixupTrain:  epoch  0, batch    99 | loss: 2.6823101
MixupTrain:  epoch  0, batch   100 | loss: 2.4736910
MixupTrain:  epoch  0, batch   101 | loss: 2.8487790
MixupTrain:  epoch  0, batch   102 | loss: 2.6142335
MixupTrain:  epoch  0, batch   103 | loss: 2.2270222
MixupTrain:  epoch  0, batch   104 | loss: 2.6015096
MixupTrain:  epoch  0, batch   105 | loss: 2.6900375
MixupTrain:  epoch  0, batch   106 | loss: 2.6712794
MixupTrain:  epoch  0, batch   107 | loss: 2.5657890
MixupTrain:  epoch  0, batch   108 | loss: 2.4569237
MixupTrain:  epoch  0, batch   109 | loss: 2.6143842
MixupTrain:  epoch  0, batch   110 | loss: 2.6603351
MixupTrain:  epoch  0, batch   111 | loss: 2.3980365
MixupTrain:  epoch  0, batch   112 | loss: 2.5814848
MixupTrain:  epoch  0, batch   113 | loss: 2.6102052
MixupTrain:  epoch  0, batch   114 | loss: 2.1408205
MixupTrain:  epoch  0, batch   115 | loss: 2.2745490
MixupTrain:  epoch  0, batch   116 | loss: 2.6674528
MixupTrain:  epoch  0, batch   117 | loss: 2.5490117
MixupTrain:  epoch  0, batch   118 | loss: 2.2479568
MixupTrain:  epoch  0, batch   119 | loss: 2.4906306
MixupTrain:  epoch  0, batch   120 | loss: 2.5436246
MixupTrain:  epoch  0, batch   121 | loss: 2.4936805
MixupTrain:  epoch  0, batch   122 | loss: 2.7115922
MixupTrain:  epoch  0, batch   123 | loss: 2.6595292
MixupTrain:  epoch  0, batch   124 | loss: 2.6729813
MixupTrain:  epoch  0, batch   125 | loss: 2.2651975
MixupTrain:  epoch  0, batch   126 | loss: 2.5840435
MixupTrain:  epoch  0, batch   127 | loss: 2.4085302
MixupTrain:  epoch  0, batch   128 | loss: 2.2060609
MixupTrain:  epoch  0, batch   129 | loss: 2.3934336
MixupTrain:  epoch  0, batch   130 | loss: 2.3954401
MixupTrain:  epoch  0, batch   131 | loss: 2.4653244
MixupTrain:  epoch  0, batch   132 | loss: 2.6070430
MixupTrain:  epoch  0, batch   133 | loss: 2.5868299
MixupTrain:  epoch  0, batch   134 | loss: 2.5067897
MixupTrain:  epoch  0, batch   135 | loss: 2.4812946
MixupTrain:  epoch  0, batch   136 | loss: 2.3537693
MixupTrain:  epoch  0, batch   137 | loss: 2.3714523
MixupTrain:  epoch  0, batch   138 | loss: 2.5738521
MixupTrain:  epoch  0, batch   139 | loss: 2.4825988
MixupTrain:  epoch  0, batch   140 | loss: 2.2744558
MixupTrain:  epoch  0, batch   141 | loss: 2.4683661
MixupTrain:  epoch  0, batch   142 | loss: 2.4466748
MixupTrain:  epoch  0, batch   143 | loss: 2.4371915
MixupTrain:  epoch  0, batch   144 | loss: 2.3094344
MixupTrain:  epoch  0, batch   145 | loss: 2.3707426
MixupTrain:  epoch  0, batch   146 | loss: 2.6054430
MixupTrain:  epoch  0, batch   147 | loss: 2.3601975
MixupTrain:  epoch  0, batch   148 | loss: 2.3885479
MixupTrain:  epoch  0, batch   149 | loss: 2.4159365
MixupTrain:  epoch  0, batch   150 | loss: 2.5686033
MixupTrain:  epoch  0, batch   151 | loss: 2.2908120
MixupTrain:  epoch  0, batch   152 | loss: 2.3670559
MixupTrain:  epoch  0, batch   153 | loss: 2.6004615
MixupTrain:  epoch  0, batch   154 | loss: 2.6115854
MixupTrain:  epoch  0, batch   155 | loss: 2.6443000
MixupTrain:  epoch  0, batch   156 | loss: 2.2750788
MixupTrain:  epoch  0, batch   157 | loss: 2.5274577
MixupTrain:  epoch  0, batch   158 | loss: 2.4778209
MixupTrain:  epoch  0, batch   159 | loss: 2.5858996
MixupTrain:  epoch  0, batch   160 | loss: 2.3472309
MixupTrain:  epoch  0, batch   161 | loss: 2.6158533
MixupTrain:  epoch  0, batch   162 | loss: 2.5033712
MixupTrain:  epoch  0, batch   163 | loss: 2.3859990
MixupTrain:  epoch  0, batch   164 | loss: 2.4417701
MixupTrain:  epoch  0, batch   165 | loss: 2.2271576
MixupTrain:  epoch  0, batch   166 | loss: 2.2915497
MixupTrain:  epoch  0, batch   167 | loss: 2.5776200
MixupTrain:  epoch  0, batch   168 | loss: 2.4141178
MixupTrain:  epoch  0, batch   169 | loss: 2.3361912
MixupTrain:  epoch  0, batch   170 | loss: 2.3873606
MixupTrain:  epoch  0, batch   171 | loss: 2.3742738
MixupTrain:  epoch  0, batch   172 | loss: 2.7252033
MixupTrain:  epoch  0, batch   173 | loss: 2.3683498
MixupTrain:  epoch  0, batch   174 | loss: 2.7128789
MixupTrain:  epoch  0, batch   175 | loss: 2.6339569
MixupTrain:  epoch  0, batch   176 | loss: 2.5632715
MixupTrain:  epoch  0, batch   177 | loss: 2.5009933
MixupTrain:  epoch  0, batch   178 | loss: 2.4480774
MixupTrain:  epoch  0, batch   179 | loss: 2.4324181
MixupTrain:  epoch  0, batch   180 | loss: 2.3337388
MixupTrain:  epoch  0, batch   181 | loss: 2.4462605
MixupTrain:  epoch  0, batch   182 | loss: 2.4663815
MixupTrain:  epoch  0, batch   183 | loss: 2.3823488
MixupTrain:  epoch  0, batch   184 | loss: 2.4600754
MixupTrain:  epoch  0, batch   185 | loss: 2.5465257
MixupTrain:  epoch  0, batch   186 | loss: 2.4341407
MixupTrain:  epoch  0, batch   187 | loss: 2.4101007
MixupTrain:  epoch  0, batch   188 | loss: 2.4477665
MixupTrain:  epoch  0, batch   189 | loss: 2.2891784
MixupTrain:  epoch  0, batch   190 | loss: 2.5173979
MixupTrain:  epoch  0, batch   191 | loss: 2.3707695
MixupTrain:  epoch  0, batch   192 | loss: 2.1937647
MixupTrain:  epoch  0, batch   193 | loss: 2.2269993
MixupTrain:  epoch  0, batch   194 | loss: 2.3986025
MixupTrain:  epoch  0, batch   195 | loss: 2.4236782
MixupTrain:  epoch  0, batch   196 | loss: 2.3026581
MixupTrain:  epoch  0, batch   197 | loss: 2.3954091
MixupTrain:  epoch  0, batch   198 | loss: 2.3071909
MixupTrain:  epoch  0, batch   199 | loss: 2.5301170
MixupTrain:  epoch  0, batch   200 | loss: 2.3437910
MixupTrain:  epoch  0, batch   201 | loss: 2.4816446
MixupTrain:  epoch  0, batch   202 | loss: 2.5541377
MixupTrain:  epoch  0, batch   203 | loss: 2.3954616
MixupTrain:  epoch  0, batch   204 | loss: 2.4408293
MixupTrain:  epoch  0, batch   205 | loss: 2.4111948
MixupTrain:  epoch  0, batch   206 | loss: 2.6525466
MixupTrain:  epoch  0, batch   207 | loss: 2.4179757
MixupTrain:  epoch  0, batch   208 | loss: 2.3102000
MixupTrain:  epoch  0, batch   209 | loss: 2.2729244
MixupTrain:  epoch  0, batch   210 | loss: 2.2061827
MixupTrain:  epoch  0, batch   211 | loss: 2.2404528
MixupTrain:  epoch  0, batch   212 | loss: 2.2952580
MixupTrain:  epoch  0, batch   213 | loss: 2.3452330
MixupTrain:  epoch  0, batch   214 | loss: 2.2871852
MixupTrain:  epoch  0, batch   215 | loss: 2.3742175
MixupTrain:  epoch  0, batch   216 | loss: 2.2814403
MixupTrain:  epoch  0, batch   217 | loss: 2.2535064
MixupTrain:  epoch  0, batch   218 | loss: 2.1104627
MixupTrain:  epoch  0, batch   219 | loss: 2.3627789
MixupTrain:  epoch  0, batch   220 | loss: 2.2280073
MixupTrain:  epoch  0, batch   221 | loss: 2.3026075
MixupTrain:  epoch  0, batch   222 | loss: 2.3395691
MixupTrain:  epoch  0, batch   223 | loss: 2.3113236
MixupTrain:  epoch  0, batch   224 | loss: 2.3530655
MixupTrain:  epoch  0, batch   225 | loss: 2.1313543
MixupTrain:  epoch  0, batch   226 | loss: 2.3168087
MixupTrain:  epoch  0, batch   227 | loss: 2.3581243
MixupTrain:  epoch  0, batch   228 | loss: 2.3039508
MixupTrain:  epoch  0, batch   229 | loss: 2.3740933
MixupTrain:  epoch  0, batch   230 | loss: 2.3427382
MixupTrain:  epoch  0, batch   231 | loss: 2.3935184
MixupTrain:  epoch  0, batch   232 | loss: 2.3133063
MixupTrain:  epoch  0, batch   233 | loss: 2.3123198
MixupTrain:  epoch  0, batch   234 | loss: 2.4744987
MixupTrain:  epoch  0, batch   235 | loss: 2.3564308
MixupTrain:  epoch  0, batch   236 | loss: 2.3201051
MixupTrain:  epoch  0, batch   237 | loss: 2.5132027
MixupTrain:  epoch  0, batch   238 | loss: 2.4418454
MixupTrain:  epoch  0, batch   239 | loss: 2.3239899
MixupTrain:  epoch  0, batch   240 | loss: 2.3781292
MixupTrain:  epoch  0, batch   241 | loss: 2.2460470
MixupTrain:  epoch  0, batch   242 | loss: 2.2142563
MixupTrain:  epoch  0, batch   243 | loss: 2.5709834
MixupTrain:  epoch  0, batch   244 | loss: 2.1205957
MixupTrain:  epoch  0, batch   245 | loss: 2.1345501
MixupTrain:  epoch  0, batch   246 | loss: 2.3560748
MixupTrain:  epoch  0, batch   247 | loss: 2.4859171
MixupTrain:  epoch  0, batch   248 | loss: 2.3407869
MixupTrain:  epoch  0, batch   249 | loss: 2.5574923
MixupTrain:  epoch  0, batch   250 | loss: 2.1198249
MixupTrain:  epoch  0, batch   251 | loss: 2.3467338
MixupTrain:  epoch  0, batch   252 | loss: 2.4455328
MixupTrain:  epoch  0, batch   253 | loss: 2.2537160
MixupTrain:  epoch  0, batch   254 | loss: 2.4426050
MixupTrain:  epoch  0, batch   255 | loss: 2.2081478
MixupTrain:  epoch  0, batch   256 | loss: 2.3230107
MixupTrain:  epoch  0, batch   257 | loss: 2.4230587
MixupTrain:  epoch  0, batch   258 | loss: 2.1774666
MixupTrain:  epoch  0, batch   259 | loss: 2.1661382
MixupTrain:  epoch  0, batch   260 | loss: 2.3712404
MixupTrain:  epoch  0, batch   261 | loss: 2.1808829
MixupTrain:  epoch  0, batch   262 | loss: 2.2613091
MixupTrain:  epoch  0, batch   263 | loss: 2.4624128
MixupTrain:  epoch  0, batch   264 | loss: 2.3131566
MixupTrain:  epoch  0, batch   265 | loss: 2.2349563
MixupTrain:  epoch  0, batch   266 | loss: 2.5692163
MixupTrain:  epoch  0, batch   267 | loss: 2.3447957
MixupTrain:  epoch  0, batch   268 | loss: 2.3779306
MixupTrain:  epoch  0, batch   269 | loss: 2.2328038
MixupTrain:  epoch  0, batch   270 | loss: 2.2877057
MixupTrain:  epoch  0, batch   271 | loss: 2.3753715
MixupTrain:  epoch  0, batch   272 | loss: 2.2995546
MixupTrain:  epoch  0, batch   273 | loss: 2.1893692
MixupTrain:  epoch  0, batch   274 | loss: 2.5462303
MixupTrain:  epoch  0, batch   275 | loss: 2.3454161
MixupTrain:  epoch  0, batch   276 | loss: 2.3401830
MixupTrain:  epoch  0, batch   277 | loss: 2.3396778
MixupTrain:  epoch  0, batch   278 | loss: 2.1575413
MixupTrain:  epoch  0, batch   279 | loss: 2.4562232
MixupTrain:  epoch  0, batch   280 | loss: 2.1686835
MixupTrain:  epoch  0, batch   281 | loss: 2.3321671
MixupTrain:  epoch  0, batch   282 | loss: 2.3963914
MixupTrain:  epoch  0, batch   283 | loss: 2.3805025
MixupTrain:  epoch  0, batch   284 | loss: 2.2614720
MixupTrain:  epoch  0, batch   285 | loss: 2.1854591
MixupTrain:  epoch  0, batch   286 | loss: 2.2865362
MixupTrain:  epoch  0, batch   287 | loss: 2.3963985
MixupTrain:  epoch  0, batch   288 | loss: 2.2874789
MixupTrain:  epoch  0, batch   289 | loss: 2.3697870
MixupTrain:  epoch  0, batch   290 | loss: 2.1842613
MixupTrain:  epoch  0, batch   291 | loss: 2.3593750
MixupTrain:  epoch  0, batch   292 | loss: 2.1502256
MixupTrain:  epoch  0, batch   293 | loss: 2.3975291
MixupTrain:  epoch  0, batch   294 | loss: 2.3213594
MixupTrain:  epoch  0, batch   295 | loss: 2.2895091
MixupTrain:  epoch  0, batch   296 | loss: 2.4073243
MixupTrain:  epoch  0, batch   297 | loss: 2.4703655
MixupTrain:  epoch  0, batch   298 | loss: 2.2416408
MixupTrain:  epoch  0, batch   299 | loss: 2.2720613
MixupTrain:  epoch  0, batch   300 | loss: 2.2320242
MixupTrain:  epoch  0, batch   301 | loss: 2.3087239
MixupTrain:  epoch  0, batch   302 | loss: 2.4341383
MixupTrain:  epoch  0, batch   303 | loss: 2.1948109
MixupTrain:  epoch  0, batch   304 | loss: 2.2509031
MixupTrain:  epoch  0, batch   305 | loss: 2.5132852
MixupTrain:  epoch  0, batch   306 | loss: 2.3675609
MixupTrain:  epoch  0, batch   307 | loss: 2.3687367
MixupTrain:  epoch  0, batch   308 | loss: 2.1819367
MixupTrain:  epoch  0, batch   309 | loss: 2.1679435
MixupTrain:  epoch  0, batch   310 | loss: 2.0814724
MixupTrain:  epoch  0, batch   311 | loss: 2.0381005
MixupTrain:  epoch  0, batch   312 | loss: 2.1760650
MixupTrain:  epoch  0, batch   313 | loss: 2.4146593
MixupTrain:  epoch  0, batch   314 | loss: 2.2865970
MixupTrain:  epoch  0, batch   315 | loss: 2.3639443
MixupTrain:  epoch  0, batch   316 | loss: 2.2420981
MixupTrain:  epoch  0, batch   317 | loss: 2.0626149
MixupTrain:  epoch  0, batch   318 | loss: 2.3485630
MixupTrain:  epoch  0, batch   319 | loss: 2.0857434
MixupTrain:  epoch  0, batch   320 | loss: 2.1375060
MixupTrain:  epoch  0, batch   321 | loss: 2.2140970
MixupTrain:  epoch  0, batch   322 | loss: 2.2707114
MixupTrain:  epoch  0, batch   323 | loss: 2.4627490
MixupTrain:  epoch  0, batch   324 | loss: 2.0694695
MixupTrain:  epoch  0, batch   325 | loss: 2.4562774
MixupTrain:  epoch  0, batch   326 | loss: 2.0800781
MixupTrain:  epoch  0, batch   327 | loss: 2.3223896
MixupTrain:  epoch  0, batch   328 | loss: 2.3039122
MixupTrain:  epoch  0, batch   329 | loss: 2.3348045
MixupTrain:  epoch  0, batch   330 | loss: 2.3964572
MixupTrain:  epoch  0, batch   331 | loss: 2.2762349
MixupTrain:  epoch  0, batch   332 | loss: 2.2834845
MixupTrain:  epoch  0, batch   333 | loss: 2.2081964
MixupTrain:  epoch  0, batch   334 | loss: 2.3123260
MixupTrain:  epoch  0, batch   335 | loss: 2.2730112
MixupTrain:  epoch  0, batch   336 | loss: 2.3329463
MixupTrain:  epoch  0, batch   337 | loss: 2.2012672
MixupTrain:  epoch  0, batch   338 | loss: 2.4255862
MixupTrain:  epoch  0, batch   339 | loss: 2.4280469
MixupTrain:  epoch  0, batch   340 | loss: 2.1771531
MixupTrain:  epoch  0, batch   341 | loss: 2.2350578
MixupTrain:  epoch  0, batch   342 | loss: 2.2952604
MixupTrain:  epoch  0, batch   343 | loss: 2.4350927
MixupTrain:  epoch  0, batch   344 | loss: 2.2559545
MixupTrain:  epoch  0, batch   345 | loss: 2.0530877
MixupTrain:  epoch  0, batch   346 | loss: 2.2927170
MixupTrain:  epoch  0, batch   347 | loss: 2.2230639
MixupTrain:  epoch  0, batch   348 | loss: 2.1804717
MixupTrain:  epoch  0, batch   349 | loss: 2.2191019
MixupTrain:  epoch  0, batch   350 | loss: 2.3755898
MixupTrain:  epoch  0, batch   351 | loss: 2.2564168
MixupTrain:  epoch  0, batch   352 | loss: 2.5150301
MixupTrain:  epoch  0, batch   353 | loss: 2.3980572
MixupTrain:  epoch  0, batch   354 | loss: 2.3084264
MixupTrain:  epoch  0, batch   355 | loss: 2.2769127
MixupTrain:  epoch  0, batch   356 | loss: 2.4997764
MixupTrain:  epoch  0, batch   357 | loss: 2.1920943
MixupTrain:  epoch  0, batch   358 | loss: 2.3537292
MixupTrain:  epoch  0, batch   359 | loss: 2.4025054
MixupTrain:  epoch  0, batch   360 | loss: 2.2959185
MixupTrain:  epoch  0, batch   361 | loss: 2.3897102
MixupTrain:  epoch  0, batch   362 | loss: 2.4300060
MixupTrain:  epoch  0, batch   363 | loss: 2.4468756
MixupTrain:  epoch  0, batch   364 | loss: 2.3825881
MixupTrain:  epoch  0, batch   365 | loss: 2.3083065
MixupTrain:  epoch  0, batch   366 | loss: 2.3140488
MixupTrain:  epoch  0, batch   367 | loss: 2.2871304
MixupTrain:  epoch  0, batch   368 | loss: 2.1965857
MixupTrain:  epoch  0, batch   369 | loss: 2.3448470
MixupTrain:  epoch  0, batch   370 | loss: 2.2668161
MixupTrain:  epoch  0, batch   371 | loss: 2.4139235
MixupTrain:  epoch  0, batch   372 | loss: 2.1502278
MixupTrain:  epoch  0, batch   373 | loss: 2.1125906
MixupTrain:  epoch  0, batch   374 | loss: 2.2064810
MixupTrain:  epoch  0, batch   375 | loss: 2.3066552
MixupTrain:  epoch  0, batch   376 | loss: 2.1636636
MixupTrain:  epoch  0, batch   377 | loss: 2.2654688
MixupTrain:  epoch  0, batch   378 | loss: 2.2418766
MixupTrain:  epoch  0, batch   379 | loss: 2.1369019
MixupTrain:  epoch  0, batch   380 | loss: 2.3122623
MixupTrain:  epoch  0, batch   381 | loss: 2.3277593
MixupTrain:  epoch  0, batch   382 | loss: 2.3313828
MixupTrain:  epoch  0, batch   383 | loss: 2.3726835
MixupTrain:  epoch  0, batch   384 | loss: 2.1328120
MixupTrain:  epoch  0, batch   385 | loss: 2.3946295
MixupTrain:  epoch  0, batch   386 | loss: 2.2489009
MixupTrain:  epoch  0, batch   387 | loss: 2.0695353
MixupTrain:  epoch  0, batch   388 | loss: 2.2969923
MixupTrain:  epoch  0, batch   389 | loss: 2.3768294
MixupTrain:  epoch  0, batch   390 | loss: 2.2442455
MixupTrain:  epoch  0, batch   391 | loss: 2.2897148
MixupTrain:  epoch  0, batch   392 | loss: 2.2965317
MixupTrain:  epoch  0, batch   393 | loss: 2.2844226
MixupTrain:  epoch  0, batch   394 | loss: 2.2820749
MixupTrain:  epoch  0, batch   395 | loss: 2.0169220
MixupTrain:  epoch  0, batch   396 | loss: 2.2861102
MixupTrain:  epoch  0, batch   397 | loss: 2.1879320
MixupTrain:  epoch  0, batch   398 | loss: 2.2339168
MixupTrain:  epoch  0, batch   399 | loss: 2.1979384
MixupTrain:  epoch  0, batch   400 | loss: 2.1877894
MixupTrain:  epoch  0, batch   401 | loss: 2.3393791
MixupTrain:  epoch  0, batch   402 | loss: 2.1422980
MixupTrain:  epoch  0, batch   403 | loss: 2.3677864
MixupTrain:  epoch  0, batch   404 | loss: 2.1941659
MixupTrain:  epoch  0, batch   405 | loss: 2.3162165
MixupTrain:  epoch  0, batch   406 | loss: 2.3452778
MixupTrain:  epoch  0, batch   407 | loss: 2.1536076
MixupTrain:  epoch  0, batch   408 | loss: 2.3967440
MixupTrain:  epoch  0, batch   409 | loss: 2.2356095
MixupTrain:  epoch  0, batch   410 | loss: 2.2932816
MixupTrain:  epoch  0, batch   411 | loss: 2.2935829
MixupTrain:  epoch  0, batch   412 | loss: 2.1297994
MixupTrain:  epoch  0, batch   413 | loss: 2.1675000
MixupTrain:  epoch  0, batch   414 | loss: 2.2239153
MixupTrain:  epoch  0, batch   415 | loss: 2.3179851
MixupTrain:  epoch  0, batch   416 | loss: 2.3669300
MixupTrain:  epoch  0, batch   417 | loss: 2.3247204
MixupTrain:  epoch  0, batch   418 | loss: 2.3396673
MixupTrain:  epoch  0, batch   419 | loss: 2.4617028
MixupTrain:  epoch  0, batch   420 | loss: 2.1704183
MixupTrain:  epoch  0, batch   421 | loss: 2.2439981
MixupTrain:  epoch  0, batch   422 | loss: 2.1552038
MixupTrain:  epoch  0, batch   423 | loss: 2.4871149
MixupTrain:  epoch  0, batch   424 | loss: 2.1593738
MixupTrain:  epoch  0, batch   425 | loss: 2.4168625
MixupTrain:  epoch  0, batch   426 | loss: 2.4413352
MixupTrain:  epoch  0, batch   427 | loss: 2.3346081
MixupTrain:  epoch  0, batch   428 | loss: 2.3120608
MixupTrain:  epoch  0, batch   429 | loss: 2.3428566
MixupTrain:  epoch  0, batch   430 | loss: 2.2128782
MixupTrain:  epoch  0, batch   431 | loss: 2.5566185
MixupTrain:  epoch  0, batch   432 | loss: 2.3011038
MixupTrain:  epoch  0, batch   433 | loss: 2.1710050
MixupTrain:  epoch  0, batch   434 | loss: 2.1357174
MixupTrain:  epoch  0, batch   435 | loss: 2.4252243
MixupTrain:  epoch  0, batch   436 | loss: 2.1391633
MixupTrain:  epoch  0, batch   437 | loss: 2.3305898
MixupTrain:  epoch  0, batch   438 | loss: 2.2622321
MixupTrain:  epoch  0, batch   439 | loss: 2.4003139
MixupTrain:  epoch  0, batch   440 | loss: 2.2293477
MixupTrain:  epoch  0, batch   441 | loss: 2.1954212
MixupTrain:  epoch  0, batch   442 | loss: 2.1380055
MixupTrain:  epoch  0, batch   443 | loss: 2.3530109
MixupTrain:  epoch  0, batch   444 | loss: 2.1674111
MixupTrain:  epoch  0, batch   445 | loss: 2.2166393
MixupTrain:  epoch  0, batch   446 | loss: 2.2478380
MixupTrain:  epoch  0, batch   447 | loss: 2.1595159
MixupTrain:  epoch  0, batch   448 | loss: 2.3177431
MixupTrain:  epoch  0, batch   449 | loss: 2.2752299
MixupTrain:  epoch  0, batch   450 | loss: 2.3883548
MixupTrain:  epoch  0, batch   451 | loss: 2.1697664
MixupTrain:  epoch  0, batch   452 | loss: 2.2871957
MixupTrain:  epoch  0, batch   453 | loss: 2.3516288
MixupTrain:  epoch  0, batch   454 | loss: 2.1975639
MixupTrain:  epoch  0, batch   455 | loss: 2.1775339
MixupTrain:  epoch  0, batch   456 | loss: 2.2460237
MixupTrain:  epoch  0, batch   457 | loss: 2.4452019
MixupTrain:  epoch  0, batch   458 | loss: 2.2818177
MixupTrain:  epoch  0, batch   459 | loss: 2.3474879
MixupTrain:  epoch  0, batch   460 | loss: 2.3418775
MixupTrain:  epoch  0, batch   461 | loss: 2.1815081
MixupTrain:  epoch  0, batch   462 | loss: 2.4132781
MixupTrain:  epoch  0, batch   463 | loss: 2.1958122
MixupTrain:  epoch  0, batch   464 | loss: 2.3725538
MixupTrain:  epoch  0, batch   465 | loss: 2.1536031
MixupTrain:  epoch  0, batch   466 | loss: 2.2033653
MixupTrain:  epoch  0, batch   467 | loss: 2.2793036
MixupTrain:  epoch  0, batch   468 | loss: 2.1411133
MixupTrain:  epoch  0, batch   469 | loss: 2.1502643
MixupTrain:  epoch  0, batch   470 | loss: 2.3449814
MixupTrain:  epoch  0, batch   471 | loss: 2.2120304
MixupTrain:  epoch  0, batch   472 | loss: 2.4419003
MixupTrain:  epoch  0, batch   473 | loss: 2.2623098
MixupTrain:  epoch  0, batch   474 | loss: 2.1587095
MixupTrain:  epoch  0, batch   475 | loss: 2.5656939
MixupTrain:  epoch  0, batch   476 | loss: 2.2769666
MixupTrain:  epoch  0, batch   477 | loss: 2.1046174
MixupTrain:  epoch  0, batch   478 | loss: 2.3975005
MixupTrain:  epoch  0, batch   479 | loss: 2.3235765
MixupTrain:  epoch  0, batch   480 | loss: 2.0522742
MixupTrain:  epoch  0, batch   481 | loss: 2.2592154
MixupTrain:  epoch  0, batch   482 | loss: 2.1755481
MixupTrain:  epoch  0, batch   483 | loss: 2.4781904
MixupTrain:  epoch  0, batch   484 | loss: 2.3608642
MixupTrain:  epoch  0, batch   485 | loss: 2.3060722
MixupTrain:  epoch  0, batch   486 | loss: 2.2759619
MixupTrain:  epoch  0, batch   487 | loss: 2.1896205
MixupTrain:  epoch  0, batch   488 | loss: 2.3520288
MixupTrain:  epoch  0, batch   489 | loss: 2.2755549
MixupTrain:  epoch  0, batch   490 | loss: 2.1652899
MixupTrain:  epoch  0, batch   491 | loss: 2.0452139
MixupTrain:  epoch  0, batch   492 | loss: 2.2212610
MixupTrain:  epoch  0, batch   493 | loss: 2.2468038
MixupTrain:  epoch  0, batch   494 | loss: 2.1530805
MixupTrain:  epoch  0, batch   495 | loss: 2.2382398
MixupTrain:  epoch  0, batch   496 | loss: 2.1783369
MixupTrain:  epoch  0, batch   497 | loss: 2.4317143
MixupTrain:  epoch  0, batch   498 | loss: 2.3877535
MixupTrain:  epoch  0, batch   499 | loss: 2.4118433
MixupTrain:  epoch  0, batch   500 | loss: 2.2263067
MixupTrain:  epoch  0, batch   501 | loss: 2.1832819
MixupTrain:  epoch  0, batch   502 | loss: 2.2818685
MixupTrain:  epoch  0, batch   503 | loss: 2.0902143
MixupTrain:  epoch  0, batch   504 | loss: 2.1356137
MixupTrain:  epoch  0, batch   505 | loss: 2.2509904
MixupTrain:  epoch  0, batch   506 | loss: 2.1154728
MixupTrain:  epoch  0, batch   507 | loss: 2.2791362
MixupTrain:  epoch  0, batch   508 | loss: 2.0980599
MixupTrain:  epoch  0, batch   509 | loss: 2.2702777
MixupTrain:  epoch  0, batch   510 | loss: 2.2230520
MixupTrain:  epoch  0, batch   511 | loss: 2.3324125
MixupTrain:  epoch  0, batch   512 | loss: 2.3539195
MixupTrain:  epoch  0, batch   513 | loss: 2.2583361
MixupTrain:  epoch  0, batch   514 | loss: 2.2346592
MixupTrain:  epoch  0, batch   515 | loss: 2.1591456
MixupTrain:  epoch  0, batch   516 | loss: 2.3722696
MixupTrain:  epoch  0, batch   517 | loss: 2.2183878
MixupTrain:  epoch  0, batch   518 | loss: 2.1744442
MixupTrain:  epoch  0, batch   519 | loss: 2.2984819
MixupTrain:  epoch  0, batch   520 | loss: 2.1729779
MixupTrain:  epoch  0, batch   521 | loss: 2.3119822
MixupTrain:  epoch  0, batch   522 | loss: 2.0939362
MixupTrain:  epoch  0, batch   523 | loss: 2.1592364
MixupTrain:  epoch  0, batch   524 | loss: 2.0542808
MixupTrain:  epoch  0, batch   525 | loss: 2.2492905
MixupTrain:  epoch  0, batch   526 | loss: 2.2745328
MixupTrain:  epoch  0, batch   527 | loss: 2.2810011
MixupTrain:  epoch  0, batch   528 | loss: 2.2771287
MixupTrain:  epoch  0, batch   529 | loss: 2.3341632
MixupTrain:  epoch  0, batch   530 | loss: 2.2841043
MixupTrain:  epoch  0, batch   531 | loss: 2.3978839
MixupTrain:  epoch  0, batch   532 | loss: 2.3250875
MixupTrain:  epoch  0, batch   533 | loss: 2.1512971
MixupTrain:  epoch  0, batch   534 | loss: 2.3411994
MixupTrain:  epoch  0, batch   535 | loss: 2.2602246
MixupTrain:  epoch  0, batch   536 | loss: 2.2658477
MixupTrain:  epoch  0, batch   537 | loss: 2.1817932
MixupTrain:  epoch  0, batch   538 | loss: 2.1390390
MixupTrain:  epoch  0, batch   539 | loss: 2.1655409
MixupTrain:  epoch  0, batch   540 | loss: 2.2914193
MixupTrain:  epoch  0, batch   541 | loss: 2.2769096
MixupTrain:  epoch  0, batch   542 | loss: 2.2762074
MixupTrain:  epoch  0, batch   543 | loss: 2.2901025
MixupTrain:  epoch  0, batch   544 | loss: 2.2247906
MixupTrain:  epoch  0, batch   545 | loss: 2.3677733
MixupTrain:  epoch  0, batch   546 | loss: 2.3283520
MixupTrain:  epoch  0, batch   547 | loss: 2.3349280
MixupTrain:  epoch  0, batch   548 | loss: 2.3411796
MixupTrain:  epoch  0, batch   549 | loss: 2.2678370
MixupTrain:  epoch  0, batch   550 | loss: 2.4646947
MixupTrain:  epoch  0, batch   551 | loss: 2.5037980
MixupTrain:  epoch  0, batch   552 | loss: 2.2382689
MixupTrain:  epoch  0, batch   553 | loss: 2.2193372
MixupTrain:  epoch  0, batch   554 | loss: 2.1939478
MixupTrain:  epoch  0, batch   555 | loss: 2.2768583
MixupTrain:  epoch  0, batch   556 | loss: 2.1857846
MixupTrain:  epoch  0, batch   557 | loss: 2.3004322
MixupTrain:  epoch  0, batch   558 | loss: 2.2097733
MixupTrain:  epoch  0, batch   559 | loss: 2.2981839
MixupTrain:  epoch  0, batch   560 | loss: 2.2784386
MixupTrain:  epoch  0, batch   561 | loss: 2.3593817
MixupTrain:  epoch  0, batch   562 | loss: 2.2083726
MixupTrain:  epoch  0, batch   563 | loss: 2.1175990
MixupTrain:  epoch  0, batch   564 | loss: 2.2150605
MixupTrain:  epoch  0, batch   565 | loss: 2.1785550
MixupTrain:  epoch  0, batch   566 | loss: 2.1718240
MixupTrain:  epoch  0, batch   567 | loss: 2.2232504
MixupTrain:  epoch  0, batch   568 | loss: 2.2335508
MixupTrain:  epoch  0, batch   569 | loss: 2.2726841
MixupTrain:  epoch  0, batch   570 | loss: 2.2023902
MixupTrain:  epoch  0, batch   571 | loss: 2.1676483
MixupTrain:  epoch  0, batch   572 | loss: 2.3918815
MixupTrain:  epoch  0, batch   573 | loss: 2.3779917
MixupTrain:  epoch  0, batch   574 | loss: 2.2511640
MixupTrain:  epoch  0, batch   575 | loss: 2.3067453
MixupTrain:  epoch  0, batch   576 | loss: 2.3202977
MixupTrain:  epoch  0, batch   577 | loss: 2.1995063
MixupTrain:  epoch  0, batch   578 | loss: 2.2533212
MixupTrain:  epoch  0, batch   579 | loss: 2.0768924
MixupTrain:  epoch  0, batch   580 | loss: 2.1421304
MixupTrain:  epoch  0, batch   581 | loss: 2.1974263
MixupTrain:  epoch  0, batch   582 | loss: 2.2589126
MixupTrain:  epoch  0, batch   583 | loss: 2.2442801
MixupTrain:  epoch  0, batch   584 | loss: 2.1493938
MixupTrain:  epoch  0, batch   585 | loss: 2.3344731
MixupTrain:  epoch  0, batch   586 | loss: 2.3780212
MixupTrain:  epoch  0, batch   587 | loss: 2.2893753
MixupTrain:  epoch  0, batch   588 | loss: 2.3078465
MixupTrain:  epoch  0, batch   589 | loss: 2.2956893
MixupTrain:  epoch  0, batch   590 | loss: 2.4610634
MixupTrain:  epoch  0, batch   591 | loss: 2.3389666
MixupTrain:  epoch  0, batch   592 | loss: 2.2667944
MixupTrain:  epoch  0, batch   593 | loss: 2.1271949
MixupTrain:  epoch  0, batch   594 | loss: 2.2068527
MixupTrain:  epoch  0, batch   595 | loss: 2.3049791
MixupTrain:  epoch  0, batch   596 | loss: 2.2312012
MixupTrain:  epoch  0, batch   597 | loss: 2.0978699
MixupTrain:  epoch  0, batch   598 | loss: 2.3195505
MixupTrain:  epoch  0, batch   599 | loss: 2.1787064
MixupTrain:  epoch  0, batch   600 | loss: 2.3346031
MixupTrain:  epoch  0, batch   601 | loss: 2.1313615
MixupTrain:  epoch  0, batch   602 | loss: 2.2974241
MixupTrain:  epoch  0, batch   603 | loss: 2.2371564
MixupTrain:  epoch  0, batch   604 | loss: 2.4354563
MixupTrain:  epoch  0, batch   605 | loss: 2.3810298
MixupTrain:  epoch  0, batch   606 | loss: 2.3609657
MixupTrain:  epoch  0, batch   607 | loss: 2.2704034
MixupTrain:  epoch  0, batch   608 | loss: 2.1971962
MixupTrain:  epoch  0, batch   609 | loss: 2.2185211
MixupTrain:  epoch  0, batch   610 | loss: 2.3462043
MixupTrain:  epoch  0, batch   611 | loss: 2.1356268
MixupTrain:  epoch  0, batch   612 | loss: 2.4236825
MixupTrain:  epoch  0, batch   613 | loss: 2.2146289
MixupTrain:  epoch  0, batch   614 | loss: 2.0686646
MixupTrain:  epoch  0, batch   615 | loss: 2.0904124
MixupTrain:  epoch  0, batch   616 | loss: 2.2598977
MixupTrain:  epoch  0, batch   617 | loss: 2.2248526
MixupTrain:  epoch  0, batch   618 | loss: 2.1486764
MixupTrain:  epoch  0, batch   619 | loss: 2.1479783
MixupTrain:  epoch  0, batch   620 | loss: 2.3840184
MixupTrain:  epoch  0, batch   621 | loss: 2.1628451
MixupTrain:  epoch  0, batch   622 | loss: 2.2524657
MixupTrain:  epoch  0, batch   623 | loss: 2.3050368
MixupTrain:  epoch  0, batch   624 | loss: 2.4381227
MixupTrain:  epoch  0, batch   625 | loss: 2.3657355
MixupTrain:  epoch  0, batch   626 | loss: 2.0261657
MixupTrain:  epoch  0, batch   627 | loss: 2.3552811
MixupTrain:  epoch  0, batch   628 | loss: 2.1905017
MixupTrain:  epoch  0, batch   629 | loss: 2.4387407
MixupTrain:  epoch  0, batch   630 | loss: 2.4229407
MixupTrain:  epoch  0, batch   631 | loss: 2.2842994
MixupTrain:  epoch  0, batch   632 | loss: 2.2340484
MixupTrain:  epoch  0, batch   633 | loss: 2.3110135
MixupTrain:  epoch  0, batch   634 | loss: 2.3010886
MixupTrain:  epoch  0, batch   635 | loss: 2.3311563
MixupTrain:  epoch  0, batch   636 | loss: 2.3602183
MixupTrain:  epoch  0, batch   637 | loss: 2.2275743
MixupTrain:  epoch  0, batch   638 | loss: 2.1799097
MixupTrain:  epoch  0, batch   639 | loss: 2.2859080
MixupTrain:  epoch  0, batch   640 | loss: 2.2696295
MixupTrain:  epoch  0, batch   641 | loss: 2.2161117
MixupTrain:  epoch  0, batch   642 | loss: 2.1631405
MixupTrain:  epoch  0, batch   643 | loss: 2.0970011
MixupTrain:  epoch  0, batch   644 | loss: 2.0746160
MixupTrain:  epoch  0, batch   645 | loss: 2.1970136
MixupTrain:  epoch  0, batch   646 | loss: 2.1262660
MixupTrain:  epoch  0, batch   647 | loss: 2.2074752
MixupTrain:  epoch  0, batch   648 | loss: 2.4667292
MixupTrain:  epoch  0, batch   649 | loss: 2.4942222
MixupTrain:  epoch  0, batch   650 | loss: 2.1627924
MixupTrain:  epoch  0, batch   651 | loss: 2.4171300
MixupTrain:  epoch  0, batch   652 | loss: 2.2725182
MixupTrain:  epoch  0, batch   653 | loss: 2.3330884
MixupTrain:  epoch  0, batch   654 | loss: 2.3198543
MixupTrain:  epoch  0, batch   655 | loss: 2.2931595
MixupTrain:  epoch  0, batch   656 | loss: 2.1800280
MixupTrain:  epoch  0, batch   657 | loss: 2.1297460
MixupTrain:  epoch  0, batch   658 | loss: 2.3551040
MixupTrain:  epoch  0, batch   659 | loss: 2.2735980
MixupTrain:  epoch  0, batch   660 | loss: 2.4239402
MixupTrain:  epoch  0, batch   661 | loss: 2.3563182
MixupTrain:  epoch  0, batch   662 | loss: 2.2705035
MixupTrain:  epoch  0, batch   663 | loss: 2.3093395
MixupTrain:  epoch  0, batch   664 | loss: 2.2543259
MixupTrain:  epoch  0, batch   665 | loss: 2.1438498
MixupTrain:  epoch  0, batch   666 | loss: 2.3814745
MixupTrain:  epoch  0, batch   667 | loss: 2.1954803
MixupTrain:  epoch  0, batch   668 | loss: 2.3875144
MixupTrain:  epoch  0, batch   669 | loss: 2.2138782
MixupTrain:  epoch  0, batch   670 | loss: 2.4847836
MixupTrain:  epoch  0, batch   671 | loss: 2.2123842
MixupTrain:  epoch  0, batch   672 | loss: 2.3339310
MixupTrain:  epoch  0, batch   673 | loss: 2.1598983
MixupTrain:  epoch  0, batch   674 | loss: 2.3032551
MixupTrain:  epoch  0, batch   675 | loss: 2.4677474
MemoryTrain:  epoch  0, batch     0 | loss: 2.0800087
MemoryTrain:  epoch  0, batch     1 | loss: 2.2564304
MemoryTrain:  epoch  0, batch     2 | loss: 2.4787569
MemoryTrain:  epoch  0, batch     3 | loss: 2.7893434
MemoryTrain:  epoch  0, batch     4 | loss: 3.1110632
MemoryTrain:  epoch  0, batch     5 | loss: 2.3768110
MemoryTrain:  epoch  0, batch     6 | loss: 3.0648332
MemoryTrain:  epoch  0, batch     7 | loss: 2.0295894
MemoryTrain:  epoch  1, batch     0 | loss: 1.8416986
MemoryTrain:  epoch  1, batch     1 | loss: 1.8549259
MemoryTrain:  epoch  1, batch     2 | loss: 1.8570080
MemoryTrain:  epoch  1, batch     3 | loss: 1.8562773
MemoryTrain:  epoch  1, batch     4 | loss: 1.8476175
MemoryTrain:  epoch  1, batch     5 | loss: 1.8835454
MemoryTrain:  epoch  1, batch     6 | loss: 1.8487980
MemoryTrain:  epoch  1, batch     7 | loss: 1.8413259
MemoryTrain:  epoch  2, batch     0 | loss: 1.8296877
MemoryTrain:  epoch  2, batch     1 | loss: 1.8447715
MemoryTrain:  epoch  2, batch     2 | loss: 1.8262205
MemoryTrain:  epoch  2, batch     3 | loss: 1.8295159
MemoryTrain:  epoch  2, batch     4 | loss: 1.8389014
MemoryTrain:  epoch  2, batch     5 | loss: 1.8395255
MemoryTrain:  epoch  2, batch     6 | loss: 1.8520060
MemoryTrain:  epoch  2, batch     7 | loss: 1.8241467
MemoryTrain:  epoch  3, batch     0 | loss: 1.8372862
MemoryTrain:  epoch  3, batch     1 | loss: 1.8342037
MemoryTrain:  epoch  3, batch     2 | loss: 1.8215896
MemoryTrain:  epoch  3, batch     3 | loss: 1.8665719
MemoryTrain:  epoch  3, batch     4 | loss: 1.8531367
MemoryTrain:  epoch  3, batch     5 | loss: 1.8442175
MemoryTrain:  epoch  3, batch     6 | loss: 1.8675953
MemoryTrain:  epoch  3, batch     7 | loss: 1.8313142
MemoryTrain:  epoch  4, batch     0 | loss: 1.8301188
MemoryTrain:  epoch  4, batch     1 | loss: 1.8464255
MemoryTrain:  epoch  4, batch     2 | loss: 1.8565065
MemoryTrain:  epoch  4, batch     3 | loss: 1.8789642
MemoryTrain:  epoch  4, batch     4 | loss: 1.8176289
MemoryTrain:  epoch  4, batch     5 | loss: 1.8264122
MemoryTrain:  epoch  4, batch     6 | loss: 1.8320529
MemoryTrain:  epoch  4, batch     7 | loss: 1.8183627
MemoryTrain:  epoch  5, batch     0 | loss: 1.8181610
MemoryTrain:  epoch  5, batch     1 | loss: 1.8280581
MemoryTrain:  epoch  5, batch     2 | loss: 1.8305675
MemoryTrain:  epoch  5, batch     3 | loss: 1.8233535
MemoryTrain:  epoch  5, batch     4 | loss: 1.8207747
MemoryTrain:  epoch  5, batch     5 | loss: 1.8354070
MemoryTrain:  epoch  5, batch     6 | loss: 1.8695985
MemoryTrain:  epoch  5, batch     7 | loss: 1.8381612
MemoryTrain:  epoch  6, batch     0 | loss: 1.8323832
MemoryTrain:  epoch  6, batch     1 | loss: 1.8249084
MemoryTrain:  epoch  6, batch     2 | loss: 1.8275671
MemoryTrain:  epoch  6, batch     3 | loss: 1.8234783
MemoryTrain:  epoch  6, batch     4 | loss: 1.8264037
MemoryTrain:  epoch  6, batch     5 | loss: 1.8323865
MemoryTrain:  epoch  6, batch     6 | loss: 1.8220071
MemoryTrain:  epoch  6, batch     7 | loss: 1.8270906
MemoryTrain:  epoch  7, batch     0 | loss: 1.8260008
MemoryTrain:  epoch  7, batch     1 | loss: 1.8198938
MemoryTrain:  epoch  7, batch     2 | loss: 1.8534588
MemoryTrain:  epoch  7, batch     3 | loss: 1.8389325
MemoryTrain:  epoch  7, batch     4 | loss: 1.8169930
MemoryTrain:  epoch  7, batch     5 | loss: 1.8224823
MemoryTrain:  epoch  7, batch     6 | loss: 1.8276962
MemoryTrain:  epoch  7, batch     7 | loss: 1.8371435
MemoryTrain:  epoch  8, batch     0 | loss: 1.8189329
MemoryTrain:  epoch  8, batch     1 | loss: 1.8324425
MemoryTrain:  epoch  8, batch     2 | loss: 1.8282855
MemoryTrain:  epoch  8, batch     3 | loss: 1.8403683
MemoryTrain:  epoch  8, batch     4 | loss: 1.8333411
MemoryTrain:  epoch  8, batch     5 | loss: 1.8212669
MemoryTrain:  epoch  8, batch     6 | loss: 1.8165190
MemoryTrain:  epoch  8, batch     7 | loss: 1.8157898
MemoryTrain:  epoch  9, batch     0 | loss: 1.8288182
MemoryTrain:  epoch  9, batch     1 | loss: 1.8316025
MemoryTrain:  epoch  9, batch     2 | loss: 1.8150284
MemoryTrain:  epoch  9, batch     3 | loss: 1.8314693
MemoryTrain:  epoch  9, batch     4 | loss: 1.8186450
MemoryTrain:  epoch  9, batch     5 | loss: 1.8181431
MemoryTrain:  epoch  9, batch     6 | loss: 1.8279655
MemoryTrain:  epoch  9, batch     7 | loss: 1.8188407
[EVAL] batch:    0 | acc: 100.00%,  total acc: 100.00%   
[EVAL] batch:    1 | acc: 93.75%,  total acc: 96.88%   
[EVAL] batch:    2 | acc: 87.50%,  total acc: 93.75%   
[EVAL] batch:    3 | acc: 100.00%,  total acc: 95.31%   
[EVAL] batch:    4 | acc: 93.75%,  total acc: 95.00%   
[EVAL] batch:    5 | acc: 87.50%,  total acc: 93.75%   
[EVAL] batch:    6 | acc: 87.50%,  total acc: 92.86%   
[EVAL] batch:    7 | acc: 75.00%,  total acc: 90.62%   
[EVAL] batch:    8 | acc: 75.00%,  total acc: 88.89%   
[EVAL] batch:    9 | acc: 100.00%,  total acc: 90.00%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 90.91%   
[EVAL] batch:   11 | acc: 100.00%,  total acc: 91.67%   
[EVAL] batch:   12 | acc: 100.00%,  total acc: 92.31%   
[EVAL] batch:   13 | acc: 100.00%,  total acc: 92.86%   
[EVAL] batch:   14 | acc: 100.00%,  total acc: 93.33%   
[EVAL] batch:   15 | acc: 100.00%,  total acc: 93.75%   
[EVAL] batch:   16 | acc: 100.00%,  total acc: 94.12%   
[EVAL] batch:   17 | acc: 18.75%,  total acc: 89.93%   
[EVAL] batch:    0 | acc: 25.00%,  total acc: 25.00%   
[EVAL] batch:    1 | acc: 50.00%,  total acc: 37.50%   
[EVAL] batch:    2 | acc: 31.25%,  total acc: 35.42%   
[EVAL] batch:    3 | acc: 31.25%,  total acc: 34.38%   
[EVAL] batch:    4 | acc: 6.25%,  total acc: 28.75%   
[EVAL] batch:    5 | acc: 31.25%,  total acc: 29.17%   
[EVAL] batch:    6 | acc: 87.50%,  total acc: 37.50%   
[EVAL] batch:    7 | acc: 87.50%,  total acc: 43.75%   
[EVAL] batch:    8 | acc: 93.75%,  total acc: 49.31%   
[EVAL] batch:    9 | acc: 81.25%,  total acc: 52.50%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 56.82%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 59.90%   
[EVAL] batch:   12 | acc: 87.50%,  total acc: 62.02%   
[EVAL] batch:   13 | acc: 62.50%,  total acc: 62.05%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 62.92%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 62.50%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 63.24%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 63.19%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 63.16%   
[EVAL] batch:   19 | acc: 75.00%,  total acc: 63.75%   
[EVAL] batch:   20 | acc: 93.75%,  total acc: 65.18%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 66.76%   
[EVAL] batch:   22 | acc: 93.75%,  total acc: 67.93%   
[EVAL] batch:   23 | acc: 93.75%,  total acc: 69.01%   
[EVAL] batch:   24 | acc: 93.75%,  total acc: 70.00%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 71.15%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 71.99%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 72.99%   
[EVAL] batch:   28 | acc: 93.75%,  total acc: 73.71%   
[EVAL] batch:   29 | acc: 75.00%,  total acc: 73.75%   
[EVAL] batch:   30 | acc: 87.50%,  total acc: 74.19%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 74.80%   
[EVAL] batch:   32 | acc: 50.00%,  total acc: 74.05%   
[EVAL] batch:   33 | acc: 6.25%,  total acc: 72.06%   
[EVAL] batch:   34 | acc: 6.25%,  total acc: 70.18%   
[EVAL] batch:   35 | acc: 12.50%,  total acc: 68.58%   
[EVAL] batch:   36 | acc: 12.50%,  total acc: 67.06%   
[EVAL] batch:   37 | acc: 56.25%,  total acc: 66.78%   
[EVAL] batch:   38 | acc: 75.00%,  total acc: 66.99%   
[EVAL] batch:   39 | acc: 100.00%,  total acc: 67.81%   
[EVAL] batch:   40 | acc: 62.50%,  total acc: 67.68%   
[EVAL] batch:   41 | acc: 100.00%,  total acc: 68.45%   
[EVAL] batch:   42 | acc: 0.00%,  total acc: 66.86%   
[EVAL] batch:   43 | acc: 6.25%,  total acc: 65.48%   
[EVAL] batch:   44 | acc: 0.00%,  total acc: 64.03%   
[EVAL] batch:   45 | acc: 0.00%,  total acc: 62.64%   
[EVAL] batch:   46 | acc: 12.50%,  total acc: 61.57%   
[EVAL] batch:   47 | acc: 43.75%,  total acc: 61.20%   
[EVAL] batch:   48 | acc: 6.25%,  total acc: 60.08%   
[EVAL] batch:   49 | acc: 0.00%,  total acc: 58.88%   
[EVAL] batch:   50 | acc: 0.00%,  total acc: 57.72%   
[EVAL] batch:   51 | acc: 18.75%,  total acc: 56.97%   
[EVAL] batch:   52 | acc: 0.00%,  total acc: 55.90%   
[EVAL] batch:   53 | acc: 37.50%,  total acc: 55.56%   
[EVAL] batch:   54 | acc: 93.75%,  total acc: 56.25%   
[EVAL] batch:   55 | acc: 87.50%,  total acc: 56.81%   
[EVAL] batch:   56 | acc: 81.25%,  total acc: 57.24%   
[EVAL] batch:   57 | acc: 75.00%,  total acc: 57.54%   
[EVAL] batch:   58 | acc: 81.25%,  total acc: 57.94%   
[EVAL] batch:   59 | acc: 62.50%,  total acc: 58.02%   
[EVAL] batch:   60 | acc: 50.00%,  total acc: 57.89%   
[EVAL] batch:   61 | acc: 93.75%,  total acc: 58.47%   
[EVAL] batch:   62 | acc: 93.75%,  total acc: 59.03%   
[EVAL] batch:   63 | acc: 93.75%,  total acc: 59.57%   
[EVAL] batch:   64 | acc: 93.75%,  total acc: 60.10%   
[EVAL] batch:   65 | acc: 93.75%,  total acc: 60.61%   
[EVAL] batch:   66 | acc: 87.50%,  total acc: 61.01%   
[EVAL] batch:   67 | acc: 87.50%,  total acc: 61.40%   
[EVAL] batch:   68 | acc: 75.00%,  total acc: 61.59%   
[EVAL] batch:   69 | acc: 81.25%,  total acc: 61.88%   
[EVAL] batch:   70 | acc: 100.00%,  total acc: 62.41%   
[EVAL] batch:   71 | acc: 100.00%,  total acc: 62.93%   
[EVAL] batch:   72 | acc: 100.00%,  total acc: 63.44%   
[EVAL] batch:   73 | acc: 100.00%,  total acc: 63.94%   
[EVAL] batch:   74 | acc: 100.00%,  total acc: 64.42%   
[EVAL] batch:   75 | acc: 100.00%,  total acc: 64.88%   
[EVAL] batch:   76 | acc: 100.00%,  total acc: 65.34%   
[EVAL] batch:   77 | acc: 68.75%,  total acc: 65.38%   
cur_acc:  ['0.8580', '0.8625', '0.8393', '0.8993']
his_acc:  ['0.8580', '0.8351', '0.7490', '0.6538']
CurrentTrain: epoch  0, batch     0 | loss: 8.8142586
CurrentTrain: epoch  0, batch     1 | loss: 8.4490204
CurrentTrain: epoch  1, batch     0 | loss: 8.0130968
CurrentTrain: epoch  1, batch     1 | loss: 7.3509216
CurrentTrain: epoch  2, batch     0 | loss: 6.6104927
CurrentTrain: epoch  2, batch     1 | loss: 7.4223623
CurrentTrain: epoch  3, batch     0 | loss: 6.9008822
CurrentTrain: epoch  3, batch     1 | loss: 5.8036799
CurrentTrain: epoch  4, batch     0 | loss: 6.6833134
CurrentTrain: epoch  4, batch     1 | loss: 5.0153489
CurrentTrain: epoch  5, batch     0 | loss: 5.6906147
CurrentTrain: epoch  5, batch     1 | loss: 5.6171970
CurrentTrain: epoch  6, batch     0 | loss: 5.8147936
CurrentTrain: epoch  6, batch     1 | loss: 5.9191709
CurrentTrain: epoch  7, batch     0 | loss: 4.9115992
CurrentTrain: epoch  7, batch     1 | loss: 5.5962434
CurrentTrain: epoch  8, batch     0 | loss: 4.5147076
CurrentTrain: epoch  8, batch     1 | loss: 4.6340485
CurrentTrain: epoch  9, batch     0 | loss: 4.8212428
CurrentTrain: epoch  9, batch     1 | loss: 3.6676805
#### organization subsidiaries ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization subsidiaries" means an organization 's subsidiary is an organization.
Here is an example:
Relation: organization subsidiaries
Context: `` firstgroup 's acquisition of laidlaw will considerably enhance firstgroup 's existing activities in north america , which themselves have grown strongly since we first invested in the u.s. in 1999 , '' said firstgroup chief executive moir lockhead .
Head Entity: firstgroup
Tail Entity: laidlaw
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization subsidiaries":
Relation: organization subsidiaries  
Context: `` in 2018, the tech giant google announced its acquisition of nest labs, a company specializing in smart home products, which has allowed google to expand its reach in the home automation market. ''  
Head Entity: google  
Tail Entity: nest labs  

Relation: organization subsidiaries  
Context: `` the merger between disney and pixar in 2006 created a powerhouse in animated films, allowing disney to leverage pixar's innovative technology and storytelling expertise. ''  
Head Entity: disney  
Tail Entity: pixar  

Relation: organization subsidiaries  
Context: `` after acquiring the popular video game company, activision blizzard, microsoft significantly bolstered its gaming portfolio and strengthened its position in the industry. ''  
Head Entity: microsoft  
Tail Entity: activision blizzard  

Relation: organization subsidiaries  
Context: `` the recent purchase of whole foods by amazon has transformed the grocery shopping experience, integrating online and offline retail in a unique way. ''  
Head Entity: amazon  
Tail Entity: whole foods  

Relation: organization subsidiaries  
Context: `` in a strategic move to enhance its product offerings, facebook acquired instagram, allowing it to tap into the growing trend of photo-sharing among users. ''  
Head Entity: facebook  
Tail Entity: instagram  
#### organization parents ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization parents" means an organization 's parent is an organization.
Here is an example:
Relation: organization parents
Context: in addition his ability to communicate with people has been recognized by his winning of the robert e. knox master teacher award and by his service on the american psychological association 's , public information committee .
Head Entity: american psychological association
Tail Entity: public information committee
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization parents":
Relation: organization parents  
Context: The merger between the two companies was finalized, leading to the formation of a new entity that would oversee the operations of both organizations.  
Head Entity: Company A  
Tail Entity: Company B  

Relation: organization parents  
Context: The foundation was established to support various initiatives, but it operates under the larger umbrella of the global charity organization.  
Head Entity: global charity organization  
Tail Entity: foundation  

Relation: organization parents  
Context: After years of collaboration, the tech startup was acquired by a major corporation, which now serves as its parent company.  
Head Entity: major corporation  
Tail Entity: tech startup  

Relation: organization parents  
Context: The university is part of a larger educational system that includes several colleges and research institutes across the country.  
Head Entity: educational system  
Tail Entity: university  

Relation: organization parents  
Context: The nonprofit organization was created to address local issues, but it is funded and supported by a larger national organization.  
Head Entity: national organization  
Tail Entity: nonprofit organization  
#### organization alternate names ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization alternate names" means a person 's alias is a person.
Here is an example:
Relation: organization alternate names
Context: the talks between graham and pak ui-chun were held in a `` friendly '' manner , the official korean central news agency -lrb- kcna -rrb- said , without giving details .
Head Entity: kcna
Tail Entity: korean central news agency
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization alternate names":
Relation: organization alternate names  
Context: The International Monetary Fund, often referred to as the IMF, plays a crucial role in global economic stability.  
Head Entity: IMF  
Tail Entity: International Monetary Fund  

Relation: organization alternate names  
Context: The World Health Organization, commonly known as WHO, has been at the forefront of the global health response.  
Head Entity: WHO  
Tail Entity: World Health Organization  

Relation: organization alternate names  
Context: The National Aeronautics and Space Administration, abbreviated as NASA, is responsible for the nation's civilian space program.  
Head Entity: NASA  
Tail Entity: National Aeronautics and Space Administration  

Relation: organization alternate names  
Context: The Federal Bureau of Investigation, or FBI, is known for its role in investigating federal crimes in the United States.  
Head Entity: FBI  
Tail Entity: Federal Bureau of Investigation  

Relation: organization alternate names  
Context: The British Broadcasting Corporation, widely known as the BBC, provides news and entertainment to audiences worldwide.  
Head Entity: BBC  
Tail Entity: British Broadcasting Corporation  
#### organization city of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization city of headquarters" means an organization is located in a city.
Here is an example:
Relation: organization city of headquarters
Context: guy-sheftall entered spelman college in atlanta at age 16 and later earned a master 's in english with a thesis titled `` faulkner 's treatment of women in his major novels . ''
Head Entity: spelman college
Tail Entity: atlanta
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization city of headquarters":
Relation: organization city of headquarters  
Context: the headquarters of the tech giant apple inc. is located in cupertino, california, where it has been since 1993.  
Head Entity: apple inc.  
Tail Entity: cupertino  

Relation: organization city of headquarters  
Context: the united nations has its main office in new york city, which serves as a hub for international diplomacy.  
Head Entity: united nations  
Tail Entity: new york city  

Relation: organization city of headquarters  
Context: the famous car manufacturer ford motor company is headquartered in dearborn, michigan, a city known for its automotive history.  
Head Entity: ford motor company  
Tail Entity: dearborn  

Relation: organization city of headquarters  
Context: google's parent company, alphabet inc., has its headquarters in mountain view, california, in the heart of silicon valley.  
Head Entity: alphabet inc.  
Tail Entity: mountain view  

Relation: organization city of headquarters  
Context: the multinational corporation samsung electronics is based in suwon, south korea, where it was founded in 1969.  
Head Entity: samsung electronics  
Tail Entity: suwon  
#### person siblings ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person siblings" means a person 's sibling is a person.
Here is an example:
Relation: person siblings
Context: forsberg , a political science professor at city college of new york , died oct. 19 in a bronx hospital of cancer , said her sister , celia seupel .
Head Entity: forsberg
Tail Entity: celia seupel
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person siblings":
Relation: person siblings  
Context: During the family reunion, John introduced his sister, Emily, who had just returned from studying abroad.  
Head Entity: John  
Tail Entity: Emily  

Relation: person siblings  
Context: After the game, Sarah celebrated her victory with her brother, Michael, who had been cheering for her from the stands.  
Head Entity: Sarah  
Tail Entity: Michael  

Relation: person siblings  
Context: In her memoir, Lisa writes fondly about her childhood adventures with her brother, Tom, who always had her back.  
Head Entity: Lisa  
Tail Entity: Tom  

Relation: person siblings  
Context: At the wedding, Anna was thrilled to see her brother, David, who had flown in from another state to be her best man.  
Head Entity: Anna  
Tail Entity: David  

Relation: person siblings  
Context: The documentary featured interviews with Rachel and her sister, Jessica, discussing their close bond and shared experiences growing up.  
Head Entity: Rachel  
Tail Entity: Jessica  
Mixup data size:  15700
MixupTrain:  epoch  0, batch     0 | loss: 5.2821188
MixupTrain:  epoch  0, batch     1 | loss: 3.6867929
MixupTrain:  epoch  0, batch     2 | loss: 3.2445149
MixupTrain:  epoch  0, batch     3 | loss: 3.8830950
MixupTrain:  epoch  0, batch     4 | loss: 3.8261452
MixupTrain:  epoch  0, batch     5 | loss: 3.2422583
MixupTrain:  epoch  0, batch     6 | loss: 3.7955520
MixupTrain:  epoch  0, batch     7 | loss: 4.5152311
MixupTrain:  epoch  0, batch     8 | loss: 3.5121195
MixupTrain:  epoch  0, batch     9 | loss: 4.5264797
MixupTrain:  epoch  0, batch    10 | loss: 3.4351039
MixupTrain:  epoch  0, batch    11 | loss: 4.0850310
MixupTrain:  epoch  0, batch    12 | loss: 3.9332671
MixupTrain:  epoch  0, batch    13 | loss: 4.3712473
MixupTrain:  epoch  0, batch    14 | loss: 3.2923226
MixupTrain:  epoch  0, batch    15 | loss: 4.2037969
MixupTrain:  epoch  0, batch    16 | loss: 3.8456450
MixupTrain:  epoch  0, batch    17 | loss: 3.0332355
MixupTrain:  epoch  0, batch    18 | loss: 2.8803303
MixupTrain:  epoch  0, batch    19 | loss: 3.6056366
MixupTrain:  epoch  0, batch    20 | loss: 4.3039703
MixupTrain:  epoch  0, batch    21 | loss: 3.6953192
MixupTrain:  epoch  0, batch    22 | loss: 2.6931236
MixupTrain:  epoch  0, batch    23 | loss: 2.8141356
MixupTrain:  epoch  0, batch    24 | loss: 3.2401261
MixupTrain:  epoch  0, batch    25 | loss: 3.0472641
MixupTrain:  epoch  0, batch    26 | loss: 2.6335545
MixupTrain:  epoch  0, batch    27 | loss: 3.7746391
MixupTrain:  epoch  0, batch    28 | loss: 3.3430293
MixupTrain:  epoch  0, batch    29 | loss: 3.6142588
MixupTrain:  epoch  0, batch    30 | loss: 3.1203201
MixupTrain:  epoch  0, batch    31 | loss: 2.5666766
MixupTrain:  epoch  0, batch    32 | loss: 4.0843334
MixupTrain:  epoch  0, batch    33 | loss: 3.0298147
MixupTrain:  epoch  0, batch    34 | loss: 3.8675840
MixupTrain:  epoch  0, batch    35 | loss: 3.1749015
MixupTrain:  epoch  0, batch    36 | loss: 3.3105330
MixupTrain:  epoch  0, batch    37 | loss: 3.4024775
MixupTrain:  epoch  0, batch    38 | loss: 3.1901610
MixupTrain:  epoch  0, batch    39 | loss: 2.7448339
MixupTrain:  epoch  0, batch    40 | loss: 3.3594203
MixupTrain:  epoch  0, batch    41 | loss: 3.6361947
MixupTrain:  epoch  0, batch    42 | loss: 2.8121634
MixupTrain:  epoch  0, batch    43 | loss: 3.3591928
MixupTrain:  epoch  0, batch    44 | loss: 3.3315372
MixupTrain:  epoch  0, batch    45 | loss: 3.8992457
MixupTrain:  epoch  0, batch    46 | loss: 4.1750937
MixupTrain:  epoch  0, batch    47 | loss: 3.4058056
MixupTrain:  epoch  0, batch    48 | loss: 2.9502685
MixupTrain:  epoch  0, batch    49 | loss: 3.5810628
MixupTrain:  epoch  0, batch    50 | loss: 4.0905800
MixupTrain:  epoch  0, batch    51 | loss: 4.0215182
MixupTrain:  epoch  0, batch    52 | loss: 3.7835102
MixupTrain:  epoch  0, batch    53 | loss: 3.7410157
MixupTrain:  epoch  0, batch    54 | loss: 2.7818594
MixupTrain:  epoch  0, batch    55 | loss: 4.3598499
MixupTrain:  epoch  0, batch    56 | loss: 2.6501131
MixupTrain:  epoch  0, batch    57 | loss: 3.3493652
MixupTrain:  epoch  0, batch    58 | loss: 2.8457260
MixupTrain:  epoch  0, batch    59 | loss: 3.5042458
MixupTrain:  epoch  0, batch    60 | loss: 3.6109130
MixupTrain:  epoch  0, batch    61 | loss: 3.1407866
MixupTrain:  epoch  0, batch    62 | loss: 2.8622375
MixupTrain:  epoch  0, batch    63 | loss: 3.1458249
MixupTrain:  epoch  0, batch    64 | loss: 3.2924995
MixupTrain:  epoch  0, batch    65 | loss: 2.5993724
MixupTrain:  epoch  0, batch    66 | loss: 3.4161987
MixupTrain:  epoch  0, batch    67 | loss: 3.4808421
MixupTrain:  epoch  0, batch    68 | loss: 3.3912570
MixupTrain:  epoch  0, batch    69 | loss: 3.5559106
MixupTrain:  epoch  0, batch    70 | loss: 3.6757650
MixupTrain:  epoch  0, batch    71 | loss: 3.4664636
MixupTrain:  epoch  0, batch    72 | loss: 2.9588127
MixupTrain:  epoch  0, batch    73 | loss: 3.5543997
MixupTrain:  epoch  0, batch    74 | loss: 3.2568967
MixupTrain:  epoch  0, batch    75 | loss: 3.6359346
MixupTrain:  epoch  0, batch    76 | loss: 2.4753807
MixupTrain:  epoch  0, batch    77 | loss: 2.9971883
MixupTrain:  epoch  0, batch    78 | loss: 3.6373703
MixupTrain:  epoch  0, batch    79 | loss: 3.0504627
MixupTrain:  epoch  0, batch    80 | loss: 3.6724143
MixupTrain:  epoch  0, batch    81 | loss: 2.9735565
MixupTrain:  epoch  0, batch    82 | loss: 2.5828624
MixupTrain:  epoch  0, batch    83 | loss: 3.1850450
MixupTrain:  epoch  0, batch    84 | loss: 2.9237993
MixupTrain:  epoch  0, batch    85 | loss: 2.9994740
MixupTrain:  epoch  0, batch    86 | loss: 3.2773046
MixupTrain:  epoch  0, batch    87 | loss: 2.9614127
MixupTrain:  epoch  0, batch    88 | loss: 2.6010652
MixupTrain:  epoch  0, batch    89 | loss: 2.7227819
MixupTrain:  epoch  0, batch    90 | loss: 2.7660875
MixupTrain:  epoch  0, batch    91 | loss: 3.2875624
MixupTrain:  epoch  0, batch    92 | loss: 3.1787052
MixupTrain:  epoch  0, batch    93 | loss: 2.9337034
MixupTrain:  epoch  0, batch    94 | loss: 2.6005363
MixupTrain:  epoch  0, batch    95 | loss: 3.0566168
MixupTrain:  epoch  0, batch    96 | loss: 2.6418300
MixupTrain:  epoch  0, batch    97 | loss: 3.4682441
MixupTrain:  epoch  0, batch    98 | loss: 3.4352641
MixupTrain:  epoch  0, batch    99 | loss: 2.6338024
MixupTrain:  epoch  0, batch   100 | loss: 2.9501128
MixupTrain:  epoch  0, batch   101 | loss: 3.1503437
MixupTrain:  epoch  0, batch   102 | loss: 3.3462520
MixupTrain:  epoch  0, batch   103 | loss: 2.9274483
MixupTrain:  epoch  0, batch   104 | loss: 3.9423699
MixupTrain:  epoch  0, batch   105 | loss: 3.0387895
MixupTrain:  epoch  0, batch   106 | loss: 3.4826322
MixupTrain:  epoch  0, batch   107 | loss: 3.2407243
MixupTrain:  epoch  0, batch   108 | loss: 2.9156032
MixupTrain:  epoch  0, batch   109 | loss: 2.9596009
MixupTrain:  epoch  0, batch   110 | loss: 2.9265873
MixupTrain:  epoch  0, batch   111 | loss: 2.8898389
MixupTrain:  epoch  0, batch   112 | loss: 3.5330510
MixupTrain:  epoch  0, batch   113 | loss: 2.6364479
MixupTrain:  epoch  0, batch   114 | loss: 2.7414777
MixupTrain:  epoch  0, batch   115 | loss: 3.2343559
MixupTrain:  epoch  0, batch   116 | loss: 2.7477293
MixupTrain:  epoch  0, batch   117 | loss: 2.9663377
MixupTrain:  epoch  0, batch   118 | loss: 2.7626915
MixupTrain:  epoch  0, batch   119 | loss: 3.1371150
MixupTrain:  epoch  0, batch   120 | loss: 2.7383041
MixupTrain:  epoch  0, batch   121 | loss: 2.9232605
MixupTrain:  epoch  0, batch   122 | loss: 2.9393888
MixupTrain:  epoch  0, batch   123 | loss: 3.1049645
MixupTrain:  epoch  0, batch   124 | loss: 3.2935104
MixupTrain:  epoch  0, batch   125 | loss: 3.3783851
MixupTrain:  epoch  0, batch   126 | loss: 2.6577706
MixupTrain:  epoch  0, batch   127 | loss: 2.2441010
MixupTrain:  epoch  0, batch   128 | loss: 3.1951070
MixupTrain:  epoch  0, batch   129 | loss: 4.0468645
MixupTrain:  epoch  0, batch   130 | loss: 2.5690198
MixupTrain:  epoch  0, batch   131 | loss: 3.2997661
MixupTrain:  epoch  0, batch   132 | loss: 2.9661965
MixupTrain:  epoch  0, batch   133 | loss: 3.1850004
MixupTrain:  epoch  0, batch   134 | loss: 3.1654055
MixupTrain:  epoch  0, batch   135 | loss: 2.7279017
MixupTrain:  epoch  0, batch   136 | loss: 2.6496296
MixupTrain:  epoch  0, batch   137 | loss: 2.5381994
MixupTrain:  epoch  0, batch   138 | loss: 2.5676003
MixupTrain:  epoch  0, batch   139 | loss: 2.8000991
MixupTrain:  epoch  0, batch   140 | loss: 2.9329157
MixupTrain:  epoch  0, batch   141 | loss: 2.8026519
MixupTrain:  epoch  0, batch   142 | loss: 2.1999974
MixupTrain:  epoch  0, batch   143 | loss: 2.4931238
MixupTrain:  epoch  0, batch   144 | loss: 2.8501000
MixupTrain:  epoch  0, batch   145 | loss: 2.3908362
MixupTrain:  epoch  0, batch   146 | loss: 2.9866486
MixupTrain:  epoch  0, batch   147 | loss: 2.7856011
MixupTrain:  epoch  0, batch   148 | loss: 3.2881534
MixupTrain:  epoch  0, batch   149 | loss: 2.9476306
MixupTrain:  epoch  0, batch   150 | loss: 2.7660551
MixupTrain:  epoch  0, batch   151 | loss: 2.6669378
MixupTrain:  epoch  0, batch   152 | loss: 2.6986496
MixupTrain:  epoch  0, batch   153 | loss: 2.9214177
MixupTrain:  epoch  0, batch   154 | loss: 3.7837167
MixupTrain:  epoch  0, batch   155 | loss: 2.9011981
MixupTrain:  epoch  0, batch   156 | loss: 2.9013929
MixupTrain:  epoch  0, batch   157 | loss: 3.1099253
MixupTrain:  epoch  0, batch   158 | loss: 2.9396901
MixupTrain:  epoch  0, batch   159 | loss: 3.0495415
MixupTrain:  epoch  0, batch   160 | loss: 2.7175426
MixupTrain:  epoch  0, batch   161 | loss: 2.4488983
MixupTrain:  epoch  0, batch   162 | loss: 3.0481043
MixupTrain:  epoch  0, batch   163 | loss: 2.7326412
MixupTrain:  epoch  0, batch   164 | loss: 3.1988540
MixupTrain:  epoch  0, batch   165 | loss: 3.0450726
MixupTrain:  epoch  0, batch   166 | loss: 3.5580018
MixupTrain:  epoch  0, batch   167 | loss: 3.3795943
MixupTrain:  epoch  0, batch   168 | loss: 2.3334005
MixupTrain:  epoch  0, batch   169 | loss: 2.7365150
MixupTrain:  epoch  0, batch   170 | loss: 2.6501570
MixupTrain:  epoch  0, batch   171 | loss: 2.4540629
MixupTrain:  epoch  0, batch   172 | loss: 2.6274478
MixupTrain:  epoch  0, batch   173 | loss: 3.0329292
MixupTrain:  epoch  0, batch   174 | loss: 2.8578086
MixupTrain:  epoch  0, batch   175 | loss: 3.0486212
MixupTrain:  epoch  0, batch   176 | loss: 2.6877270
MixupTrain:  epoch  0, batch   177 | loss: 2.3239183
MixupTrain:  epoch  0, batch   178 | loss: 2.7527504
MixupTrain:  epoch  0, batch   179 | loss: 2.6601138
MixupTrain:  epoch  0, batch   180 | loss: 2.7793391
MixupTrain:  epoch  0, batch   181 | loss: 2.5930479
MixupTrain:  epoch  0, batch   182 | loss: 2.5478754
MixupTrain:  epoch  0, batch   183 | loss: 2.4867933
MixupTrain:  epoch  0, batch   184 | loss: 2.6337848
MixupTrain:  epoch  0, batch   185 | loss: 2.6925287
MixupTrain:  epoch  0, batch   186 | loss: 2.6100688
MixupTrain:  epoch  0, batch   187 | loss: 2.7729645
MixupTrain:  epoch  0, batch   188 | loss: 2.8100362
MixupTrain:  epoch  0, batch   189 | loss: 2.7727599
MixupTrain:  epoch  0, batch   190 | loss: 2.5768480
MixupTrain:  epoch  0, batch   191 | loss: 2.6276054
MixupTrain:  epoch  0, batch   192 | loss: 2.3118429
MixupTrain:  epoch  0, batch   193 | loss: 2.3900275
MixupTrain:  epoch  0, batch   194 | loss: 2.6248748
MixupTrain:  epoch  0, batch   195 | loss: 2.6267056
MixupTrain:  epoch  0, batch   196 | loss: 2.4405160
MixupTrain:  epoch  0, batch   197 | loss: 2.7595155
MixupTrain:  epoch  0, batch   198 | loss: 2.3147063
MixupTrain:  epoch  0, batch   199 | loss: 2.8054230
MixupTrain:  epoch  0, batch   200 | loss: 2.7453337
MixupTrain:  epoch  0, batch   201 | loss: 2.5140181
MixupTrain:  epoch  0, batch   202 | loss: 2.4671001
MixupTrain:  epoch  0, batch   203 | loss: 2.6984611
MixupTrain:  epoch  0, batch   204 | loss: 2.7526135
MixupTrain:  epoch  0, batch   205 | loss: 2.5450535
MixupTrain:  epoch  0, batch   206 | loss: 3.2196269
MixupTrain:  epoch  0, batch   207 | loss: 2.7865529
MixupTrain:  epoch  0, batch   208 | loss: 2.3971126
MixupTrain:  epoch  0, batch   209 | loss: 2.5724616
MixupTrain:  epoch  0, batch   210 | loss: 2.9919105
MixupTrain:  epoch  0, batch   211 | loss: 2.9304540
MixupTrain:  epoch  0, batch   212 | loss: 2.4884429
MixupTrain:  epoch  0, batch   213 | loss: 2.2067704
MixupTrain:  epoch  0, batch   214 | loss: 2.8099718
MixupTrain:  epoch  0, batch   215 | loss: 2.5498772
MixupTrain:  epoch  0, batch   216 | loss: 2.5718331
MixupTrain:  epoch  0, batch   217 | loss: 2.6968331
MixupTrain:  epoch  0, batch   218 | loss: 2.2719526
MixupTrain:  epoch  0, batch   219 | loss: 2.9000330
MixupTrain:  epoch  0, batch   220 | loss: 2.8847156
MixupTrain:  epoch  0, batch   221 | loss: 2.4776616
MixupTrain:  epoch  0, batch   222 | loss: 2.3926444
MixupTrain:  epoch  0, batch   223 | loss: 3.0950150
MixupTrain:  epoch  0, batch   224 | loss: 2.7760539
MixupTrain:  epoch  0, batch   225 | loss: 2.9452095
MixupTrain:  epoch  0, batch   226 | loss: 2.5038028
MixupTrain:  epoch  0, batch   227 | loss: 2.7072365
MixupTrain:  epoch  0, batch   228 | loss: 2.0847812
MixupTrain:  epoch  0, batch   229 | loss: 2.8122172
MixupTrain:  epoch  0, batch   230 | loss: 3.2139323
MixupTrain:  epoch  0, batch   231 | loss: 3.0822215
MixupTrain:  epoch  0, batch   232 | loss: 2.5709515
MixupTrain:  epoch  0, batch   233 | loss: 2.6956639
MixupTrain:  epoch  0, batch   234 | loss: 2.7141728
MixupTrain:  epoch  0, batch   235 | loss: 2.6930485
MixupTrain:  epoch  0, batch   236 | loss: 2.4972601
MixupTrain:  epoch  0, batch   237 | loss: 2.4475739
MixupTrain:  epoch  0, batch   238 | loss: 2.7529385
MixupTrain:  epoch  0, batch   239 | loss: 2.5321901
MixupTrain:  epoch  0, batch   240 | loss: 2.4069057
MixupTrain:  epoch  0, batch   241 | loss: 2.7935839
MixupTrain:  epoch  0, batch   242 | loss: 2.4955049
MixupTrain:  epoch  0, batch   243 | loss: 2.4546723
MixupTrain:  epoch  0, batch   244 | loss: 2.2700467
MixupTrain:  epoch  0, batch   245 | loss: 2.2509713
MixupTrain:  epoch  0, batch   246 | loss: 2.8710132
MixupTrain:  epoch  0, batch   247 | loss: 2.4142418
MixupTrain:  epoch  0, batch   248 | loss: 2.5112057
MixupTrain:  epoch  0, batch   249 | loss: 2.9480672
MixupTrain:  epoch  0, batch   250 | loss: 2.6817057
MixupTrain:  epoch  0, batch   251 | loss: 2.6435604
MixupTrain:  epoch  0, batch   252 | loss: 2.1984291
MixupTrain:  epoch  0, batch   253 | loss: 2.7623560
MixupTrain:  epoch  0, batch   254 | loss: 2.7854912
MixupTrain:  epoch  0, batch   255 | loss: 2.3780279
MixupTrain:  epoch  0, batch   256 | loss: 2.4223895
MixupTrain:  epoch  0, batch   257 | loss: 2.6126733
MixupTrain:  epoch  0, batch   258 | loss: 2.6549017
MixupTrain:  epoch  0, batch   259 | loss: 3.1409221
MixupTrain:  epoch  0, batch   260 | loss: 2.8182826
MixupTrain:  epoch  0, batch   261 | loss: 2.5039415
MixupTrain:  epoch  0, batch   262 | loss: 2.7996292
MixupTrain:  epoch  0, batch   263 | loss: 2.6741199
MixupTrain:  epoch  0, batch   264 | loss: 2.2187178
MixupTrain:  epoch  0, batch   265 | loss: 2.8211370
MixupTrain:  epoch  0, batch   266 | loss: 2.4655309
MixupTrain:  epoch  0, batch   267 | loss: 2.5145926
MixupTrain:  epoch  0, batch   268 | loss: 3.0495768
MixupTrain:  epoch  0, batch   269 | loss: 3.0239263
MixupTrain:  epoch  0, batch   270 | loss: 2.8422747
MixupTrain:  epoch  0, batch   271 | loss: 3.0179062
MixupTrain:  epoch  0, batch   272 | loss: 2.5806975
MixupTrain:  epoch  0, batch   273 | loss: 2.2432997
MixupTrain:  epoch  0, batch   274 | loss: 2.9628656
MixupTrain:  epoch  0, batch   275 | loss: 2.8084514
MixupTrain:  epoch  0, batch   276 | loss: 2.3423178
MixupTrain:  epoch  0, batch   277 | loss: 2.3785028
MixupTrain:  epoch  0, batch   278 | loss: 2.4770904
MixupTrain:  epoch  0, batch   279 | loss: 2.4433708
MixupTrain:  epoch  0, batch   280 | loss: 2.4505599
MixupTrain:  epoch  0, batch   281 | loss: 2.6621270
MixupTrain:  epoch  0, batch   282 | loss: 2.4874027
MixupTrain:  epoch  0, batch   283 | loss: 2.9187644
MixupTrain:  epoch  0, batch   284 | loss: 2.5547287
MixupTrain:  epoch  0, batch   285 | loss: 2.5726876
MixupTrain:  epoch  0, batch   286 | loss: 2.6472135
MixupTrain:  epoch  0, batch   287 | loss: 3.1464434
MixupTrain:  epoch  0, batch   288 | loss: 2.5686793
MixupTrain:  epoch  0, batch   289 | loss: 2.9696252
MixupTrain:  epoch  0, batch   290 | loss: 2.7415481
MixupTrain:  epoch  0, batch   291 | loss: 2.5624714
MixupTrain:  epoch  0, batch   292 | loss: 2.7950273
MixupTrain:  epoch  0, batch   293 | loss: 2.7688894
MixupTrain:  epoch  0, batch   294 | loss: 2.4459362
MixupTrain:  epoch  0, batch   295 | loss: 2.9318290
MixupTrain:  epoch  0, batch   296 | loss: 2.7656510
MixupTrain:  epoch  0, batch   297 | loss: 2.5535882
MixupTrain:  epoch  0, batch   298 | loss: 2.6177070
MixupTrain:  epoch  0, batch   299 | loss: 2.7173777
MixupTrain:  epoch  0, batch   300 | loss: 2.5458581
MixupTrain:  epoch  0, batch   301 | loss: 2.6755977
MixupTrain:  epoch  0, batch   302 | loss: 2.3464231
MixupTrain:  epoch  0, batch   303 | loss: 2.0567689
MixupTrain:  epoch  0, batch   304 | loss: 2.4572175
MixupTrain:  epoch  0, batch   305 | loss: 2.7915020
MixupTrain:  epoch  0, batch   306 | loss: 2.4374828
MixupTrain:  epoch  0, batch   307 | loss: 2.6925707
MixupTrain:  epoch  0, batch   308 | loss: 2.4751801
MixupTrain:  epoch  0, batch   309 | loss: 2.6121876
MixupTrain:  epoch  0, batch   310 | loss: 2.7644424
MixupTrain:  epoch  0, batch   311 | loss: 2.6336598
MixupTrain:  epoch  0, batch   312 | loss: 2.8130217
MixupTrain:  epoch  0, batch   313 | loss: 2.4864898
MixupTrain:  epoch  0, batch   314 | loss: 2.8947449
MixupTrain:  epoch  0, batch   315 | loss: 2.7522531
MixupTrain:  epoch  0, batch   316 | loss: 2.4212344
MixupTrain:  epoch  0, batch   317 | loss: 2.8109937
MixupTrain:  epoch  0, batch   318 | loss: 2.6623545
MixupTrain:  epoch  0, batch   319 | loss: 2.4042535
MixupTrain:  epoch  0, batch   320 | loss: 2.5579147
MixupTrain:  epoch  0, batch   321 | loss: 2.8764284
MixupTrain:  epoch  0, batch   322 | loss: 2.6568315
MixupTrain:  epoch  0, batch   323 | loss: 2.2664251
MixupTrain:  epoch  0, batch   324 | loss: 2.5840871
MixupTrain:  epoch  0, batch   325 | loss: 2.5315294
MixupTrain:  epoch  0, batch   326 | loss: 2.7952497
MixupTrain:  epoch  0, batch   327 | loss: 3.0166621
MixupTrain:  epoch  0, batch   328 | loss: 2.9301934
MixupTrain:  epoch  0, batch   329 | loss: 2.7108071
MixupTrain:  epoch  0, batch   330 | loss: 2.8263690
MixupTrain:  epoch  0, batch   331 | loss: 2.8225417
MixupTrain:  epoch  0, batch   332 | loss: 2.8414960
MixupTrain:  epoch  0, batch   333 | loss: 2.7821679
MixupTrain:  epoch  0, batch   334 | loss: 2.8029983
MixupTrain:  epoch  0, batch   335 | loss: 2.3945866
MixupTrain:  epoch  0, batch   336 | loss: 2.4136074
MixupTrain:  epoch  0, batch   337 | loss: 2.5041885
MixupTrain:  epoch  0, batch   338 | loss: 2.4781146
MixupTrain:  epoch  0, batch   339 | loss: 2.9610043
MixupTrain:  epoch  0, batch   340 | loss: 2.6425333
MixupTrain:  epoch  0, batch   341 | loss: 2.5979583
MixupTrain:  epoch  0, batch   342 | loss: 2.6507850
MixupTrain:  epoch  0, batch   343 | loss: 2.4828105
MixupTrain:  epoch  0, batch   344 | loss: 2.7206788
MixupTrain:  epoch  0, batch   345 | loss: 2.9681888
MixupTrain:  epoch  0, batch   346 | loss: 2.2477007
MixupTrain:  epoch  0, batch   347 | loss: 2.3891032
MixupTrain:  epoch  0, batch   348 | loss: 2.3777308
MixupTrain:  epoch  0, batch   349 | loss: 2.6296291
MixupTrain:  epoch  0, batch   350 | loss: 2.8521419
MixupTrain:  epoch  0, batch   351 | loss: 2.7075868
MixupTrain:  epoch  0, batch   352 | loss: 2.4901376
MixupTrain:  epoch  0, batch   353 | loss: 2.4731910
MixupTrain:  epoch  0, batch   354 | loss: 2.6845968
MixupTrain:  epoch  0, batch   355 | loss: 2.5882370
MixupTrain:  epoch  0, batch   356 | loss: 2.4539185
MixupTrain:  epoch  0, batch   357 | loss: 2.4975719
MixupTrain:  epoch  0, batch   358 | loss: 2.5389750
MixupTrain:  epoch  0, batch   359 | loss: 2.6590612
MixupTrain:  epoch  0, batch   360 | loss: 2.9211354
MixupTrain:  epoch  0, batch   361 | loss: 3.2257655
MixupTrain:  epoch  0, batch   362 | loss: 1.9648006
MixupTrain:  epoch  0, batch   363 | loss: 2.6487925
MixupTrain:  epoch  0, batch   364 | loss: 2.7827339
MixupTrain:  epoch  0, batch   365 | loss: 2.5809948
MixupTrain:  epoch  0, batch   366 | loss: 2.6030030
MixupTrain:  epoch  0, batch   367 | loss: 2.6891880
MixupTrain:  epoch  0, batch   368 | loss: 2.8267150
MixupTrain:  epoch  0, batch   369 | loss: 2.7240059
MixupTrain:  epoch  0, batch   370 | loss: 2.8107581
MixupTrain:  epoch  0, batch   371 | loss: 2.5957024
MixupTrain:  epoch  0, batch   372 | loss: 2.4288774
MixupTrain:  epoch  0, batch   373 | loss: 2.3468766
MixupTrain:  epoch  0, batch   374 | loss: 2.7563055
MixupTrain:  epoch  0, batch   375 | loss: 2.6668730
MixupTrain:  epoch  0, batch   376 | loss: 2.8195410
MixupTrain:  epoch  0, batch   377 | loss: 2.6324010
MixupTrain:  epoch  0, batch   378 | loss: 2.6396894
MixupTrain:  epoch  0, batch   379 | loss: 2.3479497
MixupTrain:  epoch  0, batch   380 | loss: 2.4560513
MixupTrain:  epoch  0, batch   381 | loss: 2.6457200
MixupTrain:  epoch  0, batch   382 | loss: 2.6668482
MixupTrain:  epoch  0, batch   383 | loss: 2.3427477
MixupTrain:  epoch  0, batch   384 | loss: 2.8447311
MixupTrain:  epoch  0, batch   385 | loss: 2.4674637
MixupTrain:  epoch  0, batch   386 | loss: 2.5532422
MixupTrain:  epoch  0, batch   387 | loss: 2.8777487
MixupTrain:  epoch  0, batch   388 | loss: 2.4986515
MixupTrain:  epoch  0, batch   389 | loss: 2.1143694
MixupTrain:  epoch  0, batch   390 | loss: 2.8029590
MixupTrain:  epoch  0, batch   391 | loss: 2.4218304
MixupTrain:  epoch  0, batch   392 | loss: 2.8280058
MixupTrain:  epoch  0, batch   393 | loss: 2.3645849
MixupTrain:  epoch  0, batch   394 | loss: 2.3432751
MixupTrain:  epoch  0, batch   395 | loss: 2.7713118
MixupTrain:  epoch  0, batch   396 | loss: 2.4252312
MixupTrain:  epoch  0, batch   397 | loss: 2.2939906
MixupTrain:  epoch  0, batch   398 | loss: 2.8553386
MixupTrain:  epoch  0, batch   399 | loss: 2.2251675
MixupTrain:  epoch  0, batch   400 | loss: 2.1017933
MixupTrain:  epoch  0, batch   401 | loss: 2.4477298
MixupTrain:  epoch  0, batch   402 | loss: 2.6821284
MixupTrain:  epoch  0, batch   403 | loss: 2.0341825
MixupTrain:  epoch  0, batch   404 | loss: 2.4922414
MixupTrain:  epoch  0, batch   405 | loss: 2.9100261
MixupTrain:  epoch  0, batch   406 | loss: 2.5408349
MixupTrain:  epoch  0, batch   407 | loss: 3.0932512
MixupTrain:  epoch  0, batch   408 | loss: 2.3281858
MixupTrain:  epoch  0, batch   409 | loss: 2.5907607
MixupTrain:  epoch  0, batch   410 | loss: 2.5320845
MixupTrain:  epoch  0, batch   411 | loss: 2.5096352
MixupTrain:  epoch  0, batch   412 | loss: 2.1723421
MixupTrain:  epoch  0, batch   413 | loss: 2.3542049
MixupTrain:  epoch  0, batch   414 | loss: 2.8204699
MixupTrain:  epoch  0, batch   415 | loss: 2.6710329
MixupTrain:  epoch  0, batch   416 | loss: 2.4702127
MixupTrain:  epoch  0, batch   417 | loss: 2.2809286
MixupTrain:  epoch  0, batch   418 | loss: 2.7195148
MixupTrain:  epoch  0, batch   419 | loss: 2.5676842
MixupTrain:  epoch  0, batch   420 | loss: 2.4351490
MixupTrain:  epoch  0, batch   421 | loss: 2.7595003
MixupTrain:  epoch  0, batch   422 | loss: 2.8189459
MixupTrain:  epoch  0, batch   423 | loss: 2.5802341
MixupTrain:  epoch  0, batch   424 | loss: 2.2954993
MixupTrain:  epoch  0, batch   425 | loss: 2.4790239
MixupTrain:  epoch  0, batch   426 | loss: 2.7567685
MixupTrain:  epoch  0, batch   427 | loss: 2.4912426
MixupTrain:  epoch  0, batch   428 | loss: 2.0580411
MixupTrain:  epoch  0, batch   429 | loss: 2.4655166
MixupTrain:  epoch  0, batch   430 | loss: 2.5473077
MixupTrain:  epoch  0, batch   431 | loss: 2.1861291
MixupTrain:  epoch  0, batch   432 | loss: 2.3575358
MixupTrain:  epoch  0, batch   433 | loss: 2.9501667
MixupTrain:  epoch  0, batch   434 | loss: 2.4241714
MixupTrain:  epoch  0, batch   435 | loss: 2.3970585
MixupTrain:  epoch  0, batch   436 | loss: 2.5910251
MixupTrain:  epoch  0, batch   437 | loss: 2.2517629
MixupTrain:  epoch  0, batch   438 | loss: 2.5151310
MixupTrain:  epoch  0, batch   439 | loss: 2.3066225
MixupTrain:  epoch  0, batch   440 | loss: 2.4987695
MixupTrain:  epoch  0, batch   441 | loss: 2.3156407
MixupTrain:  epoch  0, batch   442 | loss: 2.3872132
MixupTrain:  epoch  0, batch   443 | loss: 2.8228941
MixupTrain:  epoch  0, batch   444 | loss: 2.9829106
MixupTrain:  epoch  0, batch   445 | loss: 2.3535266
MixupTrain:  epoch  0, batch   446 | loss: 2.4399879
MixupTrain:  epoch  0, batch   447 | loss: 2.0705423
MixupTrain:  epoch  0, batch   448 | loss: 2.2685423
MixupTrain:  epoch  0, batch   449 | loss: 2.4397688
MixupTrain:  epoch  0, batch   450 | loss: 2.8996139
MixupTrain:  epoch  0, batch   451 | loss: 2.1626830
MixupTrain:  epoch  0, batch   452 | loss: 2.4085879
MixupTrain:  epoch  0, batch   453 | loss: 2.4634917
MixupTrain:  epoch  0, batch   454 | loss: 2.4240456
MixupTrain:  epoch  0, batch   455 | loss: 2.6174533
MixupTrain:  epoch  0, batch   456 | loss: 2.6788960
MixupTrain:  epoch  0, batch   457 | loss: 2.5303454
MixupTrain:  epoch  0, batch   458 | loss: 2.8330719
MixupTrain:  epoch  0, batch   459 | loss: 2.5257328
MixupTrain:  epoch  0, batch   460 | loss: 3.1078343
MixupTrain:  epoch  0, batch   461 | loss: 2.5376396
MixupTrain:  epoch  0, batch   462 | loss: 2.5077400
MixupTrain:  epoch  0, batch   463 | loss: 2.2803860
MixupTrain:  epoch  0, batch   464 | loss: 2.6853890
MixupTrain:  epoch  0, batch   465 | loss: 2.6169887
MixupTrain:  epoch  0, batch   466 | loss: 2.1794717
MixupTrain:  epoch  0, batch   467 | loss: 2.4106822
MixupTrain:  epoch  0, batch   468 | loss: 2.3452001
MixupTrain:  epoch  0, batch   469 | loss: 2.6059141
MixupTrain:  epoch  0, batch   470 | loss: 2.3042486
MixupTrain:  epoch  0, batch   471 | loss: 2.4343164
MixupTrain:  epoch  0, batch   472 | loss: 2.5178051
MixupTrain:  epoch  0, batch   473 | loss: 2.2826393
MixupTrain:  epoch  0, batch   474 | loss: 2.5763803
MixupTrain:  epoch  0, batch   475 | loss: 2.2020741
MixupTrain:  epoch  0, batch   476 | loss: 2.9560876
MixupTrain:  epoch  0, batch   477 | loss: 2.1648669
MixupTrain:  epoch  0, batch   478 | loss: 2.0743992
MixupTrain:  epoch  0, batch   479 | loss: 2.6143622
MixupTrain:  epoch  0, batch   480 | loss: 2.7078586
MixupTrain:  epoch  0, batch   481 | loss: 2.5826199
MixupTrain:  epoch  0, batch   482 | loss: 2.6827588
MixupTrain:  epoch  0, batch   483 | loss: 2.6003966
MixupTrain:  epoch  0, batch   484 | loss: 2.4651661
MixupTrain:  epoch  0, batch   485 | loss: 2.2956185
MixupTrain:  epoch  0, batch   486 | loss: 2.4594920
MixupTrain:  epoch  0, batch   487 | loss: 2.6351924
MixupTrain:  epoch  0, batch   488 | loss: 1.9960873
MixupTrain:  epoch  0, batch   489 | loss: 2.5057554
MixupTrain:  epoch  0, batch   490 | loss: 2.7892270
MixupTrain:  epoch  0, batch   491 | loss: 2.7401028
MixupTrain:  epoch  0, batch   492 | loss: 2.9778299
MixupTrain:  epoch  0, batch   493 | loss: 2.5711136
MixupTrain:  epoch  0, batch   494 | loss: 2.5381823
MixupTrain:  epoch  0, batch   495 | loss: 2.4982991
MixupTrain:  epoch  0, batch   496 | loss: 2.4508414
MixupTrain:  epoch  0, batch   497 | loss: 2.4526567
MixupTrain:  epoch  0, batch   498 | loss: 2.4555483
MixupTrain:  epoch  0, batch   499 | loss: 2.2894332
MixupTrain:  epoch  0, batch   500 | loss: 2.7706294
MixupTrain:  epoch  0, batch   501 | loss: 2.3931890
MixupTrain:  epoch  0, batch   502 | loss: 2.6485660
MixupTrain:  epoch  0, batch   503 | loss: 2.8345935
MixupTrain:  epoch  0, batch   504 | loss: 2.3479271
MixupTrain:  epoch  0, batch   505 | loss: 2.6046453
MixupTrain:  epoch  0, batch   506 | loss: 2.3032403
MixupTrain:  epoch  0, batch   507 | loss: 2.2662663
MixupTrain:  epoch  0, batch   508 | loss: 2.4655497
MixupTrain:  epoch  0, batch   509 | loss: 2.4539080
MixupTrain:  epoch  0, batch   510 | loss: 2.7167597
MixupTrain:  epoch  0, batch   511 | loss: 2.2543149
MixupTrain:  epoch  0, batch   512 | loss: 2.2378168
MixupTrain:  epoch  0, batch   513 | loss: 2.6663866
MixupTrain:  epoch  0, batch   514 | loss: 2.6318712
MixupTrain:  epoch  0, batch   515 | loss: 2.2729158
MixupTrain:  epoch  0, batch   516 | loss: 3.1841836
MixupTrain:  epoch  0, batch   517 | loss: 2.2925332
MixupTrain:  epoch  0, batch   518 | loss: 2.2227125
MixupTrain:  epoch  0, batch   519 | loss: 2.7280157
MixupTrain:  epoch  0, batch   520 | loss: 2.2753463
MixupTrain:  epoch  0, batch   521 | loss: 2.0840235
MixupTrain:  epoch  0, batch   522 | loss: 2.4285684
MixupTrain:  epoch  0, batch   523 | loss: 2.5228810
MixupTrain:  epoch  0, batch   524 | loss: 2.3790107
MixupTrain:  epoch  0, batch   525 | loss: 2.4059756
MixupTrain:  epoch  0, batch   526 | loss: 2.1586359
MixupTrain:  epoch  0, batch   527 | loss: 2.5823686
MixupTrain:  epoch  0, batch   528 | loss: 2.3494802
MixupTrain:  epoch  0, batch   529 | loss: 2.6521735
MixupTrain:  epoch  0, batch   530 | loss: 2.3548212
MixupTrain:  epoch  0, batch   531 | loss: 2.7725577
MixupTrain:  epoch  0, batch   532 | loss: 2.6773033
MixupTrain:  epoch  0, batch   533 | loss: 2.5616114
MixupTrain:  epoch  0, batch   534 | loss: 2.5376973
MixupTrain:  epoch  0, batch   535 | loss: 2.5908203
MixupTrain:  epoch  0, batch   536 | loss: 2.3899713
MixupTrain:  epoch  0, batch   537 | loss: 2.7795043
MixupTrain:  epoch  0, batch   538 | loss: 2.1664591
MixupTrain:  epoch  0, batch   539 | loss: 2.5929308
MixupTrain:  epoch  0, batch   540 | loss: 2.4492207
MixupTrain:  epoch  0, batch   541 | loss: 2.6499345
MixupTrain:  epoch  0, batch   542 | loss: 2.1208432
MixupTrain:  epoch  0, batch   543 | loss: 2.9552388
MixupTrain:  epoch  0, batch   544 | loss: 2.2749629
MixupTrain:  epoch  0, batch   545 | loss: 2.7037768
MixupTrain:  epoch  0, batch   546 | loss: 2.4562297
MixupTrain:  epoch  0, batch   547 | loss: 2.5065379
MixupTrain:  epoch  0, batch   548 | loss: 2.0570476
MixupTrain:  epoch  0, batch   549 | loss: 2.4296267
MixupTrain:  epoch  0, batch   550 | loss: 2.8409715
MixupTrain:  epoch  0, batch   551 | loss: 2.4731092
MixupTrain:  epoch  0, batch   552 | loss: 2.7445121
MixupTrain:  epoch  0, batch   553 | loss: 2.6180997
MixupTrain:  epoch  0, batch   554 | loss: 2.6686716
MixupTrain:  epoch  0, batch   555 | loss: 2.4504595
MixupTrain:  epoch  0, batch   556 | loss: 2.7160816
MixupTrain:  epoch  0, batch   557 | loss: 2.5719471
MixupTrain:  epoch  0, batch   558 | loss: 2.5749512
MixupTrain:  epoch  0, batch   559 | loss: 2.6220179
MixupTrain:  epoch  0, batch   560 | loss: 2.4478934
MixupTrain:  epoch  0, batch   561 | loss: 2.6714883
MixupTrain:  epoch  0, batch   562 | loss: 2.4169245
MixupTrain:  epoch  0, batch   563 | loss: 2.7509396
MixupTrain:  epoch  0, batch   564 | loss: 2.8473711
MixupTrain:  epoch  0, batch   565 | loss: 2.4422810
MixupTrain:  epoch  0, batch   566 | loss: 2.7248261
MixupTrain:  epoch  0, batch   567 | loss: 2.3574567
MixupTrain:  epoch  0, batch   568 | loss: 2.4599876
MixupTrain:  epoch  0, batch   569 | loss: 2.3338664
MixupTrain:  epoch  0, batch   570 | loss: 2.3783178
MixupTrain:  epoch  0, batch   571 | loss: 2.3246007
MixupTrain:  epoch  0, batch   572 | loss: 2.2914228
MixupTrain:  epoch  0, batch   573 | loss: 2.3507619
MixupTrain:  epoch  0, batch   574 | loss: 2.4551220
MixupTrain:  epoch  0, batch   575 | loss: 2.2592728
MixupTrain:  epoch  0, batch   576 | loss: 2.4472306
MixupTrain:  epoch  0, batch   577 | loss: 2.5242898
MixupTrain:  epoch  0, batch   578 | loss: 2.4628849
MixupTrain:  epoch  0, batch   579 | loss: 2.2437916
MixupTrain:  epoch  0, batch   580 | loss: 2.3745127
MixupTrain:  epoch  0, batch   581 | loss: 2.5690904
MixupTrain:  epoch  0, batch   582 | loss: 2.6695180
MixupTrain:  epoch  0, batch   583 | loss: 2.5051694
MixupTrain:  epoch  0, batch   584 | loss: 2.4327998
MixupTrain:  epoch  0, batch   585 | loss: 2.1819406
MixupTrain:  epoch  0, batch   586 | loss: 2.8333642
MixupTrain:  epoch  0, batch   587 | loss: 2.0853372
MixupTrain:  epoch  0, batch   588 | loss: 2.4769177
MixupTrain:  epoch  0, batch   589 | loss: 2.1724877
MixupTrain:  epoch  0, batch   590 | loss: 2.5755668
MixupTrain:  epoch  0, batch   591 | loss: 2.5146711
MixupTrain:  epoch  0, batch   592 | loss: 2.5131340
MixupTrain:  epoch  0, batch   593 | loss: 2.3550630
MixupTrain:  epoch  0, batch   594 | loss: 2.7228744
MixupTrain:  epoch  0, batch   595 | loss: 2.4529154
MixupTrain:  epoch  0, batch   596 | loss: 2.5399089
MixupTrain:  epoch  0, batch   597 | loss: 2.2064552
MixupTrain:  epoch  0, batch   598 | loss: 2.3747230
MixupTrain:  epoch  0, batch   599 | loss: 2.9673600
MixupTrain:  epoch  0, batch   600 | loss: 2.4544678
MixupTrain:  epoch  0, batch   601 | loss: 2.9693699
MixupTrain:  epoch  0, batch   602 | loss: 2.7345643
MixupTrain:  epoch  0, batch   603 | loss: 2.3979754
MixupTrain:  epoch  0, batch   604 | loss: 2.5163021
MixupTrain:  epoch  0, batch   605 | loss: 2.5770071
MixupTrain:  epoch  0, batch   606 | loss: 2.4652407
MixupTrain:  epoch  0, batch   607 | loss: 2.3867974
MixupTrain:  epoch  0, batch   608 | loss: 2.4947181
MixupTrain:  epoch  0, batch   609 | loss: 2.6183786
MixupTrain:  epoch  0, batch   610 | loss: 2.5451043
MixupTrain:  epoch  0, batch   611 | loss: 2.2778099
MixupTrain:  epoch  0, batch   612 | loss: 2.6539083
MixupTrain:  epoch  0, batch   613 | loss: 2.4047809
MixupTrain:  epoch  0, batch   614 | loss: 2.6831284
MixupTrain:  epoch  0, batch   615 | loss: 2.3669732
MixupTrain:  epoch  0, batch   616 | loss: 2.7623355
MixupTrain:  epoch  0, batch   617 | loss: 2.5199516
MixupTrain:  epoch  0, batch   618 | loss: 2.6027174
MixupTrain:  epoch  0, batch   619 | loss: 2.5565891
MixupTrain:  epoch  0, batch   620 | loss: 2.8257966
MixupTrain:  epoch  0, batch   621 | loss: 2.2104840
MixupTrain:  epoch  0, batch   622 | loss: 2.7468538
MixupTrain:  epoch  0, batch   623 | loss: 2.3564010
MixupTrain:  epoch  0, batch   624 | loss: 2.4674795
MixupTrain:  epoch  0, batch   625 | loss: 2.5192459
MixupTrain:  epoch  0, batch   626 | loss: 2.8374419
MixupTrain:  epoch  0, batch   627 | loss: 2.5522695
MixupTrain:  epoch  0, batch   628 | loss: 2.4942331
MixupTrain:  epoch  0, batch   629 | loss: 2.6444175
MixupTrain:  epoch  0, batch   630 | loss: 2.2477424
MixupTrain:  epoch  0, batch   631 | loss: 2.2950182
MixupTrain:  epoch  0, batch   632 | loss: 2.5018415
MixupTrain:  epoch  0, batch   633 | loss: 2.5072062
MixupTrain:  epoch  0, batch   634 | loss: 2.7132516
MixupTrain:  epoch  0, batch   635 | loss: 2.8778701
MixupTrain:  epoch  0, batch   636 | loss: 2.2315538
MixupTrain:  epoch  0, batch   637 | loss: 2.0513160
MixupTrain:  epoch  0, batch   638 | loss: 2.7771368
MixupTrain:  epoch  0, batch   639 | loss: 2.3399568
MixupTrain:  epoch  0, batch   640 | loss: 2.8842103
MixupTrain:  epoch  0, batch   641 | loss: 2.3964314
MixupTrain:  epoch  0, batch   642 | loss: 2.6803241
MixupTrain:  epoch  0, batch   643 | loss: 2.4604282
MixupTrain:  epoch  0, batch   644 | loss: 2.7962546
MixupTrain:  epoch  0, batch   645 | loss: 2.1680222
MixupTrain:  epoch  0, batch   646 | loss: 2.6678877
MixupTrain:  epoch  0, batch   647 | loss: 2.5239058
MixupTrain:  epoch  0, batch   648 | loss: 2.2835422
MixupTrain:  epoch  0, batch   649 | loss: 2.6196692
MixupTrain:  epoch  0, batch   650 | loss: 2.1806321
MixupTrain:  epoch  0, batch   651 | loss: 2.2975235
MixupTrain:  epoch  0, batch   652 | loss: 2.6983156
MixupTrain:  epoch  0, batch   653 | loss: 2.5125599
MixupTrain:  epoch  0, batch   654 | loss: 2.7252469
MixupTrain:  epoch  0, batch   655 | loss: 2.3748093
MixupTrain:  epoch  0, batch   656 | loss: 2.5106969
MixupTrain:  epoch  0, batch   657 | loss: 2.4619570
MixupTrain:  epoch  0, batch   658 | loss: 2.5513465
MixupTrain:  epoch  0, batch   659 | loss: 2.6966357
MixupTrain:  epoch  0, batch   660 | loss: 2.5755520
MixupTrain:  epoch  0, batch   661 | loss: 2.5147767
MixupTrain:  epoch  0, batch   662 | loss: 2.4803631
MixupTrain:  epoch  0, batch   663 | loss: 2.4262729
MixupTrain:  epoch  0, batch   664 | loss: 2.6004000
MixupTrain:  epoch  0, batch   665 | loss: 2.3010435
MixupTrain:  epoch  0, batch   666 | loss: 2.5207677
MixupTrain:  epoch  0, batch   667 | loss: 2.3504784
MixupTrain:  epoch  0, batch   668 | loss: 2.5170846
MixupTrain:  epoch  0, batch   669 | loss: 2.6841259
MixupTrain:  epoch  0, batch   670 | loss: 2.2423706
MixupTrain:  epoch  0, batch   671 | loss: 2.5131278
MixupTrain:  epoch  0, batch   672 | loss: 2.6530528
MixupTrain:  epoch  0, batch   673 | loss: 2.5446301
MixupTrain:  epoch  0, batch   674 | loss: 2.2868962
MixupTrain:  epoch  0, batch   675 | loss: 2.4425001
MixupTrain:  epoch  0, batch   676 | loss: 2.6971781
MixupTrain:  epoch  0, batch   677 | loss: 2.3175838
MixupTrain:  epoch  0, batch   678 | loss: 2.9437599
MixupTrain:  epoch  0, batch   679 | loss: 2.3628321
MixupTrain:  epoch  0, batch   680 | loss: 2.2327170
MixupTrain:  epoch  0, batch   681 | loss: 2.3824568
MixupTrain:  epoch  0, batch   682 | loss: 2.7097497
MixupTrain:  epoch  0, batch   683 | loss: 2.2534697
MixupTrain:  epoch  0, batch   684 | loss: 2.4128010
MixupTrain:  epoch  0, batch   685 | loss: 2.5681438
MixupTrain:  epoch  0, batch   686 | loss: 2.5374756
MixupTrain:  epoch  0, batch   687 | loss: 2.0535693
MixupTrain:  epoch  0, batch   688 | loss: 2.4079461
MixupTrain:  epoch  0, batch   689 | loss: 2.9337444
MixupTrain:  epoch  0, batch   690 | loss: 2.3704977
MixupTrain:  epoch  0, batch   691 | loss: 2.4136345
MixupTrain:  epoch  0, batch   692 | loss: 2.1836934
MixupTrain:  epoch  0, batch   693 | loss: 2.7785404
MixupTrain:  epoch  0, batch   694 | loss: 2.5648336
MixupTrain:  epoch  0, batch   695 | loss: 3.0809822
MixupTrain:  epoch  0, batch   696 | loss: 2.5342515
MixupTrain:  epoch  0, batch   697 | loss: 2.1807907
MixupTrain:  epoch  0, batch   698 | loss: 2.6656945
MixupTrain:  epoch  0, batch   699 | loss: 2.5402188
MixupTrain:  epoch  0, batch   700 | loss: 2.4109209
MixupTrain:  epoch  0, batch   701 | loss: 2.5169296
MixupTrain:  epoch  0, batch   702 | loss: 2.3857925
MixupTrain:  epoch  0, batch   703 | loss: 2.3834879
MixupTrain:  epoch  0, batch   704 | loss: 2.7307782
MixupTrain:  epoch  0, batch   705 | loss: 2.9092202
MixupTrain:  epoch  0, batch   706 | loss: 2.6167130
MixupTrain:  epoch  0, batch   707 | loss: 2.7134914
MixupTrain:  epoch  0, batch   708 | loss: 2.1961865
MixupTrain:  epoch  0, batch   709 | loss: 2.2713594
MixupTrain:  epoch  0, batch   710 | loss: 2.4678464
MixupTrain:  epoch  0, batch   711 | loss: 2.0932658
MixupTrain:  epoch  0, batch   712 | loss: 2.4021432
MixupTrain:  epoch  0, batch   713 | loss: 2.7752452
MixupTrain:  epoch  0, batch   714 | loss: 2.9272492
MixupTrain:  epoch  0, batch   715 | loss: 2.5215440
MixupTrain:  epoch  0, batch   716 | loss: 2.2845747
MixupTrain:  epoch  0, batch   717 | loss: 2.3112612
MixupTrain:  epoch  0, batch   718 | loss: 2.3563693
MixupTrain:  epoch  0, batch   719 | loss: 2.3571620
MixupTrain:  epoch  0, batch   720 | loss: 2.4522715
MixupTrain:  epoch  0, batch   721 | loss: 2.5392981
MixupTrain:  epoch  0, batch   722 | loss: 2.6266212
MixupTrain:  epoch  0, batch   723 | loss: 2.2701206
MixupTrain:  epoch  0, batch   724 | loss: 2.8753335
MixupTrain:  epoch  0, batch   725 | loss: 2.4856377
MixupTrain:  epoch  0, batch   726 | loss: 2.5716119
MixupTrain:  epoch  0, batch   727 | loss: 2.6698036
MixupTrain:  epoch  0, batch   728 | loss: 2.5878510
MixupTrain:  epoch  0, batch   729 | loss: 2.6266904
MixupTrain:  epoch  0, batch   730 | loss: 2.4004164
MixupTrain:  epoch  0, batch   731 | loss: 2.3119230
MixupTrain:  epoch  0, batch   732 | loss: 2.4822500
MixupTrain:  epoch  0, batch   733 | loss: 2.9549904
MixupTrain:  epoch  0, batch   734 | loss: 2.5947847
MixupTrain:  epoch  0, batch   735 | loss: 2.5514016
MixupTrain:  epoch  0, batch   736 | loss: 2.3068352
MixupTrain:  epoch  0, batch   737 | loss: 2.2719302
MixupTrain:  epoch  0, batch   738 | loss: 2.1608586
MixupTrain:  epoch  0, batch   739 | loss: 2.3527603
MixupTrain:  epoch  0, batch   740 | loss: 2.1435165
MixupTrain:  epoch  0, batch   741 | loss: 2.5786939
MixupTrain:  epoch  0, batch   742 | loss: 2.6293054
MixupTrain:  epoch  0, batch   743 | loss: 2.2554266
MixupTrain:  epoch  0, batch   744 | loss: 2.2948036
MixupTrain:  epoch  0, batch   745 | loss: 2.1392889
MixupTrain:  epoch  0, batch   746 | loss: 2.7480218
MixupTrain:  epoch  0, batch   747 | loss: 2.1300483
MixupTrain:  epoch  0, batch   748 | loss: 2.2177067
MixupTrain:  epoch  0, batch   749 | loss: 2.2746968
MixupTrain:  epoch  0, batch   750 | loss: 2.5107391
MixupTrain:  epoch  0, batch   751 | loss: 2.7185488
MixupTrain:  epoch  0, batch   752 | loss: 2.2970462
MixupTrain:  epoch  0, batch   753 | loss: 2.7232881
MixupTrain:  epoch  0, batch   754 | loss: 2.3398182
MixupTrain:  epoch  0, batch   755 | loss: 2.7346148
MixupTrain:  epoch  0, batch   756 | loss: 2.5436907
MixupTrain:  epoch  0, batch   757 | loss: 2.5817528
MixupTrain:  epoch  0, batch   758 | loss: 2.5684209
MixupTrain:  epoch  0, batch   759 | loss: 2.2437363
MixupTrain:  epoch  0, batch   760 | loss: 2.3374391
MixupTrain:  epoch  0, batch   761 | loss: 2.5344665
MixupTrain:  epoch  0, batch   762 | loss: 2.5603120
MixupTrain:  epoch  0, batch   763 | loss: 2.2947028
MixupTrain:  epoch  0, batch   764 | loss: 2.7482612
MixupTrain:  epoch  0, batch   765 | loss: 2.3613982
MixupTrain:  epoch  0, batch   766 | loss: 2.3885841
MixupTrain:  epoch  0, batch   767 | loss: 2.2714248
MixupTrain:  epoch  0, batch   768 | loss: 2.5779352
MixupTrain:  epoch  0, batch   769 | loss: 2.1169114
MixupTrain:  epoch  0, batch   770 | loss: 2.0696530
MixupTrain:  epoch  0, batch   771 | loss: 2.2386708
MixupTrain:  epoch  0, batch   772 | loss: 2.4859228
MixupTrain:  epoch  0, batch   773 | loss: 2.4264297
MixupTrain:  epoch  0, batch   774 | loss: 2.1995883
MixupTrain:  epoch  0, batch   775 | loss: 2.5503328
MixupTrain:  epoch  0, batch   776 | loss: 2.5344944
MixupTrain:  epoch  0, batch   777 | loss: 2.8707314
MixupTrain:  epoch  0, batch   778 | loss: 2.3245816
MixupTrain:  epoch  0, batch   779 | loss: 2.3507009
MixupTrain:  epoch  0, batch   780 | loss: 2.3879855
MixupTrain:  epoch  0, batch   781 | loss: 2.6149340
MixupTrain:  epoch  0, batch   782 | loss: 2.4836581
MixupTrain:  epoch  0, batch   783 | loss: 2.6334758
MixupTrain:  epoch  0, batch   784 | loss: 2.4673061
MixupTrain:  epoch  0, batch   785 | loss: 2.3289371
MixupTrain:  epoch  0, batch   786 | loss: 2.8912339
MixupTrain:  epoch  0, batch   787 | loss: 2.1867185
MixupTrain:  epoch  0, batch   788 | loss: 2.7440829
MixupTrain:  epoch  0, batch   789 | loss: 2.3562436
MixupTrain:  epoch  0, batch   790 | loss: 2.6888719
MixupTrain:  epoch  0, batch   791 | loss: 2.8135624
MixupTrain:  epoch  0, batch   792 | loss: 2.6118698
MixupTrain:  epoch  0, batch   793 | loss: 2.9179716
MixupTrain:  epoch  0, batch   794 | loss: 2.3249016
MixupTrain:  epoch  0, batch   795 | loss: 2.5986962
MixupTrain:  epoch  0, batch   796 | loss: 2.4870002
MixupTrain:  epoch  0, batch   797 | loss: 2.9395742
MixupTrain:  epoch  0, batch   798 | loss: 2.3105180
MixupTrain:  epoch  0, batch   799 | loss: 2.5126195
MixupTrain:  epoch  0, batch   800 | loss: 2.4587376
MixupTrain:  epoch  0, batch   801 | loss: 2.2910943
MixupTrain:  epoch  0, batch   802 | loss: 2.7041245
MixupTrain:  epoch  0, batch   803 | loss: 2.7951484
MixupTrain:  epoch  0, batch   804 | loss: 2.3148308
MixupTrain:  epoch  0, batch   805 | loss: 2.3069153
MixupTrain:  epoch  0, batch   806 | loss: 2.6216760
MixupTrain:  epoch  0, batch   807 | loss: 2.2934320
MixupTrain:  epoch  0, batch   808 | loss: 2.2693329
MixupTrain:  epoch  0, batch   809 | loss: 2.2588465
MixupTrain:  epoch  0, batch   810 | loss: 2.4254532
MixupTrain:  epoch  0, batch   811 | loss: 2.1267087
MixupTrain:  epoch  0, batch   812 | loss: 2.4039969
MixupTrain:  epoch  0, batch   813 | loss: 2.6195931
MixupTrain:  epoch  0, batch   814 | loss: 2.4992862
MixupTrain:  epoch  0, batch   815 | loss: 2.3365836
MixupTrain:  epoch  0, batch   816 | loss: 2.2513442
MixupTrain:  epoch  0, batch   817 | loss: 2.4780269
MixupTrain:  epoch  0, batch   818 | loss: 2.3418250
MixupTrain:  epoch  0, batch   819 | loss: 2.8914075
MixupTrain:  epoch  0, batch   820 | loss: 2.4040794
MixupTrain:  epoch  0, batch   821 | loss: 2.5054383
MixupTrain:  epoch  0, batch   822 | loss: 2.7775328
MixupTrain:  epoch  0, batch   823 | loss: 2.6018009
MixupTrain:  epoch  0, batch   824 | loss: 2.2287748
MixupTrain:  epoch  0, batch   825 | loss: 2.6313481
MixupTrain:  epoch  0, batch   826 | loss: 2.8019309
MixupTrain:  epoch  0, batch   827 | loss: 2.4215415
MixupTrain:  epoch  0, batch   828 | loss: 2.2547493
MixupTrain:  epoch  0, batch   829 | loss: 2.4056463
MixupTrain:  epoch  0, batch   830 | loss: 2.4297938
MixupTrain:  epoch  0, batch   831 | loss: 2.3292127
MixupTrain:  epoch  0, batch   832 | loss: 2.5432830
MixupTrain:  epoch  0, batch   833 | loss: 2.5352082
MixupTrain:  epoch  0, batch   834 | loss: 2.5701821
MixupTrain:  epoch  0, batch   835 | loss: 2.4851866
MixupTrain:  epoch  0, batch   836 | loss: 2.4107625
MixupTrain:  epoch  0, batch   837 | loss: 2.6021299
MixupTrain:  epoch  0, batch   838 | loss: 2.7841129
MixupTrain:  epoch  0, batch   839 | loss: 2.5097005
MixupTrain:  epoch  0, batch   840 | loss: 2.8357692
MixupTrain:  epoch  0, batch   841 | loss: 2.4161403
MixupTrain:  epoch  0, batch   842 | loss: 2.4467311
MixupTrain:  epoch  0, batch   843 | loss: 2.4669199
MixupTrain:  epoch  0, batch   844 | loss: 2.4068530
MixupTrain:  epoch  0, batch   845 | loss: 2.7376256
MixupTrain:  epoch  0, batch   846 | loss: 2.5449610
MixupTrain:  epoch  0, batch   847 | loss: 2.3916779
MixupTrain:  epoch  0, batch   848 | loss: 2.4451294
MixupTrain:  epoch  0, batch   849 | loss: 2.3652959
MixupTrain:  epoch  0, batch   850 | loss: 2.5382738
MixupTrain:  epoch  0, batch   851 | loss: 2.4567704
MixupTrain:  epoch  0, batch   852 | loss: 2.5947702
MixupTrain:  epoch  0, batch   853 | loss: 2.5250001
MixupTrain:  epoch  0, batch   854 | loss: 2.3994169
MixupTrain:  epoch  0, batch   855 | loss: 2.4288654
MixupTrain:  epoch  0, batch   856 | loss: 2.4045436
MixupTrain:  epoch  0, batch   857 | loss: 2.7188153
MixupTrain:  epoch  0, batch   858 | loss: 2.1945817
MixupTrain:  epoch  0, batch   859 | loss: 2.1781311
MixupTrain:  epoch  0, batch   860 | loss: 2.8328929
MixupTrain:  epoch  0, batch   861 | loss: 2.5008411
MixupTrain:  epoch  0, batch   862 | loss: 2.2017500
MixupTrain:  epoch  0, batch   863 | loss: 2.4877429
MixupTrain:  epoch  0, batch   864 | loss: 2.2699075
MixupTrain:  epoch  0, batch   865 | loss: 2.7117343
MixupTrain:  epoch  0, batch   866 | loss: 2.6607189
MixupTrain:  epoch  0, batch   867 | loss: 2.1749554
MixupTrain:  epoch  0, batch   868 | loss: 2.4271638
MixupTrain:  epoch  0, batch   869 | loss: 2.3641419
MixupTrain:  epoch  0, batch   870 | loss: 2.5968335
MixupTrain:  epoch  0, batch   871 | loss: 2.9921074
MixupTrain:  epoch  0, batch   872 | loss: 2.1588900
MixupTrain:  epoch  0, batch   873 | loss: 2.9860139
MixupTrain:  epoch  0, batch   874 | loss: 2.5398712
MixupTrain:  epoch  0, batch   875 | loss: 2.2892053
MixupTrain:  epoch  0, batch   876 | loss: 2.4986839
MixupTrain:  epoch  0, batch   877 | loss: 2.7285678
MixupTrain:  epoch  0, batch   878 | loss: 2.6736355
MixupTrain:  epoch  0, batch   879 | loss: 2.7060022
MixupTrain:  epoch  0, batch   880 | loss: 2.5596287
MixupTrain:  epoch  0, batch   881 | loss: 2.4915934
MixupTrain:  epoch  0, batch   882 | loss: 2.5187616
MixupTrain:  epoch  0, batch   883 | loss: 2.5834916
MixupTrain:  epoch  0, batch   884 | loss: 2.4646320
MixupTrain:  epoch  0, batch   885 | loss: 2.7022696
MixupTrain:  epoch  0, batch   886 | loss: 2.5902755
MixupTrain:  epoch  0, batch   887 | loss: 2.7612514
MixupTrain:  epoch  0, batch   888 | loss: 2.6216702
MixupTrain:  epoch  0, batch   889 | loss: 2.3877990
MixupTrain:  epoch  0, batch   890 | loss: 2.3449323
MixupTrain:  epoch  0, batch   891 | loss: 2.0620570
MixupTrain:  epoch  0, batch   892 | loss: 2.1479924
MixupTrain:  epoch  0, batch   893 | loss: 2.5658484
MixupTrain:  epoch  0, batch   894 | loss: 2.1619911
MixupTrain:  epoch  0, batch   895 | loss: 2.2153261
MixupTrain:  epoch  0, batch   896 | loss: 2.5591688
MixupTrain:  epoch  0, batch   897 | loss: 2.8935425
MixupTrain:  epoch  0, batch   898 | loss: 2.6631274
MixupTrain:  epoch  0, batch   899 | loss: 2.8962188
MixupTrain:  epoch  0, batch   900 | loss: 2.2554550
MixupTrain:  epoch  0, batch   901 | loss: 2.9017072
MixupTrain:  epoch  0, batch   902 | loss: 2.4219694
MixupTrain:  epoch  0, batch   903 | loss: 2.5992465
MixupTrain:  epoch  0, batch   904 | loss: 2.6761220
MixupTrain:  epoch  0, batch   905 | loss: 2.1735172
MixupTrain:  epoch  0, batch   906 | loss: 2.2838483
MixupTrain:  epoch  0, batch   907 | loss: 2.8969250
MixupTrain:  epoch  0, batch   908 | loss: 2.0860186
MixupTrain:  epoch  0, batch   909 | loss: 2.2552176
MixupTrain:  epoch  0, batch   910 | loss: 2.3246164
MixupTrain:  epoch  0, batch   911 | loss: 2.3313980
MixupTrain:  epoch  0, batch   912 | loss: 2.2611332
MixupTrain:  epoch  0, batch   913 | loss: 2.4333179
MixupTrain:  epoch  0, batch   914 | loss: 2.6716197
MixupTrain:  epoch  0, batch   915 | loss: 2.6814382
MixupTrain:  epoch  0, batch   916 | loss: 2.5119650
MixupTrain:  epoch  0, batch   917 | loss: 2.0595422
MixupTrain:  epoch  0, batch   918 | loss: 2.3331800
MixupTrain:  epoch  0, batch   919 | loss: 2.4628978
MixupTrain:  epoch  0, batch   920 | loss: 2.5673676
MixupTrain:  epoch  0, batch   921 | loss: 2.5612965
MixupTrain:  epoch  0, batch   922 | loss: 2.3476396
MixupTrain:  epoch  0, batch   923 | loss: 2.2472463
MixupTrain:  epoch  0, batch   924 | loss: 2.5550714
MixupTrain:  epoch  0, batch   925 | loss: 2.4062557
MixupTrain:  epoch  0, batch   926 | loss: 2.7607541
MixupTrain:  epoch  0, batch   927 | loss: 2.1756086
MixupTrain:  epoch  0, batch   928 | loss: 2.5065842
MixupTrain:  epoch  0, batch   929 | loss: 2.3790727
MixupTrain:  epoch  0, batch   930 | loss: 2.3994732
MixupTrain:  epoch  0, batch   931 | loss: 2.8669357
MixupTrain:  epoch  0, batch   932 | loss: 2.5156512
MixupTrain:  epoch  0, batch   933 | loss: 2.4413896
MixupTrain:  epoch  0, batch   934 | loss: 2.9282563
MixupTrain:  epoch  0, batch   935 | loss: 2.3367848
MixupTrain:  epoch  0, batch   936 | loss: 2.4883480
MixupTrain:  epoch  0, batch   937 | loss: 2.3236721
MixupTrain:  epoch  0, batch   938 | loss: 2.3678238
MixupTrain:  epoch  0, batch   939 | loss: 2.4686389
MixupTrain:  epoch  0, batch   940 | loss: 2.6609588
MixupTrain:  epoch  0, batch   941 | loss: 2.7118025
MixupTrain:  epoch  0, batch   942 | loss: 2.3417089
MixupTrain:  epoch  0, batch   943 | loss: 2.4894967
MixupTrain:  epoch  0, batch   944 | loss: 2.6363437
MixupTrain:  epoch  0, batch   945 | loss: 2.5836892
MixupTrain:  epoch  0, batch   946 | loss: 2.4556522
MixupTrain:  epoch  0, batch   947 | loss: 2.4264240
MixupTrain:  epoch  0, batch   948 | loss: 2.8733068
MixupTrain:  epoch  0, batch   949 | loss: 2.7148304
MixupTrain:  epoch  0, batch   950 | loss: 2.2444267
MixupTrain:  epoch  0, batch   951 | loss: 2.4778793
MixupTrain:  epoch  0, batch   952 | loss: 2.5138001
MixupTrain:  epoch  0, batch   953 | loss: 2.4632478
MixupTrain:  epoch  0, batch   954 | loss: 2.3838191
MixupTrain:  epoch  0, batch   955 | loss: 2.2969058
MixupTrain:  epoch  0, batch   956 | loss: 2.5262277
MixupTrain:  epoch  0, batch   957 | loss: 2.7061608
MixupTrain:  epoch  0, batch   958 | loss: 2.3778040
MixupTrain:  epoch  0, batch   959 | loss: 2.1975436
MixupTrain:  epoch  0, batch   960 | loss: 2.4110460
MixupTrain:  epoch  0, batch   961 | loss: 2.2921209
MixupTrain:  epoch  0, batch   962 | loss: 2.3065305
MixupTrain:  epoch  0, batch   963 | loss: 2.4924932
MixupTrain:  epoch  0, batch   964 | loss: 2.1135726
MixupTrain:  epoch  0, batch   965 | loss: 2.5064583
MixupTrain:  epoch  0, batch   966 | loss: 2.2860887
MixupTrain:  epoch  0, batch   967 | loss: 2.4304626
MixupTrain:  epoch  0, batch   968 | loss: 2.3406878
MixupTrain:  epoch  0, batch   969 | loss: 2.1109803
MixupTrain:  epoch  0, batch   970 | loss: 1.9864753
MixupTrain:  epoch  0, batch   971 | loss: 2.5229731
MixupTrain:  epoch  0, batch   972 | loss: 2.3457971
MixupTrain:  epoch  0, batch   973 | loss: 2.2697053
MixupTrain:  epoch  0, batch   974 | loss: 2.9862742
MixupTrain:  epoch  0, batch   975 | loss: 2.2444563
MixupTrain:  epoch  0, batch   976 | loss: 2.3860836
MixupTrain:  epoch  0, batch   977 | loss: 2.4003663
MixupTrain:  epoch  0, batch   978 | loss: 2.5868835
MixupTrain:  epoch  0, batch   979 | loss: 2.5617914
MixupTrain:  epoch  0, batch   980 | loss: 2.5202818
MixupTrain:  epoch  0, batch   981 | loss: 2.2558439
MemoryTrain:  epoch  0, batch     0 | loss: 2.2469068
MemoryTrain:  epoch  0, batch     1 | loss: 3.3815172
MemoryTrain:  epoch  0, batch     2 | loss: 2.7209091
MemoryTrain:  epoch  0, batch     3 | loss: 2.4063535
MemoryTrain:  epoch  0, batch     4 | loss: 3.2177050
MemoryTrain:  epoch  0, batch     5 | loss: 2.1813989
MemoryTrain:  epoch  0, batch     6 | loss: 2.5584507
MemoryTrain:  epoch  0, batch     7 | loss: 2.1268673
MemoryTrain:  epoch  0, batch     8 | loss: 2.2817521
MemoryTrain:  epoch  0, batch     9 | loss: 2.2353578
MemoryTrain:  epoch  1, batch     0 | loss: 1.8379648
MemoryTrain:  epoch  1, batch     1 | loss: 1.9784687
MemoryTrain:  epoch  1, batch     2 | loss: 1.8495750
MemoryTrain:  epoch  1, batch     3 | loss: 1.8339859
MemoryTrain:  epoch  1, batch     4 | loss: 1.8532994
MemoryTrain:  epoch  1, batch     5 | loss: 1.8385966
MemoryTrain:  epoch  1, batch     6 | loss: 1.8572617
MemoryTrain:  epoch  1, batch     7 | loss: 1.8672247
MemoryTrain:  epoch  1, batch     8 | loss: 1.8597965
MemoryTrain:  epoch  1, batch     9 | loss: 1.8361429
MemoryTrain:  epoch  2, batch     0 | loss: 1.8257480
MemoryTrain:  epoch  2, batch     1 | loss: 1.8341998
MemoryTrain:  epoch  2, batch     2 | loss: 1.8341717
MemoryTrain:  epoch  2, batch     3 | loss: 1.8251350
MemoryTrain:  epoch  2, batch     4 | loss: 1.8684340
MemoryTrain:  epoch  2, batch     5 | loss: 1.8714657
MemoryTrain:  epoch  2, batch     6 | loss: 1.8253125
MemoryTrain:  epoch  2, batch     7 | loss: 1.8246760
MemoryTrain:  epoch  2, batch     8 | loss: 1.8296971
MemoryTrain:  epoch  2, batch     9 | loss: 1.8461884
MemoryTrain:  epoch  3, batch     0 | loss: 1.8175542
MemoryTrain:  epoch  3, batch     1 | loss: 1.8174777
MemoryTrain:  epoch  3, batch     2 | loss: 1.8213468
MemoryTrain:  epoch  3, batch     3 | loss: 1.8265448
MemoryTrain:  epoch  3, batch     4 | loss: 1.8239330
MemoryTrain:  epoch  3, batch     5 | loss: 1.8235792
MemoryTrain:  epoch  3, batch     6 | loss: 1.8272837
MemoryTrain:  epoch  3, batch     7 | loss: 1.8328261
MemoryTrain:  epoch  3, batch     8 | loss: 1.8224070
MemoryTrain:  epoch  3, batch     9 | loss: 1.8226761
MemoryTrain:  epoch  4, batch     0 | loss: 1.8268030
MemoryTrain:  epoch  4, batch     1 | loss: 1.8204463
MemoryTrain:  epoch  4, batch     2 | loss: 1.8258636
MemoryTrain:  epoch  4, batch     3 | loss: 1.8224137
MemoryTrain:  epoch  4, batch     4 | loss: 1.8244897
MemoryTrain:  epoch  4, batch     5 | loss: 1.8216941
MemoryTrain:  epoch  4, batch     6 | loss: 1.8209777
MemoryTrain:  epoch  4, batch     7 | loss: 1.8179961
MemoryTrain:  epoch  4, batch     8 | loss: 1.8258005
MemoryTrain:  epoch  4, batch     9 | loss: 1.8266896
MemoryTrain:  epoch  5, batch     0 | loss: 1.8279335
MemoryTrain:  epoch  5, batch     1 | loss: 1.8129051
MemoryTrain:  epoch  5, batch     2 | loss: 1.8185700
MemoryTrain:  epoch  5, batch     3 | loss: 1.8210733
MemoryTrain:  epoch  5, batch     4 | loss: 1.8234460
MemoryTrain:  epoch  5, batch     5 | loss: 1.8192664
MemoryTrain:  epoch  5, batch     6 | loss: 1.8234220
MemoryTrain:  epoch  5, batch     7 | loss: 1.8171849
MemoryTrain:  epoch  5, batch     8 | loss: 1.8322437
MemoryTrain:  epoch  5, batch     9 | loss: 1.8215349
MemoryTrain:  epoch  6, batch     0 | loss: 1.8190699
MemoryTrain:  epoch  6, batch     1 | loss: 1.8184587
MemoryTrain:  epoch  6, batch     2 | loss: 1.8356442
MemoryTrain:  epoch  6, batch     3 | loss: 1.8150638
MemoryTrain:  epoch  6, batch     4 | loss: 1.8306900
MemoryTrain:  epoch  6, batch     5 | loss: 1.8203095
MemoryTrain:  epoch  6, batch     6 | loss: 1.8290424
MemoryTrain:  epoch  6, batch     7 | loss: 1.8216853
MemoryTrain:  epoch  6, batch     8 | loss: 1.8217208
MemoryTrain:  epoch  6, batch     9 | loss: 1.8204653
MemoryTrain:  epoch  7, batch     0 | loss: 1.8257595
MemoryTrain:  epoch  7, batch     1 | loss: 1.8199036
MemoryTrain:  epoch  7, batch     2 | loss: 1.8165939
MemoryTrain:  epoch  7, batch     3 | loss: 1.8186748
MemoryTrain:  epoch  7, batch     4 | loss: 1.8258379
MemoryTrain:  epoch  7, batch     5 | loss: 1.8169394
MemoryTrain:  epoch  7, batch     6 | loss: 1.8220830
MemoryTrain:  epoch  7, batch     7 | loss: 1.8218143
MemoryTrain:  epoch  7, batch     8 | loss: 1.8198783
MemoryTrain:  epoch  7, batch     9 | loss: 1.8309743
MemoryTrain:  epoch  8, batch     0 | loss: 1.8204024
MemoryTrain:  epoch  8, batch     1 | loss: 1.8224366
MemoryTrain:  epoch  8, batch     2 | loss: 1.8289561
MemoryTrain:  epoch  8, batch     3 | loss: 1.8206210
MemoryTrain:  epoch  8, batch     4 | loss: 1.8182381
MemoryTrain:  epoch  8, batch     5 | loss: 1.8269811
MemoryTrain:  epoch  8, batch     6 | loss: 1.8265768
MemoryTrain:  epoch  8, batch     7 | loss: 1.8225788
MemoryTrain:  epoch  8, batch     8 | loss: 1.8168197
MemoryTrain:  epoch  8, batch     9 | loss: 1.8250175
MemoryTrain:  epoch  9, batch     0 | loss: 1.8147085
MemoryTrain:  epoch  9, batch     1 | loss: 1.8234688
MemoryTrain:  epoch  9, batch     2 | loss: 1.8227288
MemoryTrain:  epoch  9, batch     3 | loss: 1.8153238
MemoryTrain:  epoch  9, batch     4 | loss: 1.8171781
MemoryTrain:  epoch  9, batch     5 | loss: 1.8140547
MemoryTrain:  epoch  9, batch     6 | loss: 1.8131319
MemoryTrain:  epoch  9, batch     7 | loss: 1.8239696
MemoryTrain:  epoch  9, batch     8 | loss: 1.8158205
MemoryTrain:  epoch  9, batch     9 | loss: 1.8173361
[EVAL] batch:    0 | acc: 56.25%,  total acc: 56.25%   
[EVAL] batch:    1 | acc: 37.50%,  total acc: 46.88%   
[EVAL] batch:    2 | acc: 37.50%,  total acc: 43.75%   
[EVAL] batch:    3 | acc: 12.50%,  total acc: 35.94%   
[EVAL] batch:    4 | acc: 12.50%,  total acc: 31.25%   
[EVAL] batch:    5 | acc: 18.75%,  total acc: 29.17%   
[EVAL] batch:    6 | acc: 50.00%,  total acc: 32.14%   
[EVAL] batch:    7 | acc: 87.50%,  total acc: 39.06%   
[EVAL] batch:    8 | acc: 81.25%,  total acc: 43.75%   
[EVAL] batch:    9 | acc: 81.25%,  total acc: 47.50%   
[EVAL] batch:   10 | acc: 75.00%,  total acc: 50.00%   
[EVAL] batch:   11 | acc: 87.50%,  total acc: 53.12%   
[EVAL] batch:   12 | acc: 100.00%,  total acc: 56.73%   
[EVAL] batch:   13 | acc: 100.00%,  total acc: 59.82%   
[EVAL] batch:   14 | acc: 100.00%,  total acc: 62.50%   
[EVAL] batch:   15 | acc: 100.00%,  total acc: 64.84%   
[EVAL] batch:   16 | acc: 100.00%,  total acc: 66.91%   
[EVAL] batch:   17 | acc: 87.50%,  total acc: 68.06%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 67.76%   
[EVAL] batch:   19 | acc: 81.25%,  total acc: 68.44%   
[EVAL] batch:   20 | acc: 81.25%,  total acc: 69.05%   
[EVAL] batch:   21 | acc: 43.75%,  total acc: 67.90%   
[EVAL] batch:    0 | acc: 25.00%,  total acc: 25.00%   
[EVAL] batch:    1 | acc: 50.00%,  total acc: 37.50%   
[EVAL] batch:    2 | acc: 31.25%,  total acc: 35.42%   
[EVAL] batch:    3 | acc: 31.25%,  total acc: 34.38%   
[EVAL] batch:    4 | acc: 18.75%,  total acc: 31.25%   
[EVAL] batch:    5 | acc: 37.50%,  total acc: 32.29%   
[EVAL] batch:    6 | acc: 75.00%,  total acc: 38.39%   
[EVAL] batch:    7 | acc: 81.25%,  total acc: 43.75%   
[EVAL] batch:    8 | acc: 87.50%,  total acc: 48.61%   
[EVAL] batch:    9 | acc: 62.50%,  total acc: 50.00%   
[EVAL] batch:   10 | acc: 62.50%,  total acc: 51.14%   
[EVAL] batch:   11 | acc: 87.50%,  total acc: 54.17%   
[EVAL] batch:   12 | acc: 43.75%,  total acc: 53.37%   
[EVAL] batch:   13 | acc: 31.25%,  total acc: 51.79%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 53.33%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 53.52%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 54.78%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 55.21%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 55.59%   
[EVAL] batch:   19 | acc: 75.00%,  total acc: 56.56%   
[EVAL] batch:   20 | acc: 93.75%,  total acc: 58.33%   
[EVAL] batch:   21 | acc: 93.75%,  total acc: 59.94%   
[EVAL] batch:   22 | acc: 87.50%,  total acc: 61.14%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 62.76%   
[EVAL] batch:   24 | acc: 93.75%,  total acc: 64.00%   
[EVAL] batch:   25 | acc: 87.50%,  total acc: 64.90%   
[EVAL] batch:   26 | acc: 87.50%,  total acc: 65.74%   
[EVAL] batch:   27 | acc: 93.75%,  total acc: 66.74%   
[EVAL] batch:   28 | acc: 81.25%,  total acc: 67.24%   
[EVAL] batch:   29 | acc: 62.50%,  total acc: 67.08%   
[EVAL] batch:   30 | acc: 62.50%,  total acc: 66.94%   
[EVAL] batch:   31 | acc: 87.50%,  total acc: 67.58%   
[EVAL] batch:   32 | acc: 50.00%,  total acc: 67.05%   
[EVAL] batch:   33 | acc: 31.25%,  total acc: 65.99%   
[EVAL] batch:   34 | acc: 37.50%,  total acc: 65.18%   
[EVAL] batch:   35 | acc: 37.50%,  total acc: 64.41%   
[EVAL] batch:   36 | acc: 37.50%,  total acc: 63.68%   
[EVAL] batch:   37 | acc: 68.75%,  total acc: 63.82%   
[EVAL] batch:   38 | acc: 62.50%,  total acc: 63.78%   
[EVAL] batch:   39 | acc: 93.75%,  total acc: 64.53%   
[EVAL] batch:   40 | acc: 62.50%,  total acc: 64.48%   
[EVAL] batch:   41 | acc: 100.00%,  total acc: 65.33%   
[EVAL] batch:   42 | acc: 6.25%,  total acc: 63.95%   
[EVAL] batch:   43 | acc: 0.00%,  total acc: 62.50%   
[EVAL] batch:   44 | acc: 0.00%,  total acc: 61.11%   
[EVAL] batch:   45 | acc: 0.00%,  total acc: 59.78%   
[EVAL] batch:   46 | acc: 12.50%,  total acc: 58.78%   
[EVAL] batch:   47 | acc: 50.00%,  total acc: 58.59%   
[EVAL] batch:   48 | acc: 18.75%,  total acc: 57.78%   
[EVAL] batch:   49 | acc: 6.25%,  total acc: 56.75%   
[EVAL] batch:   50 | acc: 0.00%,  total acc: 55.64%   
[EVAL] batch:   51 | acc: 6.25%,  total acc: 54.69%   
[EVAL] batch:   52 | acc: 0.00%,  total acc: 53.66%   
[EVAL] batch:   53 | acc: 37.50%,  total acc: 53.36%   
[EVAL] batch:   54 | acc: 87.50%,  total acc: 53.98%   
[EVAL] batch:   55 | acc: 87.50%,  total acc: 54.58%   
[EVAL] batch:   56 | acc: 68.75%,  total acc: 54.82%   
[EVAL] batch:   57 | acc: 62.50%,  total acc: 54.96%   
[EVAL] batch:   58 | acc: 75.00%,  total acc: 55.30%   
[EVAL] batch:   59 | acc: 56.25%,  total acc: 55.31%   
[EVAL] batch:   60 | acc: 43.75%,  total acc: 55.12%   
[EVAL] batch:   61 | acc: 87.50%,  total acc: 55.65%   
[EVAL] batch:   62 | acc: 81.25%,  total acc: 56.05%   
[EVAL] batch:   63 | acc: 87.50%,  total acc: 56.54%   
[EVAL] batch:   64 | acc: 87.50%,  total acc: 57.02%   
[EVAL] batch:   65 | acc: 87.50%,  total acc: 57.48%   
[EVAL] batch:   66 | acc: 75.00%,  total acc: 57.74%   
[EVAL] batch:   67 | acc: 93.75%,  total acc: 58.27%   
[EVAL] batch:   68 | acc: 68.75%,  total acc: 58.42%   
[EVAL] batch:   69 | acc: 43.75%,  total acc: 58.21%   
[EVAL] batch:   70 | acc: 62.50%,  total acc: 58.27%   
[EVAL] batch:   71 | acc: 68.75%,  total acc: 58.42%   
[EVAL] batch:   72 | acc: 100.00%,  total acc: 58.99%   
[EVAL] batch:   73 | acc: 100.00%,  total acc: 59.54%   
[EVAL] batch:   74 | acc: 100.00%,  total acc: 60.08%   
[EVAL] batch:   75 | acc: 100.00%,  total acc: 60.61%   
[EVAL] batch:   76 | acc: 100.00%,  total acc: 61.12%   
[EVAL] batch:   77 | acc: 81.25%,  total acc: 61.38%   
[EVAL] batch:   78 | acc: 50.00%,  total acc: 61.23%   
[EVAL] batch:   79 | acc: 43.75%,  total acc: 61.02%   
[EVAL] batch:   80 | acc: 25.00%,  total acc: 60.57%   
[EVAL] batch:   81 | acc: 12.50%,  total acc: 59.98%   
[EVAL] batch:   82 | acc: 18.75%,  total acc: 59.49%   
[EVAL] batch:   83 | acc: 18.75%,  total acc: 59.00%   
[EVAL] batch:   84 | acc: 68.75%,  total acc: 59.12%   
[EVAL] batch:   85 | acc: 81.25%,  total acc: 59.38%   
[EVAL] batch:   86 | acc: 81.25%,  total acc: 59.63%   
[EVAL] batch:   87 | acc: 87.50%,  total acc: 59.94%   
[EVAL] batch:   88 | acc: 68.75%,  total acc: 60.04%   
[EVAL] batch:   89 | acc: 93.75%,  total acc: 60.42%   
[EVAL] batch:   90 | acc: 100.00%,  total acc: 60.85%   
[EVAL] batch:   91 | acc: 100.00%,  total acc: 61.28%   
[EVAL] batch:   92 | acc: 100.00%,  total acc: 61.69%   
[EVAL] batch:   93 | acc: 100.00%,  total acc: 62.10%   
[EVAL] batch:   94 | acc: 93.75%,  total acc: 62.43%   
[EVAL] batch:   95 | acc: 87.50%,  total acc: 62.70%   
[EVAL] batch:   96 | acc: 68.75%,  total acc: 62.76%   
[EVAL] batch:   97 | acc: 75.00%,  total acc: 62.88%   
[EVAL] batch:   98 | acc: 87.50%,  total acc: 63.13%   
[EVAL] batch:   99 | acc: 18.75%,  total acc: 62.69%   
cur_acc:  ['0.8580', '0.8625', '0.8393', '0.8993', '0.6790']
his_acc:  ['0.8580', '0.8351', '0.7490', '0.6538', '0.6269']
CurrentTrain: epoch  0, batch     0 | loss: 6.6580276
CurrentTrain: epoch  0, batch     1 | loss: 8.8041353
CurrentTrain: epoch  1, batch     0 | loss: 6.2829943
CurrentTrain: epoch  1, batch     1 | loss: 5.8882465
CurrentTrain: epoch  2, batch     0 | loss: 4.7905951
CurrentTrain: epoch  2, batch     1 | loss: 5.2390618
CurrentTrain: epoch  3, batch     0 | loss: 5.4372559
CurrentTrain: epoch  3, batch     1 | loss: 2.4967597
CurrentTrain: epoch  4, batch     0 | loss: 3.2811387
CurrentTrain: epoch  4, batch     1 | loss: 5.5035119
CurrentTrain: epoch  5, batch     0 | loss: 4.6653376
CurrentTrain: epoch  5, batch     1 | loss: 2.7037270
CurrentTrain: epoch  6, batch     0 | loss: 3.4414473
CurrentTrain: epoch  6, batch     1 | loss: 3.8719749
CurrentTrain: epoch  7, batch     0 | loss: 2.8273628
CurrentTrain: epoch  7, batch     1 | loss: 3.2595799
CurrentTrain: epoch  8, batch     0 | loss: 2.4780440
CurrentTrain: epoch  8, batch     1 | loss: 2.4178233
CurrentTrain: epoch  9, batch     0 | loss: 2.3948910
CurrentTrain: epoch  9, batch     1 | loss: 2.3012476
#### person country of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person country of birth" means a person was born in a country.
Here is an example:
Relation: person country of birth
Context: iran 's atomic chief ali akbar salehi has expressed tehran 's readiness to swap 1,200 kilogrammes -lrb- 2,640 pounds -rrb- of low-enriched uranium -lrb- leu -rrb- in one-shot for enriched atomic fuel .
Head Entity: ali akbar salehi
Tail Entity: iran
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person country of birth":
Relation: person country of birth  
Context: renowned physicist stephen hawking was born in oxford, england, where he later pursued his studies.  
Head Entity: stephen hawking  
Tail Entity: england  

Relation: person country of birth  
Context: actress natalie portman, who was born in jerusalem, has often spoken about her dual citizenship in israel and the united states.  
Head Entity: natalie portman  
Tail Entity: israel  

Relation: person country of birth  
Context: the famous author mark twain was born in florida, missouri, which greatly influenced his writing style and themes.  
Head Entity: mark twain  
Tail Entity: missouri  

Relation: person country of birth  
Context: the legendary musician freddie mercury was born in zanzibar, which is now part of tanzania, before moving to england.  
Head Entity: freddie mercury  
Tail Entity: tanzania  

Relation: person country of birth  
Context: the celebrated painter pablo picasso was born in malaga, spain, where he developed his early artistic skills.  
Head Entity: pablo picasso  
Tail Entity: spain  
#### organization website ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization website" means an organization 's website is an url.
Here is an example:
Relation: organization website
Context: 11.30.08 2008 cma awards red carpet special http://www.cmt.com/shows/dyn/2008-cma-awards-red-carpet/1/episode.jhtml
Head Entity: cma
Tail Entity: http://www.cmt.com/shows/dyn/2008-cma-awards-red-carpet/1/episode.jhtml
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization website":
Relation: organization website  
Context: The official site for the World Wildlife Fund is located at https://www.worldwildlife.org.  
Head Entity: World Wildlife Fund  
Tail Entity: https://www.worldwildlife.org  

Relation: organization website  
Context: For more information about the American Red Cross, visit their website at https://www.redcross.org.  
Head Entity: American Red Cross  
Tail Entity: https://www.redcross.org  

Relation: organization website  
Context: You can find the latest updates from NASA on their official website: https://www.nasa.gov.  
Head Entity: NASA  
Tail Entity: https://www.nasa.gov  

Relation: organization website  
Context: The website for the United Nations is accessible at https://www.un.org.  
Head Entity: United Nations  
Tail Entity: https://www.un.org  

Relation: organization website  
Context: Check out the official website of the National Geographic Society at https://www.nationalgeographic.org.  
Head Entity: National Geographic Society  
Tail Entity: https://www.nationalgeographic.org  
#### organization shareholders ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization shareholders" means an organization was invested by a person.
Here is an example:
Relation: organization shareholders
Context: marsans already owns the madrid-based air comet and 95 percent of aerolineas argentinas .
Head Entity: aerolineas argentinas
Tail Entity: marsans
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization shareholders":
Relation: organization shareholders  
Context: tech giant Apple has seen significant investments from Warren Buffett's Berkshire Hathaway.  
Head Entity: Apple  
Tail Entity: Berkshire Hathaway  

Relation: organization shareholders  
Context: The investment firm Vanguard Group has acquired a substantial stake in the renewable energy company NextEra Energy.  
Head Entity: NextEra Energy  
Tail Entity: Vanguard Group  

Relation: organization shareholders  
Context: Tesla's stock has attracted attention from various investors, including the well-known hedge fund manager Cathie Wood.  
Head Entity: Tesla  
Tail Entity: Cathie Wood  

Relation: organization shareholders  
Context: The pharmaceutical company Pfizer has received funding from the investment group BlackRock to expand its research initiatives.  
Head Entity: Pfizer  
Tail Entity: BlackRock  

Relation: organization shareholders  
Context: The social media platform Facebook has been heavily invested in by Mark Zuckerberg and other venture capitalists.  
Head Entity: Facebook  
Tail Entity: Mark Zuckerberg  
#### organization dissolved ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization dissolved" means an organization was dissolved in a date.
Here is an example:
Relation: organization dissolved
Context: the tse suffered its worst-ever system crash in november 2005 which paralyzed the world 's second largest bourse and forced it to shelve plan for a listing of its own .
Head Entity: tse
Tail Entity: november 2005
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization dissolved":
Relation: organization dissolved  
Context: The once-prominent tech startup, Innovatech, officially ceased operations in March 2020 after struggling to secure funding.  
Head Entity: Innovatech  
Tail Entity: March 2020  

Relation: organization dissolved  
Context: After years of financial difficulties, the local arts council announced its dissolution in January 2019, leaving many artists without support.  
Head Entity: local arts council  
Tail Entity: January 2019  

Relation: organization dissolved  
Context: The historic bookstore, Pages & Co., closed its doors for good in July 2021, marking the end of an era for the community.  
Head Entity: Pages & Co.  
Tail Entity: July 2021  

Relation: organization dissolved  
Context: Following a series of scandals, the charity organization, Helping Hands, was officially dissolved in February 2022.  
Head Entity: Helping Hands  
Tail Entity: February 2022  

Relation: organization dissolved  
Context: The environmental group, Green Future, announced its dissolution in October 2023 due to a lack of funding and support.  
Head Entity: Green Future  
Tail Entity: October 2023  
#### organization founded by ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization founded by" means an organization was found by a person.
Here is an example:
Relation: organization founded by
Context: `` i have no greater obligation than to ensure the safely of airline travelers in this country , '' transportation secretary ray lahood said in a joint statement with j. randolph babbitt , administrator of the federal aviation administration , that was issued on the eve of a senate hearing on aviation safety .
Head Entity: federal aviation administration
Tail Entity: j. randolph babbitt
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization founded by":
Relation: organization founded by  
Context: In 1975, the renowned physicist and entrepreneur, Dr. John Smith, established Quantum Innovations, a company dedicated to advancing quantum computing technologies.  
Head Entity: Quantum Innovations  
Tail Entity: Dr. John Smith  

Relation: organization founded by  
Context: The charity organization, Helping Hands, was created in 2010 by the well-known philanthropist, Sarah Johnson, to support underprivileged children.  
Head Entity: Helping Hands  
Tail Entity: Sarah Johnson  

Relation: organization founded by  
Context: In the heart of Silicon Valley, Tech Pioneers was launched in 2018 by a group of innovative engineers led by Michael Chen, aiming to revolutionize the tech industry.  
Head Entity: Tech Pioneers  
Tail Entity: Michael Chen  

Relation: organization founded by  
Context: The environmental group, Green Future, was founded in 2005 by activist Laura Green to combat climate change and promote sustainability.  
Head Entity: Green Future  
Tail Entity: Laura Green  

Relation: organization founded by  
Context: The prestigious art gallery, Modern Visions, was established in 1999 by renowned artist and curator, Emily Carter, to showcase contemporary art.  
Head Entity: Modern Visions  
Tail Entity: Emily Carter  
Mixup data size:  21490
MixupTrain:  epoch  0, batch     0 | loss: 5.0607252
MixupTrain:  epoch  0, batch     1 | loss: 4.3146901
MixupTrain:  epoch  0, batch     2 | loss: 4.8530831
MixupTrain:  epoch  0, batch     3 | loss: 2.9621267
MixupTrain:  epoch  0, batch     4 | loss: 3.9906831
MixupTrain:  epoch  0, batch     5 | loss: 4.2013054
MixupTrain:  epoch  0, batch     6 | loss: 3.9008703
MixupTrain:  epoch  0, batch     7 | loss: 3.2928305
MixupTrain:  epoch  0, batch     8 | loss: 3.2864759
MixupTrain:  epoch  0, batch     9 | loss: 3.5768552
MixupTrain:  epoch  0, batch    10 | loss: 3.8445554
MixupTrain:  epoch  0, batch    11 | loss: 3.4433243
MixupTrain:  epoch  0, batch    12 | loss: 3.6838388
MixupTrain:  epoch  0, batch    13 | loss: 4.2078805
MixupTrain:  epoch  0, batch    14 | loss: 3.5828609
MixupTrain:  epoch  0, batch    15 | loss: 3.3329022
MixupTrain:  epoch  0, batch    16 | loss: 3.8822877
MixupTrain:  epoch  0, batch    17 | loss: 3.3682241
MixupTrain:  epoch  0, batch    18 | loss: 4.1598911
MixupTrain:  epoch  0, batch    19 | loss: 4.0919142
MixupTrain:  epoch  0, batch    21 | loss: 2.9992447
MixupTrain:  epoch  0, batch    22 | loss: 4.1352053
MixupTrain:  epoch  0, batch    23 | loss: 3.1400888
MixupTrain:  epoch  0, batch    24 | loss: 3.2936511
MixupTrain:  epoch  0, batch    25 | loss: 3.5921490
MixupTrain:  epoch  0, batch    26 | loss: 3.8976038
MixupTrain:  epoch  0, batch    27 | loss: 3.6915200
MixupTrain:  epoch  0, batch    29 | loss: 2.8812246
MixupTrain:  epoch  0, batch    30 | loss: 3.1342888
MixupTrain:  epoch  0, batch    31 | loss: 3.2633510
MixupTrain:  epoch  0, batch    32 | loss: 2.7280545
MixupTrain:  epoch  0, batch    33 | loss: 2.7008245
MixupTrain:  epoch  0, batch    34 | loss: 3.1020432
MixupTrain:  epoch  0, batch    35 | loss: 3.1585364
MixupTrain:  epoch  0, batch    36 | loss: 3.3111658
MixupTrain:  epoch  0, batch    37 | loss: 3.4940920
MixupTrain:  epoch  0, batch    38 | loss: 3.5936708
MixupTrain:  epoch  0, batch    39 | loss: 2.9772739
MixupTrain:  epoch  0, batch    40 | loss: 3.4892423
MixupTrain:  epoch  0, batch    41 | loss: 3.5291631
MixupTrain:  epoch  0, batch    42 | loss: 3.3380859
MixupTrain:  epoch  0, batch    43 | loss: 3.7760196
MixupTrain:  epoch  0, batch    44 | loss: 2.6698751
MixupTrain:  epoch  0, batch    45 | loss: 3.9425492
MixupTrain:  epoch  0, batch    46 | loss: 3.9973819
MixupTrain:  epoch  0, batch    47 | loss: 3.3373713
MixupTrain:  epoch  0, batch    48 | loss: 4.0038910
MixupTrain:  epoch  0, batch    50 | loss: 3.2502029
MixupTrain:  epoch  0, batch    51 | loss: 3.1137214
MixupTrain:  epoch  0, batch    53 | loss: 2.3449733
MixupTrain:  epoch  0, batch    54 | loss: 4.0421872
MixupTrain:  epoch  0, batch    55 | loss: 2.9836984
MixupTrain:  epoch  0, batch    56 | loss: 2.1563804
MixupTrain:  epoch  0, batch    57 | loss: 2.0352256
MixupTrain:  epoch  0, batch    58 | loss: 2.8559735
MixupTrain:  epoch  0, batch    59 | loss: 3.2995219
MixupTrain:  epoch  0, batch    60 | loss: 3.1812787
MixupTrain:  epoch  0, batch    61 | loss: 3.5380716
MixupTrain:  epoch  0, batch    64 | loss: 2.9353228
MixupTrain:  epoch  0, batch    66 | loss: 2.6913157
MixupTrain:  epoch  0, batch    67 | loss: 2.5521693
MixupTrain:  epoch  0, batch    68 | loss: 2.4589455
MixupTrain:  epoch  0, batch    69 | loss: 3.5848937
MixupTrain:  epoch  0, batch    70 | loss: 2.3518891
MixupTrain:  epoch  0, batch    72 | loss: 2.3224912
MixupTrain:  epoch  0, batch    73 | loss: 3.0740008
MixupTrain:  epoch  0, batch    75 | loss: 3.2726648
MixupTrain:  epoch  0, batch    77 | loss: 2.3598678
MixupTrain:  epoch  0, batch    78 | loss: 2.9503775
MixupTrain:  epoch  0, batch    80 | loss: 2.7701368
MixupTrain:  epoch  0, batch    81 | loss: 2.8181486
MixupTrain:  epoch  0, batch    83 | loss: 2.5000994
MixupTrain:  epoch  0, batch    84 | loss: 2.8382845
MixupTrain:  epoch  0, batch    85 | loss: 2.4962029
MixupTrain:  epoch  0, batch    86 | loss: 3.4868879
MixupTrain:  epoch  0, batch    87 | loss: 2.9387355
MixupTrain:  epoch  0, batch    88 | loss: 2.0214303
MixupTrain:  epoch  0, batch    89 | loss: 2.4140472
MixupTrain:  epoch  0, batch    90 | loss: 2.4576705
MixupTrain:  epoch  0, batch    91 | loss: 2.7973242
MixupTrain:  epoch  0, batch    92 | loss: 3.0166774
MixupTrain:  epoch  0, batch    93 | loss: 2.7972922
MixupTrain:  epoch  0, batch    94 | loss: 2.9147105
MixupTrain:  epoch  0, batch    96 | loss: 2.5797763
MixupTrain:  epoch  0, batch    97 | loss: 2.8705401
MixupTrain:  epoch  0, batch    98 | loss: 2.2391691
MixupTrain:  epoch  0, batch    99 | loss: 2.3750334
MixupTrain:  epoch  0, batch   100 | loss: 3.0108318
MixupTrain:  epoch  0, batch   101 | loss: 2.5468826
MixupTrain:  epoch  0, batch   102 | loss: 2.4181211
MixupTrain:  epoch  0, batch   103 | loss: 2.6872640
MixupTrain:  epoch  0, batch   104 | loss: 2.5258880
MixupTrain:  epoch  0, batch   105 | loss: 2.4878559
MixupTrain:  epoch  0, batch   107 | loss: 2.8900294
MixupTrain:  epoch  0, batch   108 | loss: 2.6964974
MixupTrain:  epoch  0, batch   109 | loss: 2.4110692
MixupTrain:  epoch  0, batch   110 | loss: 2.6518111
MixupTrain:  epoch  0, batch   111 | loss: 2.9564767
MixupTrain:  epoch  0, batch   112 | loss: 2.3771660
MixupTrain:  epoch  0, batch   113 | loss: 2.6642075
MixupTrain:  epoch  0, batch   114 | loss: 2.9010217
MixupTrain:  epoch  0, batch   116 | loss: 2.5106611
MixupTrain:  epoch  0, batch   117 | loss: 2.8494661
MixupTrain:  epoch  0, batch   119 | loss: 2.3187964
MixupTrain:  epoch  0, batch   121 | loss: 2.3541167
MixupTrain:  epoch  0, batch   122 | loss: 2.7276416
MixupTrain:  epoch  0, batch   123 | loss: 2.9887538
MixupTrain:  epoch  0, batch   124 | loss: 2.5144382
MixupTrain:  epoch  0, batch   125 | loss: 2.0560055
MixupTrain:  epoch  0, batch   126 | loss: 2.4415770
MixupTrain:  epoch  0, batch   127 | loss: 3.0678008
MixupTrain:  epoch  0, batch   128 | loss: 2.4990337
MixupTrain:  epoch  0, batch   129 | loss: 2.9120116
MixupTrain:  epoch  0, batch   130 | loss: 2.4521937
MixupTrain:  epoch  0, batch   131 | loss: 2.5636158
MixupTrain:  epoch  0, batch   133 | loss: 2.8014107
MixupTrain:  epoch  0, batch   134 | loss: 3.1125655
MixupTrain:  epoch  0, batch   135 | loss: 2.1623478
MixupTrain:  epoch  0, batch   136 | loss: 2.4727445
MixupTrain:  epoch  0, batch   137 | loss: 2.8924263
MixupTrain:  epoch  0, batch   138 | loss: 2.4368238
MixupTrain:  epoch  0, batch   139 | loss: 2.3529339
MixupTrain:  epoch  0, batch   141 | loss: 2.2181540
MixupTrain:  epoch  0, batch   142 | loss: 2.5335641
MixupTrain:  epoch  0, batch   143 | loss: 2.6925611
MixupTrain:  epoch  0, batch   144 | loss: 2.4954371
MixupTrain:  epoch  0, batch   145 | loss: 2.4761128
MixupTrain:  epoch  0, batch   146 | loss: 2.2833066
MixupTrain:  epoch  0, batch   147 | loss: 2.5657206
MixupTrain:  epoch  0, batch   148 | loss: 2.1932650
MixupTrain:  epoch  0, batch   149 | loss: 2.7641754
MixupTrain:  epoch  0, batch   151 | loss: 1.9696025
MixupTrain:  epoch  0, batch   152 | loss: 2.5846586
MixupTrain:  epoch  0, batch   153 | loss: 2.7178533
MixupTrain:  epoch  0, batch   154 | loss: 2.3186345
MixupTrain:  epoch  0, batch   155 | loss: 2.9091117
MixupTrain:  epoch  0, batch   156 | loss: 2.2321293
MixupTrain:  epoch  0, batch   157 | loss: 2.2817583
MixupTrain:  epoch  0, batch   158 | loss: 2.7409420
MixupTrain:  epoch  0, batch   159 | loss: 2.7803891
MixupTrain:  epoch  0, batch   160 | loss: 2.3221216
MixupTrain:  epoch  0, batch   162 | loss: 2.4348040
MixupTrain:  epoch  0, batch   163 | loss: 2.4626751
MixupTrain:  epoch  0, batch   164 | loss: 2.3932877
MixupTrain:  epoch  0, batch   165 | loss: 2.1408837
MixupTrain:  epoch  0, batch   166 | loss: 2.4413633
MixupTrain:  epoch  0, batch   167 | loss: 2.5896347
MixupTrain:  epoch  0, batch   168 | loss: 2.5516734
MixupTrain:  epoch  0, batch   169 | loss: 2.6956043
MixupTrain:  epoch  0, batch   170 | loss: 2.6127415
MixupTrain:  epoch  0, batch   172 | loss: 2.4360924
MixupTrain:  epoch  0, batch   173 | loss: 3.0446596
MixupTrain:  epoch  0, batch   175 | loss: 2.3649421
MixupTrain:  epoch  0, batch   176 | loss: 2.3791528
MixupTrain:  epoch  0, batch   177 | loss: 2.4643335
MixupTrain:  epoch  0, batch   178 | loss: 2.8290348
MixupTrain:  epoch  0, batch   180 | loss: 2.4451354
MixupTrain:  epoch  0, batch   181 | loss: 1.9636731
MixupTrain:  epoch  0, batch   182 | loss: 2.3785241
MixupTrain:  epoch  0, batch   183 | loss: 2.0700784
MixupTrain:  epoch  0, batch   184 | loss: 2.2557209
MixupTrain:  epoch  0, batch   185 | loss: 2.5033243
MixupTrain:  epoch  0, batch   186 | loss: 2.5469635
MixupTrain:  epoch  0, batch   187 | loss: 2.6792483
MixupTrain:  epoch  0, batch   188 | loss: 2.4660411
MixupTrain:  epoch  0, batch   189 | loss: 2.9348917
MixupTrain:  epoch  0, batch   190 | loss: 2.2206302
MixupTrain:  epoch  0, batch   192 | loss: 2.4325814
MixupTrain:  epoch  0, batch   194 | loss: 2.3690834
MixupTrain:  epoch  0, batch   195 | loss: 2.6171381
MixupTrain:  epoch  0, batch   196 | loss: 2.1293397
MixupTrain:  epoch  0, batch   197 | loss: 2.3070540
MixupTrain:  epoch  0, batch   198 | loss: 2.2695389
MixupTrain:  epoch  0, batch   199 | loss: 2.3630939
MixupTrain:  epoch  0, batch   200 | loss: 2.1620345
MixupTrain:  epoch  0, batch   202 | loss: 2.4681399
MixupTrain:  epoch  0, batch   203 | loss: 2.3535957
MixupTrain:  epoch  0, batch   204 | loss: 2.5349340
MixupTrain:  epoch  0, batch   205 | loss: 2.3860989
MixupTrain:  epoch  0, batch   206 | loss: 2.1723742
MixupTrain:  epoch  0, batch   207 | loss: 2.7035375
MixupTrain:  epoch  0, batch   208 | loss: 2.3550239
MixupTrain:  epoch  0, batch   209 | loss: 2.4806528
MixupTrain:  epoch  0, batch   211 | loss: 2.6448176
MixupTrain:  epoch  0, batch   212 | loss: 2.8340735
MixupTrain:  epoch  0, batch   214 | loss: 2.9504294
MixupTrain:  epoch  0, batch   215 | loss: 1.9446254
MixupTrain:  epoch  0, batch   216 | loss: 2.4886410
MixupTrain:  epoch  0, batch   217 | loss: 2.6841240
MixupTrain:  epoch  0, batch   218 | loss: 2.8690395
MixupTrain:  epoch  0, batch   220 | loss: 2.8472340
MixupTrain:  epoch  0, batch   222 | loss: 2.1028941
MixupTrain:  epoch  0, batch   223 | loss: 2.2641120
MixupTrain:  epoch  0, batch   224 | loss: 2.7323630
MixupTrain:  epoch  0, batch   225 | loss: 2.1408768
MixupTrain:  epoch  0, batch   226 | loss: 2.3598232
MixupTrain:  epoch  0, batch   227 | loss: 2.7545571
MixupTrain:  epoch  0, batch   228 | loss: 2.7169414
MixupTrain:  epoch  0, batch   229 | loss: 2.5146554
MixupTrain:  epoch  0, batch   230 | loss: 1.9751381
MixupTrain:  epoch  0, batch   231 | loss: 2.6955161
MixupTrain:  epoch  0, batch   232 | loss: 2.6073241
MixupTrain:  epoch  0, batch   233 | loss: 2.3405559
MixupTrain:  epoch  0, batch   234 | loss: 2.2180381
MixupTrain:  epoch  0, batch   235 | loss: 2.4871879
MixupTrain:  epoch  0, batch   236 | loss: 2.0532644
MixupTrain:  epoch  0, batch   237 | loss: 2.7725968
MixupTrain:  epoch  0, batch   240 | loss: 2.4874105
MixupTrain:  epoch  0, batch   241 | loss: 2.2289934
MixupTrain:  epoch  0, batch   242 | loss: 2.3462551
MixupTrain:  epoch  0, batch   243 | loss: 2.6046681
MixupTrain:  epoch  0, batch   244 | loss: 2.4770093
MixupTrain:  epoch  0, batch   245 | loss: 2.4714346
MixupTrain:  epoch  0, batch   246 | loss: 2.2092185
MixupTrain:  epoch  0, batch   247 | loss: 2.3272247
MixupTrain:  epoch  0, batch   248 | loss: 2.4652262
MixupTrain:  epoch  0, batch   249 | loss: 2.0743799
MixupTrain:  epoch  0, batch   250 | loss: 2.1186907
MixupTrain:  epoch  0, batch   251 | loss: 2.5759821
MixupTrain:  epoch  0, batch   252 | loss: 2.3581109
MixupTrain:  epoch  0, batch   253 | loss: 2.2269640
MixupTrain:  epoch  0, batch   254 | loss: 2.6248889
MixupTrain:  epoch  0, batch   255 | loss: 2.3016865
MixupTrain:  epoch  0, batch   256 | loss: 2.6279228
MixupTrain:  epoch  0, batch   257 | loss: 2.5086598
MixupTrain:  epoch  0, batch   258 | loss: 2.6734476
MixupTrain:  epoch  0, batch   259 | loss: 2.2718611
MixupTrain:  epoch  0, batch   260 | loss: 2.3876257
MixupTrain:  epoch  0, batch   261 | loss: 2.4957263
MixupTrain:  epoch  0, batch   262 | loss: 2.5550776
MixupTrain:  epoch  0, batch   263 | loss: 2.6171470
MixupTrain:  epoch  0, batch   265 | loss: 2.6515572
MixupTrain:  epoch  0, batch   266 | loss: 2.5897040
MixupTrain:  epoch  0, batch   267 | loss: 2.3191519
MixupTrain:  epoch  0, batch   270 | loss: 2.7055407
MixupTrain:  epoch  0, batch   271 | loss: 2.0073590
MixupTrain:  epoch  0, batch   272 | loss: 2.4543605
MixupTrain:  epoch  0, batch   273 | loss: 2.3031089
MixupTrain:  epoch  0, batch   276 | loss: 2.0660291
MixupTrain:  epoch  0, batch   277 | loss: 2.4791794
MixupTrain:  epoch  0, batch   278 | loss: 2.7757540
MixupTrain:  epoch  0, batch   279 | loss: 2.2458112
MixupTrain:  epoch  0, batch   280 | loss: 2.9205880
MixupTrain:  epoch  0, batch   283 | loss: 1.9993696
MixupTrain:  epoch  0, batch   284 | loss: 2.2456274
MixupTrain:  epoch  0, batch   285 | loss: 2.4346256
MixupTrain:  epoch  0, batch   286 | loss: 2.8690968
MixupTrain:  epoch  0, batch   288 | loss: 2.1427855
MixupTrain:  epoch  0, batch   289 | loss: 2.3628924
MixupTrain:  epoch  0, batch   291 | loss: 2.4535310
MixupTrain:  epoch  0, batch   292 | loss: 2.8533080
MixupTrain:  epoch  0, batch   293 | loss: 2.3023477
MixupTrain:  epoch  0, batch   294 | loss: 2.5864506
MixupTrain:  epoch  0, batch   295 | loss: 2.4684374
MixupTrain:  epoch  0, batch   296 | loss: 2.3140213
MixupTrain:  epoch  0, batch   297 | loss: 2.5248864
MixupTrain:  epoch  0, batch   299 | loss: 2.4254735
MixupTrain:  epoch  0, batch   300 | loss: 2.2210512
MixupTrain:  epoch  0, batch   301 | loss: 2.7070389
MixupTrain:  epoch  0, batch   303 | loss: 2.4874816
MixupTrain:  epoch  0, batch   304 | loss: 2.4778066
MixupTrain:  epoch  0, batch   305 | loss: 2.7549376
MixupTrain:  epoch  0, batch   306 | loss: 2.3773875
MixupTrain:  epoch  0, batch   307 | loss: 2.6290226
MixupTrain:  epoch  0, batch   308 | loss: 2.4510684
MixupTrain:  epoch  0, batch   309 | loss: 2.1305666
MixupTrain:  epoch  0, batch   310 | loss: 2.3388910
MixupTrain:  epoch  0, batch   311 | loss: 2.4320688
MixupTrain:  epoch  0, batch   312 | loss: 2.2773721
MixupTrain:  epoch  0, batch   313 | loss: 2.9192989
MixupTrain:  epoch  0, batch   314 | loss: 2.6758718
MixupTrain:  epoch  0, batch   315 | loss: 2.2683897
MixupTrain:  epoch  0, batch   316 | loss: 2.0706391
MixupTrain:  epoch  0, batch   317 | loss: 2.0822201
MixupTrain:  epoch  0, batch   318 | loss: 2.6357000
MixupTrain:  epoch  0, batch   319 | loss: 2.3851690
MixupTrain:  epoch  0, batch   320 | loss: 2.5101228
MixupTrain:  epoch  0, batch   321 | loss: 2.2526431
MixupTrain:  epoch  0, batch   322 | loss: 2.4935670
MixupTrain:  epoch  0, batch   324 | loss: 2.3808858
MixupTrain:  epoch  0, batch   325 | loss: 2.5898361
MixupTrain:  epoch  0, batch   326 | loss: 2.4215028
MixupTrain:  epoch  0, batch   328 | loss: 2.3887515
MixupTrain:  epoch  0, batch   330 | loss: 2.3592050
MixupTrain:  epoch  0, batch   331 | loss: 2.5709171
MixupTrain:  epoch  0, batch   332 | loss: 2.3979874
MixupTrain:  epoch  0, batch   333 | loss: 2.1248560
MixupTrain:  epoch  0, batch   334 | loss: 2.5114627
MixupTrain:  epoch  0, batch   335 | loss: 2.8055806
MixupTrain:  epoch  0, batch   336 | loss: 2.8077793
MixupTrain:  epoch  0, batch   337 | loss: 2.1221254
MixupTrain:  epoch  0, batch   338 | loss: 2.4349098
MixupTrain:  epoch  0, batch   339 | loss: 2.3732300
MixupTrain:  epoch  0, batch   340 | loss: 2.4995322
MixupTrain:  epoch  0, batch   342 | loss: 2.3150280
MixupTrain:  epoch  0, batch   343 | loss: 2.1082430
MixupTrain:  epoch  0, batch   344 | loss: 2.7082882
MixupTrain:  epoch  0, batch   345 | loss: 2.4526448
MixupTrain:  epoch  0, batch   347 | loss: 2.3372109
MixupTrain:  epoch  0, batch   348 | loss: 2.3811083
MixupTrain:  epoch  0, batch   349 | loss: 2.2921879
MixupTrain:  epoch  0, batch   350 | loss: 2.3403349
MixupTrain:  epoch  0, batch   351 | loss: 2.3492560
MixupTrain:  epoch  0, batch   352 | loss: 2.4951301
MixupTrain:  epoch  0, batch   353 | loss: 2.1409760
MixupTrain:  epoch  0, batch   354 | loss: 2.2924724
MixupTrain:  epoch  0, batch   355 | loss: 2.2168741
MixupTrain:  epoch  0, batch   356 | loss: 2.3544538
MixupTrain:  epoch  0, batch   357 | loss: 2.2175460
MixupTrain:  epoch  0, batch   358 | loss: 2.2596428
MixupTrain:  epoch  0, batch   361 | loss: 2.3106899
MixupTrain:  epoch  0, batch   362 | loss: 2.5844803
MixupTrain:  epoch  0, batch   363 | loss: 2.4342892
MixupTrain:  epoch  0, batch   364 | loss: 2.4015794
MixupTrain:  epoch  0, batch   365 | loss: 2.3719115
MixupTrain:  epoch  0, batch   366 | loss: 2.0095429
MixupTrain:  epoch  0, batch   367 | loss: 2.5211616
MixupTrain:  epoch  0, batch   368 | loss: 2.2819233
MixupTrain:  epoch  0, batch   370 | loss: 2.5257268
MixupTrain:  epoch  0, batch   371 | loss: 2.4951272
MixupTrain:  epoch  0, batch   372 | loss: 2.3449328
MixupTrain:  epoch  0, batch   374 | loss: 2.1720390
MixupTrain:  epoch  0, batch   375 | loss: 2.1831865
MixupTrain:  epoch  0, batch   377 | loss: 2.2901607
MixupTrain:  epoch  0, batch   378 | loss: 2.3796701
MixupTrain:  epoch  0, batch   379 | loss: 2.5604196
MixupTrain:  epoch  0, batch   380 | loss: 2.1957712
MixupTrain:  epoch  0, batch   381 | loss: 2.7695198
MixupTrain:  epoch  0, batch   382 | loss: 2.6026735
MixupTrain:  epoch  0, batch   383 | loss: 2.0640841
MixupTrain:  epoch  0, batch   384 | loss: 2.1847951
MixupTrain:  epoch  0, batch   385 | loss: 2.2723517
MixupTrain:  epoch  0, batch   386 | loss: 2.1800802
MixupTrain:  epoch  0, batch   387 | loss: 2.1598496
MixupTrain:  epoch  0, batch   389 | loss: 2.2769406
MixupTrain:  epoch  0, batch   390 | loss: 2.3965595
MixupTrain:  epoch  0, batch   391 | loss: 2.4173214
MixupTrain:  epoch  0, batch   392 | loss: 2.6787548
MixupTrain:  epoch  0, batch   394 | loss: 2.1770663
MixupTrain:  epoch  0, batch   395 | loss: 2.5773864
MixupTrain:  epoch  0, batch   396 | loss: 2.4281139
MixupTrain:  epoch  0, batch   397 | loss: 2.2327573
MixupTrain:  epoch  0, batch   398 | loss: 2.6148915
MixupTrain:  epoch  0, batch   399 | loss: 2.2921441
MixupTrain:  epoch  0, batch   400 | loss: 2.0991747
MixupTrain:  epoch  0, batch   401 | loss: 2.1777387
MixupTrain:  epoch  0, batch   402 | loss: 2.6842847
MixupTrain:  epoch  0, batch   403 | loss: 2.3193297
MixupTrain:  epoch  0, batch   406 | loss: 2.6159737
MixupTrain:  epoch  0, batch   407 | loss: 2.2182112
MixupTrain:  epoch  0, batch   408 | loss: 2.1716487
MixupTrain:  epoch  0, batch   409 | loss: 2.4460888
MixupTrain:  epoch  0, batch   410 | loss: 2.6805553
MixupTrain:  epoch  0, batch   411 | loss: 2.2667406
MixupTrain:  epoch  0, batch   412 | loss: 2.1786270
MixupTrain:  epoch  0, batch   414 | loss: 2.2519233
MixupTrain:  epoch  0, batch   415 | loss: 2.4206324
MixupTrain:  epoch  0, batch   417 | loss: 2.5522752
MixupTrain:  epoch  0, batch   419 | loss: 2.6570287
MixupTrain:  epoch  0, batch   420 | loss: 2.6383176
MixupTrain:  epoch  0, batch   422 | loss: 2.2509046
MixupTrain:  epoch  0, batch   423 | loss: 2.3114696
MixupTrain:  epoch  0, batch   424 | loss: 2.1781836
MixupTrain:  epoch  0, batch   425 | loss: 2.6787124
MixupTrain:  epoch  0, batch   426 | loss: 2.1305492
MixupTrain:  epoch  0, batch   427 | loss: 2.6802738
MixupTrain:  epoch  0, batch   428 | loss: 2.3827357
MixupTrain:  epoch  0, batch   431 | loss: 2.3848276
MixupTrain:  epoch  0, batch   432 | loss: 2.6574235
MixupTrain:  epoch  0, batch   433 | loss: 2.2706041
MixupTrain:  epoch  0, batch   434 | loss: 2.0900867
MixupTrain:  epoch  0, batch   435 | loss: 2.3519533
MixupTrain:  epoch  0, batch   437 | loss: 2.3176713
MixupTrain:  epoch  0, batch   438 | loss: 2.1290879
MixupTrain:  epoch  0, batch   439 | loss: 2.3624792
MixupTrain:  epoch  0, batch   440 | loss: 2.5679836
MixupTrain:  epoch  0, batch   441 | loss: 2.4806886
MixupTrain:  epoch  0, batch   442 | loss: 2.2669778
MixupTrain:  epoch  0, batch   443 | loss: 2.4535255
MixupTrain:  epoch  0, batch   444 | loss: 2.2779045
MixupTrain:  epoch  0, batch   445 | loss: 2.3344865
MixupTrain:  epoch  0, batch   446 | loss: 2.1876674
MixupTrain:  epoch  0, batch   447 | loss: 2.4439125
MixupTrain:  epoch  0, batch   448 | loss: 2.1265187
MixupTrain:  epoch  0, batch   449 | loss: 2.3090665
MixupTrain:  epoch  0, batch   450 | loss: 2.0246005
MixupTrain:  epoch  0, batch   451 | loss: 2.4436679
MixupTrain:  epoch  0, batch   453 | loss: 2.1133475
MixupTrain:  epoch  0, batch   455 | loss: 2.1753404
MixupTrain:  epoch  0, batch   456 | loss: 2.6569588
MixupTrain:  epoch  0, batch   457 | loss: 2.4060392
MixupTrain:  epoch  0, batch   458 | loss: 2.6111760
MixupTrain:  epoch  0, batch   459 | loss: 2.3445799
MixupTrain:  epoch  0, batch   460 | loss: 2.3428981
MixupTrain:  epoch  0, batch   461 | loss: 2.2232771
MixupTrain:  epoch  0, batch   463 | loss: 2.3341110
MixupTrain:  epoch  0, batch   464 | loss: 2.1560616
MixupTrain:  epoch  0, batch   465 | loss: 2.2521427
MixupTrain:  epoch  0, batch   466 | loss: 2.4753304
MixupTrain:  epoch  0, batch   467 | loss: 2.3598688
MixupTrain:  epoch  0, batch   468 | loss: 2.1619873
MixupTrain:  epoch  0, batch   469 | loss: 2.5927420
MixupTrain:  epoch  0, batch   470 | loss: 2.7813406
MixupTrain:  epoch  0, batch   471 | loss: 2.3030014
MixupTrain:  epoch  0, batch   472 | loss: 2.8242412
MixupTrain:  epoch  0, batch   473 | loss: 2.5129113
MixupTrain:  epoch  0, batch   474 | loss: 2.5657792
MixupTrain:  epoch  0, batch   475 | loss: 2.6882663
MixupTrain:  epoch  0, batch   476 | loss: 1.9463793
MixupTrain:  epoch  0, batch   477 | loss: 2.5125365
MixupTrain:  epoch  0, batch   478 | loss: 2.4026003
MixupTrain:  epoch  0, batch   479 | loss: 2.1866667
MixupTrain:  epoch  0, batch   480 | loss: 2.0639553
MixupTrain:  epoch  0, batch   481 | loss: 2.2436092
MixupTrain:  epoch  0, batch   482 | loss: 2.2399464
MixupTrain:  epoch  0, batch   483 | loss: 2.3640161
MixupTrain:  epoch  0, batch   484 | loss: 2.2618132
MixupTrain:  epoch  0, batch   485 | loss: 2.2057490
MixupTrain:  epoch  0, batch   487 | loss: 2.1738262
MixupTrain:  epoch  0, batch   488 | loss: 1.9215186
MixupTrain:  epoch  0, batch   489 | loss: 2.8822794
MixupTrain:  epoch  0, batch   490 | loss: 2.5066786
MixupTrain:  epoch  0, batch   491 | loss: 2.1944294
MixupTrain:  epoch  0, batch   492 | loss: 2.2541449
MixupTrain:  epoch  0, batch   493 | loss: 2.1336145
MixupTrain:  epoch  0, batch   494 | loss: 2.2340341
MixupTrain:  epoch  0, batch   496 | loss: 2.1134422
MixupTrain:  epoch  0, batch   497 | loss: 2.7048481
MixupTrain:  epoch  0, batch   498 | loss: 2.7261229
MixupTrain:  epoch  0, batch   499 | loss: 2.1328204
MixupTrain:  epoch  0, batch   500 | loss: 2.7180104
MixupTrain:  epoch  0, batch   502 | loss: 2.5141666
MixupTrain:  epoch  0, batch   504 | loss: 2.0428548
MixupTrain:  epoch  0, batch   505 | loss: 1.9889729
MixupTrain:  epoch  0, batch   506 | loss: 2.5129158
MixupTrain:  epoch  0, batch   507 | loss: 2.3780117
MixupTrain:  epoch  0, batch   508 | loss: 2.0330291
MixupTrain:  epoch  0, batch   509 | loss: 2.3362367
MixupTrain:  epoch  0, batch   510 | loss: 2.2349930
MixupTrain:  epoch  0, batch   511 | loss: 2.2262657
MixupTrain:  epoch  0, batch   512 | loss: 2.3496752
MixupTrain:  epoch  0, batch   513 | loss: 2.4887824
MixupTrain:  epoch  0, batch   514 | loss: 2.1091077
MixupTrain:  epoch  0, batch   515 | loss: 2.1478298
MixupTrain:  epoch  0, batch   516 | loss: 2.3184271
MixupTrain:  epoch  0, batch   517 | loss: 2.4998128
MixupTrain:  epoch  0, batch   518 | loss: 2.7647460
MixupTrain:  epoch  0, batch   519 | loss: 2.6097915
MixupTrain:  epoch  0, batch   520 | loss: 2.4272718
MixupTrain:  epoch  0, batch   521 | loss: 2.5509143
MixupTrain:  epoch  0, batch   522 | loss: 2.2204843
MixupTrain:  epoch  0, batch   523 | loss: 2.2424173
MixupTrain:  epoch  0, batch   525 | loss: 2.1747403
MixupTrain:  epoch  0, batch   526 | loss: 2.2566419
MixupTrain:  epoch  0, batch   527 | loss: 2.2023087
MixupTrain:  epoch  0, batch   528 | loss: 2.2502675
MixupTrain:  epoch  0, batch   529 | loss: 2.4273925
MixupTrain:  epoch  0, batch   531 | loss: 2.5648208
MixupTrain:  epoch  0, batch   532 | loss: 2.4876976
MixupTrain:  epoch  0, batch   533 | loss: 2.6640682
MixupTrain:  epoch  0, batch   534 | loss: 2.5585926
MixupTrain:  epoch  0, batch   535 | loss: 2.3736575
MixupTrain:  epoch  0, batch   537 | loss: 2.4894900
MixupTrain:  epoch  0, batch   538 | loss: 2.1625071
MixupTrain:  epoch  0, batch   539 | loss: 2.2297726
MixupTrain:  epoch  0, batch   540 | loss: 2.2296243
MixupTrain:  epoch  0, batch   541 | loss: 2.3511295
MixupTrain:  epoch  0, batch   542 | loss: 2.4480093
MixupTrain:  epoch  0, batch   543 | loss: 2.6609862
MixupTrain:  epoch  0, batch   544 | loss: 2.5624893
MixupTrain:  epoch  0, batch   545 | loss: 2.1603813
MixupTrain:  epoch  0, batch   546 | loss: 2.2544076
MixupTrain:  epoch  0, batch   547 | loss: 2.2413270
MixupTrain:  epoch  0, batch   548 | loss: 2.1372335
MixupTrain:  epoch  0, batch   549 | loss: 2.3499267
MixupTrain:  epoch  0, batch   550 | loss: 2.2923899
MixupTrain:  epoch  0, batch   551 | loss: 2.3156524
MixupTrain:  epoch  0, batch   552 | loss: 2.1387484
MixupTrain:  epoch  0, batch   553 | loss: 2.0683870
MixupTrain:  epoch  0, batch   554 | loss: 2.2054389
MixupTrain:  epoch  0, batch   555 | loss: 2.3110478
MixupTrain:  epoch  0, batch   556 | loss: 2.3947365
MixupTrain:  epoch  0, batch   558 | loss: 2.2861569
MixupTrain:  epoch  0, batch   559 | loss: 2.4592824
MixupTrain:  epoch  0, batch   560 | loss: 2.4688392
MixupTrain:  epoch  0, batch   561 | loss: 1.9252404
MixupTrain:  epoch  0, batch   562 | loss: 2.5818913
MixupTrain:  epoch  0, batch   563 | loss: 2.3704531
MixupTrain:  epoch  0, batch   564 | loss: 1.9557315
MixupTrain:  epoch  0, batch   565 | loss: 2.5521677
MixupTrain:  epoch  0, batch   566 | loss: 2.2406120
MixupTrain:  epoch  0, batch   567 | loss: 2.1027846
MixupTrain:  epoch  0, batch   568 | loss: 2.0690112
MixupTrain:  epoch  0, batch   570 | loss: 2.5312109
MixupTrain:  epoch  0, batch   571 | loss: 1.9899132
MixupTrain:  epoch  0, batch   573 | loss: 2.5371389
MixupTrain:  epoch  0, batch   574 | loss: 2.3016489
MixupTrain:  epoch  0, batch   575 | loss: 2.3860478
MixupTrain:  epoch  0, batch   576 | loss: 2.2795608
MixupTrain:  epoch  0, batch   577 | loss: 2.4790187
MixupTrain:  epoch  0, batch   578 | loss: 2.0632131
MixupTrain:  epoch  0, batch   579 | loss: 2.2125425
MixupTrain:  epoch  0, batch   580 | loss: 2.6193464
MixupTrain:  epoch  0, batch   581 | loss: 2.3292420
MixupTrain:  epoch  0, batch   582 | loss: 2.3960485
MixupTrain:  epoch  0, batch   583 | loss: 2.4066141
MixupTrain:  epoch  0, batch   586 | loss: 1.9937872
MixupTrain:  epoch  0, batch   589 | loss: 2.2493334
MixupTrain:  epoch  0, batch   590 | loss: 2.4760022
MixupTrain:  epoch  0, batch   591 | loss: 2.1189077
MixupTrain:  epoch  0, batch   592 | loss: 2.3777888
MixupTrain:  epoch  0, batch   593 | loss: 2.4176939
MixupTrain:  epoch  0, batch   594 | loss: 2.4205058
MixupTrain:  epoch  0, batch   595 | loss: 2.1489813
MixupTrain:  epoch  0, batch   596 | loss: 2.6256342
MixupTrain:  epoch  0, batch   598 | loss: 2.3541028
MixupTrain:  epoch  0, batch   599 | loss: 2.2622139
MixupTrain:  epoch  0, batch   600 | loss: 2.2028913
MixupTrain:  epoch  0, batch   601 | loss: 2.2741261
MixupTrain:  epoch  0, batch   602 | loss: 2.7704616
MixupTrain:  epoch  0, batch   603 | loss: 2.2802615
MixupTrain:  epoch  0, batch   606 | loss: 2.2159452
MixupTrain:  epoch  0, batch   608 | loss: 2.2234576
MixupTrain:  epoch  0, batch   609 | loss: 2.7696800
MixupTrain:  epoch  0, batch   610 | loss: 2.6405687
MixupTrain:  epoch  0, batch   611 | loss: 2.6017542
MixupTrain:  epoch  0, batch   612 | loss: 2.2318470
MixupTrain:  epoch  0, batch   613 | loss: 1.9914422
MixupTrain:  epoch  0, batch   614 | loss: 2.3327761
MixupTrain:  epoch  0, batch   615 | loss: 2.1543367
MixupTrain:  epoch  0, batch   616 | loss: 2.0742657
MixupTrain:  epoch  0, batch   617 | loss: 2.4045498
MixupTrain:  epoch  0, batch   618 | loss: 2.1322367
MixupTrain:  epoch  0, batch   619 | loss: 2.0765939
MixupTrain:  epoch  0, batch   620 | loss: 2.3346257
MixupTrain:  epoch  0, batch   621 | loss: 2.2572994
MixupTrain:  epoch  0, batch   622 | loss: 2.3403645
MixupTrain:  epoch  0, batch   623 | loss: 2.4198344
MixupTrain:  epoch  0, batch   624 | loss: 2.5044289
MixupTrain:  epoch  0, batch   625 | loss: 2.2372746
MixupTrain:  epoch  0, batch   626 | loss: 1.9467998
MixupTrain:  epoch  0, batch   627 | loss: 2.1894507
MixupTrain:  epoch  0, batch   628 | loss: 2.6253269
MixupTrain:  epoch  0, batch   629 | loss: 2.3684185
MixupTrain:  epoch  0, batch   631 | loss: 2.5812995
MixupTrain:  epoch  0, batch   632 | loss: 2.4185510
MixupTrain:  epoch  0, batch   633 | loss: 2.2527037
MixupTrain:  epoch  0, batch   634 | loss: 2.2517071
MixupTrain:  epoch  0, batch   635 | loss: 2.0337992
MixupTrain:  epoch  0, batch   636 | loss: 2.3324122
MixupTrain:  epoch  0, batch   637 | loss: 2.4470162
MixupTrain:  epoch  0, batch   638 | loss: 2.3784742
MixupTrain:  epoch  0, batch   639 | loss: 2.5807314
MixupTrain:  epoch  0, batch   640 | loss: 2.2178965
MixupTrain:  epoch  0, batch   641 | loss: 2.2919202
MixupTrain:  epoch  0, batch   642 | loss: 1.9673157
MixupTrain:  epoch  0, batch   644 | loss: 2.0978336
MixupTrain:  epoch  0, batch   645 | loss: 2.1706009
MixupTrain:  epoch  0, batch   647 | loss: 2.2925620
MixupTrain:  epoch  0, batch   648 | loss: 1.9542105
MixupTrain:  epoch  0, batch   650 | loss: 2.3636832
MixupTrain:  epoch  0, batch   651 | loss: 2.0660198
MixupTrain:  epoch  0, batch   653 | loss: 2.6297002
MixupTrain:  epoch  0, batch   654 | loss: 2.4203238
MixupTrain:  epoch  0, batch   656 | loss: 2.2050760
MixupTrain:  epoch  0, batch   657 | loss: 2.3239517
MixupTrain:  epoch  0, batch   658 | loss: 2.1941209
MixupTrain:  epoch  0, batch   659 | loss: 2.3338523
MixupTrain:  epoch  0, batch   661 | loss: 2.3580942
MixupTrain:  epoch  0, batch   662 | loss: 2.7821360
MixupTrain:  epoch  0, batch   663 | loss: 2.4005494
MixupTrain:  epoch  0, batch   664 | loss: 2.2227426
MixupTrain:  epoch  0, batch   665 | loss: 2.5294895
MixupTrain:  epoch  0, batch   666 | loss: 2.4178276
MixupTrain:  epoch  0, batch   667 | loss: 2.2405424
MixupTrain:  epoch  0, batch   668 | loss: 2.4494138
MixupTrain:  epoch  0, batch   669 | loss: 2.1647813
MixupTrain:  epoch  0, batch   670 | loss: 2.3841846
MixupTrain:  epoch  0, batch   671 | loss: 2.2455013
MixupTrain:  epoch  0, batch   672 | loss: 2.1348476
MixupTrain:  epoch  0, batch   673 | loss: 2.2933376
MixupTrain:  epoch  0, batch   675 | loss: 2.0201502
MixupTrain:  epoch  0, batch   677 | loss: 2.0230069
MixupTrain:  epoch  0, batch   678 | loss: 2.0590172
MixupTrain:  epoch  0, batch   679 | loss: 2.5688648
MixupTrain:  epoch  0, batch   680 | loss: 2.3242848
MixupTrain:  epoch  0, batch   681 | loss: 2.2901871
MixupTrain:  epoch  0, batch   682 | loss: 2.3345301
MixupTrain:  epoch  0, batch   684 | loss: 2.0633826
MixupTrain:  epoch  0, batch   685 | loss: 2.2196686
MixupTrain:  epoch  0, batch   686 | loss: 2.4233956
MixupTrain:  epoch  0, batch   687 | loss: 2.5036454
MixupTrain:  epoch  0, batch   688 | loss: 2.2952847
MixupTrain:  epoch  0, batch   689 | loss: 2.3364410
MixupTrain:  epoch  0, batch   690 | loss: 2.4758706
MixupTrain:  epoch  0, batch   691 | loss: 2.1175799
MixupTrain:  epoch  0, batch   692 | loss: 2.3977714
MixupTrain:  epoch  0, batch   693 | loss: 2.4405739
MixupTrain:  epoch  0, batch   694 | loss: 2.0607381
MixupTrain:  epoch  0, batch   695 | loss: 2.2979932
MixupTrain:  epoch  0, batch   696 | loss: 2.2044022
MixupTrain:  epoch  0, batch   697 | loss: 2.3096204
MixupTrain:  epoch  0, batch   698 | loss: 2.4689260
MixupTrain:  epoch  0, batch   699 | loss: 2.1892667
MixupTrain:  epoch  0, batch   700 | loss: 2.1499424
MixupTrain:  epoch  0, batch   701 | loss: 2.1108406
MixupTrain:  epoch  0, batch   702 | loss: 2.1835763
MixupTrain:  epoch  0, batch   703 | loss: 2.4111147
MixupTrain:  epoch  0, batch   704 | loss: 2.1534355
MixupTrain:  epoch  0, batch   705 | loss: 2.5202065
MixupTrain:  epoch  0, batch   708 | loss: 2.2342010
MixupTrain:  epoch  0, batch   710 | loss: 2.3425374
MixupTrain:  epoch  0, batch   711 | loss: 2.6322491
MixupTrain:  epoch  0, batch   712 | loss: 2.2865338
MixupTrain:  epoch  0, batch   713 | loss: 2.2732604
MixupTrain:  epoch  0, batch   714 | loss: 2.3914948
MixupTrain:  epoch  0, batch   715 | loss: 2.5606451
MixupTrain:  epoch  0, batch   716 | loss: 2.4866700
MixupTrain:  epoch  0, batch   717 | loss: 2.3974164
MixupTrain:  epoch  0, batch   718 | loss: 2.3727074
MixupTrain:  epoch  0, batch   719 | loss: 2.4423673
MixupTrain:  epoch  0, batch   720 | loss: 2.5470333
MixupTrain:  epoch  0, batch   721 | loss: 2.9596143
MixupTrain:  epoch  0, batch   722 | loss: 2.5494781
MixupTrain:  epoch  0, batch   724 | loss: 2.1723373
MixupTrain:  epoch  0, batch   725 | loss: 2.2313831
MixupTrain:  epoch  0, batch   726 | loss: 2.3493128
MixupTrain:  epoch  0, batch   728 | loss: 2.2836969
MixupTrain:  epoch  0, batch   729 | loss: 2.1665392
MixupTrain:  epoch  0, batch   730 | loss: 2.4040601
MixupTrain:  epoch  0, batch   731 | loss: 2.4177217
MixupTrain:  epoch  0, batch   732 | loss: 2.2056770
MixupTrain:  epoch  0, batch   733 | loss: 2.1802630
MixupTrain:  epoch  0, batch   735 | loss: 2.3050883
MixupTrain:  epoch  0, batch   736 | loss: 2.4917722
MixupTrain:  epoch  0, batch   737 | loss: 2.2409463
MixupTrain:  epoch  0, batch   738 | loss: 2.3185272
MixupTrain:  epoch  0, batch   739 | loss: 2.3988914
MixupTrain:  epoch  0, batch   740 | loss: 2.2430651
MixupTrain:  epoch  0, batch   741 | loss: 2.2026272
MixupTrain:  epoch  0, batch   742 | loss: 2.0802352
MixupTrain:  epoch  0, batch   743 | loss: 2.0754302
MixupTrain:  epoch  0, batch   744 | loss: 2.2176020
MixupTrain:  epoch  0, batch   745 | loss: 2.2905769
MixupTrain:  epoch  0, batch   746 | loss: 2.3611579
MixupTrain:  epoch  0, batch   747 | loss: 2.4876668
MixupTrain:  epoch  0, batch   748 | loss: 2.2676926
MixupTrain:  epoch  0, batch   749 | loss: 2.2278376
MixupTrain:  epoch  0, batch   751 | loss: 2.4825120
MixupTrain:  epoch  0, batch   753 | loss: 2.3332381
MixupTrain:  epoch  0, batch   755 | loss: 2.3793521
MixupTrain:  epoch  0, batch   757 | loss: 2.3157866
MixupTrain:  epoch  0, batch   758 | loss: 2.2568681
MixupTrain:  epoch  0, batch   759 | loss: 2.0294070
MixupTrain:  epoch  0, batch   760 | loss: 2.4561796
MixupTrain:  epoch  0, batch   761 | loss: 2.5208118
MixupTrain:  epoch  0, batch   762 | loss: 2.5086720
MixupTrain:  epoch  0, batch   764 | loss: 2.2701364
MixupTrain:  epoch  0, batch   765 | loss: 2.1028523
MixupTrain:  epoch  0, batch   766 | loss: 2.1914845
MixupTrain:  epoch  0, batch   767 | loss: 2.5914145
MixupTrain:  epoch  0, batch   768 | loss: 2.0571189
MixupTrain:  epoch  0, batch   769 | loss: 2.3271933
MixupTrain:  epoch  0, batch   771 | loss: 2.1951146
MixupTrain:  epoch  0, batch   772 | loss: 2.1223693
MixupTrain:  epoch  0, batch   773 | loss: 2.1047592
MixupTrain:  epoch  0, batch   774 | loss: 2.7689033
MixupTrain:  epoch  0, batch   775 | loss: 2.0710511
MixupTrain:  epoch  0, batch   776 | loss: 2.4623554
MixupTrain:  epoch  0, batch   777 | loss: 2.4996791
MixupTrain:  epoch  0, batch   779 | loss: 2.8049133
MixupTrain:  epoch  0, batch   780 | loss: 2.4235568
MixupTrain:  epoch  0, batch   781 | loss: 2.3570995
MixupTrain:  epoch  0, batch   782 | loss: 2.6267543
MixupTrain:  epoch  0, batch   783 | loss: 2.3241191
MixupTrain:  epoch  0, batch   784 | loss: 2.2811036
MixupTrain:  epoch  0, batch   785 | loss: 2.2884436
MixupTrain:  epoch  0, batch   786 | loss: 2.1879590
MixupTrain:  epoch  0, batch   787 | loss: 2.2611842
MixupTrain:  epoch  0, batch   788 | loss: 2.2856264
MixupTrain:  epoch  0, batch   789 | loss: 2.6830478
MixupTrain:  epoch  0, batch   790 | loss: 2.1782036
MixupTrain:  epoch  0, batch   791 | loss: 2.5266011
MixupTrain:  epoch  0, batch   792 | loss: 2.3475728
MixupTrain:  epoch  0, batch   793 | loss: 2.3303571
MixupTrain:  epoch  0, batch   794 | loss: 2.2152438
MixupTrain:  epoch  0, batch   795 | loss: 2.3811731
MixupTrain:  epoch  0, batch   796 | loss: 2.3245754
MixupTrain:  epoch  0, batch   797 | loss: 2.3806338
MixupTrain:  epoch  0, batch   798 | loss: 2.3759665
MixupTrain:  epoch  0, batch   799 | loss: 1.9291549
MixupTrain:  epoch  0, batch   800 | loss: 2.0287311
MixupTrain:  epoch  0, batch   801 | loss: 2.2399042
MixupTrain:  epoch  0, batch   802 | loss: 2.2306993
MixupTrain:  epoch  0, batch   803 | loss: 2.1694019
MixupTrain:  epoch  0, batch   805 | loss: 2.1549506
MixupTrain:  epoch  0, batch   806 | loss: 2.4919219
MixupTrain:  epoch  0, batch   808 | loss: 2.4902935
MixupTrain:  epoch  0, batch   809 | loss: 2.1329634
MixupTrain:  epoch  0, batch   810 | loss: 2.1411576
MixupTrain:  epoch  0, batch   811 | loss: 2.2212591
MixupTrain:  epoch  0, batch   812 | loss: 2.4656990
MixupTrain:  epoch  0, batch   813 | loss: 2.5203581
MixupTrain:  epoch  0, batch   814 | loss: 2.6610537
MixupTrain:  epoch  0, batch   815 | loss: 2.5057430
MixupTrain:  epoch  0, batch   816 | loss: 2.0949850
MixupTrain:  epoch  0, batch   817 | loss: 2.6745834
MixupTrain:  epoch  0, batch   818 | loss: 1.9707536
MixupTrain:  epoch  0, batch   819 | loss: 2.4899273
MixupTrain:  epoch  0, batch   820 | loss: 2.3231788
MixupTrain:  epoch  0, batch   821 | loss: 2.4681878
MixupTrain:  epoch  0, batch   822 | loss: 2.4197898
MixupTrain:  epoch  0, batch   823 | loss: 2.2044177
MixupTrain:  epoch  0, batch   824 | loss: 2.2903657
MixupTrain:  epoch  0, batch   827 | loss: 2.3600678
MixupTrain:  epoch  0, batch   828 | loss: 2.3756607
MixupTrain:  epoch  0, batch   829 | loss: 2.3868110
MixupTrain:  epoch  0, batch   830 | loss: 2.0429392
MixupTrain:  epoch  0, batch   831 | loss: 2.2256110
MixupTrain:  epoch  0, batch   832 | loss: 2.8099875
MixupTrain:  epoch  0, batch   833 | loss: 2.1585910
MixupTrain:  epoch  0, batch   834 | loss: 2.0749583
MixupTrain:  epoch  0, batch   835 | loss: 2.5290687
MixupTrain:  epoch  0, batch   836 | loss: 2.3138328
MixupTrain:  epoch  0, batch   837 | loss: 2.0133133
MixupTrain:  epoch  0, batch   840 | loss: 2.3796048
MixupTrain:  epoch  0, batch   841 | loss: 2.3550100
MixupTrain:  epoch  0, batch   842 | loss: 2.3409140
MixupTrain:  epoch  0, batch   843 | loss: 2.7388630
MixupTrain:  epoch  0, batch   844 | loss: 2.6248548
MixupTrain:  epoch  0, batch   845 | loss: 2.0420132
MixupTrain:  epoch  0, batch   846 | loss: 2.2930450
MixupTrain:  epoch  0, batch   848 | loss: 2.2856455
MixupTrain:  epoch  0, batch   849 | loss: 2.1881776
MixupTrain:  epoch  0, batch   851 | loss: 2.0374684
MixupTrain:  epoch  0, batch   853 | loss: 2.0354171
MixupTrain:  epoch  0, batch   855 | loss: 2.2686267
MixupTrain:  epoch  0, batch   856 | loss: 2.1577826
MixupTrain:  epoch  0, batch   857 | loss: 2.4025853
MixupTrain:  epoch  0, batch   858 | loss: 2.0126400
MixupTrain:  epoch  0, batch   859 | loss: 2.4619312
MixupTrain:  epoch  0, batch   860 | loss: 2.4739351
MixupTrain:  epoch  0, batch   861 | loss: 2.0470307
MixupTrain:  epoch  0, batch   862 | loss: 2.1685276
MixupTrain:  epoch  0, batch   863 | loss: 2.3600407
MixupTrain:  epoch  0, batch   864 | loss: 2.5030894
MixupTrain:  epoch  0, batch   865 | loss: 2.2981794
MixupTrain:  epoch  0, batch   866 | loss: 2.2333541
MixupTrain:  epoch  0, batch   867 | loss: 2.0530734
MixupTrain:  epoch  0, batch   869 | loss: 2.1663094
MixupTrain:  epoch  0, batch   870 | loss: 2.0821548
MixupTrain:  epoch  0, batch   871 | loss: 2.3955336
MixupTrain:  epoch  0, batch   872 | loss: 2.3177471
MixupTrain:  epoch  0, batch   873 | loss: 2.0569229
MixupTrain:  epoch  0, batch   874 | loss: 2.5749364
MixupTrain:  epoch  0, batch   875 | loss: 2.4586663
MixupTrain:  epoch  0, batch   876 | loss: 2.2067857
MixupTrain:  epoch  0, batch   877 | loss: 2.2337303
MixupTrain:  epoch  0, batch   878 | loss: 2.3047342
MixupTrain:  epoch  0, batch   879 | loss: 2.2279568
MixupTrain:  epoch  0, batch   880 | loss: 2.1304648
MixupTrain:  epoch  0, batch   881 | loss: 2.4963446
MixupTrain:  epoch  0, batch   882 | loss: 2.0755546
MixupTrain:  epoch  0, batch   884 | loss: 2.1273856
MixupTrain:  epoch  0, batch   885 | loss: 2.5169604
MixupTrain:  epoch  0, batch   887 | loss: 2.1891038
MixupTrain:  epoch  0, batch   888 | loss: 2.2974014
MixupTrain:  epoch  0, batch   889 | loss: 2.7259958
MixupTrain:  epoch  0, batch   890 | loss: 2.6892142
MixupTrain:  epoch  0, batch   891 | loss: 2.1644382
MixupTrain:  epoch  0, batch   892 | loss: 2.3523817
MixupTrain:  epoch  0, batch   893 | loss: 1.9665203
MixupTrain:  epoch  0, batch   894 | loss: 2.2793288
MixupTrain:  epoch  0, batch   895 | loss: 2.3250821
MixupTrain:  epoch  0, batch   898 | loss: 2.3622518
MixupTrain:  epoch  0, batch   900 | loss: 2.4026117
MixupTrain:  epoch  0, batch   901 | loss: 2.3146634
MixupTrain:  epoch  0, batch   902 | loss: 2.4689441
MixupTrain:  epoch  0, batch   903 | loss: 2.4908676
MixupTrain:  epoch  0, batch   904 | loss: 1.9484687
MixupTrain:  epoch  0, batch   905 | loss: 2.4376192
MixupTrain:  epoch  0, batch   906 | loss: 2.1978712
MixupTrain:  epoch  0, batch   907 | loss: 2.1905193
MixupTrain:  epoch  0, batch   908 | loss: 2.2306809
MixupTrain:  epoch  0, batch   909 | loss: 2.2646651
MixupTrain:  epoch  0, batch   910 | loss: 2.3292532
MixupTrain:  epoch  0, batch   911 | loss: 2.4997969
MixupTrain:  epoch  0, batch   912 | loss: 2.2436967
MixupTrain:  epoch  0, batch   913 | loss: 2.1683393
MixupTrain:  epoch  0, batch   914 | loss: 2.1473727
MixupTrain:  epoch  0, batch   915 | loss: 2.3190603
MixupTrain:  epoch  0, batch   916 | loss: 2.4461212
MixupTrain:  epoch  0, batch   917 | loss: 2.2299051
MixupTrain:  epoch  0, batch   919 | loss: 2.3760076
MixupTrain:  epoch  0, batch   920 | loss: 2.2475333
MixupTrain:  epoch  0, batch   921 | loss: 2.6364338
MixupTrain:  epoch  0, batch   922 | loss: 2.6485119
MixupTrain:  epoch  0, batch   923 | loss: 1.9533575
MixupTrain:  epoch  0, batch   924 | loss: 2.1062860
MixupTrain:  epoch  0, batch   926 | loss: 2.2301359
MixupTrain:  epoch  0, batch   927 | loss: 2.2158992
MixupTrain:  epoch  0, batch   928 | loss: 2.4843202
MixupTrain:  epoch  0, batch   929 | loss: 2.5251269
MixupTrain:  epoch  0, batch   930 | loss: 2.1958475
MixupTrain:  epoch  0, batch   931 | loss: 2.1070352
MixupTrain:  epoch  0, batch   933 | loss: 2.3221426
MixupTrain:  epoch  0, batch   934 | loss: 2.2140641
MixupTrain:  epoch  0, batch   935 | loss: 2.3274012
MixupTrain:  epoch  0, batch   936 | loss: 2.2590580
MixupTrain:  epoch  0, batch   937 | loss: 2.2857702
MixupTrain:  epoch  0, batch   938 | loss: 2.3035772
MixupTrain:  epoch  0, batch   939 | loss: 1.9928948
MixupTrain:  epoch  0, batch   940 | loss: 2.6302977
MixupTrain:  epoch  0, batch   941 | loss: 2.5322688
MixupTrain:  epoch  0, batch   943 | loss: 2.2683282
MixupTrain:  epoch  0, batch   945 | loss: 2.2773345
MixupTrain:  epoch  0, batch   946 | loss: 2.3631854
MixupTrain:  epoch  0, batch   947 | loss: 2.4199195
MixupTrain:  epoch  0, batch   948 | loss: 2.1550908
MixupTrain:  epoch  0, batch   949 | loss: 2.1687684
MixupTrain:  epoch  0, batch   950 | loss: 2.0587714
MixupTrain:  epoch  0, batch   951 | loss: 2.3763270
MixupTrain:  epoch  0, batch   952 | loss: 2.4590225
MixupTrain:  epoch  0, batch   953 | loss: 2.2017698
MixupTrain:  epoch  0, batch   954 | loss: 2.5047941
MixupTrain:  epoch  0, batch   955 | loss: 2.3000240
MixupTrain:  epoch  0, batch   956 | loss: 1.9815000
MixupTrain:  epoch  0, batch   957 | loss: 2.5154715
MixupTrain:  epoch  0, batch   958 | loss: 2.2426350
MixupTrain:  epoch  0, batch   959 | loss: 2.6119215
MixupTrain:  epoch  0, batch   960 | loss: 2.6710730
MixupTrain:  epoch  0, batch   962 | loss: 2.5215960
MixupTrain:  epoch  0, batch   963 | loss: 2.4563618
MixupTrain:  epoch  0, batch   964 | loss: 1.9986804
MixupTrain:  epoch  0, batch   966 | loss: 2.4274998
MixupTrain:  epoch  0, batch   967 | loss: 2.3918359
MixupTrain:  epoch  0, batch   968 | loss: 2.5641947
MixupTrain:  epoch  0, batch   969 | loss: 2.2575047
MixupTrain:  epoch  0, batch   970 | loss: 2.3769727
MixupTrain:  epoch  0, batch   971 | loss: 2.2343059
MixupTrain:  epoch  0, batch   973 | loss: 1.9737345
MixupTrain:  epoch  0, batch   974 | loss: 2.4811583
MixupTrain:  epoch  0, batch   975 | loss: 2.1922174
MixupTrain:  epoch  0, batch   976 | loss: 2.4305251
MixupTrain:  epoch  0, batch   977 | loss: 2.1297050
MixupTrain:  epoch  0, batch   978 | loss: 2.2850375
MixupTrain:  epoch  0, batch   979 | loss: 2.0782080
MixupTrain:  epoch  0, batch   980 | loss: 2.6346083
MixupTrain:  epoch  0, batch   981 | loss: 2.3695993
MixupTrain:  epoch  0, batch   982 | loss: 2.3414810
MixupTrain:  epoch  0, batch   983 | loss: 2.4265373
MixupTrain:  epoch  0, batch   984 | loss: 2.0845814
MixupTrain:  epoch  0, batch   985 | loss: 2.4756050
MixupTrain:  epoch  0, batch   986 | loss: 2.2944765
MixupTrain:  epoch  0, batch   987 | loss: 2.0540409
MixupTrain:  epoch  0, batch   988 | loss: 2.7341261
MixupTrain:  epoch  0, batch   989 | loss: 2.0286179
MixupTrain:  epoch  0, batch   990 | loss: 2.3660200
MixupTrain:  epoch  0, batch   991 | loss: 2.2478325
MixupTrain:  epoch  0, batch   992 | loss: 2.2439303
MixupTrain:  epoch  0, batch   993 | loss: 2.3983846
MixupTrain:  epoch  0, batch   994 | loss: 2.5659938
MixupTrain:  epoch  0, batch   995 | loss: 2.3747692
MixupTrain:  epoch  0, batch   997 | loss: 2.4285736
MixupTrain:  epoch  0, batch   998 | loss: 2.2201180
MixupTrain:  epoch  0, batch   999 | loss: 2.0965366
MixupTrain:  epoch  0, batch  1000 | loss: 2.0774331
MixupTrain:  epoch  0, batch  1001 | loss: 2.3149505
MixupTrain:  epoch  0, batch  1003 | loss: 2.2505667
MixupTrain:  epoch  0, batch  1004 | loss: 2.3016300
MixupTrain:  epoch  0, batch  1005 | loss: 2.1727991
MixupTrain:  epoch  0, batch  1006 | loss: 2.1764851
MixupTrain:  epoch  0, batch  1007 | loss: 1.9658926
MixupTrain:  epoch  0, batch  1008 | loss: 2.1471334
MixupTrain:  epoch  0, batch  1009 | loss: 2.2822256
MixupTrain:  epoch  0, batch  1010 | loss: 2.3114436
MixupTrain:  epoch  0, batch  1011 | loss: 2.3542991
MixupTrain:  epoch  0, batch  1012 | loss: 2.1029947
MixupTrain:  epoch  0, batch  1013 | loss: 2.3109002
MixupTrain:  epoch  0, batch  1014 | loss: 2.3162439
MixupTrain:  epoch  0, batch  1016 | loss: 2.1538067
MixupTrain:  epoch  0, batch  1017 | loss: 2.3415329
MixupTrain:  epoch  0, batch  1018 | loss: 2.1219764
MixupTrain:  epoch  0, batch  1019 | loss: 2.3198957
MixupTrain:  epoch  0, batch  1021 | loss: 2.6102710
MixupTrain:  epoch  0, batch  1022 | loss: 1.9615816
MixupTrain:  epoch  0, batch  1024 | loss: 2.1163607
MixupTrain:  epoch  0, batch  1025 | loss: 2.2979758
MixupTrain:  epoch  0, batch  1026 | loss: 2.4774714
MixupTrain:  epoch  0, batch  1027 | loss: 2.4761434
MixupTrain:  epoch  0, batch  1028 | loss: 2.3589091
MixupTrain:  epoch  0, batch  1029 | loss: 2.2088184
MixupTrain:  epoch  0, batch  1030 | loss: 2.3254471
MixupTrain:  epoch  0, batch  1031 | loss: 2.3944674
MixupTrain:  epoch  0, batch  1032 | loss: 2.3531470
MixupTrain:  epoch  0, batch  1033 | loss: 2.1131186
MixupTrain:  epoch  0, batch  1035 | loss: 2.3449159
MixupTrain:  epoch  0, batch  1036 | loss: 2.1990166
MixupTrain:  epoch  0, batch  1037 | loss: 2.3185244
MixupTrain:  epoch  0, batch  1038 | loss: 2.0370853
MixupTrain:  epoch  0, batch  1039 | loss: 2.4295671
MixupTrain:  epoch  0, batch  1040 | loss: 2.5429192
MixupTrain:  epoch  0, batch  1042 | loss: 2.2313147
MixupTrain:  epoch  0, batch  1043 | loss: 2.4004259
MixupTrain:  epoch  0, batch  1045 | loss: 2.0288906
MixupTrain:  epoch  0, batch  1046 | loss: 2.2084236
MixupTrain:  epoch  0, batch  1048 | loss: 2.3160157
MixupTrain:  epoch  0, batch  1050 | loss: 2.2219639
MixupTrain:  epoch  0, batch  1051 | loss: 2.6066887
MixupTrain:  epoch  0, batch  1053 | loss: 2.3213234
MixupTrain:  epoch  0, batch  1054 | loss: 2.1337867
MixupTrain:  epoch  0, batch  1055 | loss: 2.5963428
MixupTrain:  epoch  0, batch  1056 | loss: 1.8874543
MixupTrain:  epoch  0, batch  1057 | loss: 2.5475802
MixupTrain:  epoch  0, batch  1058 | loss: 2.3817019
MixupTrain:  epoch  0, batch  1059 | loss: 2.3259487
MixupTrain:  epoch  0, batch  1060 | loss: 2.2103748
MixupTrain:  epoch  0, batch  1061 | loss: 1.9403361
MixupTrain:  epoch  0, batch  1063 | loss: 2.5913906
MixupTrain:  epoch  0, batch  1065 | loss: 2.3100669
MixupTrain:  epoch  0, batch  1066 | loss: 2.3364832
MixupTrain:  epoch  0, batch  1067 | loss: 2.4849541
MixupTrain:  epoch  0, batch  1069 | loss: 2.1174383
MixupTrain:  epoch  0, batch  1070 | loss: 2.0446584
MixupTrain:  epoch  0, batch  1071 | loss: 2.2366669
MixupTrain:  epoch  0, batch  1072 | loss: 2.3948355
MixupTrain:  epoch  0, batch  1073 | loss: 2.2706037
MixupTrain:  epoch  0, batch  1074 | loss: 2.3763657
MixupTrain:  epoch  0, batch  1075 | loss: 2.1821523
MixupTrain:  epoch  0, batch  1076 | loss: 2.4201419
MixupTrain:  epoch  0, batch  1077 | loss: 2.4050851
MixupTrain:  epoch  0, batch  1078 | loss: 2.0689583
MixupTrain:  epoch  0, batch  1082 | loss: 2.6783199
MixupTrain:  epoch  0, batch  1083 | loss: 2.1612186
MixupTrain:  epoch  0, batch  1084 | loss: 2.3411088
MixupTrain:  epoch  0, batch  1085 | loss: 2.1567590
MixupTrain:  epoch  0, batch  1088 | loss: 2.4931412
MixupTrain:  epoch  0, batch  1089 | loss: 2.1593969
MixupTrain:  epoch  0, batch  1090 | loss: 2.7017806
MixupTrain:  epoch  0, batch  1091 | loss: 2.3508294
MixupTrain:  epoch  0, batch  1092 | loss: 2.2420580
MixupTrain:  epoch  0, batch  1093 | loss: 2.5481324
MixupTrain:  epoch  0, batch  1094 | loss: 2.6048908
MixupTrain:  epoch  0, batch  1095 | loss: 2.2263367
MixupTrain:  epoch  0, batch  1096 | loss: 2.0604172
MixupTrain:  epoch  0, batch  1097 | loss: 2.1967432
MixupTrain:  epoch  0, batch  1098 | loss: 2.4697111
MixupTrain:  epoch  0, batch  1099 | loss: 2.3828070
MixupTrain:  epoch  0, batch  1100 | loss: 2.6861258
MixupTrain:  epoch  0, batch  1101 | loss: 2.2911382
MixupTrain:  epoch  0, batch  1102 | loss: 2.5309243
MixupTrain:  epoch  0, batch  1104 | loss: 2.3038208
MixupTrain:  epoch  0, batch  1105 | loss: 2.2445905
MixupTrain:  epoch  0, batch  1106 | loss: 2.1139066
MixupTrain:  epoch  0, batch  1108 | loss: 2.1619024
MixupTrain:  epoch  0, batch  1109 | loss: 2.3015504
MixupTrain:  epoch  0, batch  1110 | loss: 2.4745040
MixupTrain:  epoch  0, batch  1111 | loss: 2.3232045
MixupTrain:  epoch  0, batch  1112 | loss: 2.5254841
MixupTrain:  epoch  0, batch  1113 | loss: 2.5410023
MixupTrain:  epoch  0, batch  1114 | loss: 2.3968005
MixupTrain:  epoch  0, batch  1115 | loss: 2.5110168
MixupTrain:  epoch  0, batch  1116 | loss: 2.1692326
MixupTrain:  epoch  0, batch  1117 | loss: 2.2992356
MixupTrain:  epoch  0, batch  1118 | loss: 2.2523530
MixupTrain:  epoch  0, batch  1119 | loss: 2.4838576
MixupTrain:  epoch  0, batch  1121 | loss: 2.2389662
MixupTrain:  epoch  0, batch  1122 | loss: 2.6435478
MixupTrain:  epoch  0, batch  1123 | loss: 2.4522338
MixupTrain:  epoch  0, batch  1125 | loss: 2.2735543
MixupTrain:  epoch  0, batch  1126 | loss: 2.4673986
MixupTrain:  epoch  0, batch  1127 | loss: 2.2497878
MixupTrain:  epoch  0, batch  1129 | loss: 2.5173044
MixupTrain:  epoch  0, batch  1130 | loss: 2.3568635
MixupTrain:  epoch  0, batch  1131 | loss: 2.4360282
MixupTrain:  epoch  0, batch  1132 | loss: 2.1140947
MixupTrain:  epoch  0, batch  1133 | loss: 2.8278241
MixupTrain:  epoch  0, batch  1134 | loss: 2.3370817
MixupTrain:  epoch  0, batch  1135 | loss: 2.1412611
MixupTrain:  epoch  0, batch  1136 | loss: 2.4584513
MixupTrain:  epoch  0, batch  1137 | loss: 2.1853051
MixupTrain:  epoch  0, batch  1138 | loss: 2.0546575
MixupTrain:  epoch  0, batch  1140 | loss: 2.1358249
MixupTrain:  epoch  0, batch  1141 | loss: 2.2435763
MixupTrain:  epoch  0, batch  1142 | loss: 2.5477362
MixupTrain:  epoch  0, batch  1144 | loss: 2.3882179
MixupTrain:  epoch  0, batch  1145 | loss: 2.0210934
MixupTrain:  epoch  0, batch  1146 | loss: 2.1233799
MixupTrain:  epoch  0, batch  1147 | loss: 1.9614718
MixupTrain:  epoch  0, batch  1149 | loss: 2.4570084
MixupTrain:  epoch  0, batch  1150 | loss: 2.1416295
MixupTrain:  epoch  0, batch  1151 | loss: 2.3050323
MixupTrain:  epoch  0, batch  1152 | loss: 2.2099986
MixupTrain:  epoch  0, batch  1153 | loss: 2.0074887
MixupTrain:  epoch  0, batch  1154 | loss: 2.7512021
MixupTrain:  epoch  0, batch  1155 | loss: 2.1730642
MixupTrain:  epoch  0, batch  1156 | loss: 2.4121599
MixupTrain:  epoch  0, batch  1157 | loss: 2.5779562
MixupTrain:  epoch  0, batch  1158 | loss: 2.3633885
MixupTrain:  epoch  0, batch  1159 | loss: 2.3214700
MixupTrain:  epoch  0, batch  1160 | loss: 2.3704052
MixupTrain:  epoch  0, batch  1161 | loss: 2.4048300
MixupTrain:  epoch  0, batch  1162 | loss: 2.2877791
MixupTrain:  epoch  0, batch  1163 | loss: 2.0166633
MixupTrain:  epoch  0, batch  1164 | loss: 2.2907875
MixupTrain:  epoch  0, batch  1165 | loss: 2.5449543
MixupTrain:  epoch  0, batch  1166 | loss: 2.2693503
MixupTrain:  epoch  0, batch  1167 | loss: 2.1357760
MixupTrain:  epoch  0, batch  1169 | loss: 2.2928157
MixupTrain:  epoch  0, batch  1170 | loss: 2.1989121
MixupTrain:  epoch  0, batch  1171 | loss: 2.4058270
MixupTrain:  epoch  0, batch  1172 | loss: 2.4663131
MixupTrain:  epoch  0, batch  1173 | loss: 2.3828988
MixupTrain:  epoch  0, batch  1174 | loss: 2.0633183
MixupTrain:  epoch  0, batch  1175 | loss: 2.1796761
MixupTrain:  epoch  0, batch  1176 | loss: 2.0627110
MixupTrain:  epoch  0, batch  1177 | loss: 2.0902267
MixupTrain:  epoch  0, batch  1178 | loss: 2.3005567
MixupTrain:  epoch  0, batch  1179 | loss: 2.3910069
MixupTrain:  epoch  0, batch  1180 | loss: 2.4175239
MixupTrain:  epoch  0, batch  1181 | loss: 2.5777998
MixupTrain:  epoch  0, batch  1182 | loss: 2.4223149
MixupTrain:  epoch  0, batch  1183 | loss: 2.2248659
MixupTrain:  epoch  0, batch  1184 | loss: 2.7571611
MixupTrain:  epoch  0, batch  1185 | loss: 2.2933569
MixupTrain:  epoch  0, batch  1186 | loss: 2.4898210
MixupTrain:  epoch  0, batch  1187 | loss: 2.2384338
MixupTrain:  epoch  0, batch  1188 | loss: 2.5519254
MixupTrain:  epoch  0, batch  1190 | loss: 2.2323377
MixupTrain:  epoch  0, batch  1191 | loss: 2.1393180
MixupTrain:  epoch  0, batch  1192 | loss: 2.0348849
MixupTrain:  epoch  0, batch  1193 | loss: 2.5715392
MixupTrain:  epoch  0, batch  1194 | loss: 1.9579046
MixupTrain:  epoch  0, batch  1196 | loss: 2.0253673
MixupTrain:  epoch  0, batch  1197 | loss: 2.4936817
MixupTrain:  epoch  0, batch  1198 | loss: 2.2679973
MixupTrain:  epoch  0, batch  1199 | loss: 2.4386387
MixupTrain:  epoch  0, batch  1200 | loss: 3.0322418
MixupTrain:  epoch  0, batch  1201 | loss: 2.2749910
MixupTrain:  epoch  0, batch  1204 | loss: 2.5531962
MixupTrain:  epoch  0, batch  1206 | loss: 2.0567245
MixupTrain:  epoch  0, batch  1207 | loss: 2.1686490
MixupTrain:  epoch  0, batch  1208 | loss: 2.0727344
MixupTrain:  epoch  0, batch  1209 | loss: 2.1070299
MixupTrain:  epoch  0, batch  1210 | loss: 2.5015473
MixupTrain:  epoch  0, batch  1211 | loss: 2.3680882
MixupTrain:  epoch  0, batch  1212 | loss: 2.3258181
MixupTrain:  epoch  0, batch  1213 | loss: 2.4516470
MixupTrain:  epoch  0, batch  1214 | loss: 2.5635986
MixupTrain:  epoch  0, batch  1215 | loss: 2.3915949
MixupTrain:  epoch  0, batch  1216 | loss: 2.1539757
MixupTrain:  epoch  0, batch  1217 | loss: 1.9257900
MixupTrain:  epoch  0, batch  1218 | loss: 2.4425354
MixupTrain:  epoch  0, batch  1219 | loss: 2.0005093
MixupTrain:  epoch  0, batch  1220 | loss: 2.2137666
MixupTrain:  epoch  0, batch  1222 | loss: 2.0485392
MixupTrain:  epoch  0, batch  1223 | loss: 2.6883445
MixupTrain:  epoch  0, batch  1224 | loss: 2.3978302
MixupTrain:  epoch  0, batch  1226 | loss: 2.4856856
MixupTrain:  epoch  0, batch  1227 | loss: 1.9124889
MixupTrain:  epoch  0, batch  1228 | loss: 2.2055650
MixupTrain:  epoch  0, batch  1229 | loss: 2.1375380
MixupTrain:  epoch  0, batch  1230 | loss: 2.3149619
MixupTrain:  epoch  0, batch  1232 | loss: 2.4575043
MixupTrain:  epoch  0, batch  1233 | loss: 2.5138745
MixupTrain:  epoch  0, batch  1234 | loss: 2.3797963
MixupTrain:  epoch  0, batch  1235 | loss: 1.9744205
MixupTrain:  epoch  0, batch  1237 | loss: 2.1652923
MixupTrain:  epoch  0, batch  1238 | loss: 2.2684970
MixupTrain:  epoch  0, batch  1239 | loss: 2.4746025
MixupTrain:  epoch  0, batch  1240 | loss: 2.4193532
MixupTrain:  epoch  0, batch  1241 | loss: 2.3231187
MixupTrain:  epoch  0, batch  1242 | loss: 2.5277891
MixupTrain:  epoch  0, batch  1244 | loss: 2.5234909
MixupTrain:  epoch  0, batch  1245 | loss: 2.2721586
MixupTrain:  epoch  0, batch  1246 | loss: 2.3697944
MixupTrain:  epoch  0, batch  1247 | loss: 2.0770996
MixupTrain:  epoch  0, batch  1249 | loss: 2.2966518
MixupTrain:  epoch  0, batch  1250 | loss: 2.1473553
MixupTrain:  epoch  0, batch  1251 | loss: 2.3541622
MixupTrain:  epoch  0, batch  1252 | loss: 2.8450024
MixupTrain:  epoch  0, batch  1253 | loss: 2.3741989
MixupTrain:  epoch  0, batch  1254 | loss: 2.1062255
MixupTrain:  epoch  0, batch  1255 | loss: 2.2268462
MixupTrain:  epoch  0, batch  1256 | loss: 2.3591397
MixupTrain:  epoch  0, batch  1257 | loss: 2.1112041
MixupTrain:  epoch  0, batch  1258 | loss: 2.1425011
MixupTrain:  epoch  0, batch  1261 | loss: 2.4852557
MixupTrain:  epoch  0, batch  1262 | loss: 2.4628110
MixupTrain:  epoch  0, batch  1263 | loss: 2.0217710
MixupTrain:  epoch  0, batch  1264 | loss: 2.3435245
MixupTrain:  epoch  0, batch  1265 | loss: 2.5529974
MixupTrain:  epoch  0, batch  1267 | loss: 2.1249850
MixupTrain:  epoch  0, batch  1269 | loss: 2.3997419
MixupTrain:  epoch  0, batch  1270 | loss: 2.0292330
MixupTrain:  epoch  0, batch  1271 | loss: 2.1043725
MixupTrain:  epoch  0, batch  1272 | loss: 2.1737578
MixupTrain:  epoch  0, batch  1273 | loss: 2.4482627
MixupTrain:  epoch  0, batch  1274 | loss: 2.5247719
MixupTrain:  epoch  0, batch  1276 | loss: 2.3221769
MixupTrain:  epoch  0, batch  1277 | loss: 2.2698603
MixupTrain:  epoch  0, batch  1278 | loss: 2.2872906
MixupTrain:  epoch  0, batch  1279 | loss: 2.2653995
MixupTrain:  epoch  0, batch  1280 | loss: 1.9994298
MixupTrain:  epoch  0, batch  1281 | loss: 2.3374729
MixupTrain:  epoch  0, batch  1282 | loss: 2.3437643
MixupTrain:  epoch  0, batch  1284 | loss: 2.6850815
MixupTrain:  epoch  0, batch  1285 | loss: 2.2767081
MixupTrain:  epoch  0, batch  1286 | loss: 2.5903139
MixupTrain:  epoch  0, batch  1287 | loss: 2.4135776
MixupTrain:  epoch  0, batch  1288 | loss: 2.5053725
MixupTrain:  epoch  0, batch  1289 | loss: 2.2870014
MixupTrain:  epoch  0, batch  1290 | loss: 2.4219012
MixupTrain:  epoch  0, batch  1291 | loss: 1.9715352
MixupTrain:  epoch  0, batch  1292 | loss: 2.3646853
MixupTrain:  epoch  0, batch  1293 | loss: 2.3427336
MixupTrain:  epoch  0, batch  1294 | loss: 1.8686521
MixupTrain:  epoch  0, batch  1295 | loss: 2.1470020
MixupTrain:  epoch  0, batch  1296 | loss: 2.1316826
MixupTrain:  epoch  0, batch  1297 | loss: 2.5346761
MixupTrain:  epoch  0, batch  1298 | loss: 2.4074638
MixupTrain:  epoch  0, batch  1299 | loss: 2.2140126
MixupTrain:  epoch  0, batch  1301 | loss: 2.1811280
MixupTrain:  epoch  0, batch  1302 | loss: 2.5385206
MixupTrain:  epoch  0, batch  1303 | loss: 2.1705945
MixupTrain:  epoch  0, batch  1306 | loss: 2.3871069
MixupTrain:  epoch  0, batch  1307 | loss: 2.3524017
MixupTrain:  epoch  0, batch  1308 | loss: 2.1772673
MixupTrain:  epoch  0, batch  1310 | loss: 1.9311793
MixupTrain:  epoch  0, batch  1311 | loss: 2.0006027
MixupTrain:  epoch  0, batch  1312 | loss: 2.4643893
MixupTrain:  epoch  0, batch  1313 | loss: 2.4821577
MixupTrain:  epoch  0, batch  1314 | loss: 2.5384684
MixupTrain:  epoch  0, batch  1315 | loss: 2.3359990
MixupTrain:  epoch  0, batch  1318 | loss: 2.3214438
MixupTrain:  epoch  0, batch  1319 | loss: 2.2570901
MixupTrain:  epoch  0, batch  1320 | loss: 2.4858332
MixupTrain:  epoch  0, batch  1321 | loss: 1.9782290
MixupTrain:  epoch  0, batch  1322 | loss: 2.3751183
MixupTrain:  epoch  0, batch  1323 | loss: 2.2815652
MixupTrain:  epoch  0, batch  1324 | loss: 2.1852245
MixupTrain:  epoch  0, batch  1326 | loss: 2.3944314
MixupTrain:  epoch  0, batch  1328 | loss: 2.4201095
MixupTrain:  epoch  0, batch  1330 | loss: 2.4662914
MixupTrain:  epoch  0, batch  1331 | loss: 2.5757313
MixupTrain:  epoch  0, batch  1332 | loss: 2.4377902
MixupTrain:  epoch  0, batch  1333 | loss: 2.6053505
MixupTrain:  epoch  0, batch  1334 | loss: 2.1365106
MixupTrain:  epoch  0, batch  1336 | loss: 2.5131941
MixupTrain:  epoch  0, batch  1337 | loss: 2.4426088
MixupTrain:  epoch  0, batch  1338 | loss: 2.3132155
MixupTrain:  epoch  0, batch  1339 | loss: 2.4122169
MixupTrain:  epoch  0, batch  1340 | loss: 2.3610110
MixupTrain:  epoch  0, batch  1341 | loss: 2.4970565
MixupTrain:  epoch  0, batch  1342 | loss: 2.3346653
MixupTrain:  epoch  0, batch  1343 | loss: 1.8889577
MemoryTrain:  epoch  0, batch     0 | loss: 2.1602037
MemoryTrain:  epoch  0, batch     1 | loss: 2.3631382
MemoryTrain:  epoch  0, batch     2 | loss: 2.7050436
MemoryTrain:  epoch  0, batch     3 | loss: 2.2472980
MemoryTrain:  epoch  0, batch     4 | loss: 2.3611178
MemoryTrain:  epoch  0, batch     5 | loss: 2.6049809
MemoryTrain:  epoch  0, batch     6 | loss: 2.1587906
MemoryTrain:  epoch  0, batch     7 | loss: 2.1996851
MemoryTrain:  epoch  0, batch     8 | loss: 2.4462242
MemoryTrain:  epoch  0, batch     9 | loss: 2.3179379
MemoryTrain:  epoch  0, batch    10 | loss: 1.9571474
MemoryTrain:  epoch  0, batch    11 | loss: 2.0587842
MemoryTrain:  epoch  1, batch     0 | loss: 1.8315408
MemoryTrain:  epoch  1, batch     1 | loss: 1.8386307
MemoryTrain:  epoch  1, batch     2 | loss: 2.0706375
MemoryTrain:  epoch  1, batch     3 | loss: 1.8625568
MemoryTrain:  epoch  1, batch     4 | loss: 1.8359241
MemoryTrain:  epoch  1, batch     5 | loss: 1.8403285
MemoryTrain:  epoch  1, batch     6 | loss: 1.8216244
MemoryTrain:  epoch  1, batch     7 | loss: 1.8981526
MemoryTrain:  epoch  1, batch     8 | loss: 1.8534441
MemoryTrain:  epoch  1, batch     9 | loss: 1.8532848
MemoryTrain:  epoch  1, batch    10 | loss: 1.8542252
MemoryTrain:  epoch  1, batch    11 | loss: 1.8188461
MemoryTrain:  epoch  2, batch     0 | loss: 1.8681146
MemoryTrain:  epoch  2, batch     1 | loss: 1.8264219
MemoryTrain:  epoch  2, batch     2 | loss: 1.8677524
MemoryTrain:  epoch  2, batch     3 | loss: 1.8385382
MemoryTrain:  epoch  2, batch     4 | loss: 1.8250155
MemoryTrain:  epoch  2, batch     5 | loss: 1.8497398
MemoryTrain:  epoch  2, batch     6 | loss: 1.8213216
MemoryTrain:  epoch  2, batch     7 | loss: 1.8258352
MemoryTrain:  epoch  2, batch     8 | loss: 1.8318551
MemoryTrain:  epoch  2, batch     9 | loss: 1.8213420
MemoryTrain:  epoch  2, batch    10 | loss: 1.8174908
MemoryTrain:  epoch  2, batch    11 | loss: 1.8215736
MemoryTrain:  epoch  3, batch     0 | loss: 1.8271033
MemoryTrain:  epoch  3, batch     1 | loss: 1.8303598
MemoryTrain:  epoch  3, batch     2 | loss: 1.8351443
MemoryTrain:  epoch  3, batch     3 | loss: 1.8143619
MemoryTrain:  epoch  3, batch     4 | loss: 1.8181734
MemoryTrain:  epoch  3, batch     5 | loss: 1.8149610
MemoryTrain:  epoch  3, batch     6 | loss: 1.8208948
MemoryTrain:  epoch  3, batch     7 | loss: 1.8176243
MemoryTrain:  epoch  3, batch     8 | loss: 1.8193107
MemoryTrain:  epoch  3, batch     9 | loss: 1.8200803
MemoryTrain:  epoch  3, batch    10 | loss: 1.8221335
MemoryTrain:  epoch  3, batch    11 | loss: 1.8177025
MemoryTrain:  epoch  4, batch     0 | loss: 1.8219711
MemoryTrain:  epoch  4, batch     1 | loss: 1.8219329
MemoryTrain:  epoch  4, batch     2 | loss: 1.8189908
MemoryTrain:  epoch  4, batch     3 | loss: 1.8250434
MemoryTrain:  epoch  4, batch     4 | loss: 1.8216004
MemoryTrain:  epoch  4, batch     5 | loss: 1.8134944
MemoryTrain:  epoch  4, batch     6 | loss: 1.8178283
MemoryTrain:  epoch  4, batch     7 | loss: 1.8191458
MemoryTrain:  epoch  4, batch     8 | loss: 1.8229932
MemoryTrain:  epoch  4, batch     9 | loss: 1.8268366
MemoryTrain:  epoch  4, batch    10 | loss: 1.8163750
MemoryTrain:  epoch  4, batch    11 | loss: 1.8254591
MemoryTrain:  epoch  5, batch     0 | loss: 1.8185093
MemoryTrain:  epoch  5, batch     1 | loss: 1.8192008
MemoryTrain:  epoch  5, batch     2 | loss: 1.8141614
MemoryTrain:  epoch  5, batch     3 | loss: 1.8125596
MemoryTrain:  epoch  5, batch     4 | loss: 1.8312125
MemoryTrain:  epoch  5, batch     5 | loss: 1.8304217
MemoryTrain:  epoch  5, batch     6 | loss: 1.8391490
MemoryTrain:  epoch  5, batch     7 | loss: 1.8180696
MemoryTrain:  epoch  5, batch     8 | loss: 1.8222210
MemoryTrain:  epoch  5, batch     9 | loss: 1.8252393
MemoryTrain:  epoch  5, batch    10 | loss: 1.8251152
MemoryTrain:  epoch  5, batch    11 | loss: 1.8208493
MemoryTrain:  epoch  6, batch     0 | loss: 1.8298709
MemoryTrain:  epoch  6, batch     1 | loss: 1.8232211
MemoryTrain:  epoch  6, batch     2 | loss: 1.8238385
MemoryTrain:  epoch  6, batch     3 | loss: 1.8242347
MemoryTrain:  epoch  6, batch     4 | loss: 1.8205762
MemoryTrain:  epoch  6, batch     5 | loss: 1.8199729
MemoryTrain:  epoch  6, batch     6 | loss: 1.8152652
MemoryTrain:  epoch  6, batch     7 | loss: 1.8104386
MemoryTrain:  epoch  6, batch     8 | loss: 1.8176860
MemoryTrain:  epoch  6, batch     9 | loss: 1.8239567
MemoryTrain:  epoch  6, batch    10 | loss: 1.8167543
MemoryTrain:  epoch  6, batch    11 | loss: 1.8194739
MemoryTrain:  epoch  7, batch     0 | loss: 1.8167474
MemoryTrain:  epoch  7, batch     1 | loss: 1.8253996
MemoryTrain:  epoch  7, batch     2 | loss: 1.8097136
MemoryTrain:  epoch  7, batch     3 | loss: 1.8160905
MemoryTrain:  epoch  7, batch     4 | loss: 1.8151102
MemoryTrain:  epoch  7, batch     5 | loss: 1.8173157
MemoryTrain:  epoch  7, batch     6 | loss: 1.8126082
MemoryTrain:  epoch  7, batch     7 | loss: 1.8158619
MemoryTrain:  epoch  7, batch     8 | loss: 1.8194871
MemoryTrain:  epoch  7, batch     9 | loss: 1.8170929
MemoryTrain:  epoch  7, batch    10 | loss: 1.8190389
MemoryTrain:  epoch  7, batch    11 | loss: 1.8179512
MemoryTrain:  epoch  8, batch     0 | loss: 1.8128209
MemoryTrain:  epoch  8, batch     1 | loss: 1.8187768
MemoryTrain:  epoch  8, batch     2 | loss: 1.8250096
MemoryTrain:  epoch  8, batch     3 | loss: 1.8209889
MemoryTrain:  epoch  8, batch     4 | loss: 1.8118258
MemoryTrain:  epoch  8, batch     5 | loss: 1.8238778
MemoryTrain:  epoch  8, batch     6 | loss: 1.8118817
MemoryTrain:  epoch  8, batch     7 | loss: 1.8191723
MemoryTrain:  epoch  8, batch     8 | loss: 1.8122578
MemoryTrain:  epoch  8, batch     9 | loss: 1.8163309
MemoryTrain:  epoch  8, batch    10 | loss: 1.8136218
MemoryTrain:  epoch  8, batch    11 | loss: 1.8214102
MemoryTrain:  epoch  9, batch     0 | loss: 1.8150809
MemoryTrain:  epoch  9, batch     1 | loss: 1.8130280
MemoryTrain:  epoch  9, batch     2 | loss: 1.8141689
MemoryTrain:  epoch  9, batch     3 | loss: 1.8170353
MemoryTrain:  epoch  9, batch     4 | loss: 1.8203250
MemoryTrain:  epoch  9, batch     5 | loss: 1.8160717
MemoryTrain:  epoch  9, batch     6 | loss: 1.8138430
MemoryTrain:  epoch  9, batch     7 | loss: 1.8196465
MemoryTrain:  epoch  9, batch     8 | loss: 1.8104268
MemoryTrain:  epoch  9, batch     9 | loss: 1.8092109
MemoryTrain:  epoch  9, batch    10 | loss: 1.8201445
MemoryTrain:  epoch  9, batch    11 | loss: 1.8188944
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   
[EVAL] batch:    1 | acc: 87.50%,  total acc: 81.25%   
[EVAL] batch:    2 | acc: 87.50%,  total acc: 83.33%   
[EVAL] batch:    3 | acc: 93.75%,  total acc: 85.94%   
[EVAL] batch:    4 | acc: 87.50%,  total acc: 86.25%   
[EVAL] batch:    5 | acc: 100.00%,  total acc: 88.54%   
[EVAL] batch:    6 | acc: 100.00%,  total acc: 90.18%   
[EVAL] batch:    7 | acc: 12.50%,  total acc: 80.47%   
[EVAL] batch:    0 | acc: 0.00%,  total acc: 0.00%   
[EVAL] batch:    1 | acc: 18.75%,  total acc: 9.38%   
[EVAL] batch:    2 | acc: 6.25%,  total acc: 8.33%   
[EVAL] batch:    3 | acc: 6.25%,  total acc: 7.81%   
[EVAL] batch:    4 | acc: 0.00%,  total acc: 6.25%   
[EVAL] batch:    5 | acc: 6.25%,  total acc: 6.25%   
[EVAL] batch:    6 | acc: 6.25%,  total acc: 6.25%   
[EVAL] batch:    7 | acc: 0.00%,  total acc: 5.47%   
[EVAL] batch:    8 | acc: 0.00%,  total acc: 4.86%   
[EVAL] batch:    9 | acc: 0.00%,  total acc: 4.38%   
[EVAL] batch:   10 | acc: 0.00%,  total acc: 3.98%   
[EVAL] batch:   11 | acc: 6.25%,  total acc: 4.17%   
[EVAL] batch:   12 | acc: 0.00%,  total acc: 3.85%   
[EVAL] batch:   13 | acc: 25.00%,  total acc: 5.36%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 10.00%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 12.89%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 16.54%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 19.10%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 21.38%   
[EVAL] batch:   19 | acc: 75.00%,  total acc: 24.06%   
[EVAL] batch:   20 | acc: 93.75%,  total acc: 27.38%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 30.68%   
[EVAL] batch:   22 | acc: 93.75%,  total acc: 33.42%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 36.20%   
[EVAL] batch:   24 | acc: 93.75%,  total acc: 38.50%   
[EVAL] batch:   25 | acc: 87.50%,  total acc: 40.38%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 42.36%   
[EVAL] batch:   27 | acc: 81.25%,  total acc: 43.75%   
[EVAL] batch:   28 | acc: 81.25%,  total acc: 45.04%   
[EVAL] batch:   29 | acc: 56.25%,  total acc: 45.42%   
[EVAL] batch:   30 | acc: 68.75%,  total acc: 46.17%   
[EVAL] batch:   31 | acc: 87.50%,  total acc: 47.46%   
[EVAL] batch:   32 | acc: 56.25%,  total acc: 47.73%   
[EVAL] batch:   33 | acc: 18.75%,  total acc: 46.88%   
[EVAL] batch:   34 | acc: 25.00%,  total acc: 46.25%   
[EVAL] batch:   35 | acc: 25.00%,  total acc: 45.66%   
[EVAL] batch:   36 | acc: 25.00%,  total acc: 45.10%   
[EVAL] batch:   37 | acc: 50.00%,  total acc: 45.23%   
[EVAL] batch:   38 | acc: 50.00%,  total acc: 45.35%   
[EVAL] batch:   39 | acc: 87.50%,  total acc: 46.41%   
[EVAL] batch:   40 | acc: 62.50%,  total acc: 46.80%   
[EVAL] batch:   41 | acc: 100.00%,  total acc: 48.07%   
[EVAL] batch:   42 | acc: 6.25%,  total acc: 47.09%   
[EVAL] batch:   43 | acc: 0.00%,  total acc: 46.02%   
[EVAL] batch:   44 | acc: 0.00%,  total acc: 45.00%   
[EVAL] batch:   45 | acc: 0.00%,  total acc: 44.02%   
[EVAL] batch:   46 | acc: 18.75%,  total acc: 43.48%   
[EVAL] batch:   47 | acc: 50.00%,  total acc: 43.62%   
[EVAL] batch:   48 | acc: 12.50%,  total acc: 42.98%   
[EVAL] batch:   49 | acc: 6.25%,  total acc: 42.25%   
[EVAL] batch:   50 | acc: 0.00%,  total acc: 41.42%   
[EVAL] batch:   51 | acc: 6.25%,  total acc: 40.75%   
[EVAL] batch:   52 | acc: 0.00%,  total acc: 39.98%   
[EVAL] batch:   53 | acc: 37.50%,  total acc: 39.93%   
[EVAL] batch:   54 | acc: 87.50%,  total acc: 40.80%   
[EVAL] batch:   55 | acc: 81.25%,  total acc: 41.52%   
[EVAL] batch:   56 | acc: 50.00%,  total acc: 41.67%   
[EVAL] batch:   57 | acc: 68.75%,  total acc: 42.13%   
[EVAL] batch:   58 | acc: 56.25%,  total acc: 42.37%   
[EVAL] batch:   59 | acc: 56.25%,  total acc: 42.60%   
[EVAL] batch:   60 | acc: 25.00%,  total acc: 42.32%   
[EVAL] batch:   61 | acc: 43.75%,  total acc: 42.34%   
[EVAL] batch:   62 | acc: 25.00%,  total acc: 42.06%   
[EVAL] batch:   63 | acc: 43.75%,  total acc: 42.09%   
[EVAL] batch:   64 | acc: 31.25%,  total acc: 41.92%   
[EVAL] batch:   65 | acc: 37.50%,  total acc: 41.86%   
[EVAL] batch:   66 | acc: 43.75%,  total acc: 41.88%   
[EVAL] batch:   67 | acc: 87.50%,  total acc: 42.56%   
[EVAL] batch:   68 | acc: 43.75%,  total acc: 42.57%   
[EVAL] batch:   69 | acc: 25.00%,  total acc: 42.32%   
[EVAL] batch:   70 | acc: 43.75%,  total acc: 42.34%   
[EVAL] batch:   71 | acc: 68.75%,  total acc: 42.71%   
[EVAL] batch:   72 | acc: 100.00%,  total acc: 43.49%   
[EVAL] batch:   73 | acc: 100.00%,  total acc: 44.26%   
[EVAL] batch:   74 | acc: 100.00%,  total acc: 45.00%   
[EVAL] batch:   75 | acc: 100.00%,  total acc: 45.72%   
[EVAL] batch:   76 | acc: 100.00%,  total acc: 46.43%   
[EVAL] batch:   77 | acc: 75.00%,  total acc: 46.79%   
[EVAL] batch:   78 | acc: 0.00%,  total acc: 46.20%   
[EVAL] batch:   79 | acc: 0.00%,  total acc: 45.62%   
[EVAL] batch:   80 | acc: 0.00%,  total acc: 45.06%   
[EVAL] batch:   81 | acc: 6.25%,  total acc: 44.59%   
[EVAL] batch:   82 | acc: 12.50%,  total acc: 44.20%   
[EVAL] batch:   83 | acc: 6.25%,  total acc: 43.75%   
[EVAL] batch:   84 | acc: 6.25%,  total acc: 43.31%   
[EVAL] batch:   85 | acc: 37.50%,  total acc: 43.24%   
[EVAL] batch:   86 | acc: 25.00%,  total acc: 43.03%   
[EVAL] batch:   87 | acc: 37.50%,  total acc: 42.97%   
[EVAL] batch:   88 | acc: 25.00%,  total acc: 42.77%   
[EVAL] batch:   89 | acc: 37.50%,  total acc: 42.71%   
[EVAL] batch:   90 | acc: 56.25%,  total acc: 42.86%   
[EVAL] batch:   91 | acc: 100.00%,  total acc: 43.48%   
[EVAL] batch:   92 | acc: 93.75%,  total acc: 44.02%   
[EVAL] batch:   93 | acc: 100.00%,  total acc: 44.61%   
[EVAL] batch:   94 | acc: 87.50%,  total acc: 45.07%   
[EVAL] batch:   95 | acc: 93.75%,  total acc: 45.57%   
[EVAL] batch:   96 | acc: 68.75%,  total acc: 45.81%   
[EVAL] batch:   97 | acc: 75.00%,  total acc: 46.11%   
[EVAL] batch:   98 | acc: 75.00%,  total acc: 46.40%   
[EVAL] batch:   99 | acc: 81.25%,  total acc: 46.75%   
[EVAL] batch:  100 | acc: 81.25%,  total acc: 47.09%   
[EVAL] batch:  101 | acc: 87.50%,  total acc: 47.49%   
[EVAL] batch:  102 | acc: 93.75%,  total acc: 47.94%   
[EVAL] batch:  103 | acc: 87.50%,  total acc: 48.32%   
[EVAL] batch:  104 | acc: 100.00%,  total acc: 48.81%   
[EVAL] batch:  105 | acc: 100.00%,  total acc: 49.29%   
[EVAL] batch:  106 | acc: 31.25%,  total acc: 49.12%   
cur_acc:  ['0.8580', '0.8625', '0.8393', '0.8993', '0.6790', '0.8047']
his_acc:  ['0.8580', '0.8351', '0.7490', '0.6538', '0.6269', '0.4912']
CurrentTrain: epoch  0, batch     0 | loss: 4.3249679
CurrentTrain: epoch  0, batch     1 | loss: 4.2579188
CurrentTrain: epoch  1, batch     0 | loss: 3.2231548
CurrentTrain: epoch  1, batch     1 | loss: 2.7009382
CurrentTrain: epoch  2, batch     0 | loss: 2.4721794
CurrentTrain: epoch  2, batch     1 | loss: 2.3416889
CurrentTrain: epoch  3, batch     0 | loss: 2.2708178
CurrentTrain: epoch  3, batch     1 | loss: 2.0298283
CurrentTrain: epoch  4, batch     0 | loss: 2.0829062
CurrentTrain: epoch  4, batch     1 | loss: 1.9133908
CurrentTrain: epoch  5, batch     0 | loss: 1.9453831
CurrentTrain: epoch  5, batch     1 | loss: 1.9535179
CurrentTrain: epoch  6, batch     0 | loss: 1.8574102
CurrentTrain: epoch  6, batch     1 | loss: 1.8562086
CurrentTrain: epoch  7, batch     0 | loss: 1.8406421
CurrentTrain: epoch  7, batch     1 | loss: 1.7985379
CurrentTrain: epoch  8, batch     0 | loss: 1.7758459
CurrentTrain: epoch  8, batch     1 | loss: 1.7840527
CurrentTrain: epoch  9, batch     0 | loss: 1.7720996
CurrentTrain: epoch  9, batch     1 | loss: 1.7820206
#### person cause of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person cause of death" means a person was died of an event.
Here is an example:
Relation: person cause of death
Context: mr scheider had suffered from multiple myeloma for several years , and died of complications from a staph infection , his wife , brenda siemer , said .
Head Entity: mr scheider
Tail Entity: complications from a staph infection
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person cause of death":
Relation: person cause of death  
Context: after battling lung cancer for over a year, john doe passed away peacefully in his sleep, surrounded by family.  
Head Entity: john doe  
Tail Entity: lung cancer  

Relation: person cause of death  
Context: the renowned author, jane smith, tragically lost her life due to a car accident while returning from a book signing event.  
Head Entity: jane smith  
Tail Entity: car accident  

Relation: person cause of death  
Context: following a long struggle with heart disease, mr. thompson succumbed to his illness last night at the hospital.  
Head Entity: mr. thompson  
Tail Entity: heart disease  

Relation: person cause of death  
Context: the community mourned the loss of officer jones, who was killed in the line of duty during a robbery attempt.  
Head Entity: officer jones  
Tail Entity: robbery attempt  

Relation: person cause of death  
Context: after a courageous fight against diabetes, elena rodriguez passed away due to complications related to her condition.  
Head Entity: elena rodriguez  
Tail Entity: complications related to diabetes  
#### organization political religious affiliation ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization political religious affiliation" means an organization is the member of a religion.
Here is an example:
Relation: organization political religious affiliation
Context: the militia has also suffered from allegations of being involved in clashes with rival shiite militias , particularly the badr corp , the military wing linked to supreme iraqi islamic council , the party led by powerful politician abdel aziz al-hakim .
Head Entity: badr corp
Tail Entity: shiite
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization political religious affiliation":
Relation: organization political religious affiliation  
Context: The Christian Democratic Union has been a significant player in German politics, often aligning itself with various religious groups to promote its agenda.  
Head Entity: Christian Democratic Union  
Tail Entity: Christian  

Relation: organization political religious affiliation  
Context: The Islamic Society of North America has been actively involved in political advocacy, representing the interests of the Muslim community in the United States.  
Head Entity: Islamic Society of North America  
Tail Entity: Muslim  

Relation: organization political religious affiliation  
Context: The National Council of Churches works to unite various Christian denominations in the U.S. to address social justice issues and promote interfaith dialogue.  
Head Entity: National Council of Churches  
Tail Entity: Christian  

Relation: organization political religious affiliation  
Context: The Jewish Federation of North America plays a crucial role in supporting Jewish communities and advocating for their rights in political spheres.  
Head Entity: Jewish Federation of North America  
Tail Entity: Jewish  

Relation: organization political religious affiliation  
Context: The Hindu American Foundation has been instrumental in raising awareness about Hindu issues in the political landscape of the United States.  
Head Entity: Hindu American Foundation  
Tail Entity: Hindu  
#### organization stateorprovince of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization stateorprovince of headquarters" means an organization is located in a state or province.
Here is an example:
Relation: organization stateorprovince of headquarters
Context: washington , nov 30 -lrb- xinhua -rrb- -- nasa has skipped space shuttle endeavour 's second landing opportunity at kennedy space center in florida on sunday afternoon due to bad weather , according to nasa tv .
Head Entity: kennedy space center
Tail Entity: florida
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization stateorprovince of headquarters":
Relation: organization stateorprovince of headquarters  
Context: the headquarters of the multinational technology company is located in cupertino, california, where it has been a significant player in the tech industry for decades.  
Head Entity: multinational technology company  
Tail Entity: california  

Relation: organization stateorprovince of headquarters  
Context: after years of expansion, the non-profit organization has established its main office in a historic building in downtown boston, massachusetts.  
Head Entity: non-profit organization  
Tail Entity: massachusetts  

Relation: organization stateorprovince of headquarters  
Context: the famous coffee chain has its corporate headquarters situated in seattle, washington, which is known for its vibrant coffee culture.  
Head Entity: coffee chain  
Tail Entity: washington  

Relation: organization stateorprovince of headquarters  
Context: the automotive manufacturer announced plans to build a new facility in detroit, michigan, which will serve as its main headquarters for electric vehicle production.  
Head Entity: automotive manufacturer  
Tail Entity: michigan  

Relation: organization stateorprovince of headquarters  
Context: the global consulting firm has its headquarters in new york city, new york, where it provides services to clients around the world.  
Head Entity: global consulting firm  
Tail Entity: new york  
#### person other family ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person other family" means a person 's relative is a person.
Here is an example:
Relation: person other family
Context: parren mitchell 's sister-in-law , juanita jackson mitchell , was the long - time head and legal counsel of the maryland naacp .
Head Entity: parren mitchell
Tail Entity: juanita jackson mitchell
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person other family":
Relation: person other family  
Context: barack obama's half-sister, maya soetoro-ng, is an educator and a prominent figure in her own right.  
Head Entity: barack obama  
Tail Entity: maya soetoro-ng  

Relation: person other family  
Context: the famous actor, tom hanks, has a brother named jim hanks who is also involved in the film industry.  
Head Entity: tom hanks  
Tail Entity: jim hanks  

Relation: person other family  
Context: queen elizabeth ii's cousin, prince michael of kent, often attends royal events and ceremonies.  
Head Entity: queen elizabeth ii  
Tail Entity: prince michael of kent  

Relation: person other family  
Context: the renowned scientist, albert einstein, had a sister named maria who was a talented musician.  
Head Entity: albert einstein  
Tail Entity: maria einstein  

Relation: person other family  
Context: the famous author, j.k. rowling, has a younger brother named diane who has supported her throughout her career.  
Head Entity: j.k. rowling  
Tail Entity: diane rowling  
#### person city of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person city of death" means a person was died in a city.
Here is an example:
Relation: person city of death
Context: irene morgan kirkaldy , 90 , who died of alzheimer 's disease aug. 10 at her home in gloucester , va. , quietly changed history in 1944 when she refused to give up her seat on a crowded greyhound bus to a white couple .
Head Entity: her
Tail Entity: gloucester
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person city of death":
Relation: person city of death  
Context: john smith, a renowned author, passed away on march 5 in his apartment located in new york city, leaving behind a legacy of literary works that inspired many.  
Head Entity: john smith  
Tail Entity: new york city  

Relation: person city of death  
Context: after a long battle with cancer, elizabeth taylor died on march 23 at a hospital in los angeles, where she had spent her final days surrounded by family and friends.  
Head Entity: elizabeth taylor  
Tail Entity: los angeles  

Relation: person city of death  
Context: the famous physicist, albert einstein, died on april 18, 1955, in princeton, new jersey, where he had lived for many years while working at the institute for advanced study.  
Head Entity: albert einstein  
Tail Entity: princeton  

Relation: person city of death  
Context: on january 1, 2020, the beloved actor, kobe bryant, tragically lost his life in a helicopter crash in calabasas, california, shocking fans around the world.  
Head Entity: kobe bryant  
Tail Entity: calabasas  

Relation: person city of death  
Context: the legendary musician, freddie mercury, passed away on november 24, 1991, at his home in london, england, leaving a profound impact on the music industry.  
Head Entity: freddie mercury  
Tail Entity: london  
Mixup data size:  28180
MixupTrain:  epoch  0, batch     0 | loss: 3.8886724
MixupTrain:  epoch  0, batch     1 | loss: 4.0730381
MixupTrain:  epoch  0, batch     2 | loss: 4.3375006
MixupTrain:  epoch  0, batch     3 | loss: 3.9597316
MixupTrain:  epoch  0, batch     4 | loss: 3.1714523
MixupTrain:  epoch  0, batch     5 | loss: 4.4622269
MixupTrain:  epoch  0, batch     6 | loss: 4.0492191
MixupTrain:  epoch  0, batch     7 | loss: 3.9150496
MixupTrain:  epoch  0, batch     8 | loss: 3.8513997
MixupTrain:  epoch  0, batch     9 | loss: 4.0981379
MixupTrain:  epoch  0, batch    10 | loss: 4.1222811
MixupTrain:  epoch  0, batch    11 | loss: 3.5972805
MixupTrain:  epoch  0, batch    12 | loss: 3.9098232
MixupTrain:  epoch  0, batch    13 | loss: 3.6364670
MixupTrain:  epoch  0, batch    14 | loss: 3.5822427
MixupTrain:  epoch  0, batch    15 | loss: 3.8553948
MixupTrain:  epoch  0, batch    16 | loss: 3.5750208
MixupTrain:  epoch  0, batch    17 | loss: 3.0104947
MixupTrain:  epoch  0, batch    18 | loss: 3.3764896
MixupTrain:  epoch  0, batch    19 | loss: 3.8553581
MixupTrain:  epoch  0, batch    20 | loss: 3.4710188
MixupTrain:  epoch  0, batch    21 | loss: 2.6601896
MixupTrain:  epoch  0, batch    22 | loss: 3.2704105
MixupTrain:  epoch  0, batch    23 | loss: 3.7518821
MixupTrain:  epoch  0, batch    24 | loss: 3.7805195
MixupTrain:  epoch  0, batch    25 | loss: 3.0319743
MixupTrain:  epoch  0, batch    26 | loss: 3.5106294
MixupTrain:  epoch  0, batch    27 | loss: 4.6675415
MixupTrain:  epoch  0, batch    28 | loss: 4.0774951
MixupTrain:  epoch  0, batch    29 | loss: 3.2887263
MixupTrain:  epoch  0, batch    30 | loss: 3.1314280
MixupTrain:  epoch  0, batch    31 | loss: 2.8857570
MixupTrain:  epoch  0, batch    32 | loss: 4.3859472
MixupTrain:  epoch  0, batch    33 | loss: 4.3221731
MixupTrain:  epoch  0, batch    34 | loss: 3.2718263
MixupTrain:  epoch  0, batch    35 | loss: 3.3241258
MixupTrain:  epoch  0, batch    36 | loss: 2.6787300
MixupTrain:  epoch  0, batch    37 | loss: 3.0287342
MixupTrain:  epoch  0, batch    38 | loss: 3.7580020
MixupTrain:  epoch  0, batch    39 | loss: 3.5175173
MixupTrain:  epoch  0, batch    40 | loss: 3.4028349
MixupTrain:  epoch  0, batch    41 | loss: 3.4308095
MixupTrain:  epoch  0, batch    42 | loss: 3.3972130
MixupTrain:  epoch  0, batch    43 | loss: 3.4160504
MixupTrain:  epoch  0, batch    44 | loss: 2.9465752
MixupTrain:  epoch  0, batch    45 | loss: 2.9548759
MixupTrain:  epoch  0, batch    46 | loss: 3.5040274
MixupTrain:  epoch  0, batch    47 | loss: 3.3529913
MixupTrain:  epoch  0, batch    48 | loss: 2.9881253
MixupTrain:  epoch  0, batch    49 | loss: 3.1259017
MixupTrain:  epoch  0, batch    50 | loss: 3.0341103
MixupTrain:  epoch  0, batch    51 | loss: 2.4710357
MixupTrain:  epoch  0, batch    52 | loss: 2.8780890
MixupTrain:  epoch  0, batch    53 | loss: 2.6256273
MixupTrain:  epoch  0, batch    54 | loss: 3.3770685
MixupTrain:  epoch  0, batch    55 | loss: 3.1715875
MixupTrain:  epoch  0, batch    56 | loss: 2.9202247
MixupTrain:  epoch  0, batch    57 | loss: 3.8358321
MixupTrain:  epoch  0, batch    58 | loss: 3.0351675
MixupTrain:  epoch  0, batch    59 | loss: 3.2003114
MixupTrain:  epoch  0, batch    60 | loss: 3.0904579
MixupTrain:  epoch  0, batch    61 | loss: 3.3577106
MixupTrain:  epoch  0, batch    62 | loss: 3.5701172
MixupTrain:  epoch  0, batch    63 | loss: 2.9075780
MixupTrain:  epoch  0, batch    64 | loss: 3.0226955
MixupTrain:  epoch  0, batch    65 | loss: 2.7773232
MixupTrain:  epoch  0, batch    66 | loss: 2.7108307
MixupTrain:  epoch  0, batch    67 | loss: 3.0431113
MixupTrain:  epoch  0, batch    68 | loss: 3.1272957
MixupTrain:  epoch  0, batch    69 | loss: 3.4379568
MixupTrain:  epoch  0, batch    70 | loss: 3.2716584
MixupTrain:  epoch  0, batch    71 | loss: 2.4954247
MixupTrain:  epoch  0, batch    72 | loss: 2.5853448
MixupTrain:  epoch  0, batch    73 | loss: 3.5493257
MixupTrain:  epoch  0, batch    74 | loss: 2.8286803
MixupTrain:  epoch  0, batch    75 | loss: 3.0823047
MixupTrain:  epoch  0, batch    76 | loss: 2.9878995
MixupTrain:  epoch  0, batch    77 | loss: 2.7779760
MixupTrain:  epoch  0, batch    78 | loss: 2.2596259
MixupTrain:  epoch  0, batch    79 | loss: 3.0058036
MixupTrain:  epoch  0, batch    80 | loss: 2.8373632
MixupTrain:  epoch  0, batch    81 | loss: 3.1483941
MixupTrain:  epoch  0, batch    82 | loss: 2.5564418
MixupTrain:  epoch  0, batch    83 | loss: 2.9318223
MixupTrain:  epoch  0, batch    84 | loss: 2.5571699
MixupTrain:  epoch  0, batch    85 | loss: 2.7296934
MixupTrain:  epoch  0, batch    86 | loss: 2.6917241
MixupTrain:  epoch  0, batch    87 | loss: 2.8816800
MixupTrain:  epoch  0, batch    88 | loss: 3.0278544
MixupTrain:  epoch  0, batch    89 | loss: 2.8349109
MixupTrain:  epoch  0, batch    90 | loss: 2.5791080
MixupTrain:  epoch  0, batch    91 | loss: 3.0220344
MixupTrain:  epoch  0, batch    92 | loss: 2.5875335
MixupTrain:  epoch  0, batch    93 | loss: 2.5621133
MixupTrain:  epoch  0, batch    94 | loss: 2.5765915
MixupTrain:  epoch  0, batch    95 | loss: 2.7947335
MixupTrain:  epoch  0, batch    96 | loss: 3.0462410
MixupTrain:  epoch  0, batch    97 | loss: 2.6542606
MixupTrain:  epoch  0, batch    98 | loss: 2.9766073
MixupTrain:  epoch  0, batch    99 | loss: 2.8181679
MixupTrain:  epoch  0, batch   100 | loss: 2.8020687
MixupTrain:  epoch  0, batch   101 | loss: 3.0698090
MixupTrain:  epoch  0, batch   102 | loss: 2.7930334
MixupTrain:  epoch  0, batch   103 | loss: 2.8265109
MixupTrain:  epoch  0, batch   104 | loss: 2.8351674
MixupTrain:  epoch  0, batch   105 | loss: 2.6600685
MixupTrain:  epoch  0, batch   106 | loss: 2.6795249
MixupTrain:  epoch  0, batch   107 | loss: 2.6999817
MixupTrain:  epoch  0, batch   108 | loss: 2.5826054
MixupTrain:  epoch  0, batch   109 | loss: 3.1396389
MixupTrain:  epoch  0, batch   110 | loss: 2.4776821
MixupTrain:  epoch  0, batch   111 | loss: 3.1242018
MixupTrain:  epoch  0, batch   112 | loss: 2.5241940
MixupTrain:  epoch  0, batch   113 | loss: 2.7317548
MixupTrain:  epoch  0, batch   114 | loss: 2.6946154
MixupTrain:  epoch  0, batch   115 | loss: 2.7439251
MixupTrain:  epoch  0, batch   116 | loss: 3.0600040
MixupTrain:  epoch  0, batch   117 | loss: 3.0292392
MixupTrain:  epoch  0, batch   118 | loss: 2.8656549
MixupTrain:  epoch  0, batch   119 | loss: 2.7433100
MixupTrain:  epoch  0, batch   120 | loss: 2.2887535
MixupTrain:  epoch  0, batch   121 | loss: 2.6684694
MixupTrain:  epoch  0, batch   122 | loss: 2.4916368
MixupTrain:  epoch  0, batch   123 | loss: 2.5971642
MixupTrain:  epoch  0, batch   124 | loss: 2.0455518
MixupTrain:  epoch  0, batch   125 | loss: 2.5418525
MixupTrain:  epoch  0, batch   126 | loss: 2.6141601
MixupTrain:  epoch  0, batch   127 | loss: 2.6691065
MixupTrain:  epoch  0, batch   128 | loss: 2.5702801
MixupTrain:  epoch  0, batch   129 | loss: 2.7892969
MixupTrain:  epoch  0, batch   130 | loss: 2.8479066
MixupTrain:  epoch  0, batch   131 | loss: 2.6252737
MixupTrain:  epoch  0, batch   132 | loss: 2.6539860
MixupTrain:  epoch  0, batch   133 | loss: 2.7860329
MixupTrain:  epoch  0, batch   134 | loss: 2.7406416
MixupTrain:  epoch  0, batch   135 | loss: 2.5915327
MixupTrain:  epoch  0, batch   136 | loss: 2.6522064
MixupTrain:  epoch  0, batch   137 | loss: 3.0355492
MixupTrain:  epoch  0, batch   138 | loss: 2.6991813
MixupTrain:  epoch  0, batch   139 | loss: 2.5737987
MixupTrain:  epoch  0, batch   140 | loss: 2.7469301
MixupTrain:  epoch  0, batch   141 | loss: 2.6416786
MixupTrain:  epoch  0, batch   142 | loss: 2.5628943
MixupTrain:  epoch  0, batch   143 | loss: 2.5110383
MixupTrain:  epoch  0, batch   144 | loss: 2.7383685
MixupTrain:  epoch  0, batch   145 | loss: 2.1065750
MixupTrain:  epoch  0, batch   146 | loss: 2.7719016
MixupTrain:  epoch  0, batch   147 | loss: 2.5309918
MixupTrain:  epoch  0, batch   148 | loss: 2.6194510
MixupTrain:  epoch  0, batch   149 | loss: 2.5457220
MixupTrain:  epoch  0, batch   150 | loss: 2.7647088
MixupTrain:  epoch  0, batch   151 | loss: 2.6644537
MixupTrain:  epoch  0, batch   152 | loss: 2.6693611
MixupTrain:  epoch  0, batch   153 | loss: 2.1481864
MixupTrain:  epoch  0, batch   154 | loss: 3.1411991
MixupTrain:  epoch  0, batch   155 | loss: 2.7514575
MixupTrain:  epoch  0, batch   156 | loss: 2.6190112
MixupTrain:  epoch  0, batch   157 | loss: 2.7568004
MixupTrain:  epoch  0, batch   158 | loss: 3.5364857
MixupTrain:  epoch  0, batch   159 | loss: 2.5439095
MixupTrain:  epoch  0, batch   160 | loss: 2.7340760
MixupTrain:  epoch  0, batch   161 | loss: 2.5578837
MixupTrain:  epoch  0, batch   162 | loss: 2.8689127
MixupTrain:  epoch  0, batch   163 | loss: 2.3584542
MixupTrain:  epoch  0, batch   164 | loss: 2.5456016
MixupTrain:  epoch  0, batch   165 | loss: 2.5854516
MixupTrain:  epoch  0, batch   166 | loss: 3.1429045
MixupTrain:  epoch  0, batch   167 | loss: 2.3790743
MixupTrain:  epoch  0, batch   168 | loss: 2.7263885
MixupTrain:  epoch  0, batch   169 | loss: 2.6613319
MixupTrain:  epoch  0, batch   170 | loss: 2.7214315
MixupTrain:  epoch  0, batch   171 | loss: 2.4636846
MixupTrain:  epoch  0, batch   172 | loss: 2.4524798
MixupTrain:  epoch  0, batch   173 | loss: 2.3314135
MixupTrain:  epoch  0, batch   174 | loss: 2.5428040
MixupTrain:  epoch  0, batch   175 | loss: 2.4317522
MixupTrain:  epoch  0, batch   176 | loss: 2.7281919
MixupTrain:  epoch  0, batch   177 | loss: 2.1490946
MixupTrain:  epoch  0, batch   178 | loss: 2.4372172
MixupTrain:  epoch  0, batch   179 | loss: 2.7129486
MixupTrain:  epoch  0, batch   180 | loss: 2.3777232
MixupTrain:  epoch  0, batch   181 | loss: 2.3171015
MixupTrain:  epoch  0, batch   182 | loss: 2.5352240
MixupTrain:  epoch  0, batch   183 | loss: 2.7502818
MixupTrain:  epoch  0, batch   184 | loss: 2.8096802
MixupTrain:  epoch  0, batch   185 | loss: 2.4535336
MixupTrain:  epoch  0, batch   186 | loss: 2.6222763
MixupTrain:  epoch  0, batch   187 | loss: 2.5526619
MixupTrain:  epoch  0, batch   188 | loss: 2.4346018
MixupTrain:  epoch  0, batch   189 | loss: 2.2857974
MixupTrain:  epoch  0, batch   190 | loss: 2.4620070
MixupTrain:  epoch  0, batch   191 | loss: 2.5286446
MixupTrain:  epoch  0, batch   192 | loss: 2.3213506
MixupTrain:  epoch  0, batch   193 | loss: 2.7000284
MixupTrain:  epoch  0, batch   194 | loss: 2.1029396
MixupTrain:  epoch  0, batch   195 | loss: 2.4103408
MixupTrain:  epoch  0, batch   196 | loss: 2.5762911
MixupTrain:  epoch  0, batch   197 | loss: 2.7381575
MixupTrain:  epoch  0, batch   198 | loss: 2.2181954
MixupTrain:  epoch  0, batch   199 | loss: 2.5162168
MixupTrain:  epoch  0, batch   200 | loss: 2.4938202
MixupTrain:  epoch  0, batch   201 | loss: 2.9548714
MixupTrain:  epoch  0, batch   202 | loss: 2.6163206
MixupTrain:  epoch  0, batch   203 | loss: 2.5642972
MixupTrain:  epoch  0, batch   204 | loss: 2.6000619
MixupTrain:  epoch  0, batch   205 | loss: 2.6103592
MixupTrain:  epoch  0, batch   206 | loss: 2.4127252
MixupTrain:  epoch  0, batch   207 | loss: 2.3916459
MixupTrain:  epoch  0, batch   208 | loss: 2.5608704
MixupTrain:  epoch  0, batch   209 | loss: 2.5647984
MixupTrain:  epoch  0, batch   210 | loss: 2.4451957
MixupTrain:  epoch  0, batch   211 | loss: 2.4051905
MixupTrain:  epoch  0, batch   212 | loss: 2.3558912
MixupTrain:  epoch  0, batch   213 | loss: 2.3557248
MixupTrain:  epoch  0, batch   214 | loss: 2.7071886
MixupTrain:  epoch  0, batch   215 | loss: 2.6254621
MixupTrain:  epoch  0, batch   216 | loss: 2.4580221
MixupTrain:  epoch  0, batch   217 | loss: 2.5638356
MixupTrain:  epoch  0, batch   218 | loss: 2.6340764
MixupTrain:  epoch  0, batch   219 | loss: 2.3720043
MixupTrain:  epoch  0, batch   220 | loss: 2.2787523
MixupTrain:  epoch  0, batch   221 | loss: 2.3352480
MixupTrain:  epoch  0, batch   222 | loss: 2.5386751
MixupTrain:  epoch  0, batch   223 | loss: 2.6614594
MixupTrain:  epoch  0, batch   224 | loss: 2.8083200
MixupTrain:  epoch  0, batch   225 | loss: 2.3206992
MixupTrain:  epoch  0, batch   226 | loss: 2.6837754
MixupTrain:  epoch  0, batch   227 | loss: 2.6252260
MixupTrain:  epoch  0, batch   228 | loss: 2.4143796
MixupTrain:  epoch  0, batch   229 | loss: 2.3809640
MixupTrain:  epoch  0, batch   230 | loss: 2.5555873
MixupTrain:  epoch  0, batch   231 | loss: 2.5164027
MixupTrain:  epoch  0, batch   232 | loss: 2.2933733
MixupTrain:  epoch  0, batch   233 | loss: 2.4966216
MixupTrain:  epoch  0, batch   234 | loss: 2.6927662
MixupTrain:  epoch  0, batch   235 | loss: 2.5206156
MixupTrain:  epoch  0, batch   236 | loss: 2.7276809
MixupTrain:  epoch  0, batch   237 | loss: 2.4320784
MixupTrain:  epoch  0, batch   238 | loss: 2.9976721
MixupTrain:  epoch  0, batch   239 | loss: 2.6039355
MixupTrain:  epoch  0, batch   240 | loss: 2.4759629
MixupTrain:  epoch  0, batch   241 | loss: 2.3315263
MixupTrain:  epoch  0, batch   242 | loss: 2.3586831
MixupTrain:  epoch  0, batch   243 | loss: 2.5492716
MixupTrain:  epoch  0, batch   244 | loss: 2.5230045
MixupTrain:  epoch  0, batch   245 | loss: 2.5496492
MixupTrain:  epoch  0, batch   246 | loss: 2.4980192
MixupTrain:  epoch  0, batch   247 | loss: 2.6107721
MixupTrain:  epoch  0, batch   248 | loss: 2.5192969
MixupTrain:  epoch  0, batch   249 | loss: 2.5688004
MixupTrain:  epoch  0, batch   250 | loss: 2.0554204
MixupTrain:  epoch  0, batch   251 | loss: 2.9493823
MixupTrain:  epoch  0, batch   252 | loss: 2.4214964
MixupTrain:  epoch  0, batch   253 | loss: 2.4733717
MixupTrain:  epoch  0, batch   254 | loss: 2.8708797
MixupTrain:  epoch  0, batch   255 | loss: 2.2646523
MixupTrain:  epoch  0, batch   256 | loss: 2.4291883
MixupTrain:  epoch  0, batch   257 | loss: 2.5052760
MixupTrain:  epoch  0, batch   258 | loss: 2.6389503
MixupTrain:  epoch  0, batch   259 | loss: 2.7658472
MixupTrain:  epoch  0, batch   260 | loss: 2.4093707
MixupTrain:  epoch  0, batch   261 | loss: 2.5723510
MixupTrain:  epoch  0, batch   262 | loss: 2.5507669
MixupTrain:  epoch  0, batch   263 | loss: 2.4099503
MixupTrain:  epoch  0, batch   264 | loss: 2.5775924
MixupTrain:  epoch  0, batch   265 | loss: 2.3990979
MixupTrain:  epoch  0, batch   266 | loss: 2.2126777
MixupTrain:  epoch  0, batch   267 | loss: 2.3451319
MixupTrain:  epoch  0, batch   268 | loss: 2.2687373
MixupTrain:  epoch  0, batch   269 | loss: 2.3247225
MixupTrain:  epoch  0, batch   270 | loss: 2.3909688
MixupTrain:  epoch  0, batch   271 | loss: 2.4677544
MixupTrain:  epoch  0, batch   272 | loss: 2.5257800
MixupTrain:  epoch  0, batch   273 | loss: 2.4383185
MixupTrain:  epoch  0, batch   274 | loss: 2.6431611
MixupTrain:  epoch  0, batch   275 | loss: 2.4264185
MixupTrain:  epoch  0, batch   276 | loss: 2.2869189
MixupTrain:  epoch  0, batch   277 | loss: 2.3773160
MixupTrain:  epoch  0, batch   278 | loss: 2.4944973
MixupTrain:  epoch  0, batch   279 | loss: 2.3783636
MixupTrain:  epoch  0, batch   280 | loss: 2.3531134
MixupTrain:  epoch  0, batch   281 | loss: 2.3886156
MixupTrain:  epoch  0, batch   282 | loss: 2.3819690
MixupTrain:  epoch  0, batch   283 | loss: 2.5891826
MixupTrain:  epoch  0, batch   284 | loss: 2.8573942
MixupTrain:  epoch  0, batch   285 | loss: 2.4254265
MixupTrain:  epoch  0, batch   286 | loss: 2.3784130
MixupTrain:  epoch  0, batch   287 | loss: 2.6582024
MixupTrain:  epoch  0, batch   288 | loss: 2.3236547
MixupTrain:  epoch  0, batch   289 | loss: 2.3745325
MixupTrain:  epoch  0, batch   290 | loss: 2.2571845
MixupTrain:  epoch  0, batch   291 | loss: 2.5944903
MixupTrain:  epoch  0, batch   292 | loss: 2.5849853
MixupTrain:  epoch  0, batch   293 | loss: 1.9460001
MixupTrain:  epoch  0, batch   294 | loss: 2.4753051
MixupTrain:  epoch  0, batch   295 | loss: 2.2138028
MixupTrain:  epoch  0, batch   296 | loss: 2.3403568
MixupTrain:  epoch  0, batch   297 | loss: 2.2027750
MixupTrain:  epoch  0, batch   298 | loss: 2.4311814
MixupTrain:  epoch  0, batch   299 | loss: 2.6514826
MixupTrain:  epoch  0, batch   300 | loss: 2.2698586
MixupTrain:  epoch  0, batch   301 | loss: 2.3543415
MixupTrain:  epoch  0, batch   302 | loss: 2.5167632
MixupTrain:  epoch  0, batch   303 | loss: 2.2387516
MixupTrain:  epoch  0, batch   304 | loss: 2.3106408
MixupTrain:  epoch  0, batch   305 | loss: 2.5035601
MixupTrain:  epoch  0, batch   306 | loss: 2.3831360
MixupTrain:  epoch  0, batch   307 | loss: 2.5530448
MixupTrain:  epoch  0, batch   308 | loss: 2.2228527
MixupTrain:  epoch  0, batch   309 | loss: 2.2661643
MixupTrain:  epoch  0, batch   310 | loss: 2.2271743
MixupTrain:  epoch  0, batch   311 | loss: 2.3747714
MixupTrain:  epoch  0, batch   312 | loss: 2.4080105
MixupTrain:  epoch  0, batch   313 | loss: 2.7887623
MixupTrain:  epoch  0, batch   314 | loss: 2.4647911
MixupTrain:  epoch  0, batch   315 | loss: 2.4939852
MixupTrain:  epoch  0, batch   316 | loss: 2.3284237
MixupTrain:  epoch  0, batch   317 | loss: 2.4868054
MixupTrain:  epoch  0, batch   318 | loss: 2.4275208
MixupTrain:  epoch  0, batch   319 | loss: 2.4771624
MixupTrain:  epoch  0, batch   320 | loss: 2.7166853
MixupTrain:  epoch  0, batch   321 | loss: 2.6136916
MixupTrain:  epoch  0, batch   322 | loss: 2.3253131
MixupTrain:  epoch  0, batch   323 | loss: 2.6733658
MixupTrain:  epoch  0, batch   324 | loss: 2.2967477
MixupTrain:  epoch  0, batch   325 | loss: 2.3518639
MixupTrain:  epoch  0, batch   326 | loss: 2.4813814
MixupTrain:  epoch  0, batch   327 | loss: 2.5325253
MixupTrain:  epoch  0, batch   328 | loss: 2.6996584
MixupTrain:  epoch  0, batch   329 | loss: 2.4741590
MixupTrain:  epoch  0, batch   330 | loss: 2.4906492
MixupTrain:  epoch  0, batch   331 | loss: 2.6318474
MixupTrain:  epoch  0, batch   332 | loss: 2.5222673
MixupTrain:  epoch  0, batch   333 | loss: 2.6113377
MixupTrain:  epoch  0, batch   334 | loss: 2.1518874
MixupTrain:  epoch  0, batch   335 | loss: 2.3272195
MixupTrain:  epoch  0, batch   336 | loss: 2.6222939
MixupTrain:  epoch  0, batch   337 | loss: 2.2755299
MixupTrain:  epoch  0, batch   338 | loss: 2.6360450
MixupTrain:  epoch  0, batch   339 | loss: 2.3925121
MixupTrain:  epoch  0, batch   340 | loss: 2.4733829
MixupTrain:  epoch  0, batch   341 | loss: 2.2252226
MixupTrain:  epoch  0, batch   342 | loss: 2.4222960
MixupTrain:  epoch  0, batch   343 | loss: 2.3943031
MixupTrain:  epoch  0, batch   344 | loss: 2.4948192
MixupTrain:  epoch  0, batch   345 | loss: 2.5363817
MixupTrain:  epoch  0, batch   346 | loss: 2.2532191
MixupTrain:  epoch  0, batch   347 | loss: 2.1844325
MixupTrain:  epoch  0, batch   348 | loss: 2.4492488
MixupTrain:  epoch  0, batch   349 | loss: 2.1476698
MixupTrain:  epoch  0, batch   350 | loss: 2.5247359
MixupTrain:  epoch  0, batch   351 | loss: 2.0841608
MixupTrain:  epoch  0, batch   352 | loss: 2.4432178
MixupTrain:  epoch  0, batch   353 | loss: 2.7272041
MixupTrain:  epoch  0, batch   354 | loss: 2.4586210
MixupTrain:  epoch  0, batch   355 | loss: 2.4415658
MixupTrain:  epoch  0, batch   356 | loss: 2.3387513
MixupTrain:  epoch  0, batch   357 | loss: 1.9260230
MixupTrain:  epoch  0, batch   358 | loss: 2.1683893
MixupTrain:  epoch  0, batch   359 | loss: 2.6183624
MixupTrain:  epoch  0, batch   360 | loss: 2.5598419
MixupTrain:  epoch  0, batch   361 | loss: 2.4141760
MixupTrain:  epoch  0, batch   362 | loss: 2.5322807
MixupTrain:  epoch  0, batch   363 | loss: 2.6693978
MixupTrain:  epoch  0, batch   364 | loss: 2.3834257
MixupTrain:  epoch  0, batch   365 | loss: 2.1053300
MixupTrain:  epoch  0, batch   366 | loss: 2.2515366
MixupTrain:  epoch  0, batch   367 | loss: 2.5748620
MixupTrain:  epoch  0, batch   368 | loss: 2.4283135
MixupTrain:  epoch  0, batch   369 | loss: 2.2366025
MixupTrain:  epoch  0, batch   370 | loss: 2.3636980
MixupTrain:  epoch  0, batch   371 | loss: 2.2457592
MixupTrain:  epoch  0, batch   372 | loss: 2.2528224
MixupTrain:  epoch  0, batch   373 | loss: 2.7425008
MixupTrain:  epoch  0, batch   374 | loss: 2.5248723
MixupTrain:  epoch  0, batch   375 | loss: 2.1848617
MixupTrain:  epoch  0, batch   376 | loss: 2.1831021
MixupTrain:  epoch  0, batch   377 | loss: 2.5117512
MixupTrain:  epoch  0, batch   378 | loss: 2.2870889
MixupTrain:  epoch  0, batch   379 | loss: 2.2208478
MixupTrain:  epoch  0, batch   380 | loss: 2.3102748
MixupTrain:  epoch  0, batch   381 | loss: 2.5545063
MixupTrain:  epoch  0, batch   382 | loss: 2.4760451
MixupTrain:  epoch  0, batch   383 | loss: 2.2819846
MixupTrain:  epoch  0, batch   384 | loss: 2.3059640
MixupTrain:  epoch  0, batch   385 | loss: 2.2430480
MixupTrain:  epoch  0, batch   386 | loss: 2.5691485
MixupTrain:  epoch  0, batch   387 | loss: 2.2592444
MixupTrain:  epoch  0, batch   388 | loss: 2.7203426
MixupTrain:  epoch  0, batch   389 | loss: 2.3794935
MixupTrain:  epoch  0, batch   390 | loss: 2.4695189
MixupTrain:  epoch  0, batch   391 | loss: 2.7079744
MixupTrain:  epoch  0, batch   392 | loss: 2.0671306
MixupTrain:  epoch  0, batch   393 | loss: 2.4438307
MixupTrain:  epoch  0, batch   394 | loss: 2.1979523
MixupTrain:  epoch  0, batch   395 | loss: 2.2800078
MixupTrain:  epoch  0, batch   396 | loss: 2.5589769
MixupTrain:  epoch  0, batch   397 | loss: 2.7135162
MixupTrain:  epoch  0, batch   398 | loss: 2.4026132
MixupTrain:  epoch  0, batch   399 | loss: 2.3603365
MixupTrain:  epoch  0, batch   400 | loss: 2.3708935
MixupTrain:  epoch  0, batch   401 | loss: 2.3795688
MixupTrain:  epoch  0, batch   402 | loss: 2.1422825
MixupTrain:  epoch  0, batch   403 | loss: 2.5238280
MixupTrain:  epoch  0, batch   404 | loss: 2.0910189
MixupTrain:  epoch  0, batch   405 | loss: 2.0291395
MixupTrain:  epoch  0, batch   406 | loss: 2.3249655
MixupTrain:  epoch  0, batch   407 | loss: 2.5412645
MixupTrain:  epoch  0, batch   408 | loss: 2.2276120
MixupTrain:  epoch  0, batch   409 | loss: 2.1327870
MixupTrain:  epoch  0, batch   410 | loss: 2.1773477
MixupTrain:  epoch  0, batch   411 | loss: 2.5295868
MixupTrain:  epoch  0, batch   412 | loss: 2.4078014
MixupTrain:  epoch  0, batch   413 | loss: 2.4186697
MixupTrain:  epoch  0, batch   414 | loss: 2.7193859
MixupTrain:  epoch  0, batch   415 | loss: 2.7824368
MixupTrain:  epoch  0, batch   416 | loss: 2.3937299
MixupTrain:  epoch  0, batch   417 | loss: 2.3674722
MixupTrain:  epoch  0, batch   418 | loss: 2.3601608
MixupTrain:  epoch  0, batch   419 | loss: 2.0499816
MixupTrain:  epoch  0, batch   420 | loss: 2.3059821
MixupTrain:  epoch  0, batch   421 | loss: 2.6328633
MixupTrain:  epoch  0, batch   422 | loss: 2.5317442
MixupTrain:  epoch  0, batch   423 | loss: 2.3733790
MixupTrain:  epoch  0, batch   424 | loss: 2.1946106
MixupTrain:  epoch  0, batch   425 | loss: 2.1564832
MixupTrain:  epoch  0, batch   426 | loss: 2.2782252
MixupTrain:  epoch  0, batch   427 | loss: 2.5360599
MixupTrain:  epoch  0, batch   428 | loss: 2.4495759
MixupTrain:  epoch  0, batch   429 | loss: 2.2325950
MixupTrain:  epoch  0, batch   430 | loss: 2.5435841
MixupTrain:  epoch  0, batch   431 | loss: 2.5068307
MixupTrain:  epoch  0, batch   432 | loss: 2.3569770
MixupTrain:  epoch  0, batch   433 | loss: 2.3553352
MixupTrain:  epoch  0, batch   434 | loss: 2.3462329
MixupTrain:  epoch  0, batch   435 | loss: 2.4568038
MixupTrain:  epoch  0, batch   436 | loss: 2.3145599
MixupTrain:  epoch  0, batch   437 | loss: 2.3512626
MixupTrain:  epoch  0, batch   438 | loss: 2.5940170
MixupTrain:  epoch  0, batch   439 | loss: 2.3898568
MixupTrain:  epoch  0, batch   440 | loss: 2.2246468
MixupTrain:  epoch  0, batch   441 | loss: 2.3994074
MixupTrain:  epoch  0, batch   442 | loss: 2.6503549
MixupTrain:  epoch  0, batch   443 | loss: 2.3404083
MixupTrain:  epoch  0, batch   444 | loss: 2.3660181
MixupTrain:  epoch  0, batch   445 | loss: 2.3859255
MixupTrain:  epoch  0, batch   446 | loss: 2.6837924
MixupTrain:  epoch  0, batch   447 | loss: 2.2229037
MixupTrain:  epoch  0, batch   448 | loss: 1.9633248
MixupTrain:  epoch  0, batch   449 | loss: 2.5378265
MixupTrain:  epoch  0, batch   450 | loss: 2.3880062
MixupTrain:  epoch  0, batch   451 | loss: 2.2293005
MixupTrain:  epoch  0, batch   452 | loss: 2.4540854
MixupTrain:  epoch  0, batch   453 | loss: 2.4657969
MixupTrain:  epoch  0, batch   454 | loss: 2.3831453
MixupTrain:  epoch  0, batch   455 | loss: 2.2996035
MixupTrain:  epoch  0, batch   456 | loss: 2.1778519
MixupTrain:  epoch  0, batch   457 | loss: 2.4879234
MixupTrain:  epoch  0, batch   458 | loss: 2.4913788
MixupTrain:  epoch  0, batch   459 | loss: 2.5601678
MixupTrain:  epoch  0, batch   460 | loss: 2.8508463
MixupTrain:  epoch  0, batch   461 | loss: 2.4448113
MixupTrain:  epoch  0, batch   462 | loss: 2.2765114
MixupTrain:  epoch  0, batch   463 | loss: 2.2913895
MixupTrain:  epoch  0, batch   464 | loss: 2.6099210
MixupTrain:  epoch  0, batch   465 | loss: 2.4404190
MixupTrain:  epoch  0, batch   466 | loss: 2.1108804
MixupTrain:  epoch  0, batch   467 | loss: 2.2666132
MixupTrain:  epoch  0, batch   468 | loss: 2.2785158
MixupTrain:  epoch  0, batch   469 | loss: 2.2693243
MixupTrain:  epoch  0, batch   470 | loss: 2.2886772
MixupTrain:  epoch  0, batch   471 | loss: 2.3868191
MixupTrain:  epoch  0, batch   472 | loss: 2.6915755
MixupTrain:  epoch  0, batch   473 | loss: 2.1978555
MixupTrain:  epoch  0, batch   474 | loss: 2.2186253
MixupTrain:  epoch  0, batch   475 | loss: 2.4380870
MixupTrain:  epoch  0, batch   476 | loss: 2.2579668
MixupTrain:  epoch  0, batch   477 | loss: 2.2393785
MixupTrain:  epoch  0, batch   478 | loss: 2.3053164
MixupTrain:  epoch  0, batch   479 | loss: 2.7708464
MixupTrain:  epoch  0, batch   480 | loss: 2.2506104
MixupTrain:  epoch  0, batch   481 | loss: 2.6685293
MixupTrain:  epoch  0, batch   482 | loss: 2.5687995
MixupTrain:  epoch  0, batch   483 | loss: 2.2892015
MixupTrain:  epoch  0, batch   484 | loss: 2.1834197
MixupTrain:  epoch  0, batch   485 | loss: 2.1893241
MixupTrain:  epoch  0, batch   486 | loss: 2.5201797
MixupTrain:  epoch  0, batch   487 | loss: 2.1036584
MixupTrain:  epoch  0, batch   488 | loss: 2.5011373
MixupTrain:  epoch  0, batch   489 | loss: 2.1958337
MixupTrain:  epoch  0, batch   490 | loss: 2.2860563
MixupTrain:  epoch  0, batch   491 | loss: 2.3948219
MixupTrain:  epoch  0, batch   492 | loss: 2.3613579
MixupTrain:  epoch  0, batch   493 | loss: 2.1016989
MixupTrain:  epoch  0, batch   494 | loss: 2.2509530
MixupTrain:  epoch  0, batch   495 | loss: 2.0067277
MixupTrain:  epoch  0, batch   496 | loss: 2.2195320
MixupTrain:  epoch  0, batch   497 | loss: 2.2901864
MixupTrain:  epoch  0, batch   498 | loss: 2.4509716
MixupTrain:  epoch  0, batch   499 | loss: 2.6552715
MixupTrain:  epoch  0, batch   500 | loss: 2.7220469
MixupTrain:  epoch  0, batch   501 | loss: 1.9169226
MixupTrain:  epoch  0, batch   502 | loss: 2.5161490
MixupTrain:  epoch  0, batch   503 | loss: 2.6380792
MixupTrain:  epoch  0, batch   504 | loss: 2.4990373
MixupTrain:  epoch  0, batch   505 | loss: 2.2900815
MixupTrain:  epoch  0, batch   506 | loss: 2.1829727
MixupTrain:  epoch  0, batch   507 | loss: 2.2259684
MixupTrain:  epoch  0, batch   508 | loss: 2.4919949
MixupTrain:  epoch  0, batch   509 | loss: 2.3484511
MixupTrain:  epoch  0, batch   510 | loss: 2.4711728
MixupTrain:  epoch  0, batch   511 | loss: 2.4581144
MixupTrain:  epoch  0, batch   512 | loss: 2.3879740
MixupTrain:  epoch  0, batch   513 | loss: 2.4995036
MixupTrain:  epoch  0, batch   514 | loss: 2.2397377
MixupTrain:  epoch  0, batch   515 | loss: 2.2650068
MixupTrain:  epoch  0, batch   516 | loss: 2.6246219
MixupTrain:  epoch  0, batch   517 | loss: 2.2519431
MixupTrain:  epoch  0, batch   518 | loss: 2.3344023
MixupTrain:  epoch  0, batch   519 | loss: 2.5484095
MixupTrain:  epoch  0, batch   520 | loss: 2.4193497
MixupTrain:  epoch  0, batch   521 | loss: 2.5229545
MixupTrain:  epoch  0, batch   522 | loss: 2.3524356
MixupTrain:  epoch  0, batch   523 | loss: 2.3705049
MixupTrain:  epoch  0, batch   524 | loss: 2.4198039
MixupTrain:  epoch  0, batch   525 | loss: 2.3143685
MixupTrain:  epoch  0, batch   526 | loss: 2.5088627
MixupTrain:  epoch  0, batch   527 | loss: 2.2744212
MixupTrain:  epoch  0, batch   528 | loss: 2.4408209
MixupTrain:  epoch  0, batch   529 | loss: 2.4242587
MixupTrain:  epoch  0, batch   530 | loss: 2.3621459
MixupTrain:  epoch  0, batch   531 | loss: 2.6319966
MixupTrain:  epoch  0, batch   532 | loss: 2.4121521
MixupTrain:  epoch  0, batch   533 | loss: 2.4374316
MixupTrain:  epoch  0, batch   534 | loss: 2.2444205
MixupTrain:  epoch  0, batch   535 | loss: 2.5179362
MixupTrain:  epoch  0, batch   536 | loss: 2.1925130
MixupTrain:  epoch  0, batch   537 | loss: 2.5375967
MixupTrain:  epoch  0, batch   538 | loss: 2.3573585
MixupTrain:  epoch  0, batch   539 | loss: 2.2921362
MixupTrain:  epoch  0, batch   540 | loss: 2.4112287
MixupTrain:  epoch  0, batch   541 | loss: 2.3865569
MixupTrain:  epoch  0, batch   542 | loss: 2.3873534
MixupTrain:  epoch  0, batch   543 | loss: 2.1920929
MixupTrain:  epoch  0, batch   544 | loss: 2.4597178
MixupTrain:  epoch  0, batch   545 | loss: 2.1511946
MixupTrain:  epoch  0, batch   546 | loss: 2.4416795
MixupTrain:  epoch  0, batch   547 | loss: 2.2751627
MixupTrain:  epoch  0, batch   548 | loss: 2.4855158
MixupTrain:  epoch  0, batch   549 | loss: 2.3048675
MixupTrain:  epoch  0, batch   550 | loss: 2.3337288
MixupTrain:  epoch  0, batch   551 | loss: 2.5190940
MixupTrain:  epoch  0, batch   552 | loss: 2.5474751
MixupTrain:  epoch  0, batch   553 | loss: 2.2554376
MixupTrain:  epoch  0, batch   554 | loss: 2.3709111
MixupTrain:  epoch  0, batch   555 | loss: 2.3014288
MixupTrain:  epoch  0, batch   556 | loss: 2.3072517
MixupTrain:  epoch  0, batch   557 | loss: 2.2585716
MixupTrain:  epoch  0, batch   558 | loss: 2.0816495
MixupTrain:  epoch  0, batch   559 | loss: 2.3729897
MixupTrain:  epoch  0, batch   560 | loss: 2.5203536
MixupTrain:  epoch  0, batch   561 | loss: 2.3462081
MixupTrain:  epoch  0, batch   562 | loss: 2.1584601
MixupTrain:  epoch  0, batch   563 | loss: 2.6001587
MixupTrain:  epoch  0, batch   564 | loss: 2.3490975
MixupTrain:  epoch  0, batch   565 | loss: 2.2957726
MixupTrain:  epoch  0, batch   566 | loss: 2.2175634
MixupTrain:  epoch  0, batch   567 | loss: 2.1626096
MixupTrain:  epoch  0, batch   568 | loss: 2.2223253
MixupTrain:  epoch  0, batch   569 | loss: 2.7013900
MixupTrain:  epoch  0, batch   570 | loss: 2.5009685
MixupTrain:  epoch  0, batch   571 | loss: 2.1547847
MixupTrain:  epoch  0, batch   572 | loss: 2.0954072
MixupTrain:  epoch  0, batch   573 | loss: 2.2234948
MixupTrain:  epoch  0, batch   574 | loss: 2.8207705
MixupTrain:  epoch  0, batch   575 | loss: 2.4479375
MixupTrain:  epoch  0, batch   576 | loss: 2.4666419
MixupTrain:  epoch  0, batch   577 | loss: 2.2430201
MixupTrain:  epoch  0, batch   578 | loss: 2.3354564
MixupTrain:  epoch  0, batch   579 | loss: 2.3226116
MixupTrain:  epoch  0, batch   580 | loss: 2.2234271
MixupTrain:  epoch  0, batch   581 | loss: 2.4233327
MixupTrain:  epoch  0, batch   582 | loss: 2.3014503
MixupTrain:  epoch  0, batch   583 | loss: 2.5349059
MixupTrain:  epoch  0, batch   584 | loss: 2.6733456
MixupTrain:  epoch  0, batch   585 | loss: 2.2406251
MixupTrain:  epoch  0, batch   586 | loss: 2.1760659
MixupTrain:  epoch  0, batch   587 | loss: 2.6778998
MixupTrain:  epoch  0, batch   588 | loss: 2.3078594
MixupTrain:  epoch  0, batch   589 | loss: 2.2266674
MixupTrain:  epoch  0, batch   590 | loss: 2.3438063
MixupTrain:  epoch  0, batch   591 | loss: 2.3375533
MixupTrain:  epoch  0, batch   592 | loss: 2.4171085
MixupTrain:  epoch  0, batch   593 | loss: 2.4220338
MixupTrain:  epoch  0, batch   594 | loss: 2.1370564
MixupTrain:  epoch  0, batch   595 | loss: 2.3451872
MixupTrain:  epoch  0, batch   596 | loss: 2.2612603
MixupTrain:  epoch  0, batch   597 | loss: 2.2883439
MixupTrain:  epoch  0, batch   598 | loss: 2.3478515
MixupTrain:  epoch  0, batch   599 | loss: 2.4029343
MixupTrain:  epoch  0, batch   600 | loss: 2.4691486
MixupTrain:  epoch  0, batch   601 | loss: 2.1828158
MixupTrain:  epoch  0, batch   602 | loss: 2.4161592
MixupTrain:  epoch  0, batch   603 | loss: 2.3316364
MixupTrain:  epoch  0, batch   604 | loss: 2.2292950
MixupTrain:  epoch  0, batch   605 | loss: 2.2489018
MixupTrain:  epoch  0, batch   606 | loss: 2.2002735
MixupTrain:  epoch  0, batch   607 | loss: 2.3941567
MixupTrain:  epoch  0, batch   608 | loss: 2.4356022
MixupTrain:  epoch  0, batch   609 | loss: 2.4298391
MixupTrain:  epoch  0, batch   610 | loss: 2.5683699
MixupTrain:  epoch  0, batch   611 | loss: 2.1787233
MixupTrain:  epoch  0, batch   612 | loss: 2.4799662
MixupTrain:  epoch  0, batch   613 | loss: 2.3284326
MixupTrain:  epoch  0, batch   614 | loss: 2.8219566
MixupTrain:  epoch  0, batch   615 | loss: 2.5375986
MixupTrain:  epoch  0, batch   616 | loss: 2.6788325
MixupTrain:  epoch  0, batch   617 | loss: 2.2900579
MixupTrain:  epoch  0, batch   618 | loss: 2.3063021
MixupTrain:  epoch  0, batch   619 | loss: 2.1817358
MixupTrain:  epoch  0, batch   620 | loss: 2.0056233
MixupTrain:  epoch  0, batch   621 | loss: 2.5110283
MixupTrain:  epoch  0, batch   622 | loss: 2.2336943
MixupTrain:  epoch  0, batch   623 | loss: 2.5023665
MixupTrain:  epoch  0, batch   624 | loss: 2.0954533
MixupTrain:  epoch  0, batch   625 | loss: 2.2133880
MixupTrain:  epoch  0, batch   626 | loss: 2.3986232
MixupTrain:  epoch  0, batch   627 | loss: 2.5037010
MixupTrain:  epoch  0, batch   628 | loss: 2.5143795
MixupTrain:  epoch  0, batch   629 | loss: 2.1269126
MixupTrain:  epoch  0, batch   630 | loss: 2.4158597
MixupTrain:  epoch  0, batch   631 | loss: 2.1309299
MixupTrain:  epoch  0, batch   632 | loss: 2.5115905
MixupTrain:  epoch  0, batch   633 | loss: 2.1890922
MixupTrain:  epoch  0, batch   634 | loss: 2.3070817
MixupTrain:  epoch  0, batch   635 | loss: 2.4662476
MixupTrain:  epoch  0, batch   636 | loss: 2.2162676
MixupTrain:  epoch  0, batch   637 | loss: 2.3409362
MixupTrain:  epoch  0, batch   638 | loss: 2.4012308
MixupTrain:  epoch  0, batch   639 | loss: 2.2356021
MixupTrain:  epoch  0, batch   640 | loss: 2.3626170
MixupTrain:  epoch  0, batch   641 | loss: 2.5345900
MixupTrain:  epoch  0, batch   642 | loss: 2.2432339
MixupTrain:  epoch  0, batch   643 | loss: 2.4005461
MixupTrain:  epoch  0, batch   644 | loss: 2.2452826
MixupTrain:  epoch  0, batch   645 | loss: 2.4749150
MixupTrain:  epoch  0, batch   646 | loss: 2.4815998
MixupTrain:  epoch  0, batch   647 | loss: 2.3079405
MixupTrain:  epoch  0, batch   648 | loss: 2.2720184
MixupTrain:  epoch  0, batch   649 | loss: 2.2418294
MixupTrain:  epoch  0, batch   650 | loss: 2.3517995
MixupTrain:  epoch  0, batch   651 | loss: 2.4119582
MixupTrain:  epoch  0, batch   652 | loss: 2.4864068
MixupTrain:  epoch  0, batch   653 | loss: 2.2986279
MixupTrain:  epoch  0, batch   654 | loss: 2.3688440
MixupTrain:  epoch  0, batch   655 | loss: 2.5213351
MixupTrain:  epoch  0, batch   656 | loss: 2.4318860
MixupTrain:  epoch  0, batch   657 | loss: 2.3492985
MixupTrain:  epoch  0, batch   658 | loss: 2.6718488
MixupTrain:  epoch  0, batch   659 | loss: 2.5034788
MixupTrain:  epoch  0, batch   660 | loss: 2.4040799
MixupTrain:  epoch  0, batch   661 | loss: 2.3596144
MixupTrain:  epoch  0, batch   662 | loss: 2.3281384
MixupTrain:  epoch  0, batch   663 | loss: 2.3063831
MixupTrain:  epoch  0, batch   664 | loss: 2.3514504
MixupTrain:  epoch  0, batch   665 | loss: 2.3571765
MixupTrain:  epoch  0, batch   666 | loss: 2.1116378
MixupTrain:  epoch  0, batch   667 | loss: 2.2072990
MixupTrain:  epoch  0, batch   668 | loss: 2.3355732
MixupTrain:  epoch  0, batch   669 | loss: 2.2638967
MixupTrain:  epoch  0, batch   670 | loss: 2.3388226
MixupTrain:  epoch  0, batch   671 | loss: 2.3970885
MixupTrain:  epoch  0, batch   672 | loss: 2.5522861
MixupTrain:  epoch  0, batch   673 | loss: 2.3280029
MixupTrain:  epoch  0, batch   674 | loss: 2.3743129
MixupTrain:  epoch  0, batch   675 | loss: 2.3767772
MixupTrain:  epoch  0, batch   676 | loss: 2.3756976
MixupTrain:  epoch  0, batch   677 | loss: 2.3322580
MixupTrain:  epoch  0, batch   678 | loss: 2.3915133
MixupTrain:  epoch  0, batch   679 | loss: 2.2768917
MixupTrain:  epoch  0, batch   680 | loss: 2.4244924
MixupTrain:  epoch  0, batch   681 | loss: 2.2293646
MixupTrain:  epoch  0, batch   682 | loss: 2.4404528
MixupTrain:  epoch  0, batch   683 | loss: 2.4202628
MixupTrain:  epoch  0, batch   684 | loss: 2.1117420
MixupTrain:  epoch  0, batch   685 | loss: 2.5077202
MixupTrain:  epoch  0, batch   686 | loss: 2.3507843
MixupTrain:  epoch  0, batch   687 | loss: 2.1579914
MixupTrain:  epoch  0, batch   688 | loss: 2.2109101
MixupTrain:  epoch  0, batch   689 | loss: 2.2214909
MixupTrain:  epoch  0, batch   690 | loss: 2.4578264
MixupTrain:  epoch  0, batch   691 | loss: 2.4726555
MixupTrain:  epoch  0, batch   692 | loss: 2.2474577
MixupTrain:  epoch  0, batch   693 | loss: 2.2961950
MixupTrain:  epoch  0, batch   694 | loss: 2.6073580
MixupTrain:  epoch  0, batch   695 | loss: 2.2043219
MixupTrain:  epoch  0, batch   696 | loss: 2.2298546
MixupTrain:  epoch  0, batch   697 | loss: 2.4752302
MixupTrain:  epoch  0, batch   698 | loss: 2.3863513
MixupTrain:  epoch  0, batch   699 | loss: 2.2432184
MixupTrain:  epoch  0, batch   700 | loss: 2.1800494
MixupTrain:  epoch  0, batch   701 | loss: 2.2203159
MixupTrain:  epoch  0, batch   702 | loss: 2.3570838
MixupTrain:  epoch  0, batch   703 | loss: 2.5523396
MixupTrain:  epoch  0, batch   704 | loss: 2.4179983
MixupTrain:  epoch  0, batch   705 | loss: 2.3600593
MixupTrain:  epoch  0, batch   706 | loss: 2.3773389
MixupTrain:  epoch  0, batch   707 | loss: 2.2329946
MixupTrain:  epoch  0, batch   708 | loss: 2.4234385
MixupTrain:  epoch  0, batch   709 | loss: 2.4657466
MixupTrain:  epoch  0, batch   710 | loss: 2.4361687
MixupTrain:  epoch  0, batch   711 | loss: 2.3729959
MixupTrain:  epoch  0, batch   712 | loss: 2.3405769
MixupTrain:  epoch  0, batch   713 | loss: 2.3242779
MixupTrain:  epoch  0, batch   714 | loss: 2.1440926
MixupTrain:  epoch  0, batch   715 | loss: 2.2220140
MixupTrain:  epoch  0, batch   716 | loss: 2.4823875
MixupTrain:  epoch  0, batch   717 | loss: 2.7147150
MixupTrain:  epoch  0, batch   718 | loss: 2.2513490
MixupTrain:  epoch  0, batch   719 | loss: 2.3166502
MixupTrain:  epoch  0, batch   720 | loss: 2.6161475
MixupTrain:  epoch  0, batch   721 | loss: 2.4092622
MixupTrain:  epoch  0, batch   722 | loss: 2.3214650
MixupTrain:  epoch  0, batch   723 | loss: 2.6492906
MixupTrain:  epoch  0, batch   724 | loss: 2.3187304
MixupTrain:  epoch  0, batch   725 | loss: 2.4355106
MixupTrain:  epoch  0, batch   726 | loss: 2.3768477
MixupTrain:  epoch  0, batch   727 | loss: 2.3622508
MixupTrain:  epoch  0, batch   728 | loss: 2.0697274
MixupTrain:  epoch  0, batch   729 | loss: 2.6655726
MixupTrain:  epoch  0, batch   730 | loss: 2.3705029
MixupTrain:  epoch  0, batch   731 | loss: 2.4225087
MixupTrain:  epoch  0, batch   732 | loss: 2.1631413
MixupTrain:  epoch  0, batch   733 | loss: 2.2698169
MixupTrain:  epoch  0, batch   734 | loss: 2.2854452
MixupTrain:  epoch  0, batch   735 | loss: 2.4117723
MixupTrain:  epoch  0, batch   736 | loss: 2.5780678
MixupTrain:  epoch  0, batch   737 | loss: 2.3630173
MixupTrain:  epoch  0, batch   738 | loss: 2.1469293
MixupTrain:  epoch  0, batch   739 | loss: 2.3518586
MixupTrain:  epoch  0, batch   740 | loss: 2.3664560
MixupTrain:  epoch  0, batch   741 | loss: 2.3297448
MixupTrain:  epoch  0, batch   742 | loss: 2.4148288
MixupTrain:  epoch  0, batch   743 | loss: 2.6901422
MixupTrain:  epoch  0, batch   744 | loss: 2.4318650
MixupTrain:  epoch  0, batch   745 | loss: 2.4359269
MixupTrain:  epoch  0, batch   746 | loss: 2.0505915
MixupTrain:  epoch  0, batch   747 | loss: 2.1405747
MixupTrain:  epoch  0, batch   748 | loss: 2.3504534
MixupTrain:  epoch  0, batch   749 | loss: 2.4410346
MixupTrain:  epoch  0, batch   750 | loss: 2.3794882
MixupTrain:  epoch  0, batch   751 | loss: 2.3843346
MixupTrain:  epoch  0, batch   752 | loss: 2.3035924
MixupTrain:  epoch  0, batch   753 | loss: 2.2982621
MixupTrain:  epoch  0, batch   754 | loss: 2.5123022
MixupTrain:  epoch  0, batch   755 | loss: 2.5083776
MixupTrain:  epoch  0, batch   756 | loss: 2.1643298
MixupTrain:  epoch  0, batch   757 | loss: 2.3866944
MixupTrain:  epoch  0, batch   758 | loss: 2.3093898
MixupTrain:  epoch  0, batch   759 | loss: 2.3305290
MixupTrain:  epoch  0, batch   760 | loss: 2.4977045
MixupTrain:  epoch  0, batch   761 | loss: 2.4027820
MixupTrain:  epoch  0, batch   762 | loss: 2.3805599
MixupTrain:  epoch  0, batch   763 | loss: 2.2873883
MixupTrain:  epoch  0, batch   764 | loss: 2.5161841
MixupTrain:  epoch  0, batch   765 | loss: 2.4602432
MixupTrain:  epoch  0, batch   766 | loss: 2.2324347
MixupTrain:  epoch  0, batch   767 | loss: 2.3904781
MixupTrain:  epoch  0, batch   768 | loss: 2.2268531
MixupTrain:  epoch  0, batch   769 | loss: 2.2379704
MixupTrain:  epoch  0, batch   770 | loss: 2.3195505
MixupTrain:  epoch  0, batch   771 | loss: 2.3803866
MixupTrain:  epoch  0, batch   772 | loss: 2.1522489
MixupTrain:  epoch  0, batch   773 | loss: 2.4593096
MixupTrain:  epoch  0, batch   774 | loss: 2.4592147
MixupTrain:  epoch  0, batch   775 | loss: 2.5224061
MixupTrain:  epoch  0, batch   776 | loss: 2.5249872
MixupTrain:  epoch  0, batch   777 | loss: 2.2197738
MixupTrain:  epoch  0, batch   778 | loss: 2.6547661
MixupTrain:  epoch  0, batch   779 | loss: 2.4195437
MixupTrain:  epoch  0, batch   780 | loss: 2.1257331
MixupTrain:  epoch  0, batch   781 | loss: 2.5115087
MixupTrain:  epoch  0, batch   782 | loss: 2.1148300
MixupTrain:  epoch  0, batch   783 | loss: 2.3837707
MixupTrain:  epoch  0, batch   784 | loss: 2.3566043
MixupTrain:  epoch  0, batch   785 | loss: 2.4042640
MixupTrain:  epoch  0, batch   786 | loss: 2.4046984
MixupTrain:  epoch  0, batch   787 | loss: 2.6055150
MixupTrain:  epoch  0, batch   788 | loss: 2.4434426
MixupTrain:  epoch  0, batch   789 | loss: 2.4486265
MixupTrain:  epoch  0, batch   790 | loss: 2.3896163
MixupTrain:  epoch  0, batch   791 | loss: 2.3324800
MixupTrain:  epoch  0, batch   792 | loss: 2.3215270
MixupTrain:  epoch  0, batch   793 | loss: 2.3457665
MixupTrain:  epoch  0, batch   794 | loss: 2.6231868
MixupTrain:  epoch  0, batch   795 | loss: 2.2800045
MixupTrain:  epoch  0, batch   796 | loss: 2.0597668
MixupTrain:  epoch  0, batch   797 | loss: 2.3137071
MixupTrain:  epoch  0, batch   798 | loss: 2.4741354
MixupTrain:  epoch  0, batch   799 | loss: 2.3542194
MixupTrain:  epoch  0, batch   800 | loss: 2.3956709
MixupTrain:  epoch  0, batch   801 | loss: 2.1139545
MixupTrain:  epoch  0, batch   802 | loss: 2.7212505
MixupTrain:  epoch  0, batch   803 | loss: 2.4904182
MixupTrain:  epoch  0, batch   804 | loss: 2.3924701
MixupTrain:  epoch  0, batch   805 | loss: 2.4351215
MixupTrain:  epoch  0, batch   806 | loss: 2.3842275
MixupTrain:  epoch  0, batch   807 | loss: 2.7557914
MixupTrain:  epoch  0, batch   808 | loss: 2.2782490
MixupTrain:  epoch  0, batch   809 | loss: 2.4133430
MixupTrain:  epoch  0, batch   810 | loss: 2.2401390
MixupTrain:  epoch  0, batch   811 | loss: 2.3557878
MixupTrain:  epoch  0, batch   812 | loss: 2.2386250
MixupTrain:  epoch  0, batch   813 | loss: 2.7831764
MixupTrain:  epoch  0, batch   814 | loss: 2.6349487
MixupTrain:  epoch  0, batch   815 | loss: 2.3126984
MixupTrain:  epoch  0, batch   816 | loss: 2.5897129
MixupTrain:  epoch  0, batch   817 | loss: 2.3236308
MixupTrain:  epoch  0, batch   818 | loss: 2.3434880
MixupTrain:  epoch  0, batch   819 | loss: 2.3538008
MixupTrain:  epoch  0, batch   820 | loss: 2.3046579
MixupTrain:  epoch  0, batch   821 | loss: 2.0360615
MixupTrain:  epoch  0, batch   822 | loss: 2.0998728
MixupTrain:  epoch  0, batch   823 | loss: 2.4456751
MixupTrain:  epoch  0, batch   824 | loss: 2.4550495
MixupTrain:  epoch  0, batch   825 | loss: 2.3077490
MixupTrain:  epoch  0, batch   826 | loss: 2.2710485
MixupTrain:  epoch  0, batch   827 | loss: 2.2153530
MixupTrain:  epoch  0, batch   828 | loss: 2.4472184
MixupTrain:  epoch  0, batch   829 | loss: 2.2925558
MixupTrain:  epoch  0, batch   830 | loss: 2.3260915
MixupTrain:  epoch  0, batch   831 | loss: 2.5550840
MixupTrain:  epoch  0, batch   832 | loss: 2.3050799
MixupTrain:  epoch  0, batch   833 | loss: 2.2887411
MixupTrain:  epoch  0, batch   834 | loss: 2.3732042
MixupTrain:  epoch  0, batch   835 | loss: 2.1886744
MixupTrain:  epoch  0, batch   836 | loss: 2.4966986
MixupTrain:  epoch  0, batch   837 | loss: 2.4799945
MixupTrain:  epoch  0, batch   838 | loss: 2.0557766
MixupTrain:  epoch  0, batch   839 | loss: 2.4262643
MixupTrain:  epoch  0, batch   840 | loss: 2.3818803
MixupTrain:  epoch  0, batch   841 | loss: 2.3854737
MixupTrain:  epoch  0, batch   842 | loss: 2.2736721
MixupTrain:  epoch  0, batch   843 | loss: 2.3440409
MixupTrain:  epoch  0, batch   844 | loss: 2.2212291
MixupTrain:  epoch  0, batch   845 | loss: 2.3037999
MixupTrain:  epoch  0, batch   846 | loss: 2.1134501
MixupTrain:  epoch  0, batch   847 | loss: 2.3844390
MixupTrain:  epoch  0, batch   848 | loss: 2.2230470
MixupTrain:  epoch  0, batch   849 | loss: 2.1324129
MixupTrain:  epoch  0, batch   850 | loss: 2.3514078
MixupTrain:  epoch  0, batch   851 | loss: 2.3657050
MixupTrain:  epoch  0, batch   852 | loss: 2.4269619
MixupTrain:  epoch  0, batch   853 | loss: 2.4735951
MixupTrain:  epoch  0, batch   854 | loss: 2.0589373
MixupTrain:  epoch  0, batch   855 | loss: 2.2498493
MixupTrain:  epoch  0, batch   856 | loss: 2.3652284
MixupTrain:  epoch  0, batch   857 | loss: 2.2082436
MixupTrain:  epoch  0, batch   858 | loss: 2.2619722
MixupTrain:  epoch  0, batch   859 | loss: 2.1972775
MixupTrain:  epoch  0, batch   860 | loss: 2.2541575
MixupTrain:  epoch  0, batch   861 | loss: 2.3660398
MixupTrain:  epoch  0, batch   862 | loss: 2.2727971
MixupTrain:  epoch  0, batch   863 | loss: 2.5768943
MixupTrain:  epoch  0, batch   864 | loss: 2.6609566
MixupTrain:  epoch  0, batch   865 | loss: 2.1804080
MixupTrain:  epoch  0, batch   866 | loss: 2.2570708
MixupTrain:  epoch  0, batch   867 | loss: 2.2488871
MixupTrain:  epoch  0, batch   868 | loss: 2.2839444
MixupTrain:  epoch  0, batch   869 | loss: 2.1096349
MixupTrain:  epoch  0, batch   870 | loss: 2.2236352
MixupTrain:  epoch  0, batch   871 | loss: 2.3511662
MixupTrain:  epoch  0, batch   872 | loss: 2.2536445
MixupTrain:  epoch  0, batch   873 | loss: 2.4811392
MixupTrain:  epoch  0, batch   874 | loss: 2.3947570
MixupTrain:  epoch  0, batch   875 | loss: 2.4234819
MixupTrain:  epoch  0, batch   876 | loss: 2.2821541
MixupTrain:  epoch  0, batch   877 | loss: 2.4923444
MixupTrain:  epoch  0, batch   878 | loss: 2.4278750
MixupTrain:  epoch  0, batch   879 | loss: 2.3130360
MixupTrain:  epoch  0, batch   880 | loss: 2.4706287
MixupTrain:  epoch  0, batch   881 | loss: 2.3543100
MixupTrain:  epoch  0, batch   882 | loss: 2.2812872
MixupTrain:  epoch  0, batch   883 | loss: 2.3207977
MixupTrain:  epoch  0, batch   884 | loss: 2.3788419
MixupTrain:  epoch  0, batch   885 | loss: 2.1044459
MixupTrain:  epoch  0, batch   886 | loss: 2.1824317
MixupTrain:  epoch  0, batch   887 | loss: 2.3284404
MixupTrain:  epoch  0, batch   888 | loss: 2.4292388
MixupTrain:  epoch  0, batch   889 | loss: 2.0427625
MixupTrain:  epoch  0, batch   890 | loss: 2.3756351
MixupTrain:  epoch  0, batch   891 | loss: 2.3950291
MixupTrain:  epoch  0, batch   892 | loss: 2.2587192
MixupTrain:  epoch  0, batch   893 | loss: 2.3888109
MixupTrain:  epoch  0, batch   894 | loss: 2.4714928
MixupTrain:  epoch  0, batch   895 | loss: 2.2945249
MixupTrain:  epoch  0, batch   896 | loss: 2.3400974
MixupTrain:  epoch  0, batch   897 | loss: 2.2367036
MixupTrain:  epoch  0, batch   898 | loss: 2.2677169
MixupTrain:  epoch  0, batch   899 | loss: 2.4030919
MixupTrain:  epoch  0, batch   900 | loss: 2.3617764
MixupTrain:  epoch  0, batch   901 | loss: 2.3929350
MixupTrain:  epoch  0, batch   902 | loss: 2.5317237
MixupTrain:  epoch  0, batch   903 | loss: 2.4889164
MixupTrain:  epoch  0, batch   904 | loss: 2.4102826
MixupTrain:  epoch  0, batch   905 | loss: 2.3589211
MixupTrain:  epoch  0, batch   906 | loss: 2.1736572
MixupTrain:  epoch  0, batch   907 | loss: 2.3810918
MixupTrain:  epoch  0, batch   908 | loss: 2.3528101
MixupTrain:  epoch  0, batch   909 | loss: 2.1739259
MixupTrain:  epoch  0, batch   910 | loss: 2.3851368
MixupTrain:  epoch  0, batch   911 | loss: 2.1971569
MixupTrain:  epoch  0, batch   912 | loss: 2.3238978
MixupTrain:  epoch  0, batch   913 | loss: 2.4587073
MixupTrain:  epoch  0, batch   914 | loss: 2.2888007
MixupTrain:  epoch  0, batch   915 | loss: 2.4433832
MixupTrain:  epoch  0, batch   916 | loss: 2.2611156
MixupTrain:  epoch  0, batch   917 | loss: 2.3680151
MixupTrain:  epoch  0, batch   918 | loss: 2.1446967
MixupTrain:  epoch  0, batch   919 | loss: 2.4877191
MixupTrain:  epoch  0, batch   920 | loss: 2.4600739
MixupTrain:  epoch  0, batch   921 | loss: 2.4990110
MixupTrain:  epoch  0, batch   922 | loss: 2.6079333
MixupTrain:  epoch  0, batch   923 | loss: 2.3428836
MixupTrain:  epoch  0, batch   924 | loss: 2.3905878
MixupTrain:  epoch  0, batch   925 | loss: 2.3762412
MixupTrain:  epoch  0, batch   926 | loss: 2.5196092
MixupTrain:  epoch  0, batch   927 | loss: 2.3191147
MixupTrain:  epoch  0, batch   928 | loss: 2.2107556
MixupTrain:  epoch  0, batch   929 | loss: 2.5115213
MixupTrain:  epoch  0, batch   930 | loss: 2.0264492
MixupTrain:  epoch  0, batch   931 | loss: 2.3427367
MixupTrain:  epoch  0, batch   932 | loss: 2.3954093
MixupTrain:  epoch  0, batch   933 | loss: 2.1415038
MixupTrain:  epoch  0, batch   934 | loss: 2.4236417
MixupTrain:  epoch  0, batch   935 | loss: 2.4678483
MixupTrain:  epoch  0, batch   936 | loss: 2.7204804
MixupTrain:  epoch  0, batch   937 | loss: 2.3174310
MixupTrain:  epoch  0, batch   938 | loss: 2.3910260
MixupTrain:  epoch  0, batch   939 | loss: 2.2269657
MixupTrain:  epoch  0, batch   940 | loss: 2.3365107
MixupTrain:  epoch  0, batch   941 | loss: 2.4906454
MixupTrain:  epoch  0, batch   942 | loss: 2.2677679
MixupTrain:  epoch  0, batch   943 | loss: 2.4498472
MixupTrain:  epoch  0, batch   944 | loss: 2.1734164
MixupTrain:  epoch  0, batch   945 | loss: 2.5081582
MixupTrain:  epoch  0, batch   946 | loss: 2.1734221
MixupTrain:  epoch  0, batch   947 | loss: 2.3882346
MixupTrain:  epoch  0, batch   948 | loss: 2.3104997
MixupTrain:  epoch  0, batch   949 | loss: 2.4121523
MixupTrain:  epoch  0, batch   950 | loss: 2.4473290
MixupTrain:  epoch  0, batch   951 | loss: 2.6261764
MixupTrain:  epoch  0, batch   952 | loss: 2.3444529
MixupTrain:  epoch  0, batch   953 | loss: 2.3108227
MixupTrain:  epoch  0, batch   954 | loss: 2.3093266
MixupTrain:  epoch  0, batch   955 | loss: 2.4678900
MixupTrain:  epoch  0, batch   956 | loss: 2.4474533
MixupTrain:  epoch  0, batch   957 | loss: 2.0894108
MixupTrain:  epoch  0, batch   958 | loss: 2.2742558
MixupTrain:  epoch  0, batch   959 | loss: 2.2115083
MixupTrain:  epoch  0, batch   960 | loss: 2.4310596
MixupTrain:  epoch  0, batch   961 | loss: 2.1339786
MixupTrain:  epoch  0, batch   962 | loss: 2.2025409
MixupTrain:  epoch  0, batch   963 | loss: 2.3368754
MixupTrain:  epoch  0, batch   964 | loss: 2.3004987
MixupTrain:  epoch  0, batch   965 | loss: 2.6317379
MixupTrain:  epoch  0, batch   966 | loss: 2.4036703
MixupTrain:  epoch  0, batch   967 | loss: 2.2049232
MixupTrain:  epoch  0, batch   968 | loss: 2.4128022
MixupTrain:  epoch  0, batch   969 | loss: 2.2928209
MixupTrain:  epoch  0, batch   970 | loss: 2.2037003
MixupTrain:  epoch  0, batch   971 | loss: 2.2636721
MixupTrain:  epoch  0, batch   972 | loss: 2.0994132
MixupTrain:  epoch  0, batch   973 | loss: 2.4558983
MixupTrain:  epoch  0, batch   974 | loss: 2.4502678
MixupTrain:  epoch  0, batch   975 | loss: 2.3409486
MixupTrain:  epoch  0, batch   976 | loss: 2.4312987
MixupTrain:  epoch  0, batch   977 | loss: 2.3867035
MixupTrain:  epoch  0, batch   978 | loss: 2.3206136
MixupTrain:  epoch  0, batch   979 | loss: 2.3613143
MixupTrain:  epoch  0, batch   980 | loss: 2.2361274
MixupTrain:  epoch  0, batch   981 | loss: 2.4315243
MixupTrain:  epoch  0, batch   982 | loss: 2.1417274
MixupTrain:  epoch  0, batch   983 | loss: 2.2609882
MixupTrain:  epoch  0, batch   984 | loss: 2.1561699
MixupTrain:  epoch  0, batch   985 | loss: 2.3159857
MixupTrain:  epoch  0, batch   986 | loss: 2.2651010
MixupTrain:  epoch  0, batch   987 | loss: 2.4242983
MixupTrain:  epoch  0, batch   988 | loss: 2.2113776
MixupTrain:  epoch  0, batch   989 | loss: 2.4005890
MixupTrain:  epoch  0, batch   990 | loss: 2.0984659
MixupTrain:  epoch  0, batch   991 | loss: 2.4163218
MixupTrain:  epoch  0, batch   992 | loss: 2.5626390
MixupTrain:  epoch  0, batch   993 | loss: 2.1545386
MixupTrain:  epoch  0, batch   994 | loss: 2.2873130
MixupTrain:  epoch  0, batch   995 | loss: 2.4013715
MixupTrain:  epoch  0, batch   996 | loss: 2.5844176
MixupTrain:  epoch  0, batch   997 | loss: 2.1746726
MixupTrain:  epoch  0, batch   998 | loss: 2.2453618
MixupTrain:  epoch  0, batch   999 | loss: 2.3107967
MixupTrain:  epoch  0, batch  1000 | loss: 2.3054972
MixupTrain:  epoch  0, batch  1001 | loss: 2.4141974
MixupTrain:  epoch  0, batch  1002 | loss: 2.1955440
MixupTrain:  epoch  0, batch  1003 | loss: 2.4392562
MixupTrain:  epoch  0, batch  1004 | loss: 2.1896057
MixupTrain:  epoch  0, batch  1005 | loss: 2.2848766
MixupTrain:  epoch  0, batch  1006 | loss: 2.2619853
MixupTrain:  epoch  0, batch  1007 | loss: 2.4808745
MixupTrain:  epoch  0, batch  1008 | loss: 2.2961512
MixupTrain:  epoch  0, batch  1009 | loss: 2.3327289
MixupTrain:  epoch  0, batch  1010 | loss: 2.5533857
MixupTrain:  epoch  0, batch  1011 | loss: 2.2448020
MixupTrain:  epoch  0, batch  1012 | loss: 2.3178284
MixupTrain:  epoch  0, batch  1013 | loss: 2.3559437
MixupTrain:  epoch  0, batch  1014 | loss: 2.3247490
MixupTrain:  epoch  0, batch  1015 | loss: 2.5725927
MixupTrain:  epoch  0, batch  1016 | loss: 2.6592770
MixupTrain:  epoch  0, batch  1017 | loss: 2.4169612
MixupTrain:  epoch  0, batch  1018 | loss: 2.1919963
MixupTrain:  epoch  0, batch  1019 | loss: 2.4079690
MixupTrain:  epoch  0, batch  1020 | loss: 2.4504404
MixupTrain:  epoch  0, batch  1021 | loss: 2.5264874
MixupTrain:  epoch  0, batch  1022 | loss: 2.2467306
MixupTrain:  epoch  0, batch  1023 | loss: 2.5185683
MixupTrain:  epoch  0, batch  1024 | loss: 2.5852101
MixupTrain:  epoch  0, batch  1025 | loss: 2.3404074
MixupTrain:  epoch  0, batch  1026 | loss: 2.0377889
MixupTrain:  epoch  0, batch  1027 | loss: 2.3159294
MixupTrain:  epoch  0, batch  1028 | loss: 2.2452543
MixupTrain:  epoch  0, batch  1029 | loss: 2.5927644
MixupTrain:  epoch  0, batch  1030 | loss: 2.5658257
MixupTrain:  epoch  0, batch  1031 | loss: 2.4563198
MixupTrain:  epoch  0, batch  1032 | loss: 2.2918403
MixupTrain:  epoch  0, batch  1033 | loss: 2.1571527
MixupTrain:  epoch  0, batch  1034 | loss: 2.2950373
MixupTrain:  epoch  0, batch  1035 | loss: 2.0945032
MixupTrain:  epoch  0, batch  1036 | loss: 2.1171932
MixupTrain:  epoch  0, batch  1037 | loss: 2.3365951
MixupTrain:  epoch  0, batch  1038 | loss: 2.4518375
MixupTrain:  epoch  0, batch  1039 | loss: 2.4154720
MixupTrain:  epoch  0, batch  1040 | loss: 2.2850344
MixupTrain:  epoch  0, batch  1041 | loss: 2.5496140
MixupTrain:  epoch  0, batch  1042 | loss: 2.4356201
MixupTrain:  epoch  0, batch  1043 | loss: 2.3057675
MixupTrain:  epoch  0, batch  1044 | loss: 2.5127447
MixupTrain:  epoch  0, batch  1045 | loss: 2.6679749
MixupTrain:  epoch  0, batch  1046 | loss: 2.3693814
MixupTrain:  epoch  0, batch  1047 | loss: 2.5405197
MixupTrain:  epoch  0, batch  1048 | loss: 2.3781641
MixupTrain:  epoch  0, batch  1049 | loss: 2.1918240
MixupTrain:  epoch  0, batch  1050 | loss: 2.3689046
MixupTrain:  epoch  0, batch  1051 | loss: 2.5672715
MixupTrain:  epoch  0, batch  1052 | loss: 2.2516758
MixupTrain:  epoch  0, batch  1053 | loss: 2.4441631
MixupTrain:  epoch  0, batch  1054 | loss: 2.3327575
MixupTrain:  epoch  0, batch  1055 | loss: 2.4299765
MixupTrain:  epoch  0, batch  1056 | loss: 2.4625857
MixupTrain:  epoch  0, batch  1057 | loss: 2.1645522
MixupTrain:  epoch  0, batch  1058 | loss: 2.1534042
MixupTrain:  epoch  0, batch  1059 | loss: 2.1292434
MixupTrain:  epoch  0, batch  1060 | loss: 2.2571495
MixupTrain:  epoch  0, batch  1061 | loss: 2.2302780
MixupTrain:  epoch  0, batch  1062 | loss: 2.2237403
MixupTrain:  epoch  0, batch  1063 | loss: 2.5792136
MixupTrain:  epoch  0, batch  1064 | loss: 2.3117220
MixupTrain:  epoch  0, batch  1065 | loss: 2.1235828
MixupTrain:  epoch  0, batch  1066 | loss: 2.2910457
MixupTrain:  epoch  0, batch  1067 | loss: 2.3825190
MixupTrain:  epoch  0, batch  1068 | loss: 2.4497991
MixupTrain:  epoch  0, batch  1069 | loss: 2.1705883
MixupTrain:  epoch  0, batch  1070 | loss: 2.3069754
MixupTrain:  epoch  0, batch  1071 | loss: 2.4651017
MixupTrain:  epoch  0, batch  1072 | loss: 2.2756891
MixupTrain:  epoch  0, batch  1073 | loss: 2.2449095
MixupTrain:  epoch  0, batch  1074 | loss: 2.3918533
MixupTrain:  epoch  0, batch  1075 | loss: 2.0706313
MixupTrain:  epoch  0, batch  1076 | loss: 2.0468392
MixupTrain:  epoch  0, batch  1077 | loss: 2.4970737
MixupTrain:  epoch  0, batch  1078 | loss: 2.2391481
MixupTrain:  epoch  0, batch  1079 | loss: 2.5363181
MixupTrain:  epoch  0, batch  1080 | loss: 2.2977943
MixupTrain:  epoch  0, batch  1081 | loss: 2.2650311
MixupTrain:  epoch  0, batch  1082 | loss: 2.2756660
MixupTrain:  epoch  0, batch  1083 | loss: 2.3261817
MixupTrain:  epoch  0, batch  1084 | loss: 2.3272414
MixupTrain:  epoch  0, batch  1085 | loss: 2.2417538
MixupTrain:  epoch  0, batch  1086 | loss: 2.4654098
MixupTrain:  epoch  0, batch  1087 | loss: 2.5660746
MixupTrain:  epoch  0, batch  1088 | loss: 2.4246435
MixupTrain:  epoch  0, batch  1089 | loss: 2.4600611
MixupTrain:  epoch  0, batch  1090 | loss: 2.7129822
MixupTrain:  epoch  0, batch  1091 | loss: 2.2224984
MixupTrain:  epoch  0, batch  1092 | loss: 2.3168879
MixupTrain:  epoch  0, batch  1093 | loss: 2.3757989
MixupTrain:  epoch  0, batch  1094 | loss: 2.2556858
MixupTrain:  epoch  0, batch  1095 | loss: 2.4494474
MixupTrain:  epoch  0, batch  1096 | loss: 2.5627899
MixupTrain:  epoch  0, batch  1097 | loss: 2.3577352
MixupTrain:  epoch  0, batch  1098 | loss: 2.2863772
MixupTrain:  epoch  0, batch  1099 | loss: 2.0247922
MixupTrain:  epoch  0, batch  1100 | loss: 2.1273561
MixupTrain:  epoch  0, batch  1101 | loss: 2.4064741
MixupTrain:  epoch  0, batch  1102 | loss: 2.5584307
MixupTrain:  epoch  0, batch  1103 | loss: 2.1812785
MixupTrain:  epoch  0, batch  1104 | loss: 2.4576268
MixupTrain:  epoch  0, batch  1105 | loss: 2.4168105
MixupTrain:  epoch  0, batch  1106 | loss: 2.5547240
MixupTrain:  epoch  0, batch  1107 | loss: 2.4446402
MixupTrain:  epoch  0, batch  1108 | loss: 2.3006618
MixupTrain:  epoch  0, batch  1109 | loss: 2.2931848
MixupTrain:  epoch  0, batch  1110 | loss: 2.3020291
MixupTrain:  epoch  0, batch  1111 | loss: 2.4663930
MixupTrain:  epoch  0, batch  1112 | loss: 2.1591811
MixupTrain:  epoch  0, batch  1113 | loss: 2.3246603
MixupTrain:  epoch  0, batch  1114 | loss: 2.3190546
MixupTrain:  epoch  0, batch  1115 | loss: 2.3098638
MixupTrain:  epoch  0, batch  1116 | loss: 2.2270045
MixupTrain:  epoch  0, batch  1117 | loss: 2.2519488
MixupTrain:  epoch  0, batch  1118 | loss: 2.2419174
MixupTrain:  epoch  0, batch  1119 | loss: 2.1361027
MixupTrain:  epoch  0, batch  1120 | loss: 2.4361131
MixupTrain:  epoch  0, batch  1121 | loss: 2.2902944
MixupTrain:  epoch  0, batch  1122 | loss: 2.2468133
MixupTrain:  epoch  0, batch  1123 | loss: 2.5032630
MixupTrain:  epoch  0, batch  1124 | loss: 2.1347451
MixupTrain:  epoch  0, batch  1125 | loss: 2.2222493
MixupTrain:  epoch  0, batch  1126 | loss: 2.2567887
MixupTrain:  epoch  0, batch  1127 | loss: 2.6173368
MixupTrain:  epoch  0, batch  1128 | loss: 2.0356660
MixupTrain:  epoch  0, batch  1129 | loss: 2.1984560
MixupTrain:  epoch  0, batch  1130 | loss: 2.4770703
MixupTrain:  epoch  0, batch  1131 | loss: 2.7018032
MixupTrain:  epoch  0, batch  1132 | loss: 2.5005713
MixupTrain:  epoch  0, batch  1133 | loss: 2.4539440
MixupTrain:  epoch  0, batch  1134 | loss: 2.1995904
MixupTrain:  epoch  0, batch  1135 | loss: 2.3617125
MixupTrain:  epoch  0, batch  1136 | loss: 2.5149765
MixupTrain:  epoch  0, batch  1137 | loss: 2.4440107
MixupTrain:  epoch  0, batch  1138 | loss: 2.2718146
MixupTrain:  epoch  0, batch  1139 | loss: 2.4250550
MixupTrain:  epoch  0, batch  1140 | loss: 2.1861835
MixupTrain:  epoch  0, batch  1141 | loss: 2.3903339
MixupTrain:  epoch  0, batch  1142 | loss: 2.4800978
MixupTrain:  epoch  0, batch  1143 | loss: 2.2590013
MixupTrain:  epoch  0, batch  1144 | loss: 2.2546403
MixupTrain:  epoch  0, batch  1145 | loss: 2.4625423
MixupTrain:  epoch  0, batch  1146 | loss: 2.3248000
MixupTrain:  epoch  0, batch  1147 | loss: 2.2255349
MixupTrain:  epoch  0, batch  1148 | loss: 2.3100595
MixupTrain:  epoch  0, batch  1149 | loss: 2.3515997
MixupTrain:  epoch  0, batch  1150 | loss: 2.1652584
MixupTrain:  epoch  0, batch  1151 | loss: 2.0899184
MixupTrain:  epoch  0, batch  1152 | loss: 2.3982399
MixupTrain:  epoch  0, batch  1153 | loss: 2.3239117
MixupTrain:  epoch  0, batch  1154 | loss: 2.4475269
MixupTrain:  epoch  0, batch  1155 | loss: 2.3736677
MixupTrain:  epoch  0, batch  1156 | loss: 2.3242159
MixupTrain:  epoch  0, batch  1157 | loss: 2.3430665
MixupTrain:  epoch  0, batch  1158 | loss: 2.1175823
MixupTrain:  epoch  0, batch  1159 | loss: 2.4096513
MixupTrain:  epoch  0, batch  1160 | loss: 2.4749017
MixupTrain:  epoch  0, batch  1161 | loss: 2.5334651
MixupTrain:  epoch  0, batch  1162 | loss: 2.3020701
MixupTrain:  epoch  0, batch  1163 | loss: 2.1074619
MixupTrain:  epoch  0, batch  1164 | loss: 2.2400346
MixupTrain:  epoch  0, batch  1165 | loss: 1.9467278
MixupTrain:  epoch  0, batch  1166 | loss: 2.3991556
MixupTrain:  epoch  0, batch  1167 | loss: 2.3065462
MixupTrain:  epoch  0, batch  1168 | loss: 2.2249346
MixupTrain:  epoch  0, batch  1169 | loss: 2.4030392
MixupTrain:  epoch  0, batch  1170 | loss: 2.2851896
MixupTrain:  epoch  0, batch  1171 | loss: 2.5416701
MixupTrain:  epoch  0, batch  1172 | loss: 2.3942809
MixupTrain:  epoch  0, batch  1173 | loss: 2.4949710
MixupTrain:  epoch  0, batch  1174 | loss: 2.3950353
MixupTrain:  epoch  0, batch  1175 | loss: 2.2716198
MixupTrain:  epoch  0, batch  1176 | loss: 2.4250872
MixupTrain:  epoch  0, batch  1177 | loss: 2.4830184
MixupTrain:  epoch  0, batch  1178 | loss: 2.3293073
MixupTrain:  epoch  0, batch  1179 | loss: 2.5312800
MixupTrain:  epoch  0, batch  1180 | loss: 2.2312157
MixupTrain:  epoch  0, batch  1181 | loss: 2.3609438
MixupTrain:  epoch  0, batch  1182 | loss: 2.1983137
MixupTrain:  epoch  0, batch  1183 | loss: 2.4881754
MixupTrain:  epoch  0, batch  1184 | loss: 2.3845906
MixupTrain:  epoch  0, batch  1185 | loss: 2.7850811
MixupTrain:  epoch  0, batch  1186 | loss: 2.5388126
MixupTrain:  epoch  0, batch  1187 | loss: 2.2039843
MixupTrain:  epoch  0, batch  1188 | loss: 2.4108102
MixupTrain:  epoch  0, batch  1189 | loss: 2.1685858
MixupTrain:  epoch  0, batch  1190 | loss: 2.2303689
MixupTrain:  epoch  0, batch  1191 | loss: 2.6555457
MixupTrain:  epoch  0, batch  1192 | loss: 2.3121276
MixupTrain:  epoch  0, batch  1193 | loss: 2.4360909
MixupTrain:  epoch  0, batch  1194 | loss: 2.6751328
MixupTrain:  epoch  0, batch  1195 | loss: 2.1755939
MixupTrain:  epoch  0, batch  1196 | loss: 2.5094934
MixupTrain:  epoch  0, batch  1197 | loss: 2.0683231
MixupTrain:  epoch  0, batch  1198 | loss: 2.3707213
MixupTrain:  epoch  0, batch  1199 | loss: 2.2747927
MixupTrain:  epoch  0, batch  1200 | loss: 2.4347713
MixupTrain:  epoch  0, batch  1201 | loss: 2.3731704
MixupTrain:  epoch  0, batch  1202 | loss: 2.5270069
MixupTrain:  epoch  0, batch  1203 | loss: 2.2248430
MixupTrain:  epoch  0, batch  1204 | loss: 2.3127341
MixupTrain:  epoch  0, batch  1205 | loss: 2.3835731
MixupTrain:  epoch  0, batch  1206 | loss: 2.1030476
MixupTrain:  epoch  0, batch  1207 | loss: 2.5009584
MixupTrain:  epoch  0, batch  1208 | loss: 2.3569965
MixupTrain:  epoch  0, batch  1209 | loss: 2.2465596
MixupTrain:  epoch  0, batch  1210 | loss: 2.6016369
MixupTrain:  epoch  0, batch  1211 | loss: 2.2690291
MixupTrain:  epoch  0, batch  1212 | loss: 2.2886393
MixupTrain:  epoch  0, batch  1213 | loss: 2.3269074
MixupTrain:  epoch  0, batch  1214 | loss: 2.4887390
MixupTrain:  epoch  0, batch  1215 | loss: 2.0772400
MixupTrain:  epoch  0, batch  1216 | loss: 2.5335217
MixupTrain:  epoch  0, batch  1217 | loss: 2.2112510
MixupTrain:  epoch  0, batch  1218 | loss: 2.7328355
MixupTrain:  epoch  0, batch  1219 | loss: 2.5138361
MixupTrain:  epoch  0, batch  1220 | loss: 2.3486013
MixupTrain:  epoch  0, batch  1221 | loss: 2.2560043
MixupTrain:  epoch  0, batch  1222 | loss: 2.1596262
MixupTrain:  epoch  0, batch  1223 | loss: 2.2955732
MixupTrain:  epoch  0, batch  1224 | loss: 2.2705221
MixupTrain:  epoch  0, batch  1225 | loss: 2.2854872
MixupTrain:  epoch  0, batch  1226 | loss: 2.4587350
MixupTrain:  epoch  0, batch  1227 | loss: 2.3965290
MixupTrain:  epoch  0, batch  1228 | loss: 2.1811254
MixupTrain:  epoch  0, batch  1229 | loss: 2.1925576
MixupTrain:  epoch  0, batch  1230 | loss: 2.2133102
MixupTrain:  epoch  0, batch  1231 | loss: 2.3158276
MixupTrain:  epoch  0, batch  1232 | loss: 2.3535049
MixupTrain:  epoch  0, batch  1233 | loss: 2.3756514
MixupTrain:  epoch  0, batch  1234 | loss: 2.3275790
MixupTrain:  epoch  0, batch  1235 | loss: 2.2468638
MixupTrain:  epoch  0, batch  1236 | loss: 2.3175626
MixupTrain:  epoch  0, batch  1237 | loss: 2.5113397
MixupTrain:  epoch  0, batch  1238 | loss: 2.3291986
MixupTrain:  epoch  0, batch  1239 | loss: 2.4177639
MixupTrain:  epoch  0, batch  1240 | loss: 2.2788014
MixupTrain:  epoch  0, batch  1241 | loss: 2.2832181
MixupTrain:  epoch  0, batch  1242 | loss: 2.6218400
MixupTrain:  epoch  0, batch  1243 | loss: 2.1550937
MixupTrain:  epoch  0, batch  1244 | loss: 2.7560260
MixupTrain:  epoch  0, batch  1245 | loss: 2.3797085
MixupTrain:  epoch  0, batch  1246 | loss: 2.4286661
MixupTrain:  epoch  0, batch  1247 | loss: 2.3193588
MixupTrain:  epoch  0, batch  1248 | loss: 2.1794350
MixupTrain:  epoch  0, batch  1249 | loss: 2.5382056
MixupTrain:  epoch  0, batch  1250 | loss: 2.5162923
MixupTrain:  epoch  0, batch  1251 | loss: 2.2708855
MixupTrain:  epoch  0, batch  1252 | loss: 2.4328620
MixupTrain:  epoch  0, batch  1253 | loss: 2.4740214
MixupTrain:  epoch  0, batch  1254 | loss: 2.6451945
MixupTrain:  epoch  0, batch  1255 | loss: 2.2374649
MixupTrain:  epoch  0, batch  1256 | loss: 2.7148299
MixupTrain:  epoch  0, batch  1257 | loss: 2.5187411
MixupTrain:  epoch  0, batch  1258 | loss: 2.1871314
MixupTrain:  epoch  0, batch  1259 | loss: 2.3727694
MixupTrain:  epoch  0, batch  1260 | loss: 2.5135143
MixupTrain:  epoch  0, batch  1261 | loss: 2.2682476
MixupTrain:  epoch  0, batch  1262 | loss: 2.5503438
MixupTrain:  epoch  0, batch  1263 | loss: 2.2759347
MixupTrain:  epoch  0, batch  1264 | loss: 2.1669602
MixupTrain:  epoch  0, batch  1265 | loss: 2.5282686
MixupTrain:  epoch  0, batch  1266 | loss: 2.3193102
MixupTrain:  epoch  0, batch  1267 | loss: 2.3592329
MixupTrain:  epoch  0, batch  1268 | loss: 2.4311430
MixupTrain:  epoch  0, batch  1269 | loss: 2.3545206
MixupTrain:  epoch  0, batch  1270 | loss: 2.4008012
MixupTrain:  epoch  0, batch  1271 | loss: 2.1939414
MixupTrain:  epoch  0, batch  1272 | loss: 2.2959714
MixupTrain:  epoch  0, batch  1273 | loss: 2.3654246
MixupTrain:  epoch  0, batch  1274 | loss: 2.2703149
MixupTrain:  epoch  0, batch  1275 | loss: 2.4207840
MixupTrain:  epoch  0, batch  1276 | loss: 2.3802571
MixupTrain:  epoch  0, batch  1277 | loss: 2.2191052
MixupTrain:  epoch  0, batch  1278 | loss: 2.5701246
MixupTrain:  epoch  0, batch  1279 | loss: 2.4997423
MixupTrain:  epoch  0, batch  1280 | loss: 2.3677151
MixupTrain:  epoch  0, batch  1281 | loss: 2.1373558
MixupTrain:  epoch  0, batch  1282 | loss: 2.5851641
MixupTrain:  epoch  0, batch  1283 | loss: 2.2496860
MixupTrain:  epoch  0, batch  1284 | loss: 2.1950574
MixupTrain:  epoch  0, batch  1285 | loss: 2.0433621
MixupTrain:  epoch  0, batch  1286 | loss: 2.3324122
MixupTrain:  epoch  0, batch  1287 | loss: 2.1246657
MixupTrain:  epoch  0, batch  1288 | loss: 2.5685363
MixupTrain:  epoch  0, batch  1289 | loss: 2.2951903
MixupTrain:  epoch  0, batch  1290 | loss: 2.3177342
MixupTrain:  epoch  0, batch  1291 | loss: 2.4472198
MixupTrain:  epoch  0, batch  1292 | loss: 2.3215470
MixupTrain:  epoch  0, batch  1293 | loss: 2.2136354
MixupTrain:  epoch  0, batch  1294 | loss: 2.2873526
MixupTrain:  epoch  0, batch  1295 | loss: 2.3826582
MixupTrain:  epoch  0, batch  1296 | loss: 2.4583011
MixupTrain:  epoch  0, batch  1297 | loss: 2.1969876
MixupTrain:  epoch  0, batch  1298 | loss: 2.2517555
MixupTrain:  epoch  0, batch  1299 | loss: 2.1871901
MixupTrain:  epoch  0, batch  1300 | loss: 2.4648638
MixupTrain:  epoch  0, batch  1301 | loss: 2.2403007
MixupTrain:  epoch  0, batch  1302 | loss: 2.4018512
MixupTrain:  epoch  0, batch  1303 | loss: 2.2433345
MixupTrain:  epoch  0, batch  1304 | loss: 2.3792765
MixupTrain:  epoch  0, batch  1305 | loss: 2.5918455
MixupTrain:  epoch  0, batch  1306 | loss: 2.3491917
MixupTrain:  epoch  0, batch  1307 | loss: 2.5887394
MixupTrain:  epoch  0, batch  1308 | loss: 2.4532125
MixupTrain:  epoch  0, batch  1309 | loss: 2.3250077
MixupTrain:  epoch  0, batch  1310 | loss: 2.1651120
MixupTrain:  epoch  0, batch  1311 | loss: 2.3650148
MixupTrain:  epoch  0, batch  1312 | loss: 2.5273173
MixupTrain:  epoch  0, batch  1313 | loss: 2.5228844
MixupTrain:  epoch  0, batch  1314 | loss: 2.3752935
MixupTrain:  epoch  0, batch  1315 | loss: 2.2178822
MixupTrain:  epoch  0, batch  1316 | loss: 2.5840068
MixupTrain:  epoch  0, batch  1317 | loss: 2.3022103
MixupTrain:  epoch  0, batch  1318 | loss: 2.4407618
MixupTrain:  epoch  0, batch  1319 | loss: 2.3224316
MixupTrain:  epoch  0, batch  1320 | loss: 2.1105769
MixupTrain:  epoch  0, batch  1321 | loss: 2.2325258
MixupTrain:  epoch  0, batch  1322 | loss: 2.0333834
MixupTrain:  epoch  0, batch  1323 | loss: 2.3732202
MixupTrain:  epoch  0, batch  1324 | loss: 2.4387808
MixupTrain:  epoch  0, batch  1325 | loss: 2.3556290
MixupTrain:  epoch  0, batch  1326 | loss: 2.3561635
MixupTrain:  epoch  0, batch  1327 | loss: 2.4523401
MixupTrain:  epoch  0, batch  1328 | loss: 2.3644977
MixupTrain:  epoch  0, batch  1329 | loss: 2.5346639
MixupTrain:  epoch  0, batch  1330 | loss: 2.6055493
MixupTrain:  epoch  0, batch  1331 | loss: 2.4155886
MixupTrain:  epoch  0, batch  1332 | loss: 2.1835363
MixupTrain:  epoch  0, batch  1333 | loss: 2.3688564
MixupTrain:  epoch  0, batch  1334 | loss: 2.3755217
MixupTrain:  epoch  0, batch  1335 | loss: 2.1613131
MixupTrain:  epoch  0, batch  1336 | loss: 2.3865767
MixupTrain:  epoch  0, batch  1337 | loss: 2.4110615
MixupTrain:  epoch  0, batch  1338 | loss: 2.3675652
MixupTrain:  epoch  0, batch  1339 | loss: 2.6492295
MixupTrain:  epoch  0, batch  1340 | loss: 2.0950234
MixupTrain:  epoch  0, batch  1341 | loss: 2.3864076
MixupTrain:  epoch  0, batch  1342 | loss: 2.3281765
MixupTrain:  epoch  0, batch  1343 | loss: 1.9897907
MixupTrain:  epoch  0, batch  1344 | loss: 2.3114796
MixupTrain:  epoch  0, batch  1345 | loss: 2.6280453
MixupTrain:  epoch  0, batch  1346 | loss: 2.1409011
MixupTrain:  epoch  0, batch  1347 | loss: 2.1714513
MixupTrain:  epoch  0, batch  1348 | loss: 2.5582767
MixupTrain:  epoch  0, batch  1349 | loss: 2.2442794
MixupTrain:  epoch  0, batch  1350 | loss: 1.9597524
MixupTrain:  epoch  0, batch  1351 | loss: 2.3499632
MixupTrain:  epoch  0, batch  1352 | loss: 2.2332952
MixupTrain:  epoch  0, batch  1353 | loss: 1.9821390
MixupTrain:  epoch  0, batch  1354 | loss: 2.0700965
MixupTrain:  epoch  0, batch  1355 | loss: 2.3867588
MixupTrain:  epoch  0, batch  1356 | loss: 2.4811606
MixupTrain:  epoch  0, batch  1357 | loss: 2.0608540
MixupTrain:  epoch  0, batch  1358 | loss: 2.6245251
MixupTrain:  epoch  0, batch  1359 | loss: 2.2337303
MixupTrain:  epoch  0, batch  1360 | loss: 2.5342822
MixupTrain:  epoch  0, batch  1361 | loss: 2.2034476
MixupTrain:  epoch  0, batch  1362 | loss: 2.4717770
MixupTrain:  epoch  0, batch  1363 | loss: 2.4452653
MixupTrain:  epoch  0, batch  1364 | loss: 2.3376384
MixupTrain:  epoch  0, batch  1365 | loss: 2.1261764
MixupTrain:  epoch  0, batch  1366 | loss: 2.5703156
MixupTrain:  epoch  0, batch  1367 | loss: 2.5162821
MixupTrain:  epoch  0, batch  1368 | loss: 2.3620129
MixupTrain:  epoch  0, batch  1369 | loss: 1.9750286
MixupTrain:  epoch  0, batch  1370 | loss: 2.4775145
MixupTrain:  epoch  0, batch  1371 | loss: 2.2302206
MixupTrain:  epoch  0, batch  1372 | loss: 2.5967050
MixupTrain:  epoch  0, batch  1373 | loss: 2.4812193
MixupTrain:  epoch  0, batch  1374 | loss: 2.5870049
MixupTrain:  epoch  0, batch  1375 | loss: 2.4788468
MixupTrain:  epoch  0, batch  1376 | loss: 2.3777919
MixupTrain:  epoch  0, batch  1377 | loss: 2.1527190
MixupTrain:  epoch  0, batch  1378 | loss: 2.5257859
MixupTrain:  epoch  0, batch  1379 | loss: 2.3049648
MixupTrain:  epoch  0, batch  1380 | loss: 2.3699040
MixupTrain:  epoch  0, batch  1381 | loss: 2.5594206
MixupTrain:  epoch  0, batch  1382 | loss: 2.3797278
MixupTrain:  epoch  0, batch  1383 | loss: 2.2356014
MixupTrain:  epoch  0, batch  1384 | loss: 2.1319199
MixupTrain:  epoch  0, batch  1385 | loss: 2.2663150
MixupTrain:  epoch  0, batch  1386 | loss: 2.1896014
MixupTrain:  epoch  0, batch  1387 | loss: 2.4040661
MixupTrain:  epoch  0, batch  1388 | loss: 2.3481381
MixupTrain:  epoch  0, batch  1389 | loss: 2.3952034
MixupTrain:  epoch  0, batch  1390 | loss: 2.1908932
MixupTrain:  epoch  0, batch  1391 | loss: 2.1864204
MixupTrain:  epoch  0, batch  1392 | loss: 2.3030729
MixupTrain:  epoch  0, batch  1393 | loss: 2.2954197
MixupTrain:  epoch  0, batch  1394 | loss: 2.3194151
MixupTrain:  epoch  0, batch  1395 | loss: 2.2294245
MixupTrain:  epoch  0, batch  1396 | loss: 2.5541582
MixupTrain:  epoch  0, batch  1397 | loss: 2.1106939
MixupTrain:  epoch  0, batch  1398 | loss: 2.4687433
MixupTrain:  epoch  0, batch  1399 | loss: 2.3697472
MixupTrain:  epoch  0, batch  1400 | loss: 2.2896056
MixupTrain:  epoch  0, batch  1401 | loss: 2.2774577
MixupTrain:  epoch  0, batch  1402 | loss: 2.3875930
MixupTrain:  epoch  0, batch  1403 | loss: 2.2913351
MixupTrain:  epoch  0, batch  1404 | loss: 2.1720247
MixupTrain:  epoch  0, batch  1405 | loss: 2.3079052
MixupTrain:  epoch  0, batch  1406 | loss: 2.4167840
MixupTrain:  epoch  0, batch  1407 | loss: 2.3304052
MixupTrain:  epoch  0, batch  1408 | loss: 2.4833081
MixupTrain:  epoch  0, batch  1409 | loss: 2.3755102
MixupTrain:  epoch  0, batch  1410 | loss: 2.4951377
MixupTrain:  epoch  0, batch  1411 | loss: 2.2029583
MixupTrain:  epoch  0, batch  1412 | loss: 2.3943088
MixupTrain:  epoch  0, batch  1413 | loss: 2.2887733
MixupTrain:  epoch  0, batch  1414 | loss: 2.0460923
MixupTrain:  epoch  0, batch  1415 | loss: 2.0949748
MixupTrain:  epoch  0, batch  1416 | loss: 2.2161272
MixupTrain:  epoch  0, batch  1417 | loss: 2.1733236
MixupTrain:  epoch  0, batch  1418 | loss: 2.4671762
MixupTrain:  epoch  0, batch  1419 | loss: 2.3494091
MixupTrain:  epoch  0, batch  1420 | loss: 2.7076364
MixupTrain:  epoch  0, batch  1421 | loss: 2.3952279
MixupTrain:  epoch  0, batch  1422 | loss: 2.1561689
MixupTrain:  epoch  0, batch  1423 | loss: 2.2015700
MixupTrain:  epoch  0, batch  1424 | loss: 2.3833392
MixupTrain:  epoch  0, batch  1425 | loss: 2.3404770
MixupTrain:  epoch  0, batch  1426 | loss: 2.2601998
MixupTrain:  epoch  0, batch  1427 | loss: 2.2778120
MixupTrain:  epoch  0, batch  1428 | loss: 2.4155383
MixupTrain:  epoch  0, batch  1429 | loss: 2.1964223
MixupTrain:  epoch  0, batch  1430 | loss: 2.3042169
MixupTrain:  epoch  0, batch  1431 | loss: 2.4809978
MixupTrain:  epoch  0, batch  1432 | loss: 2.1136217
MixupTrain:  epoch  0, batch  1433 | loss: 2.1386328
MixupTrain:  epoch  0, batch  1434 | loss: 2.1348791
MixupTrain:  epoch  0, batch  1435 | loss: 2.4200037
MixupTrain:  epoch  0, batch  1436 | loss: 2.5023303
MixupTrain:  epoch  0, batch  1437 | loss: 2.3709970
MixupTrain:  epoch  0, batch  1438 | loss: 2.3769851
MixupTrain:  epoch  0, batch  1439 | loss: 2.3019896
MixupTrain:  epoch  0, batch  1440 | loss: 2.2992296
MixupTrain:  epoch  0, batch  1441 | loss: 2.1154761
MixupTrain:  epoch  0, batch  1442 | loss: 2.2565279
MixupTrain:  epoch  0, batch  1443 | loss: 2.4558892
MixupTrain:  epoch  0, batch  1444 | loss: 2.2142849
MixupTrain:  epoch  0, batch  1445 | loss: 2.2738299
MixupTrain:  epoch  0, batch  1446 | loss: 2.4984469
MixupTrain:  epoch  0, batch  1447 | loss: 2.3794649
MixupTrain:  epoch  0, batch  1448 | loss: 2.2572494
MixupTrain:  epoch  0, batch  1449 | loss: 2.3170836
MixupTrain:  epoch  0, batch  1450 | loss: 2.5195632
MixupTrain:  epoch  0, batch  1451 | loss: 2.3613045
MixupTrain:  epoch  0, batch  1452 | loss: 2.0727372
MixupTrain:  epoch  0, batch  1453 | loss: 2.3560152
MixupTrain:  epoch  0, batch  1454 | loss: 2.2418966
MixupTrain:  epoch  0, batch  1455 | loss: 2.1034000
MixupTrain:  epoch  0, batch  1456 | loss: 2.2743695
MixupTrain:  epoch  0, batch  1457 | loss: 2.2880063
MixupTrain:  epoch  0, batch  1458 | loss: 2.3647900
MixupTrain:  epoch  0, batch  1459 | loss: 2.4506304
MixupTrain:  epoch  0, batch  1460 | loss: 2.2645817
MixupTrain:  epoch  0, batch  1461 | loss: 2.4102726
MixupTrain:  epoch  0, batch  1462 | loss: 2.3353376
MixupTrain:  epoch  0, batch  1463 | loss: 2.2113943
MixupTrain:  epoch  0, batch  1464 | loss: 2.4568686
MixupTrain:  epoch  0, batch  1465 | loss: 2.3158345
MixupTrain:  epoch  0, batch  1466 | loss: 2.1457992
MixupTrain:  epoch  0, batch  1467 | loss: 2.2334867
MixupTrain:  epoch  0, batch  1468 | loss: 2.4055736
MixupTrain:  epoch  0, batch  1469 | loss: 2.3301773
MixupTrain:  epoch  0, batch  1470 | loss: 2.5176435
MixupTrain:  epoch  0, batch  1471 | loss: 2.2316556
MixupTrain:  epoch  0, batch  1472 | loss: 2.2209764
MixupTrain:  epoch  0, batch  1473 | loss: 2.3473961
MixupTrain:  epoch  0, batch  1474 | loss: 2.3680475
MixupTrain:  epoch  0, batch  1475 | loss: 2.3824508
MixupTrain:  epoch  0, batch  1476 | loss: 2.2959094
MixupTrain:  epoch  0, batch  1477 | loss: 2.5409107
MixupTrain:  epoch  0, batch  1478 | loss: 2.3511238
MixupTrain:  epoch  0, batch  1479 | loss: 2.2352576
MixupTrain:  epoch  0, batch  1480 | loss: 2.3773866
MixupTrain:  epoch  0, batch  1481 | loss: 2.1787095
MixupTrain:  epoch  0, batch  1482 | loss: 2.3957462
MixupTrain:  epoch  0, batch  1483 | loss: 2.3597324
MixupTrain:  epoch  0, batch  1484 | loss: 2.3387117
MixupTrain:  epoch  0, batch  1485 | loss: 2.4361243
MixupTrain:  epoch  0, batch  1486 | loss: 2.1545968
MixupTrain:  epoch  0, batch  1487 | loss: 2.2654474
MixupTrain:  epoch  0, batch  1488 | loss: 2.3753872
MixupTrain:  epoch  0, batch  1489 | loss: 2.3994834
MixupTrain:  epoch  0, batch  1490 | loss: 2.6060216
MixupTrain:  epoch  0, batch  1491 | loss: 2.2289128
MixupTrain:  epoch  0, batch  1492 | loss: 2.6758075
MixupTrain:  epoch  0, batch  1493 | loss: 2.6875286
MixupTrain:  epoch  0, batch  1494 | loss: 2.4336286
MixupTrain:  epoch  0, batch  1495 | loss: 2.6356926
MixupTrain:  epoch  0, batch  1496 | loss: 2.2792873
MixupTrain:  epoch  0, batch  1497 | loss: 2.4331760
MixupTrain:  epoch  0, batch  1498 | loss: 2.2508767
MixupTrain:  epoch  0, batch  1499 | loss: 2.1534543
MixupTrain:  epoch  0, batch  1500 | loss: 2.3292503
MixupTrain:  epoch  0, batch  1501 | loss: 2.2424092
MixupTrain:  epoch  0, batch  1502 | loss: 2.4173496
MixupTrain:  epoch  0, batch  1503 | loss: 2.3454719
MixupTrain:  epoch  0, batch  1504 | loss: 2.0466375
MixupTrain:  epoch  0, batch  1505 | loss: 2.1793497
MixupTrain:  epoch  0, batch  1506 | loss: 2.3366141
MixupTrain:  epoch  0, batch  1507 | loss: 2.5561957
MixupTrain:  epoch  0, batch  1508 | loss: 2.3830843
MixupTrain:  epoch  0, batch  1509 | loss: 2.5085256
MixupTrain:  epoch  0, batch  1510 | loss: 2.3224568
MixupTrain:  epoch  0, batch  1511 | loss: 2.5017438
MixupTrain:  epoch  0, batch  1512 | loss: 2.2723737
MixupTrain:  epoch  0, batch  1513 | loss: 2.1957269
MixupTrain:  epoch  0, batch  1514 | loss: 2.2403350
MixupTrain:  epoch  0, batch  1515 | loss: 2.4672351
MixupTrain:  epoch  0, batch  1516 | loss: 2.2044683
MixupTrain:  epoch  0, batch  1517 | loss: 2.6015406
MixupTrain:  epoch  0, batch  1518 | loss: 2.0828462
MixupTrain:  epoch  0, batch  1519 | loss: 2.1238561
MixupTrain:  epoch  0, batch  1520 | loss: 2.0754564
MixupTrain:  epoch  0, batch  1521 | loss: 2.4534154
MixupTrain:  epoch  0, batch  1522 | loss: 2.1209319
MixupTrain:  epoch  0, batch  1523 | loss: 2.1287758
MixupTrain:  epoch  0, batch  1524 | loss: 2.1900570
MixupTrain:  epoch  0, batch  1525 | loss: 2.4048302
MixupTrain:  epoch  0, batch  1526 | loss: 2.4335504
MixupTrain:  epoch  0, batch  1527 | loss: 2.5128384
MixupTrain:  epoch  0, batch  1528 | loss: 2.2073052
MixupTrain:  epoch  0, batch  1529 | loss: 2.1903186
MixupTrain:  epoch  0, batch  1530 | loss: 2.4652319
MixupTrain:  epoch  0, batch  1531 | loss: 2.5161994
MixupTrain:  epoch  0, batch  1532 | loss: 2.3161769
MixupTrain:  epoch  0, batch  1533 | loss: 2.6809893
MixupTrain:  epoch  0, batch  1534 | loss: 2.4165244
MixupTrain:  epoch  0, batch  1535 | loss: 2.2570465
MixupTrain:  epoch  0, batch  1536 | loss: 2.3167853
MixupTrain:  epoch  0, batch  1537 | loss: 2.3528724
MixupTrain:  epoch  0, batch  1538 | loss: 2.2206795
MixupTrain:  epoch  0, batch  1539 | loss: 2.3743730
MixupTrain:  epoch  0, batch  1540 | loss: 2.3088231
MixupTrain:  epoch  0, batch  1541 | loss: 2.3174357
MixupTrain:  epoch  0, batch  1542 | loss: 2.2892780
MixupTrain:  epoch  0, batch  1543 | loss: 2.3900597
MixupTrain:  epoch  0, batch  1544 | loss: 2.2768574
MixupTrain:  epoch  0, batch  1545 | loss: 2.2910337
MixupTrain:  epoch  0, batch  1546 | loss: 2.3133619
MixupTrain:  epoch  0, batch  1547 | loss: 2.2648823
MixupTrain:  epoch  0, batch  1548 | loss: 2.2572336
MixupTrain:  epoch  0, batch  1549 | loss: 2.1949217
MixupTrain:  epoch  0, batch  1550 | loss: 2.5025628
MixupTrain:  epoch  0, batch  1551 | loss: 2.3521576
MixupTrain:  epoch  0, batch  1552 | loss: 2.4889655
MixupTrain:  epoch  0, batch  1553 | loss: 2.2228365
MixupTrain:  epoch  0, batch  1554 | loss: 2.5385141
MixupTrain:  epoch  0, batch  1555 | loss: 2.2283869
MixupTrain:  epoch  0, batch  1556 | loss: 2.0586767
MixupTrain:  epoch  0, batch  1557 | loss: 2.4505491
MixupTrain:  epoch  0, batch  1558 | loss: 2.2116084
MixupTrain:  epoch  0, batch  1559 | loss: 2.2467053
MixupTrain:  epoch  0, batch  1560 | loss: 2.2116873
MixupTrain:  epoch  0, batch  1561 | loss: 2.4880602
MixupTrain:  epoch  0, batch  1562 | loss: 2.0208290
MixupTrain:  epoch  0, batch  1563 | loss: 2.1551085
MixupTrain:  epoch  0, batch  1564 | loss: 2.2305613
MixupTrain:  epoch  0, batch  1565 | loss: 2.3019302
MixupTrain:  epoch  0, batch  1566 | loss: 2.3599753
MixupTrain:  epoch  0, batch  1567 | loss: 2.1794815
MixupTrain:  epoch  0, batch  1568 | loss: 2.2337348
MixupTrain:  epoch  0, batch  1569 | loss: 2.5104094
MixupTrain:  epoch  0, batch  1570 | loss: 2.2338204
MixupTrain:  epoch  0, batch  1571 | loss: 2.5095787
MixupTrain:  epoch  0, batch  1572 | loss: 2.3635373
MixupTrain:  epoch  0, batch  1573 | loss: 2.3115911
MixupTrain:  epoch  0, batch  1574 | loss: 2.6181207
MixupTrain:  epoch  0, batch  1575 | loss: 2.3037219
MixupTrain:  epoch  0, batch  1576 | loss: 2.4124417
MixupTrain:  epoch  0, batch  1577 | loss: 2.1104214
MixupTrain:  epoch  0, batch  1578 | loss: 2.1957207
MixupTrain:  epoch  0, batch  1579 | loss: 2.2705333
MixupTrain:  epoch  0, batch  1580 | loss: 2.7406201
MixupTrain:  epoch  0, batch  1581 | loss: 2.3134766
MixupTrain:  epoch  0, batch  1582 | loss: 2.1373763
MixupTrain:  epoch  0, batch  1583 | loss: 2.1030130
MixupTrain:  epoch  0, batch  1584 | loss: 2.1231041
MixupTrain:  epoch  0, batch  1585 | loss: 2.3312216
MixupTrain:  epoch  0, batch  1586 | loss: 2.6160970
MixupTrain:  epoch  0, batch  1587 | loss: 2.5210052
MixupTrain:  epoch  0, batch  1588 | loss: 2.4010301
MixupTrain:  epoch  0, batch  1589 | loss: 2.1982067
MixupTrain:  epoch  0, batch  1590 | loss: 2.0685639
MixupTrain:  epoch  0, batch  1591 | loss: 2.2171898
MixupTrain:  epoch  0, batch  1592 | loss: 2.1482682
MixupTrain:  epoch  0, batch  1593 | loss: 2.3308363
MixupTrain:  epoch  0, batch  1594 | loss: 2.5086660
MixupTrain:  epoch  0, batch  1595 | loss: 2.4035003
MixupTrain:  epoch  0, batch  1596 | loss: 2.6056511
MixupTrain:  epoch  0, batch  1597 | loss: 2.1650693
MixupTrain:  epoch  0, batch  1598 | loss: 2.4264209
MixupTrain:  epoch  0, batch  1599 | loss: 2.3421175
MixupTrain:  epoch  0, batch  1600 | loss: 2.2113361
MixupTrain:  epoch  0, batch  1601 | loss: 2.3728228
MixupTrain:  epoch  0, batch  1602 | loss: 2.3166151
MixupTrain:  epoch  0, batch  1603 | loss: 2.1712129
MixupTrain:  epoch  0, batch  1604 | loss: 2.4720087
MixupTrain:  epoch  0, batch  1605 | loss: 2.4671960
MixupTrain:  epoch  0, batch  1606 | loss: 2.5099611
MixupTrain:  epoch  0, batch  1607 | loss: 2.1422896
MixupTrain:  epoch  0, batch  1608 | loss: 2.3426547
MixupTrain:  epoch  0, batch  1609 | loss: 2.3281717
MixupTrain:  epoch  0, batch  1610 | loss: 2.1444085
MixupTrain:  epoch  0, batch  1611 | loss: 2.4801338
MixupTrain:  epoch  0, batch  1612 | loss: 2.1821055
MixupTrain:  epoch  0, batch  1613 | loss: 2.3608518
MixupTrain:  epoch  0, batch  1614 | loss: 2.3340533
MixupTrain:  epoch  0, batch  1615 | loss: 2.4188242
MixupTrain:  epoch  0, batch  1616 | loss: 2.5422182
MixupTrain:  epoch  0, batch  1617 | loss: 2.2865446
MixupTrain:  epoch  0, batch  1618 | loss: 2.4193377
MixupTrain:  epoch  0, batch  1619 | loss: 2.0720496
MixupTrain:  epoch  0, batch  1620 | loss: 2.0435543
MixupTrain:  epoch  0, batch  1621 | loss: 2.2015262
MixupTrain:  epoch  0, batch  1622 | loss: 2.5485563
MixupTrain:  epoch  0, batch  1623 | loss: 2.2232866
MixupTrain:  epoch  0, batch  1624 | loss: 2.3109317
MixupTrain:  epoch  0, batch  1625 | loss: 2.3494725
MixupTrain:  epoch  0, batch  1626 | loss: 2.3540003
MixupTrain:  epoch  0, batch  1627 | loss: 2.4558485
MixupTrain:  epoch  0, batch  1628 | loss: 2.4651775
MixupTrain:  epoch  0, batch  1629 | loss: 2.4022303
MixupTrain:  epoch  0, batch  1630 | loss: 2.3765531
MixupTrain:  epoch  0, batch  1631 | loss: 2.3983879
MixupTrain:  epoch  0, batch  1632 | loss: 2.2220211
MixupTrain:  epoch  0, batch  1633 | loss: 2.3808937
MixupTrain:  epoch  0, batch  1634 | loss: 2.5360799
MixupTrain:  epoch  0, batch  1635 | loss: 2.2019610
MixupTrain:  epoch  0, batch  1636 | loss: 2.3906231
MixupTrain:  epoch  0, batch  1637 | loss: 2.3063524
MixupTrain:  epoch  0, batch  1638 | loss: 2.6424112
MixupTrain:  epoch  0, batch  1639 | loss: 2.1670446
MixupTrain:  epoch  0, batch  1640 | loss: 2.3666768
MixupTrain:  epoch  0, batch  1641 | loss: 2.3424189
MixupTrain:  epoch  0, batch  1642 | loss: 2.3349645
MixupTrain:  epoch  0, batch  1643 | loss: 2.2996926
MixupTrain:  epoch  0, batch  1644 | loss: 2.2810736
MixupTrain:  epoch  0, batch  1645 | loss: 2.0381370
MixupTrain:  epoch  0, batch  1646 | loss: 2.2784681
MixupTrain:  epoch  0, batch  1647 | loss: 2.3304825
MixupTrain:  epoch  0, batch  1648 | loss: 2.3504229
MixupTrain:  epoch  0, batch  1649 | loss: 2.3663919
MixupTrain:  epoch  0, batch  1650 | loss: 2.1953969
MixupTrain:  epoch  0, batch  1651 | loss: 2.3626680
MixupTrain:  epoch  0, batch  1652 | loss: 2.6619322
MixupTrain:  epoch  0, batch  1653 | loss: 2.2582803
MixupTrain:  epoch  0, batch  1654 | loss: 2.4474273
MixupTrain:  epoch  0, batch  1655 | loss: 2.3031917
MixupTrain:  epoch  0, batch  1656 | loss: 2.4697802
MixupTrain:  epoch  0, batch  1657 | loss: 2.4446473
MixupTrain:  epoch  0, batch  1658 | loss: 2.8126395
MixupTrain:  epoch  0, batch  1659 | loss: 2.3357544
MixupTrain:  epoch  0, batch  1660 | loss: 2.4204493
MixupTrain:  epoch  0, batch  1661 | loss: 2.3169842
MixupTrain:  epoch  0, batch  1662 | loss: 2.3611338
MixupTrain:  epoch  0, batch  1663 | loss: 2.4387674
MixupTrain:  epoch  0, batch  1664 | loss: 2.1813722
MixupTrain:  epoch  0, batch  1665 | loss: 2.0083795
MixupTrain:  epoch  0, batch  1666 | loss: 2.2256975
MixupTrain:  epoch  0, batch  1667 | loss: 2.1089299
MixupTrain:  epoch  0, batch  1668 | loss: 2.1652489
MixupTrain:  epoch  0, batch  1669 | loss: 2.3653569
MixupTrain:  epoch  0, batch  1670 | loss: 2.3373988
MixupTrain:  epoch  0, batch  1671 | loss: 2.4522376
MixupTrain:  epoch  0, batch  1672 | loss: 2.3427444
MixupTrain:  epoch  0, batch  1673 | loss: 2.1623998
MixupTrain:  epoch  0, batch  1674 | loss: 2.4179220
MixupTrain:  epoch  0, batch  1675 | loss: 2.4560859
MixupTrain:  epoch  0, batch  1676 | loss: 2.3450675
MixupTrain:  epoch  0, batch  1677 | loss: 2.2877069
MixupTrain:  epoch  0, batch  1678 | loss: 2.4429832
MixupTrain:  epoch  0, batch  1679 | loss: 2.4257612
MixupTrain:  epoch  0, batch  1680 | loss: 2.2626579
MixupTrain:  epoch  0, batch  1681 | loss: 2.1536775
MixupTrain:  epoch  0, batch  1682 | loss: 2.2785025
MixupTrain:  epoch  0, batch  1683 | loss: 2.6706424
MixupTrain:  epoch  0, batch  1684 | loss: 2.4102874
MixupTrain:  epoch  0, batch  1685 | loss: 2.3262296
MixupTrain:  epoch  0, batch  1686 | loss: 2.4825938
MixupTrain:  epoch  0, batch  1687 | loss: 2.3109188
MixupTrain:  epoch  0, batch  1688 | loss: 2.4040632
MixupTrain:  epoch  0, batch  1689 | loss: 2.2392056
MixupTrain:  epoch  0, batch  1690 | loss: 2.5248156
MixupTrain:  epoch  0, batch  1691 | loss: 2.1877604
MixupTrain:  epoch  0, batch  1692 | loss: 2.4467540
MixupTrain:  epoch  0, batch  1693 | loss: 2.1379731
MixupTrain:  epoch  0, batch  1694 | loss: 2.1825042
MixupTrain:  epoch  0, batch  1695 | loss: 2.1259162
MixupTrain:  epoch  0, batch  1696 | loss: 2.3132410
MixupTrain:  epoch  0, batch  1697 | loss: 2.3473616
MixupTrain:  epoch  0, batch  1698 | loss: 2.6234527
MixupTrain:  epoch  0, batch  1699 | loss: 2.0686579
MixupTrain:  epoch  0, batch  1700 | loss: 2.4631982
MixupTrain:  epoch  0, batch  1701 | loss: 2.3568401
MixupTrain:  epoch  0, batch  1702 | loss: 2.4720755
MixupTrain:  epoch  0, batch  1703 | loss: 2.1028993
MixupTrain:  epoch  0, batch  1704 | loss: 2.6086578
MixupTrain:  epoch  0, batch  1705 | loss: 2.2150297
MixupTrain:  epoch  0, batch  1706 | loss: 2.1973619
MixupTrain:  epoch  0, batch  1707 | loss: 2.4079413
MixupTrain:  epoch  0, batch  1708 | loss: 2.4153702
MixupTrain:  epoch  0, batch  1709 | loss: 2.2183321
MixupTrain:  epoch  0, batch  1710 | loss: 2.3813446
MixupTrain:  epoch  0, batch  1711 | loss: 2.1628289
MixupTrain:  epoch  0, batch  1712 | loss: 2.3723466
MixupTrain:  epoch  0, batch  1713 | loss: 2.4395988
MixupTrain:  epoch  0, batch  1714 | loss: 2.3117299
MixupTrain:  epoch  0, batch  1715 | loss: 2.2244377
MixupTrain:  epoch  0, batch  1716 | loss: 2.3623846
MixupTrain:  epoch  0, batch  1717 | loss: 2.2415867
MixupTrain:  epoch  0, batch  1718 | loss: 2.2910163
MixupTrain:  epoch  0, batch  1719 | loss: 2.2565713
MixupTrain:  epoch  0, batch  1720 | loss: 2.2581732
MixupTrain:  epoch  0, batch  1721 | loss: 2.3555443
MixupTrain:  epoch  0, batch  1722 | loss: 2.4099994
MixupTrain:  epoch  0, batch  1723 | loss: 2.0850115
MixupTrain:  epoch  0, batch  1724 | loss: 2.1505198
MixupTrain:  epoch  0, batch  1725 | loss: 2.2928920
MixupTrain:  epoch  0, batch  1726 | loss: 2.3023970
MixupTrain:  epoch  0, batch  1727 | loss: 2.3291128
MixupTrain:  epoch  0, batch  1728 | loss: 2.2854562
MixupTrain:  epoch  0, batch  1729 | loss: 2.1764250
MixupTrain:  epoch  0, batch  1730 | loss: 2.3779895
MixupTrain:  epoch  0, batch  1731 | loss: 2.4996448
MixupTrain:  epoch  0, batch  1732 | loss: 2.5233409
MixupTrain:  epoch  0, batch  1733 | loss: 2.6128216
MixupTrain:  epoch  0, batch  1734 | loss: 2.3352509
MixupTrain:  epoch  0, batch  1735 | loss: 2.1321115
MixupTrain:  epoch  0, batch  1736 | loss: 2.2683687
MixupTrain:  epoch  0, batch  1737 | loss: 2.2351580
MixupTrain:  epoch  0, batch  1738 | loss: 2.3127208
MixupTrain:  epoch  0, batch  1739 | loss: 2.0796323
MixupTrain:  epoch  0, batch  1740 | loss: 2.1890011
MixupTrain:  epoch  0, batch  1741 | loss: 2.2781863
MixupTrain:  epoch  0, batch  1742 | loss: 2.2457051
MixupTrain:  epoch  0, batch  1743 | loss: 2.4436858
MixupTrain:  epoch  0, batch  1744 | loss: 2.6500156
MixupTrain:  epoch  0, batch  1745 | loss: 2.4215178
MixupTrain:  epoch  0, batch  1746 | loss: 2.3194904
MixupTrain:  epoch  0, batch  1747 | loss: 2.2264647
MixupTrain:  epoch  0, batch  1748 | loss: 2.4405954
MixupTrain:  epoch  0, batch  1749 | loss: 2.4175987
MixupTrain:  epoch  0, batch  1750 | loss: 2.5086808
MixupTrain:  epoch  0, batch  1751 | loss: 2.3624945
MixupTrain:  epoch  0, batch  1752 | loss: 2.1973381
MixupTrain:  epoch  0, batch  1753 | loss: 2.1992562
MixupTrain:  epoch  0, batch  1754 | loss: 2.5773439
MixupTrain:  epoch  0, batch  1755 | loss: 2.4677467
MixupTrain:  epoch  0, batch  1756 | loss: 2.1796243
MixupTrain:  epoch  0, batch  1757 | loss: 2.2888796
MixupTrain:  epoch  0, batch  1758 | loss: 2.2960501
MixupTrain:  epoch  0, batch  1759 | loss: 2.4067838
MixupTrain:  epoch  0, batch  1760 | loss: 2.2629044
MixupTrain:  epoch  0, batch  1761 | loss: 2.0772743
MemoryTrain:  epoch  0, batch     0 | loss: 2.4851112
MemoryTrain:  epoch  0, batch     1 | loss: 2.4521399
MemoryTrain:  epoch  0, batch     2 | loss: 2.5835335
MemoryTrain:  epoch  0, batch     3 | loss: 2.5126655
MemoryTrain:  epoch  0, batch     4 | loss: 2.7424815
MemoryTrain:  epoch  0, batch     5 | loss: 2.2191620
MemoryTrain:  epoch  0, batch     6 | loss: 2.6126542
MemoryTrain:  epoch  0, batch     7 | loss: 2.6444600
MemoryTrain:  epoch  0, batch     8 | loss: 2.2716601
MemoryTrain:  epoch  0, batch     9 | loss: 2.0694971
MemoryTrain:  epoch  0, batch    10 | loss: 1.9738412
MemoryTrain:  epoch  0, batch    11 | loss: 2.0056739
MemoryTrain:  epoch  0, batch    12 | loss: 2.1418567
MemoryTrain:  epoch  0, batch    13 | loss: 2.3047109
MemoryTrain:  epoch  1, batch     0 | loss: 1.8541816
MemoryTrain:  epoch  1, batch     1 | loss: 1.8272077
MemoryTrain:  epoch  1, batch     2 | loss: 1.8409488
MemoryTrain:  epoch  1, batch     3 | loss: 2.1804190
MemoryTrain:  epoch  1, batch     4 | loss: 1.9608331
MemoryTrain:  epoch  1, batch     5 | loss: 1.8321671
MemoryTrain:  epoch  1, batch     6 | loss: 1.8833175
MemoryTrain:  epoch  1, batch     7 | loss: 2.2036223
MemoryTrain:  epoch  1, batch     8 | loss: 1.9678807
MemoryTrain:  epoch  1, batch     9 | loss: 1.8557053
MemoryTrain:  epoch  1, batch    10 | loss: 1.8622432
MemoryTrain:  epoch  1, batch    11 | loss: 1.8846772
MemoryTrain:  epoch  1, batch    12 | loss: 1.8956429
MemoryTrain:  epoch  1, batch    13 | loss: 1.8924946
MemoryTrain:  epoch  2, batch     0 | loss: 1.8941612
MemoryTrain:  epoch  2, batch     1 | loss: 1.9107895
MemoryTrain:  epoch  2, batch     2 | loss: 1.9116544
MemoryTrain:  epoch  2, batch     3 | loss: 2.0047493
MemoryTrain:  epoch  2, batch     4 | loss: 1.8940871
MemoryTrain:  epoch  2, batch     5 | loss: 1.8302916
MemoryTrain:  epoch  2, batch     6 | loss: 1.9049442
MemoryTrain:  epoch  2, batch     7 | loss: 1.8638635
MemoryTrain:  epoch  2, batch     8 | loss: 1.9519119
MemoryTrain:  epoch  2, batch     9 | loss: 1.8540146
MemoryTrain:  epoch  2, batch    10 | loss: 1.8290551
MemoryTrain:  epoch  2, batch    11 | loss: 1.8176649
MemoryTrain:  epoch  2, batch    12 | loss: 1.8426198
MemoryTrain:  epoch  2, batch    13 | loss: 1.8225489
MemoryTrain:  epoch  3, batch     0 | loss: 1.8170805
MemoryTrain:  epoch  3, batch     1 | loss: 1.8204229
MemoryTrain:  epoch  3, batch     2 | loss: 1.8238940
MemoryTrain:  epoch  3, batch     3 | loss: 1.8200190
MemoryTrain:  epoch  3, batch     4 | loss: 1.8077525
MemoryTrain:  epoch  3, batch     5 | loss: 1.8189967
MemoryTrain:  epoch  3, batch     6 | loss: 1.8187566
MemoryTrain:  epoch  3, batch     7 | loss: 1.8109703
MemoryTrain:  epoch  3, batch     8 | loss: 1.8142946
MemoryTrain:  epoch  3, batch     9 | loss: 1.8155255
MemoryTrain:  epoch  3, batch    10 | loss: 1.8115418
MemoryTrain:  epoch  3, batch    11 | loss: 1.8176513
MemoryTrain:  epoch  3, batch    12 | loss: 1.8117669
MemoryTrain:  epoch  3, batch    13 | loss: 1.8124800
MemoryTrain:  epoch  4, batch     0 | loss: 1.8172206
MemoryTrain:  epoch  4, batch     1 | loss: 1.8176198
MemoryTrain:  epoch  4, batch     2 | loss: 1.8177058
MemoryTrain:  epoch  4, batch     3 | loss: 1.8092068
MemoryTrain:  epoch  4, batch     4 | loss: 1.8182797
MemoryTrain:  epoch  4, batch     5 | loss: 1.8155823
MemoryTrain:  epoch  4, batch     6 | loss: 1.8276356
MemoryTrain:  epoch  4, batch     7 | loss: 1.8150589
MemoryTrain:  epoch  4, batch     8 | loss: 1.8150672
MemoryTrain:  epoch  4, batch     9 | loss: 1.8170485
MemoryTrain:  epoch  4, batch    10 | loss: 1.8103020
MemoryTrain:  epoch  4, batch    11 | loss: 1.8181033
MemoryTrain:  epoch  4, batch    12 | loss: 1.8179306
MemoryTrain:  epoch  4, batch    13 | loss: 1.8087968
MemoryTrain:  epoch  5, batch     0 | loss: 1.8175155
MemoryTrain:  epoch  5, batch     1 | loss: 1.8088512
MemoryTrain:  epoch  5, batch     2 | loss: 1.8153217
MemoryTrain:  epoch  5, batch     3 | loss: 1.8108189
MemoryTrain:  epoch  5, batch     4 | loss: 1.8174407
MemoryTrain:  epoch  5, batch     5 | loss: 1.8191016
MemoryTrain:  epoch  5, batch     6 | loss: 1.8124484
MemoryTrain:  epoch  5, batch     7 | loss: 1.8082178
MemoryTrain:  epoch  5, batch     8 | loss: 1.8165603
MemoryTrain:  epoch  5, batch     9 | loss: 1.8092215
MemoryTrain:  epoch  5, batch    10 | loss: 1.8166337
MemoryTrain:  epoch  5, batch    11 | loss: 1.8166530
MemoryTrain:  epoch  5, batch    12 | loss: 1.8137708
MemoryTrain:  epoch  5, batch    13 | loss: 1.8173366
MemoryTrain:  epoch  6, batch     0 | loss: 1.8102080
MemoryTrain:  epoch  6, batch     1 | loss: 1.8115296
MemoryTrain:  epoch  6, batch     2 | loss: 1.8104033
MemoryTrain:  epoch  6, batch     3 | loss: 1.8107765
MemoryTrain:  epoch  6, batch     4 | loss: 1.8160903
MemoryTrain:  epoch  6, batch     5 | loss: 1.8142229
MemoryTrain:  epoch  6, batch     6 | loss: 1.8170656
MemoryTrain:  epoch  6, batch     7 | loss: 1.8135269
MemoryTrain:  epoch  6, batch     8 | loss: 1.8085780
MemoryTrain:  epoch  6, batch     9 | loss: 1.8161323
MemoryTrain:  epoch  6, batch    10 | loss: 1.8054159
MemoryTrain:  epoch  6, batch    11 | loss: 1.8169327
MemoryTrain:  epoch  6, batch    12 | loss: 1.8161964
MemoryTrain:  epoch  6, batch    13 | loss: 1.8167319
MemoryTrain:  epoch  7, batch     0 | loss: 1.8111204
MemoryTrain:  epoch  7, batch     1 | loss: 1.8105569
MemoryTrain:  epoch  7, batch     2 | loss: 1.8126979
MemoryTrain:  epoch  7, batch     3 | loss: 1.8122091
MemoryTrain:  epoch  7, batch     4 | loss: 1.8178847
MemoryTrain:  epoch  7, batch     5 | loss: 1.8134761
MemoryTrain:  epoch  7, batch     6 | loss: 1.8099542
MemoryTrain:  epoch  7, batch     7 | loss: 1.8117112
MemoryTrain:  epoch  7, batch     8 | loss: 1.8095918
MemoryTrain:  epoch  7, batch     9 | loss: 1.8126464
MemoryTrain:  epoch  7, batch    10 | loss: 1.8125846
MemoryTrain:  epoch  7, batch    11 | loss: 1.8158331
MemoryTrain:  epoch  7, batch    12 | loss: 1.8080323
MemoryTrain:  epoch  7, batch    13 | loss: 1.8128896
MemoryTrain:  epoch  8, batch     0 | loss: 1.8107065
MemoryTrain:  epoch  8, batch     1 | loss: 1.8177160
MemoryTrain:  epoch  8, batch     2 | loss: 1.8104537
MemoryTrain:  epoch  8, batch     3 | loss: 1.8146738
MemoryTrain:  epoch  8, batch     4 | loss: 1.8118763
MemoryTrain:  epoch  8, batch     5 | loss: 1.8129265
MemoryTrain:  epoch  8, batch     6 | loss: 1.8146420
MemoryTrain:  epoch  8, batch     7 | loss: 1.8152878
MemoryTrain:  epoch  8, batch     8 | loss: 1.8078263
MemoryTrain:  epoch  8, batch     9 | loss: 1.8125638
MemoryTrain:  epoch  8, batch    10 | loss: 1.8184161
MemoryTrain:  epoch  8, batch    11 | loss: 1.8137915
MemoryTrain:  epoch  8, batch    12 | loss: 1.8200005
MemoryTrain:  epoch  8, batch    13 | loss: 1.8141668
MemoryTrain:  epoch  9, batch     0 | loss: 1.8084493
MemoryTrain:  epoch  9, batch     1 | loss: 1.8117435
MemoryTrain:  epoch  9, batch     2 | loss: 1.8112512
MemoryTrain:  epoch  9, batch     3 | loss: 1.8136386
MemoryTrain:  epoch  9, batch     4 | loss: 1.8137188
MemoryTrain:  epoch  9, batch     5 | loss: 1.8113971
MemoryTrain:  epoch  9, batch     6 | loss: 1.8067685
MemoryTrain:  epoch  9, batch     7 | loss: 1.8097715
MemoryTrain:  epoch  9, batch     8 | loss: 1.8187286
MemoryTrain:  epoch  9, batch     9 | loss: 1.8162332
MemoryTrain:  epoch  9, batch    10 | loss: 1.8156904
MemoryTrain:  epoch  9, batch    11 | loss: 1.8060602
MemoryTrain:  epoch  9, batch    12 | loss: 1.8205527
MemoryTrain:  epoch  9, batch    13 | loss: 1.8163300
[EVAL] batch:    0 | acc: 68.75%,  total acc: 68.75%   
[EVAL] batch:    1 | acc: 81.25%,  total acc: 75.00%   
[EVAL] batch:    2 | acc: 81.25%,  total acc: 77.08%   
[EVAL] batch:    3 | acc: 87.50%,  total acc: 79.69%   
[EVAL] batch:    4 | acc: 93.75%,  total acc: 82.50%   
[EVAL] batch:    5 | acc: 100.00%,  total acc: 85.42%   
[EVAL] batch:    6 | acc: 100.00%,  total acc: 87.50%   
[EVAL] batch:    7 | acc: 93.75%,  total acc: 88.28%   
[EVAL] batch:    8 | acc: 81.25%,  total acc: 87.50%   
[EVAL] batch:    9 | acc: 87.50%,  total acc: 87.50%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 88.64%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 89.06%   
[EVAL] batch:   12 | acc: 56.25%,  total acc: 86.54%   
[EVAL] batch:    0 | acc: 0.00%,  total acc: 0.00%   
[EVAL] batch:    1 | acc: 25.00%,  total acc: 12.50%   
[EVAL] batch:    2 | acc: 6.25%,  total acc: 10.42%   
[EVAL] batch:    3 | acc: 6.25%,  total acc: 9.38%   
[EVAL] batch:    4 | acc: 12.50%,  total acc: 10.00%   
[EVAL] batch:    5 | acc: 6.25%,  total acc: 9.38%   
[EVAL] batch:    6 | acc: 6.25%,  total acc: 8.93%   
[EVAL] batch:    7 | acc: 0.00%,  total acc: 7.81%   
[EVAL] batch:    8 | acc: 0.00%,  total acc: 6.94%   
[EVAL] batch:    9 | acc: 0.00%,  total acc: 6.25%   
[EVAL] batch:   10 | acc: 0.00%,  total acc: 5.68%   
[EVAL] batch:   11 | acc: 6.25%,  total acc: 5.73%   
[EVAL] batch:   12 | acc: 0.00%,  total acc: 5.29%   
[EVAL] batch:   13 | acc: 31.25%,  total acc: 7.14%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 11.67%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 14.45%   
[EVAL] batch:   16 | acc: 68.75%,  total acc: 17.65%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 20.14%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 22.37%   
[EVAL] batch:   19 | acc: 81.25%,  total acc: 25.31%   
[EVAL] batch:   20 | acc: 93.75%,  total acc: 28.57%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 31.82%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 34.78%   
[EVAL] batch:   23 | acc: 93.75%,  total acc: 37.24%   
[EVAL] batch:   24 | acc: 93.75%,  total acc: 39.50%   
[EVAL] batch:   25 | acc: 87.50%,  total acc: 41.35%   
[EVAL] batch:   26 | acc: 62.50%,  total acc: 42.13%   
[EVAL] batch:   27 | acc: 31.25%,  total acc: 41.74%   
[EVAL] batch:   28 | acc: 37.50%,  total acc: 41.59%   
[EVAL] batch:   29 | acc: 31.25%,  total acc: 41.25%   
[EVAL] batch:   30 | acc: 31.25%,  total acc: 40.93%   
[EVAL] batch:   31 | acc: 37.50%,  total acc: 40.82%   
[EVAL] batch:   32 | acc: 12.50%,  total acc: 39.96%   
[EVAL] batch:   33 | acc: 6.25%,  total acc: 38.97%   
[EVAL] batch:   34 | acc: 6.25%,  total acc: 38.04%   
[EVAL] batch:   35 | acc: 12.50%,  total acc: 37.33%   
[EVAL] batch:   36 | acc: 6.25%,  total acc: 36.49%   
[EVAL] batch:   37 | acc: 56.25%,  total acc: 37.01%   
[EVAL] batch:   38 | acc: 75.00%,  total acc: 37.98%   
[EVAL] batch:   39 | acc: 100.00%,  total acc: 39.53%   
[EVAL] batch:   40 | acc: 62.50%,  total acc: 40.09%   
[EVAL] batch:   41 | acc: 100.00%,  total acc: 41.52%   
[EVAL] batch:   42 | acc: 0.00%,  total acc: 40.55%   
[EVAL] batch:   43 | acc: 0.00%,  total acc: 39.63%   
[EVAL] batch:   44 | acc: 0.00%,  total acc: 38.75%   
[EVAL] batch:   45 | acc: 0.00%,  total acc: 37.91%   
[EVAL] batch:   46 | acc: 12.50%,  total acc: 37.37%   
[EVAL] batch:   47 | acc: 43.75%,  total acc: 37.50%   
[EVAL] batch:   48 | acc: 0.00%,  total acc: 36.73%   
[EVAL] batch:   49 | acc: 0.00%,  total acc: 36.00%   
[EVAL] batch:   50 | acc: 0.00%,  total acc: 35.29%   
[EVAL] batch:   51 | acc: 0.00%,  total acc: 34.62%   
[EVAL] batch:   52 | acc: 0.00%,  total acc: 33.96%   
[EVAL] batch:   53 | acc: 31.25%,  total acc: 33.91%   
[EVAL] batch:   54 | acc: 87.50%,  total acc: 34.89%   
[EVAL] batch:   55 | acc: 81.25%,  total acc: 35.71%   
[EVAL] batch:   56 | acc: 68.75%,  total acc: 36.29%   
[EVAL] batch:   57 | acc: 62.50%,  total acc: 36.75%   
[EVAL] batch:   58 | acc: 56.25%,  total acc: 37.08%   
[EVAL] batch:   59 | acc: 56.25%,  total acc: 37.40%   
[EVAL] batch:   60 | acc: 0.00%,  total acc: 36.78%   
[EVAL] batch:   61 | acc: 6.25%,  total acc: 36.29%   
[EVAL] batch:   62 | acc: 12.50%,  total acc: 35.91%   
[EVAL] batch:   63 | acc: 25.00%,  total acc: 35.74%   
[EVAL] batch:   64 | acc: 6.25%,  total acc: 35.29%   
[EVAL] batch:   65 | acc: 6.25%,  total acc: 34.85%   
[EVAL] batch:   66 | acc: 18.75%,  total acc: 34.61%   
[EVAL] batch:   67 | acc: 93.75%,  total acc: 35.48%   
[EVAL] batch:   68 | acc: 43.75%,  total acc: 35.60%   
[EVAL] batch:   69 | acc: 18.75%,  total acc: 35.36%   
[EVAL] batch:   70 | acc: 37.50%,  total acc: 35.39%   
[EVAL] batch:   71 | acc: 68.75%,  total acc: 35.85%   
[EVAL] batch:   72 | acc: 93.75%,  total acc: 36.64%   
[EVAL] batch:   73 | acc: 100.00%,  total acc: 37.50%   
[EVAL] batch:   74 | acc: 100.00%,  total acc: 38.33%   
[EVAL] batch:   75 | acc: 100.00%,  total acc: 39.14%   
[EVAL] batch:   76 | acc: 100.00%,  total acc: 39.94%   
[EVAL] batch:   77 | acc: 62.50%,  total acc: 40.22%   
[EVAL] batch:   78 | acc: 0.00%,  total acc: 39.72%   
[EVAL] batch:   79 | acc: 0.00%,  total acc: 39.22%   
[EVAL] batch:   80 | acc: 0.00%,  total acc: 38.73%   
[EVAL] batch:   81 | acc: 6.25%,  total acc: 38.34%   
[EVAL] batch:   82 | acc: 12.50%,  total acc: 38.03%   
[EVAL] batch:   83 | acc: 12.50%,  total acc: 37.72%   
[EVAL] batch:   84 | acc: 25.00%,  total acc: 37.57%   
[EVAL] batch:   85 | acc: 50.00%,  total acc: 37.72%   
[EVAL] batch:   86 | acc: 37.50%,  total acc: 37.72%   
[EVAL] batch:   87 | acc: 75.00%,  total acc: 38.14%   
[EVAL] batch:   88 | acc: 50.00%,  total acc: 38.27%   
[EVAL] batch:   89 | acc: 50.00%,  total acc: 38.40%   
[EVAL] batch:   90 | acc: 68.75%,  total acc: 38.74%   
[EVAL] batch:   91 | acc: 87.50%,  total acc: 39.27%   
[EVAL] batch:   92 | acc: 93.75%,  total acc: 39.85%   
[EVAL] batch:   93 | acc: 75.00%,  total acc: 40.23%   
[EVAL] batch:   94 | acc: 56.25%,  total acc: 40.39%   
[EVAL] batch:   95 | acc: 56.25%,  total acc: 40.56%   
[EVAL] batch:   96 | acc: 6.25%,  total acc: 40.21%   
[EVAL] batch:   97 | acc: 6.25%,  total acc: 39.86%   
[EVAL] batch:   98 | acc: 12.50%,  total acc: 39.58%   
[EVAL] batch:   99 | acc: 75.00%,  total acc: 39.94%   
[EVAL] batch:  100 | acc: 81.25%,  total acc: 40.35%   
[EVAL] batch:  101 | acc: 87.50%,  total acc: 40.81%   
[EVAL] batch:  102 | acc: 87.50%,  total acc: 41.26%   
[EVAL] batch:  103 | acc: 87.50%,  total acc: 41.71%   
[EVAL] batch:  104 | acc: 100.00%,  total acc: 42.26%   
[EVAL] batch:  105 | acc: 100.00%,  total acc: 42.81%   
[EVAL] batch:  106 | acc: 81.25%,  total acc: 43.17%   
[EVAL] batch:  107 | acc: 75.00%,  total acc: 43.46%   
[EVAL] batch:  108 | acc: 81.25%,  total acc: 43.81%   
[EVAL] batch:  109 | acc: 81.25%,  total acc: 44.15%   
[EVAL] batch:  110 | acc: 100.00%,  total acc: 44.65%   
[EVAL] batch:  111 | acc: 93.75%,  total acc: 45.09%   
[EVAL] batch:  112 | acc: 100.00%,  total acc: 45.58%   
[EVAL] batch:  113 | acc: 100.00%,  total acc: 46.05%   
[EVAL] batch:  114 | acc: 93.75%,  total acc: 46.47%   
[EVAL] batch:  115 | acc: 68.75%,  total acc: 46.66%   
[EVAL] batch:  116 | acc: 100.00%,  total acc: 47.12%   
[EVAL] batch:  117 | acc: 100.00%,  total acc: 47.56%   
[EVAL] batch:  118 | acc: 81.25%,  total acc: 47.85%   
cur_acc:  ['0.8580', '0.8625', '0.8393', '0.8993', '0.6790', '0.8047', '0.8654']
his_acc:  ['0.8580', '0.8351', '0.7490', '0.6538', '0.6269', '0.4912', '0.4785']
CurrentTrain: epoch  0, batch     0 | loss: 4.7556052
CurrentTrain: epoch  0, batch     1 | loss: 4.4225726
CurrentTrain: epoch  1, batch     0 | loss: 4.0256968
CurrentTrain: epoch  1, batch     1 | loss: 2.7327027
CurrentTrain: epoch  2, batch     0 | loss: 2.8549056
CurrentTrain: epoch  2, batch     1 | loss: 2.6249018
CurrentTrain: epoch  3, batch     0 | loss: 2.6658802
CurrentTrain: epoch  3, batch     1 | loss: 2.2626474
CurrentTrain: epoch  4, batch     0 | loss: 2.7007060
CurrentTrain: epoch  4, batch     1 | loss: 1.8453901
CurrentTrain: epoch  5, batch     0 | loss: 2.4968638
CurrentTrain: epoch  5, batch     1 | loss: 1.7920004
CurrentTrain: epoch  6, batch     0 | loss: 1.7970791
CurrentTrain: epoch  6, batch     1 | loss: 2.7287309
CurrentTrain: epoch  7, batch     0 | loss: 2.1319792
CurrentTrain: epoch  7, batch     1 | loss: 1.9083898
CurrentTrain: epoch  8, batch     0 | loss: 1.8092699
CurrentTrain: epoch  8, batch     1 | loss: 2.1361809
CurrentTrain: epoch  9, batch     0 | loss: 1.9685608
CurrentTrain: epoch  9, batch     1 | loss: 1.7721994
#### organization founded ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization founded" means an organization was found in a date.
Here is an example:
Relation: organization founded
Context: the company was founded as a hobby in 1979 by the husband and wife team of tim and nina zagat , a pair of lawyers who started recuiting friends to provide their own ratings of the food , decor and service of restaurants they frequented .
Head Entity: zagat
Tail Entity: 1979
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization founded":
Relation: organization founded  
Context: In 1995, the tech startup was established by a group of engineers who aimed to revolutionize the software industry with innovative solutions.  
Head Entity: tech startup  
Tail Entity: 1995  

Relation: organization founded  
Context: The non-profit organization was created in 2001 to support local artists and promote cultural events in the community.  
Head Entity: non-profit organization  
Tail Entity: 2001  

Relation: organization founded  
Context: Founded in 1984, the educational institution has been dedicated to providing quality education and fostering research in various fields.  
Head Entity: educational institution  
Tail Entity: 1984  

Relation: organization founded  
Context: The environmental group was formed in 2010 by a coalition of activists who wanted to address climate change and promote sustainability.  
Head Entity: environmental group  
Tail Entity: 2010  

Relation: organization founded  
Context: In 1965, the charity was established to help underprivileged children gain access to education and healthcare services.  
Head Entity: charity  
Tail Entity: 1965  
#### person age ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person age" means a person 's age is a number.
Here is an example:
Relation: person age
Context: virginia republican jo ann davis passed away on saturday at the age of 57 .
Head Entity: jo ann davis
Tail Entity: 57
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person age":
Relation: person age  
Context: the famous actor robert downey jr. celebrated his 56th birthday last week.  
Head Entity: robert downey jr.  
Tail Entity: 56  

Relation: person age  
Context: on her 30th birthday, emily decided to throw a big party for her friends.  
Head Entity: emily  
Tail Entity: 30  

Relation: person age  
Context: the renowned scientist albert einstein was born in 1879, making him 76 years old when he passed away.  
Head Entity: albert einstein  
Tail Entity: 76  

Relation: person age  
Context: during the interview, the journalist revealed that she is 45 years old.  
Head Entity: the journalist  
Tail Entity: 45  

Relation: person age  
Context: my grandmother turned 80 last month, and we celebrated her life with a family gathering.  
Head Entity: my grandmother  
Tail Entity: 80  
#### person city of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person city of birth" means a person was born in a city.
Here is an example:
Relation: person city of birth
Context: joseph simpson farland was born on aug 11 , 1914 , in clarksburg , wva , the only child of richard and grace simpson farland .
Head Entity: joseph simpson farland
Tail Entity: clarksburg
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person city of birth":
Relation: person city of birth  
Context: marie curie was born in warsaw, poland, on november 7, 1867, and later became a renowned physicist and chemist.  
Head Entity: marie curie  
Tail Entity: warsaw  

Relation: person city of birth  
Context: barack obama was born in honolulu, hawaii, on august 4, 1961, and went on to become the 44th president of the united states.  
Head Entity: barack obama  
Tail Entity: honolulu  

Relation: person city of birth  
Context: frida kahlo was born in coyoacán, mexico city, on july 6, 1907, and is celebrated for her unique artistic style.  
Head Entity: frida kahlo  
Tail Entity: coyoacán  

Relation: person city of birth  
Context: nelson mandela was born in mvezo, south africa, on july 18, 1918, and became a key figure in the fight against apartheid.  
Head Entity: nelson mandela  
Tail Entity: mvezo  

Relation: person city of birth  
Context: agatha christie was born in torquay, england, on september 15, 1890, and is known as the queen of mystery novels.  
Head Entity: agatha christie  
Tail Entity: torquay  
#### organization members ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization members" means an organization 's member is an organization.
Here is an example:
Relation: organization members
Context: sun plays for the grand rapids flight of the international basketball league after toiling for the maryland nighthawks of the american basketball association , both development leagues for those who dream of an nba career .
Head Entity: american basketball association
Tail Entity: maryland nighthawks
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization members":
Relation: organization members  
Context: The New York Philharmonic is one of the oldest orchestras in the United States, and it has had many notable musicians, including members from the Boston Symphony Orchestra.  
Head Entity: Boston Symphony Orchestra  
Tail Entity: New York Philharmonic  

Relation: organization members  
Context: The National Football League has numerous teams, and the Dallas Cowboys are one of its most famous members, often competing against the New England Patriots.  
Head Entity: New England Patriots  
Tail Entity: Dallas Cowboys  

Relation: organization members  
Context: The United Nations consists of various specialized agencies, including the World Health Organization, which plays a crucial role in global health initiatives.  
Head Entity: World Health Organization  
Tail Entity: United Nations  

Relation: organization members  
Context: The International Olympic Committee oversees the Olympic Games and includes various national committees, such as the United States Olympic and Paralympic Committee.  
Head Entity: United States Olympic and Paralympic Committee  
Tail Entity: International Olympic Committee  

Relation: organization members  
Context: The European Union is made up of several member states, including Germany, which plays a significant role in the EU's economic policies.  
Head Entity: Germany  
Tail Entity: European Union  
#### person religion ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person religion" means an person is the member of a religion.
Here is an example:
Relation: person religion
Context: the pope defended his action on the grounds that he could not refuse an audience to a head of state from a country with a strong catholic tradition unless he had clear-cut proof of the allegations against him .
Head Entity: he
Tail Entity: catholic
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person religion":
Relation: person religion  
Context: During the ceremony, the rabbi spoke about the importance of faith and community in Judaism, emphasizing how every member plays a vital role.  
Head Entity: rabbi  
Tail Entity: Judaism  

Relation: person religion  
Context: The imam led the prayers at the mosque, reminding the congregation of their duties as followers of Islam and the significance of their beliefs.  
Head Entity: imam  
Tail Entity: Islam  

Relation: person religion  
Context: As a devout follower, she often participates in the rituals of her faith, which is deeply rooted in the teachings of Buddhism.  
Head Entity: she  
Tail Entity: Buddhism  

Relation: person religion  
Context: The pastor delivered a powerful sermon about love and forgiveness, encouraging his congregation to embrace the principles of Christianity in their daily lives.  
Head Entity: pastor  
Tail Entity: Christianity  

Relation: person religion  
Context: He often shares his experiences as a Sikh, highlighting the values of equality and service that are central to his religion.  
Head Entity: he  
Tail Entity: Sikhism  
Mixup data size:  35770
MixupTrain:  epoch  0, batch     0 | loss: 4.0374289
MixupTrain:  epoch  0, batch     1 | loss: 3.2986391
MixupTrain:  epoch  0, batch     2 | loss: 3.9604335
MixupTrain:  epoch  0, batch     3 | loss: 3.6612329
MixupTrain:  epoch  0, batch     4 | loss: 4.3562145
MixupTrain:  epoch  0, batch     5 | loss: 3.8199899
MixupTrain:  epoch  0, batch     6 | loss: 3.5608227
MixupTrain:  epoch  0, batch     7 | loss: 3.4172468
MixupTrain:  epoch  0, batch     8 | loss: 3.3825989
MixupTrain:  epoch  0, batch     9 | loss: 2.9865103
MixupTrain:  epoch  0, batch    10 | loss: 3.6280034
MixupTrain:  epoch  0, batch    11 | loss: 3.8569136
MixupTrain:  epoch  0, batch    12 | loss: 3.2305760
MixupTrain:  epoch  0, batch    13 | loss: 3.9709959
MixupTrain:  epoch  0, batch    14 | loss: 3.6076667
MixupTrain:  epoch  0, batch    15 | loss: 2.9868801
MixupTrain:  epoch  0, batch    16 | loss: 3.3667269
MixupTrain:  epoch  0, batch    17 | loss: 2.7259364
MixupTrain:  epoch  0, batch    18 | loss: 3.5478830
MixupTrain:  epoch  0, batch    19 | loss: 3.0142255
MixupTrain:  epoch  0, batch    20 | loss: 2.6044235
MixupTrain:  epoch  0, batch    21 | loss: 3.3363423
MixupTrain:  epoch  0, batch    22 | loss: 3.6521442
MixupTrain:  epoch  0, batch    23 | loss: 3.4529653
MixupTrain:  epoch  0, batch    24 | loss: 2.7520058
MixupTrain:  epoch  0, batch    25 | loss: 3.9883580
MixupTrain:  epoch  0, batch    26 | loss: 2.3592782
MixupTrain:  epoch  0, batch    27 | loss: 2.9774461
MixupTrain:  epoch  0, batch    28 | loss: 3.7184386
MixupTrain:  epoch  0, batch    29 | loss: 3.2910781
MixupTrain:  epoch  0, batch    30 | loss: 2.9053864
MixupTrain:  epoch  0, batch    31 | loss: 3.3318043
MixupTrain:  epoch  0, batch    32 | loss: 3.0970187
MixupTrain:  epoch  0, batch    33 | loss: 3.8917499
MixupTrain:  epoch  0, batch    34 | loss: 3.0234153
MixupTrain:  epoch  0, batch    35 | loss: 3.2885399
MixupTrain:  epoch  0, batch    36 | loss: 2.5435021
MixupTrain:  epoch  0, batch    37 | loss: 2.8356118
MixupTrain:  epoch  0, batch    38 | loss: 3.1415825
MixupTrain:  epoch  0, batch    39 | loss: 3.0106387
MixupTrain:  epoch  0, batch    40 | loss: 3.2526402
MixupTrain:  epoch  0, batch    41 | loss: 3.7160707
MixupTrain:  epoch  0, batch    42 | loss: 3.2432485
MixupTrain:  epoch  0, batch    43 | loss: 2.9279218
MixupTrain:  epoch  0, batch    44 | loss: 3.2703800
MixupTrain:  epoch  0, batch    45 | loss: 3.0237184
MixupTrain:  epoch  0, batch    46 | loss: 3.4895008
MixupTrain:  epoch  0, batch    47 | loss: 3.2059073
MixupTrain:  epoch  0, batch    48 | loss: 3.5856357
MixupTrain:  epoch  0, batch    49 | loss: 3.0255799
MixupTrain:  epoch  0, batch    50 | loss: 3.1993709
MixupTrain:  epoch  0, batch    51 | loss: 2.9849024
MixupTrain:  epoch  0, batch    52 | loss: 2.8639886
MixupTrain:  epoch  0, batch    53 | loss: 4.1743078
MixupTrain:  epoch  0, batch    54 | loss: 3.9309506
MixupTrain:  epoch  0, batch    55 | loss: 2.8613901
MixupTrain:  epoch  0, batch    56 | loss: 3.3545995
MixupTrain:  epoch  0, batch    57 | loss: 3.0679715
MixupTrain:  epoch  0, batch    58 | loss: 3.3430376
MixupTrain:  epoch  0, batch    59 | loss: 2.8235972
MixupTrain:  epoch  0, batch    60 | loss: 2.9280431
MixupTrain:  epoch  0, batch    61 | loss: 3.1971848
MixupTrain:  epoch  0, batch    62 | loss: 3.5739250
MixupTrain:  epoch  0, batch    63 | loss: 3.4893789
MixupTrain:  epoch  0, batch    64 | loss: 2.9419777
MixupTrain:  epoch  0, batch    65 | loss: 2.7129595
MixupTrain:  epoch  0, batch    66 | loss: 3.0837560
MixupTrain:  epoch  0, batch    67 | loss: 2.9452646
MixupTrain:  epoch  0, batch    68 | loss: 2.5656388
MixupTrain:  epoch  0, batch    69 | loss: 3.1051087
MixupTrain:  epoch  0, batch    70 | loss: 3.1564269
MixupTrain:  epoch  0, batch    71 | loss: 3.2464771
MixupTrain:  epoch  0, batch    72 | loss: 2.6369381
MixupTrain:  epoch  0, batch    73 | loss: 2.3707380
MixupTrain:  epoch  0, batch    74 | loss: 2.4811461
MixupTrain:  epoch  0, batch    75 | loss: 2.8110199
MixupTrain:  epoch  0, batch    76 | loss: 3.2268510
MixupTrain:  epoch  0, batch    77 | loss: 2.3924034
MixupTrain:  epoch  0, batch    78 | loss: 2.6746979
MixupTrain:  epoch  0, batch    79 | loss: 3.0492263
MixupTrain:  epoch  0, batch    80 | loss: 2.8214054
MixupTrain:  epoch  0, batch    81 | loss: 2.5706022
MixupTrain:  epoch  0, batch    82 | loss: 2.7128241
MixupTrain:  epoch  0, batch    83 | loss: 2.5722427
MixupTrain:  epoch  0, batch    84 | loss: 3.4246910
MixupTrain:  epoch  0, batch    85 | loss: 2.8462019
MixupTrain:  epoch  0, batch    86 | loss: 2.8402405
MixupTrain:  epoch  0, batch    87 | loss: 2.9451323
MixupTrain:  epoch  0, batch    88 | loss: 2.7659924
MixupTrain:  epoch  0, batch    89 | loss: 2.5603189
MixupTrain:  epoch  0, batch    90 | loss: 2.8672678
MixupTrain:  epoch  0, batch    91 | loss: 2.5139797
MixupTrain:  epoch  0, batch    92 | loss: 2.4278705
MixupTrain:  epoch  0, batch    93 | loss: 3.1518226
MixupTrain:  epoch  0, batch    94 | loss: 2.2951834
MixupTrain:  epoch  0, batch    95 | loss: 2.7488203
MixupTrain:  epoch  0, batch    96 | loss: 2.2924767
MixupTrain:  epoch  0, batch    97 | loss: 2.8750126
MixupTrain:  epoch  0, batch    98 | loss: 2.9806669
MixupTrain:  epoch  0, batch    99 | loss: 2.5784109
MixupTrain:  epoch  0, batch   100 | loss: 1.8743892
MixupTrain:  epoch  0, batch   101 | loss: 3.0890214
MixupTrain:  epoch  0, batch   102 | loss: 2.3324108
MixupTrain:  epoch  0, batch   103 | loss: 2.4381313
MixupTrain:  epoch  0, batch   104 | loss: 2.3060222
MixupTrain:  epoch  0, batch   105 | loss: 3.5736203
MixupTrain:  epoch  0, batch   106 | loss: 2.8947330
MixupTrain:  epoch  0, batch   107 | loss: 2.3445244
MixupTrain:  epoch  0, batch   108 | loss: 2.5051522
MixupTrain:  epoch  0, batch   109 | loss: 2.8573043
MixupTrain:  epoch  0, batch   110 | loss: 2.6083751
MixupTrain:  epoch  0, batch   111 | loss: 2.7116885
MixupTrain:  epoch  0, batch   112 | loss: 2.3654590
MixupTrain:  epoch  0, batch   113 | loss: 2.8065071
MixupTrain:  epoch  0, batch   114 | loss: 2.9663491
MixupTrain:  epoch  0, batch   115 | loss: 2.7154503
MixupTrain:  epoch  0, batch   116 | loss: 2.5196631
MixupTrain:  epoch  0, batch   117 | loss: 2.8467088
MixupTrain:  epoch  0, batch   118 | loss: 3.0253077
MixupTrain:  epoch  0, batch   119 | loss: 2.7297561
MixupTrain:  epoch  0, batch   120 | loss: 2.5502992
MixupTrain:  epoch  0, batch   121 | loss: 2.9708502
MixupTrain:  epoch  0, batch   122 | loss: 2.2098789
MixupTrain:  epoch  0, batch   123 | loss: 3.2790842
MixupTrain:  epoch  0, batch   124 | loss: 2.5165935
MixupTrain:  epoch  0, batch   125 | loss: 2.5623846
MixupTrain:  epoch  0, batch   126 | loss: 3.1306424
MixupTrain:  epoch  0, batch   127 | loss: 2.4995165
MixupTrain:  epoch  0, batch   128 | loss: 2.5133896
MixupTrain:  epoch  0, batch   129 | loss: 2.8152235
MixupTrain:  epoch  0, batch   130 | loss: 2.9441364
MixupTrain:  epoch  0, batch   131 | loss: 2.3702576
MixupTrain:  epoch  0, batch   132 | loss: 2.7756286
MixupTrain:  epoch  0, batch   133 | loss: 2.6778586
MixupTrain:  epoch  0, batch   134 | loss: 2.3993404
MixupTrain:  epoch  0, batch   135 | loss: 2.4423242
MixupTrain:  epoch  0, batch   136 | loss: 2.3319535
MixupTrain:  epoch  0, batch   137 | loss: 2.8045363
MixupTrain:  epoch  0, batch   138 | loss: 3.2436492
MixupTrain:  epoch  0, batch   139 | loss: 3.3112757
MixupTrain:  epoch  0, batch   140 | loss: 3.3818371
MixupTrain:  epoch  0, batch   141 | loss: 2.7933259
MixupTrain:  epoch  0, batch   142 | loss: 2.4248428
MixupTrain:  epoch  0, batch   143 | loss: 2.8180742
MixupTrain:  epoch  0, batch   144 | loss: 2.7140346
MixupTrain:  epoch  0, batch   145 | loss: 2.6750522
MixupTrain:  epoch  0, batch   146 | loss: 2.7116158
MixupTrain:  epoch  0, batch   147 | loss: 2.8074522
MixupTrain:  epoch  0, batch   148 | loss: 2.8258104
MixupTrain:  epoch  0, batch   149 | loss: 2.5179291
MixupTrain:  epoch  0, batch   150 | loss: 2.5669603
MixupTrain:  epoch  0, batch   151 | loss: 2.7665761
MixupTrain:  epoch  0, batch   152 | loss: 2.6354482
MixupTrain:  epoch  0, batch   153 | loss: 2.3515573
MixupTrain:  epoch  0, batch   154 | loss: 2.9560528
MixupTrain:  epoch  0, batch   155 | loss: 2.4015908
MixupTrain:  epoch  0, batch   156 | loss: 2.6486011
MixupTrain:  epoch  0, batch   157 | loss: 2.4252768
MixupTrain:  epoch  0, batch   158 | loss: 2.2842112
MixupTrain:  epoch  0, batch   159 | loss: 3.2526536
MixupTrain:  epoch  0, batch   160 | loss: 2.4129891
MixupTrain:  epoch  0, batch   161 | loss: 2.5080571
MixupTrain:  epoch  0, batch   162 | loss: 3.2423193
MixupTrain:  epoch  0, batch   163 | loss: 2.8187647
MixupTrain:  epoch  0, batch   164 | loss: 2.6206739
MixupTrain:  epoch  0, batch   165 | loss: 2.2694032
MixupTrain:  epoch  0, batch   166 | loss: 2.3214765
MixupTrain:  epoch  0, batch   167 | loss: 2.1579390
MixupTrain:  epoch  0, batch   168 | loss: 2.8130865
MixupTrain:  epoch  0, batch   169 | loss: 2.6370935
MixupTrain:  epoch  0, batch   170 | loss: 2.3534923
MixupTrain:  epoch  0, batch   171 | loss: 3.0847664
MixupTrain:  epoch  0, batch   172 | loss: 2.0087619
MixupTrain:  epoch  0, batch   173 | loss: 2.4174824
MixupTrain:  epoch  0, batch   174 | loss: 2.3252025
MixupTrain:  epoch  0, batch   175 | loss: 2.1159925
MixupTrain:  epoch  0, batch   176 | loss: 2.7823253
MixupTrain:  epoch  0, batch   177 | loss: 2.2522960
MixupTrain:  epoch  0, batch   178 | loss: 2.2975073
MixupTrain:  epoch  0, batch   179 | loss: 2.2921576
MixupTrain:  epoch  0, batch   180 | loss: 2.3570495
MixupTrain:  epoch  0, batch   181 | loss: 3.3493881
MixupTrain:  epoch  0, batch   182 | loss: 2.3339005
MixupTrain:  epoch  0, batch   183 | loss: 2.6705999
MixupTrain:  epoch  0, batch   184 | loss: 2.6022594
MixupTrain:  epoch  0, batch   185 | loss: 2.2040155
MixupTrain:  epoch  0, batch   186 | loss: 2.7680552
MixupTrain:  epoch  0, batch   187 | loss: 3.2244411
MixupTrain:  epoch  0, batch   188 | loss: 2.7183332
MixupTrain:  epoch  0, batch   189 | loss: 2.3341026
MixupTrain:  epoch  0, batch   190 | loss: 2.6728368
MixupTrain:  epoch  0, batch   191 | loss: 2.2593687
MixupTrain:  epoch  0, batch   192 | loss: 2.6172605
MixupTrain:  epoch  0, batch   193 | loss: 2.0511308
MixupTrain:  epoch  0, batch   194 | loss: 2.5457010
MixupTrain:  epoch  0, batch   195 | loss: 3.1860185
MixupTrain:  epoch  0, batch   196 | loss: 2.5058508
MixupTrain:  epoch  0, batch   197 | loss: 2.5851457
MixupTrain:  epoch  0, batch   198 | loss: 2.7225094
MixupTrain:  epoch  0, batch   199 | loss: 2.7167659
MixupTrain:  epoch  0, batch   200 | loss: 2.4295201
MixupTrain:  epoch  0, batch   201 | loss: 2.4175608
MixupTrain:  epoch  0, batch   202 | loss: 2.5135732
MixupTrain:  epoch  0, batch   203 | loss: 2.7701263
MixupTrain:  epoch  0, batch   204 | loss: 2.5314565
MixupTrain:  epoch  0, batch   205 | loss: 2.2750287
MixupTrain:  epoch  0, batch   206 | loss: 2.7373271
MixupTrain:  epoch  0, batch   207 | loss: 3.0057082
MixupTrain:  epoch  0, batch   208 | loss: 2.7643323
MixupTrain:  epoch  0, batch   209 | loss: 2.5520954
MixupTrain:  epoch  0, batch   210 | loss: 3.6663983
MixupTrain:  epoch  0, batch   211 | loss: 2.1168699
MixupTrain:  epoch  0, batch   212 | loss: 2.6898241
MixupTrain:  epoch  0, batch   213 | loss: 2.5457482
MixupTrain:  epoch  0, batch   214 | loss: 2.2250335
MixupTrain:  epoch  0, batch   215 | loss: 2.3594146
MixupTrain:  epoch  0, batch   216 | loss: 2.6431780
MixupTrain:  epoch  0, batch   217 | loss: 2.7008502
MixupTrain:  epoch  0, batch   218 | loss: 2.5319979
MixupTrain:  epoch  0, batch   219 | loss: 2.4907768
MixupTrain:  epoch  0, batch   220 | loss: 2.2993467
MixupTrain:  epoch  0, batch   221 | loss: 2.8208008
MixupTrain:  epoch  0, batch   222 | loss: 2.3070626
MixupTrain:  epoch  0, batch   223 | loss: 2.7407176
MixupTrain:  epoch  0, batch   224 | loss: 2.7489994
MixupTrain:  epoch  0, batch   225 | loss: 2.5075359
MixupTrain:  epoch  0, batch   226 | loss: 2.3918240
MixupTrain:  epoch  0, batch   227 | loss: 2.5681179
MixupTrain:  epoch  0, batch   228 | loss: 2.2708087
MixupTrain:  epoch  0, batch   229 | loss: 2.7248926
MixupTrain:  epoch  0, batch   230 | loss: 2.3280921
MixupTrain:  epoch  0, batch   231 | loss: 2.7336545
MixupTrain:  epoch  0, batch   232 | loss: 2.7181692
MixupTrain:  epoch  0, batch   233 | loss: 2.7130904
MixupTrain:  epoch  0, batch   234 | loss: 3.0273743
MixupTrain:  epoch  0, batch   235 | loss: 1.9646320
MixupTrain:  epoch  0, batch   236 | loss: 2.0464058
MixupTrain:  epoch  0, batch   237 | loss: 2.5331731
MixupTrain:  epoch  0, batch   238 | loss: 2.2013667
MixupTrain:  epoch  0, batch   239 | loss: 2.5136240
MixupTrain:  epoch  0, batch   240 | loss: 2.3787205
MixupTrain:  epoch  0, batch   241 | loss: 2.1551831
MixupTrain:  epoch  0, batch   242 | loss: 2.4243050
MixupTrain:  epoch  0, batch   243 | loss: 2.6538291
MixupTrain:  epoch  0, batch   244 | loss: 2.5375390
MixupTrain:  epoch  0, batch   245 | loss: 2.2059860
MixupTrain:  epoch  0, batch   246 | loss: 2.1205196
MixupTrain:  epoch  0, batch   247 | loss: 2.7227550
MixupTrain:  epoch  0, batch   248 | loss: 3.1302581
MixupTrain:  epoch  0, batch   249 | loss: 2.6031566
MixupTrain:  epoch  0, batch   250 | loss: 2.5973351
MixupTrain:  epoch  0, batch   251 | loss: 2.1886368
MixupTrain:  epoch  0, batch   252 | loss: 2.5754106
MixupTrain:  epoch  0, batch   253 | loss: 2.3719769
MixupTrain:  epoch  0, batch   254 | loss: 2.2584455
MixupTrain:  epoch  0, batch   255 | loss: 2.4992180
MixupTrain:  epoch  0, batch   256 | loss: 2.0324399
MixupTrain:  epoch  0, batch   257 | loss: 2.3725586
MixupTrain:  epoch  0, batch   258 | loss: 2.3331852
MixupTrain:  epoch  0, batch   259 | loss: 2.7338133
MixupTrain:  epoch  0, batch   260 | loss: 2.1870399
MixupTrain:  epoch  0, batch   261 | loss: 2.5936720
MixupTrain:  epoch  0, batch   262 | loss: 2.5151536
MixupTrain:  epoch  0, batch   263 | loss: 2.3361645
MixupTrain:  epoch  0, batch   264 | loss: 2.8662956
MixupTrain:  epoch  0, batch   265 | loss: 2.1769004
MixupTrain:  epoch  0, batch   266 | loss: 2.6774864
MixupTrain:  epoch  0, batch   267 | loss: 2.1887460
MixupTrain:  epoch  0, batch   268 | loss: 2.2229981
MixupTrain:  epoch  0, batch   269 | loss: 2.6765382
MixupTrain:  epoch  0, batch   270 | loss: 2.2787771
MixupTrain:  epoch  0, batch   271 | loss: 2.3247905
MixupTrain:  epoch  0, batch   272 | loss: 2.3843303
MixupTrain:  epoch  0, batch   273 | loss: 2.6116977
MixupTrain:  epoch  0, batch   274 | loss: 2.4489176
MixupTrain:  epoch  0, batch   275 | loss: 2.2486691
MixupTrain:  epoch  0, batch   276 | loss: 2.8786950
MixupTrain:  epoch  0, batch   277 | loss: 3.1046238
MixupTrain:  epoch  0, batch   278 | loss: 2.4738398
MixupTrain:  epoch  0, batch   279 | loss: 2.4153209
MixupTrain:  epoch  0, batch   280 | loss: 2.6237235
MixupTrain:  epoch  0, batch   281 | loss: 2.3324072
MixupTrain:  epoch  0, batch   282 | loss: 2.7398820
MixupTrain:  epoch  0, batch   283 | loss: 2.8752515
MixupTrain:  epoch  0, batch   284 | loss: 2.4012432
MixupTrain:  epoch  0, batch   285 | loss: 2.3461270
MixupTrain:  epoch  0, batch   286 | loss: 2.4330320
MixupTrain:  epoch  0, batch   287 | loss: 2.7351007
MixupTrain:  epoch  0, batch   288 | loss: 3.0415838
MixupTrain:  epoch  0, batch   289 | loss: 2.6912632
MixupTrain:  epoch  0, batch   290 | loss: 2.3385630
MixupTrain:  epoch  0, batch   291 | loss: 2.3949344
MixupTrain:  epoch  0, batch   292 | loss: 2.2951705
MixupTrain:  epoch  0, batch   293 | loss: 2.2753401
MixupTrain:  epoch  0, batch   294 | loss: 2.6525636
MixupTrain:  epoch  0, batch   295 | loss: 2.7882195
MixupTrain:  epoch  0, batch   296 | loss: 2.7033348
MixupTrain:  epoch  0, batch   297 | loss: 2.3067079
MixupTrain:  epoch  0, batch   298 | loss: 2.6017456
MixupTrain:  epoch  0, batch   299 | loss: 2.4365015
MixupTrain:  epoch  0, batch   300 | loss: 2.4611268
MixupTrain:  epoch  0, batch   301 | loss: 2.6961708
MixupTrain:  epoch  0, batch   302 | loss: 2.1620009
MixupTrain:  epoch  0, batch   303 | loss: 2.2415323
MixupTrain:  epoch  0, batch   304 | loss: 2.1785893
MixupTrain:  epoch  0, batch   305 | loss: 2.4808140
MixupTrain:  epoch  0, batch   306 | loss: 2.4226651
MixupTrain:  epoch  0, batch   307 | loss: 2.4857044
MixupTrain:  epoch  0, batch   308 | loss: 2.7153854
MixupTrain:  epoch  0, batch   309 | loss: 2.9680893
MixupTrain:  epoch  0, batch   310 | loss: 2.2068448
MixupTrain:  epoch  0, batch   311 | loss: 2.7119136
MixupTrain:  epoch  0, batch   312 | loss: 3.0521822
MixupTrain:  epoch  0, batch   313 | loss: 2.3214273
MixupTrain:  epoch  0, batch   314 | loss: 2.3123853
MixupTrain:  epoch  0, batch   315 | loss: 2.5911045
MixupTrain:  epoch  0, batch   316 | loss: 2.0228245
MixupTrain:  epoch  0, batch   317 | loss: 2.7804270
MixupTrain:  epoch  0, batch   318 | loss: 2.5940447
MixupTrain:  epoch  0, batch   319 | loss: 2.4853375
MixupTrain:  epoch  0, batch   320 | loss: 2.3591049
MixupTrain:  epoch  0, batch   321 | loss: 2.2282782
MixupTrain:  epoch  0, batch   322 | loss: 2.5398536
MixupTrain:  epoch  0, batch   323 | loss: 2.2609549
MixupTrain:  epoch  0, batch   324 | loss: 2.5124652
MixupTrain:  epoch  0, batch   325 | loss: 2.3169832
MixupTrain:  epoch  0, batch   326 | loss: 2.2838430
MixupTrain:  epoch  0, batch   327 | loss: 2.2853334
MixupTrain:  epoch  0, batch   328 | loss: 2.7411325
MixupTrain:  epoch  0, batch   329 | loss: 2.7456579
MixupTrain:  epoch  0, batch   330 | loss: 2.7592430
MixupTrain:  epoch  0, batch   331 | loss: 2.4170752
MixupTrain:  epoch  0, batch   332 | loss: 2.5759168
MixupTrain:  epoch  0, batch   333 | loss: 2.4604778
MixupTrain:  epoch  0, batch   334 | loss: 2.7052226
MixupTrain:  epoch  0, batch   335 | loss: 2.8333497
MixupTrain:  epoch  0, batch   336 | loss: 2.8675404
MixupTrain:  epoch  0, batch   337 | loss: 2.4652083
MixupTrain:  epoch  0, batch   338 | loss: 2.4010890
MixupTrain:  epoch  0, batch   339 | loss: 2.4152546
MixupTrain:  epoch  0, batch   340 | loss: 2.4046712
MixupTrain:  epoch  0, batch   341 | loss: 2.7638052
MixupTrain:  epoch  0, batch   342 | loss: 2.7292399
MixupTrain:  epoch  0, batch   343 | loss: 2.1994126
MixupTrain:  epoch  0, batch   344 | loss: 2.4327314
MixupTrain:  epoch  0, batch   345 | loss: 2.6075304
MixupTrain:  epoch  0, batch   346 | loss: 2.3272274
MixupTrain:  epoch  0, batch   347 | loss: 2.4944737
MixupTrain:  epoch  0, batch   348 | loss: 2.4235530
MixupTrain:  epoch  0, batch   349 | loss: 2.2919898
MixupTrain:  epoch  0, batch   350 | loss: 2.6074746
MixupTrain:  epoch  0, batch   351 | loss: 2.4566641
MixupTrain:  epoch  0, batch   352 | loss: 2.2600503
MixupTrain:  epoch  0, batch   353 | loss: 2.1216412
MixupTrain:  epoch  0, batch   354 | loss: 2.5197940
MixupTrain:  epoch  0, batch   355 | loss: 2.5456121
MixupTrain:  epoch  0, batch   356 | loss: 2.8337049
MixupTrain:  epoch  0, batch   357 | loss: 2.1791589
MixupTrain:  epoch  0, batch   358 | loss: 2.8283010
MixupTrain:  epoch  0, batch   359 | loss: 2.4840066
MixupTrain:  epoch  0, batch   360 | loss: 2.4942157
MixupTrain:  epoch  0, batch   361 | loss: 2.9502001
MixupTrain:  epoch  0, batch   362 | loss: 2.2845893
MixupTrain:  epoch  0, batch   363 | loss: 2.1162200
MixupTrain:  epoch  0, batch   364 | loss: 2.3152478
MixupTrain:  epoch  0, batch   365 | loss: 2.3842597
MixupTrain:  epoch  0, batch   366 | loss: 2.9511383
MixupTrain:  epoch  0, batch   367 | loss: 2.3803282
MixupTrain:  epoch  0, batch   368 | loss: 2.4950120
MixupTrain:  epoch  0, batch   369 | loss: 2.7595196
MixupTrain:  epoch  0, batch   370 | loss: 2.2795243
MixupTrain:  epoch  0, batch   371 | loss: 2.5193343
MixupTrain:  epoch  0, batch   372 | loss: 2.2066519
MixupTrain:  epoch  0, batch   373 | loss: 2.3589292
MixupTrain:  epoch  0, batch   374 | loss: 2.6724896
MixupTrain:  epoch  0, batch   375 | loss: 3.1642675
MixupTrain:  epoch  0, batch   376 | loss: 2.5383840
MixupTrain:  epoch  0, batch   377 | loss: 2.6089580
MixupTrain:  epoch  0, batch   378 | loss: 2.4835277
MixupTrain:  epoch  0, batch   379 | loss: 2.4470453
MixupTrain:  epoch  0, batch   380 | loss: 2.3560586
MixupTrain:  epoch  0, batch   381 | loss: 2.1979494
MixupTrain:  epoch  0, batch   382 | loss: 2.2449622
MixupTrain:  epoch  0, batch   383 | loss: 2.4991016
MixupTrain:  epoch  0, batch   384 | loss: 2.5082355
MixupTrain:  epoch  0, batch   385 | loss: 2.7405369
MixupTrain:  epoch  0, batch   386 | loss: 2.2144144
MixupTrain:  epoch  0, batch   387 | loss: 2.4686208
MixupTrain:  epoch  0, batch   388 | loss: 2.1780210
MixupTrain:  epoch  0, batch   389 | loss: 2.4652672
MixupTrain:  epoch  0, batch   390 | loss: 2.5700345
MixupTrain:  epoch  0, batch   391 | loss: 2.5599093
MixupTrain:  epoch  0, batch   392 | loss: 2.2615347
MixupTrain:  epoch  0, batch   393 | loss: 2.3084393
MixupTrain:  epoch  0, batch   394 | loss: 2.2880483
MixupTrain:  epoch  0, batch   395 | loss: 2.8790150
MixupTrain:  epoch  0, batch   396 | loss: 2.6482728
MixupTrain:  epoch  0, batch   397 | loss: 2.2497787
MixupTrain:  epoch  0, batch   398 | loss: 2.5909853
MixupTrain:  epoch  0, batch   399 | loss: 2.3542962
MixupTrain:  epoch  0, batch   400 | loss: 2.4807017
MixupTrain:  epoch  0, batch   401 | loss: 2.5228209
MixupTrain:  epoch  0, batch   402 | loss: 2.2679520
MixupTrain:  epoch  0, batch   403 | loss: 2.6138279
MixupTrain:  epoch  0, batch   404 | loss: 2.7417903
MixupTrain:  epoch  0, batch   405 | loss: 2.5975652
MixupTrain:  epoch  0, batch   406 | loss: 2.6686783
MixupTrain:  epoch  0, batch   407 | loss: 2.2825112
MixupTrain:  epoch  0, batch   408 | loss: 2.3212867
MixupTrain:  epoch  0, batch   409 | loss: 2.5460687
MixupTrain:  epoch  0, batch   410 | loss: 2.3369403
MixupTrain:  epoch  0, batch   411 | loss: 2.3526144
MixupTrain:  epoch  0, batch   412 | loss: 2.6867070
MixupTrain:  epoch  0, batch   413 | loss: 2.5661769
MixupTrain:  epoch  0, batch   414 | loss: 2.1645794
MixupTrain:  epoch  0, batch   415 | loss: 2.3254747
MixupTrain:  epoch  0, batch   416 | loss: 2.4013393
MixupTrain:  epoch  0, batch   417 | loss: 2.7458782
MixupTrain:  epoch  0, batch   418 | loss: 2.0567918
MixupTrain:  epoch  0, batch   419 | loss: 2.4588125
MixupTrain:  epoch  0, batch   420 | loss: 2.5839667
MixupTrain:  epoch  0, batch   421 | loss: 2.2622502
MixupTrain:  epoch  0, batch   422 | loss: 2.5553730
MixupTrain:  epoch  0, batch   423 | loss: 2.7495213
MixupTrain:  epoch  0, batch   424 | loss: 2.4488199
MixupTrain:  epoch  0, batch   425 | loss: 2.5123053
MixupTrain:  epoch  0, batch   426 | loss: 2.1807435
MixupTrain:  epoch  0, batch   427 | loss: 2.6124234
MixupTrain:  epoch  0, batch   428 | loss: 2.2841895
MixupTrain:  epoch  0, batch   429 | loss: 2.3026018
MixupTrain:  epoch  0, batch   430 | loss: 2.4392443
MixupTrain:  epoch  0, batch   431 | loss: 2.8682647
MixupTrain:  epoch  0, batch   432 | loss: 2.2179880
MixupTrain:  epoch  0, batch   433 | loss: 2.8573995
MixupTrain:  epoch  0, batch   434 | loss: 2.5062718
MixupTrain:  epoch  0, batch   435 | loss: 3.0555644
MixupTrain:  epoch  0, batch   436 | loss: 2.4763579
MixupTrain:  epoch  0, batch   437 | loss: 2.4647374
MixupTrain:  epoch  0, batch   438 | loss: 2.4763269
MixupTrain:  epoch  0, batch   439 | loss: 2.1418185
MixupTrain:  epoch  0, batch   440 | loss: 2.6354356
MixupTrain:  epoch  0, batch   441 | loss: 2.1086094
MixupTrain:  epoch  0, batch   442 | loss: 2.3760052
MixupTrain:  epoch  0, batch   443 | loss: 2.4743092
MixupTrain:  epoch  0, batch   444 | loss: 2.5378623
MixupTrain:  epoch  0, batch   445 | loss: 2.3734612
MixupTrain:  epoch  0, batch   446 | loss: 2.5634022
MixupTrain:  epoch  0, batch   447 | loss: 2.6765161
MixupTrain:  epoch  0, batch   448 | loss: 2.4720752
MixupTrain:  epoch  0, batch   449 | loss: 2.4315879
MixupTrain:  epoch  0, batch   450 | loss: 2.7262096
MixupTrain:  epoch  0, batch   451 | loss: 2.6131301
MixupTrain:  epoch  0, batch   452 | loss: 2.4197097
MixupTrain:  epoch  0, batch   453 | loss: 2.7385874
MixupTrain:  epoch  0, batch   454 | loss: 2.3799264
MixupTrain:  epoch  0, batch   455 | loss: 2.3829618
MixupTrain:  epoch  0, batch   456 | loss: 2.6492667
MixupTrain:  epoch  0, batch   457 | loss: 2.8511295
MixupTrain:  epoch  0, batch   458 | loss: 2.4032569
MixupTrain:  epoch  0, batch   459 | loss: 2.5398877
MixupTrain:  epoch  0, batch   460 | loss: 2.4115191
MixupTrain:  epoch  0, batch   461 | loss: 2.3523824
MixupTrain:  epoch  0, batch   462 | loss: 2.6052151
MixupTrain:  epoch  0, batch   463 | loss: 2.2361104
MixupTrain:  epoch  0, batch   464 | loss: 2.5550909
MixupTrain:  epoch  0, batch   465 | loss: 2.4483318
MixupTrain:  epoch  0, batch   466 | loss: 2.4066143
MixupTrain:  epoch  0, batch   467 | loss: 2.3157768
MixupTrain:  epoch  0, batch   468 | loss: 2.2902091
MixupTrain:  epoch  0, batch   469 | loss: 2.4470592
MixupTrain:  epoch  0, batch   470 | loss: 2.5894327
MixupTrain:  epoch  0, batch   471 | loss: 2.3643064
MixupTrain:  epoch  0, batch   472 | loss: 2.4987001
MixupTrain:  epoch  0, batch   473 | loss: 2.5427046
MixupTrain:  epoch  0, batch   474 | loss: 2.5398612
MixupTrain:  epoch  0, batch   475 | loss: 2.2723150
MixupTrain:  epoch  0, batch   476 | loss: 2.1481090
MixupTrain:  epoch  0, batch   477 | loss: 2.2150617
MixupTrain:  epoch  0, batch   478 | loss: 2.6426315
MixupTrain:  epoch  0, batch   479 | loss: 2.2527306
MixupTrain:  epoch  0, batch   480 | loss: 2.5221508
MixupTrain:  epoch  0, batch   481 | loss: 2.2047300
MixupTrain:  epoch  0, batch   482 | loss: 2.9078612
MixupTrain:  epoch  0, batch   483 | loss: 2.1363482
MixupTrain:  epoch  0, batch   484 | loss: 2.9642773
MixupTrain:  epoch  0, batch   485 | loss: 2.4160211
MixupTrain:  epoch  0, batch   486 | loss: 2.3076406
MixupTrain:  epoch  0, batch   487 | loss: 2.5825467
MixupTrain:  epoch  0, batch   488 | loss: 2.4089155
MixupTrain:  epoch  0, batch   489 | loss: 2.0915847
MixupTrain:  epoch  0, batch   490 | loss: 2.1912658
MixupTrain:  epoch  0, batch   491 | loss: 2.4909470
MixupTrain:  epoch  0, batch   492 | loss: 2.3885601
MixupTrain:  epoch  0, batch   493 | loss: 2.5813050
MixupTrain:  epoch  0, batch   494 | loss: 2.5542247
MixupTrain:  epoch  0, batch   495 | loss: 2.5616932
MixupTrain:  epoch  0, batch   496 | loss: 2.2092552
MixupTrain:  epoch  0, batch   497 | loss: 2.4194880
MixupTrain:  epoch  0, batch   498 | loss: 2.1951251
MixupTrain:  epoch  0, batch   499 | loss: 2.8952167
MixupTrain:  epoch  0, batch   500 | loss: 2.2811260
MixupTrain:  epoch  0, batch   501 | loss: 2.4208055
MixupTrain:  epoch  0, batch   502 | loss: 2.0201750
MixupTrain:  epoch  0, batch   503 | loss: 2.4350193
MixupTrain:  epoch  0, batch   504 | loss: 2.7439332
MixupTrain:  epoch  0, batch   505 | loss: 2.8589859
MixupTrain:  epoch  0, batch   506 | loss: 2.4268889
MixupTrain:  epoch  0, batch   507 | loss: 2.4658446
MixupTrain:  epoch  0, batch   508 | loss: 1.8989646
MixupTrain:  epoch  0, batch   509 | loss: 2.6114917
MixupTrain:  epoch  0, batch   510 | loss: 2.5629048
MixupTrain:  epoch  0, batch   511 | loss: 2.3825064
MixupTrain:  epoch  0, batch   512 | loss: 2.5389001
MixupTrain:  epoch  0, batch   513 | loss: 2.2779961
MixupTrain:  epoch  0, batch   514 | loss: 2.0249038
MixupTrain:  epoch  0, batch   515 | loss: 2.3225703
MixupTrain:  epoch  0, batch   516 | loss: 2.3205600
MixupTrain:  epoch  0, batch   517 | loss: 2.4208434
MixupTrain:  epoch  0, batch   518 | loss: 2.4970808
MixupTrain:  epoch  0, batch   519 | loss: 2.2441273
MixupTrain:  epoch  0, batch   520 | loss: 2.4590590
MixupTrain:  epoch  0, batch   521 | loss: 2.3760579
MixupTrain:  epoch  0, batch   522 | loss: 2.6950426
MixupTrain:  epoch  0, batch   523 | loss: 2.3251526
MixupTrain:  epoch  0, batch   524 | loss: 2.2467873
MixupTrain:  epoch  0, batch   525 | loss: 2.6599288
MixupTrain:  epoch  0, batch   526 | loss: 2.3810112
MixupTrain:  epoch  0, batch   527 | loss: 2.3327045
MixupTrain:  epoch  0, batch   528 | loss: 1.9584811
MixupTrain:  epoch  0, batch   529 | loss: 2.2988372
MixupTrain:  epoch  0, batch   530 | loss: 2.5995219
MixupTrain:  epoch  0, batch   531 | loss: 2.3282204
MixupTrain:  epoch  0, batch   532 | loss: 2.2442985
MixupTrain:  epoch  0, batch   533 | loss: 2.0794747
MixupTrain:  epoch  0, batch   534 | loss: 2.3422382
MixupTrain:  epoch  0, batch   535 | loss: 2.3549738
MixupTrain:  epoch  0, batch   536 | loss: 2.1930468
MixupTrain:  epoch  0, batch   537 | loss: 2.7441916
MixupTrain:  epoch  0, batch   538 | loss: 2.4065912
MixupTrain:  epoch  0, batch   539 | loss: 2.2891796
MixupTrain:  epoch  0, batch   540 | loss: 2.4643049
MixupTrain:  epoch  0, batch   541 | loss: 2.7957621
MixupTrain:  epoch  0, batch   542 | loss: 2.5683489
MixupTrain:  epoch  0, batch   543 | loss: 2.4924588
MixupTrain:  epoch  0, batch   544 | loss: 2.2111626
MixupTrain:  epoch  0, batch   545 | loss: 2.2723470
MixupTrain:  epoch  0, batch   546 | loss: 2.4632268
MixupTrain:  epoch  0, batch   547 | loss: 2.0308321
MixupTrain:  epoch  0, batch   548 | loss: 2.4887438
MixupTrain:  epoch  0, batch   549 | loss: 2.4007397
MixupTrain:  epoch  0, batch   550 | loss: 2.5199497
MixupTrain:  epoch  0, batch   551 | loss: 2.1478293
MixupTrain:  epoch  0, batch   552 | loss: 2.5344496
MixupTrain:  epoch  0, batch   553 | loss: 2.3840919
MixupTrain:  epoch  0, batch   554 | loss: 2.4909501
MixupTrain:  epoch  0, batch   555 | loss: 2.5427599
MixupTrain:  epoch  0, batch   556 | loss: 1.9349979
MixupTrain:  epoch  0, batch   557 | loss: 2.3269796
MixupTrain:  epoch  0, batch   558 | loss: 2.4816093
MixupTrain:  epoch  0, batch   559 | loss: 2.5637975
MixupTrain:  epoch  0, batch   560 | loss: 2.5650418
MixupTrain:  epoch  0, batch   561 | loss: 2.5073614
MixupTrain:  epoch  0, batch   562 | loss: 2.0465720
MixupTrain:  epoch  0, batch   563 | loss: 2.1383739
MixupTrain:  epoch  0, batch   564 | loss: 2.3417194
MixupTrain:  epoch  0, batch   565 | loss: 2.8553324
MixupTrain:  epoch  0, batch   566 | loss: 2.5459895
MixupTrain:  epoch  0, batch   567 | loss: 2.3811131
MixupTrain:  epoch  0, batch   568 | loss: 2.5509531
MixupTrain:  epoch  0, batch   569 | loss: 2.7621679
MixupTrain:  epoch  0, batch   570 | loss: 2.5425277
MixupTrain:  epoch  0, batch   571 | loss: 2.3778529
MixupTrain:  epoch  0, batch   572 | loss: 2.1251459
MixupTrain:  epoch  0, batch   573 | loss: 2.5151803
MixupTrain:  epoch  0, batch   574 | loss: 2.3186193
MixupTrain:  epoch  0, batch   575 | loss: 2.9041958
MixupTrain:  epoch  0, batch   576 | loss: 2.0721619
MixupTrain:  epoch  0, batch   577 | loss: 2.3873110
MixupTrain:  epoch  0, batch   578 | loss: 2.2063227
MixupTrain:  epoch  0, batch   579 | loss: 2.6913047
MixupTrain:  epoch  0, batch   580 | loss: 2.2602577
MixupTrain:  epoch  0, batch   581 | loss: 2.2426515
MixupTrain:  epoch  0, batch   582 | loss: 2.5728462
MixupTrain:  epoch  0, batch   583 | loss: 2.4106030
MixupTrain:  epoch  0, batch   584 | loss: 2.2389126
MixupTrain:  epoch  0, batch   585 | loss: 2.0651364
MixupTrain:  epoch  0, batch   586 | loss: 2.3234456
MixupTrain:  epoch  0, batch   587 | loss: 2.2998936
MixupTrain:  epoch  0, batch   588 | loss: 2.3460207
MixupTrain:  epoch  0, batch   589 | loss: 2.6182904
MixupTrain:  epoch  0, batch   590 | loss: 2.4648046
MixupTrain:  epoch  0, batch   591 | loss: 2.4100106
MixupTrain:  epoch  0, batch   592 | loss: 2.9557242
MixupTrain:  epoch  0, batch   593 | loss: 2.3897412
MixupTrain:  epoch  0, batch   594 | loss: 2.5279446
MixupTrain:  epoch  0, batch   595 | loss: 2.3562813
MixupTrain:  epoch  0, batch   596 | loss: 2.1946607
MixupTrain:  epoch  0, batch   597 | loss: 2.1832180
MixupTrain:  epoch  0, batch   598 | loss: 2.3431554
MixupTrain:  epoch  0, batch   599 | loss: 2.4598308
MixupTrain:  epoch  0, batch   600 | loss: 2.6151061
MixupTrain:  epoch  0, batch   601 | loss: 2.5569766
MixupTrain:  epoch  0, batch   602 | loss: 2.6031260
MixupTrain:  epoch  0, batch   603 | loss: 2.2002873
MixupTrain:  epoch  0, batch   604 | loss: 2.5140121
MixupTrain:  epoch  0, batch   605 | loss: 2.5563202
MixupTrain:  epoch  0, batch   606 | loss: 2.2227349
MixupTrain:  epoch  0, batch   607 | loss: 2.0185471
MixupTrain:  epoch  0, batch   608 | loss: 2.7331538
MixupTrain:  epoch  0, batch   609 | loss: 2.3997722
MixupTrain:  epoch  0, batch   610 | loss: 2.1194775
MixupTrain:  epoch  0, batch   611 | loss: 2.2750242
MixupTrain:  epoch  0, batch   612 | loss: 2.1043696
MixupTrain:  epoch  0, batch   613 | loss: 2.2765620
MixupTrain:  epoch  0, batch   614 | loss: 2.8340092
MixupTrain:  epoch  0, batch   615 | loss: 2.2480886
MixupTrain:  epoch  0, batch   616 | loss: 2.4913406
MixupTrain:  epoch  0, batch   617 | loss: 2.5285015
MixupTrain:  epoch  0, batch   618 | loss: 2.5091448
MixupTrain:  epoch  0, batch   619 | loss: 2.3385811
MixupTrain:  epoch  0, batch   620 | loss: 2.5042925
MixupTrain:  epoch  0, batch   621 | loss: 2.7139950
MixupTrain:  epoch  0, batch   622 | loss: 2.5322032
MixupTrain:  epoch  0, batch   623 | loss: 2.7598770
MixupTrain:  epoch  0, batch   624 | loss: 2.5007730
MixupTrain:  epoch  0, batch   625 | loss: 2.3130250
MixupTrain:  epoch  0, batch   626 | loss: 2.3673899
MixupTrain:  epoch  0, batch   627 | loss: 2.7295158
MixupTrain:  epoch  0, batch   628 | loss: 2.1791327
MixupTrain:  epoch  0, batch   629 | loss: 2.5481067
MixupTrain:  epoch  0, batch   630 | loss: 2.3537714
MixupTrain:  epoch  0, batch   631 | loss: 2.7318063
MixupTrain:  epoch  0, batch   632 | loss: 2.3800325
MixupTrain:  epoch  0, batch   633 | loss: 2.3216596
MixupTrain:  epoch  0, batch   634 | loss: 2.4201820
MixupTrain:  epoch  0, batch   635 | loss: 2.7122335
MixupTrain:  epoch  0, batch   636 | loss: 2.3639979
MixupTrain:  epoch  0, batch   637 | loss: 2.2790205
MixupTrain:  epoch  0, batch   638 | loss: 2.2903287
MixupTrain:  epoch  0, batch   639 | loss: 2.3619285
MixupTrain:  epoch  0, batch   640 | loss: 2.3589263
MixupTrain:  epoch  0, batch   641 | loss: 2.2922816
MixupTrain:  epoch  0, batch   642 | loss: 2.4897828
MixupTrain:  epoch  0, batch   643 | loss: 2.3424590
MixupTrain:  epoch  0, batch   644 | loss: 2.2893047
MixupTrain:  epoch  0, batch   645 | loss: 2.6322591
MixupTrain:  epoch  0, batch   646 | loss: 2.9660759
MixupTrain:  epoch  0, batch   647 | loss: 2.0403342
MixupTrain:  epoch  0, batch   648 | loss: 2.4779396
MixupTrain:  epoch  0, batch   649 | loss: 2.7534430
MixupTrain:  epoch  0, batch   650 | loss: 2.6942766
MixupTrain:  epoch  0, batch   651 | loss: 2.4385715
MixupTrain:  epoch  0, batch   652 | loss: 2.1660395
MixupTrain:  epoch  0, batch   653 | loss: 2.1551230
MixupTrain:  epoch  0, batch   654 | loss: 2.9261744
MixupTrain:  epoch  0, batch   655 | loss: 2.2166505
MixupTrain:  epoch  0, batch   656 | loss: 2.6275949
MixupTrain:  epoch  0, batch   657 | loss: 2.3596659
MixupTrain:  epoch  0, batch   658 | loss: 2.0449362
MixupTrain:  epoch  0, batch   659 | loss: 2.5314827
MixupTrain:  epoch  0, batch   660 | loss: 2.4414692
MixupTrain:  epoch  0, batch   661 | loss: 2.5177283
MixupTrain:  epoch  0, batch   662 | loss: 2.4737163
MixupTrain:  epoch  0, batch   663 | loss: 2.2067821
MixupTrain:  epoch  0, batch   664 | loss: 2.1929722
MixupTrain:  epoch  0, batch   665 | loss: 2.3082476
MixupTrain:  epoch  0, batch   666 | loss: 2.5663934
MixupTrain:  epoch  0, batch   667 | loss: 2.3228676
MixupTrain:  epoch  0, batch   668 | loss: 2.7174444
MixupTrain:  epoch  0, batch   669 | loss: 2.3752794
MixupTrain:  epoch  0, batch   670 | loss: 2.3529420
MixupTrain:  epoch  0, batch   671 | loss: 2.4179025
MixupTrain:  epoch  0, batch   672 | loss: 2.5686450
MixupTrain:  epoch  0, batch   673 | loss: 2.0469561
MixupTrain:  epoch  0, batch   674 | loss: 2.4682641
MixupTrain:  epoch  0, batch   675 | loss: 2.3618872
MixupTrain:  epoch  0, batch   676 | loss: 2.1634119
MixupTrain:  epoch  0, batch   677 | loss: 2.6133394
MixupTrain:  epoch  0, batch   678 | loss: 2.3358088
MixupTrain:  epoch  0, batch   679 | loss: 2.4866199
MixupTrain:  epoch  0, batch   680 | loss: 2.5932305
MixupTrain:  epoch  0, batch   681 | loss: 2.2807255
MixupTrain:  epoch  0, batch   682 | loss: 2.5230780
MixupTrain:  epoch  0, batch   683 | loss: 2.3877187
MixupTrain:  epoch  0, batch   684 | loss: 2.5272350
MixupTrain:  epoch  0, batch   685 | loss: 2.2474284
MixupTrain:  epoch  0, batch   686 | loss: 2.0131359
MixupTrain:  epoch  0, batch   687 | loss: 2.2705231
MixupTrain:  epoch  0, batch   688 | loss: 2.4109936
MixupTrain:  epoch  0, batch   689 | loss: 2.3018832
MixupTrain:  epoch  0, batch   690 | loss: 2.2822766
MixupTrain:  epoch  0, batch   691 | loss: 2.6611938
MixupTrain:  epoch  0, batch   692 | loss: 2.2976549
MixupTrain:  epoch  0, batch   693 | loss: 2.5524559
MixupTrain:  epoch  0, batch   694 | loss: 2.1722474
MixupTrain:  epoch  0, batch   695 | loss: 2.7728887
MixupTrain:  epoch  0, batch   696 | loss: 2.3986566
MixupTrain:  epoch  0, batch   697 | loss: 2.4532948
MixupTrain:  epoch  0, batch   698 | loss: 2.4469485
MixupTrain:  epoch  0, batch   699 | loss: 2.4907353
MixupTrain:  epoch  0, batch   700 | loss: 2.2547975
MixupTrain:  epoch  0, batch   701 | loss: 2.3123822
MixupTrain:  epoch  0, batch   702 | loss: 1.9965851
MixupTrain:  epoch  0, batch   703 | loss: 2.9721191
MixupTrain:  epoch  0, batch   704 | loss: 2.3274894
MixupTrain:  epoch  0, batch   705 | loss: 2.7710235
MixupTrain:  epoch  0, batch   706 | loss: 2.3816233
MixupTrain:  epoch  0, batch   707 | loss: 2.2213533
MixupTrain:  epoch  0, batch   708 | loss: 2.0967560
MixupTrain:  epoch  0, batch   709 | loss: 2.4981968
MixupTrain:  epoch  0, batch   710 | loss: 2.4805582
MixupTrain:  epoch  0, batch   711 | loss: 2.4133863
MixupTrain:  epoch  0, batch   712 | loss: 2.2685499
MixupTrain:  epoch  0, batch   713 | loss: 2.2556753
MixupTrain:  epoch  0, batch   714 | loss: 2.5847893
MixupTrain:  epoch  0, batch   715 | loss: 2.3951080
MixupTrain:  epoch  0, batch   716 | loss: 2.6490526
MixupTrain:  epoch  0, batch   717 | loss: 2.4186172
MixupTrain:  epoch  0, batch   718 | loss: 2.2138078
MixupTrain:  epoch  0, batch   719 | loss: 2.1717472
MixupTrain:  epoch  0, batch   720 | loss: 2.1325693
MixupTrain:  epoch  0, batch   721 | loss: 2.7350245
MixupTrain:  epoch  0, batch   722 | loss: 2.4901352
MixupTrain:  epoch  0, batch   723 | loss: 2.1504130
MixupTrain:  epoch  0, batch   724 | loss: 2.4352829
MixupTrain:  epoch  0, batch   725 | loss: 2.7106595
MixupTrain:  epoch  0, batch   726 | loss: 2.0858166
MixupTrain:  epoch  0, batch   727 | loss: 2.0526013
MixupTrain:  epoch  0, batch   728 | loss: 2.7696414
MixupTrain:  epoch  0, batch   729 | loss: 2.2918205
MixupTrain:  epoch  0, batch   730 | loss: 2.7520652
MixupTrain:  epoch  0, batch   731 | loss: 2.5089526
MixupTrain:  epoch  0, batch   732 | loss: 2.6171918
MixupTrain:  epoch  0, batch   733 | loss: 2.7299607
MixupTrain:  epoch  0, batch   734 | loss: 2.3208280
MixupTrain:  epoch  0, batch   735 | loss: 2.7399507
MixupTrain:  epoch  0, batch   736 | loss: 2.8062329
MixupTrain:  epoch  0, batch   737 | loss: 2.0721197
MixupTrain:  epoch  0, batch   738 | loss: 1.8881118
MixupTrain:  epoch  0, batch   739 | loss: 2.3196723
MixupTrain:  epoch  0, batch   740 | loss: 2.4762218
MixupTrain:  epoch  0, batch   741 | loss: 2.3317800
MixupTrain:  epoch  0, batch   742 | loss: 2.1631112
MixupTrain:  epoch  0, batch   743 | loss: 2.4840274
MixupTrain:  epoch  0, batch   744 | loss: 2.4841866
MixupTrain:  epoch  0, batch   745 | loss: 2.4929812
MixupTrain:  epoch  0, batch   746 | loss: 2.3789358
MixupTrain:  epoch  0, batch   747 | loss: 2.4211020
MixupTrain:  epoch  0, batch   748 | loss: 2.6417184
MixupTrain:  epoch  0, batch   749 | loss: 2.1999629
MixupTrain:  epoch  0, batch   750 | loss: 2.4118736
MixupTrain:  epoch  0, batch   751 | loss: 2.4441495
MixupTrain:  epoch  0, batch   752 | loss: 2.5268583
MixupTrain:  epoch  0, batch   753 | loss: 2.1375203
MixupTrain:  epoch  0, batch   754 | loss: 2.8317502
MixupTrain:  epoch  0, batch   755 | loss: 2.1386161
MixupTrain:  epoch  0, batch   756 | loss: 2.4720907
MixupTrain:  epoch  0, batch   757 | loss: 3.0756340
MixupTrain:  epoch  0, batch   758 | loss: 2.4011106
MixupTrain:  epoch  0, batch   759 | loss: 2.1810606
MixupTrain:  epoch  0, batch   760 | loss: 2.3300693
MixupTrain:  epoch  0, batch   761 | loss: 2.3930969
MixupTrain:  epoch  0, batch   762 | loss: 2.4622684
MixupTrain:  epoch  0, batch   763 | loss: 1.9069237
MixupTrain:  epoch  0, batch   764 | loss: 2.5504739
MixupTrain:  epoch  0, batch   765 | loss: 2.3650801
MixupTrain:  epoch  0, batch   766 | loss: 2.6958203
MixupTrain:  epoch  0, batch   767 | loss: 2.3431847
MixupTrain:  epoch  0, batch   768 | loss: 2.2687092
MixupTrain:  epoch  0, batch   769 | loss: 2.7353427
MixupTrain:  epoch  0, batch   770 | loss: 2.2889078
MixupTrain:  epoch  0, batch   771 | loss: 2.5254910
MixupTrain:  epoch  0, batch   772 | loss: 2.6744380
MixupTrain:  epoch  0, batch   773 | loss: 2.4296689
MixupTrain:  epoch  0, batch   774 | loss: 2.4375875
MixupTrain:  epoch  0, batch   775 | loss: 2.1030991
MixupTrain:  epoch  0, batch   776 | loss: 2.0930545
MixupTrain:  epoch  0, batch   777 | loss: 2.5791039
MixupTrain:  epoch  0, batch   778 | loss: 2.3540330
MixupTrain:  epoch  0, batch   779 | loss: 1.9349437
MixupTrain:  epoch  0, batch   780 | loss: 2.8090763
MixupTrain:  epoch  0, batch   781 | loss: 2.6924767
MixupTrain:  epoch  0, batch   782 | loss: 2.5145354
MixupTrain:  epoch  0, batch   783 | loss: 2.4206386
MixupTrain:  epoch  0, batch   784 | loss: 2.7585282
MixupTrain:  epoch  0, batch   785 | loss: 2.5140882
MixupTrain:  epoch  0, batch   786 | loss: 2.0546031
MixupTrain:  epoch  0, batch   787 | loss: 2.0055480
MixupTrain:  epoch  0, batch   788 | loss: 2.4365854
MixupTrain:  epoch  0, batch   789 | loss: 2.6611867
MixupTrain:  epoch  0, batch   790 | loss: 2.1142454
MixupTrain:  epoch  0, batch   791 | loss: 2.6868587
MixupTrain:  epoch  0, batch   792 | loss: 2.4433601
MixupTrain:  epoch  0, batch   793 | loss: 2.3132291
MixupTrain:  epoch  0, batch   794 | loss: 2.1387677
MixupTrain:  epoch  0, batch   795 | loss: 2.8564715
MixupTrain:  epoch  0, batch   796 | loss: 2.4538767
MixupTrain:  epoch  0, batch   797 | loss: 2.6339421
MixupTrain:  epoch  0, batch   798 | loss: 2.3551686
MixupTrain:  epoch  0, batch   799 | loss: 2.3828292
MixupTrain:  epoch  0, batch   800 | loss: 2.1931434
MixupTrain:  epoch  0, batch   801 | loss: 2.3929462
MixupTrain:  epoch  0, batch   802 | loss: 2.3244181
MixupTrain:  epoch  0, batch   803 | loss: 2.4465442
MixupTrain:  epoch  0, batch   804 | loss: 2.2417784
MixupTrain:  epoch  0, batch   805 | loss: 2.3538833
MixupTrain:  epoch  0, batch   806 | loss: 2.5522060
MixupTrain:  epoch  0, batch   807 | loss: 2.2225130
MixupTrain:  epoch  0, batch   808 | loss: 2.7213211
MixupTrain:  epoch  0, batch   809 | loss: 2.2643304
MixupTrain:  epoch  0, batch   810 | loss: 2.0864964
MixupTrain:  epoch  0, batch   811 | loss: 2.2114034
MixupTrain:  epoch  0, batch   812 | loss: 2.3949289
MixupTrain:  epoch  0, batch   813 | loss: 2.5391164
MixupTrain:  epoch  0, batch   814 | loss: 2.2676299
MixupTrain:  epoch  0, batch   815 | loss: 2.3091834
MixupTrain:  epoch  0, batch   816 | loss: 2.4881468
MixupTrain:  epoch  0, batch   817 | loss: 2.1237938
MixupTrain:  epoch  0, batch   818 | loss: 2.3577271
MixupTrain:  epoch  0, batch   819 | loss: 2.2936175
MixupTrain:  epoch  0, batch   820 | loss: 2.5031033
MixupTrain:  epoch  0, batch   821 | loss: 2.4375460
MixupTrain:  epoch  0, batch   822 | loss: 2.2619834
MixupTrain:  epoch  0, batch   823 | loss: 2.2297416
MixupTrain:  epoch  0, batch   824 | loss: 2.2292857
MixupTrain:  epoch  0, batch   825 | loss: 2.1974688
MixupTrain:  epoch  0, batch   826 | loss: 3.1471703
MixupTrain:  epoch  0, batch   827 | loss: 2.3371441
MixupTrain:  epoch  0, batch   828 | loss: 2.7223580
MixupTrain:  epoch  0, batch   829 | loss: 2.0855408
MixupTrain:  epoch  0, batch   830 | loss: 2.2654805
MixupTrain:  epoch  0, batch   831 | loss: 2.4727335
MixupTrain:  epoch  0, batch   832 | loss: 2.3400698
MixupTrain:  epoch  0, batch   833 | loss: 2.6152365
MixupTrain:  epoch  0, batch   834 | loss: 2.1091268
MixupTrain:  epoch  0, batch   835 | loss: 2.1574759
MixupTrain:  epoch  0, batch   836 | loss: 2.4900291
MixupTrain:  epoch  0, batch   837 | loss: 2.4097047
MixupTrain:  epoch  0, batch   838 | loss: 1.8716391
MixupTrain:  epoch  0, batch   839 | loss: 2.3640065
MixupTrain:  epoch  0, batch   840 | loss: 2.3741117
MixupTrain:  epoch  0, batch   841 | loss: 2.0920472
MixupTrain:  epoch  0, batch   842 | loss: 2.6632056
MixupTrain:  epoch  0, batch   843 | loss: 2.5474274
MixupTrain:  epoch  0, batch   844 | loss: 2.1642706
MixupTrain:  epoch  0, batch   845 | loss: 2.5448065
MixupTrain:  epoch  0, batch   846 | loss: 2.1619797
MixupTrain:  epoch  0, batch   847 | loss: 2.3798900
MixupTrain:  epoch  0, batch   848 | loss: 2.6047392
MixupTrain:  epoch  0, batch   849 | loss: 2.4417720
MixupTrain:  epoch  0, batch   850 | loss: 2.2145262
MixupTrain:  epoch  0, batch   851 | loss: 2.1665912
MixupTrain:  epoch  0, batch   852 | loss: 2.3828835
MixupTrain:  epoch  0, batch   853 | loss: 2.3445067
MixupTrain:  epoch  0, batch   854 | loss: 2.4169118
MixupTrain:  epoch  0, batch   855 | loss: 2.3219609
MixupTrain:  epoch  0, batch   856 | loss: 2.1456985
MixupTrain:  epoch  0, batch   857 | loss: 2.4135511
MixupTrain:  epoch  0, batch   858 | loss: 2.0227227
MixupTrain:  epoch  0, batch   859 | loss: 2.4079902
MixupTrain:  epoch  0, batch   860 | loss: 2.6179721
MixupTrain:  epoch  0, batch   861 | loss: 2.3208160
MixupTrain:  epoch  0, batch   862 | loss: 2.3849070
MixupTrain:  epoch  0, batch   863 | loss: 2.6471241
MixupTrain:  epoch  0, batch   864 | loss: 2.5868132
MixupTrain:  epoch  0, batch   865 | loss: 2.3870623
MixupTrain:  epoch  0, batch   866 | loss: 2.3126249
MixupTrain:  epoch  0, batch   867 | loss: 2.6547043
MixupTrain:  epoch  0, batch   868 | loss: 2.4554701
MixupTrain:  epoch  0, batch   869 | loss: 2.1850364
MixupTrain:  epoch  0, batch   870 | loss: 2.7401738
MixupTrain:  epoch  0, batch   871 | loss: 2.3351631
MixupTrain:  epoch  0, batch   872 | loss: 2.5774331
MixupTrain:  epoch  0, batch   873 | loss: 2.5531721
MixupTrain:  epoch  0, batch   874 | loss: 2.3554294
MixupTrain:  epoch  0, batch   875 | loss: 2.4548366
MixupTrain:  epoch  0, batch   876 | loss: 2.1154444
MixupTrain:  epoch  0, batch   877 | loss: 2.6130512
MixupTrain:  epoch  0, batch   878 | loss: 2.2826085
MixupTrain:  epoch  0, batch   879 | loss: 2.3634834
MixupTrain:  epoch  0, batch   880 | loss: 2.2970629
MixupTrain:  epoch  0, batch   881 | loss: 2.3164051
MixupTrain:  epoch  0, batch   882 | loss: 2.1479220
MixupTrain:  epoch  0, batch   883 | loss: 2.1463847
MixupTrain:  epoch  0, batch   884 | loss: 2.5677950
MixupTrain:  epoch  0, batch   885 | loss: 2.7418225
MixupTrain:  epoch  0, batch   886 | loss: 2.1285653
MixupTrain:  epoch  0, batch   887 | loss: 2.1538215
MixupTrain:  epoch  0, batch   888 | loss: 2.2919803
MixupTrain:  epoch  0, batch   889 | loss: 2.4751952
MixupTrain:  epoch  0, batch   890 | loss: 2.2879617
MixupTrain:  epoch  0, batch   891 | loss: 2.5178692
MixupTrain:  epoch  0, batch   892 | loss: 2.8096294
MixupTrain:  epoch  0, batch   893 | loss: 2.5736396
MixupTrain:  epoch  0, batch   894 | loss: 2.1661177
MixupTrain:  epoch  0, batch   895 | loss: 2.6863399
MixupTrain:  epoch  0, batch   896 | loss: 2.5810041
MixupTrain:  epoch  0, batch   897 | loss: 2.3627729
MixupTrain:  epoch  0, batch   898 | loss: 2.5201650
MixupTrain:  epoch  0, batch   899 | loss: 2.3868990
MixupTrain:  epoch  0, batch   900 | loss: 2.3968105
MixupTrain:  epoch  0, batch   901 | loss: 2.6867747
MixupTrain:  epoch  0, batch   902 | loss: 2.5395436
MixupTrain:  epoch  0, batch   903 | loss: 2.5932612
MixupTrain:  epoch  0, batch   904 | loss: 2.0778630
MixupTrain:  epoch  0, batch   905 | loss: 2.6816583
MixupTrain:  epoch  0, batch   906 | loss: 2.4389544
MixupTrain:  epoch  0, batch   907 | loss: 2.3219323
MixupTrain:  epoch  0, batch   908 | loss: 2.3789387
MixupTrain:  epoch  0, batch   909 | loss: 2.4289486
MixupTrain:  epoch  0, batch   910 | loss: 2.3084660
MixupTrain:  epoch  0, batch   911 | loss: 2.4787145
MixupTrain:  epoch  0, batch   912 | loss: 2.6043675
MixupTrain:  epoch  0, batch   913 | loss: 2.5370262
MixupTrain:  epoch  0, batch   914 | loss: 2.2904837
MixupTrain:  epoch  0, batch   915 | loss: 2.3378291
MixupTrain:  epoch  0, batch   916 | loss: 2.3260336
MixupTrain:  epoch  0, batch   917 | loss: 2.7451780
MixupTrain:  epoch  0, batch   918 | loss: 2.2417068
MixupTrain:  epoch  0, batch   919 | loss: 2.1232173
MixupTrain:  epoch  0, batch   920 | loss: 2.2985125
MixupTrain:  epoch  0, batch   921 | loss: 2.6271071
MixupTrain:  epoch  0, batch   922 | loss: 2.2307014
MixupTrain:  epoch  0, batch   923 | loss: 2.2576001
MixupTrain:  epoch  0, batch   924 | loss: 2.2468538
MixupTrain:  epoch  0, batch   925 | loss: 2.4144447
MixupTrain:  epoch  0, batch   926 | loss: 2.5406110
MixupTrain:  epoch  0, batch   927 | loss: 2.1470504
MixupTrain:  epoch  0, batch   928 | loss: 2.4600468
MixupTrain:  epoch  0, batch   929 | loss: 2.4168973
MixupTrain:  epoch  0, batch   930 | loss: 1.9870951
MixupTrain:  epoch  0, batch   931 | loss: 2.4115341
MixupTrain:  epoch  0, batch   932 | loss: 2.1472249
MixupTrain:  epoch  0, batch   933 | loss: 2.2921329
MixupTrain:  epoch  0, batch   934 | loss: 2.4413416
MixupTrain:  epoch  0, batch   935 | loss: 2.5141757
MixupTrain:  epoch  0, batch   936 | loss: 2.4244180
MixupTrain:  epoch  0, batch   937 | loss: 2.4518523
MixupTrain:  epoch  0, batch   938 | loss: 2.2778788
MixupTrain:  epoch  0, batch   939 | loss: 2.4483972
MixupTrain:  epoch  0, batch   940 | loss: 2.4350910
MixupTrain:  epoch  0, batch   941 | loss: 2.4193988
MixupTrain:  epoch  0, batch   942 | loss: 2.3043678
MixupTrain:  epoch  0, batch   943 | loss: 2.3777533
MixupTrain:  epoch  0, batch   944 | loss: 2.4931724
MixupTrain:  epoch  0, batch   945 | loss: 2.6778378
MixupTrain:  epoch  0, batch   946 | loss: 2.5922484
MixupTrain:  epoch  0, batch   947 | loss: 2.5348830
MixupTrain:  epoch  0, batch   948 | loss: 2.5756378
MixupTrain:  epoch  0, batch   949 | loss: 2.5351932
MixupTrain:  epoch  0, batch   950 | loss: 2.2919493
MixupTrain:  epoch  0, batch   951 | loss: 2.0653524
MixupTrain:  epoch  0, batch   952 | loss: 2.1695623
MixupTrain:  epoch  0, batch   953 | loss: 2.3008826
MixupTrain:  epoch  0, batch   954 | loss: 2.5172286
MixupTrain:  epoch  0, batch   955 | loss: 2.7469120
MixupTrain:  epoch  0, batch   956 | loss: 2.3781552
MixupTrain:  epoch  0, batch   957 | loss: 2.4644716
MixupTrain:  epoch  0, batch   958 | loss: 2.8084300
MixupTrain:  epoch  0, batch   959 | loss: 2.1500971
MixupTrain:  epoch  0, batch   960 | loss: 2.3278980
MixupTrain:  epoch  0, batch   961 | loss: 2.2913437
MixupTrain:  epoch  0, batch   962 | loss: 2.4122229
MixupTrain:  epoch  0, batch   963 | loss: 2.7006316
MixupTrain:  epoch  0, batch   964 | loss: 2.2664933
MixupTrain:  epoch  0, batch   965 | loss: 2.5124593
MixupTrain:  epoch  0, batch   966 | loss: 2.2567236
MixupTrain:  epoch  0, batch   967 | loss: 2.4883080
MixupTrain:  epoch  0, batch   968 | loss: 2.4930203
MixupTrain:  epoch  0, batch   969 | loss: 2.5180652
MixupTrain:  epoch  0, batch   970 | loss: 2.2069597
MixupTrain:  epoch  0, batch   971 | loss: 2.1653304
MixupTrain:  epoch  0, batch   972 | loss: 2.4757624
MixupTrain:  epoch  0, batch   973 | loss: 2.4192550
MixupTrain:  epoch  0, batch   974 | loss: 2.1605663
MixupTrain:  epoch  0, batch   975 | loss: 2.4523036
MixupTrain:  epoch  0, batch   976 | loss: 2.9738765
MixupTrain:  epoch  0, batch   977 | loss: 2.5655236
MixupTrain:  epoch  0, batch   978 | loss: 2.6545906
MixupTrain:  epoch  0, batch   979 | loss: 2.9225945
MixupTrain:  epoch  0, batch   980 | loss: 2.5934918
MixupTrain:  epoch  0, batch   981 | loss: 2.5587034
MixupTrain:  epoch  0, batch   982 | loss: 2.6393366
MixupTrain:  epoch  0, batch   983 | loss: 2.5262337
MixupTrain:  epoch  0, batch   984 | loss: 2.8635097
MixupTrain:  epoch  0, batch   985 | loss: 2.4855299
MixupTrain:  epoch  0, batch   986 | loss: 2.7015419
MixupTrain:  epoch  0, batch   987 | loss: 2.5846553
MixupTrain:  epoch  0, batch   988 | loss: 2.2856216
MixupTrain:  epoch  0, batch   989 | loss: 2.5846553
MixupTrain:  epoch  0, batch   990 | loss: 2.5423987
MixupTrain:  epoch  0, batch   991 | loss: 2.2801294
MixupTrain:  epoch  0, batch   992 | loss: 2.4831557
MixupTrain:  epoch  0, batch   993 | loss: 2.3034935
MixupTrain:  epoch  0, batch   994 | loss: 3.0216589
MixupTrain:  epoch  0, batch   995 | loss: 2.3636348
MixupTrain:  epoch  0, batch   996 | loss: 2.6187096
MixupTrain:  epoch  0, batch   997 | loss: 2.1553988
MixupTrain:  epoch  0, batch   998 | loss: 2.5021348
MixupTrain:  epoch  0, batch   999 | loss: 2.2326417
MixupTrain:  epoch  0, batch  1000 | loss: 2.4440870
MixupTrain:  epoch  0, batch  1001 | loss: 2.4246874
MixupTrain:  epoch  0, batch  1002 | loss: 2.7178411
MixupTrain:  epoch  0, batch  1003 | loss: 2.6205826
MixupTrain:  epoch  0, batch  1004 | loss: 2.8440809
MixupTrain:  epoch  0, batch  1005 | loss: 2.4829316
MixupTrain:  epoch  0, batch  1006 | loss: 2.8452444
MixupTrain:  epoch  0, batch  1007 | loss: 2.3972158
MixupTrain:  epoch  0, batch  1008 | loss: 2.2421353
MixupTrain:  epoch  0, batch  1009 | loss: 2.0800607
MixupTrain:  epoch  0, batch  1010 | loss: 2.6394985
MixupTrain:  epoch  0, batch  1011 | loss: 2.8513694
MixupTrain:  epoch  0, batch  1012 | loss: 2.3936648
MixupTrain:  epoch  0, batch  1013 | loss: 2.5557609
MixupTrain:  epoch  0, batch  1014 | loss: 2.1980152
MixupTrain:  epoch  0, batch  1015 | loss: 2.1434050
MixupTrain:  epoch  0, batch  1016 | loss: 2.5352173
MixupTrain:  epoch  0, batch  1017 | loss: 2.3240469
MixupTrain:  epoch  0, batch  1018 | loss: 1.9272920
MixupTrain:  epoch  0, batch  1019 | loss: 2.5104535
MixupTrain:  epoch  0, batch  1020 | loss: 2.6023183
MixupTrain:  epoch  0, batch  1021 | loss: 2.0686560
MixupTrain:  epoch  0, batch  1022 | loss: 2.7082148
MixupTrain:  epoch  0, batch  1023 | loss: 2.1707902
MixupTrain:  epoch  0, batch  1024 | loss: 2.4605093
MixupTrain:  epoch  0, batch  1025 | loss: 2.2538514
MixupTrain:  epoch  0, batch  1026 | loss: 2.3839514
MixupTrain:  epoch  0, batch  1027 | loss: 2.3063664
MixupTrain:  epoch  0, batch  1028 | loss: 2.5393493
MixupTrain:  epoch  0, batch  1029 | loss: 2.2167788
MixupTrain:  epoch  0, batch  1030 | loss: 2.6540368
MixupTrain:  epoch  0, batch  1031 | loss: 2.4022045
MixupTrain:  epoch  0, batch  1032 | loss: 2.3365221
MixupTrain:  epoch  0, batch  1033 | loss: 2.1858356
MixupTrain:  epoch  0, batch  1034 | loss: 2.3385170
MixupTrain:  epoch  0, batch  1035 | loss: 2.3996904
MixupTrain:  epoch  0, batch  1036 | loss: 2.6959376
MixupTrain:  epoch  0, batch  1037 | loss: 2.6757207
MixupTrain:  epoch  0, batch  1038 | loss: 2.7591715
MixupTrain:  epoch  0, batch  1039 | loss: 2.3350003
MixupTrain:  epoch  0, batch  1040 | loss: 2.1228471
MixupTrain:  epoch  0, batch  1041 | loss: 2.6080968
MixupTrain:  epoch  0, batch  1042 | loss: 2.2325346
MixupTrain:  epoch  0, batch  1043 | loss: 2.2622278
MixupTrain:  epoch  0, batch  1044 | loss: 2.8470085
MixupTrain:  epoch  0, batch  1045 | loss: 2.6435411
MixupTrain:  epoch  0, batch  1046 | loss: 2.6247599
MixupTrain:  epoch  0, batch  1047 | loss: 2.1158433
MixupTrain:  epoch  0, batch  1048 | loss: 2.3892698
MixupTrain:  epoch  0, batch  1049 | loss: 2.4589117
MixupTrain:  epoch  0, batch  1050 | loss: 2.1115441
MixupTrain:  epoch  0, batch  1051 | loss: 2.3568740
MixupTrain:  epoch  0, batch  1052 | loss: 2.4374552
MixupTrain:  epoch  0, batch  1053 | loss: 2.3502946
MixupTrain:  epoch  0, batch  1054 | loss: 2.3658264
MixupTrain:  epoch  0, batch  1055 | loss: 2.3982852
MixupTrain:  epoch  0, batch  1056 | loss: 2.5914240
MixupTrain:  epoch  0, batch  1057 | loss: 1.9533521
MixupTrain:  epoch  0, batch  1058 | loss: 2.1712670
MixupTrain:  epoch  0, batch  1059 | loss: 2.6897433
MixupTrain:  epoch  0, batch  1060 | loss: 2.5678666
MixupTrain:  epoch  0, batch  1061 | loss: 2.6534076
MixupTrain:  epoch  0, batch  1062 | loss: 1.9620913
MixupTrain:  epoch  0, batch  1063 | loss: 2.3608778
MixupTrain:  epoch  0, batch  1064 | loss: 2.3623178
MixupTrain:  epoch  0, batch  1065 | loss: 2.6020381
MixupTrain:  epoch  0, batch  1066 | loss: 2.1275144
MixupTrain:  epoch  0, batch  1067 | loss: 2.4034362
MixupTrain:  epoch  0, batch  1068 | loss: 2.2015409
MixupTrain:  epoch  0, batch  1069 | loss: 2.3609324
MixupTrain:  epoch  0, batch  1070 | loss: 1.9545164
MixupTrain:  epoch  0, batch  1071 | loss: 2.6151571
MixupTrain:  epoch  0, batch  1072 | loss: 2.5650797
MixupTrain:  epoch  0, batch  1073 | loss: 2.3380880
MixupTrain:  epoch  0, batch  1074 | loss: 2.2401752
MixupTrain:  epoch  0, batch  1075 | loss: 2.3618500
MixupTrain:  epoch  0, batch  1076 | loss: 2.1198578
MixupTrain:  epoch  0, batch  1077 | loss: 2.2644224
MixupTrain:  epoch  0, batch  1078 | loss: 2.5710487
MixupTrain:  epoch  0, batch  1079 | loss: 2.4496768
MixupTrain:  epoch  0, batch  1080 | loss: 2.4850578
MixupTrain:  epoch  0, batch  1081 | loss: 2.2736530
MixupTrain:  epoch  0, batch  1082 | loss: 2.7464283
MixupTrain:  epoch  0, batch  1083 | loss: 2.0943778
MixupTrain:  epoch  0, batch  1084 | loss: 2.3675160
MixupTrain:  epoch  0, batch  1085 | loss: 2.1913533
MixupTrain:  epoch  0, batch  1086 | loss: 2.3467355
MixupTrain:  epoch  0, batch  1087 | loss: 2.4895911
MixupTrain:  epoch  0, batch  1088 | loss: 2.2259007
MixupTrain:  epoch  0, batch  1089 | loss: 2.4459782
MixupTrain:  epoch  0, batch  1090 | loss: 2.0343959
MixupTrain:  epoch  0, batch  1091 | loss: 2.6774626
MixupTrain:  epoch  0, batch  1092 | loss: 2.5071955
MixupTrain:  epoch  0, batch  1093 | loss: 2.3699756
MixupTrain:  epoch  0, batch  1094 | loss: 2.6838884
MixupTrain:  epoch  0, batch  1095 | loss: 2.5214524
MixupTrain:  epoch  0, batch  1096 | loss: 2.1789005
MixupTrain:  epoch  0, batch  1097 | loss: 2.3874750
MixupTrain:  epoch  0, batch  1098 | loss: 2.2918854
MixupTrain:  epoch  0, batch  1099 | loss: 2.3627646
MixupTrain:  epoch  0, batch  1100 | loss: 2.3840928
MixupTrain:  epoch  0, batch  1101 | loss: 2.3512540
MixupTrain:  epoch  0, batch  1102 | loss: 2.4378667
MixupTrain:  epoch  0, batch  1103 | loss: 2.2797878
MixupTrain:  epoch  0, batch  1104 | loss: 2.5155439
MixupTrain:  epoch  0, batch  1105 | loss: 2.3175101
MixupTrain:  epoch  0, batch  1106 | loss: 2.4028716
MixupTrain:  epoch  0, batch  1107 | loss: 2.1984346
MixupTrain:  epoch  0, batch  1108 | loss: 2.0832400
MixupTrain:  epoch  0, batch  1109 | loss: 2.3008771
MixupTrain:  epoch  0, batch  1110 | loss: 2.1960554
MixupTrain:  epoch  0, batch  1111 | loss: 2.5387995
MixupTrain:  epoch  0, batch  1112 | loss: 2.3801796
MixupTrain:  epoch  0, batch  1113 | loss: 1.9636177
MixupTrain:  epoch  0, batch  1114 | loss: 2.3389020
MixupTrain:  epoch  0, batch  1115 | loss: 2.0932887
MixupTrain:  epoch  0, batch  1116 | loss: 2.7003660
MixupTrain:  epoch  0, batch  1117 | loss: 2.2219315
MixupTrain:  epoch  0, batch  1118 | loss: 2.4945345
MixupTrain:  epoch  0, batch  1119 | loss: 2.8771498
MixupTrain:  epoch  0, batch  1120 | loss: 2.4890633
MixupTrain:  epoch  0, batch  1121 | loss: 2.2783194
MixupTrain:  epoch  0, batch  1122 | loss: 2.5284359
MixupTrain:  epoch  0, batch  1123 | loss: 2.6984196
MixupTrain:  epoch  0, batch  1124 | loss: 2.4225402
MixupTrain:  epoch  0, batch  1125 | loss: 2.3683615
MixupTrain:  epoch  0, batch  1126 | loss: 3.0120449
MixupTrain:  epoch  0, batch  1127 | loss: 2.0770428
MixupTrain:  epoch  0, batch  1128 | loss: 2.8763394
MixupTrain:  epoch  0, batch  1129 | loss: 2.7086625
MixupTrain:  epoch  0, batch  1130 | loss: 2.2373283
MixupTrain:  epoch  0, batch  1131 | loss: 2.9148588
MixupTrain:  epoch  0, batch  1132 | loss: 2.6940806
MixupTrain:  epoch  0, batch  1133 | loss: 2.3472335
MixupTrain:  epoch  0, batch  1134 | loss: 2.2492900
MixupTrain:  epoch  0, batch  1135 | loss: 2.2468038
MixupTrain:  epoch  0, batch  1136 | loss: 2.3518710
MixupTrain:  epoch  0, batch  1137 | loss: 2.3140936
MixupTrain:  epoch  0, batch  1138 | loss: 2.1836672
MixupTrain:  epoch  0, batch  1139 | loss: 2.4853535
MixupTrain:  epoch  0, batch  1140 | loss: 2.3988745
MixupTrain:  epoch  0, batch  1141 | loss: 2.0380177
MixupTrain:  epoch  0, batch  1142 | loss: 2.2984281
MixupTrain:  epoch  0, batch  1143 | loss: 2.2146485
MixupTrain:  epoch  0, batch  1144 | loss: 2.5923994
MixupTrain:  epoch  0, batch  1145 | loss: 2.0603795
MixupTrain:  epoch  0, batch  1146 | loss: 2.3771968
MixupTrain:  epoch  0, batch  1147 | loss: 2.2919755
MixupTrain:  epoch  0, batch  1148 | loss: 2.1076713
MixupTrain:  epoch  0, batch  1149 | loss: 2.4016829
MixupTrain:  epoch  0, batch  1150 | loss: 2.1828160
MixupTrain:  epoch  0, batch  1151 | loss: 2.2534454
MixupTrain:  epoch  0, batch  1152 | loss: 2.5272050
MixupTrain:  epoch  0, batch  1153 | loss: 2.1894274
MixupTrain:  epoch  0, batch  1154 | loss: 2.7491555
MixupTrain:  epoch  0, batch  1155 | loss: 2.3815203
MixupTrain:  epoch  0, batch  1156 | loss: 2.2895470
MixupTrain:  epoch  0, batch  1157 | loss: 2.5792944
MixupTrain:  epoch  0, batch  1158 | loss: 2.7420993
MixupTrain:  epoch  0, batch  1159 | loss: 2.2395475
MixupTrain:  epoch  0, batch  1160 | loss: 2.6662703
MixupTrain:  epoch  0, batch  1161 | loss: 2.6605401
MixupTrain:  epoch  0, batch  1162 | loss: 2.3351007
MixupTrain:  epoch  0, batch  1163 | loss: 2.2052026
MixupTrain:  epoch  0, batch  1164 | loss: 2.1800661
MixupTrain:  epoch  0, batch  1165 | loss: 2.6257758
MixupTrain:  epoch  0, batch  1166 | loss: 2.1518066
MixupTrain:  epoch  0, batch  1167 | loss: 2.4722812
MixupTrain:  epoch  0, batch  1168 | loss: 2.5610092
MixupTrain:  epoch  0, batch  1169 | loss: 2.2464411
MixupTrain:  epoch  0, batch  1170 | loss: 2.3303697
MixupTrain:  epoch  0, batch  1171 | loss: 2.4999232
MixupTrain:  epoch  0, batch  1172 | loss: 2.6753283
MixupTrain:  epoch  0, batch  1173 | loss: 2.2863517
MixupTrain:  epoch  0, batch  1174 | loss: 2.5986640
MixupTrain:  epoch  0, batch  1175 | loss: 2.3857784
MixupTrain:  epoch  0, batch  1176 | loss: 2.3793404
MixupTrain:  epoch  0, batch  1177 | loss: 2.6962934
MixupTrain:  epoch  0, batch  1178 | loss: 2.2132814
MixupTrain:  epoch  0, batch  1179 | loss: 2.7183979
MixupTrain:  epoch  0, batch  1180 | loss: 2.2689390
MixupTrain:  epoch  0, batch  1181 | loss: 2.4285240
MixupTrain:  epoch  0, batch  1182 | loss: 2.4029961
MixupTrain:  epoch  0, batch  1183 | loss: 2.5007629
MixupTrain:  epoch  0, batch  1184 | loss: 2.5185089
MixupTrain:  epoch  0, batch  1185 | loss: 2.3376417
MixupTrain:  epoch  0, batch  1186 | loss: 2.4347942
MixupTrain:  epoch  0, batch  1187 | loss: 2.5990272
MixupTrain:  epoch  0, batch  1188 | loss: 2.0629866
MixupTrain:  epoch  0, batch  1189 | loss: 2.6744435
MixupTrain:  epoch  0, batch  1190 | loss: 2.0586085
MixupTrain:  epoch  0, batch  1191 | loss: 2.6111941
MixupTrain:  epoch  0, batch  1192 | loss: 2.5836883
MixupTrain:  epoch  0, batch  1193 | loss: 2.6375375
MixupTrain:  epoch  0, batch  1194 | loss: 1.9918764
MixupTrain:  epoch  0, batch  1195 | loss: 2.0158629
MixupTrain:  epoch  0, batch  1196 | loss: 2.1858020
MixupTrain:  epoch  0, batch  1197 | loss: 2.3066432
MixupTrain:  epoch  0, batch  1198 | loss: 2.3752456
MixupTrain:  epoch  0, batch  1199 | loss: 2.2686934
MixupTrain:  epoch  0, batch  1200 | loss: 2.0477610
MixupTrain:  epoch  0, batch  1201 | loss: 2.4899874
MixupTrain:  epoch  0, batch  1202 | loss: 2.6390917
MixupTrain:  epoch  0, batch  1203 | loss: 2.3770578
MixupTrain:  epoch  0, batch  1204 | loss: 2.3960032
MixupTrain:  epoch  0, batch  1205 | loss: 2.8339643
MixupTrain:  epoch  0, batch  1206 | loss: 2.4685905
MixupTrain:  epoch  0, batch  1207 | loss: 2.4898713
MixupTrain:  epoch  0, batch  1208 | loss: 2.4514985
MixupTrain:  epoch  0, batch  1209 | loss: 2.2764080
MixupTrain:  epoch  0, batch  1210 | loss: 2.5256662
MixupTrain:  epoch  0, batch  1211 | loss: 2.7150040
MixupTrain:  epoch  0, batch  1212 | loss: 2.4438047
MixupTrain:  epoch  0, batch  1213 | loss: 2.5130665
MixupTrain:  epoch  0, batch  1214 | loss: 2.5638201
MixupTrain:  epoch  0, batch  1215 | loss: 2.5376306
MixupTrain:  epoch  0, batch  1216 | loss: 2.6060712
MixupTrain:  epoch  0, batch  1217 | loss: 2.3504901
MixupTrain:  epoch  0, batch  1218 | loss: 2.3225629
MixupTrain:  epoch  0, batch  1219 | loss: 2.2423148
MixupTrain:  epoch  0, batch  1220 | loss: 2.3284569
MixupTrain:  epoch  0, batch  1221 | loss: 2.4862251
MixupTrain:  epoch  0, batch  1222 | loss: 2.4956722
MixupTrain:  epoch  0, batch  1223 | loss: 2.4036617
MixupTrain:  epoch  0, batch  1224 | loss: 2.4749594
MixupTrain:  epoch  0, batch  1225 | loss: 2.2788594
MixupTrain:  epoch  0, batch  1226 | loss: 2.2097621
MixupTrain:  epoch  0, batch  1227 | loss: 2.6682019
MixupTrain:  epoch  0, batch  1228 | loss: 2.0046506
MixupTrain:  epoch  0, batch  1229 | loss: 2.0179818
MixupTrain:  epoch  0, batch  1230 | loss: 2.3344483
MixupTrain:  epoch  0, batch  1231 | loss: 2.1841514
MixupTrain:  epoch  0, batch  1232 | loss: 2.5349479
MixupTrain:  epoch  0, batch  1233 | loss: 2.3105748
MixupTrain:  epoch  0, batch  1234 | loss: 2.1979709
MixupTrain:  epoch  0, batch  1235 | loss: 2.7415261
MixupTrain:  epoch  0, batch  1236 | loss: 2.4053080
MixupTrain:  epoch  0, batch  1237 | loss: 2.5758660
MixupTrain:  epoch  0, batch  1238 | loss: 2.1731422
MixupTrain:  epoch  0, batch  1239 | loss: 2.2507043
MixupTrain:  epoch  0, batch  1240 | loss: 2.4695246
MixupTrain:  epoch  0, batch  1241 | loss: 2.4418757
MixupTrain:  epoch  0, batch  1242 | loss: 2.4466398
MixupTrain:  epoch  0, batch  1243 | loss: 2.1562557
MixupTrain:  epoch  0, batch  1244 | loss: 2.2525384
MixupTrain:  epoch  0, batch  1245 | loss: 2.2563601
MixupTrain:  epoch  0, batch  1246 | loss: 2.6838286
MixupTrain:  epoch  0, batch  1247 | loss: 2.2664566
MixupTrain:  epoch  0, batch  1248 | loss: 2.1904421
MixupTrain:  epoch  0, batch  1249 | loss: 2.1500373
MixupTrain:  epoch  0, batch  1250 | loss: 2.8009176
MixupTrain:  epoch  0, batch  1251 | loss: 2.2098029
MixupTrain:  epoch  0, batch  1252 | loss: 2.1823235
MixupTrain:  epoch  0, batch  1253 | loss: 2.5144250
MixupTrain:  epoch  0, batch  1254 | loss: 2.2332568
MixupTrain:  epoch  0, batch  1255 | loss: 2.0562530
MixupTrain:  epoch  0, batch  1256 | loss: 2.1742163
MixupTrain:  epoch  0, batch  1257 | loss: 2.3366768
MixupTrain:  epoch  0, batch  1258 | loss: 2.5577416
MixupTrain:  epoch  0, batch  1259 | loss: 2.2836528
MixupTrain:  epoch  0, batch  1260 | loss: 2.8905163
MixupTrain:  epoch  0, batch  1261 | loss: 2.3341429
MixupTrain:  epoch  0, batch  1262 | loss: 2.4761150
MixupTrain:  epoch  0, batch  1263 | loss: 2.6930857
MixupTrain:  epoch  0, batch  1264 | loss: 2.0379012
MixupTrain:  epoch  0, batch  1265 | loss: 2.7149312
MixupTrain:  epoch  0, batch  1266 | loss: 2.0788817
MixupTrain:  epoch  0, batch  1267 | loss: 2.1956306
MixupTrain:  epoch  0, batch  1268 | loss: 2.8401444
MixupTrain:  epoch  0, batch  1269 | loss: 2.6980658
MixupTrain:  epoch  0, batch  1270 | loss: 2.6523609
MixupTrain:  epoch  0, batch  1271 | loss: 2.6530602
MixupTrain:  epoch  0, batch  1272 | loss: 2.9366465
MixupTrain:  epoch  0, batch  1273 | loss: 2.4974689
MixupTrain:  epoch  0, batch  1274 | loss: 2.1091018
MixupTrain:  epoch  0, batch  1275 | loss: 2.5451379
MixupTrain:  epoch  0, batch  1276 | loss: 2.3877032
MixupTrain:  epoch  0, batch  1277 | loss: 2.7894058
MixupTrain:  epoch  0, batch  1278 | loss: 2.2983341
MixupTrain:  epoch  0, batch  1279 | loss: 2.4956925
MixupTrain:  epoch  0, batch  1280 | loss: 2.2703314
MixupTrain:  epoch  0, batch  1281 | loss: 2.4774463
MixupTrain:  epoch  0, batch  1282 | loss: 2.8700881
MixupTrain:  epoch  0, batch  1283 | loss: 2.4694190
MixupTrain:  epoch  0, batch  1284 | loss: 2.2344670
MixupTrain:  epoch  0, batch  1285 | loss: 2.0451207
MixupTrain:  epoch  0, batch  1286 | loss: 2.5656884
MixupTrain:  epoch  0, batch  1287 | loss: 2.2975965
MixupTrain:  epoch  0, batch  1288 | loss: 2.1952820
MixupTrain:  epoch  0, batch  1289 | loss: 2.0837786
MixupTrain:  epoch  0, batch  1290 | loss: 2.5276842
MixupTrain:  epoch  0, batch  1291 | loss: 2.4802468
MixupTrain:  epoch  0, batch  1292 | loss: 2.1288493
MixupTrain:  epoch  0, batch  1293 | loss: 2.1140029
MixupTrain:  epoch  0, batch  1294 | loss: 2.4379134
MixupTrain:  epoch  0, batch  1295 | loss: 2.3377969
MixupTrain:  epoch  0, batch  1296 | loss: 2.4078834
MixupTrain:  epoch  0, batch  1297 | loss: 2.1151729
MixupTrain:  epoch  0, batch  1298 | loss: 2.5381389
MixupTrain:  epoch  0, batch  1299 | loss: 2.3778129
MixupTrain:  epoch  0, batch  1300 | loss: 2.5390809
MixupTrain:  epoch  0, batch  1301 | loss: 2.1092026
MixupTrain:  epoch  0, batch  1302 | loss: 2.2222686
MixupTrain:  epoch  0, batch  1303 | loss: 2.6236422
MixupTrain:  epoch  0, batch  1304 | loss: 2.4537864
MixupTrain:  epoch  0, batch  1305 | loss: 2.7755532
MixupTrain:  epoch  0, batch  1306 | loss: 2.8950198
MixupTrain:  epoch  0, batch  1307 | loss: 2.7329402
MixupTrain:  epoch  0, batch  1308 | loss: 2.3497372
MixupTrain:  epoch  0, batch  1309 | loss: 2.4183304
MixupTrain:  epoch  0, batch  1310 | loss: 2.1806071
MixupTrain:  epoch  0, batch  1311 | loss: 2.2082367
MixupTrain:  epoch  0, batch  1312 | loss: 2.2109320
MixupTrain:  epoch  0, batch  1313 | loss: 2.7012391
MixupTrain:  epoch  0, batch  1314 | loss: 2.0812511
MixupTrain:  epoch  0, batch  1315 | loss: 2.7248580
MixupTrain:  epoch  0, batch  1316 | loss: 2.6297073
MixupTrain:  epoch  0, batch  1317 | loss: 2.3640709
MixupTrain:  epoch  0, batch  1318 | loss: 2.6706557
MixupTrain:  epoch  0, batch  1319 | loss: 2.4950843
MixupTrain:  epoch  0, batch  1320 | loss: 2.4878314
MixupTrain:  epoch  0, batch  1321 | loss: 2.1882503
MixupTrain:  epoch  0, batch  1322 | loss: 2.5083189
MixupTrain:  epoch  0, batch  1323 | loss: 2.5315599
MixupTrain:  epoch  0, batch  1324 | loss: 2.3811252
MixupTrain:  epoch  0, batch  1325 | loss: 2.8660426
MixupTrain:  epoch  0, batch  1326 | loss: 2.4191823
MixupTrain:  epoch  0, batch  1327 | loss: 2.5712361
MixupTrain:  epoch  0, batch  1328 | loss: 2.2737598
MixupTrain:  epoch  0, batch  1329 | loss: 2.2563357
MixupTrain:  epoch  0, batch  1330 | loss: 2.2501473
MixupTrain:  epoch  0, batch  1331 | loss: 2.2908223
MixupTrain:  epoch  0, batch  1332 | loss: 2.2894530
MixupTrain:  epoch  0, batch  1333 | loss: 2.1477966
MixupTrain:  epoch  0, batch  1334 | loss: 2.2636573
MixupTrain:  epoch  0, batch  1335 | loss: 2.3850851
MixupTrain:  epoch  0, batch  1336 | loss: 2.1465890
MixupTrain:  epoch  0, batch  1337 | loss: 2.5787218
MixupTrain:  epoch  0, batch  1338 | loss: 2.2628975
MixupTrain:  epoch  0, batch  1339 | loss: 2.3574600
MixupTrain:  epoch  0, batch  1340 | loss: 2.3811169
MixupTrain:  epoch  0, batch  1341 | loss: 2.1200626
MixupTrain:  epoch  0, batch  1342 | loss: 2.2395964
MixupTrain:  epoch  0, batch  1343 | loss: 2.7274337
MixupTrain:  epoch  0, batch  1344 | loss: 2.4237654
MixupTrain:  epoch  0, batch  1345 | loss: 2.5174541
MixupTrain:  epoch  0, batch  1346 | loss: 2.4037914
MixupTrain:  epoch  0, batch  1347 | loss: 2.3015938
MixupTrain:  epoch  0, batch  1348 | loss: 2.4769855
MixupTrain:  epoch  0, batch  1349 | loss: 2.4088054
MixupTrain:  epoch  0, batch  1350 | loss: 2.3611774
MixupTrain:  epoch  0, batch  1351 | loss: 2.4750202
MixupTrain:  epoch  0, batch  1352 | loss: 2.2570515
MixupTrain:  epoch  0, batch  1353 | loss: 2.6965499
MixupTrain:  epoch  0, batch  1354 | loss: 2.3885674
MixupTrain:  epoch  0, batch  1355 | loss: 2.2632253
MixupTrain:  epoch  0, batch  1356 | loss: 2.2376945
MixupTrain:  epoch  0, batch  1357 | loss: 2.3142052
MixupTrain:  epoch  0, batch  1358 | loss: 2.2577863
MixupTrain:  epoch  0, batch  1359 | loss: 2.0837688
MixupTrain:  epoch  0, batch  1360 | loss: 2.4165866
MixupTrain:  epoch  0, batch  1361 | loss: 2.5474970
MixupTrain:  epoch  0, batch  1362 | loss: 2.7246432
MixupTrain:  epoch  0, batch  1363 | loss: 2.2974281
MixupTrain:  epoch  0, batch  1364 | loss: 2.2422090
MixupTrain:  epoch  0, batch  1365 | loss: 2.7469940
MixupTrain:  epoch  0, batch  1366 | loss: 2.4154973
MixupTrain:  epoch  0, batch  1367 | loss: 2.5314193
MixupTrain:  epoch  0, batch  1368 | loss: 2.1752558
MixupTrain:  epoch  0, batch  1369 | loss: 2.3436506
MixupTrain:  epoch  0, batch  1370 | loss: 2.3144531
MixupTrain:  epoch  0, batch  1371 | loss: 2.5883770
MixupTrain:  epoch  0, batch  1372 | loss: 2.4752033
MixupTrain:  epoch  0, batch  1373 | loss: 2.4411407
MixupTrain:  epoch  0, batch  1374 | loss: 2.2205424
MixupTrain:  epoch  0, batch  1375 | loss: 2.5238993
MixupTrain:  epoch  0, batch  1376 | loss: 2.3967667
MixupTrain:  epoch  0, batch  1377 | loss: 2.3723609
MixupTrain:  epoch  0, batch  1378 | loss: 2.4753289
MixupTrain:  epoch  0, batch  1379 | loss: 2.2767904
MixupTrain:  epoch  0, batch  1380 | loss: 2.2289119
MixupTrain:  epoch  0, batch  1381 | loss: 2.6633737
MixupTrain:  epoch  0, batch  1382 | loss: 1.9860187
MixupTrain:  epoch  0, batch  1383 | loss: 2.5493970
MixupTrain:  epoch  0, batch  1384 | loss: 2.2196627
MixupTrain:  epoch  0, batch  1385 | loss: 2.8596582
MixupTrain:  epoch  0, batch  1386 | loss: 2.3798771
MixupTrain:  epoch  0, batch  1387 | loss: 2.6785932
MixupTrain:  epoch  0, batch  1388 | loss: 2.1256504
MixupTrain:  epoch  0, batch  1389 | loss: 2.3708234
MixupTrain:  epoch  0, batch  1390 | loss: 2.4653964
MixupTrain:  epoch  0, batch  1391 | loss: 2.2242332
MixupTrain:  epoch  0, batch  1392 | loss: 2.4939294
MixupTrain:  epoch  0, batch  1393 | loss: 2.5889835
MixupTrain:  epoch  0, batch  1394 | loss: 2.5792961
MixupTrain:  epoch  0, batch  1395 | loss: 2.8491187
MixupTrain:  epoch  0, batch  1396 | loss: 2.3048358
MixupTrain:  epoch  0, batch  1397 | loss: 2.2268014
MixupTrain:  epoch  0, batch  1398 | loss: 2.3465691
MixupTrain:  epoch  0, batch  1399 | loss: 2.3757765
MixupTrain:  epoch  0, batch  1400 | loss: 2.4929473
MixupTrain:  epoch  0, batch  1401 | loss: 2.5287023
MixupTrain:  epoch  0, batch  1402 | loss: 2.5360181
MixupTrain:  epoch  0, batch  1403 | loss: 2.5507786
MixupTrain:  epoch  0, batch  1404 | loss: 2.3982728
MixupTrain:  epoch  0, batch  1405 | loss: 2.2735796
MixupTrain:  epoch  0, batch  1406 | loss: 2.3712621
MixupTrain:  epoch  0, batch  1407 | loss: 2.5206342
MixupTrain:  epoch  0, batch  1408 | loss: 2.7031112
MixupTrain:  epoch  0, batch  1409 | loss: 2.4800625
MixupTrain:  epoch  0, batch  1410 | loss: 2.5579624
MixupTrain:  epoch  0, batch  1411 | loss: 2.5414453
MixupTrain:  epoch  0, batch  1412 | loss: 2.3482671
MixupTrain:  epoch  0, batch  1413 | loss: 2.3814669
MixupTrain:  epoch  0, batch  1414 | loss: 2.3550279
MixupTrain:  epoch  0, batch  1415 | loss: 2.4659758
MixupTrain:  epoch  0, batch  1416 | loss: 2.4556603
MixupTrain:  epoch  0, batch  1417 | loss: 2.4288294
MixupTrain:  epoch  0, batch  1418 | loss: 2.3867099
MixupTrain:  epoch  0, batch  1419 | loss: 2.2272522
MixupTrain:  epoch  0, batch  1420 | loss: 2.6025503
MixupTrain:  epoch  0, batch  1421 | loss: 2.3648231
MixupTrain:  epoch  0, batch  1422 | loss: 2.4708822
MixupTrain:  epoch  0, batch  1423 | loss: 2.3008623
MixupTrain:  epoch  0, batch  1424 | loss: 2.6378560
MixupTrain:  epoch  0, batch  1425 | loss: 2.5456023
MixupTrain:  epoch  0, batch  1426 | loss: 2.4016383
MixupTrain:  epoch  0, batch  1427 | loss: 2.4465590
MixupTrain:  epoch  0, batch  1428 | loss: 2.3647845
MixupTrain:  epoch  0, batch  1429 | loss: 3.0459533
MixupTrain:  epoch  0, batch  1430 | loss: 2.6656833
MixupTrain:  epoch  0, batch  1431 | loss: 2.4684706
MixupTrain:  epoch  0, batch  1432 | loss: 2.3062212
MixupTrain:  epoch  0, batch  1433 | loss: 2.6463594
MixupTrain:  epoch  0, batch  1434 | loss: 2.5330999
MixupTrain:  epoch  0, batch  1435 | loss: 2.4682548
MixupTrain:  epoch  0, batch  1436 | loss: 2.4327815
MixupTrain:  epoch  0, batch  1437 | loss: 2.1933706
MixupTrain:  epoch  0, batch  1438 | loss: 2.5769694
MixupTrain:  epoch  0, batch  1439 | loss: 2.2044907
MixupTrain:  epoch  0, batch  1440 | loss: 2.6496050
MixupTrain:  epoch  0, batch  1441 | loss: 2.1661458
MixupTrain:  epoch  0, batch  1442 | loss: 2.2578924
MixupTrain:  epoch  0, batch  1443 | loss: 2.1650124
MixupTrain:  epoch  0, batch  1444 | loss: 2.4236841
MixupTrain:  epoch  0, batch  1445 | loss: 2.6111000
MixupTrain:  epoch  0, batch  1446 | loss: 1.9905803
MixupTrain:  epoch  0, batch  1447 | loss: 2.1404777
MixupTrain:  epoch  0, batch  1448 | loss: 2.1110339
MixupTrain:  epoch  0, batch  1449 | loss: 2.5759344
MixupTrain:  epoch  0, batch  1450 | loss: 2.3127294
MixupTrain:  epoch  0, batch  1451 | loss: 2.6531129
MixupTrain:  epoch  0, batch  1452 | loss: 2.1276617
MixupTrain:  epoch  0, batch  1453 | loss: 2.5828097
MixupTrain:  epoch  0, batch  1454 | loss: 2.7918975
MixupTrain:  epoch  0, batch  1455 | loss: 2.5767875
MixupTrain:  epoch  0, batch  1456 | loss: 2.2878695
MixupTrain:  epoch  0, batch  1457 | loss: 2.9211340
MixupTrain:  epoch  0, batch  1458 | loss: 2.3096311
MixupTrain:  epoch  0, batch  1459 | loss: 2.3889303
MixupTrain:  epoch  0, batch  1460 | loss: 2.2993157
MixupTrain:  epoch  0, batch  1461 | loss: 2.1807947
MixupTrain:  epoch  0, batch  1462 | loss: 2.1730967
MixupTrain:  epoch  0, batch  1463 | loss: 2.5702965
MixupTrain:  epoch  0, batch  1464 | loss: 2.3622234
MixupTrain:  epoch  0, batch  1465 | loss: 2.5787129
MixupTrain:  epoch  0, batch  1466 | loss: 2.4477067
MixupTrain:  epoch  0, batch  1467 | loss: 2.5158689
MixupTrain:  epoch  0, batch  1468 | loss: 2.4878831
MixupTrain:  epoch  0, batch  1469 | loss: 2.5959029
MixupTrain:  epoch  0, batch  1470 | loss: 2.7336240
MixupTrain:  epoch  0, batch  1471 | loss: 2.5157328
MixupTrain:  epoch  0, batch  1472 | loss: 2.1505246
MixupTrain:  epoch  0, batch  1473 | loss: 2.4334459
MixupTrain:  epoch  0, batch  1474 | loss: 2.3301046
MixupTrain:  epoch  0, batch  1475 | loss: 2.2079949
MixupTrain:  epoch  0, batch  1476 | loss: 2.3475959
MixupTrain:  epoch  0, batch  1477 | loss: 2.0372715
MixupTrain:  epoch  0, batch  1478 | loss: 2.5507283
MixupTrain:  epoch  0, batch  1479 | loss: 2.3661628
MixupTrain:  epoch  0, batch  1480 | loss: 2.1863012
MixupTrain:  epoch  0, batch  1481 | loss: 2.1959224
MixupTrain:  epoch  0, batch  1482 | loss: 2.5866911
MixupTrain:  epoch  0, batch  1483 | loss: 2.2472186
MixupTrain:  epoch  0, batch  1484 | loss: 2.4176733
MixupTrain:  epoch  0, batch  1485 | loss: 2.2828560
MixupTrain:  epoch  0, batch  1486 | loss: 2.4602795
MixupTrain:  epoch  0, batch  1487 | loss: 2.4635639
MixupTrain:  epoch  0, batch  1488 | loss: 2.4834201
MixupTrain:  epoch  0, batch  1489 | loss: 2.1248415
MixupTrain:  epoch  0, batch  1490 | loss: 2.5188241
MixupTrain:  epoch  0, batch  1491 | loss: 2.1484084
MixupTrain:  epoch  0, batch  1492 | loss: 2.6586781
MixupTrain:  epoch  0, batch  1493 | loss: 2.5197561
MixupTrain:  epoch  0, batch  1494 | loss: 2.5662756
MixupTrain:  epoch  0, batch  1495 | loss: 2.5886979
MixupTrain:  epoch  0, batch  1496 | loss: 2.6241665
MixupTrain:  epoch  0, batch  1497 | loss: 2.5055995
MixupTrain:  epoch  0, batch  1498 | loss: 2.5178380
MixupTrain:  epoch  0, batch  1499 | loss: 1.9502265
MixupTrain:  epoch  0, batch  1500 | loss: 2.7462838
MixupTrain:  epoch  0, batch  1501 | loss: 2.8321538
MixupTrain:  epoch  0, batch  1502 | loss: 2.2627225
MixupTrain:  epoch  0, batch  1503 | loss: 2.4567676
MixupTrain:  epoch  0, batch  1504 | loss: 1.8018340
MixupTrain:  epoch  0, batch  1505 | loss: 2.7699265
MixupTrain:  epoch  0, batch  1506 | loss: 2.5264380
MixupTrain:  epoch  0, batch  1507 | loss: 2.3213351
MixupTrain:  epoch  0, batch  1508 | loss: 2.1227133
MixupTrain:  epoch  0, batch  1509 | loss: 2.5130525
MixupTrain:  epoch  0, batch  1510 | loss: 2.1635969
MixupTrain:  epoch  0, batch  1511 | loss: 2.1836967
MixupTrain:  epoch  0, batch  1512 | loss: 2.4177315
MixupTrain:  epoch  0, batch  1513 | loss: 2.2008250
MixupTrain:  epoch  0, batch  1514 | loss: 2.4084218
MixupTrain:  epoch  0, batch  1515 | loss: 2.6341119
MixupTrain:  epoch  0, batch  1516 | loss: 2.4231415
MixupTrain:  epoch  0, batch  1517 | loss: 2.3313212
MixupTrain:  epoch  0, batch  1518 | loss: 1.9960204
MixupTrain:  epoch  0, batch  1519 | loss: 2.4611802
MixupTrain:  epoch  0, batch  1520 | loss: 2.4798479
MixupTrain:  epoch  0, batch  1521 | loss: 2.2823973
MixupTrain:  epoch  0, batch  1522 | loss: 2.1226773
MixupTrain:  epoch  0, batch  1523 | loss: 2.2505519
MixupTrain:  epoch  0, batch  1524 | loss: 2.2013822
MixupTrain:  epoch  0, batch  1525 | loss: 2.5327871
MixupTrain:  epoch  0, batch  1526 | loss: 2.7460670
MixupTrain:  epoch  0, batch  1527 | loss: 2.2818472
MixupTrain:  epoch  0, batch  1528 | loss: 2.4510012
MixupTrain:  epoch  0, batch  1529 | loss: 2.3060250
MixupTrain:  epoch  0, batch  1530 | loss: 2.6367106
MixupTrain:  epoch  0, batch  1531 | loss: 2.8333135
MixupTrain:  epoch  0, batch  1532 | loss: 2.7442870
MixupTrain:  epoch  0, batch  1533 | loss: 2.4896927
MixupTrain:  epoch  0, batch  1534 | loss: 2.1082344
MixupTrain:  epoch  0, batch  1535 | loss: 2.4581883
MixupTrain:  epoch  0, batch  1536 | loss: 2.5662827
MixupTrain:  epoch  0, batch  1537 | loss: 2.2545252
MixupTrain:  epoch  0, batch  1538 | loss: 2.2289197
MixupTrain:  epoch  0, batch  1539 | loss: 2.4837284
MixupTrain:  epoch  0, batch  1540 | loss: 2.5277047
MixupTrain:  epoch  0, batch  1541 | loss: 2.6270771
MixupTrain:  epoch  0, batch  1542 | loss: 2.0603852
MixupTrain:  epoch  0, batch  1543 | loss: 2.6970773
MixupTrain:  epoch  0, batch  1544 | loss: 2.5520091
MixupTrain:  epoch  0, batch  1545 | loss: 2.2449622
MixupTrain:  epoch  0, batch  1546 | loss: 2.4351928
MixupTrain:  epoch  0, batch  1547 | loss: 2.2180500
MixupTrain:  epoch  0, batch  1548 | loss: 2.6346660
MixupTrain:  epoch  0, batch  1549 | loss: 2.5880766
MixupTrain:  epoch  0, batch  1550 | loss: 2.2892368
MixupTrain:  epoch  0, batch  1551 | loss: 2.2313437
MixupTrain:  epoch  0, batch  1552 | loss: 2.5317438
MixupTrain:  epoch  0, batch  1553 | loss: 1.9581381
MixupTrain:  epoch  0, batch  1554 | loss: 1.7966881
MixupTrain:  epoch  0, batch  1555 | loss: 2.2199936
MixupTrain:  epoch  0, batch  1556 | loss: 2.6223998
MixupTrain:  epoch  0, batch  1557 | loss: 2.3313193
MixupTrain:  epoch  0, batch  1558 | loss: 2.5106859
MixupTrain:  epoch  0, batch  1559 | loss: 2.3956406
MixupTrain:  epoch  0, batch  1560 | loss: 2.2061412
MixupTrain:  epoch  0, batch  1561 | loss: 2.2420211
MixupTrain:  epoch  0, batch  1562 | loss: 2.2333283
MixupTrain:  epoch  0, batch  1563 | loss: 2.2805920
MixupTrain:  epoch  0, batch  1564 | loss: 2.2671838
MixupTrain:  epoch  0, batch  1565 | loss: 2.1770809
MixupTrain:  epoch  0, batch  1566 | loss: 2.7112284
MixupTrain:  epoch  0, batch  1567 | loss: 2.8864594
MixupTrain:  epoch  0, batch  1568 | loss: 2.2440012
MixupTrain:  epoch  0, batch  1569 | loss: 2.1249466
MixupTrain:  epoch  0, batch  1570 | loss: 2.6655324
MixupTrain:  epoch  0, batch  1571 | loss: 2.7494309
MixupTrain:  epoch  0, batch  1572 | loss: 2.2568295
MixupTrain:  epoch  0, batch  1573 | loss: 2.2626011
MixupTrain:  epoch  0, batch  1574 | loss: 2.2247348
MixupTrain:  epoch  0, batch  1575 | loss: 2.2221112
MixupTrain:  epoch  0, batch  1576 | loss: 2.4773703
MixupTrain:  epoch  0, batch  1577 | loss: 2.1841266
MixupTrain:  epoch  0, batch  1578 | loss: 2.2777786
MixupTrain:  epoch  0, batch  1579 | loss: 2.3610628
MixupTrain:  epoch  0, batch  1580 | loss: 2.3473876
MixupTrain:  epoch  0, batch  1581 | loss: 2.4547315
MixupTrain:  epoch  0, batch  1582 | loss: 2.4861789
MixupTrain:  epoch  0, batch  1583 | loss: 2.5994246
MixupTrain:  epoch  0, batch  1584 | loss: 2.8294396
MixupTrain:  epoch  0, batch  1585 | loss: 2.4193511
MixupTrain:  epoch  0, batch  1586 | loss: 2.5768218
MixupTrain:  epoch  0, batch  1587 | loss: 2.1187162
MixupTrain:  epoch  0, batch  1588 | loss: 2.6630507
MixupTrain:  epoch  0, batch  1589 | loss: 2.4191535
MixupTrain:  epoch  0, batch  1590 | loss: 2.5651212
MixupTrain:  epoch  0, batch  1591 | loss: 2.5262566
MixupTrain:  epoch  0, batch  1592 | loss: 2.1794291
MixupTrain:  epoch  0, batch  1593 | loss: 1.9890002
MixupTrain:  epoch  0, batch  1594 | loss: 2.0194991
MixupTrain:  epoch  0, batch  1595 | loss: 2.8298345
MixupTrain:  epoch  0, batch  1596 | loss: 2.3603821
MixupTrain:  epoch  0, batch  1597 | loss: 2.5982299
MixupTrain:  epoch  0, batch  1598 | loss: 2.4232817
MixupTrain:  epoch  0, batch  1599 | loss: 2.5845094
MixupTrain:  epoch  0, batch  1600 | loss: 2.0326030
MixupTrain:  epoch  0, batch  1601 | loss: 2.0764008
MixupTrain:  epoch  0, batch  1602 | loss: 2.1611662
MixupTrain:  epoch  0, batch  1603 | loss: 2.5498860
MixupTrain:  epoch  0, batch  1604 | loss: 2.2162306
MixupTrain:  epoch  0, batch  1605 | loss: 2.6389658
MixupTrain:  epoch  0, batch  1606 | loss: 2.2138510
MixupTrain:  epoch  0, batch  1607 | loss: 2.4655259
MixupTrain:  epoch  0, batch  1608 | loss: 2.1668262
MixupTrain:  epoch  0, batch  1609 | loss: 2.0321116
MixupTrain:  epoch  0, batch  1610 | loss: 2.2034326
MixupTrain:  epoch  0, batch  1611 | loss: 2.4377856
MixupTrain:  epoch  0, batch  1612 | loss: 1.9851198
MixupTrain:  epoch  0, batch  1613 | loss: 2.3173761
MixupTrain:  epoch  0, batch  1614 | loss: 2.5673401
MixupTrain:  epoch  0, batch  1615 | loss: 2.4526799
MixupTrain:  epoch  0, batch  1616 | loss: 2.7562032
MixupTrain:  epoch  0, batch  1617 | loss: 2.0949225
MixupTrain:  epoch  0, batch  1618 | loss: 2.5715041
MixupTrain:  epoch  0, batch  1619 | loss: 2.4414215
MixupTrain:  epoch  0, batch  1620 | loss: 2.5536418
MixupTrain:  epoch  0, batch  1621 | loss: 2.3510180
MixupTrain:  epoch  0, batch  1622 | loss: 2.2484720
MixupTrain:  epoch  0, batch  1623 | loss: 2.6888344
MixupTrain:  epoch  0, batch  1624 | loss: 2.1834676
MixupTrain:  epoch  0, batch  1625 | loss: 2.4128780
MixupTrain:  epoch  0, batch  1626 | loss: 2.4942544
MixupTrain:  epoch  0, batch  1627 | loss: 2.4195623
MixupTrain:  epoch  0, batch  1628 | loss: 2.3315654
MixupTrain:  epoch  0, batch  1629 | loss: 2.2940655
MixupTrain:  epoch  0, batch  1630 | loss: 2.4031768
MixupTrain:  epoch  0, batch  1631 | loss: 2.5725973
MixupTrain:  epoch  0, batch  1632 | loss: 2.6312830
MixupTrain:  epoch  0, batch  1633 | loss: 2.5857375
MixupTrain:  epoch  0, batch  1634 | loss: 2.5433474
MixupTrain:  epoch  0, batch  1635 | loss: 2.3883071
MixupTrain:  epoch  0, batch  1636 | loss: 2.3133907
MixupTrain:  epoch  0, batch  1637 | loss: 2.6609123
MixupTrain:  epoch  0, batch  1638 | loss: 2.3851664
MixupTrain:  epoch  0, batch  1639 | loss: 2.3625727
MixupTrain:  epoch  0, batch  1640 | loss: 2.4962969
MixupTrain:  epoch  0, batch  1641 | loss: 2.6687379
MixupTrain:  epoch  0, batch  1642 | loss: 2.4944944
MixupTrain:  epoch  0, batch  1643 | loss: 2.2043476
MixupTrain:  epoch  0, batch  1644 | loss: 2.2885284
MixupTrain:  epoch  0, batch  1645 | loss: 2.4695616
MixupTrain:  epoch  0, batch  1646 | loss: 2.1476479
MixupTrain:  epoch  0, batch  1647 | loss: 2.4751573
MixupTrain:  epoch  0, batch  1648 | loss: 2.6181149
MixupTrain:  epoch  0, batch  1649 | loss: 2.3856540
MixupTrain:  epoch  0, batch  1650 | loss: 2.4371200
MixupTrain:  epoch  0, batch  1651 | loss: 2.0796094
MixupTrain:  epoch  0, batch  1652 | loss: 2.1728234
MixupTrain:  epoch  0, batch  1653 | loss: 2.1077111
MixupTrain:  epoch  0, batch  1654 | loss: 2.5370331
MixupTrain:  epoch  0, batch  1655 | loss: 2.3950026
MixupTrain:  epoch  0, batch  1656 | loss: 2.6013427
MixupTrain:  epoch  0, batch  1657 | loss: 2.4499590
MixupTrain:  epoch  0, batch  1658 | loss: 2.2181895
MixupTrain:  epoch  0, batch  1659 | loss: 2.2681420
MixupTrain:  epoch  0, batch  1660 | loss: 2.6948154
MixupTrain:  epoch  0, batch  1661 | loss: 2.2887225
MixupTrain:  epoch  0, batch  1662 | loss: 2.7437024
MixupTrain:  epoch  0, batch  1663 | loss: 2.9726286
MixupTrain:  epoch  0, batch  1664 | loss: 2.4922938
MixupTrain:  epoch  0, batch  1665 | loss: 2.7543211
MixupTrain:  epoch  0, batch  1666 | loss: 2.9584806
MixupTrain:  epoch  0, batch  1667 | loss: 2.2850535
MixupTrain:  epoch  0, batch  1668 | loss: 2.8725185
MixupTrain:  epoch  0, batch  1669 | loss: 2.2842498
MixupTrain:  epoch  0, batch  1670 | loss: 2.5413997
MixupTrain:  epoch  0, batch  1671 | loss: 2.4542484
MixupTrain:  epoch  0, batch  1672 | loss: 2.4614823
MixupTrain:  epoch  0, batch  1673 | loss: 2.0674829
MixupTrain:  epoch  0, batch  1674 | loss: 2.5144210
MixupTrain:  epoch  0, batch  1675 | loss: 2.7952917
MixupTrain:  epoch  0, batch  1676 | loss: 2.2923007
MixupTrain:  epoch  0, batch  1677 | loss: 2.1948609
MixupTrain:  epoch  0, batch  1678 | loss: 2.5284681
MixupTrain:  epoch  0, batch  1679 | loss: 2.0843847
MixupTrain:  epoch  0, batch  1680 | loss: 2.7100348
MixupTrain:  epoch  0, batch  1681 | loss: 2.3959346
MixupTrain:  epoch  0, batch  1682 | loss: 3.1255682
MixupTrain:  epoch  0, batch  1683 | loss: 2.0746894
MixupTrain:  epoch  0, batch  1684 | loss: 2.4759505
MixupTrain:  epoch  0, batch  1685 | loss: 2.5234299
MixupTrain:  epoch  0, batch  1686 | loss: 2.6264114
MixupTrain:  epoch  0, batch  1687 | loss: 2.2525845
MixupTrain:  epoch  0, batch  1688 | loss: 2.2018366
MixupTrain:  epoch  0, batch  1689 | loss: 2.4718809
MixupTrain:  epoch  0, batch  1690 | loss: 2.2467618
MixupTrain:  epoch  0, batch  1691 | loss: 2.5032375
MixupTrain:  epoch  0, batch  1692 | loss: 2.4487929
MixupTrain:  epoch  0, batch  1693 | loss: 2.2166445
MixupTrain:  epoch  0, batch  1694 | loss: 2.6601253
MixupTrain:  epoch  0, batch  1695 | loss: 2.3621473
MixupTrain:  epoch  0, batch  1696 | loss: 2.6570764
MixupTrain:  epoch  0, batch  1697 | loss: 2.5886805
MixupTrain:  epoch  0, batch  1698 | loss: 2.4497836
MixupTrain:  epoch  0, batch  1699 | loss: 2.8674903
MixupTrain:  epoch  0, batch  1700 | loss: 2.1314399
MixupTrain:  epoch  0, batch  1701 | loss: 2.4011128
MixupTrain:  epoch  0, batch  1702 | loss: 2.2758837
MixupTrain:  epoch  0, batch  1703 | loss: 2.0092807
MixupTrain:  epoch  0, batch  1704 | loss: 2.5219657
MixupTrain:  epoch  0, batch  1705 | loss: 2.2776833
MixupTrain:  epoch  0, batch  1706 | loss: 2.5904632
MixupTrain:  epoch  0, batch  1707 | loss: 2.5726991
MixupTrain:  epoch  0, batch  1708 | loss: 2.5095851
MixupTrain:  epoch  0, batch  1709 | loss: 2.1351395
MixupTrain:  epoch  0, batch  1710 | loss: 2.4634843
MixupTrain:  epoch  0, batch  1711 | loss: 2.6102715
MixupTrain:  epoch  0, batch  1712 | loss: 3.0565577
MixupTrain:  epoch  0, batch  1713 | loss: 2.3519363
MixupTrain:  epoch  0, batch  1714 | loss: 2.3830733
MixupTrain:  epoch  0, batch  1715 | loss: 2.3731022
MixupTrain:  epoch  0, batch  1716 | loss: 2.5778470
MixupTrain:  epoch  0, batch  1717 | loss: 2.7049665
MixupTrain:  epoch  0, batch  1718 | loss: 2.4338918
MixupTrain:  epoch  0, batch  1719 | loss: 2.0722291
MixupTrain:  epoch  0, batch  1720 | loss: 2.2944388
MixupTrain:  epoch  0, batch  1721 | loss: 2.7016032
MixupTrain:  epoch  0, batch  1722 | loss: 2.1702592
MixupTrain:  epoch  0, batch  1723 | loss: 2.6304090
MixupTrain:  epoch  0, batch  1724 | loss: 2.8481927
MixupTrain:  epoch  0, batch  1725 | loss: 2.2821765
MixupTrain:  epoch  0, batch  1726 | loss: 2.4037573
MixupTrain:  epoch  0, batch  1727 | loss: 2.4784312
MixupTrain:  epoch  0, batch  1728 | loss: 2.5176392
MixupTrain:  epoch  0, batch  1729 | loss: 2.4686456
MixupTrain:  epoch  0, batch  1730 | loss: 2.3281026
MixupTrain:  epoch  0, batch  1731 | loss: 2.4398336
MixupTrain:  epoch  0, batch  1732 | loss: 2.3892140
MixupTrain:  epoch  0, batch  1733 | loss: 2.5442777
MixupTrain:  epoch  0, batch  1734 | loss: 2.4448671
MixupTrain:  epoch  0, batch  1735 | loss: 2.2864065
MixupTrain:  epoch  0, batch  1736 | loss: 1.9246449
MixupTrain:  epoch  0, batch  1737 | loss: 2.2178543
MixupTrain:  epoch  0, batch  1738 | loss: 2.6339569
MixupTrain:  epoch  0, batch  1739 | loss: 2.8062258
MixupTrain:  epoch  0, batch  1740 | loss: 2.2055373
MixupTrain:  epoch  0, batch  1741 | loss: 2.0874367
MixupTrain:  epoch  0, batch  1742 | loss: 2.1303904
MixupTrain:  epoch  0, batch  1743 | loss: 2.4937270
MixupTrain:  epoch  0, batch  1744 | loss: 2.1845603
MixupTrain:  epoch  0, batch  1745 | loss: 2.4565763
MixupTrain:  epoch  0, batch  1746 | loss: 2.5065193
MixupTrain:  epoch  0, batch  1747 | loss: 2.2038379
MixupTrain:  epoch  0, batch  1748 | loss: 2.8240118
MixupTrain:  epoch  0, batch  1749 | loss: 2.6028640
MixupTrain:  epoch  0, batch  1750 | loss: 2.5110624
MixupTrain:  epoch  0, batch  1751 | loss: 2.6808097
MixupTrain:  epoch  0, batch  1752 | loss: 2.6467214
MixupTrain:  epoch  0, batch  1753 | loss: 2.4090328
MixupTrain:  epoch  0, batch  1754 | loss: 2.1239777
MixupTrain:  epoch  0, batch  1755 | loss: 2.3576779
MixupTrain:  epoch  0, batch  1756 | loss: 2.4757791
MixupTrain:  epoch  0, batch  1757 | loss: 2.0652881
MixupTrain:  epoch  0, batch  1758 | loss: 2.6495757
MixupTrain:  epoch  0, batch  1759 | loss: 2.6469793
MixupTrain:  epoch  0, batch  1760 | loss: 2.6973476
MixupTrain:  epoch  0, batch  1761 | loss: 2.5689955
MixupTrain:  epoch  0, batch  1762 | loss: 2.3662481
MixupTrain:  epoch  0, batch  1763 | loss: 2.5161636
MixupTrain:  epoch  0, batch  1764 | loss: 2.7231185
MixupTrain:  epoch  0, batch  1765 | loss: 2.5021958
MixupTrain:  epoch  0, batch  1766 | loss: 2.3974600
MixupTrain:  epoch  0, batch  1767 | loss: 2.2643914
MixupTrain:  epoch  0, batch  1768 | loss: 2.4049015
MixupTrain:  epoch  0, batch  1769 | loss: 2.4620903
MixupTrain:  epoch  0, batch  1770 | loss: 2.1047168
MixupTrain:  epoch  0, batch  1771 | loss: 2.3202238
MixupTrain:  epoch  0, batch  1772 | loss: 2.1668744
MixupTrain:  epoch  0, batch  1773 | loss: 2.3103480
MixupTrain:  epoch  0, batch  1774 | loss: 2.5299323
MixupTrain:  epoch  0, batch  1775 | loss: 2.6769981
MixupTrain:  epoch  0, batch  1776 | loss: 2.6017406
MixupTrain:  epoch  0, batch  1777 | loss: 2.5831184
MixupTrain:  epoch  0, batch  1778 | loss: 2.5470173
MixupTrain:  epoch  0, batch  1779 | loss: 2.5336690
MixupTrain:  epoch  0, batch  1780 | loss: 2.5071850
MixupTrain:  epoch  0, batch  1781 | loss: 2.6817946
MixupTrain:  epoch  0, batch  1782 | loss: 2.1430655
MixupTrain:  epoch  0, batch  1783 | loss: 2.5447831
MixupTrain:  epoch  0, batch  1784 | loss: 2.2046299
MixupTrain:  epoch  0, batch  1785 | loss: 2.7898779
MixupTrain:  epoch  0, batch  1786 | loss: 2.8413079
MixupTrain:  epoch  0, batch  1787 | loss: 2.3590641
MixupTrain:  epoch  0, batch  1788 | loss: 2.1485364
MixupTrain:  epoch  0, batch  1789 | loss: 2.2688546
MixupTrain:  epoch  0, batch  1790 | loss: 2.3605247
MixupTrain:  epoch  0, batch  1791 | loss: 2.5508316
MixupTrain:  epoch  0, batch  1792 | loss: 2.1060042
MixupTrain:  epoch  0, batch  1793 | loss: 2.6475668
MixupTrain:  epoch  0, batch  1794 | loss: 2.2698255
MixupTrain:  epoch  0, batch  1795 | loss: 2.4002781
MixupTrain:  epoch  0, batch  1796 | loss: 2.4007392
MixupTrain:  epoch  0, batch  1797 | loss: 2.0932007
MixupTrain:  epoch  0, batch  1798 | loss: 2.4398885
MixupTrain:  epoch  0, batch  1799 | loss: 2.2042146
MixupTrain:  epoch  0, batch  1800 | loss: 2.2544718
MixupTrain:  epoch  0, batch  1801 | loss: 2.5389094
MixupTrain:  epoch  0, batch  1802 | loss: 2.4282255
MixupTrain:  epoch  0, batch  1803 | loss: 2.3529186
MixupTrain:  epoch  0, batch  1804 | loss: 1.9970491
MixupTrain:  epoch  0, batch  1805 | loss: 2.1907768
MixupTrain:  epoch  0, batch  1806 | loss: 2.2032747
MixupTrain:  epoch  0, batch  1807 | loss: 2.3797541
MixupTrain:  epoch  0, batch  1808 | loss: 1.9982066
MixupTrain:  epoch  0, batch  1809 | loss: 2.2305143
MixupTrain:  epoch  0, batch  1810 | loss: 2.3865664
MixupTrain:  epoch  0, batch  1811 | loss: 2.3480394
MixupTrain:  epoch  0, batch  1812 | loss: 2.6596253
MixupTrain:  epoch  0, batch  1813 | loss: 2.5622499
MixupTrain:  epoch  0, batch  1814 | loss: 2.0687864
MixupTrain:  epoch  0, batch  1815 | loss: 2.7747571
MixupTrain:  epoch  0, batch  1816 | loss: 2.4936295
MixupTrain:  epoch  0, batch  1817 | loss: 2.4754796
MixupTrain:  epoch  0, batch  1818 | loss: 2.3394501
MixupTrain:  epoch  0, batch  1819 | loss: 2.2753954
MixupTrain:  epoch  0, batch  1820 | loss: 2.5104418
MixupTrain:  epoch  0, batch  1821 | loss: 2.6167455
MixupTrain:  epoch  0, batch  1822 | loss: 2.5682235
MixupTrain:  epoch  0, batch  1823 | loss: 2.4247308
MixupTrain:  epoch  0, batch  1824 | loss: 2.5119877
MixupTrain:  epoch  0, batch  1825 | loss: 2.2743516
MixupTrain:  epoch  0, batch  1826 | loss: 2.4312465
MixupTrain:  epoch  0, batch  1827 | loss: 2.3810139
MixupTrain:  epoch  0, batch  1828 | loss: 2.3377736
MixupTrain:  epoch  0, batch  1829 | loss: 2.2936308
MixupTrain:  epoch  0, batch  1830 | loss: 2.2042041
MixupTrain:  epoch  0, batch  1831 | loss: 2.3579302
MixupTrain:  epoch  0, batch  1832 | loss: 2.3565266
MixupTrain:  epoch  0, batch  1833 | loss: 2.2944980
MixupTrain:  epoch  0, batch  1834 | loss: 2.1487598
MixupTrain:  epoch  0, batch  1835 | loss: 2.4273086
MixupTrain:  epoch  0, batch  1836 | loss: 2.1136563
MixupTrain:  epoch  0, batch  1837 | loss: 2.5847623
MixupTrain:  epoch  0, batch  1838 | loss: 2.4524479
MixupTrain:  epoch  0, batch  1839 | loss: 2.7275276
MixupTrain:  epoch  0, batch  1840 | loss: 2.8837259
MixupTrain:  epoch  0, batch  1841 | loss: 2.1755438
MixupTrain:  epoch  0, batch  1842 | loss: 2.3022408
MixupTrain:  epoch  0, batch  1843 | loss: 2.5071564
MixupTrain:  epoch  0, batch  1844 | loss: 2.2113278
MixupTrain:  epoch  0, batch  1845 | loss: 2.8397274
MixupTrain:  epoch  0, batch  1846 | loss: 2.5446925
MixupTrain:  epoch  0, batch  1847 | loss: 2.2754786
MixupTrain:  epoch  0, batch  1848 | loss: 2.4239907
MixupTrain:  epoch  0, batch  1849 | loss: 2.1399910
MixupTrain:  epoch  0, batch  1850 | loss: 2.5858355
MixupTrain:  epoch  0, batch  1851 | loss: 2.4655344
MixupTrain:  epoch  0, batch  1852 | loss: 2.2558572
MixupTrain:  epoch  0, batch  1853 | loss: 2.2506428
MixupTrain:  epoch  0, batch  1854 | loss: 2.3096395
MixupTrain:  epoch  0, batch  1855 | loss: 2.3711660
MixupTrain:  epoch  0, batch  1856 | loss: 2.3216271
MixupTrain:  epoch  0, batch  1857 | loss: 2.3920646
MixupTrain:  epoch  0, batch  1858 | loss: 2.4340520
MixupTrain:  epoch  0, batch  1859 | loss: 2.5692792
MixupTrain:  epoch  0, batch  1860 | loss: 2.2002378
MixupTrain:  epoch  0, batch  1861 | loss: 2.8140450
MixupTrain:  epoch  0, batch  1862 | loss: 1.9882022
MixupTrain:  epoch  0, batch  1863 | loss: 2.7159719
MixupTrain:  epoch  0, batch  1864 | loss: 2.2622879
MixupTrain:  epoch  0, batch  1865 | loss: 2.5788918
MixupTrain:  epoch  0, batch  1866 | loss: 2.3064365
MixupTrain:  epoch  0, batch  1867 | loss: 2.3309016
MixupTrain:  epoch  0, batch  1868 | loss: 2.6618822
MixupTrain:  epoch  0, batch  1869 | loss: 2.3457608
MixupTrain:  epoch  0, batch  1870 | loss: 2.1870227
MixupTrain:  epoch  0, batch  1871 | loss: 2.1175513
MixupTrain:  epoch  0, batch  1872 | loss: 2.2951727
MixupTrain:  epoch  0, batch  1873 | loss: 2.5730340
MixupTrain:  epoch  0, batch  1874 | loss: 2.8151135
MixupTrain:  epoch  0, batch  1875 | loss: 2.6025636
MixupTrain:  epoch  0, batch  1876 | loss: 2.4298658
MixupTrain:  epoch  0, batch  1877 | loss: 2.4649119
MixupTrain:  epoch  0, batch  1878 | loss: 2.7802134
MixupTrain:  epoch  0, batch  1879 | loss: 2.7318749
MixupTrain:  epoch  0, batch  1880 | loss: 2.7678602
MixupTrain:  epoch  0, batch  1881 | loss: 1.9533811
MixupTrain:  epoch  0, batch  1882 | loss: 2.3387341
MixupTrain:  epoch  0, batch  1883 | loss: 2.5152717
MixupTrain:  epoch  0, batch  1884 | loss: 2.6154222
MixupTrain:  epoch  0, batch  1885 | loss: 2.3617702
MixupTrain:  epoch  0, batch  1886 | loss: 2.3889103
MixupTrain:  epoch  0, batch  1887 | loss: 2.6943893
MixupTrain:  epoch  0, batch  1888 | loss: 2.7411830
MixupTrain:  epoch  0, batch  1889 | loss: 2.2311304
MixupTrain:  epoch  0, batch  1890 | loss: 2.3865581
MixupTrain:  epoch  0, batch  1891 | loss: 2.7800477
MixupTrain:  epoch  0, batch  1892 | loss: 2.4146047
MixupTrain:  epoch  0, batch  1893 | loss: 2.2889171
MixupTrain:  epoch  0, batch  1894 | loss: 2.1173000
MixupTrain:  epoch  0, batch  1895 | loss: 2.4939165
MixupTrain:  epoch  0, batch  1896 | loss: 2.4685340
MixupTrain:  epoch  0, batch  1897 | loss: 2.6878176
MixupTrain:  epoch  0, batch  1898 | loss: 2.4867444
MixupTrain:  epoch  0, batch  1899 | loss: 2.3671813
MixupTrain:  epoch  0, batch  1900 | loss: 2.3350964
MixupTrain:  epoch  0, batch  1901 | loss: 2.4135132
MixupTrain:  epoch  0, batch  1902 | loss: 2.4018693
MixupTrain:  epoch  0, batch  1903 | loss: 2.6954687
MixupTrain:  epoch  0, batch  1904 | loss: 2.1135724
MixupTrain:  epoch  0, batch  1905 | loss: 2.8450756
MixupTrain:  epoch  0, batch  1906 | loss: 2.6936688
MixupTrain:  epoch  0, batch  1907 | loss: 2.3301120
MixupTrain:  epoch  0, batch  1908 | loss: 2.6435282
MixupTrain:  epoch  0, batch  1909 | loss: 2.3752494
MixupTrain:  epoch  0, batch  1910 | loss: 2.7605791
MixupTrain:  epoch  0, batch  1911 | loss: 2.6902764
MixupTrain:  epoch  0, batch  1912 | loss: 2.3894565
MixupTrain:  epoch  0, batch  1913 | loss: 2.0568099
MixupTrain:  epoch  0, batch  1914 | loss: 2.1740398
MixupTrain:  epoch  0, batch  1915 | loss: 2.9071412
MixupTrain:  epoch  0, batch  1916 | loss: 2.6302438
MixupTrain:  epoch  0, batch  1917 | loss: 2.3292115
MixupTrain:  epoch  0, batch  1918 | loss: 2.5011868
MixupTrain:  epoch  0, batch  1919 | loss: 2.3062778
MixupTrain:  epoch  0, batch  1920 | loss: 2.5320344
MixupTrain:  epoch  0, batch  1921 | loss: 2.4716005
MixupTrain:  epoch  0, batch  1922 | loss: 2.4715214
MixupTrain:  epoch  0, batch  1923 | loss: 1.9861600
MixupTrain:  epoch  0, batch  1924 | loss: 2.4232879
MixupTrain:  epoch  0, batch  1925 | loss: 2.4175608
MixupTrain:  epoch  0, batch  1926 | loss: 2.3265235
MixupTrain:  epoch  0, batch  1927 | loss: 2.5225911
MixupTrain:  epoch  0, batch  1928 | loss: 2.1481640
MixupTrain:  epoch  0, batch  1929 | loss: 2.5352173
MixupTrain:  epoch  0, batch  1930 | loss: 2.2840869
MixupTrain:  epoch  0, batch  1931 | loss: 2.1424756
MixupTrain:  epoch  0, batch  1932 | loss: 2.4393091
MixupTrain:  epoch  0, batch  1933 | loss: 2.2986710
MixupTrain:  epoch  0, batch  1934 | loss: 2.2179112
MixupTrain:  epoch  0, batch  1935 | loss: 2.5056143
MixupTrain:  epoch  0, batch  1936 | loss: 2.2391000
MixupTrain:  epoch  0, batch  1937 | loss: 2.7288637
MixupTrain:  epoch  0, batch  1938 | loss: 2.4644313
MixupTrain:  epoch  0, batch  1939 | loss: 2.5014977
MixupTrain:  epoch  0, batch  1940 | loss: 2.1038632
MixupTrain:  epoch  0, batch  1941 | loss: 2.6618590
MixupTrain:  epoch  0, batch  1942 | loss: 2.5760846
MixupTrain:  epoch  0, batch  1943 | loss: 2.5195522
MixupTrain:  epoch  0, batch  1944 | loss: 2.3269835
MixupTrain:  epoch  0, batch  1945 | loss: 2.4203539
MixupTrain:  epoch  0, batch  1946 | loss: 2.8303552
MixupTrain:  epoch  0, batch  1947 | loss: 2.1451664
MixupTrain:  epoch  0, batch  1948 | loss: 2.5399189
MixupTrain:  epoch  0, batch  1949 | loss: 2.7641921
MixupTrain:  epoch  0, batch  1950 | loss: 2.6791363
MixupTrain:  epoch  0, batch  1951 | loss: 2.4414225
MixupTrain:  epoch  0, batch  1952 | loss: 2.3640244
MixupTrain:  epoch  0, batch  1953 | loss: 2.3259282
MixupTrain:  epoch  0, batch  1954 | loss: 2.8231473
MixupTrain:  epoch  0, batch  1955 | loss: 2.3648684
MixupTrain:  epoch  0, batch  1956 | loss: 2.4793463
MixupTrain:  epoch  0, batch  1957 | loss: 2.2181153
MixupTrain:  epoch  0, batch  1958 | loss: 1.9540131
MixupTrain:  epoch  0, batch  1959 | loss: 2.1641920
MixupTrain:  epoch  0, batch  1960 | loss: 2.4056137
MixupTrain:  epoch  0, batch  1961 | loss: 2.3321366
MixupTrain:  epoch  0, batch  1962 | loss: 2.1785696
MixupTrain:  epoch  0, batch  1963 | loss: 2.3262019
MixupTrain:  epoch  0, batch  1964 | loss: 2.3972425
MixupTrain:  epoch  0, batch  1965 | loss: 2.2354920
MixupTrain:  epoch  0, batch  1966 | loss: 2.0345955
MixupTrain:  epoch  0, batch  1967 | loss: 2.2512326
MixupTrain:  epoch  0, batch  1968 | loss: 2.3331194
MixupTrain:  epoch  0, batch  1969 | loss: 2.3149405
MixupTrain:  epoch  0, batch  1970 | loss: 2.3147397
MixupTrain:  epoch  0, batch  1971 | loss: 2.1259604
MixupTrain:  epoch  0, batch  1972 | loss: 2.2792392
MixupTrain:  epoch  0, batch  1973 | loss: 2.3859735
MixupTrain:  epoch  0, batch  1974 | loss: 2.4848008
MixupTrain:  epoch  0, batch  1975 | loss: 2.1525128
MixupTrain:  epoch  0, batch  1976 | loss: 2.4392734
MixupTrain:  epoch  0, batch  1977 | loss: 2.2785745
MixupTrain:  epoch  0, batch  1978 | loss: 2.6496527
MixupTrain:  epoch  0, batch  1979 | loss: 2.5247283
MixupTrain:  epoch  0, batch  1980 | loss: 2.3325763
MixupTrain:  epoch  0, batch  1981 | loss: 2.0715842
MixupTrain:  epoch  0, batch  1982 | loss: 2.6718674
MixupTrain:  epoch  0, batch  1983 | loss: 2.4684327
MixupTrain:  epoch  0, batch  1984 | loss: 2.1848793
MixupTrain:  epoch  0, batch  1985 | loss: 2.5135598
MixupTrain:  epoch  0, batch  1986 | loss: 2.3107405
MixupTrain:  epoch  0, batch  1987 | loss: 2.3831167
MixupTrain:  epoch  0, batch  1988 | loss: 2.4793806
MixupTrain:  epoch  0, batch  1989 | loss: 2.2715633
MixupTrain:  epoch  0, batch  1990 | loss: 2.1953523
MixupTrain:  epoch  0, batch  1991 | loss: 2.2074032
MixupTrain:  epoch  0, batch  1992 | loss: 2.3692303
MixupTrain:  epoch  0, batch  1993 | loss: 2.1538522
MixupTrain:  epoch  0, batch  1994 | loss: 2.1665707
MixupTrain:  epoch  0, batch  1995 | loss: 2.5040290
MixupTrain:  epoch  0, batch  1996 | loss: 2.6946869
MixupTrain:  epoch  0, batch  1997 | loss: 2.2363987
MixupTrain:  epoch  0, batch  1998 | loss: 2.0860374
MixupTrain:  epoch  0, batch  1999 | loss: 2.5515888
MixupTrain:  epoch  0, batch  2000 | loss: 2.3536100
MixupTrain:  epoch  0, batch  2001 | loss: 2.2876804
MixupTrain:  epoch  0, batch  2002 | loss: 2.2859039
MixupTrain:  epoch  0, batch  2003 | loss: 2.3356855
MixupTrain:  epoch  0, batch  2004 | loss: 2.5409908
MixupTrain:  epoch  0, batch  2005 | loss: 2.5033288
MixupTrain:  epoch  0, batch  2006 | loss: 2.6222360
MixupTrain:  epoch  0, batch  2007 | loss: 2.3933024
MixupTrain:  epoch  0, batch  2008 | loss: 2.2709455
MixupTrain:  epoch  0, batch  2009 | loss: 2.3156750
MixupTrain:  epoch  0, batch  2010 | loss: 2.3259966
MixupTrain:  epoch  0, batch  2011 | loss: 2.4163761
MixupTrain:  epoch  0, batch  2012 | loss: 2.5731523
MixupTrain:  epoch  0, batch  2013 | loss: 2.3337669
MixupTrain:  epoch  0, batch  2014 | loss: 2.3900874
MixupTrain:  epoch  0, batch  2015 | loss: 2.4446816
MixupTrain:  epoch  0, batch  2016 | loss: 2.2908123
MixupTrain:  epoch  0, batch  2017 | loss: 2.5142760
MixupTrain:  epoch  0, batch  2018 | loss: 2.0541008
MixupTrain:  epoch  0, batch  2019 | loss: 2.3320642
MixupTrain:  epoch  0, batch  2020 | loss: 2.4691818
MixupTrain:  epoch  0, batch  2021 | loss: 2.6888103
MixupTrain:  epoch  0, batch  2022 | loss: 2.3373747
MixupTrain:  epoch  0, batch  2023 | loss: 2.4383652
MixupTrain:  epoch  0, batch  2024 | loss: 2.1599550
MixupTrain:  epoch  0, batch  2025 | loss: 2.2503791
MixupTrain:  epoch  0, batch  2026 | loss: 2.6453733
MixupTrain:  epoch  0, batch  2027 | loss: 2.5664244
MixupTrain:  epoch  0, batch  2028 | loss: 2.3758535
MixupTrain:  epoch  0, batch  2029 | loss: 2.5341651
MixupTrain:  epoch  0, batch  2030 | loss: 2.4193416
MixupTrain:  epoch  0, batch  2031 | loss: 2.4119871
MixupTrain:  epoch  0, batch  2032 | loss: 2.3315332
MixupTrain:  epoch  0, batch  2033 | loss: 2.2534757
MixupTrain:  epoch  0, batch  2034 | loss: 2.3372126
MixupTrain:  epoch  0, batch  2035 | loss: 2.1561103
MixupTrain:  epoch  0, batch  2036 | loss: 2.3081722
MixupTrain:  epoch  0, batch  2037 | loss: 2.2867570
MixupTrain:  epoch  0, batch  2038 | loss: 2.7409210
MixupTrain:  epoch  0, batch  2039 | loss: 2.4063516
MixupTrain:  epoch  0, batch  2040 | loss: 2.5687637
MixupTrain:  epoch  0, batch  2041 | loss: 2.2349157
MixupTrain:  epoch  0, batch  2042 | loss: 2.3549995
MixupTrain:  epoch  0, batch  2043 | loss: 2.4920411
MixupTrain:  epoch  0, batch  2044 | loss: 2.7157726
MixupTrain:  epoch  0, batch  2045 | loss: 2.1871171
MixupTrain:  epoch  0, batch  2046 | loss: 1.9286362
MixupTrain:  epoch  0, batch  2047 | loss: 2.2042298
MixupTrain:  epoch  0, batch  2048 | loss: 2.3014195
MixupTrain:  epoch  0, batch  2049 | loss: 2.6283550
MixupTrain:  epoch  0, batch  2050 | loss: 2.2533267
MixupTrain:  epoch  0, batch  2051 | loss: 2.8258379
MixupTrain:  epoch  0, batch  2052 | loss: 2.4451933
MixupTrain:  epoch  0, batch  2053 | loss: 2.3716378
MixupTrain:  epoch  0, batch  2054 | loss: 2.5350032
MixupTrain:  epoch  0, batch  2055 | loss: 2.2618904
MixupTrain:  epoch  0, batch  2056 | loss: 2.1699598
MixupTrain:  epoch  0, batch  2057 | loss: 2.5757952
MixupTrain:  epoch  0, batch  2058 | loss: 2.3292012
MixupTrain:  epoch  0, batch  2059 | loss: 2.2310247
MixupTrain:  epoch  0, batch  2060 | loss: 2.3405647
MixupTrain:  epoch  0, batch  2061 | loss: 2.6725810
MixupTrain:  epoch  0, batch  2062 | loss: 2.4664841
MixupTrain:  epoch  0, batch  2063 | loss: 2.1809301
MixupTrain:  epoch  0, batch  2064 | loss: 2.2870598
MixupTrain:  epoch  0, batch  2065 | loss: 2.6961756
MixupTrain:  epoch  0, batch  2066 | loss: 2.2581871
MixupTrain:  epoch  0, batch  2067 | loss: 2.4799380
MixupTrain:  epoch  0, batch  2068 | loss: 2.4412014
MixupTrain:  epoch  0, batch  2069 | loss: 2.3444514
MixupTrain:  epoch  0, batch  2070 | loss: 2.8208821
MixupTrain:  epoch  0, batch  2071 | loss: 2.3148375
MixupTrain:  epoch  0, batch  2072 | loss: 2.7092216
MixupTrain:  epoch  0, batch  2073 | loss: 2.4182031
MixupTrain:  epoch  0, batch  2074 | loss: 2.6811361
MixupTrain:  epoch  0, batch  2075 | loss: 2.4311247
MixupTrain:  epoch  0, batch  2076 | loss: 2.6524706
MixupTrain:  epoch  0, batch  2077 | loss: 2.2112947
MixupTrain:  epoch  0, batch  2078 | loss: 2.3918600
MixupTrain:  epoch  0, batch  2079 | loss: 2.5452914
MixupTrain:  epoch  0, batch  2080 | loss: 2.6334970
MixupTrain:  epoch  0, batch  2081 | loss: 2.4636705
MixupTrain:  epoch  0, batch  2082 | loss: 2.6316767
MixupTrain:  epoch  0, batch  2083 | loss: 2.6176856
MixupTrain:  epoch  0, batch  2084 | loss: 2.4306643
MixupTrain:  epoch  0, batch  2085 | loss: 2.2870121
MixupTrain:  epoch  0, batch  2086 | loss: 2.2590942
MixupTrain:  epoch  0, batch  2087 | loss: 2.5785990
MixupTrain:  epoch  0, batch  2088 | loss: 2.5138597
MixupTrain:  epoch  0, batch  2089 | loss: 2.4725659
MixupTrain:  epoch  0, batch  2090 | loss: 2.0200953
MixupTrain:  epoch  0, batch  2091 | loss: 2.3759336
MixupTrain:  epoch  0, batch  2092 | loss: 2.8373237
MixupTrain:  epoch  0, batch  2093 | loss: 2.2344182
MixupTrain:  epoch  0, batch  2094 | loss: 2.1652210
MixupTrain:  epoch  0, batch  2095 | loss: 2.4553571
MixupTrain:  epoch  0, batch  2096 | loss: 2.5008998
MixupTrain:  epoch  0, batch  2097 | loss: 2.6157029
MixupTrain:  epoch  0, batch  2098 | loss: 2.4731202
MixupTrain:  epoch  0, batch  2099 | loss: 2.4578495
MixupTrain:  epoch  0, batch  2100 | loss: 2.2565594
MixupTrain:  epoch  0, batch  2101 | loss: 2.5144124
MixupTrain:  epoch  0, batch  2102 | loss: 2.3617349
MixupTrain:  epoch  0, batch  2103 | loss: 2.4369717
MixupTrain:  epoch  0, batch  2104 | loss: 2.6552444
MixupTrain:  epoch  0, batch  2105 | loss: 2.0226414
MixupTrain:  epoch  0, batch  2106 | loss: 2.5151494
MixupTrain:  epoch  0, batch  2107 | loss: 3.0697680
MixupTrain:  epoch  0, batch  2108 | loss: 2.2967627
MixupTrain:  epoch  0, batch  2109 | loss: 2.6713095
MixupTrain:  epoch  0, batch  2110 | loss: 2.3740196
MixupTrain:  epoch  0, batch  2111 | loss: 2.0319815
MixupTrain:  epoch  0, batch  2112 | loss: 2.4176207
MixupTrain:  epoch  0, batch  2113 | loss: 2.3507371
MixupTrain:  epoch  0, batch  2114 | loss: 2.4606745
MixupTrain:  epoch  0, batch  2115 | loss: 2.4968643
MixupTrain:  epoch  0, batch  2116 | loss: 2.1415687
MixupTrain:  epoch  0, batch  2117 | loss: 2.5037420
MixupTrain:  epoch  0, batch  2118 | loss: 2.3788791
MixupTrain:  epoch  0, batch  2119 | loss: 2.3902779
MixupTrain:  epoch  0, batch  2120 | loss: 2.3370271
MixupTrain:  epoch  0, batch  2121 | loss: 2.4688425
MixupTrain:  epoch  0, batch  2122 | loss: 2.4976692
MixupTrain:  epoch  0, batch  2123 | loss: 2.0311444
MixupTrain:  epoch  0, batch  2124 | loss: 2.2890577
MixupTrain:  epoch  0, batch  2125 | loss: 2.2823491
MixupTrain:  epoch  0, batch  2126 | loss: 2.2150187
MixupTrain:  epoch  0, batch  2127 | loss: 2.1901677
MixupTrain:  epoch  0, batch  2128 | loss: 2.6426520
MixupTrain:  epoch  0, batch  2129 | loss: 2.2273698
MixupTrain:  epoch  0, batch  2130 | loss: 2.3658605
MixupTrain:  epoch  0, batch  2131 | loss: 2.7375150
MixupTrain:  epoch  0, batch  2132 | loss: 2.5777030
MixupTrain:  epoch  0, batch  2133 | loss: 2.4184504
MixupTrain:  epoch  0, batch  2134 | loss: 2.5300715
MixupTrain:  epoch  0, batch  2135 | loss: 1.9989291
MixupTrain:  epoch  0, batch  2136 | loss: 2.1047373
MixupTrain:  epoch  0, batch  2137 | loss: 2.2722862
MixupTrain:  epoch  0, batch  2138 | loss: 2.7187729
MixupTrain:  epoch  0, batch  2139 | loss: 2.1398292
MixupTrain:  epoch  0, batch  2140 | loss: 2.2991195
MixupTrain:  epoch  0, batch  2141 | loss: 2.4322984
MixupTrain:  epoch  0, batch  2142 | loss: 2.1954889
MixupTrain:  epoch  0, batch  2143 | loss: 1.9813243
MixupTrain:  epoch  0, batch  2144 | loss: 2.4411690
MixupTrain:  epoch  0, batch  2145 | loss: 2.1330895
MixupTrain:  epoch  0, batch  2146 | loss: 2.4655564
MixupTrain:  epoch  0, batch  2147 | loss: 2.4239788
MixupTrain:  epoch  0, batch  2148 | loss: 2.3156791
MixupTrain:  epoch  0, batch  2149 | loss: 1.9983833
MixupTrain:  epoch  0, batch  2150 | loss: 2.4483800
MixupTrain:  epoch  0, batch  2151 | loss: 2.6585727
MixupTrain:  epoch  0, batch  2152 | loss: 2.2980957
MixupTrain:  epoch  0, batch  2153 | loss: 2.2399154
MixupTrain:  epoch  0, batch  2154 | loss: 2.1213033
MixupTrain:  epoch  0, batch  2155 | loss: 2.3725376
MixupTrain:  epoch  0, batch  2156 | loss: 2.2141848
MixupTrain:  epoch  0, batch  2157 | loss: 2.0410216
MixupTrain:  epoch  0, batch  2158 | loss: 2.6471484
MixupTrain:  epoch  0, batch  2159 | loss: 2.4423821
MixupTrain:  epoch  0, batch  2160 | loss: 2.1978064
MixupTrain:  epoch  0, batch  2161 | loss: 2.4784966
MixupTrain:  epoch  0, batch  2162 | loss: 2.1620214
MixupTrain:  epoch  0, batch  2163 | loss: 2.8757665
MixupTrain:  epoch  0, batch  2164 | loss: 2.4268029
MixupTrain:  epoch  0, batch  2165 | loss: 2.5708487
MixupTrain:  epoch  0, batch  2166 | loss: 2.1866531
MixupTrain:  epoch  0, batch  2167 | loss: 2.6727955
MixupTrain:  epoch  0, batch  2168 | loss: 2.4999161
MixupTrain:  epoch  0, batch  2169 | loss: 2.4338140
MixupTrain:  epoch  0, batch  2170 | loss: 3.0259342
MixupTrain:  epoch  0, batch  2171 | loss: 2.5162563
MixupTrain:  epoch  0, batch  2172 | loss: 2.5069394
MixupTrain:  epoch  0, batch  2173 | loss: 2.6052845
MixupTrain:  epoch  0, batch  2174 | loss: 2.2290564
MixupTrain:  epoch  0, batch  2175 | loss: 2.2242856
MixupTrain:  epoch  0, batch  2176 | loss: 2.5162666
MixupTrain:  epoch  0, batch  2177 | loss: 2.3704095
MixupTrain:  epoch  0, batch  2178 | loss: 2.0893006
MixupTrain:  epoch  0, batch  2179 | loss: 2.6447642
MixupTrain:  epoch  0, batch  2180 | loss: 2.1503119
MixupTrain:  epoch  0, batch  2181 | loss: 2.1831660
MixupTrain:  epoch  0, batch  2182 | loss: 2.6042461
MixupTrain:  epoch  0, batch  2183 | loss: 2.2380638
MixupTrain:  epoch  0, batch  2184 | loss: 2.4845855
MixupTrain:  epoch  0, batch  2185 | loss: 2.2731414
MixupTrain:  epoch  0, batch  2186 | loss: 2.5002236
MixupTrain:  epoch  0, batch  2187 | loss: 2.2077796
MixupTrain:  epoch  0, batch  2188 | loss: 2.6444917
MixupTrain:  epoch  0, batch  2189 | loss: 2.4359651
MixupTrain:  epoch  0, batch  2190 | loss: 2.7092044
MixupTrain:  epoch  0, batch  2191 | loss: 2.3432193
MixupTrain:  epoch  0, batch  2192 | loss: 2.1731801
MixupTrain:  epoch  0, batch  2193 | loss: 2.1229579
MixupTrain:  epoch  0, batch  2194 | loss: 2.3210659
MixupTrain:  epoch  0, batch  2195 | loss: 2.1404829
MixupTrain:  epoch  0, batch  2196 | loss: 2.5345931
MixupTrain:  epoch  0, batch  2197 | loss: 2.3473277
MixupTrain:  epoch  0, batch  2198 | loss: 2.5920582
MixupTrain:  epoch  0, batch  2199 | loss: 2.6438813
MixupTrain:  epoch  0, batch  2200 | loss: 2.1947391
MixupTrain:  epoch  0, batch  2201 | loss: 2.7068391
MixupTrain:  epoch  0, batch  2202 | loss: 2.4175680
MixupTrain:  epoch  0, batch  2203 | loss: 2.8887985
MixupTrain:  epoch  0, batch  2204 | loss: 2.3560581
MixupTrain:  epoch  0, batch  2205 | loss: 2.5047302
MixupTrain:  epoch  0, batch  2206 | loss: 2.2773802
MixupTrain:  epoch  0, batch  2207 | loss: 2.6045754
MixupTrain:  epoch  0, batch  2208 | loss: 2.4731297
MixupTrain:  epoch  0, batch  2209 | loss: 2.7995400
MixupTrain:  epoch  0, batch  2210 | loss: 2.2950282
MixupTrain:  epoch  0, batch  2211 | loss: 2.3409905
MixupTrain:  epoch  0, batch  2212 | loss: 2.4962373
MixupTrain:  epoch  0, batch  2213 | loss: 2.4256325
MixupTrain:  epoch  0, batch  2214 | loss: 2.3852382
MixupTrain:  epoch  0, batch  2215 | loss: 2.5985923
MixupTrain:  epoch  0, batch  2216 | loss: 2.4261868
MixupTrain:  epoch  0, batch  2217 | loss: 2.4833579
MixupTrain:  epoch  0, batch  2218 | loss: 2.7018054
MixupTrain:  epoch  0, batch  2219 | loss: 2.5709786
MixupTrain:  epoch  0, batch  2220 | loss: 2.6278598
MixupTrain:  epoch  0, batch  2221 | loss: 2.2667994
MixupTrain:  epoch  0, batch  2222 | loss: 2.1181650
MixupTrain:  epoch  0, batch  2223 | loss: 2.1143875
MixupTrain:  epoch  0, batch  2224 | loss: 2.3502102
MixupTrain:  epoch  0, batch  2225 | loss: 2.2605753
MixupTrain:  epoch  0, batch  2226 | loss: 2.2274108
MixupTrain:  epoch  0, batch  2227 | loss: 2.3677950
MixupTrain:  epoch  0, batch  2228 | loss: 2.4116945
MixupTrain:  epoch  0, batch  2229 | loss: 2.4822717
MixupTrain:  epoch  0, batch  2230 | loss: 2.6774893
MixupTrain:  epoch  0, batch  2231 | loss: 2.3745914
MixupTrain:  epoch  0, batch  2232 | loss: 2.8337917
MixupTrain:  epoch  0, batch  2233 | loss: 1.9845455
MixupTrain:  epoch  0, batch  2234 | loss: 1.8792642
MixupTrain:  epoch  0, batch  2235 | loss: 2.3554506
MemoryTrain:  epoch  0, batch     0 | loss: 2.1891816
MemoryTrain:  epoch  0, batch     1 | loss: 3.4283590
MemoryTrain:  epoch  0, batch     2 | loss: 2.5390878
MemoryTrain:  epoch  0, batch     3 | loss: 2.5604773
MemoryTrain:  epoch  0, batch     4 | loss: 2.8449817
MemoryTrain:  epoch  0, batch     5 | loss: 2.0207090
MemoryTrain:  epoch  0, batch     6 | loss: 2.0593326
MemoryTrain:  epoch  0, batch     7 | loss: 2.0488698
MemoryTrain:  epoch  0, batch     8 | loss: 3.2922635
MemoryTrain:  epoch  0, batch     9 | loss: 2.3926237
MemoryTrain:  epoch  0, batch    10 | loss: 1.9752196
MemoryTrain:  epoch  0, batch    11 | loss: 2.0748472
MemoryTrain:  epoch  0, batch    12 | loss: 2.5439301
MemoryTrain:  epoch  0, batch    13 | loss: 2.0568929
MemoryTrain:  epoch  0, batch    14 | loss: 1.9960346
MemoryTrain:  epoch  0, batch    15 | loss: 1.9835546
MemoryTrain:  epoch  1, batch     0 | loss: 1.8183407
MemoryTrain:  epoch  1, batch     1 | loss: 1.8454783
MemoryTrain:  epoch  1, batch     2 | loss: 1.8326533
MemoryTrain:  epoch  1, batch     3 | loss: 1.8428040
MemoryTrain:  epoch  1, batch     4 | loss: 1.8216028
MemoryTrain:  epoch  1, batch     5 | loss: 1.8877784
MemoryTrain:  epoch  1, batch     6 | loss: 1.8420609
MemoryTrain:  epoch  1, batch     7 | loss: 1.8173027
MemoryTrain:  epoch  1, batch     8 | loss: 1.8371207
MemoryTrain:  epoch  1, batch     9 | loss: 1.8268377
MemoryTrain:  epoch  1, batch    10 | loss: 1.8365208
MemoryTrain:  epoch  1, batch    11 | loss: 1.8244939
MemoryTrain:  epoch  1, batch    12 | loss: 1.8171566
MemoryTrain:  epoch  1, batch    13 | loss: 1.8207614
MemoryTrain:  epoch  1, batch    14 | loss: 1.8261371
MemoryTrain:  epoch  1, batch    15 | loss: 1.8475177
MemoryTrain:  epoch  2, batch     0 | loss: 1.8191534
MemoryTrain:  epoch  2, batch     1 | loss: 1.8343666
MemoryTrain:  epoch  2, batch     2 | loss: 1.8199776
MemoryTrain:  epoch  2, batch     3 | loss: 1.8258189
MemoryTrain:  epoch  2, batch     4 | loss: 1.8189347
MemoryTrain:  epoch  2, batch     5 | loss: 1.8120294
MemoryTrain:  epoch  2, batch     6 | loss: 1.8167852
MemoryTrain:  epoch  2, batch     7 | loss: 1.8155079
MemoryTrain:  epoch  2, batch     8 | loss: 1.8085961
MemoryTrain:  epoch  2, batch     9 | loss: 1.8265601
MemoryTrain:  epoch  2, batch    10 | loss: 1.8171614
MemoryTrain:  epoch  2, batch    11 | loss: 1.8243426
MemoryTrain:  epoch  2, batch    12 | loss: 1.8224452
MemoryTrain:  epoch  2, batch    13 | loss: 1.8127272
MemoryTrain:  epoch  2, batch    14 | loss: 1.8159661
MemoryTrain:  epoch  2, batch    15 | loss: 1.8431286
MemoryTrain:  epoch  3, batch     0 | loss: 1.8075912
MemoryTrain:  epoch  3, batch     1 | loss: 1.8108884
MemoryTrain:  epoch  3, batch     2 | loss: 1.8129194
MemoryTrain:  epoch  3, batch     3 | loss: 1.8096453
MemoryTrain:  epoch  3, batch     4 | loss: 1.8094065
MemoryTrain:  epoch  3, batch     5 | loss: 1.8120286
MemoryTrain:  epoch  3, batch     6 | loss: 1.8120201
MemoryTrain:  epoch  3, batch     7 | loss: 1.8088075
MemoryTrain:  epoch  3, batch     8 | loss: 1.8095481
MemoryTrain:  epoch  3, batch     9 | loss: 1.8111236
MemoryTrain:  epoch  3, batch    10 | loss: 1.8109818
MemoryTrain:  epoch  3, batch    11 | loss: 1.8107923
MemoryTrain:  epoch  3, batch    12 | loss: 1.8091483
MemoryTrain:  epoch  3, batch    13 | loss: 1.8080636
MemoryTrain:  epoch  3, batch    14 | loss: 1.8088799
MemoryTrain:  epoch  3, batch    15 | loss: 1.8186855
MemoryTrain:  epoch  4, batch     0 | loss: 1.8132184
MemoryTrain:  epoch  4, batch     1 | loss: 1.8184371
MemoryTrain:  epoch  4, batch     2 | loss: 1.8059158
MemoryTrain:  epoch  4, batch     3 | loss: 1.8108554
MemoryTrain:  epoch  4, batch     4 | loss: 1.8126605
MemoryTrain:  epoch  4, batch     5 | loss: 1.8160359
MemoryTrain:  epoch  4, batch     6 | loss: 1.8155192
MemoryTrain:  epoch  4, batch     7 | loss: 1.8153658
MemoryTrain:  epoch  4, batch     8 | loss: 1.8163823
MemoryTrain:  epoch  4, batch     9 | loss: 1.8104928
MemoryTrain:  epoch  4, batch    10 | loss: 1.8092625
MemoryTrain:  epoch  4, batch    11 | loss: 1.8121886
MemoryTrain:  epoch  4, batch    12 | loss: 1.8131150
MemoryTrain:  epoch  4, batch    13 | loss: 1.8093469
MemoryTrain:  epoch  4, batch    14 | loss: 1.8162267
MemoryTrain:  epoch  4, batch    15 | loss: 1.8195189
MemoryTrain:  epoch  5, batch     0 | loss: 1.8141088
MemoryTrain:  epoch  5, batch     1 | loss: 1.8136226
MemoryTrain:  epoch  5, batch     2 | loss: 1.8120860
MemoryTrain:  epoch  5, batch     3 | loss: 1.8168390
MemoryTrain:  epoch  5, batch     4 | loss: 1.8073691
MemoryTrain:  epoch  5, batch     5 | loss: 1.8145316
MemoryTrain:  epoch  5, batch     6 | loss: 1.8114624
MemoryTrain:  epoch  5, batch     7 | loss: 1.8150208
MemoryTrain:  epoch  5, batch     8 | loss: 1.8111689
MemoryTrain:  epoch  5, batch     9 | loss: 1.8109983
MemoryTrain:  epoch  5, batch    10 | loss: 1.8184690
MemoryTrain:  epoch  5, batch    11 | loss: 1.8119485
MemoryTrain:  epoch  5, batch    12 | loss: 1.8073225
MemoryTrain:  epoch  5, batch    13 | loss: 1.8128711
MemoryTrain:  epoch  5, batch    14 | loss: 1.8103058
MemoryTrain:  epoch  5, batch    15 | loss: 1.8100895
MemoryTrain:  epoch  6, batch     0 | loss: 1.8208861
MemoryTrain:  epoch  6, batch     1 | loss: 1.8095675
MemoryTrain:  epoch  6, batch     2 | loss: 1.8100963
MemoryTrain:  epoch  6, batch     3 | loss: 1.8110136
MemoryTrain:  epoch  6, batch     4 | loss: 1.8105704
MemoryTrain:  epoch  6, batch     5 | loss: 1.8127267
MemoryTrain:  epoch  6, batch     6 | loss: 1.8085058
MemoryTrain:  epoch  6, batch     7 | loss: 1.8133652
MemoryTrain:  epoch  6, batch     8 | loss: 1.8077415
MemoryTrain:  epoch  6, batch     9 | loss: 1.8032892
MemoryTrain:  epoch  6, batch    10 | loss: 1.8143890
MemoryTrain:  epoch  6, batch    11 | loss: 1.8090746
MemoryTrain:  epoch  6, batch    12 | loss: 1.8056495
MemoryTrain:  epoch  6, batch    13 | loss: 1.8137170
MemoryTrain:  epoch  6, batch    14 | loss: 1.8109870
MemoryTrain:  epoch  6, batch    15 | loss: 1.8113551
MemoryTrain:  epoch  7, batch     0 | loss: 1.8146586
MemoryTrain:  epoch  7, batch     1 | loss: 1.8068167
MemoryTrain:  epoch  7, batch     2 | loss: 1.8087518
MemoryTrain:  epoch  7, batch     3 | loss: 1.8066779
MemoryTrain:  epoch  7, batch     4 | loss: 1.8123095
MemoryTrain:  epoch  7, batch     5 | loss: 1.8059202
MemoryTrain:  epoch  7, batch     6 | loss: 1.8091006
MemoryTrain:  epoch  7, batch     7 | loss: 1.8083835
MemoryTrain:  epoch  7, batch     8 | loss: 1.8049682
MemoryTrain:  epoch  7, batch     9 | loss: 1.8096268
MemoryTrain:  epoch  7, batch    10 | loss: 1.8124161
MemoryTrain:  epoch  7, batch    11 | loss: 1.8142947
MemoryTrain:  epoch  7, batch    12 | loss: 1.8134683
MemoryTrain:  epoch  7, batch    13 | loss: 1.8139555
MemoryTrain:  epoch  7, batch    14 | loss: 1.8086754
MemoryTrain:  epoch  7, batch    15 | loss: 1.8100455
MemoryTrain:  epoch  8, batch     0 | loss: 1.8083785
MemoryTrain:  epoch  8, batch     1 | loss: 1.8107047
MemoryTrain:  epoch  8, batch     2 | loss: 1.8080343
MemoryTrain:  epoch  8, batch     3 | loss: 1.8050466
MemoryTrain:  epoch  8, batch     4 | loss: 1.8103800
MemoryTrain:  epoch  8, batch     5 | loss: 1.8031157
MemoryTrain:  epoch  8, batch     6 | loss: 1.8099136
MemoryTrain:  epoch  8, batch     7 | loss: 1.8100486
MemoryTrain:  epoch  8, batch     8 | loss: 1.8135257
MemoryTrain:  epoch  8, batch     9 | loss: 1.8116312
MemoryTrain:  epoch  8, batch    10 | loss: 1.8066014
MemoryTrain:  epoch  8, batch    11 | loss: 1.8137891
MemoryTrain:  epoch  8, batch    12 | loss: 1.8051398
MemoryTrain:  epoch  8, batch    13 | loss: 1.8117793
MemoryTrain:  epoch  8, batch    14 | loss: 1.8086715
MemoryTrain:  epoch  8, batch    15 | loss: 1.8107970
MemoryTrain:  epoch  9, batch     0 | loss: 1.8074250
MemoryTrain:  epoch  9, batch     1 | loss: 1.8100886
MemoryTrain:  epoch  9, batch     2 | loss: 1.8168681
MemoryTrain:  epoch  9, batch     3 | loss: 1.8103917
MemoryTrain:  epoch  9, batch     4 | loss: 1.8068922
MemoryTrain:  epoch  9, batch     5 | loss: 1.8102328
MemoryTrain:  epoch  9, batch     6 | loss: 1.8107021
MemoryTrain:  epoch  9, batch     7 | loss: 1.8108767
MemoryTrain:  epoch  9, batch     8 | loss: 1.8083851
MemoryTrain:  epoch  9, batch     9 | loss: 1.8054037
MemoryTrain:  epoch  9, batch    10 | loss: 1.8081610
MemoryTrain:  epoch  9, batch    11 | loss: 1.8088200
MemoryTrain:  epoch  9, batch    12 | loss: 1.8133843
MemoryTrain:  epoch  9, batch    13 | loss: 1.8085060
MemoryTrain:  epoch  9, batch    14 | loss: 1.8095706
MemoryTrain:  epoch  9, batch    15 | loss: 1.8141927
[EVAL] batch:    0 | acc: 100.00%,  total acc: 100.00%   
[EVAL] batch:    1 | acc: 93.75%,  total acc: 96.88%   
[EVAL] batch:    2 | acc: 100.00%,  total acc: 97.92%   
[EVAL] batch:    3 | acc: 100.00%,  total acc: 98.44%   
[EVAL] batch:    4 | acc: 100.00%,  total acc: 98.75%   
[EVAL] batch:    5 | acc: 100.00%,  total acc: 98.96%   
[EVAL] batch:    6 | acc: 100.00%,  total acc: 99.11%   
[EVAL] batch:    7 | acc: 100.00%,  total acc: 99.22%   
[EVAL] batch:    8 | acc: 75.00%,  total acc: 96.53%   
[EVAL] batch:    9 | acc: 50.00%,  total acc: 91.88%   
[EVAL] batch:   10 | acc: 68.75%,  total acc: 89.77%   
[EVAL] batch:   11 | acc: 100.00%,  total acc: 90.62%   
[EVAL] batch:   12 | acc: 100.00%,  total acc: 91.35%   
[EVAL] batch:   13 | acc: 75.00%,  total acc: 90.18%   
[EVAL] batch:    0 | acc: 0.00%,  total acc: 0.00%   
[EVAL] batch:    1 | acc: 31.25%,  total acc: 15.62%   
[EVAL] batch:    2 | acc: 6.25%,  total acc: 12.50%   
[EVAL] batch:    3 | acc: 6.25%,  total acc: 10.94%   
[EVAL] batch:    4 | acc: 6.25%,  total acc: 10.00%   
[EVAL] batch:    5 | acc: 6.25%,  total acc: 9.38%   
[EVAL] batch:    6 | acc: 6.25%,  total acc: 8.93%   
[EVAL] batch:    7 | acc: 0.00%,  total acc: 7.81%   
[EVAL] batch:    8 | acc: 0.00%,  total acc: 6.94%   
[EVAL] batch:    9 | acc: 0.00%,  total acc: 6.25%   
[EVAL] batch:   10 | acc: 0.00%,  total acc: 5.68%   
[EVAL] batch:   11 | acc: 6.25%,  total acc: 5.73%   
[EVAL] batch:   12 | acc: 0.00%,  total acc: 5.29%   
[EVAL] batch:   13 | acc: 25.00%,  total acc: 6.70%   
[EVAL] batch:   14 | acc: 43.75%,  total acc: 9.17%   
[EVAL] batch:   15 | acc: 50.00%,  total acc: 11.72%   
[EVAL] batch:   16 | acc: 50.00%,  total acc: 13.97%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 16.67%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 19.08%   
[EVAL] batch:   19 | acc: 62.50%,  total acc: 21.25%   
[EVAL] batch:   20 | acc: 87.50%,  total acc: 24.40%   
[EVAL] batch:   21 | acc: 87.50%,  total acc: 27.27%   
[EVAL] batch:   22 | acc: 93.75%,  total acc: 30.16%   
[EVAL] batch:   23 | acc: 93.75%,  total acc: 32.81%   
[EVAL] batch:   24 | acc: 93.75%,  total acc: 35.25%   
[EVAL] batch:   25 | acc: 87.50%,  total acc: 37.26%   
[EVAL] batch:   26 | acc: 56.25%,  total acc: 37.96%   
[EVAL] batch:   27 | acc: 37.50%,  total acc: 37.95%   
[EVAL] batch:   28 | acc: 50.00%,  total acc: 38.36%   
[EVAL] batch:   29 | acc: 37.50%,  total acc: 38.33%   
[EVAL] batch:   30 | acc: 50.00%,  total acc: 38.71%   
[EVAL] batch:   31 | acc: 43.75%,  total acc: 38.87%   
[EVAL] batch:   32 | acc: 37.50%,  total acc: 38.83%   
[EVAL] batch:   33 | acc: 12.50%,  total acc: 38.05%   
[EVAL] batch:   34 | acc: 12.50%,  total acc: 37.32%   
[EVAL] batch:   35 | acc: 18.75%,  total acc: 36.81%   
[EVAL] batch:   36 | acc: 18.75%,  total acc: 36.32%   
[EVAL] batch:   37 | acc: 62.50%,  total acc: 37.01%   
[EVAL] batch:   38 | acc: 68.75%,  total acc: 37.82%   
[EVAL] batch:   39 | acc: 100.00%,  total acc: 39.38%   
[EVAL] batch:   40 | acc: 68.75%,  total acc: 40.09%   
[EVAL] batch:   41 | acc: 100.00%,  total acc: 41.52%   
[EVAL] batch:   42 | acc: 0.00%,  total acc: 40.55%   
[EVAL] batch:   43 | acc: 0.00%,  total acc: 39.63%   
[EVAL] batch:   44 | acc: 0.00%,  total acc: 38.75%   
[EVAL] batch:   45 | acc: 0.00%,  total acc: 37.91%   
[EVAL] batch:   46 | acc: 18.75%,  total acc: 37.50%   
[EVAL] batch:   47 | acc: 37.50%,  total acc: 37.50%   
[EVAL] batch:   48 | acc: 0.00%,  total acc: 36.73%   
[EVAL] batch:   49 | acc: 0.00%,  total acc: 36.00%   
[EVAL] batch:   50 | acc: 0.00%,  total acc: 35.29%   
[EVAL] batch:   51 | acc: 0.00%,  total acc: 34.62%   
[EVAL] batch:   52 | acc: 0.00%,  total acc: 33.96%   
[EVAL] batch:   53 | acc: 31.25%,  total acc: 33.91%   
[EVAL] batch:   54 | acc: 87.50%,  total acc: 34.89%   
[EVAL] batch:   55 | acc: 81.25%,  total acc: 35.71%   
[EVAL] batch:   56 | acc: 75.00%,  total acc: 36.40%   
[EVAL] batch:   57 | acc: 62.50%,  total acc: 36.85%   
[EVAL] batch:   58 | acc: 50.00%,  total acc: 37.08%   
[EVAL] batch:   59 | acc: 56.25%,  total acc: 37.40%   
[EVAL] batch:   60 | acc: 6.25%,  total acc: 36.89%   
[EVAL] batch:   61 | acc: 25.00%,  total acc: 36.69%   
[EVAL] batch:   62 | acc: 12.50%,  total acc: 36.31%   
[EVAL] batch:   63 | acc: 31.25%,  total acc: 36.23%   
[EVAL] batch:   64 | acc: 12.50%,  total acc: 35.87%   
[EVAL] batch:   65 | acc: 18.75%,  total acc: 35.61%   
[EVAL] batch:   66 | acc: 18.75%,  total acc: 35.35%   
[EVAL] batch:   67 | acc: 93.75%,  total acc: 36.21%   
[EVAL] batch:   68 | acc: 43.75%,  total acc: 36.32%   
[EVAL] batch:   69 | acc: 31.25%,  total acc: 36.25%   
[EVAL] batch:   70 | acc: 37.50%,  total acc: 36.27%   
[EVAL] batch:   71 | acc: 68.75%,  total acc: 36.72%   
[EVAL] batch:   72 | acc: 93.75%,  total acc: 37.50%   
[EVAL] batch:   73 | acc: 93.75%,  total acc: 38.26%   
[EVAL] batch:   74 | acc: 100.00%,  total acc: 39.08%   
[EVAL] batch:   75 | acc: 93.75%,  total acc: 39.80%   
[EVAL] batch:   76 | acc: 100.00%,  total acc: 40.58%   
[EVAL] batch:   77 | acc: 62.50%,  total acc: 40.87%   
[EVAL] batch:   78 | acc: 0.00%,  total acc: 40.35%   
[EVAL] batch:   79 | acc: 0.00%,  total acc: 39.84%   
[EVAL] batch:   80 | acc: 0.00%,  total acc: 39.35%   
[EVAL] batch:   81 | acc: 0.00%,  total acc: 38.87%   
[EVAL] batch:   82 | acc: 0.00%,  total acc: 38.40%   
[EVAL] batch:   83 | acc: 0.00%,  total acc: 37.95%   
[EVAL] batch:   84 | acc: 31.25%,  total acc: 37.87%   
[EVAL] batch:   85 | acc: 43.75%,  total acc: 37.94%   
[EVAL] batch:   86 | acc: 25.00%,  total acc: 37.79%   
[EVAL] batch:   87 | acc: 56.25%,  total acc: 38.00%   
[EVAL] batch:   88 | acc: 43.75%,  total acc: 38.06%   
[EVAL] batch:   89 | acc: 37.50%,  total acc: 38.06%   
[EVAL] batch:   90 | acc: 56.25%,  total acc: 38.26%   
[EVAL] batch:   91 | acc: 100.00%,  total acc: 38.93%   
[EVAL] batch:   92 | acc: 100.00%,  total acc: 39.58%   
[EVAL] batch:   93 | acc: 87.50%,  total acc: 40.09%   
[EVAL] batch:   94 | acc: 75.00%,  total acc: 40.46%   
[EVAL] batch:   95 | acc: 75.00%,  total acc: 40.82%   
[EVAL] batch:   96 | acc: 25.00%,  total acc: 40.66%   
[EVAL] batch:   97 | acc: 12.50%,  total acc: 40.37%   
[EVAL] batch:   98 | acc: 31.25%,  total acc: 40.28%   
[EVAL] batch:   99 | acc: 75.00%,  total acc: 40.62%   
[EVAL] batch:  100 | acc: 87.50%,  total acc: 41.09%   
[EVAL] batch:  101 | acc: 56.25%,  total acc: 41.24%   
[EVAL] batch:  102 | acc: 81.25%,  total acc: 41.63%   
[EVAL] batch:  103 | acc: 87.50%,  total acc: 42.07%   
[EVAL] batch:  104 | acc: 93.75%,  total acc: 42.56%   
[EVAL] batch:  105 | acc: 93.75%,  total acc: 43.04%   
[EVAL] batch:  106 | acc: 75.00%,  total acc: 43.34%   
[EVAL] batch:  107 | acc: 50.00%,  total acc: 43.40%   
[EVAL] batch:  108 | acc: 75.00%,  total acc: 43.69%   
[EVAL] batch:  109 | acc: 68.75%,  total acc: 43.92%   
[EVAL] batch:  110 | acc: 93.75%,  total acc: 44.37%   
[EVAL] batch:  111 | acc: 93.75%,  total acc: 44.81%   
[EVAL] batch:  112 | acc: 87.50%,  total acc: 45.19%   
[EVAL] batch:  113 | acc: 93.75%,  total acc: 45.61%   
[EVAL] batch:  114 | acc: 93.75%,  total acc: 46.03%   
[EVAL] batch:  115 | acc: 81.25%,  total acc: 46.34%   
[EVAL] batch:  116 | acc: 100.00%,  total acc: 46.79%   
[EVAL] batch:  117 | acc: 100.00%,  total acc: 47.25%   
[EVAL] batch:  118 | acc: 93.75%,  total acc: 47.64%   
[EVAL] batch:  119 | acc: 100.00%,  total acc: 48.07%   
[EVAL] batch:  120 | acc: 93.75%,  total acc: 48.45%   
[EVAL] batch:  121 | acc: 100.00%,  total acc: 48.87%   
[EVAL] batch:  122 | acc: 100.00%,  total acc: 49.29%   
[EVAL] batch:  123 | acc: 100.00%,  total acc: 49.70%   
[EVAL] batch:  124 | acc: 100.00%,  total acc: 50.10%   
[EVAL] batch:  125 | acc: 100.00%,  total acc: 50.50%   
[EVAL] batch:  126 | acc: 100.00%,  total acc: 50.89%   
[EVAL] batch:  127 | acc: 68.75%,  total acc: 51.03%   
[EVAL] batch:  128 | acc: 56.25%,  total acc: 51.07%   
[EVAL] batch:  129 | acc: 68.75%,  total acc: 51.20%   
[EVAL] batch:  130 | acc: 100.00%,  total acc: 51.57%   
[EVAL] batch:  131 | acc: 100.00%,  total acc: 51.94%   
[EVAL] batch:  132 | acc: 62.50%,  total acc: 52.02%   
cur_acc:  ['0.8580', '0.8625', '0.8393', '0.8993', '0.6790', '0.8047', '0.8654', '0.9018']
his_acc:  ['0.8580', '0.8351', '0.7490', '0.6538', '0.6269', '0.4912', '0.4785', '0.5202']
--------Round  2
seed:  300
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 2 3 1 5 6 0 4]
prepared data!
CurrentTrain: epoch  0, batch     0 | loss: 12.2235289
CurrentTrain: epoch  0, batch     1 | loss: 11.6012354
CurrentTrain: epoch  0, batch     2 | loss: 11.5257454
CurrentTrain: epoch  0, batch     3 | loss: 11.6904202
CurrentTrain: epoch  0, batch     4 | loss: 10.9835796
CurrentTrain: epoch  0, batch     5 | loss: 11.4194059
CurrentTrain: epoch  0, batch     6 | loss: 11.3137150
CurrentTrain: epoch  0, batch     7 | loss: 11.1523075
CurrentTrain: epoch  0, batch     8 | loss: 10.7042618
CurrentTrain: epoch  0, batch     9 | loss: 11.3345747
CurrentTrain: epoch  0, batch    10 | loss: 10.9373703
CurrentTrain: epoch  0, batch    11 | loss: 10.5601006
CurrentTrain: epoch  0, batch    12 | loss: 11.0272827
CurrentTrain: epoch  0, batch    13 | loss: 10.6640139
CurrentTrain: epoch  0, batch    14 | loss: 9.9904108
CurrentTrain: epoch  0, batch    15 | loss: 10.5560760
CurrentTrain: epoch  0, batch    16 | loss: 9.8801861
CurrentTrain: epoch  0, batch    17 | loss: 10.5686178
CurrentTrain: epoch  0, batch    18 | loss: 9.9176397
CurrentTrain: epoch  0, batch    19 | loss: 10.0305481
CurrentTrain: epoch  0, batch    20 | loss: 11.0087309
CurrentTrain: epoch  0, batch    21 | loss: 10.0851135
CurrentTrain: epoch  0, batch    22 | loss: 10.2436237
CurrentTrain: epoch  0, batch    23 | loss: 9.7869158
CurrentTrain: epoch  0, batch    24 | loss: 10.8029518
CurrentTrain: epoch  0, batch    25 | loss: 9.5900755
CurrentTrain: epoch  0, batch    26 | loss: 10.1298637
CurrentTrain: epoch  0, batch    27 | loss: 9.7597895
CurrentTrain: epoch  0, batch    28 | loss: 9.5765381
CurrentTrain: epoch  0, batch    29 | loss: 10.6666222
CurrentTrain: epoch  0, batch    30 | loss: 10.2415333
CurrentTrain: epoch  0, batch    31 | loss: 9.8458548
CurrentTrain: epoch  0, batch    32 | loss: 9.8180456
CurrentTrain: epoch  0, batch    33 | loss: 9.2173386
CurrentTrain: epoch  0, batch    34 | loss: 9.9039907
CurrentTrain: epoch  0, batch    35 | loss: 9.9288893
CurrentTrain: epoch  0, batch    36 | loss: 10.4208393
CurrentTrain: epoch  0, batch    37 | loss: 10.2407684
CurrentTrain: epoch  1, batch     0 | loss: 9.5261593
CurrentTrain: epoch  1, batch     1 | loss: 8.6924095
CurrentTrain: epoch  1, batch     2 | loss: 9.3646431
CurrentTrain: epoch  1, batch     3 | loss: 10.4240856
CurrentTrain: epoch  1, batch     4 | loss: 9.9412327
CurrentTrain: epoch  1, batch     5 | loss: 8.5328579
CurrentTrain: epoch  1, batch     6 | loss: 9.5076294
CurrentTrain: epoch  1, batch     7 | loss: 8.3821726
CurrentTrain: epoch  1, batch     8 | loss: 9.4141350
CurrentTrain: epoch  1, batch     9 | loss: 9.1764994
CurrentTrain: epoch  1, batch    10 | loss: 9.9788189
CurrentTrain: epoch  1, batch    11 | loss: 9.1200390
CurrentTrain: epoch  1, batch    12 | loss: 9.3290348
CurrentTrain: epoch  1, batch    13 | loss: 9.2806139
CurrentTrain: epoch  1, batch    14 | loss: 9.2163420
CurrentTrain: epoch  1, batch    15 | loss: 8.6268082
CurrentTrain: epoch  1, batch    16 | loss: 8.9161806
CurrentTrain: epoch  1, batch    17 | loss: 8.5738525
CurrentTrain: epoch  1, batch    18 | loss: 8.8401871
CurrentTrain: epoch  1, batch    19 | loss: 8.8012505
CurrentTrain: epoch  1, batch    20 | loss: 8.9534941
CurrentTrain: epoch  1, batch    21 | loss: 8.7734394
CurrentTrain: epoch  1, batch    22 | loss: 8.3856926
CurrentTrain: epoch  1, batch    23 | loss: 7.7867908
CurrentTrain: epoch  1, batch    24 | loss: 8.2105236
CurrentTrain: epoch  1, batch    25 | loss: 8.5588417
CurrentTrain: epoch  1, batch    26 | loss: 8.2076626
CurrentTrain: epoch  1, batch    27 | loss: 9.3603249
CurrentTrain: epoch  1, batch    28 | loss: 7.9655094
CurrentTrain: epoch  1, batch    29 | loss: 9.0838776
CurrentTrain: epoch  1, batch    30 | loss: 8.3628798
CurrentTrain: epoch  1, batch    31 | loss: 8.0664501
CurrentTrain: epoch  1, batch    32 | loss: 8.1517239
CurrentTrain: epoch  1, batch    33 | loss: 7.4297657
CurrentTrain: epoch  1, batch    34 | loss: 7.6982636
CurrentTrain: epoch  1, batch    35 | loss: 8.1527796
CurrentTrain: epoch  1, batch    36 | loss: 8.2214308
CurrentTrain: epoch  1, batch    37 | loss: 8.6178246
CurrentTrain: epoch  2, batch     0 | loss: 8.1226301
CurrentTrain: epoch  2, batch     1 | loss: 8.3084698
CurrentTrain: epoch  2, batch     2 | loss: 8.0316963
CurrentTrain: epoch  2, batch     3 | loss: 8.0500917
CurrentTrain: epoch  2, batch     4 | loss: 8.2289238
CurrentTrain: epoch  2, batch     5 | loss: 7.3855429
CurrentTrain: epoch  2, batch     6 | loss: 7.6015353
CurrentTrain: epoch  2, batch     7 | loss: 8.4907990
CurrentTrain: epoch  2, batch     8 | loss: 7.4046979
CurrentTrain: epoch  2, batch     9 | loss: 7.9526167
CurrentTrain: epoch  2, batch    10 | loss: 8.6386967
CurrentTrain: epoch  2, batch    11 | loss: 7.6446152
CurrentTrain: epoch  2, batch    12 | loss: 7.5197120
CurrentTrain: epoch  2, batch    13 | loss: 7.5708265
CurrentTrain: epoch  2, batch    14 | loss: 7.0511937
CurrentTrain: epoch  2, batch    15 | loss: 7.2505779
CurrentTrain: epoch  2, batch    16 | loss: 8.2384539
CurrentTrain: epoch  2, batch    17 | loss: 7.4479733
CurrentTrain: epoch  2, batch    18 | loss: 8.3681459
CurrentTrain: epoch  2, batch    19 | loss: 7.6288462
CurrentTrain: epoch  2, batch    20 | loss: 8.1848164
CurrentTrain: epoch  2, batch    21 | loss: 8.2998886
CurrentTrain: epoch  2, batch    22 | loss: 6.6678123
CurrentTrain: epoch  2, batch    23 | loss: 7.5567398
CurrentTrain: epoch  2, batch    24 | loss: 7.1805491
CurrentTrain: epoch  2, batch    25 | loss: 7.2397885
CurrentTrain: epoch  2, batch    26 | loss: 7.3748751
CurrentTrain: epoch  2, batch    27 | loss: 8.1420879
CurrentTrain: epoch  2, batch    28 | loss: 7.3700409
CurrentTrain: epoch  2, batch    29 | loss: 7.3289447
CurrentTrain: epoch  2, batch    30 | loss: 7.8608675
CurrentTrain: epoch  2, batch    31 | loss: 7.4112296
CurrentTrain: epoch  2, batch    32 | loss: 6.5715413
CurrentTrain: epoch  2, batch    33 | loss: 7.7304668
CurrentTrain: epoch  2, batch    34 | loss: 7.6862307
CurrentTrain: epoch  2, batch    35 | loss: 7.3744669
CurrentTrain: epoch  2, batch    36 | loss: 7.6391673
CurrentTrain: epoch  2, batch    37 | loss: 7.6384230
CurrentTrain: epoch  3, batch     0 | loss: 6.9526005
CurrentTrain: epoch  3, batch     1 | loss: 6.9352446
CurrentTrain: epoch  3, batch     2 | loss: 7.5693951
CurrentTrain: epoch  3, batch     3 | loss: 7.5147963
CurrentTrain: epoch  3, batch     4 | loss: 7.5202107
CurrentTrain: epoch  3, batch     5 | loss: 6.6781216
CurrentTrain: epoch  3, batch     6 | loss: 7.8598270
CurrentTrain: epoch  3, batch     7 | loss: 7.0131717
CurrentTrain: epoch  3, batch     8 | loss: 7.0488162
CurrentTrain: epoch  3, batch     9 | loss: 6.5135937
CurrentTrain: epoch  3, batch    10 | loss: 7.0534897
CurrentTrain: epoch  3, batch    11 | loss: 7.1865802
CurrentTrain: epoch  3, batch    12 | loss: 6.2991724
CurrentTrain: epoch  3, batch    13 | loss: 6.7319489
CurrentTrain: epoch  3, batch    14 | loss: 6.6299314
CurrentTrain: epoch  3, batch    15 | loss: 6.9258633
CurrentTrain: epoch  3, batch    16 | loss: 6.9281969
CurrentTrain: epoch  3, batch    17 | loss: 6.6365776
CurrentTrain: epoch  3, batch    18 | loss: 7.0686121
CurrentTrain: epoch  3, batch    19 | loss: 6.9434662
CurrentTrain: epoch  3, batch    20 | loss: 6.4053082
CurrentTrain: epoch  3, batch    21 | loss: 7.6111193
CurrentTrain: epoch  3, batch    22 | loss: 7.0337820
CurrentTrain: epoch  3, batch    23 | loss: 6.7422271
CurrentTrain: epoch  3, batch    24 | loss: 6.8758883
CurrentTrain: epoch  3, batch    25 | loss: 7.1140866
CurrentTrain: epoch  3, batch    26 | loss: 6.8154402
CurrentTrain: epoch  3, batch    27 | loss: 7.3271408
CurrentTrain: epoch  3, batch    28 | loss: 7.0625839
CurrentTrain: epoch  3, batch    29 | loss: 6.8716898
CurrentTrain: epoch  3, batch    30 | loss: 6.3503251
CurrentTrain: epoch  3, batch    31 | loss: 6.2356133
CurrentTrain: epoch  3, batch    32 | loss: 6.5557985
CurrentTrain: epoch  3, batch    33 | loss: 7.9598713
CurrentTrain: epoch  3, batch    34 | loss: 6.9840403
CurrentTrain: epoch  3, batch    35 | loss: 7.0934377
CurrentTrain: epoch  3, batch    36 | loss: 7.0819778
CurrentTrain: epoch  3, batch    37 | loss: 6.5163021
CurrentTrain: epoch  4, batch     0 | loss: 7.1702003
CurrentTrain: epoch  4, batch     1 | loss: 7.1052094
CurrentTrain: epoch  4, batch     2 | loss: 6.6689324
CurrentTrain: epoch  4, batch     3 | loss: 6.9101954
CurrentTrain: epoch  4, batch     4 | loss: 7.0476985
CurrentTrain: epoch  4, batch     5 | loss: 6.3322759
CurrentTrain: epoch  4, batch     6 | loss: 6.4997368
CurrentTrain: epoch  4, batch     7 | loss: 6.7569389
CurrentTrain: epoch  4, batch     8 | loss: 6.3124533
CurrentTrain: epoch  4, batch     9 | loss: 6.8162212
CurrentTrain: epoch  4, batch    10 | loss: 6.4345541
CurrentTrain: epoch  4, batch    11 | loss: 6.3310432
CurrentTrain: epoch  4, batch    12 | loss: 5.9426465
CurrentTrain: epoch  4, batch    13 | loss: 6.1724405
CurrentTrain: epoch  4, batch    14 | loss: 6.6857653
CurrentTrain: epoch  4, batch    15 | loss: 6.5288429
CurrentTrain: epoch  4, batch    16 | loss: 6.7462583
CurrentTrain: epoch  4, batch    17 | loss: 6.7955780
CurrentTrain: epoch  4, batch    18 | loss: 6.7017679
CurrentTrain: epoch  4, batch    19 | loss: 6.6497822
CurrentTrain: epoch  4, batch    20 | loss: 6.7515059
CurrentTrain: epoch  4, batch    21 | loss: 5.4568396
CurrentTrain: epoch  4, batch    22 | loss: 6.7425737
CurrentTrain: epoch  4, batch    23 | loss: 7.4248905
CurrentTrain: epoch  4, batch    24 | loss: 6.8030601
CurrentTrain: epoch  4, batch    25 | loss: 5.7128201
CurrentTrain: epoch  4, batch    26 | loss: 6.0901766
CurrentTrain: epoch  4, batch    27 | loss: 6.0195417
CurrentTrain: epoch  4, batch    28 | loss: 5.8877831
CurrentTrain: epoch  4, batch    29 | loss: 5.9017639
CurrentTrain: epoch  4, batch    30 | loss: 5.9644861
CurrentTrain: epoch  4, batch    31 | loss: 6.3193359
CurrentTrain: epoch  4, batch    32 | loss: 6.4298000
CurrentTrain: epoch  4, batch    33 | loss: 6.3905287
CurrentTrain: epoch  4, batch    34 | loss: 5.6124401
CurrentTrain: epoch  4, batch    35 | loss: 6.1344948
CurrentTrain: epoch  4, batch    36 | loss: 6.2416821
CurrentTrain: epoch  4, batch    37 | loss: 6.7295990
CurrentTrain: epoch  5, batch     0 | loss: 6.0638447
CurrentTrain: epoch  5, batch     1 | loss: 6.5099201
CurrentTrain: epoch  5, batch     2 | loss: 6.3294730
CurrentTrain: epoch  5, batch     3 | loss: 5.9556818
CurrentTrain: epoch  5, batch     4 | loss: 5.5878048
CurrentTrain: epoch  5, batch     5 | loss: 6.4758449
CurrentTrain: epoch  5, batch     6 | loss: 6.0975027
CurrentTrain: epoch  5, batch     7 | loss: 6.6805487
CurrentTrain: epoch  5, batch     8 | loss: 5.6297979
CurrentTrain: epoch  5, batch     9 | loss: 5.8817210
CurrentTrain: epoch  5, batch    10 | loss: 5.3463736
CurrentTrain: epoch  5, batch    11 | loss: 6.0796318
CurrentTrain: epoch  5, batch    12 | loss: 6.1611595
CurrentTrain: epoch  5, batch    13 | loss: 5.8811350
CurrentTrain: epoch  5, batch    14 | loss: 6.4045796
CurrentTrain: epoch  5, batch    15 | loss: 5.6460304
CurrentTrain: epoch  5, batch    16 | loss: 5.6028724
CurrentTrain: epoch  5, batch    17 | loss: 6.0058813
CurrentTrain: epoch  5, batch    18 | loss: 5.4141655
CurrentTrain: epoch  5, batch    19 | loss: 6.2086625
CurrentTrain: epoch  5, batch    20 | loss: 5.7103853
CurrentTrain: epoch  5, batch    21 | loss: 6.1477237
CurrentTrain: epoch  5, batch    22 | loss: 5.3158579
CurrentTrain: epoch  5, batch    23 | loss: 6.4904366
CurrentTrain: epoch  5, batch    24 | loss: 5.8449993
CurrentTrain: epoch  5, batch    25 | loss: 5.8837261
CurrentTrain: epoch  5, batch    26 | loss: 5.7056332
CurrentTrain: epoch  5, batch    27 | loss: 5.8060641
CurrentTrain: epoch  5, batch    28 | loss: 5.5694952
CurrentTrain: epoch  5, batch    29 | loss: 5.5440083
CurrentTrain: epoch  5, batch    30 | loss: 5.0780563
CurrentTrain: epoch  5, batch    31 | loss: 6.9819088
CurrentTrain: epoch  5, batch    32 | loss: 5.5653896
CurrentTrain: epoch  5, batch    33 | loss: 5.9810810
CurrentTrain: epoch  5, batch    34 | loss: 5.7205348
CurrentTrain: epoch  5, batch    35 | loss: 5.6590934
CurrentTrain: epoch  5, batch    36 | loss: 5.4188609
CurrentTrain: epoch  5, batch    37 | loss: 5.6370058
CurrentTrain: epoch  6, batch     0 | loss: 6.1358523
CurrentTrain: epoch  6, batch     1 | loss: 5.4234552
CurrentTrain: epoch  6, batch     2 | loss: 5.5030365
CurrentTrain: epoch  6, batch     3 | loss: 5.4956236
CurrentTrain: epoch  6, batch     4 | loss: 5.3796434
CurrentTrain: epoch  6, batch     5 | loss: 5.8246398
CurrentTrain: epoch  6, batch     6 | loss: 5.3124366
CurrentTrain: epoch  6, batch     7 | loss: 5.3673453
CurrentTrain: epoch  6, batch     8 | loss: 5.1170020
CurrentTrain: epoch  6, batch     9 | loss: 5.5554328
CurrentTrain: epoch  6, batch    10 | loss: 5.4514837
CurrentTrain: epoch  6, batch    11 | loss: 5.2072983
CurrentTrain: epoch  6, batch    12 | loss: 5.5819921
CurrentTrain: epoch  6, batch    13 | loss: 5.5284238
CurrentTrain: epoch  6, batch    14 | loss: 5.5129395
CurrentTrain: epoch  6, batch    15 | loss: 5.5518851
CurrentTrain: epoch  6, batch    16 | loss: 5.8723001
CurrentTrain: epoch  6, batch    17 | loss: 5.8069162
CurrentTrain: epoch  6, batch    18 | loss: 5.9898615
CurrentTrain: epoch  6, batch    19 | loss: 5.3905783
CurrentTrain: epoch  6, batch    20 | loss: 5.5957661
CurrentTrain: epoch  6, batch    21 | loss: 5.2736311
CurrentTrain: epoch  6, batch    22 | loss: 5.6877246
CurrentTrain: epoch  6, batch    23 | loss: 5.3700190
CurrentTrain: epoch  6, batch    24 | loss: 5.9099770
CurrentTrain: epoch  6, batch    25 | loss: 5.9062252
CurrentTrain: epoch  6, batch    26 | loss: 5.0880518
CurrentTrain: epoch  6, batch    27 | loss: 6.3377171
CurrentTrain: epoch  6, batch    28 | loss: 5.6386800
CurrentTrain: epoch  6, batch    29 | loss: 5.2615800
CurrentTrain: epoch  6, batch    30 | loss: 5.7328978
CurrentTrain: epoch  6, batch    31 | loss: 5.7445903
CurrentTrain: epoch  6, batch    32 | loss: 5.4329548
CurrentTrain: epoch  6, batch    33 | loss: 5.4067039
CurrentTrain: epoch  6, batch    34 | loss: 5.7061162
CurrentTrain: epoch  6, batch    35 | loss: 5.5632606
CurrentTrain: epoch  6, batch    36 | loss: 6.0420170
CurrentTrain: epoch  6, batch    37 | loss: 4.8924651
CurrentTrain: epoch  7, batch     0 | loss: 5.3223524
CurrentTrain: epoch  7, batch     1 | loss: 5.2712803
CurrentTrain: epoch  7, batch     2 | loss: 5.1291885
CurrentTrain: epoch  7, batch     3 | loss: 5.5866871
CurrentTrain: epoch  7, batch     4 | loss: 5.2703133
CurrentTrain: epoch  7, batch     5 | loss: 5.2885656
CurrentTrain: epoch  7, batch     6 | loss: 5.2503104
CurrentTrain: epoch  7, batch     7 | loss: 5.1253343
CurrentTrain: epoch  7, batch     8 | loss: 5.4255157
CurrentTrain: epoch  7, batch     9 | loss: 5.2402787
CurrentTrain: epoch  7, batch    10 | loss: 5.3399220
CurrentTrain: epoch  7, batch    11 | loss: 5.2283945
CurrentTrain: epoch  7, batch    12 | loss: 5.7639842
CurrentTrain: epoch  7, batch    13 | loss: 5.0452366
CurrentTrain: epoch  7, batch    14 | loss: 5.3695588
CurrentTrain: epoch  7, batch    15 | loss: 5.0102339
CurrentTrain: epoch  7, batch    16 | loss: 4.9660373
CurrentTrain: epoch  7, batch    17 | loss: 5.1004190
CurrentTrain: epoch  7, batch    18 | loss: 5.7913666
CurrentTrain: epoch  7, batch    19 | loss: 5.0827866
CurrentTrain: epoch  7, batch    20 | loss: 5.2652025
CurrentTrain: epoch  7, batch    21 | loss: 5.1868858
CurrentTrain: epoch  7, batch    22 | loss: 5.8795671
CurrentTrain: epoch  7, batch    23 | loss: 5.2625484
CurrentTrain: epoch  7, batch    24 | loss: 5.3696251
CurrentTrain: epoch  7, batch    25 | loss: 5.0030622
CurrentTrain: epoch  7, batch    26 | loss: 5.2823572
CurrentTrain: epoch  7, batch    27 | loss: 5.8802376
CurrentTrain: epoch  7, batch    28 | loss: 5.4402351
CurrentTrain: epoch  7, batch    29 | loss: 5.2253008
CurrentTrain: epoch  7, batch    30 | loss: 4.9519720
CurrentTrain: epoch  7, batch    31 | loss: 5.4786401
CurrentTrain: epoch  7, batch    32 | loss: 5.0609975
CurrentTrain: epoch  7, batch    33 | loss: 5.5265512
CurrentTrain: epoch  7, batch    34 | loss: 5.4148798
CurrentTrain: epoch  7, batch    35 | loss: 5.3916426
CurrentTrain: epoch  7, batch    36 | loss: 5.6798849
CurrentTrain: epoch  7, batch    37 | loss: 4.9304237
CurrentTrain: epoch  8, batch     0 | loss: 5.2661433
CurrentTrain: epoch  8, batch     1 | loss: 5.2813563
CurrentTrain: epoch  8, batch     2 | loss: 4.9945636
CurrentTrain: epoch  8, batch     3 | loss: 5.0611744
CurrentTrain: epoch  8, batch     4 | loss: 5.0330563
CurrentTrain: epoch  8, batch     5 | loss: 5.1592002
CurrentTrain: epoch  8, batch     6 | loss: 5.0671940
CurrentTrain: epoch  8, batch     7 | loss: 5.3456912
CurrentTrain: epoch  8, batch     8 | loss: 5.5755839
CurrentTrain: epoch  8, batch     9 | loss: 4.9678736
CurrentTrain: epoch  8, batch    10 | loss: 5.3238401
CurrentTrain: epoch  8, batch    11 | loss: 5.3905330
CurrentTrain: epoch  8, batch    12 | loss: 5.1274366
CurrentTrain: epoch  8, batch    13 | loss: 5.2200403
CurrentTrain: epoch  8, batch    14 | loss: 5.0500274
CurrentTrain: epoch  8, batch    15 | loss: 5.3302779
CurrentTrain: epoch  8, batch    16 | loss: 5.3767262
CurrentTrain: epoch  8, batch    17 | loss: 5.0386205
CurrentTrain: epoch  8, batch    18 | loss: 5.1632056
CurrentTrain: epoch  8, batch    19 | loss: 4.9310617
CurrentTrain: epoch  8, batch    20 | loss: 5.0625210
CurrentTrain: epoch  8, batch    21 | loss: 4.9970398
CurrentTrain: epoch  8, batch    22 | loss: 5.2432747
CurrentTrain: epoch  8, batch    23 | loss: 4.9008179
CurrentTrain: epoch  8, batch    24 | loss: 5.0348969
CurrentTrain: epoch  8, batch    25 | loss: 5.9137144
CurrentTrain: epoch  8, batch    26 | loss: 4.9745903
CurrentTrain: epoch  8, batch    27 | loss: 4.9717259
CurrentTrain: epoch  8, batch    28 | loss: 4.9230428
CurrentTrain: epoch  8, batch    29 | loss: 5.0081944
CurrentTrain: epoch  8, batch    30 | loss: 4.8410225
CurrentTrain: epoch  8, batch    31 | loss: 5.3595600
CurrentTrain: epoch  8, batch    32 | loss: 5.0667229
CurrentTrain: epoch  8, batch    33 | loss: 5.3267832
CurrentTrain: epoch  8, batch    34 | loss: 5.8288541
CurrentTrain: epoch  8, batch    35 | loss: 4.8750610
CurrentTrain: epoch  8, batch    36 | loss: 5.0870757
CurrentTrain: epoch  8, batch    37 | loss: 4.8982739
CurrentTrain: epoch  9, batch     0 | loss: 5.0278521
CurrentTrain: epoch  9, batch     1 | loss: 5.0443730
CurrentTrain: epoch  9, batch     2 | loss: 5.1203442
CurrentTrain: epoch  9, batch     3 | loss: 4.9747372
CurrentTrain: epoch  9, batch     4 | loss: 4.9550591
CurrentTrain: epoch  9, batch     5 | loss: 4.9425640
CurrentTrain: epoch  9, batch     6 | loss: 5.1590147
CurrentTrain: epoch  9, batch     7 | loss: 4.9942837
CurrentTrain: epoch  9, batch     8 | loss: 5.1984777
CurrentTrain: epoch  9, batch     9 | loss: 5.0505915
CurrentTrain: epoch  9, batch    10 | loss: 4.9431801
CurrentTrain: epoch  9, batch    11 | loss: 4.9884076
CurrentTrain: epoch  9, batch    12 | loss: 4.8272181
CurrentTrain: epoch  9, batch    13 | loss: 5.0113335
CurrentTrain: epoch  9, batch    14 | loss: 4.9350376
CurrentTrain: epoch  9, batch    15 | loss: 5.2500772
CurrentTrain: epoch  9, batch    16 | loss: 4.8563576
CurrentTrain: epoch  9, batch    17 | loss: 4.9644494
CurrentTrain: epoch  9, batch    18 | loss: 5.4033704
CurrentTrain: epoch  9, batch    19 | loss: 4.7974510
CurrentTrain: epoch  9, batch    20 | loss: 5.0202074
CurrentTrain: epoch  9, batch    21 | loss: 4.9257131
CurrentTrain: epoch  9, batch    22 | loss: 4.9508648
CurrentTrain: epoch  9, batch    23 | loss: 4.9035320
CurrentTrain: epoch  9, batch    24 | loss: 5.0091434
CurrentTrain: epoch  9, batch    25 | loss: 5.0253158
CurrentTrain: epoch  9, batch    26 | loss: 4.8755970
CurrentTrain: epoch  9, batch    27 | loss: 5.0673437
CurrentTrain: epoch  9, batch    28 | loss: 4.8139763
CurrentTrain: epoch  9, batch    29 | loss: 4.8387389
CurrentTrain: epoch  9, batch    30 | loss: 5.2106128
CurrentTrain: epoch  9, batch    31 | loss: 5.0102196
CurrentTrain: epoch  9, batch    32 | loss: 5.2474909
CurrentTrain: epoch  9, batch    33 | loss: 4.9042397
CurrentTrain: epoch  9, batch    34 | loss: 4.7741499
CurrentTrain: epoch  9, batch    35 | loss: 4.8608227
CurrentTrain: epoch  9, batch    36 | loss: 4.8348632
CurrentTrain: epoch  9, batch    37 | loss: 4.8774786
#### person countries of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person countries of residence" means a person is living in a country.
Here is an example:
Relation: person countries of residence
Context: embattled us attorney general alberto gonzales formally announced his resignation on monday , after months at the center of a raging political storm .
Head Entity: alberto gonzales
Tail Entity: us
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person countries of residence":
Relation: person countries of residence  
Context: After years of living in Paris, the renowned artist decided to return to his hometown in Italy.  
Head Entity: the renowned artist  
Tail Entity: Italy  

Relation: person countries of residence  
Context: Following her studies in London, she moved to Canada to start her career in technology.  
Head Entity: she  
Tail Entity: Canada  

Relation: person countries of residence  
Context: The famous actor has been residing in Australia for the past few years while filming his latest movie.  
Head Entity: The famous actor  
Tail Entity: Australia  

Relation: person countries of residence  
Context: After spending a decade in Japan, the scientist relocated to Germany for a new research opportunity.  
Head Entity: the scientist  
Tail Entity: Germany  

Relation: person countries of residence  
Context: He has lived in Brazil for most of his life, enjoying the vibrant culture and beautiful landscapes.  
Head Entity: He  
Tail Entity: Brazil  
#### organization top members employees ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization top members employees" means an organization 's employer is a person.
Here is an example:
Relation: organization top members employees
Context: `` the fdic has good intentions , and they are probably demonstrating things that can be done better , '' said bob davis , an executive vice president with the american bankers association .
Head Entity: american bankers association
Tail Entity: bob davis
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization top members employees":
Relation: organization top members employees  
Context: "During the annual meeting, the CEO of Tech Innovations, Sarah Lee, highlighted the contributions of her team."  
Head Entity: Tech Innovations  
Tail Entity: Sarah Lee  

Relation: organization top members employees  
Context: "In a recent interview, John Smith, the Chief Financial Officer of Global Finance Corp, discussed the company's growth strategies."  
Head Entity: Global Finance Corp  
Tail Entity: John Smith  

Relation: organization top members employees  
Context: "The board of directors praised Maria Gonzalez, the head of marketing at Creative Solutions, for her innovative campaigns."  
Head Entity: Creative Solutions  
Tail Entity: Maria Gonzalez  

Relation: organization top members employees  
Context: "At the charity gala, the founder of Green Earth Initiative, Tom Richards, spoke about the importance of sustainability."  
Head Entity: Green Earth Initiative  
Tail Entity: Tom Richards  

Relation: organization top members employees  
Context: "The conference featured a keynote speech by Dr. Emily Chen, the lead researcher at BioHealth Labs, on recent medical advancements."  
Head Entity: BioHealth Labs  
Tail Entity: Dr. Emily Chen  
#### organization member of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization member of" means an organization is the member of an organization.
Here is an example:
Relation: organization member of
Context: rookie steve slaton rushed for 130 yards and two touchdowns monday as the houston texans trounced the jacksonville jaguars 30-17 in a national football league contest .
Head Entity: jacksonville jaguars
Tail Entity: national football league
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization member of":
Relation: organization member of  
Context: the united nations is an international organization founded in 1945 and currently has 193 member states.  
Head Entity: united nations  
Tail Entity: member states  

Relation: organization member of  
Context: the european union is a political and economic union of 27 member countries located primarily in europe.  
Head Entity: european union  
Tail Entity: member countries  

Relation: organization member of  
Context: the world health organization works with various member nations to improve global health standards and responses to health emergencies.  
Head Entity: world health organization  
Tail Entity: member nations  

Relation: organization member of  
Context: the national basketball association consists of 30 teams, each representing a different city or region in the united states and canada.  
Head Entity: national basketball association  
Tail Entity: teams  

Relation: organization member of  
Context: the international olympic committee oversees the organization of the olympic games and has numerous national committees as its members.  
Head Entity: international olympic committee  
Tail Entity: national committees  
#### person origin ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person origin" means a person 's nationality is a country.
Here is an example:
Relation: person origin
Context: the former detainee , murat kurnaz , was turned over to german authorities and freed in 2006 after a personal plea from german chancellor angela merkel .
Head Entity: murat kurnaz
Tail Entity: german
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person origin":
Relation: person origin  
Context: The renowned physicist Albert Einstein was born in the Kingdom of Württemberg in the German Empire.  
Head Entity: Albert Einstein  
Tail Entity: German  

Relation: person origin  
Context: The famous author Gabriel García Márquez was born in Aracataca, Colombia, where he drew inspiration for many of his works.  
Head Entity: Gabriel García Márquez  
Tail Entity: Colombian  

Relation: person origin  
Context: The celebrated artist Frida Kahlo was born in Coyoacán, Mexico, and is known for her unique style and contributions to art.  
Head Entity: Frida Kahlo  
Tail Entity: Mexican  

Relation: person origin  
Context: The legendary musician Bob Marley was born in Nine Mile, Jamaica, and became a global icon of reggae music.  
Head Entity: Bob Marley  
Tail Entity: Jamaican  

Relation: person origin  
Context: The influential civil rights leader Nelson Mandela was born in the village of Mvezo in South Africa, where he began his journey towards activism.  
Head Entity: Nelson Mandela  
Tail Entity: South African  
#### person title ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person title" means a person 's title is a title.
Here is an example:
Relation: person title
Context: `` making the amendment retroactive will ... help repair the image of the sentencing guidelines in communities of color , '' naacp chairman julian bond wrote to the commission .
Head Entity: julian bond
Tail Entity: chairman
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person title":
Relation: person title  
Context: `` After years of dedicated service, the board appointed Dr. Emily Carter as the new president of the university. ''  
Head Entity: Dr. Emily Carter  
Tail Entity: president  

Relation: person title  
Context: `` In her latest book, renowned author Sarah Johnson shares her journey as a leading voice in contemporary literature. ''  
Head Entity: Sarah Johnson  
Tail Entity: author  

Relation: person title  
Context: `` During the annual meeting, the committee recognized Michael Lee for his outstanding contributions as the chief financial officer. ''  
Head Entity: Michael Lee  
Tail Entity: chief financial officer  

Relation: person title  
Context: `` The city council elected Maria Gonzalez to serve as the new mayor, marking a significant milestone in local governance. ''  
Head Entity: Maria Gonzalez  
Tail Entity: mayor  

Relation: person title  
Context: `` As the head of the research department, Dr. Alan Smith has been instrumental in advancing the field of biotechnology. ''  
Head Entity: Dr. Alan Smith  
Tail Entity: head of the research department  
#### organization country of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization country of headquarters" means an organization is located in a country.
Here is an example:
Relation: organization country of headquarters
Context: baghdad , oct 3 -lrb- xinhua -rrb- the irgc-qf attempts to destabilize the government of iraq , through iran 's `` militia-proxies '' inside iraq , it added .
Head Entity: irgc-qf
Tail Entity: iran
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization country of headquarters":
Relation: organization country of headquarters  
Context: in a recent report, the world health organization highlighted the need for improved healthcare systems in developing nations.  
Head Entity: world health organization  
Tail Entity: developing nations  

Relation: organization country of headquarters  
Context: the headquarters of the international monetary fund is located in Washington, D.C., which plays a crucial role in global economic stability.  
Head Entity: international monetary fund  
Tail Entity: Washington, D.C.  

Relation: organization country of headquarters  
Context: google has expanded its operations significantly in the united states, establishing multiple offices across the country.  
Head Entity: google  
Tail Entity: united states  

Relation: organization country of headquarters  
Context: the united nations is headquartered in new york city, where it conducts its international diplomatic activities.  
Head Entity: united nations  
Tail Entity: new york city  

Relation: organization country of headquarters  
Context: the european space agency, known for its innovative space missions, is based in paris, france.  
Head Entity: european space agency  
Tail Entity: france  
[EVAL] batch:    0 | acc: 87.50%,  total acc: 87.50%   
[EVAL] batch:    1 | acc: 81.25%,  total acc: 84.38%   
[EVAL] batch:    2 | acc: 81.25%,  total acc: 83.33%   
[EVAL] batch:    3 | acc: 87.50%,  total acc: 84.38%   
[EVAL] batch:    4 | acc: 87.50%,  total acc: 85.00%   
[EVAL] batch:    5 | acc: 75.00%,  total acc: 83.33%   
[EVAL] batch:    6 | acc: 100.00%,  total acc: 85.71%   
[EVAL] batch:    7 | acc: 100.00%,  total acc: 87.50%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 88.89%   
[EVAL] batch:    9 | acc: 93.75%,  total acc: 89.38%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 90.34%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 90.62%   
[EVAL] batch:   12 | acc: 93.75%,  total acc: 90.87%   
[EVAL] batch:   13 | acc: 68.75%,  total acc: 89.29%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 88.33%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 86.33%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 85.66%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 84.38%   
[EVAL] batch:   18 | acc: 81.25%,  total acc: 84.21%   
[EVAL] batch:   19 | acc: 75.00%,  total acc: 83.75%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 84.52%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 85.23%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 85.87%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 86.46%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 87.00%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 87.50%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 87.73%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 88.17%   
[EVAL] batch:   28 | acc: 100.00%,  total acc: 88.58%   
[EVAL] batch:   29 | acc: 87.50%,  total acc: 88.54%   
[EVAL] batch:   30 | acc: 81.25%,  total acc: 88.31%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 88.48%   
[EVAL] batch:   32 | acc: 37.50%,  total acc: 86.93%   
[EVAL] batch:    0 | acc: 87.50%,  total acc: 87.50%   
[EVAL] batch:    1 | acc: 81.25%,  total acc: 84.38%   
[EVAL] batch:    2 | acc: 81.25%,  total acc: 83.33%   
[EVAL] batch:    3 | acc: 87.50%,  total acc: 84.38%   
[EVAL] batch:    4 | acc: 87.50%,  total acc: 85.00%   
[EVAL] batch:    5 | acc: 75.00%,  total acc: 83.33%   
[EVAL] batch:    6 | acc: 100.00%,  total acc: 85.71%   
[EVAL] batch:    7 | acc: 100.00%,  total acc: 87.50%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 88.89%   
[EVAL] batch:    9 | acc: 93.75%,  total acc: 89.38%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 90.34%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 90.62%   
[EVAL] batch:   12 | acc: 93.75%,  total acc: 90.87%   
[EVAL] batch:   13 | acc: 68.75%,  total acc: 89.29%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 88.33%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 86.33%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 85.66%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 84.38%   
[EVAL] batch:   18 | acc: 81.25%,  total acc: 84.21%   
[EVAL] batch:   19 | acc: 75.00%,  total acc: 83.75%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 84.52%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 85.23%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 85.87%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 86.46%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 87.00%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 87.50%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 87.73%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 88.17%   
[EVAL] batch:   28 | acc: 100.00%,  total acc: 88.58%   
[EVAL] batch:   29 | acc: 87.50%,  total acc: 88.54%   
[EVAL] batch:   30 | acc: 81.25%,  total acc: 88.31%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 88.48%   
[EVAL] batch:   32 | acc: 37.50%,  total acc: 86.93%   
cur_acc:  ['0.8693']
his_acc:  ['0.8693']
CurrentTrain: epoch  0, batch     0 | loss: 7.2450051
CurrentTrain: epoch  0, batch     1 | loss: 5.7905478
CurrentTrain: epoch  1, batch     0 | loss: 5.5444226
CurrentTrain: epoch  1, batch     1 | loss: 6.5063052
CurrentTrain: epoch  2, batch     0 | loss: 5.4093285
CurrentTrain: epoch  2, batch     1 | loss: 4.8179345
CurrentTrain: epoch  3, batch     0 | loss: 4.9402122
CurrentTrain: epoch  3, batch     1 | loss: 4.6359363
CurrentTrain: epoch  4, batch     0 | loss: 4.2216988
CurrentTrain: epoch  4, batch     1 | loss: 4.9159369
CurrentTrain: epoch  5, batch     0 | loss: 3.8588192
CurrentTrain: epoch  5, batch     1 | loss: 3.8879464
CurrentTrain: epoch  6, batch     0 | loss: 3.8960366
CurrentTrain: epoch  6, batch     1 | loss: 3.4131196
CurrentTrain: epoch  7, batch     0 | loss: 3.7177508
CurrentTrain: epoch  7, batch     1 | loss: 2.9366570
CurrentTrain: epoch  8, batch     0 | loss: 3.6196628
CurrentTrain: epoch  8, batch     1 | loss: 3.5788906
CurrentTrain: epoch  9, batch     0 | loss: 3.2791355
CurrentTrain: epoch  9, batch     1 | loss: 2.7208090
#### person cities of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person cities of residence" means a person is living in a city.
Here is an example:
Relation: person cities of residence
Context: tv-idol-johns -- atlanta -- `` american idol '' finalist michael johns moved to los angeles several years ago , but his heart is still in atlanta .
Head Entity: his
Tail Entity: atlanta
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person cities of residence":
Relation: person cities of residence  
Context: after years of living in new york city, the famous author decided to return to her hometown of boston, where she feels most at home.  
Head Entity: she  
Tail Entity: boston  

Relation: person cities of residence  
Context: despite being born in chicago, the musician has spent most of his adult life in nashville, where he finds inspiration for his songs.  
Head Entity: he  
Tail Entity: nashville  

Relation: person cities of residence  
Context: the tech entrepreneur moved from san francisco to a quieter life in austin, seeking a balance between work and personal life.  
Head Entity: he  
Tail Entity: austin  

Relation: person cities of residence  
Context: after graduating from college in los angeles, the actress decided to settle down in san diego, enjoying the beach lifestyle.  
Head Entity: she  
Tail Entity: san diego  

Relation: person cities of residence  
Context: although he grew up in seattle, the athlete now resides in miami, where he trains year-round for his upcoming competitions.  
Head Entity: he  
Tail Entity: miami  
#### person schools attended ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person schools attended" means a person 's school is an organization.
Here is an example:
Relation: person schools attended
Context: after world war ii , he attended the university of southern california , where he became editor of a college magazine .
Head Entity: he
Tail Entity: university of southern california
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person schools attended":
Relation: person schools attended  
Context: She graduated from Harvard University with a degree in economics before pursuing her career in finance.  
Head Entity: She  
Tail Entity: Harvard University  

Relation: person schools attended  
Context: After completing his high school education, John enrolled at Stanford University to study computer science.  
Head Entity: John  
Tail Entity: Stanford University  

Relation: person schools attended  
Context: Maria attended the University of Oxford for her postgraduate studies in literature, where she developed her passion for writing.  
Head Entity: Maria  
Tail Entity: University of Oxford  

Relation: person schools attended  
Context: Following his time in the military, he went to the Massachusetts Institute of Technology to study engineering.  
Head Entity: he  
Tail Entity: Massachusetts Institute of Technology  

Relation: person schools attended  
Context: During her youth, she was a student at the Royal College of Art, which greatly influenced her artistic style.  
Head Entity: she  
Tail Entity: Royal College of Art  
#### person country of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person country of death" means a person was died in a country.
Here is an example:
Relation: person country of death
Context: us republican congresswoman jo ann davis dies after fight with breast cancer
Head Entity: jo ann davis
Tail Entity: us
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person country of death":
1. Relation: person country of death  
   Context: renowned physicist stephen hawking passed away in cambridge, england.  
   Head Entity: stephen hawking  
   Tail Entity: england  

2. Relation: person country of death  
   Context: famous singer freddie mercury died in his home in london, united kingdom.  
   Head Entity: freddie mercury  
   Tail Entity: united kingdom  

3. Relation: person country of death  
   Context: beloved author agatha christie breathed her last in wallingford, england.  
   Head Entity: agatha christie  
   Tail Entity: england  

4. Relation: person country of death  
   Context: legendary actor robin williams was found dead in his home in california, usa.  
   Head Entity: robin williams  
   Tail Entity: usa  

5. Relation: person country of death  
   Context: influential civil rights leader martin luther king jr. was assassinated in memphis, tennessee, usa.  
   Head Entity: martin luther king jr.  
   Tail Entity: usa  
#### person children ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person children" means a person 's children is a person.
Here is an example:
Relation: person children
Context: he is survived by two stepdaughters , barbara a. hammond and brenda l. stevenson ; a stepson , michael a. taylor ; two grandchildren and one great-grandchild .
Head Entity: he
Tail Entity: brenda l. stevenson
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person children":
Relation: person children  
Context: she has three children, including her son, john, and her daughters, emily and sarah, who are both very talented.  
Head Entity: she  
Tail Entity: emily  

Relation: person children  
Context: after the passing of their father, the siblings, including jake and his sister, lila, took care of their mother.  
Head Entity: jake  
Tail Entity: lila  

Relation: person children  
Context: the famous author often mentioned his daughter, katherine, in interviews, highlighting her achievements.  
Head Entity: the famous author  
Tail Entity: katherine  

Relation: person children  
Context: during the family reunion, uncle tom proudly introduced his grandchildren, including little max and his sister, lily.  
Head Entity: uncle tom  
Tail Entity: lily  

Relation: person children  
Context: after the divorce, she made sure her son, aiden, and daughter, mia, had everything they needed to thrive.  
Head Entity: she  
Tail Entity: mia  
#### person charges ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person charges" means a person was charged with an event.
Here is an example:
Relation: person charges
Context: flowers always contended politics was behind the extortion investigation , but appeals courts ruled against him .
Head Entity: him
Tail Entity: extortion
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person charges":
Relation: person charges  
Context: The prosecutor announced that the former mayor was charged with corruption after a lengthy investigation.  
Head Entity: former mayor  
Tail Entity: corruption  

Relation: person charges  
Context: After the incident, the police confirmed that the suspect was charged with assault and battery.  
Head Entity: suspect  
Tail Entity: assault and battery  

Relation: person charges  
Context: The district attorney revealed that the celebrity was charged with DUI following the car accident.  
Head Entity: celebrity  
Tail Entity: DUI  

Relation: person charges  
Context: Following the investigation, the authorities stated that the accountant was charged with fraud.  
Head Entity: accountant  
Tail Entity: fraud  

Relation: person charges  
Context: The judge announced that the activist was charged with trespassing during the protest.  
Head Entity: activist  
Tail Entity: trespassing  
Mixup data size:  3730
MixupTrain:  epoch  0, batch     0 | loss: 4.8618546
MixupTrain:  epoch  0, batch     1 | loss: 5.4536619
MixupTrain:  epoch  0, batch     2 | loss: 5.7928691
MixupTrain:  epoch  0, batch     3 | loss: 4.7845173
MixupTrain:  epoch  0, batch     4 | loss: 5.2646775
MixupTrain:  epoch  0, batch     5 | loss: 4.2236061
MixupTrain:  epoch  0, batch     6 | loss: 4.0240669
MixupTrain:  epoch  0, batch     7 | loss: 4.2975712
MixupTrain:  epoch  0, batch     8 | loss: 4.3882933
MixupTrain:  epoch  0, batch     9 | loss: 4.1490097
MixupTrain:  epoch  0, batch    10 | loss: 4.3844781
MixupTrain:  epoch  0, batch    11 | loss: 3.9060097
MixupTrain:  epoch  0, batch    12 | loss: 4.0085201
MixupTrain:  epoch  0, batch    13 | loss: 4.3158417
MixupTrain:  epoch  0, batch    14 | loss: 3.7579141
MixupTrain:  epoch  0, batch    15 | loss: 3.7668345
MixupTrain:  epoch  0, batch    16 | loss: 4.0395126
MixupTrain:  epoch  0, batch    17 | loss: 3.8193855
MixupTrain:  epoch  0, batch    18 | loss: 3.8673115
MixupTrain:  epoch  0, batch    19 | loss: 4.5005040
MixupTrain:  epoch  0, batch    20 | loss: 3.1874335
MixupTrain:  epoch  0, batch    21 | loss: 3.4074385
MixupTrain:  epoch  0, batch    22 | loss: 3.6086171
MixupTrain:  epoch  0, batch    23 | loss: 3.2574468
MixupTrain:  epoch  0, batch    24 | loss: 3.5126340
MixupTrain:  epoch  0, batch    25 | loss: 3.7199659
MixupTrain:  epoch  0, batch    26 | loss: 3.1396148
MixupTrain:  epoch  0, batch    27 | loss: 3.5019186
MixupTrain:  epoch  0, batch    28 | loss: 3.2600727
MixupTrain:  epoch  0, batch    29 | loss: 3.1144166
MixupTrain:  epoch  0, batch    30 | loss: 3.3687947
MixupTrain:  epoch  0, batch    31 | loss: 3.3179240
MixupTrain:  epoch  0, batch    32 | loss: 3.1930106
MixupTrain:  epoch  0, batch    33 | loss: 2.9816203
MixupTrain:  epoch  0, batch    34 | loss: 2.6053414
MixupTrain:  epoch  0, batch    35 | loss: 2.7501731
MixupTrain:  epoch  0, batch    36 | loss: 3.3116529
MixupTrain:  epoch  0, batch    37 | loss: 3.4396434
MixupTrain:  epoch  0, batch    38 | loss: 3.0615859
MixupTrain:  epoch  0, batch    39 | loss: 3.1292002
MixupTrain:  epoch  0, batch    40 | loss: 3.0593495
MixupTrain:  epoch  0, batch    41 | loss: 3.0755408
MixupTrain:  epoch  0, batch    42 | loss: 2.9460113
MixupTrain:  epoch  0, batch    43 | loss: 2.9233470
MixupTrain:  epoch  0, batch    44 | loss: 2.6270962
MixupTrain:  epoch  0, batch    45 | loss: 3.0563021
MixupTrain:  epoch  0, batch    46 | loss: 3.0829759
MixupTrain:  epoch  0, batch    47 | loss: 2.9965072
MixupTrain:  epoch  0, batch    48 | loss: 2.7459595
MixupTrain:  epoch  0, batch    49 | loss: 2.5337360
MixupTrain:  epoch  0, batch    50 | loss: 2.8101554
MixupTrain:  epoch  0, batch    51 | loss: 2.8230586
MixupTrain:  epoch  0, batch    52 | loss: 2.8283687
MixupTrain:  epoch  0, batch    53 | loss: 2.9169822
MixupTrain:  epoch  0, batch    54 | loss: 3.1173239
MixupTrain:  epoch  0, batch    55 | loss: 2.8235254
MixupTrain:  epoch  0, batch    56 | loss: 2.7240148
MixupTrain:  epoch  0, batch    57 | loss: 2.7922440
MixupTrain:  epoch  0, batch    58 | loss: 2.7162805
MixupTrain:  epoch  0, batch    59 | loss: 2.8770680
MixupTrain:  epoch  0, batch    60 | loss: 2.6931810
MixupTrain:  epoch  0, batch    61 | loss: 2.7234049
MixupTrain:  epoch  0, batch    62 | loss: 2.5252852
MixupTrain:  epoch  0, batch    63 | loss: 2.7846923
MixupTrain:  epoch  0, batch    64 | loss: 2.3515635
MixupTrain:  epoch  0, batch    65 | loss: 2.4944541
MixupTrain:  epoch  0, batch    66 | loss: 2.4744034
MixupTrain:  epoch  0, batch    67 | loss: 2.4173820
MixupTrain:  epoch  0, batch    68 | loss: 2.3818533
MixupTrain:  epoch  0, batch    69 | loss: 2.4025474
MixupTrain:  epoch  0, batch    70 | loss: 2.7615323
MixupTrain:  epoch  0, batch    71 | loss: 2.7368383
MixupTrain:  epoch  0, batch    72 | loss: 2.6024442
MixupTrain:  epoch  0, batch    73 | loss: 2.5966430
MixupTrain:  epoch  0, batch    74 | loss: 2.4160180
MixupTrain:  epoch  0, batch    75 | loss: 2.5593765
MixupTrain:  epoch  0, batch    76 | loss: 2.4747972
MixupTrain:  epoch  0, batch    77 | loss: 2.5156217
MixupTrain:  epoch  0, batch    78 | loss: 2.4679070
MixupTrain:  epoch  0, batch    79 | loss: 2.4410143
MixupTrain:  epoch  0, batch    80 | loss: 2.4099588
MixupTrain:  epoch  0, batch    81 | loss: 2.4479041
MixupTrain:  epoch  0, batch    82 | loss: 2.4299979
MixupTrain:  epoch  0, batch    83 | loss: 2.6239929
MixupTrain:  epoch  0, batch    84 | loss: 2.6170111
MixupTrain:  epoch  0, batch    85 | loss: 2.5324850
MixupTrain:  epoch  0, batch    86 | loss: 2.3603292
MixupTrain:  epoch  0, batch    87 | loss: 2.2846797
MixupTrain:  epoch  0, batch    88 | loss: 2.4445062
MixupTrain:  epoch  0, batch    89 | loss: 2.3286681
MixupTrain:  epoch  0, batch    90 | loss: 2.5481343
MixupTrain:  epoch  0, batch    91 | loss: 2.2620387
MixupTrain:  epoch  0, batch    92 | loss: 2.3223796
MixupTrain:  epoch  0, batch    93 | loss: 2.1361313
MixupTrain:  epoch  0, batch    94 | loss: 2.3431940
MixupTrain:  epoch  0, batch    95 | loss: 2.1997852
MixupTrain:  epoch  0, batch    96 | loss: 2.3835044
MixupTrain:  epoch  0, batch    97 | loss: 2.2193584
MixupTrain:  epoch  0, batch    98 | loss: 2.3151665
MixupTrain:  epoch  0, batch    99 | loss: 2.3547902
MixupTrain:  epoch  0, batch   100 | loss: 2.2144012
MixupTrain:  epoch  0, batch   101 | loss: 2.1387053
MixupTrain:  epoch  0, batch   102 | loss: 2.3620417
MixupTrain:  epoch  0, batch   103 | loss: 2.3766556
MixupTrain:  epoch  0, batch   104 | loss: 2.3628449
MixupTrain:  epoch  0, batch   105 | loss: 2.3332357
MixupTrain:  epoch  0, batch   106 | loss: 2.4420404
MixupTrain:  epoch  0, batch   107 | loss: 2.3077540
MixupTrain:  epoch  0, batch   108 | loss: 2.4150357
MixupTrain:  epoch  0, batch   109 | loss: 2.1461105
MixupTrain:  epoch  0, batch   110 | loss: 2.4748430
MixupTrain:  epoch  0, batch   111 | loss: 2.3364677
MixupTrain:  epoch  0, batch   112 | loss: 2.1639056
MixupTrain:  epoch  0, batch   113 | loss: 2.2706561
MixupTrain:  epoch  0, batch   114 | loss: 2.4072556
MixupTrain:  epoch  0, batch   115 | loss: 2.2515807
MixupTrain:  epoch  0, batch   116 | loss: 2.2652621
MixupTrain:  epoch  0, batch   117 | loss: 2.2315385
MixupTrain:  epoch  0, batch   118 | loss: 2.2373929
MixupTrain:  epoch  0, batch   119 | loss: 2.1093717
MixupTrain:  epoch  0, batch   120 | loss: 2.3234463
MixupTrain:  epoch  0, batch   121 | loss: 2.2604632
MixupTrain:  epoch  0, batch   122 | loss: 2.1304204
MixupTrain:  epoch  0, batch   123 | loss: 2.1537910
MixupTrain:  epoch  0, batch   124 | loss: 2.1677799
MixupTrain:  epoch  0, batch   125 | loss: 2.0801287
MixupTrain:  epoch  0, batch   126 | loss: 2.2213421
MixupTrain:  epoch  0, batch   127 | loss: 2.2549677
MixupTrain:  epoch  0, batch   128 | loss: 2.1152780
MixupTrain:  epoch  0, batch   129 | loss: 2.1570818
MixupTrain:  epoch  0, batch   130 | loss: 2.1475356
MixupTrain:  epoch  0, batch   131 | loss: 2.2194111
MixupTrain:  epoch  0, batch   132 | loss: 2.1950130
MixupTrain:  epoch  0, batch   133 | loss: 2.1031063
MixupTrain:  epoch  0, batch   134 | loss: 2.0478659
MixupTrain:  epoch  0, batch   135 | loss: 2.2778902
MixupTrain:  epoch  0, batch   136 | loss: 2.1416438
MixupTrain:  epoch  0, batch   137 | loss: 2.1174917
MixupTrain:  epoch  0, batch   138 | loss: 2.3563251
MixupTrain:  epoch  0, batch   139 | loss: 2.2211444
MixupTrain:  epoch  0, batch   140 | loss: 2.1777644
MixupTrain:  epoch  0, batch   141 | loss: 2.1501889
MixupTrain:  epoch  0, batch   142 | loss: 2.2980905
MixupTrain:  epoch  0, batch   143 | loss: 2.2978427
MixupTrain:  epoch  0, batch   144 | loss: 2.0946131
MixupTrain:  epoch  0, batch   145 | loss: 2.1274748
MixupTrain:  epoch  0, batch   146 | loss: 2.1842122
MixupTrain:  epoch  0, batch   147 | loss: 2.1531692
MixupTrain:  epoch  0, batch   148 | loss: 2.1110463
MixupTrain:  epoch  0, batch   149 | loss: 2.1561337
MixupTrain:  epoch  0, batch   150 | loss: 2.1301551
MixupTrain:  epoch  0, batch   151 | loss: 2.2217085
MixupTrain:  epoch  0, batch   152 | loss: 2.1335893
MixupTrain:  epoch  0, batch   153 | loss: 2.1058309
MixupTrain:  epoch  0, batch   154 | loss: 2.2001736
MixupTrain:  epoch  0, batch   155 | loss: 2.0287237
MixupTrain:  epoch  0, batch   156 | loss: 2.1319859
MixupTrain:  epoch  0, batch   157 | loss: 2.1462831
MixupTrain:  epoch  0, batch   158 | loss: 2.0402064
MixupTrain:  epoch  0, batch   159 | loss: 2.0739331
MixupTrain:  epoch  0, batch   160 | loss: 2.1833415
MixupTrain:  epoch  0, batch   161 | loss: 2.1063552
MixupTrain:  epoch  0, batch   162 | loss: 2.1078343
MixupTrain:  epoch  0, batch   163 | loss: 2.0756688
MixupTrain:  epoch  0, batch   164 | loss: 2.0584023
MixupTrain:  epoch  0, batch   165 | loss: 2.1013899
MixupTrain:  epoch  0, batch   166 | loss: 2.0577288
MixupTrain:  epoch  0, batch   167 | loss: 2.1484537
MixupTrain:  epoch  0, batch   168 | loss: 2.2150893
MixupTrain:  epoch  0, batch   169 | loss: 2.0708807
MixupTrain:  epoch  0, batch   170 | loss: 2.1244402
MixupTrain:  epoch  0, batch   171 | loss: 2.1684971
MixupTrain:  epoch  0, batch   172 | loss: 2.1341870
MixupTrain:  epoch  0, batch   173 | loss: 2.0910859
MixupTrain:  epoch  0, batch   174 | loss: 2.1292300
MixupTrain:  epoch  0, batch   175 | loss: 2.2696526
MixupTrain:  epoch  0, batch   176 | loss: 2.4323883
MixupTrain:  epoch  0, batch   177 | loss: 2.1041272
MixupTrain:  epoch  0, batch   178 | loss: 2.1456664
MixupTrain:  epoch  0, batch   179 | loss: 2.1499531
MixupTrain:  epoch  0, batch   180 | loss: 2.0766680
MixupTrain:  epoch  0, batch   181 | loss: 2.1632934
MixupTrain:  epoch  0, batch   182 | loss: 2.1941662
MixupTrain:  epoch  0, batch   183 | loss: 2.0167584
MixupTrain:  epoch  0, batch   184 | loss: 2.1889548
MixupTrain:  epoch  0, batch   185 | loss: 2.0533671
MixupTrain:  epoch  0, batch   186 | loss: 2.0723195
MixupTrain:  epoch  0, batch   187 | loss: 2.0284734
MixupTrain:  epoch  0, batch   188 | loss: 2.0790119
MixupTrain:  epoch  0, batch   189 | loss: 2.0501494
MixupTrain:  epoch  0, batch   190 | loss: 2.1091268
MixupTrain:  epoch  0, batch   191 | loss: 2.1161981
MixupTrain:  epoch  0, batch   192 | loss: 2.1378353
MixupTrain:  epoch  0, batch   193 | loss: 2.1105299
MixupTrain:  epoch  0, batch   194 | loss: 2.0776830
MixupTrain:  epoch  0, batch   195 | loss: 2.0463398
MixupTrain:  epoch  0, batch   196 | loss: 2.0217948
MixupTrain:  epoch  0, batch   197 | loss: 2.0548651
MixupTrain:  epoch  0, batch   198 | loss: 2.1618452
MixupTrain:  epoch  0, batch   199 | loss: 2.1325142
MixupTrain:  epoch  0, batch   200 | loss: 2.0152361
MixupTrain:  epoch  0, batch   201 | loss: 1.9663675
MixupTrain:  epoch  0, batch   202 | loss: 2.0712280
MixupTrain:  epoch  0, batch   203 | loss: 1.9242002
MixupTrain:  epoch  0, batch   204 | loss: 2.1054859
MixupTrain:  epoch  0, batch   205 | loss: 2.0250144
MixupTrain:  epoch  0, batch   206 | loss: 2.1140385
MixupTrain:  epoch  0, batch   207 | loss: 2.0183325
MixupTrain:  epoch  0, batch   208 | loss: 2.0030129
MixupTrain:  epoch  0, batch   209 | loss: 2.0746810
MixupTrain:  epoch  0, batch   210 | loss: 2.0604067
MixupTrain:  epoch  0, batch   211 | loss: 2.1439648
MixupTrain:  epoch  0, batch   212 | loss: 2.0675881
MixupTrain:  epoch  0, batch   213 | loss: 2.0849080
MixupTrain:  epoch  0, batch   214 | loss: 2.0700066
MixupTrain:  epoch  0, batch   215 | loss: 2.0333698
MixupTrain:  epoch  0, batch   216 | loss: 2.0786848
MixupTrain:  epoch  0, batch   217 | loss: 2.1329460
MixupTrain:  epoch  0, batch   218 | loss: 2.0388241
MixupTrain:  epoch  0, batch   219 | loss: 2.0018592
MixupTrain:  epoch  0, batch   220 | loss: 2.0236807
MixupTrain:  epoch  0, batch   221 | loss: 2.0841930
MixupTrain:  epoch  0, batch   222 | loss: 2.0353096
MixupTrain:  epoch  0, batch   223 | loss: 2.0515633
MixupTrain:  epoch  0, batch   224 | loss: 2.0441301
MixupTrain:  epoch  0, batch   225 | loss: 1.9384987
MixupTrain:  epoch  0, batch   226 | loss: 2.1626749
MixupTrain:  epoch  0, batch   227 | loss: 2.0392451
MixupTrain:  epoch  0, batch   228 | loss: 2.0756273
MixupTrain:  epoch  0, batch   229 | loss: 1.9175682
MixupTrain:  epoch  0, batch   230 | loss: 2.1317413
MixupTrain:  epoch  0, batch   231 | loss: 2.0455155
MixupTrain:  epoch  0, batch   232 | loss: 1.9905326
MixupTrain:  epoch  0, batch   233 | loss: 1.8273802
MemoryTrain:  epoch  0, batch     0 | loss: 1.9973009
MemoryTrain:  epoch  0, batch     1 | loss: 2.7845581
MemoryTrain:  epoch  0, batch     2 | loss: 3.0606112
MemoryTrain:  epoch  0, batch     3 | loss: 2.7487895
MemoryTrain:  epoch  0, batch     4 | loss: 2.4151826
MemoryTrain:  epoch  1, batch     0 | loss: 1.8879426
MemoryTrain:  epoch  1, batch     1 | loss: 1.8623228
MemoryTrain:  epoch  1, batch     2 | loss: 1.8536451
MemoryTrain:  epoch  1, batch     3 | loss: 1.8639615
MemoryTrain:  epoch  1, batch     4 | loss: 1.8492626
MemoryTrain:  epoch  2, batch     0 | loss: 1.8655113
MemoryTrain:  epoch  2, batch     1 | loss: 1.8545597
MemoryTrain:  epoch  2, batch     2 | loss: 1.8640546
MemoryTrain:  epoch  2, batch     3 | loss: 1.8722675
MemoryTrain:  epoch  2, batch     4 | loss: 1.8517671
MemoryTrain:  epoch  3, batch     0 | loss: 1.8778915
MemoryTrain:  epoch  3, batch     1 | loss: 1.8566189
MemoryTrain:  epoch  3, batch     2 | loss: 1.8377247
MemoryTrain:  epoch  3, batch     3 | loss: 1.8597307
MemoryTrain:  epoch  3, batch     4 | loss: 1.8366807
MemoryTrain:  epoch  4, batch     0 | loss: 1.8529993
MemoryTrain:  epoch  4, batch     1 | loss: 1.8584647
MemoryTrain:  epoch  4, batch     2 | loss: 1.8513438
MemoryTrain:  epoch  4, batch     3 | loss: 1.8481021
MemoryTrain:  epoch  4, batch     4 | loss: 1.8552804
MemoryTrain:  epoch  5, batch     0 | loss: 1.8455253
MemoryTrain:  epoch  5, batch     1 | loss: 1.8582692
MemoryTrain:  epoch  5, batch     2 | loss: 1.8611677
MemoryTrain:  epoch  5, batch     3 | loss: 1.8454554
MemoryTrain:  epoch  5, batch     4 | loss: 1.9077098
MemoryTrain:  epoch  6, batch     0 | loss: 1.8523546
MemoryTrain:  epoch  6, batch     1 | loss: 1.8735917
MemoryTrain:  epoch  6, batch     2 | loss: 1.8628585
MemoryTrain:  epoch  6, batch     3 | loss: 1.8781562
MemoryTrain:  epoch  6, batch     4 | loss: 1.8389797
MemoryTrain:  epoch  7, batch     0 | loss: 1.8549275
MemoryTrain:  epoch  7, batch     1 | loss: 1.8918278
MemoryTrain:  epoch  7, batch     2 | loss: 1.8797178
MemoryTrain:  epoch  7, batch     3 | loss: 1.8651507
MemoryTrain:  epoch  7, batch     4 | loss: 1.8644404
MemoryTrain:  epoch  8, batch     0 | loss: 1.8792306
MemoryTrain:  epoch  8, batch     1 | loss: 1.8814063
MemoryTrain:  epoch  8, batch     2 | loss: 1.9574569
MemoryTrain:  epoch  8, batch     3 | loss: 1.8961499
MemoryTrain:  epoch  8, batch     4 | loss: 1.8209141
MemoryTrain:  epoch  9, batch     0 | loss: 1.8415689
MemoryTrain:  epoch  9, batch     1 | loss: 1.8377759
MemoryTrain:  epoch  9, batch     2 | loss: 1.8482958
MemoryTrain:  epoch  9, batch     3 | loss: 1.8617400
MemoryTrain:  epoch  9, batch     4 | loss: 1.8670505
[EVAL] batch:    0 | acc: 93.75%,  total acc: 93.75%   
[EVAL] batch:    1 | acc: 93.75%,  total acc: 93.75%   
[EVAL] batch:    2 | acc: 87.50%,  total acc: 91.67%   
[EVAL] batch:    3 | acc: 93.75%,  total acc: 92.19%   
[EVAL] batch:    4 | acc: 87.50%,  total acc: 91.25%   
[EVAL] batch:    5 | acc: 87.50%,  total acc: 90.62%   
[EVAL] batch:    6 | acc: 93.75%,  total acc: 91.07%   
[EVAL] batch:    7 | acc: 87.50%,  total acc: 90.62%   
[EVAL] batch:    8 | acc: 93.75%,  total acc: 90.97%   
[EVAL] batch:    9 | acc: 100.00%,  total acc: 91.88%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 92.61%   
[EVAL] batch:   11 | acc: 100.00%,  total acc: 93.23%   
[EVAL] batch:   12 | acc: 100.00%,  total acc: 93.75%   
[EVAL] batch:   13 | acc: 100.00%,  total acc: 94.20%   
[EVAL] batch:   14 | acc: 100.00%,  total acc: 94.58%   
[EVAL] batch:   15 | acc: 100.00%,  total acc: 94.92%   
[EVAL] batch:   16 | acc: 100.00%,  total acc: 95.22%   
[EVAL] batch:   17 | acc: 25.00%,  total acc: 91.32%   
[EVAL] batch:    0 | acc: 25.00%,  total acc: 25.00%   
[EVAL] batch:    1 | acc: 50.00%,  total acc: 37.50%   
[EVAL] batch:    2 | acc: 50.00%,  total acc: 41.67%   
[EVAL] batch:    3 | acc: 25.00%,  total acc: 37.50%   
[EVAL] batch:    4 | acc: 25.00%,  total acc: 35.00%   
[EVAL] batch:    5 | acc: 43.75%,  total acc: 36.46%   
[EVAL] batch:    6 | acc: 87.50%,  total acc: 43.75%   
[EVAL] batch:    7 | acc: 87.50%,  total acc: 49.22%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 54.86%   
[EVAL] batch:    9 | acc: 87.50%,  total acc: 58.13%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 61.93%   
[EVAL] batch:   11 | acc: 87.50%,  total acc: 64.06%   
[EVAL] batch:   12 | acc: 81.25%,  total acc: 65.38%   
[EVAL] batch:   13 | acc: 68.75%,  total acc: 65.62%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 66.25%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 65.62%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 66.18%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 65.97%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 65.79%   
[EVAL] batch:   19 | acc: 87.50%,  total acc: 66.88%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 68.45%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 69.89%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 71.20%   
[EVAL] batch:   23 | acc: 93.75%,  total acc: 72.14%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 73.25%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 74.28%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 75.00%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 75.89%   
[EVAL] batch:   28 | acc: 100.00%,  total acc: 76.72%   
[EVAL] batch:   29 | acc: 87.50%,  total acc: 77.08%   
[EVAL] batch:   30 | acc: 100.00%,  total acc: 77.82%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 78.32%   
[EVAL] batch:   32 | acc: 100.00%,  total acc: 78.98%   
[EVAL] batch:   33 | acc: 87.50%,  total acc: 79.23%   
[EVAL] batch:   34 | acc: 87.50%,  total acc: 79.46%   
[EVAL] batch:   35 | acc: 93.75%,  total acc: 79.86%   
[EVAL] batch:   36 | acc: 87.50%,  total acc: 80.07%   
[EVAL] batch:   37 | acc: 87.50%,  total acc: 80.26%   
[EVAL] batch:   38 | acc: 93.75%,  total acc: 80.61%   
[EVAL] batch:   39 | acc: 100.00%,  total acc: 81.09%   
[EVAL] batch:   40 | acc: 81.25%,  total acc: 81.10%   
[EVAL] batch:   41 | acc: 100.00%,  total acc: 81.55%   
[EVAL] batch:   42 | acc: 100.00%,  total acc: 81.98%   
[EVAL] batch:   43 | acc: 100.00%,  total acc: 82.39%   
[EVAL] batch:   44 | acc: 100.00%,  total acc: 82.78%   
[EVAL] batch:   45 | acc: 100.00%,  total acc: 83.15%   
[EVAL] batch:   46 | acc: 100.00%,  total acc: 83.51%   
[EVAL] batch:   47 | acc: 100.00%,  total acc: 83.85%   
[EVAL] batch:   48 | acc: 100.00%,  total acc: 84.18%   
[EVAL] batch:   49 | acc: 62.50%,  total acc: 83.75%   
cur_acc:  ['0.8693', '0.9132']
his_acc:  ['0.8693', '0.8375']
CurrentTrain: epoch  0, batch     0 | loss: 6.3557916
CurrentTrain: epoch  0, batch     1 | loss: 7.8577290
CurrentTrain: epoch  1, batch     0 | loss: 7.0979762
CurrentTrain: epoch  1, batch     1 | loss: 4.8704615
CurrentTrain: epoch  2, batch     0 | loss: 4.8793716
CurrentTrain: epoch  2, batch     1 | loss: 5.6225982
CurrentTrain: epoch  3, batch     0 | loss: 4.4593325
CurrentTrain: epoch  3, batch     1 | loss: 5.7715325
CurrentTrain: epoch  4, batch     0 | loss: 5.6110325
CurrentTrain: epoch  4, batch     1 | loss: 3.1236703
CurrentTrain: epoch  5, batch     0 | loss: 4.2321000
CurrentTrain: epoch  5, batch     1 | loss: 4.7603073
CurrentTrain: epoch  6, batch     0 | loss: 4.7087798
CurrentTrain: epoch  6, batch     1 | loss: 3.3434212
CurrentTrain: epoch  7, batch     0 | loss: 3.9660711
CurrentTrain: epoch  7, batch     1 | loss: 3.3742173
CurrentTrain: epoch  8, batch     0 | loss: 3.2623525
CurrentTrain: epoch  8, batch     1 | loss: 4.4212942
CurrentTrain: epoch  9, batch     0 | loss: 3.5900204
CurrentTrain: epoch  9, batch     1 | loss: 2.9111347
#### person date of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person date of birth" means a person was born in a date.
Here is an example:
Relation: person date of birth
Context: born of schoolteacher parents in the western town of sabaneta on july 28 , 1954 , chavez studied at the military academy of venezuela in caracas .
Head Entity: chavez
Tail Entity: july 28 , 1954
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person date of birth":
Relation: person date of birth  
Context: the famous physicist albert einstein was born in ulm, in the kingdom of wurttemberg in the german empire on march 14, 1879.  
Head Entity: albert einstein  
Tail Entity: march 14, 1879  

Relation: person date of birth  
Context: the renowned author jane austen was born on december 16, 1775, in steventon, hampshire, england.  
Head Entity: jane austen  
Tail Entity: december 16, 1775  

Relation: person date of birth  
Context: the legendary musician freddie mercury was born farrokh bulsara on september 5, 1946, in zanzibar, tanzania.  
Head Entity: freddie mercury  
Tail Entity: september 5, 1946  

Relation: person date of birth  
Context: the influential civil rights leader martin luther king jr. was born on january 15, 1929, in atlanta, georgia.  
Head Entity: martin luther king jr.  
Tail Entity: january 15, 1929  

Relation: person date of birth  
Context: the famous painter pablo picasso was born on october 25, 1881, in malaga, spain.  
Head Entity: pablo picasso  
Tail Entity: october 25, 1881  
#### person stateorprovince of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of birth" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of birth
Context: jefferson joseph deblanc sr. was born in lockport , la. , on feb. 15 , 1921 , and grew up in st. martinville .
Head Entity: jefferson joseph deblanc sr.
Tail Entity: la.
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of birth":
Relation: person stateorprovince of birth  
Context: martha stewart was born in jersey city, nj, on august 3, 1941, and later moved to new york.  
Head Entity: martha stewart  
Tail Entity: nj  

Relation: person stateorprovince of birth  
Context: barack obama was born in honolulu, hi, on august 4, 1961, and spent his childhood in indonesia.  
Head Entity: barack obama  
Tail Entity: hi  

Relation: person stateorprovince of birth  
Context: taylor swift was born in reading, pa, on december 13, 1989, and later relocated to nashville, tennessee.  
Head Entity: taylor swift  
Tail Entity: pa  

Relation: person stateorprovince of birth  
Context: oprah winfrey was born in kosciusko, ms, on january 29, 1954, and grew up in milwaukee, wisconsin.  
Head Entity: oprah winfrey  
Tail Entity: ms  

Relation: person stateorprovince of birth  
Context: elon musk was born in pretoria, south africa, on june 28, 1971, and moved to the united states for his studies.  
Head Entity: elon musk  
Tail Entity: south africa  
#### person parents ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person parents" means a person 's parent is a person.
Here is an example:
Relation: person parents
Context: as the case developed , sandy 's mother , denise sandy , quietly made herself a spectral but central figure , by faithfully attending pretrial hearings .
Head Entity: sandy
Tail Entity: denise sandy
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person parents":
Relation: person parents  
Context: After the ceremony, Emily's father, John Smith, gave a heartfelt speech about family values and the importance of love.  
Head Entity: Emily  
Tail Entity: John Smith  

Relation: person parents  
Context: During the family reunion, Michael's mother, Sarah Johnson, shared stories from her childhood that made everyone laugh.  
Head Entity: Michael  
Tail Entity: Sarah Johnson  

Relation: person parents  
Context: At the graduation party, Lisa's father, Robert Brown, proudly watched as his daughter received her diploma.  
Head Entity: Lisa  
Tail Entity: Robert Brown  

Relation: person parents  
Context: In the documentary, Anna's mother, Patricia Lee, discussed the challenges of raising a child in a big city.  
Head Entity: Anna  
Tail Entity: Patricia Lee  

Relation: person parents  
Context: As they reminisced, David's father, George White, recalled the lessons he taught his son about hard work and perseverance.  
Head Entity: David  
Tail Entity: George White  
#### person employee of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person employee of" means a person is an employee of an organization.
Here is an example:
Relation: person employee of
Context: seeking revenge , axel reunites with old pal sgt. billy rosewood -lrb- judge reinhold -rrb- and jon flint -lrb- hector elizondo -rrb- of the beverly hills police department .
Head Entity: hector elizondo
Tail Entity: beverly hills police department
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person employee of":
Relation: person employee of  
Context: After years of hard work, Maria finally landed a job at the prestigious tech firm, where she collaborates with some of the brightest minds in the industry.  
Head Entity: Maria  
Tail Entity: prestigious tech firm  

Relation: person employee of  
Context: John has been with the company for over a decade, contributing to numerous successful projects and earning the respect of his colleagues.  
Head Entity: John  
Tail Entity: the company  

Relation: person employee of  
Context: As a lead designer at the fashion house, Sarah showcases her creativity and innovation, making a name for herself in the competitive industry.  
Head Entity: Sarah  
Tail Entity: the fashion house  

Relation: person employee of  
Context: After graduating from university, Tom accepted a position at a well-known financial institution, where he quickly climbed the corporate ladder.  
Head Entity: Tom  
Tail Entity: well-known financial institution  

Relation: person employee of  
Context: Emily's dedication to her role at the non-profit organization has made a significant impact on the community, earning her several awards.  
Head Entity: Emily  
Tail Entity: non-profit organization  
#### person stateorprovince of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of death" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of death
Context: irene morgan kirkaldy , whose defiance of bus segregation laws more than a decade before rosa parks ' landmark case helped lay the foundation for later civil rights victories , died friday at her home in hayes , va. .
Head Entity: irene morgan kirkaldy
Tail Entity: va.
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of death":
Relation: person stateorprovince of death  
Context: john doe, a renowned author known for his thrilling novels, passed away peacefully in his sleep at his residence in los angeles, ca.  
Head Entity: john doe  
Tail Entity: ca.  

Relation: person stateorprovince of death  
Context: after a long battle with illness, elizabeth taylor, the iconic actress, died at the age of 79 in her home located in bel air, ca.  
Head Entity: elizabeth taylor  
Tail Entity: ca.  

Relation: person stateorprovince of death  
Context: the famous physicist, albert einstein, took his last breath in princeton, nj, where he had lived for many years.  
Head Entity: albert einstein  
Tail Entity: nj.  

Relation: person stateorprovince of death  
Context: the beloved musician, prince, was found unresponsive in his home in minneapolis, mn, leading to an outpouring of grief from fans worldwide.  
Head Entity: prince  
Tail Entity: mn.  

Relation: person stateorprovince of death  
Context: the legendary civil rights leader, martin luther king jr., was assassinated in memphis, tn, a tragic event that shocked the nation.  
Head Entity: martin luther king jr.  
Tail Entity: tn.  
Mixup data size:  6820
MixupTrain:  epoch  0, batch     0 | loss: 5.0465508
MixupTrain:  epoch  0, batch     1 | loss: 4.7222204
MixupTrain:  epoch  0, batch     2 | loss: 4.2519312
MixupTrain:  epoch  0, batch     3 | loss: 4.9213395
MixupTrain:  epoch  0, batch     4 | loss: 4.7252011
MixupTrain:  epoch  0, batch     5 | loss: 4.8480310
MixupTrain:  epoch  0, batch     6 | loss: 4.7115870
MixupTrain:  epoch  0, batch     7 | loss: 4.5675511
MixupTrain:  epoch  0, batch     8 | loss: 5.0269928
MixupTrain:  epoch  0, batch     9 | loss: 4.0901737
MixupTrain:  epoch  0, batch    10 | loss: 4.0827479
MixupTrain:  epoch  0, batch    11 | loss: 3.6738291
MixupTrain:  epoch  0, batch    12 | loss: 3.9613533
MixupTrain:  epoch  0, batch    13 | loss: 4.1368170
MixupTrain:  epoch  0, batch    14 | loss: 4.6493168
MixupTrain:  epoch  0, batch    15 | loss: 4.2331300
MixupTrain:  epoch  0, batch    16 | loss: 4.1927476
MixupTrain:  epoch  0, batch    17 | loss: 3.8104842
MixupTrain:  epoch  0, batch    18 | loss: 2.9535370
MixupTrain:  epoch  0, batch    19 | loss: 3.4342604
MixupTrain:  epoch  0, batch    20 | loss: 4.7815480
MixupTrain:  epoch  0, batch    21 | loss: 3.9339838
MixupTrain:  epoch  0, batch    22 | loss: 3.4415979
MixupTrain:  epoch  0, batch    23 | loss: 3.0862546
MixupTrain:  epoch  0, batch    24 | loss: 3.6636605
MixupTrain:  epoch  0, batch    25 | loss: 4.0837455
MixupTrain:  epoch  0, batch    26 | loss: 4.3630433
MixupTrain:  epoch  0, batch    27 | loss: 3.9428377
MixupTrain:  epoch  0, batch    28 | loss: 3.2046015
MixupTrain:  epoch  0, batch    29 | loss: 4.0410233
MixupTrain:  epoch  0, batch    30 | loss: 3.7002330
MixupTrain:  epoch  0, batch    31 | loss: 3.3528838
MixupTrain:  epoch  0, batch    32 | loss: 3.5906563
MixupTrain:  epoch  0, batch    33 | loss: 3.5756588
MixupTrain:  epoch  0, batch    34 | loss: 2.5726287
MixupTrain:  epoch  0, batch    35 | loss: 3.7224002
MixupTrain:  epoch  0, batch    36 | loss: 4.2459598
MixupTrain:  epoch  0, batch    37 | loss: 2.9254212
MixupTrain:  epoch  0, batch    38 | loss: 3.1903219
MixupTrain:  epoch  0, batch    39 | loss: 3.2257929
MixupTrain:  epoch  0, batch    40 | loss: 3.9373631
MixupTrain:  epoch  0, batch    41 | loss: 2.9196551
MixupTrain:  epoch  0, batch    42 | loss: 3.0072489
MixupTrain:  epoch  0, batch    43 | loss: 3.8714471
MixupTrain:  epoch  0, batch    44 | loss: 2.7345686
MixupTrain:  epoch  0, batch    45 | loss: 3.6537080
MixupTrain:  epoch  0, batch    46 | loss: 4.0357971
MixupTrain:  epoch  0, batch    47 | loss: 3.5087991
MixupTrain:  epoch  0, batch    48 | loss: 3.1919594
MixupTrain:  epoch  0, batch    49 | loss: 3.8276854
MixupTrain:  epoch  0, batch    50 | loss: 2.8754451
MixupTrain:  epoch  0, batch    51 | loss: 3.4505074
MixupTrain:  epoch  0, batch    52 | loss: 2.7343807
MixupTrain:  epoch  0, batch    53 | loss: 3.0638783
MixupTrain:  epoch  0, batch    54 | loss: 3.3204465
MixupTrain:  epoch  0, batch    55 | loss: 3.5065465
MixupTrain:  epoch  0, batch    56 | loss: 3.3006420
MixupTrain:  epoch  0, batch    57 | loss: 3.0526857
MixupTrain:  epoch  0, batch    58 | loss: 2.8926401
MixupTrain:  epoch  0, batch    59 | loss: 3.0214651
MixupTrain:  epoch  0, batch    60 | loss: 2.5275059
MixupTrain:  epoch  0, batch    61 | loss: 3.1748624
MixupTrain:  epoch  0, batch    62 | loss: 3.0072508
MixupTrain:  epoch  0, batch    63 | loss: 3.1759477
MixupTrain:  epoch  0, batch    64 | loss: 2.7013571
MixupTrain:  epoch  0, batch    65 | loss: 3.0973730
MixupTrain:  epoch  0, batch    66 | loss: 2.9132366
MixupTrain:  epoch  0, batch    67 | loss: 2.7861166
MixupTrain:  epoch  0, batch    68 | loss: 2.8474436
MixupTrain:  epoch  0, batch    69 | loss: 2.6635630
MixupTrain:  epoch  0, batch    70 | loss: 2.9642863
MixupTrain:  epoch  0, batch    71 | loss: 3.1743996
MixupTrain:  epoch  0, batch    72 | loss: 3.3093998
MixupTrain:  epoch  0, batch    73 | loss: 2.6999149
MixupTrain:  epoch  0, batch    74 | loss: 3.1066155
MixupTrain:  epoch  0, batch    75 | loss: 2.5819783
MixupTrain:  epoch  0, batch    76 | loss: 2.7992225
MixupTrain:  epoch  0, batch    77 | loss: 2.9007432
MixupTrain:  epoch  0, batch    78 | loss: 2.6527762
MixupTrain:  epoch  0, batch    79 | loss: 2.6138334
MixupTrain:  epoch  0, batch    80 | loss: 3.1334848
MixupTrain:  epoch  0, batch    81 | loss: 2.6170502
MixupTrain:  epoch  0, batch    82 | loss: 2.6126292
MixupTrain:  epoch  0, batch    83 | loss: 2.3792143
MixupTrain:  epoch  0, batch    84 | loss: 2.8939910
MixupTrain:  epoch  0, batch    85 | loss: 2.8658123
MixupTrain:  epoch  0, batch    86 | loss: 2.5453920
MixupTrain:  epoch  0, batch    87 | loss: 2.8857276
MixupTrain:  epoch  0, batch    88 | loss: 2.6219876
MixupTrain:  epoch  0, batch    89 | loss: 2.3460982
MixupTrain:  epoch  0, batch    90 | loss: 2.7322338
MixupTrain:  epoch  0, batch    91 | loss: 2.4687502
MixupTrain:  epoch  0, batch    92 | loss: 2.5765185
MixupTrain:  epoch  0, batch    93 | loss: 2.7946095
MixupTrain:  epoch  0, batch    94 | loss: 2.7617490
MixupTrain:  epoch  0, batch    95 | loss: 2.9545217
MixupTrain:  epoch  0, batch    96 | loss: 2.6653934
MixupTrain:  epoch  0, batch    97 | loss: 2.6897271
MixupTrain:  epoch  0, batch    98 | loss: 2.5597570
MixupTrain:  epoch  0, batch    99 | loss: 2.4359596
MixupTrain:  epoch  0, batch   100 | loss: 2.7652311
MixupTrain:  epoch  0, batch   101 | loss: 2.6871929
MixupTrain:  epoch  0, batch   102 | loss: 2.4746990
MixupTrain:  epoch  0, batch   103 | loss: 2.9013972
MixupTrain:  epoch  0, batch   104 | loss: 2.5143192
MixupTrain:  epoch  0, batch   105 | loss: 2.6556196
MixupTrain:  epoch  0, batch   106 | loss: 2.7185159
MixupTrain:  epoch  0, batch   107 | loss: 2.8094301
MixupTrain:  epoch  0, batch   108 | loss: 2.8541005
MixupTrain:  epoch  0, batch   109 | loss: 2.5672483
MixupTrain:  epoch  0, batch   110 | loss: 2.8165536
MixupTrain:  epoch  0, batch   111 | loss: 2.6076436
MixupTrain:  epoch  0, batch   112 | loss: 2.5733202
MixupTrain:  epoch  0, batch   113 | loss: 2.4609361
MixupTrain:  epoch  0, batch   114 | loss: 2.5690198
MixupTrain:  epoch  0, batch   115 | loss: 2.6418877
MixupTrain:  epoch  0, batch   116 | loss: 2.3582499
MixupTrain:  epoch  0, batch   117 | loss: 2.5193248
MixupTrain:  epoch  0, batch   118 | loss: 2.8362653
MixupTrain:  epoch  0, batch   119 | loss: 2.6840920
MixupTrain:  epoch  0, batch   120 | loss: 2.6327879
MixupTrain:  epoch  0, batch   121 | loss: 2.4999337
MixupTrain:  epoch  0, batch   122 | loss: 2.7226543
MixupTrain:  epoch  0, batch   123 | loss: 2.5579419
MixupTrain:  epoch  0, batch   124 | loss: 2.2253842
MixupTrain:  epoch  0, batch   125 | loss: 2.4600654
MixupTrain:  epoch  0, batch   126 | loss: 2.2337089
MixupTrain:  epoch  0, batch   127 | loss: 2.7462656
MixupTrain:  epoch  0, batch   128 | loss: 2.4530885
MixupTrain:  epoch  0, batch   129 | loss: 2.3600490
MixupTrain:  epoch  0, batch   130 | loss: 2.2933488
MixupTrain:  epoch  0, batch   131 | loss: 2.6810369
MixupTrain:  epoch  0, batch   132 | loss: 2.3105237
MixupTrain:  epoch  0, batch   133 | loss: 2.5493479
MixupTrain:  epoch  0, batch   134 | loss: 2.6151600
MixupTrain:  epoch  0, batch   135 | loss: 2.5180812
MixupTrain:  epoch  0, batch   136 | loss: 2.4386690
MixupTrain:  epoch  0, batch   137 | loss: 2.5855474
MixupTrain:  epoch  0, batch   138 | loss: 2.4149215
MixupTrain:  epoch  0, batch   139 | loss: 2.7038400
MixupTrain:  epoch  0, batch   140 | loss: 2.7263269
MixupTrain:  epoch  0, batch   141 | loss: 2.5828342
MixupTrain:  epoch  0, batch   142 | loss: 2.2774501
MixupTrain:  epoch  0, batch   143 | loss: 2.7625797
MixupTrain:  epoch  0, batch   144 | loss: 2.1917224
MixupTrain:  epoch  0, batch   145 | loss: 2.2967415
MixupTrain:  epoch  0, batch   146 | loss: 2.8125148
MixupTrain:  epoch  0, batch   147 | loss: 2.3752851
MixupTrain:  epoch  0, batch   148 | loss: 2.5481110
MixupTrain:  epoch  0, batch   149 | loss: 2.4445977
MixupTrain:  epoch  0, batch   150 | loss: 2.5525231
MixupTrain:  epoch  0, batch   151 | loss: 2.5191123
MixupTrain:  epoch  0, batch   152 | loss: 2.4124687
MixupTrain:  epoch  0, batch   153 | loss: 2.5674031
MixupTrain:  epoch  0, batch   154 | loss: 2.4437675
MixupTrain:  epoch  0, batch   155 | loss: 2.2328000
MixupTrain:  epoch  0, batch   156 | loss: 2.6968422
MixupTrain:  epoch  0, batch   157 | loss: 2.3793612
MixupTrain:  epoch  0, batch   158 | loss: 2.2515631
MixupTrain:  epoch  0, batch   159 | loss: 3.0766554
MixupTrain:  epoch  0, batch   160 | loss: 2.5918527
MixupTrain:  epoch  0, batch   161 | loss: 2.5760217
MixupTrain:  epoch  0, batch   162 | loss: 2.2693205
MixupTrain:  epoch  0, batch   163 | loss: 2.3193681
MixupTrain:  epoch  0, batch   164 | loss: 2.4885063
MixupTrain:  epoch  0, batch   165 | loss: 2.2835078
MixupTrain:  epoch  0, batch   166 | loss: 2.5338793
MixupTrain:  epoch  0, batch   167 | loss: 2.6067364
MixupTrain:  epoch  0, batch   168 | loss: 2.1700203
MixupTrain:  epoch  0, batch   169 | loss: 2.4663382
MixupTrain:  epoch  0, batch   170 | loss: 2.3747580
MixupTrain:  epoch  0, batch   171 | loss: 2.6167226
MixupTrain:  epoch  0, batch   172 | loss: 2.4370952
MixupTrain:  epoch  0, batch   173 | loss: 2.1716423
MixupTrain:  epoch  0, batch   174 | loss: 2.5278955
MixupTrain:  epoch  0, batch   175 | loss: 2.4637017
MixupTrain:  epoch  0, batch   176 | loss: 2.4272661
MixupTrain:  epoch  0, batch   177 | loss: 2.5941072
MixupTrain:  epoch  0, batch   178 | loss: 2.1847644
MixupTrain:  epoch  0, batch   179 | loss: 2.3955770
MixupTrain:  epoch  0, batch   180 | loss: 2.3572354
MixupTrain:  epoch  0, batch   181 | loss: 2.3768642
MixupTrain:  epoch  0, batch   182 | loss: 2.5253863
MixupTrain:  epoch  0, batch   183 | loss: 2.4864118
MixupTrain:  epoch  0, batch   184 | loss: 2.4367480
MixupTrain:  epoch  0, batch   185 | loss: 2.2971191
MixupTrain:  epoch  0, batch   186 | loss: 2.4187224
MixupTrain:  epoch  0, batch   187 | loss: 2.2702885
MixupTrain:  epoch  0, batch   188 | loss: 2.2079873
MixupTrain:  epoch  0, batch   189 | loss: 2.2823827
MixupTrain:  epoch  0, batch   190 | loss: 2.4468172
MixupTrain:  epoch  0, batch   191 | loss: 2.5170975
MixupTrain:  epoch  0, batch   192 | loss: 2.2454989
MixupTrain:  epoch  0, batch   193 | loss: 2.3223543
MixupTrain:  epoch  0, batch   194 | loss: 2.1954844
MixupTrain:  epoch  0, batch   195 | loss: 2.2030125
MixupTrain:  epoch  0, batch   196 | loss: 2.4332228
MixupTrain:  epoch  0, batch   197 | loss: 2.2843821
MixupTrain:  epoch  0, batch   198 | loss: 2.4268565
MixupTrain:  epoch  0, batch   199 | loss: 2.2363436
MixupTrain:  epoch  0, batch   200 | loss: 2.2368326
MixupTrain:  epoch  0, batch   201 | loss: 2.5215530
MixupTrain:  epoch  0, batch   202 | loss: 2.3225756
MixupTrain:  epoch  0, batch   203 | loss: 2.3046882
MixupTrain:  epoch  0, batch   204 | loss: 2.6097217
MixupTrain:  epoch  0, batch   205 | loss: 2.1904590
MixupTrain:  epoch  0, batch   206 | loss: 2.2056088
MixupTrain:  epoch  0, batch   207 | loss: 2.2325871
MixupTrain:  epoch  0, batch   208 | loss: 2.6896758
MixupTrain:  epoch  0, batch   209 | loss: 2.2444808
MixupTrain:  epoch  0, batch   210 | loss: 2.4738255
MixupTrain:  epoch  0, batch   211 | loss: 2.3610449
MixupTrain:  epoch  0, batch   212 | loss: 2.2280641
MixupTrain:  epoch  0, batch   213 | loss: 2.2433758
MixupTrain:  epoch  0, batch   214 | loss: 2.4320040
MixupTrain:  epoch  0, batch   215 | loss: 2.4835174
MixupTrain:  epoch  0, batch   216 | loss: 2.2562001
MixupTrain:  epoch  0, batch   217 | loss: 2.4971690
MixupTrain:  epoch  0, batch   218 | loss: 2.4767718
MixupTrain:  epoch  0, batch   219 | loss: 2.1785786
MixupTrain:  epoch  0, batch   220 | loss: 2.6655614
MixupTrain:  epoch  0, batch   221 | loss: 2.3307166
MixupTrain:  epoch  0, batch   222 | loss: 2.2636209
MixupTrain:  epoch  0, batch   223 | loss: 2.2055111
MixupTrain:  epoch  0, batch   224 | loss: 2.3910348
MixupTrain:  epoch  0, batch   225 | loss: 2.5278563
MixupTrain:  epoch  0, batch   226 | loss: 2.2753310
MixupTrain:  epoch  0, batch   227 | loss: 2.3728707
MixupTrain:  epoch  0, batch   228 | loss: 2.3836684
MixupTrain:  epoch  0, batch   229 | loss: 2.4016423
MixupTrain:  epoch  0, batch   230 | loss: 2.0780077
MixupTrain:  epoch  0, batch   231 | loss: 2.4356308
MixupTrain:  epoch  0, batch   232 | loss: 2.1823123
MixupTrain:  epoch  0, batch   233 | loss: 2.3699515
MixupTrain:  epoch  0, batch   234 | loss: 2.2743657
MixupTrain:  epoch  0, batch   235 | loss: 2.2096434
MixupTrain:  epoch  0, batch   236 | loss: 2.1321602
MixupTrain:  epoch  0, batch   237 | loss: 2.3613038
MixupTrain:  epoch  0, batch   238 | loss: 2.3175616
MixupTrain:  epoch  0, batch   239 | loss: 2.4689698
MixupTrain:  epoch  0, batch   240 | loss: 2.3472922
MixupTrain:  epoch  0, batch   241 | loss: 2.3143535
MixupTrain:  epoch  0, batch   242 | loss: 2.4165955
MixupTrain:  epoch  0, batch   243 | loss: 2.1719141
MixupTrain:  epoch  0, batch   244 | loss: 2.3163049
MixupTrain:  epoch  0, batch   245 | loss: 2.2706857
MixupTrain:  epoch  0, batch   246 | loss: 2.5344677
MixupTrain:  epoch  0, batch   247 | loss: 2.3267870
MixupTrain:  epoch  0, batch   248 | loss: 2.2954185
MixupTrain:  epoch  0, batch   249 | loss: 2.2790914
MixupTrain:  epoch  0, batch   250 | loss: 2.2867427
MixupTrain:  epoch  0, batch   251 | loss: 2.3446002
MixupTrain:  epoch  0, batch   252 | loss: 2.5527766
MixupTrain:  epoch  0, batch   253 | loss: 2.3261671
MixupTrain:  epoch  0, batch   254 | loss: 2.4064527
MixupTrain:  epoch  0, batch   255 | loss: 2.4698665
MixupTrain:  epoch  0, batch   256 | loss: 2.2244992
MixupTrain:  epoch  0, batch   257 | loss: 2.2849307
MixupTrain:  epoch  0, batch   258 | loss: 2.2278323
MixupTrain:  epoch  0, batch   259 | loss: 2.3353500
MixupTrain:  epoch  0, batch   260 | loss: 2.3717403
MixupTrain:  epoch  0, batch   261 | loss: 2.2197170
MixupTrain:  epoch  0, batch   262 | loss: 2.5008698
MixupTrain:  epoch  0, batch   263 | loss: 2.3210557
MixupTrain:  epoch  0, batch   264 | loss: 2.3764882
MixupTrain:  epoch  0, batch   265 | loss: 2.1606238
MixupTrain:  epoch  0, batch   266 | loss: 2.1196799
MixupTrain:  epoch  0, batch   267 | loss: 2.2954235
MixupTrain:  epoch  0, batch   268 | loss: 2.1783853
MixupTrain:  epoch  0, batch   269 | loss: 2.3571422
MixupTrain:  epoch  0, batch   270 | loss: 2.2815766
MixupTrain:  epoch  0, batch   271 | loss: 2.5725904
MixupTrain:  epoch  0, batch   272 | loss: 2.2489805
MixupTrain:  epoch  0, batch   273 | loss: 2.5622411
MixupTrain:  epoch  0, batch   274 | loss: 2.1412034
MixupTrain:  epoch  0, batch   275 | loss: 2.2500486
MixupTrain:  epoch  0, batch   276 | loss: 2.2606091
MixupTrain:  epoch  0, batch   277 | loss: 2.5041327
MixupTrain:  epoch  0, batch   278 | loss: 2.2687266
MixupTrain:  epoch  0, batch   279 | loss: 2.5769606
MixupTrain:  epoch  0, batch   280 | loss: 2.2318628
MixupTrain:  epoch  0, batch   281 | loss: 2.2112126
MixupTrain:  epoch  0, batch   282 | loss: 2.2704706
MixupTrain:  epoch  0, batch   283 | loss: 2.4894447
MixupTrain:  epoch  0, batch   284 | loss: 2.2229359
MixupTrain:  epoch  0, batch   285 | loss: 2.3321435
MixupTrain:  epoch  0, batch   286 | loss: 2.5081587
MixupTrain:  epoch  0, batch   287 | loss: 2.1735582
MixupTrain:  epoch  0, batch   288 | loss: 2.3875680
MixupTrain:  epoch  0, batch   289 | loss: 2.3983479
MixupTrain:  epoch  0, batch   290 | loss: 2.2679174
MixupTrain:  epoch  0, batch   291 | loss: 2.4073665
MixupTrain:  epoch  0, batch   292 | loss: 2.2688539
MixupTrain:  epoch  0, batch   293 | loss: 2.4420826
MixupTrain:  epoch  0, batch   294 | loss: 2.5990777
MixupTrain:  epoch  0, batch   295 | loss: 2.2697241
MixupTrain:  epoch  0, batch   296 | loss: 2.1280644
MixupTrain:  epoch  0, batch   297 | loss: 2.3483529
MixupTrain:  epoch  0, batch   298 | loss: 2.1870098
MixupTrain:  epoch  0, batch   299 | loss: 2.2160707
MixupTrain:  epoch  0, batch   300 | loss: 2.3161776
MixupTrain:  epoch  0, batch   301 | loss: 2.3302047
MixupTrain:  epoch  0, batch   302 | loss: 2.1731148
MixupTrain:  epoch  0, batch   303 | loss: 2.1244802
MixupTrain:  epoch  0, batch   304 | loss: 2.4726691
MixupTrain:  epoch  0, batch   305 | loss: 2.3367839
MixupTrain:  epoch  0, batch   306 | loss: 2.1743870
MixupTrain:  epoch  0, batch   307 | loss: 2.2852073
MixupTrain:  epoch  0, batch   308 | loss: 2.3938420
MixupTrain:  epoch  0, batch   309 | loss: 2.5363474
MixupTrain:  epoch  0, batch   310 | loss: 2.3640656
MixupTrain:  epoch  0, batch   311 | loss: 2.5433850
MixupTrain:  epoch  0, batch   312 | loss: 2.2728758
MixupTrain:  epoch  0, batch   313 | loss: 2.4891233
MixupTrain:  epoch  0, batch   314 | loss: 2.4469531
MixupTrain:  epoch  0, batch   315 | loss: 2.2960503
MixupTrain:  epoch  0, batch   316 | loss: 2.5038943
MixupTrain:  epoch  0, batch   317 | loss: 2.2400708
MixupTrain:  epoch  0, batch   318 | loss: 2.1615081
MixupTrain:  epoch  0, batch   319 | loss: 2.3886328
MixupTrain:  epoch  0, batch   320 | loss: 2.2909012
MixupTrain:  epoch  0, batch   321 | loss: 2.1522243
MixupTrain:  epoch  0, batch   322 | loss: 2.3908067
MixupTrain:  epoch  0, batch   323 | loss: 2.3100729
MixupTrain:  epoch  0, batch   324 | loss: 2.2739542
MixupTrain:  epoch  0, batch   325 | loss: 2.3834243
MixupTrain:  epoch  0, batch   326 | loss: 2.3029480
MixupTrain:  epoch  0, batch   327 | loss: 2.2010839
MixupTrain:  epoch  0, batch   328 | loss: 2.3559828
MixupTrain:  epoch  0, batch   329 | loss: 2.3088078
MixupTrain:  epoch  0, batch   330 | loss: 2.4058046
MixupTrain:  epoch  0, batch   331 | loss: 2.1802821
MixupTrain:  epoch  0, batch   332 | loss: 2.4561970
MixupTrain:  epoch  0, batch   333 | loss: 2.2476850
MixupTrain:  epoch  0, batch   334 | loss: 2.3424716
MixupTrain:  epoch  0, batch   335 | loss: 2.3622470
MixupTrain:  epoch  0, batch   336 | loss: 2.3270752
MixupTrain:  epoch  0, batch   337 | loss: 2.3823085
MixupTrain:  epoch  0, batch   338 | loss: 2.2779403
MixupTrain:  epoch  0, batch   339 | loss: 2.1500871
MixupTrain:  epoch  0, batch   340 | loss: 2.2104552
MixupTrain:  epoch  0, batch   341 | loss: 2.3883967
MixupTrain:  epoch  0, batch   342 | loss: 2.2555938
MixupTrain:  epoch  0, batch   343 | loss: 2.4589548
MixupTrain:  epoch  0, batch   344 | loss: 2.1843905
MixupTrain:  epoch  0, batch   345 | loss: 2.3487015
MixupTrain:  epoch  0, batch   346 | loss: 2.0286236
MixupTrain:  epoch  0, batch   347 | loss: 2.3916850
MixupTrain:  epoch  0, batch   348 | loss: 2.3374724
MixupTrain:  epoch  0, batch   349 | loss: 2.4178095
MixupTrain:  epoch  0, batch   350 | loss: 2.3139338
MixupTrain:  epoch  0, batch   351 | loss: 2.2854247
MixupTrain:  epoch  0, batch   352 | loss: 2.2251940
MixupTrain:  epoch  0, batch   353 | loss: 2.6040285
MixupTrain:  epoch  0, batch   354 | loss: 2.1217446
MixupTrain:  epoch  0, batch   355 | loss: 2.4024258
MixupTrain:  epoch  0, batch   356 | loss: 2.3129377
MixupTrain:  epoch  0, batch   357 | loss: 2.2560611
MixupTrain:  epoch  0, batch   358 | loss: 2.3365059
MixupTrain:  epoch  0, batch   359 | loss: 2.2988782
MixupTrain:  epoch  0, batch   360 | loss: 2.3998539
MixupTrain:  epoch  0, batch   361 | loss: 2.3490551
MixupTrain:  epoch  0, batch   362 | loss: 2.2246022
MixupTrain:  epoch  0, batch   363 | loss: 2.3674328
MixupTrain:  epoch  0, batch   364 | loss: 2.2960794
MixupTrain:  epoch  0, batch   365 | loss: 2.3602667
MixupTrain:  epoch  0, batch   366 | loss: 2.1981363
MixupTrain:  epoch  0, batch   367 | loss: 2.2605562
MixupTrain:  epoch  0, batch   368 | loss: 2.3726811
MixupTrain:  epoch  0, batch   369 | loss: 2.2372973
MixupTrain:  epoch  0, batch   370 | loss: 2.3908556
MixupTrain:  epoch  0, batch   371 | loss: 2.3662910
MixupTrain:  epoch  0, batch   372 | loss: 2.4094951
MixupTrain:  epoch  0, batch   373 | loss: 2.2729321
MixupTrain:  epoch  0, batch   374 | loss: 2.2180738
MixupTrain:  epoch  0, batch   375 | loss: 2.2101841
MixupTrain:  epoch  0, batch   376 | loss: 2.2551217
MixupTrain:  epoch  0, batch   377 | loss: 2.3669529
MixupTrain:  epoch  0, batch   378 | loss: 2.4910638
MixupTrain:  epoch  0, batch   379 | loss: 2.2551947
MixupTrain:  epoch  0, batch   380 | loss: 2.2355032
MixupTrain:  epoch  0, batch   381 | loss: 2.0829673
MixupTrain:  epoch  0, batch   382 | loss: 2.4711351
MixupTrain:  epoch  0, batch   383 | loss: 2.2032976
MixupTrain:  epoch  0, batch   384 | loss: 2.3341784
MixupTrain:  epoch  0, batch   385 | loss: 2.2662611
MixupTrain:  epoch  0, batch   386 | loss: 2.3493061
MixupTrain:  epoch  0, batch   387 | loss: 2.2031322
MixupTrain:  epoch  0, batch   388 | loss: 2.2714903
MixupTrain:  epoch  0, batch   389 | loss: 2.1415243
MixupTrain:  epoch  0, batch   390 | loss: 2.3985729
MixupTrain:  epoch  0, batch   391 | loss: 2.2764103
MixupTrain:  epoch  0, batch   392 | loss: 2.4703679
MixupTrain:  epoch  0, batch   393 | loss: 2.2223024
MixupTrain:  epoch  0, batch   394 | loss: 2.4456022
MixupTrain:  epoch  0, batch   395 | loss: 2.0133317
MixupTrain:  epoch  0, batch   396 | loss: 2.1409454
MixupTrain:  epoch  0, batch   397 | loss: 2.0460906
MixupTrain:  epoch  0, batch   398 | loss: 2.2777309
MixupTrain:  epoch  0, batch   399 | loss: 2.1796446
MixupTrain:  epoch  0, batch   400 | loss: 2.1673257
MixupTrain:  epoch  0, batch   401 | loss: 2.2217789
MixupTrain:  epoch  0, batch   402 | loss: 2.4045005
MixupTrain:  epoch  0, batch   403 | loss: 2.4244311
MixupTrain:  epoch  0, batch   404 | loss: 2.1609406
MixupTrain:  epoch  0, batch   405 | loss: 2.3099964
MixupTrain:  epoch  0, batch   406 | loss: 2.1091709
MixupTrain:  epoch  0, batch   407 | loss: 2.3103004
MixupTrain:  epoch  0, batch   408 | loss: 2.1146960
MixupTrain:  epoch  0, batch   409 | loss: 2.1669860
MixupTrain:  epoch  0, batch   410 | loss: 2.3445959
MixupTrain:  epoch  0, batch   411 | loss: 2.4025445
MixupTrain:  epoch  0, batch   412 | loss: 2.5231204
MixupTrain:  epoch  0, batch   413 | loss: 2.4705725
MixupTrain:  epoch  0, batch   414 | loss: 2.0581827
MixupTrain:  epoch  0, batch   415 | loss: 2.1395791
MixupTrain:  epoch  0, batch   416 | loss: 2.2036052
MixupTrain:  epoch  0, batch   417 | loss: 2.2112014
MixupTrain:  epoch  0, batch   418 | loss: 2.2973170
MixupTrain:  epoch  0, batch   419 | loss: 2.2785029
MixupTrain:  epoch  0, batch   420 | loss: 2.3674741
MixupTrain:  epoch  0, batch   421 | loss: 2.3304174
MixupTrain:  epoch  0, batch   422 | loss: 2.3165312
MixupTrain:  epoch  0, batch   423 | loss: 2.2162824
MixupTrain:  epoch  0, batch   424 | loss: 2.0553858
MixupTrain:  epoch  0, batch   425 | loss: 2.2906160
MixupTrain:  epoch  0, batch   426 | loss: 2.2139869
MemoryTrain:  epoch  0, batch     0 | loss: 2.3026400
MemoryTrain:  epoch  0, batch     1 | loss: 3.2388978
MemoryTrain:  epoch  0, batch     2 | loss: 3.0687017
MemoryTrain:  epoch  0, batch     3 | loss: 3.1349850
MemoryTrain:  epoch  0, batch     4 | loss: 2.5235138
MemoryTrain:  epoch  0, batch     5 | loss: 2.1507905
MemoryTrain:  epoch  1, batch     0 | loss: 1.8639159
MemoryTrain:  epoch  1, batch     1 | loss: 1.8535743
MemoryTrain:  epoch  1, batch     2 | loss: 1.9298480
MemoryTrain:  epoch  1, batch     3 | loss: 2.2347832
MemoryTrain:  epoch  1, batch     4 | loss: 1.9237342
MemoryTrain:  epoch  1, batch     5 | loss: 1.8847920
MemoryTrain:  epoch  2, batch     0 | loss: 2.0384576
MemoryTrain:  epoch  2, batch     1 | loss: 1.8952253
MemoryTrain:  epoch  2, batch     2 | loss: 2.0259411
MemoryTrain:  epoch  2, batch     3 | loss: 1.8495733
MemoryTrain:  epoch  2, batch     4 | loss: 1.8365798
MemoryTrain:  epoch  2, batch     5 | loss: 1.8541859
MemoryTrain:  epoch  3, batch     0 | loss: 1.8610344
MemoryTrain:  epoch  3, batch     1 | loss: 1.8853054
MemoryTrain:  epoch  3, batch     2 | loss: 1.8674178
MemoryTrain:  epoch  3, batch     3 | loss: 1.8823377
MemoryTrain:  epoch  3, batch     4 | loss: 1.8311894
MemoryTrain:  epoch  3, batch     5 | loss: 1.8654292
MemoryTrain:  epoch  4, batch     0 | loss: 1.8340889
MemoryTrain:  epoch  4, batch     1 | loss: 1.8470663
MemoryTrain:  epoch  4, batch     2 | loss: 1.8326762
MemoryTrain:  epoch  4, batch     3 | loss: 1.8745844
MemoryTrain:  epoch  4, batch     4 | loss: 1.8638262
MemoryTrain:  epoch  4, batch     5 | loss: 1.8389912
MemoryTrain:  epoch  5, batch     0 | loss: 1.8614101
MemoryTrain:  epoch  5, batch     1 | loss: 1.8572798
MemoryTrain:  epoch  5, batch     2 | loss: 1.8445286
MemoryTrain:  epoch  5, batch     3 | loss: 1.8418610
MemoryTrain:  epoch  5, batch     4 | loss: 1.8310276
MemoryTrain:  epoch  5, batch     5 | loss: 1.8436103
MemoryTrain:  epoch  6, batch     0 | loss: 1.8212115
MemoryTrain:  epoch  6, batch     1 | loss: 1.8228090
MemoryTrain:  epoch  6, batch     2 | loss: 1.8483503
MemoryTrain:  epoch  6, batch     3 | loss: 1.8373212
MemoryTrain:  epoch  6, batch     4 | loss: 1.8500934
MemoryTrain:  epoch  6, batch     5 | loss: 1.8402343
MemoryTrain:  epoch  7, batch     0 | loss: 1.8660244
MemoryTrain:  epoch  7, batch     1 | loss: 1.8428149
MemoryTrain:  epoch  7, batch     2 | loss: 1.8459934
MemoryTrain:  epoch  7, batch     3 | loss: 1.8261153
MemoryTrain:  epoch  7, batch     4 | loss: 1.8434361
MemoryTrain:  epoch  7, batch     5 | loss: 1.8340728
MemoryTrain:  epoch  8, batch     0 | loss: 1.8472886
MemoryTrain:  epoch  8, batch     1 | loss: 1.8452718
MemoryTrain:  epoch  8, batch     2 | loss: 1.8516217
MemoryTrain:  epoch  8, batch     3 | loss: 1.8260916
MemoryTrain:  epoch  8, batch     4 | loss: 1.8396796
MemoryTrain:  epoch  8, batch     5 | loss: 1.8219765
MemoryTrain:  epoch  9, batch     0 | loss: 1.8443253
MemoryTrain:  epoch  9, batch     1 | loss: 1.8550563
MemoryTrain:  epoch  9, batch     2 | loss: 1.8848863
MemoryTrain:  epoch  9, batch     3 | loss: 1.8824298
MemoryTrain:  epoch  9, batch     4 | loss: 1.8385506
MemoryTrain:  epoch  9, batch     5 | loss: 1.8951972
[EVAL] batch:    0 | acc: 87.50%,  total acc: 87.50%   
[EVAL] batch:    1 | acc: 100.00%,  total acc: 93.75%   
[EVAL] batch:    2 | acc: 100.00%,  total acc: 95.83%   
[EVAL] batch:    3 | acc: 93.75%,  total acc: 95.31%   
[EVAL] batch:    4 | acc: 93.75%,  total acc: 95.00%   
[EVAL] batch:    5 | acc: 81.25%,  total acc: 92.71%   
[EVAL] batch:    6 | acc: 68.75%,  total acc: 89.29%   
[EVAL] batch:    7 | acc: 93.75%,  total acc: 89.84%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 90.97%   
[EVAL] batch:    9 | acc: 87.50%,  total acc: 90.62%   
[EVAL] batch:   10 | acc: 87.50%,  total acc: 90.34%   
[EVAL] batch:   11 | acc: 81.25%,  total acc: 89.58%   
[EVAL] batch:   12 | acc: 81.25%,  total acc: 88.94%   
[EVAL] batch:   13 | acc: 0.00%,  total acc: 82.59%   
[EVAL] batch:    0 | acc: 6.25%,  total acc: 6.25%   
[EVAL] batch:    1 | acc: 25.00%,  total acc: 15.62%   
[EVAL] batch:    2 | acc: 25.00%,  total acc: 18.75%   
[EVAL] batch:    3 | acc: 6.25%,  total acc: 15.62%   
[EVAL] batch:    4 | acc: 6.25%,  total acc: 13.75%   
[EVAL] batch:    5 | acc: 31.25%,  total acc: 16.67%   
[EVAL] batch:    6 | acc: 87.50%,  total acc: 26.79%   
[EVAL] batch:    7 | acc: 87.50%,  total acc: 34.38%   
[EVAL] batch:    8 | acc: 100.00%,  total acc: 41.67%   
[EVAL] batch:    9 | acc: 81.25%,  total acc: 45.62%   
[EVAL] batch:   10 | acc: 100.00%,  total acc: 50.57%   
[EVAL] batch:   11 | acc: 93.75%,  total acc: 54.17%   
[EVAL] batch:   12 | acc: 75.00%,  total acc: 55.77%   
[EVAL] batch:   13 | acc: 56.25%,  total acc: 55.80%   
[EVAL] batch:   14 | acc: 75.00%,  total acc: 57.08%   
[EVAL] batch:   15 | acc: 56.25%,  total acc: 57.03%   
[EVAL] batch:   16 | acc: 75.00%,  total acc: 58.09%   
[EVAL] batch:   17 | acc: 62.50%,  total acc: 58.33%   
[EVAL] batch:   18 | acc: 62.50%,  total acc: 58.55%   
[EVAL] batch:   19 | acc: 87.50%,  total acc: 60.00%   
[EVAL] batch:   20 | acc: 100.00%,  total acc: 61.90%   
[EVAL] batch:   21 | acc: 100.00%,  total acc: 63.64%   
[EVAL] batch:   22 | acc: 100.00%,  total acc: 65.22%   
[EVAL] batch:   23 | acc: 100.00%,  total acc: 66.67%   
[EVAL] batch:   24 | acc: 100.00%,  total acc: 68.00%   
[EVAL] batch:   25 | acc: 100.00%,  total acc: 69.23%   
[EVAL] batch:   26 | acc: 93.75%,  total acc: 70.14%   
[EVAL] batch:   27 | acc: 100.00%,  total acc: 71.21%   
[EVAL] batch:   28 | acc: 100.00%,  total acc: 72.20%   
[EVAL] batch:   29 | acc: 81.25%,  total acc: 72.50%   
[EVAL] batch:   30 | acc: 100.00%,  total acc: 73.39%   
[EVAL] batch:   31 | acc: 93.75%,  total acc: 74.02%   
[EVAL] batch:   32 | acc: 87.50%,  total acc: 74.43%   
[EVAL] batch:   33 | acc: 75.00%,  total acc: 74.45%   
[EVAL] batch:   34 | acc: 81.25%,  total acc: 74.64%   
[EVAL] batch:   35 | acc: 75.00%,  total acc: 74.65%   
[EVAL] batch:   36 | acc: 81.25%,  total acc: 74.83%   
[EVAL] batch:   37 | acc: 75.00%,  total acc: 74.84%   
[EVAL] batch:   38 | acc: 75.00%,  total acc: 74.84%   
[EVAL] batch:   39 | acc: 75.00%,  total acc: 74.84%   
[EVAL] batch:   40 | acc: 56.25%,  total acc: 74.39%   
[EVAL] batch:   41 | acc: 18.75%,  total acc: 73.07%   
[EVAL] batch:   42 | acc: 25.00%,  total acc: 71.95%   
[EVAL] batch:   43 | acc: 62.50%,  total acc: 71.73%   
[EVAL] batch:   44 | acc: 100.00%,  total acc: 72.36%   
[EVAL] batch:   45 | acc: 100.00%,  total acc: 72.96%   
[EVAL] batch:   46 | acc: 100.00%,  total acc: 73.54%   
[EVAL] batch:   47 | acc: 100.00%,  total acc: 74.09%   
[EVAL] batch:   48 | acc: 100.00%,  total acc: 74.62%   
[EVAL] batch:   49 | acc: 93.75%,  total acc: 75.00%   
[EVAL] batch:   50 | acc: 87.50%,  total acc: 75.25%   
[EVAL] batch:   51 | acc: 100.00%,  total acc: 75.72%   
[EVAL] batch:   52 | acc: 100.00%,  total acc: 76.18%   
[EVAL] batch:   53 | acc: 93.75%,  total acc: 76.50%   
[EVAL] batch:   54 | acc: 81.25%,  total acc: 76.59%   
[EVAL] batch:   55 | acc: 81.25%,  total acc: 76.67%   
[EVAL] batch:   56 | acc: 81.25%,  total acc: 76.75%   
[EVAL] batch:   57 | acc: 93.75%,  total acc: 77.05%   
[EVAL] batch:   58 | acc: 93.75%,  total acc: 77.33%   
[EVAL] batch:   59 | acc: 93.75%,  total acc: 77.60%   
[EVAL] batch:   60 | acc: 75.00%,  total acc: 77.56%   
[EVAL] batch:   61 | acc: 93.75%,  total acc: 77.82%   
[EVAL] batch:   62 | acc: 43.75%,  total acc: 77.28%   
[EVAL] batch:   63 | acc: 0.00%,  total acc: 76.07%   
cur_acc:  ['0.8693', '0.9132', '0.8259']
his_acc:  ['0.8693', '0.8375', '0.7607']
CurrentTrain: epoch  0, batch     0 | loss: 3.7414479
CurrentTrain: epoch  0, batch     1 | loss: 4.6371217
CurrentTrain: epoch  1, batch     0 | loss: 3.7118723
CurrentTrain: epoch  1, batch     1 | loss: 2.6337521
CurrentTrain: epoch  2, batch     0 | loss: 2.7954545
CurrentTrain: epoch  2, batch     1 | loss: 2.7837894
CurrentTrain: epoch  3, batch     0 | loss: 2.5783055
CurrentTrain: epoch  3, batch     1 | loss: 2.6188061
CurrentTrain: epoch  4, batch     0 | loss: 2.5448503
CurrentTrain: epoch  4, batch     1 | loss: 2.3629296
CurrentTrain: epoch  5, batch     0 | loss: 2.0530243
CurrentTrain: epoch  5, batch     1 | loss: 2.7519462
CurrentTrain: epoch  6, batch     0 | loss: 2.1353254
CurrentTrain: epoch  6, batch     1 | loss: 2.2919195
CurrentTrain: epoch  7, batch     0 | loss: 2.0789132
CurrentTrain: epoch  7, batch     1 | loss: 2.0405390
CurrentTrain: epoch  8, batch     0 | loss: 2.1233940
CurrentTrain: epoch  8, batch     1 | loss: 1.8077791
CurrentTrain: epoch  9, batch     0 | loss: 2.0480666
CurrentTrain: epoch  9, batch     1 | loss: 1.8215741
#### organization founded ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization founded" means an organization was found in a date.
Here is an example:
Relation: organization founded
Context: pandit worked at the brokerage morgan stanley for about 11 years until 2005 , when he and some morgan stanley colleagues quit and later founded the hedge fund old lane partners .
Head Entity: old lane partners
Tail Entity: 2005
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization founded":
Relation: organization founded  
Context: In 1998, a group of engineers and entrepreneurs came together to establish the tech startup, Innovatech Solutions, which has since become a leader in software development.  
Head Entity: Innovatech Solutions  
Tail Entity: 1998  

Relation: organization founded  
Context: The non-profit organization Green Earth Initiative was launched in 2010 to promote environmental awareness and sustainability practices across communities.  
Head Entity: Green Earth Initiative  
Tail Entity: 2010  

Relation: organization founded  
Context: After years of research and development, the pharmaceutical company HealthPlus was officially founded in 2015 to focus on innovative healthcare solutions.  
Head Entity: HealthPlus  
Tail Entity: 2015  

Relation: organization founded  
Context: In 2001, the educational institution Future Leaders Academy was established to provide quality education and leadership training to young students.  
Head Entity: Future Leaders Academy  
Tail Entity: 2001  

Relation: organization founded  
Context: The fashion brand EcoWear was founded in 2018 by a group of designers committed to sustainable and ethical clothing production.  
Head Entity: EcoWear  
Tail Entity: 2018  
#### person age ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person age" means a person 's age is a number.
Here is an example:
Relation: person age
Context: virginia republican jo ann davis passed away on saturday at the age of 57 .
Head Entity: jo ann davis
Tail Entity: 57
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person age":
Relation: person age  
Context: the famous actor robert downey jr. celebrated his 56th birthday last week.  
Head Entity: robert downey jr.  
Tail Entity: 56  

Relation: person age  
Context: on her 30th birthday, emily decided to throw a big party for her friends.  
Head Entity: emily  
Tail Entity: 30  

Relation: person age  
Context: the renowned scientist albert einstein was born in 1879, making him 76 years old when he passed away.  
Head Entity: albert einstein  
Tail Entity: 76  

Relation: person age  
Context: during the interview, the journalist revealed that she is 45 years old.  
Head Entity: the journalist  
Tail Entity: 45  

Relation: person age  
Context: my grandmother turned 80 last month, and we celebrated her life with a family gathering.  
Head Entity: my grandmother  
Tail Entity: 80  
#### person city of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person city of birth" means a person was born in a city.
Here is an example:
Relation: person city of birth
Context: joseph simpson farland was born on aug 11 , 1914 , in clarksburg , wva , the only child of richard and grace simpson farland .
Head Entity: joseph simpson farland
Tail Entity: clarksburg
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person city of birth":
Relation: person city of birth  
Context: emma watson was born on april 15, 1990, in paris, france, where she spent her early childhood.  
Head Entity: emma watson  
Tail Entity: paris  

Relation: person city of birth  
Context: barack obama was born on august 4, 1961, in honolulu, hawaii, which played a significant role in his upbringing.  
Head Entity: barack obama  
Tail Entity: honolulu  

Relation: person city of birth  
Context: frida kahlo was born on july 6, 1907, in coyoacán, mexico, a place that greatly influenced her art.  
Head Entity: frida kahlo  
Tail Entity: coyoacán  

Relation: person city of birth  
Context: albert einstein was born on march 14, 1879, in ulm, germany, before moving to munich with his family.  
Head Entity: albert einstein  
Tail Entity: ulm  

Relation: person city of birth  
Context: malala yousafzai was born on july 12, 1997, in mingora, pakistan, where she began her advocacy for education.  
Head Entity: malala yousafzai  
Tail Entity: mingora  
#### organization members ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization members" means an organization 's member is an organization.
Here is an example:
Relation: organization members
Context: sun plays for the grand rapids flight of the international basketball league after toiling for the maryland nighthawks of the american basketball association , both development leagues for those who dream of an nba career .
Head Entity: american basketball association
Tail Entity: maryland nighthawks
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization members":
Relation: organization members  
Context: The New York Philharmonic is one of the oldest orchestras in the United States, and it has had many notable musicians, including members from the London Symphony Orchestra.  
Head Entity: London Symphony Orchestra  
Tail Entity: New York Philharmonic  

Relation: organization members  
Context: The National Football League has several teams, including the Dallas Cowboys, which is known for its iconic cheerleaders who are members of the organization.  
Head Entity: Dallas Cowboys  
Tail Entity: NFL Cheerleaders  

Relation: organization members  
Context: The United Nations consists of various specialized agencies, including the World Health Organization, which plays a crucial role in global health initiatives.  
Head Entity: World Health Organization  
Tail Entity: United Nations  

Relation: organization members  
Context: The International Olympic Committee oversees the Olympic Games and has various national committees, such as the United States Olympic and Paralympic Committee, which is responsible for American athletes.  
Head Entity: United States Olympic and Paralympic Committee  
Tail Entity: International Olympic Committee  

Relation: organization members  
Context: The International Red Cross is known for its humanitarian efforts, and it has numerous local chapters, including the American Red Cross, which serves communities across the United States.  
Head Entity: American Red Cross  
Tail Entity: International Red Cross  
#### person religion ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person religion" means an person is the member of a religion.
Here is an example:
Relation: person religion
Context: the pope defended his action on the grounds that he could not refuse an audience to a head of state from a country with a strong catholic tradition unless he had clear-cut proof of the allegations against him .
Head Entity: he
Tail Entity: catholic
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person religion":
1. Relation: person religion  
   Context: After years of study and reflection, Maria decided to embrace Buddhism, finding peace and purpose in its teachings.  
   Head Entity: Maria  
   Tail Entity: Buddhism  

2. Relation: person religion  
   Context: During the festival, Ahmed proudly wore his traditional attire, celebrating his deep connection to Islam and its rich cultural heritage.  
   Head Entity: Ahmed  
   Tail Entity: Islam  

3. Relation: person religion  
   Context: The community gathered to honor Rabbi Cohen, who has been a guiding light in their Jewish faith for over three decades.  
   Head Entity: Rabbi Cohen  
   Tail Entity: Jewish  

4. Relation: person religion  
   Context: As a lifelong member of the Quaker community, John often speaks about the values of peace and simplicity that guide his life.  
   Head Entity: John  
   Tail Entity: Quaker  

5. Relation: person religion  
   Context: Growing up in a Hindu household, Priya participated in various rituals that deepened her understanding of her faith.  
   Head Entity: Priya  
   Tail Entity: Hindu  
Mixup data size:  10810
MixupTrain:  epoch  0, batch     0 | loss: 4.6721740
MixupTrain:  epoch  0, batch     1 | loss: 4.0359478
MixupTrain:  epoch  0, batch     2 | loss: 3.7383695
MixupTrain:  epoch  0, batch     3 | loss: 3.8494823
MixupTrain:  epoch  0, batch     4 | loss: 3.8863664
MixupTrain:  epoch  0, batch     5 | loss: 3.7241540
MixupTrain:  epoch  0, batch     6 | loss: 3.5618708
MixupTrain:  epoch  0, batch     7 | loss: 3.7025843
MixupTrain:  epoch  0, batch     8 | loss: 3.7507858
MixupTrain:  epoch  0, batch     9 | loss: 3.9411669
MixupTrain:  epoch  0, batch    10 | loss: 3.6190944
MixupTrain:  epoch  0, batch    11 | loss: 4.0223551
MixupTrain:  epoch  0, batch    12 | loss: 3.1488607
MixupTrain:  epoch  0, batch    13 | loss: 3.0544271
MixupTrain:  epoch  0, batch    14 | loss: 3.6079373
MixupTrain:  epoch  0, batch    15 | loss: 3.1598425
MixupTrain:  epoch  0, batch    16 | loss: 3.5652134
MixupTrain:  epoch  0, batch    17 | loss: 3.5660391
MixupTrain:  epoch  0, batch    18 | loss: 3.0553660
MixupTrain:  epoch  0, batch    19 | loss: 3.5354297
MixupTrain:  epoch  0, batch    20 | loss: 2.8976996
MixupTrain:  epoch  0, batch    21 | loss: 3.3130064
MixupTrain:  epoch  0, batch    22 | loss: 3.1210527
MixupTrain:  epoch  0, batch    23 | loss: 3.3467183
MixupTrain:  epoch  0, batch    24 | loss: 3.3820198
MixupTrain:  epoch  0, batch    25 | loss: 3.3580222
MixupTrain:  epoch  0, batch    26 | loss: 2.7765844
MixupTrain:  epoch  0, batch    27 | loss: 3.7758956
MixupTrain:  epoch  0, batch    28 | loss: 3.5598125
MixupTrain:  epoch  0, batch    29 | loss: 3.0273645
MixupTrain:  epoch  0, batch    30 | loss: 3.6790059
MixupTrain:  epoch  0, batch    31 | loss: 3.6388388
MixupTrain:  epoch  0, batch    32 | loss: 3.1398199
MixupTrain:  epoch  0, batch    33 | loss: 2.7591813
MixupTrain:  epoch  0, batch    34 | loss: 3.3370149
MixupTrain:  epoch  0, batch    35 | loss: 3.3825266
MixupTrain:  epoch  0, batch    36 | loss: 3.4289508
MixupTrain:  epoch  0, batch    37 | loss: 2.9655261
MixupTrain:  epoch  0, batch    38 | loss: 3.0602400
MixupTrain:  epoch  0, batch    39 | loss: 2.6666682
MixupTrain:  epoch  0, batch    40 | loss: 2.7211728
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2197, 2005, 2023, 1010, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 4]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 5]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 3]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 5]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 3]}
{'ids': [101, 2342, 5678, 1234, 4321, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [5, 3]}
#############params############
cuda:0
Task=Tacred, 5-shot
Encoding model: bert
pattern=hardprompt
mem=1, margin=0.3, gen=1, gen_num=5
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
CurrentTrain: epoch  0, batch     0 | loss: 12.2377892CurrentTrain: epoch  0, batch     1 | loss: 11.8358202CurrentTrain: epoch  0, batch     2 | loss: 11.5842304CurrentTrain: epoch  0, batch     3 | loss: 11.7963333CurrentTrain: epoch  0, batch     4 | loss: 11.3291626CurrentTrain: epoch  0, batch     5 | loss: 11.3988247CurrentTrain: epoch  0, batch     6 | loss: 11.4306774CurrentTrain: epoch  0, batch     7 | loss: 11.4957294CurrentTrain: epoch  0, batch     8 | loss: 10.9524660CurrentTrain: epoch  0, batch     9 | loss: 11.0981150CurrentTrain: epoch  0, batch    10 | loss: 11.0817156CurrentTrain: epoch  0, batch    11 | loss: 11.0157957CurrentTrain: epoch  0, batch    12 | loss: 10.9861202CurrentTrain: epoch  0, batch    13 | loss: 10.7110462CurrentTrain: epoch  0, batch    14 | loss: 10.5633354CurrentTrain: epoch  0, batch    15 | loss: 10.2521629CurrentTrain: epoch  0, batch    16 | loss: 9.5208607CurrentTrain: epoch  0, batch    17 | loss: 10.0118418CurrentTrain: epoch  0, batch    18 | loss: 9.9925213CurrentTrain: epoch  0, batch    19 | loss: 10.5049925CurrentTrain: epoch  0, batch    20 | loss: 9.9245691CurrentTrain: epoch  0, batch    21 | loss: 10.7969608CurrentTrain: epoch  0, batch    22 | loss: 10.3663940CurrentTrain: epoch  0, batch    23 | loss: 9.9787502CurrentTrain: epoch  0, batch    24 | loss: 10.1565428CurrentTrain: epoch  0, batch    25 | loss: 9.8991623CurrentTrain: epoch  0, batch    26 | loss: 10.0962982CurrentTrain: epoch  0, batch    27 | loss: 9.3844519CurrentTrain: epoch  0, batch    28 | loss: 9.7764397CurrentTrain: epoch  0, batch    29 | loss: 9.7736034CurrentTrain: epoch  0, batch    30 | loss: 9.4480782CurrentTrain: epoch  0, batch    31 | loss: 9.9147511CurrentTrain: epoch  0, batch    32 | loss: 9.6330633CurrentTrain: epoch  0, batch    33 | loss: 9.6556149CurrentTrain: epoch  0, batch    34 | loss: 8.9573956CurrentTrain: epoch  0, batch    35 | loss: 9.5650816CurrentTrain: epoch  0, batch    36 | loss: 9.7023954CurrentTrain: epoch  0, batch    37 | loss: 9.6724091CurrentTrain: epoch  1, batch     0 | loss: 9.4604149CurrentTrain: epoch  1, batch     1 | loss: 10.1246471CurrentTrain: epoch  1, batch     2 | loss: 8.5899754CurrentTrain: epoch  1, batch     3 | loss: 9.2962093CurrentTrain: epoch  1, batch     4 | loss: 8.6637697CurrentTrain: epoch  1, batch     5 | loss: 9.6263733CurrentTrain: epoch  1, batch     6 | loss: 8.9486284CurrentTrain: epoch  1, batch     7 | loss: 9.0029678CurrentTrain: epoch  1, batch     8 | loss: 8.8491497CurrentTrain: epoch  1, batch     9 | loss: 8.9430141CurrentTrain: epoch  1, batch    10 | loss: 9.5420208CurrentTrain: epoch  1, batch    11 | loss: 9.6031132CurrentTrain: epoch  1, batch    12 | loss: 9.1848850CurrentTrain: epoch  1, batch    13 | loss: 8.3578682CurrentTrain: epoch  1, batch    14 | loss: 8.9222250CurrentTrain: epoch  1, batch    15 | loss: 8.7862034CurrentTrain: epoch  1, batch    16 | loss: 8.7784939CurrentTrain: epoch  1, batch    17 | loss: 9.0060778CurrentTrain: epoch  1, batch    18 | loss: 8.9019585CurrentTrain: epoch  1, batch    19 | loss: 9.1300135CurrentTrain: epoch  1, batch    20 | loss: 9.2238483CurrentTrain: epoch  1, batch    21 | loss: 8.7556190CurrentTrain: epoch  1, batch    22 | loss: 8.7446423CurrentTrain: epoch  1, batch    23 | loss: 8.4535732CurrentTrain: epoch  1, batch    24 | loss: 8.9085588CurrentTrain: epoch  1, batch    25 | loss: 7.8729029CurrentTrain: epoch  1, batch    26 | loss: 8.9874878CurrentTrain: epoch  1, batch    27 | loss: 8.0600681CurrentTrain: epoch  1, batch    28 | loss: 8.3288574CurrentTrain: epoch  1, batch    29 | loss: 7.3486710CurrentTrain: epoch  1, batch    30 | loss: 8.0324583CurrentTrain: epoch  1, batch    31 | loss: 9.0403643CurrentTrain: epoch  1, batch    32 | loss: 8.3986797CurrentTrain: epoch  1, batch    33 | loss: 8.3034315CurrentTrain: epoch  1, batch    34 | loss: 8.3720951CurrentTrain: epoch  1, batch    35 | loss: 7.7797775CurrentTrain: epoch  1, batch    36 | loss: 8.1887569CurrentTrain: epoch  1, batch    37 | loss: 9.3430576CurrentTrain: epoch  2, batch     0 | loss: 7.3662424CurrentTrain: epoch  2, batch     1 | loss: 8.3544626CurrentTrain: epoch  2, batch     2 | loss: 8.4783211CurrentTrain: epoch  2, batch     3 | loss: 7.9830246CurrentTrain: epoch  2, batch     4 | loss: 8.9861774CurrentTrain: epoch  2, batch     5 | loss: 9.1120319CurrentTrain: epoch  2, batch     6 | loss: 8.2785549CurrentTrain: epoch  2, batch     7 | loss: 7.8161860CurrentTrain: epoch  2, batch     8 | loss: 7.7946243CurrentTrain: epoch  2, batch     9 | loss: 8.1371365CurrentTrain: epoch  2, batch    10 | loss: 8.1274719CurrentTrain: epoch  2, batch    11 | loss: 8.1458416CurrentTrain: epoch  2, batch    12 | loss: 7.7329111CurrentTrain: epoch  2, batch    13 | loss: 7.4998751CurrentTrain: epoch  2, batch    14 | loss: 6.7733631CurrentTrain: epoch  2, batch    15 | loss: 7.4271975CurrentTrain: epoch  2, batch    16 | loss: 7.8946323CurrentTrain: epoch  2, batch    17 | loss: 8.1287365CurrentTrain: epoch  2, batch    18 | loss: 7.7022080CurrentTrain: epoch  2, batch    19 | loss: 7.6633844CurrentTrain: epoch  2, batch    20 | loss: 7.5645056CurrentTrain: epoch  2, batch    21 | loss: 7.2468576CurrentTrain: epoch  2, batch    22 | loss: 6.6268282CurrentTrain: epoch  2, batch    23 | loss: 7.0505657CurrentTrain: epoch  2, batch    24 | loss: 7.3652039CurrentTrain: epoch  2, batch    25 | loss: 7.9841595CurrentTrain: epoch  2, batch    26 | loss: 6.9228649CurrentTrain: epoch  2, batch    27 | loss: 8.3433628CurrentTrain: epoch  2, batch    28 | loss: 6.2205820CurrentTrain: epoch  2, batch    29 | loss: 7.9827604CurrentTrain: epoch  2, batch    30 | loss: 7.5686135CurrentTrain: epoch  2, batch    31 | loss: 6.7521391CurrentTrain: epoch  2, batch    32 | loss: 7.1855884CurrentTrain: epoch  2, batch    33 | loss: 7.1788774CurrentTrain: epoch  2, batch    34 | loss: 8.3621635CurrentTrain: epoch  2, batch    35 | loss: 6.9254699CurrentTrain: epoch  2, batch    36 | loss: 7.5592299CurrentTrain: epoch  2, batch    37 | loss: 6.8255949CurrentTrain: epoch  3, batch     0 | loss: 7.7647505CurrentTrain: epoch  3, batch     1 | loss: 7.5025458CurrentTrain: epoch  3, batch     2 | loss: 7.7400827CurrentTrain: epoch  3, batch     3 | loss: 8.1283417CurrentTrain: epoch  3, batch     4 | loss: 7.6592603CurrentTrain: epoch  3, batch     5 | loss: 7.6934776CurrentTrain: epoch  3, batch     6 | loss: 8.0932388CurrentTrain: epoch  3, batch     7 | loss: 6.8233399CurrentTrain: epoch  3, batch     8 | loss: 7.4070482CurrentTrain: epoch  3, batch     9 | loss: 7.3779402CurrentTrain: epoch  3, batch    10 | loss: 6.8089685CurrentTrain: epoch  3, batch    11 | loss: 6.3608518CurrentTrain: epoch  3, batch    12 | loss: 7.6196122CurrentTrain: epoch  3, batch    13 | loss: 8.0267200CurrentTrain: epoch  3, batch    14 | loss: 7.0713158CurrentTrain: epoch  3, batch    15 | loss: 7.1864080CurrentTrain: epoch  3, batch    16 | loss: 7.9409227CurrentTrain: epoch  3, batch    17 | loss: 7.0805454CurrentTrain: epoch  3, batch    18 | loss: 7.2674842CurrentTrain: epoch  3, batch    19 | loss: 7.0971551CurrentTrain: epoch  3, batch    20 | loss: 7.1673136CurrentTrain: epoch  3, batch    21 | loss: 7.2108817CurrentTrain: epoch  3, batch    22 | loss: 8.0766506CurrentTrain: epoch  3, batch    23 | loss: 7.5205364CurrentTrain: epoch  3, batch    24 | loss: 6.2361536CurrentTrain: epoch  3, batch    25 | loss: 6.7487731CurrentTrain: epoch  3, batch    26 | loss: 6.3052359CurrentTrain: epoch  3, batch    27 | loss: 7.1938982CurrentTrain: epoch  3, batch    28 | loss: 7.2758160CurrentTrain: epoch  3, batch    29 | loss: 5.9751406CurrentTrain: epoch  3, batch    30 | loss: 7.0339866CurrentTrain: epoch  3, batch    31 | loss: 7.0741363CurrentTrain: epoch  3, batch    32 | loss: 6.2167683CurrentTrain: epoch  3, batch    33 | loss: 5.7902369CurrentTrain: epoch  3, batch    34 | loss: 6.7244143CurrentTrain: epoch  3, batch    35 | loss: 6.2465477CurrentTrain: epoch  3, batch    36 | loss: 6.7644510CurrentTrain: epoch  3, batch    37 | loss: 6.6600256CurrentTrain: epoch  4, batch     0 | loss: 6.9214773CurrentTrain: epoch  4, batch     1 | loss: 6.3543296CurrentTrain: epoch  4, batch     2 | loss: 5.6729169CurrentTrain: epoch  4, batch     3 | loss: 6.7485514CurrentTrain: epoch  4, batch     4 | loss: 7.2618380CurrentTrain: epoch  4, batch     5 | loss: 6.6126189CurrentTrain: epoch  4, batch     6 | loss: 6.2170911CurrentTrain: epoch  4, batch     7 | loss: 6.6977735CurrentTrain: epoch  4, batch     8 | loss: 7.4788270CurrentTrain: epoch  4, batch     9 | loss: 6.5936441CurrentTrain: epoch  4, batch    10 | loss: 6.9046702CurrentTrain: epoch  4, batch    11 | loss: 6.0163383CurrentTrain: epoch  4, batch    12 | loss: 6.5755177CurrentTrain: epoch  4, batch    13 | loss: 6.2283492CurrentTrain: epoch  4, batch    14 | loss: 7.0001431CurrentTrain: epoch  4, batch    15 | loss: 6.6601152CurrentTrain: epoch  4, batch    16 | loss: 6.3596520CurrentTrain: epoch  4, batch    17 | loss: 6.3576050CurrentTrain: epoch  4, batch    18 | loss: 5.9598074CurrentTrain: epoch  4, batch    19 | loss: 6.0913982CurrentTrain: epoch  4, batch    20 | loss: 6.2184505CurrentTrain: epoch  4, batch    21 | loss: 6.5159440CurrentTrain: epoch  4, batch    22 | loss: 6.6188974CurrentTrain: epoch  4, batch    23 | loss: 5.9724197CurrentTrain: epoch  4, batch    24 | loss: 6.6317444CurrentTrain: epoch  4, batch    25 | loss: 6.5978203CurrentTrain: epoch  4, batch    26 | loss: 6.0009141CurrentTrain: epoch  4, batch    27 | loss: 7.6149282CurrentTrain: epoch  4, batch    28 | loss: 5.8510528CurrentTrain: epoch  4, batch    29 | loss: 6.1155725CurrentTrain: epoch  4, batch    30 | loss: 5.9866090CurrentTrain: epoch  4, batch    31 | loss: 6.0753689CurrentTrain: epoch  4, batch    32 | loss: 6.2112637CurrentTrain: epoch  4, batch    33 | loss: 5.6074681CurrentTrain: epoch  4, batch    34 | loss: 6.8721824CurrentTrain: epoch  4, batch    35 | loss: 6.1603594CurrentTrain: epoch  4, batch    36 | loss: 5.9010696CurrentTrain: epoch  4, batch    37 | loss: 6.5777607CurrentTrain: epoch  5, batch     0 | loss: 5.6601758CurrentTrain: epoch  5, batch     1 | loss: 6.0248494CurrentTrain: epoch  5, batch     2 | loss: 6.2602463CurrentTrain: epoch  5, batch     3 | loss: 6.3877387CurrentTrain: epoch  5, batch     4 | loss: 5.9552431CurrentTrain: epoch  5, batch     5 | loss: 5.9370213CurrentTrain: epoch  5, batch     6 | loss: 6.2484322CurrentTrain: epoch  5, batch     7 | loss: 6.5060091CurrentTrain: epoch  5, batch     8 | loss: 6.5059867CurrentTrain: epoch  5, batch     9 | loss: 5.7736840CurrentTrain: epoch  5, batch    10 | loss: 5.7672777CurrentTrain: epoch  5, batch    11 | loss: 6.0279074CurrentTrain: epoch  5, batch    12 | loss: 5.7482686CurrentTrain: epoch  5, batch    13 | loss: 5.9997821CurrentTrain: epoch  5, batch    14 | loss: 6.2035551CurrentTrain: epoch  5, batch    15 | loss: 6.5068035CurrentTrain: epoch  5, batch    16 | loss: 5.3515067CurrentTrain: epoch  5, batch    17 | loss: 5.5702515CurrentTrain: epoch  5, batch    18 | loss: 6.6157694CurrentTrain: epoch  5, batch    19 | loss: 7.0879307CurrentTrain: epoch  5, batch    20 | loss: 5.5562043CurrentTrain: epoch  5, batch    21 | loss: 5.8516216CurrentTrain: epoch  5, batch    22 | loss: 5.6183128CurrentTrain: epoch  5, batch    23 | loss: 6.0548382CurrentTrain: epoch  5, batch    24 | loss: 6.8281794CurrentTrain: epoch  5, batch    25 | loss: 5.7778754CurrentTrain: epoch  5, batch    26 | loss: 5.8007574CurrentTrain: epoch  5, batch    27 | loss: 5.6567163CurrentTrain: epoch  5, batch    28 | loss: 6.8478708CurrentTrain: epoch  5, batch    29 | loss: 6.6075182CurrentTrain: epoch  5, batch    30 | loss: 5.7610102CurrentTrain: epoch  5, batch    31 | loss: 5.8279133CurrentTrain: epoch  5, batch    32 | loss: 5.3630514CurrentTrain: epoch  5, batch    33 | loss: 5.9219146CurrentTrain: epoch  5, batch    34 | loss: 5.7536297CurrentTrain: epoch  5, batch    35 | loss: 5.9297442CurrentTrain: epoch  5, batch    36 | loss: 6.1582942CurrentTrain: epoch  5, batch    37 | loss: 5.3770695CurrentTrain: epoch  6, batch     0 | loss: 5.3385010CurrentTrain: epoch  6, batch     1 | loss: 5.7504702CurrentTrain: epoch  6, batch     2 | loss: 6.0827885CurrentTrain: epoch  6, batch     3 | loss: 6.0616360CurrentTrain: epoch  6, batch     4 | loss: 5.5673351CurrentTrain: epoch  6, batch     5 | loss: 5.4255438CurrentTrain: epoch  6, batch     6 | loss: 5.8536959CurrentTrain: epoch  6, batch     7 | loss: 5.7188549CurrentTrain: epoch  6, batch     8 | loss: 5.2314873CurrentTrain: epoch  6, batch     9 | loss: 5.6400099CurrentTrain: epoch  6, batch    10 | loss: 5.3543816CurrentTrain: epoch  6, batch    11 | loss: 5.3050299CurrentTrain: epoch  6, batch    12 | loss: 5.7439237CurrentTrain: epoch  6, batch    13 | loss: 5.4360719CurrentTrain: epoch  6, batch    14 | loss: 5.3918200CurrentTrain: epoch  6, batch    15 | loss: 5.1954913CurrentTrain: epoch  6, batch    16 | loss: 5.9823422CurrentTrain: epoch  6, batch    17 | loss: 5.4264145CurrentTrain: epoch  6, batch    18 | loss: 5.6327276CurrentTrain: epoch  6, batch    19 | loss: 5.9033957CurrentTrain: epoch  6, batch    20 | loss: 6.1786757CurrentTrain: epoch  6, batch    21 | loss: 6.3660412CurrentTrain: epoch  6, batch    22 | loss: 6.0595322CurrentTrain: epoch  6, batch    23 | loss: 5.5738835CurrentTrain: epoch  6, batch    24 | loss: 5.1174212CurrentTrain: epoch  6, batch    25 | loss: 5.9595833CurrentTrain: epoch  6, batch    26 | loss: 6.1485519CurrentTrain: epoch  6, batch    27 | loss: 5.7259197CurrentTrain: epoch  6, batch    28 | loss: 5.8726430CurrentTrain: epoch  6, batch    29 | loss: 5.5694523CurrentTrain: epoch  6, batch    30 | loss: 6.0045009CurrentTrain: epoch  6, batch    31 | loss: 5.6451173CurrentTrain: epoch  6, batch    32 | loss: 5.2247005CurrentTrain: epoch  6, batch    33 | loss: 6.1387463CurrentTrain: epoch  6, batch    34 | loss: 5.2706861CurrentTrain: epoch  6, batch    35 | loss: 5.5575624CurrentTrain: epoch  6, batch    36 | loss: 5.3598919CurrentTrain: epoch  6, batch    37 | loss: 5.5043011CurrentTrain: epoch  7, batch     0 | loss: 5.8221326CurrentTrain: epoch  7, batch     1 | loss: 5.2134027CurrentTrain: epoch  7, batch     2 | loss: 5.3066864CurrentTrain: epoch  7, batch     3 | loss: 5.0514336CurrentTrain: epoch  7, batch     4 | loss: 5.5705714CurrentTrain: epoch  7, batch     5 | loss: 5.2637019CurrentTrain: epoch  7, batch     6 | loss: 5.3848391CurrentTrain: epoch  7, batch     7 | loss: 5.0422788CurrentTrain: epoch  7, batch     8 | loss: 5.4018226CurrentTrain: epoch  7, batch     9 | loss: 5.1225381CurrentTrain: epoch  7, batch    10 | loss: 5.3415217CurrentTrain: epoch  7, batch    11 | loss: 5.3493118CurrentTrain: epoch  7, batch    12 | loss: 5.3571339CurrentTrain: epoch  7, batch    13 | loss: 5.5703020CurrentTrain: epoch  7, batch    14 | loss: 5.9958162CurrentTrain: epoch  7, batch    15 | loss: 5.4087534CurrentTrain: epoch  7, batch    16 | loss: 5.5808349CurrentTrain: epoch  7, batch    17 | loss: 5.3512669CurrentTrain: epoch  7, batch    18 | loss: 4.9717011CurrentTrain: epoch  7, batch    19 | loss: 5.1010613CurrentTrain: epoch  7, batch    20 | loss: 5.5419488CurrentTrain: epoch  7, batch    21 | loss: 5.0689411CurrentTrain: epoch  7, batch    22 | loss: 6.1445966CurrentTrain: epoch  7, batch    23 | loss: 5.4027791CurrentTrain: epoch  7, batch    24 | loss: 5.8069553CurrentTrain: epoch  7, batch    25 | loss: 5.1294775CurrentTrain: epoch  7, batch    26 | loss: 5.2494717CurrentTrain: epoch  7, batch    27 | loss: 5.3885818CurrentTrain: epoch  7, batch    28 | loss: 5.1891451CurrentTrain: epoch  7, batch    29 | loss: 5.2763824CurrentTrain: epoch  7, batch    30 | loss: 5.2565598CurrentTrain: epoch  7, batch    31 | loss: 5.2446299CurrentTrain: epoch  7, batch    32 | loss: 5.1272998CurrentTrain: epoch  7, batch    33 | loss: 5.2244992CurrentTrain: epoch  7, batch    34 | loss: 5.0223141CurrentTrain: epoch  7, batch    35 | loss: 5.1779542CurrentTrain: epoch  7, batch    36 | loss: 5.1301193CurrentTrain: epoch  7, batch    37 | loss: 4.8143196CurrentTrain: epoch  8, batch     0 | loss: 5.1579475CurrentTrain: epoch  8, batch     1 | loss: 5.1543798CurrentTrain: epoch  8, batch     2 | loss: 4.8897972CurrentTrain: epoch  8, batch     3 | loss: 5.0410523CurrentTrain: epoch  8, batch     4 | loss: 5.2717929CurrentTrain: epoch  8, batch     5 | loss: 4.9771128CurrentTrain: epoch  8, batch     6 | loss: 5.0834179CurrentTrain: epoch  8, batch     7 | loss: 5.0067358CurrentTrain: epoch  8, batch     8 | loss: 5.0641761CurrentTrain: epoch  8, batch     9 | loss: 5.0935326CurrentTrain: epoch  8, batch    10 | loss: 5.2907119CurrentTrain: epoch  8, batch    11 | loss: 4.9250479CurrentTrain: epoch  8, batch    12 | loss: 5.0914650CurrentTrain: epoch  8, batch    13 | loss: 4.9756813CurrentTrain: epoch  8, batch    14 | loss: 5.2059898CurrentTrain: epoch  8, batch    15 | loss: 5.2468882CurrentTrain: epoch  8, batch    16 | loss: 4.9808016CurrentTrain: epoch  8, batch    17 | loss: 4.8144884CurrentTrain: epoch  8, batch    18 | loss: 5.2888255CurrentTrain: epoch  8, batch    19 | loss: 4.9981937CurrentTrain: epoch  8, batch    20 | loss: 5.1061277CurrentTrain: epoch  8, batch    21 | loss: 5.0941725CurrentTrain: epoch  8, batch    22 | loss: 5.3479795CurrentTrain: epoch  8, batch    23 | loss: 5.2284288CurrentTrain: epoch  8, batch    24 | loss: 4.9951601CurrentTrain: epoch  8, batch    25 | loss: 5.0256500CurrentTrain: epoch  8, batch    26 | loss: 5.3343859CurrentTrain: epoch  8, batch    27 | loss: 4.9719343CurrentTrain: epoch  8, batch    28 | loss: 5.2509747CurrentTrain: epoch  8, batch    29 | loss: 5.0940399CurrentTrain: epoch  8, batch    30 | loss: 4.9406633CurrentTrain: epoch  8, batch    31 | loss: 5.1270304CurrentTrain: epoch  8, batch    32 | loss: 4.7761073CurrentTrain: epoch  8, batch    33 | loss: 4.9832006CurrentTrain: epoch  8, batch    34 | loss: 4.9552345CurrentTrain: epoch  8, batch    35 | loss: 5.4438825CurrentTrain: epoch  8, batch    36 | loss: 4.9208779CurrentTrain: epoch  8, batch    37 | loss: 4.9012098CurrentTrain: epoch  9, batch     0 | loss: 5.3065910CurrentTrain: epoch  9, batch     1 | loss: 5.1796370CurrentTrain: epoch  9, batch     2 | loss: 5.1072073CurrentTrain: epoch  9, batch     3 | loss: 4.9213343CurrentTrain: epoch  9, batch     4 | loss: 4.8819547CurrentTrain: epoch  9, batch     5 | loss: 5.1034369CurrentTrain: epoch  9, batch     6 | loss: 5.3321552CurrentTrain: epoch  9, batch     7 | loss: 4.9197969CurrentTrain: epoch  9, batch     8 | loss: 4.9653072CurrentTrain: epoch  9, batch     9 | loss: 4.8860769CurrentTrain: epoch  9, batch    10 | loss: 5.0107727CurrentTrain: epoch  9, batch    11 | loss: 4.8371091CurrentTrain: epoch  9, batch    12 | loss: 4.9469938CurrentTrain: epoch  9, batch    13 | loss: 5.0067148CurrentTrain: epoch  9, batch    14 | loss: 4.9856386CurrentTrain: epoch  9, batch    15 | loss: 4.8672819CurrentTrain: epoch  9, batch    16 | loss: 4.8858490CurrentTrain: epoch  9, batch    17 | loss: 5.0205936CurrentTrain: epoch  9, batch    18 | loss: 5.0734935CurrentTrain: epoch  9, batch    19 | loss: 4.8799629CurrentTrain: epoch  9, batch    20 | loss: 4.8950119CurrentTrain: epoch  9, batch    21 | loss: 4.7830744CurrentTrain: epoch  9, batch    22 | loss: 4.8854637CurrentTrain: epoch  9, batch    23 | loss: 4.9289637CurrentTrain: epoch  9, batch    24 | loss: 4.9857821CurrentTrain: epoch  9, batch    25 | loss: 4.7893872CurrentTrain: epoch  9, batch    26 | loss: 5.1338005CurrentTrain: epoch  9, batch    27 | loss: 5.0343213CurrentTrain: epoch  9, batch    28 | loss: 4.9264212CurrentTrain: epoch  9, batch    29 | loss: 5.0215325CurrentTrain: epoch  9, batch    30 | loss: 4.7740507CurrentTrain: epoch  9, batch    31 | loss: 4.8163271CurrentTrain: epoch  9, batch    32 | loss: 4.8064499CurrentTrain: epoch  9, batch    33 | loss: 4.7759576CurrentTrain: epoch  9, batch    34 | loss: 4.9853191CurrentTrain: epoch  9, batch    35 | loss: 4.7680750CurrentTrain: epoch  9, batch    36 | loss: 4.7871542CurrentTrain: epoch  9, batch    37 | loss: 4.9062581
#### person countries of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person countries of residence" means a person is living in a country.
Here is an example:
Relation: person countries of residence
Context: khamenei , 67 , has final say on all state matters in iran as supreme leader , a post he has held since 1989 .
Head Entity: khamenei
Tail Entity: iran
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person countries of residence":
Relation: person countries of residence  
Context: After years of living in the United States, Maria decided to return to her roots in Mexico.  
Head Entity: Maria  
Tail Entity: Mexico  

Relation: person countries of residence  
Context: The famous actor, Leonardo DiCaprio, has spent a significant amount of time in Australia while filming his latest movie.  
Head Entity: Leonardo DiCaprio  
Tail Entity: Australia  

Relation: person countries of residence  
Context: Following his retirement, the former president moved to Canada to enjoy a quieter life.  
Head Entity: former president  
Tail Entity: Canada  

Relation: person countries of residence  
Context: Despite being born in Japan, Akira has lived in Germany for over a decade now.  
Head Entity: Akira  
Tail Entity: Germany  

Relation: person countries of residence  
Context: After completing her studies in France, Sophie decided to settle down in Italy for a new adventure.  
Head Entity: Sophie  
Tail Entity: Italy  
#### organization top members employees ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization top members employees" means an organization 's employer is a person.
Here is an example:
Relation: organization top members employees
Context: `` customer relationships are the backbone of banking , and banks are constantly striving to meet customer demands , '' said peter garuccio , spokesman for the american bankers association .
Head Entity: american bankers association
Tail Entity: peter garuccio
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization top members employees":
1. Relation: organization top members employees  
   Context: "As the CEO of the tech giant, she has been instrumental in driving innovation," said a company spokesperson about Jane Doe, who leads the organization.  
   Head Entity: tech giant  
   Tail Entity: Jane Doe  

2. Relation: organization top members employees  
   Context: "The board of directors is pleased to announce the appointment of John Smith as the new CFO," stated the press release from the financial services firm.  
   Head Entity: financial services firm  
   Tail Entity: John Smith  

3. Relation: organization top members employees  
   Context: "During the annual meeting, the president of the nonprofit organization highlighted the contributions of their lead researcher," reported the local news outlet.  
   Head Entity: nonprofit organization  
   Tail Entity: lead researcher  

4. Relation: organization top members employees  
   Context: "The founder of the startup expressed gratitude towards her team for their hard work and dedication," said a representative during the launch event.  
   Head Entity: startup  
   Tail Entity: founder  

5. Relation: organization top members employees  
   Context: "In a recent interview, the director of the environmental agency praised the efforts of their lead scientist in tackling climate change," noted the environmental journal.  
   Head Entity: environmental agency  
   Tail Entity: lead scientist  
#### organization member of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization member of" means an organization is the member of an organization.
Here is an example:
Relation: organization member of
Context: over the course of the week the european union engaged in a gentlemanly tug-of-war with the organization of the islamic conference -lrb- oic -rrb- and the african regional group - which is controlled by the oic - over a range of terms and conditions .
Head Entity: oic
Tail Entity: organization of the islamic conference
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization member of":
Relation: organization member of  
Context: The United Nations has been working closely with the World Health Organization to address global health issues and improve international cooperation.  
Head Entity: World Health Organization  
Tail Entity: United Nations  

Relation: organization member of  
Context: During the annual conference, the International Olympic Committee discussed its collaboration with various national sports organizations to promote athletic excellence.  
Head Entity: International Olympic Committee  
Tail Entity: national sports organizations  

Relation: organization member of  
Context: The European Union has recently expanded its membership to include several new countries, enhancing its influence in global politics.  
Head Entity: European Union  
Tail Entity: new countries  

Relation: organization member of  
Context: The Global Climate Alliance is a coalition of various environmental organizations working together to combat climate change and promote sustainability.  
Head Entity: Global Climate Alliance  
Tail Entity: environmental organizations  

Relation: organization member of  
Context: The International Federation of Red Cross and Red Crescent Societies collaborates with numerous local humanitarian organizations to provide disaster relief and support.  
Head Entity: International Federation of Red Cross and Red Crescent Societies  
Tail Entity: local humanitarian organizations  
#### person origin ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person origin" means a person 's nationality is a country.
Here is an example:
Relation: person origin
Context: urgent chadian pm dies in paris hospital chad 's prime minister pascal yoadimnadji has died from a cerebral hemorrhage in a paris hospital , the chadian ambassador said friday .
Head Entity: pascal yoadimnadji
Tail Entity: chadian
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person origin":
Relation: person origin  
Context: the renowned scientist albert einstein was born in ulm, germany, and later became a citizen of the united states.  
Head Entity: albert einstein  
Tail Entity: german  

Relation: person origin  
Context: the famous author chimamanda ngozi adichie hails from enugu, nigeria, where she developed her passion for storytelling.  
Head Entity: chimamanda ngozi adichie  
Tail Entity: nigerian  

Relation: person origin  
Context: the legendary musician bob marley was born in nine mile, jamaica, and is celebrated worldwide for his contributions to reggae music.  
Head Entity: bob marley  
Tail Entity: jamaican  

Relation: person origin  
Context: the acclaimed filmmaker akira kurosawa was born in tokyo, japan, and is known for his influential works in cinema.  
Head Entity: akira kurosawa  
Tail Entity: japanese  

Relation: person origin  
Context: the famous physicist stephen hawking was born in oxford, england, and made groundbreaking contributions to theoretical physics.  
Head Entity: stephen hawking  
Tail Entity: british  
#### person title ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person title" means a person 's title is a title.
Here is an example:
Relation: person title
Context: `` making the amendment retroactive will ... help repair the image of the sentencing guidelines in communities of color , '' naacp chairman julian bond wrote to the commission .
Head Entity: julian bond
Tail Entity: chairman
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person title":
Relation: person title  
Context: `` After years of dedicated service, the board appointed Dr. Emily Carter as the new president of the university. ''  
Head Entity: Dr. Emily Carter  
Tail Entity: president  

Relation: person title  
Context: `` In his latest book, former senator John Smith shares insights from his time as the majority leader in Congress. ''  
Head Entity: John Smith  
Tail Entity: majority leader  

Relation: person title  
Context: `` The company announced that Sarah Johnson will take over as the chief executive officer starting next month. ''  
Head Entity: Sarah Johnson  
Tail Entity: chief executive officer  

Relation: person title  
Context: `` During the ceremony, the mayor recognized Michael Lee for his contributions as the city’s chief of police. ''  
Head Entity: Michael Lee  
Tail Entity: chief of police  

Relation: person title  
Context: `` The organization celebrated its 50th anniversary by honoring its founder, Dr. Alice Thompson, for her role as the executive director. ''  
Head Entity: Dr. Alice Thompson  
Tail Entity: executive director  
#### organization country of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization country of headquarters" means an organization is located in a country.
Here is an example:
Relation: organization country of headquarters
Context: chunghwa telecom co , taiwan 's leading telecom operator , said friday its 2007 net profit rose some eight percent from a year earlier , largely due to cost reductions .
Head Entity: chunghwa telecom
Tail Entity: taiwan
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization country of headquarters":
Relation: organization country of headquarters  
Context: Samsung Electronics, a global leader in technology, has its headquarters in South Korea, where it continues to innovate in various sectors.  
Head Entity: Samsung Electronics  
Tail Entity: South Korea  

Relation: organization country of headquarters  
Context: Nestlé, the world's largest food and beverage company, is headquartered in Switzerland, a country known for its high quality of life.  
Head Entity: Nestlé  
Tail Entity: Switzerland  

Relation: organization country of headquarters  
Context: Toyota Motor Corporation, a major player in the automotive industry, operates its headquarters in Japan, contributing significantly to the country's economy.  
Head Entity: Toyota Motor Corporation  
Tail Entity: Japan  

Relation: organization country of headquarters  
Context: Unilever, a multinational consumer goods company, has its headquarters located in the United Kingdom, where it was originally founded.  
Head Entity: Unilever  
Tail Entity: United Kingdom  

Relation: organization country of headquarters  
Context: Siemens AG, a global engineering and technology company, is headquartered in Germany, a country renowned for its engineering excellence.  
Head Entity: Siemens AG  
Tail Entity: Germany  
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    1 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    2 | acc: 87.50%,  total acc: 83.33%   [EVAL] batch:    3 | acc: 62.50%,  total acc: 78.12%   [EVAL] batch:    4 | acc: 93.75%,  total acc: 81.25%   [EVAL] batch:    5 | acc: 75.00%,  total acc: 80.21%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 82.14%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 84.38%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 86.11%   [EVAL] batch:    9 | acc: 93.75%,  total acc: 86.88%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 88.07%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 88.54%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 88.94%   [EVAL] batch:   13 | acc: 68.75%,  total acc: 87.50%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 86.67%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 84.77%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 84.19%   [EVAL] batch:   17 | acc: 68.75%,  total acc: 83.33%   [EVAL] batch:   18 | acc: 87.50%,  total acc: 83.55%   [EVAL] batch:   19 | acc: 87.50%,  total acc: 83.75%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 84.52%   [EVAL] batch:   21 | acc: 100.00%,  total acc: 85.23%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 85.87%   [EVAL] batch:   23 | acc: 100.00%,  total acc: 86.46%   [EVAL] batch:   24 | acc: 100.00%,  total acc: 87.00%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 87.50%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 87.73%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 88.17%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 88.58%   [EVAL] batch:   29 | acc: 87.50%,  total acc: 88.54%   [EVAL] batch:   30 | acc: 87.50%,  total acc: 88.51%   [EVAL] batch:   31 | acc: 93.75%,  total acc: 88.67%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 87.12%   
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    1 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    2 | acc: 87.50%,  total acc: 83.33%   [EVAL] batch:    3 | acc: 62.50%,  total acc: 78.12%   [EVAL] batch:    4 | acc: 93.75%,  total acc: 81.25%   [EVAL] batch:    5 | acc: 75.00%,  total acc: 80.21%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 82.14%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 84.38%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 86.11%   [EVAL] batch:    9 | acc: 93.75%,  total acc: 86.88%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 88.07%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 88.54%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 88.94%   [EVAL] batch:   13 | acc: 68.75%,  total acc: 87.50%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 86.67%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 84.77%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 84.19%   [EVAL] batch:   17 | acc: 68.75%,  total acc: 83.33%   [EVAL] batch:   18 | acc: 87.50%,  total acc: 83.55%   [EVAL] batch:   19 | acc: 87.50%,  total acc: 83.75%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 84.52%   [EVAL] batch:   21 | acc: 100.00%,  total acc: 85.23%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 85.87%   [EVAL] batch:   23 | acc: 100.00%,  total acc: 86.46%   [EVAL] batch:   24 | acc: 100.00%,  total acc: 87.00%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 87.50%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 87.73%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 88.17%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 88.58%   [EVAL] batch:   29 | acc: 87.50%,  total acc: 88.54%   [EVAL] batch:   30 | acc: 87.50%,  total acc: 88.51%   [EVAL] batch:   31 | acc: 93.75%,  total acc: 88.67%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 87.12%   
cur_acc:  ['0.8712']
his_acc:  ['0.8712']
CurrentTrain: epoch  0, batch     0 | loss: 6.3973942CurrentTrain: epoch  0, batch     1 | loss: 7.3796716CurrentTrain: epoch  1, batch     0 | loss: 6.4657888CurrentTrain: epoch  1, batch     1 | loss: 5.3782830CurrentTrain: epoch  2, batch     0 | loss: 6.1777396CurrentTrain: epoch  2, batch     1 | loss: 5.3747253CurrentTrain: epoch  3, batch     0 | loss: 5.5423403CurrentTrain: epoch  3, batch     1 | loss: 5.1534314CurrentTrain: epoch  4, batch     0 | loss: 5.3756881CurrentTrain: epoch  4, batch     1 | loss: 5.0625086CurrentTrain: epoch  5, batch     0 | loss: 5.0119185CurrentTrain: epoch  5, batch     1 | loss: 3.9117169CurrentTrain: epoch  6, batch     0 | loss: 4.4607000CurrentTrain: epoch  6, batch     1 | loss: 3.8968837CurrentTrain: epoch  7, batch     0 | loss: 4.1129036CurrentTrain: epoch  7, batch     1 | loss: 4.0668969CurrentTrain: epoch  8, batch     0 | loss: 3.4643028CurrentTrain: epoch  8, batch     1 | loss: 4.1775894CurrentTrain: epoch  9, batch     0 | loss: 3.3281112CurrentTrain: epoch  9, batch     1 | loss: 3.7418110
#### person date of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person date of birth" means a person was born in a date.
Here is an example:
Relation: person date of birth
Context: born in 1950 in the northeastern city of basel , ospel left school at 15 to take an apprenticeship at the transvalor brokerage house before joining swiss banking corporation -lrb- sbs -rrb- , which merged with union bank of switzerland to form ubs in 1998 .
Head Entity: ospel
Tail Entity: 1950
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person date of birth":
Relation: person date of birth  
Context: she was born on July 4, 1985, in a small town in California, where she spent her childhood before moving to New York for her career.  
Head Entity: she  
Tail Entity: July 4, 1985  

Relation: person date of birth  
Context: the famous physicist was born in 1879 in Ulm, in the Kingdom of Württemberg in the German Empire, and later moved to Switzerland.  
Head Entity: the famous physicist  
Tail Entity: 1879  

Relation: person date of birth  
Context: born in 1992 in a bustling city, he quickly became known for his contributions to technology and innovation.  
Head Entity: he  
Tail Entity: 1992  

Relation: person date of birth  
Context: the author was born in 1965 in a small village, where she developed her love for storytelling from a young age.  
Head Entity: the author  
Tail Entity: 1965  

Relation: person date of birth  
Context: born in 2000, she has already made a name for herself in the world of competitive sports, showcasing her talent from an early age.  
Head Entity: she  
Tail Entity: 2000  
#### person stateorprovince of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of birth" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of birth
Context: jane matilda bolin was born on april 11 , 1908 , in poughkeepsie , ny .
Head Entity: jane matilda bolin
Tail Entity: ny
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of birth":
Relation: person stateorprovince of birth  
Context: albert einstein was born on march 14, 1879, in ulm, württemberg, germany.  
Head Entity: albert einstein  
Tail Entity: württemberg  

Relation: person stateorprovince of birth  
Context: marilyn monroe was born on june 1, 1926, in los angeles, california.  
Head Entity: marilyn monroe  
Tail Entity: california  

Relation: person stateorprovince of birth  
Context: barack obama was born on august 4, 1961, in honolulu, hawaii.  
Head Entity: barack obama  
Tail Entity: hawaii  

Relation: person stateorprovince of birth  
Context: agatha christie was born on september 15, 1890, in torquay, devon.  
Head Entity: agatha christie  
Tail Entity: devon  

Relation: person stateorprovince of birth  
Context: nelson mandela was born on july 18, 1918, in mvezo, eastern cape.  
Head Entity: nelson mandela  
Tail Entity: eastern cape  
#### person parents ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person parents" means a person 's parent is a person.
Here is an example:
Relation: person parents
Context: lynne spears told the court that lutfi had treated her daughter like a hostage in her own home , drugged her and took over her finances .
Head Entity: her
Tail Entity: lynne spears
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person parents":
1. Relation: person parents  
   Context: After years of hard work, Sarah finally made her parents proud by graduating at the top of her class.  
   Head Entity: her  
   Tail Entity: parents  

2. Relation: person parents  
   Context: During the family reunion, Michael shared stories about how his father taught him valuable life lessons.  
   Head Entity: his  
   Tail Entity: father  

3. Relation: person parents  
   Context: Emily often reminisces about the summer vacations she spent with her mother at the beach.  
   Head Entity: her  
   Tail Entity: mother  

4. Relation: person parents  
   Context: The documentary highlighted how the struggles of his parents shaped his career as an artist.  
   Head Entity: his  
   Tail Entity: parents  

5. Relation: person parents  
   Context: Jessica credits her success to the unwavering support she received from her father throughout her life.  
   Head Entity: her  
   Tail Entity: father  
#### person employee of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person employee of" means a person is an employee of an organization.
Here is an example:
Relation: person employee of
Context: seeking revenge , axel reunites with old pal sgt. billy rosewood -lrb- judge reinhold -rrb- and jon flint -lrb- hector elizondo -rrb- of the beverly hills police department .
Head Entity: hector elizondo
Tail Entity: beverly hills police department
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person employee of":
Relation: person employee of  
Context: After years of hard work, Maria finally landed a job at the prestigious tech company, where she would be working alongside some of the brightest minds in the industry.  
Head Entity: Maria  
Tail Entity: prestigious tech company  

Relation: person employee of  
Context: John has been with the marketing firm for over a decade, contributing to numerous successful campaigns and earning the respect of his colleagues.  
Head Entity: John  
Tail Entity: marketing firm  

Relation: person employee of  
Context: As a lead designer at the fashion house, Sarah was responsible for creating some of the most iconic collections that defined the brand's identity.  
Head Entity: Sarah  
Tail Entity: fashion house  

Relation: person employee of  
Context: After graduating from university, Tom accepted a position at a well-known financial institution, where he quickly climbed the corporate ladder.  
Head Entity: Tom  
Tail Entity: well-known financial institution  

Relation: person employee of  
Context: Emily's dedication to her role as a nurse at the local hospital has made her a beloved figure among patients and staff alike.  
Head Entity: Emily  
Tail Entity: local hospital  
#### person stateorprovince of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of death" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of death
Context: irene morgan kirkaldy , whose defiance of bus segregation laws more than a decade before rosa parks ' landmark case helped lay the foundation for later civil rights victories , died friday at her home in hayes , va. .
Head Entity: irene morgan kirkaldy
Tail Entity: va.
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of death":
Relation: person stateorprovince of death  
Context: john doe, a renowned author known for his thrilling novels, passed away peacefully in his sleep at his residence in california.  
Head Entity: john doe  
Tail Entity: california  

Relation: person stateorprovince of death  
Context: after a long battle with illness, elizabeth taylor, the iconic actress, died in a hospital in nevada surrounded by family.  
Head Entity: elizabeth taylor  
Tail Entity: nevada  

Relation: person stateorprovince of death  
Context: the famous physicist, albert einstein, took his last breath in a hospital in new jersey, where he had been receiving treatment.  
Head Entity: albert einstein  
Tail Entity: new jersey  

Relation: person stateorprovince of death  
Context: the beloved musician, prince, was found unresponsive in his home in minnesota, where he later died.  
Head Entity: prince  
Tail Entity: minnesota  

Relation: person stateorprovince of death  
Context: the celebrated civil rights leader, martin luther king jr., was assassinated in tennessee, marking a tragic moment in history.  
Head Entity: martin luther king jr.  
Tail Entity: tennessee  
Mixup data size:  3730
MixupTrain:  epoch  0, batch     0 | loss: 5.8567657MixupTrain:  epoch  0, batch     1 | loss: 5.8397245MixupTrain:  epoch  0, batch     2 | loss: 5.3619037MixupTrain:  epoch  0, batch     3 | loss: 5.0327063MixupTrain:  epoch  0, batch     4 | loss: 5.2456636MixupTrain:  epoch  0, batch     5 | loss: 4.8449721MixupTrain:  epoch  0, batch     6 | loss: 5.5382485MixupTrain:  epoch  0, batch     7 | loss: 5.0913296MixupTrain:  epoch  0, batch     8 | loss: 4.9459605MixupTrain:  epoch  0, batch     9 | loss: 4.6102104MixupTrain:  epoch  0, batch    10 | loss: 4.5522490MixupTrain:  epoch  0, batch    11 | loss: 4.3684640MixupTrain:  epoch  0, batch    12 | loss: 4.2432971MixupTrain:  epoch  0, batch    13 | loss: 5.3607845MixupTrain:  epoch  0, batch    14 | loss: 4.3203850MixupTrain:  epoch  0, batch    15 | loss: 4.5715094MixupTrain:  epoch  0, batch    16 | loss: 4.4029474MixupTrain:  epoch  0, batch    17 | loss: 3.6532249MixupTrain:  epoch  0, batch    18 | loss: 4.4488244MixupTrain:  epoch  0, batch    19 | loss: 3.9176767MixupTrain:  epoch  0, batch    20 | loss: 3.9850571MixupTrain:  epoch  0, batch    21 | loss: 3.9589992MixupTrain:  epoch  0, batch    22 | loss: 4.2674222MixupTrain:  epoch  0, batch    23 | loss: 4.0988908MixupTrain:  epoch  0, batch    24 | loss: 3.8465097MixupTrain:  epoch  0, batch    25 | loss: 4.0728188MixupTrain:  epoch  0, batch    26 | loss: 3.8456097MixupTrain:  epoch  0, batch    27 | loss: 3.0962505MixupTrain:  epoch  0, batch    28 | loss: 3.5413337MixupTrain:  epoch  0, batch    29 | loss: 3.9034309MixupTrain:  epoch  0, batch    30 | loss: 3.5857689MixupTrain:  epoch  0, batch    31 | loss: 3.8307192MixupTrain:  epoch  0, batch    32 | loss: 3.7610605MixupTrain:  epoch  0, batch    33 | loss: 3.4227591MixupTrain:  epoch  0, batch    34 | loss: 3.5708213MixupTrain:  epoch  0, batch    35 | loss: 3.4657805MixupTrain:  epoch  0, batch    36 | loss: 3.4420295MixupTrain:  epoch  0, batch    37 | loss: 3.9418468MixupTrain:  epoch  0, batch    38 | loss: 4.0006623MixupTrain:  epoch  0, batch    39 | loss: 3.3649902MixupTrain:  epoch  0, batch    40 | loss: 3.3759828MixupTrain:  epoch  0, batch    41 | loss: 3.4747930MixupTrain:  epoch  0, batch    42 | loss: 3.0280974MixupTrain:  epoch  0, batch    43 | loss: 3.1516113MixupTrain:  epoch  0, batch    44 | loss: 3.0371919MixupTrain:  epoch  0, batch    45 | loss: 3.6220560MixupTrain:  epoch  0, batch    46 | loss: 3.6260128MixupTrain:  epoch  0, batch    47 | loss: 3.2327752MixupTrain:  epoch  0, batch    48 | loss: 2.9505658MixupTrain:  epoch  0, batch    49 | loss: 3.0108173MixupTrain:  epoch  0, batch    50 | loss: 2.6557484MixupTrain:  epoch  0, batch    51 | loss: 2.7755237MixupTrain:  epoch  0, batch    52 | loss: 2.8662481MixupTrain:  epoch  0, batch    53 | loss: 2.9241951MixupTrain:  epoch  0, batch    54 | loss: 3.0486538MixupTrain:  epoch  0, batch    55 | loss: 2.9959264MixupTrain:  epoch  0, batch    56 | loss: 2.7784953MixupTrain:  epoch  0, batch    57 | loss: 3.0262649MixupTrain:  epoch  0, batch    58 | loss: 2.7916551MixupTrain:  epoch  0, batch    59 | loss: 2.8753140MixupTrain:  epoch  0, batch    60 | loss: 2.8595564MixupTrain:  epoch  0, batch    61 | loss: 2.7053943MixupTrain:  epoch  0, batch    62 | loss: 2.6138711MixupTrain:  epoch  0, batch    63 | loss: 2.7829888MixupTrain:  epoch  0, batch    64 | loss: 2.8753815MixupTrain:  epoch  0, batch    65 | loss: 2.6173592MixupTrain:  epoch  0, batch    66 | loss: 2.7482026MixupTrain:  epoch  0, batch    67 | loss: 2.8633170MixupTrain:  epoch  0, batch    68 | loss: 2.4753265MixupTrain:  epoch  0, batch    69 | loss: 2.4551306MixupTrain:  epoch  0, batch    70 | loss: 2.5269117MixupTrain:  epoch  0, batch    71 | loss: 2.6606016MixupTrain:  epoch  0, batch    72 | loss: 2.6177578MixupTrain:  epoch  0, batch    73 | loss: 2.5740893MixupTrain:  epoch  0, batch    74 | loss: 2.5946743MixupTrain:  epoch  0, batch    75 | loss: 2.5749969MixupTrain:  epoch  0, batch    76 | loss: 2.5216618MixupTrain:  epoch  0, batch    77 | loss: 2.4288104MixupTrain:  epoch  0, batch    78 | loss: 2.4493771MixupTrain:  epoch  0, batch    79 | loss: 2.4910693MixupTrain:  epoch  0, batch    80 | loss: 2.4252710MixupTrain:  epoch  0, batch    81 | loss: 2.5623374MixupTrain:  epoch  0, batch    82 | loss: 2.4565191MixupTrain:  epoch  0, batch    83 | loss: 2.5343165MixupTrain:  epoch  0, batch    84 | loss: 2.6342459MixupTrain:  epoch  0, batch    85 | loss: 2.4991941MixupTrain:  epoch  0, batch    86 | loss: 2.5155787MixupTrain:  epoch  0, batch    87 | loss: 2.3179202MixupTrain:  epoch  0, batch    88 | loss: 2.3850281MixupTrain:  epoch  0, batch    89 | loss: 2.5277960MixupTrain:  epoch  0, batch    90 | loss: 2.4352298MixupTrain:  epoch  0, batch    91 | loss: 2.3698785MixupTrain:  epoch  0, batch    92 | loss: 2.3533654MixupTrain:  epoch  0, batch    93 | loss: 2.3765240MixupTrain:  epoch  0, batch    94 | loss: 2.3622971MixupTrain:  epoch  0, batch    95 | loss: 2.3128633MixupTrain:  epoch  0, batch    96 | loss: 2.1825447MixupTrain:  epoch  0, batch    97 | loss: 2.3417869MixupTrain:  epoch  0, batch    98 | loss: 2.4096928MixupTrain:  epoch  0, batch    99 | loss: 2.4495618MixupTrain:  epoch  0, batch   100 | loss: 2.2618265MixupTrain:  epoch  0, batch   101 | loss: 2.2658553MixupTrain:  epoch  0, batch   102 | loss: 2.3002913MixupTrain:  epoch  0, batch   103 | loss: 2.3245125MixupTrain:  epoch  0, batch   104 | loss: 2.3162551MixupTrain:  epoch  0, batch   105 | loss: 2.3116229MixupTrain:  epoch  0, batch   106 | loss: 2.4823775MixupTrain:  epoch  0, batch   107 | loss: 2.2699237MixupTrain:  epoch  0, batch   108 | loss: 2.2480330MixupTrain:  epoch  0, batch   109 | loss: 2.3525748MixupTrain:  epoch  0, batch   110 | loss: 2.2703557MixupTrain:  epoch  0, batch   111 | loss: 2.4423726MixupTrain:  epoch  0, batch   112 | loss: 2.3141780MixupTrain:  epoch  0, batch   113 | loss: 2.1917973MixupTrain:  epoch  0, batch   114 | loss: 2.2611575MixupTrain:  epoch  0, batch   115 | loss: 2.1498308MixupTrain:  epoch  0, batch   116 | loss: 2.2143381MixupTrain:  epoch  0, batch   117 | loss: 2.1758022MixupTrain:  epoch  0, batch   118 | loss: 2.1621428MixupTrain:  epoch  0, batch   119 | loss: 2.1907787MixupTrain:  epoch  0, batch   120 | loss: 2.2350845MixupTrain:  epoch  0, batch   121 | loss: 2.1971357MixupTrain:  epoch  0, batch   122 | loss: 2.2773185MixupTrain:  epoch  0, batch   123 | loss: 2.2686830MixupTrain:  epoch  0, batch   124 | loss: 2.2448549MixupTrain:  epoch  0, batch   125 | loss: 2.1508660MixupTrain:  epoch  0, batch   126 | loss: 2.2282112MixupTrain:  epoch  0, batch   127 | loss: 2.1666114MixupTrain:  epoch  0, batch   128 | loss: 2.1644235MixupTrain:  epoch  0, batch   129 | loss: 2.1583462MixupTrain:  epoch  0, batch   130 | loss: 2.2611046MixupTrain:  epoch  0, batch   131 | loss: 2.2219734MixupTrain:  epoch  0, batch   132 | loss: 2.1513004MixupTrain:  epoch  0, batch   133 | loss: 2.1531923MixupTrain:  epoch  0, batch   134 | loss: 2.1026201MixupTrain:  epoch  0, batch   135 | loss: 2.1690192MixupTrain:  epoch  0, batch   136 | loss: 2.2235663MixupTrain:  epoch  0, batch   137 | loss: 2.0805643MixupTrain:  epoch  0, batch   138 | loss: 2.1639905MixupTrain:  epoch  0, batch   139 | loss: 2.1458917MixupTrain:  epoch  0, batch   140 | loss: 2.1246641MixupTrain:  epoch  0, batch   141 | loss: 2.1774082MixupTrain:  epoch  0, batch   142 | loss: 2.1130047MixupTrain:  epoch  0, batch   143 | loss: 2.2100086MixupTrain:  epoch  0, batch   144 | loss: 2.1311331MixupTrain:  epoch  0, batch   145 | loss: 2.1146398MixupTrain:  epoch  0, batch   146 | loss: 2.1470425MixupTrain:  epoch  0, batch   147 | loss: 2.2021446MixupTrain:  epoch  0, batch   148 | loss: 2.1708777MixupTrain:  epoch  0, batch   149 | loss: 2.1853237MixupTrain:  epoch  0, batch   150 | loss: 2.1010015MixupTrain:  epoch  0, batch   151 | loss: 2.2282381MixupTrain:  epoch  0, batch   152 | loss: 2.1400867MixupTrain:  epoch  0, batch   153 | loss: 2.0196402MixupTrain:  epoch  0, batch   154 | loss: 2.1454754MixupTrain:  epoch  0, batch   155 | loss: 2.1418505MixupTrain:  epoch  0, batch   156 | loss: 2.1902900MixupTrain:  epoch  0, batch   157 | loss: 2.1562877MixupTrain:  epoch  0, batch   158 | loss: 2.1488509MixupTrain:  epoch  0, batch   159 | loss: 2.1344304MixupTrain:  epoch  0, batch   160 | loss: 2.1134906MixupTrain:  epoch  0, batch   161 | loss: 2.0814178MixupTrain:  epoch  0, batch   162 | loss: 2.1294799MixupTrain:  epoch  0, batch   163 | loss: 2.1581404MixupTrain:  epoch  0, batch   164 | loss: 2.0797358MixupTrain:  epoch  0, batch   165 | loss: 2.1423764MixupTrain:  epoch  0, batch   166 | loss: 2.1771731MixupTrain:  epoch  0, batch   167 | loss: 2.1849785MixupTrain:  epoch  0, batch   168 | loss: 2.1083763MixupTrain:  epoch  0, batch   169 | loss: 2.1109681MixupTrain:  epoch  0, batch   170 | loss: 2.1492698MixupTrain:  epoch  0, batch   171 | loss: 2.0836389MixupTrain:  epoch  0, batch   172 | loss: 2.0890560MixupTrain:  epoch  0, batch   173 | loss: 2.0770755MixupTrain:  epoch  0, batch   174 | loss: 2.0889449MixupTrain:  epoch  0, batch   175 | loss: 2.1426783MixupTrain:  epoch  0, batch   176 | loss: 2.1056378MixupTrain:  epoch  0, batch   177 | loss: 2.1635652MixupTrain:  epoch  0, batch   178 | loss: 2.0257092MixupTrain:  epoch  0, batch   179 | loss: 2.1205237MixupTrain:  epoch  0, batch   180 | loss: 2.0819707MixupTrain:  epoch  0, batch   181 | loss: 2.1304362MixupTrain:  epoch  0, batch   182 | loss: 2.0228658MixupTrain:  epoch  0, batch   183 | loss: 2.1212111MixupTrain:  epoch  0, batch   184 | loss: 2.0869660MixupTrain:  epoch  0, batch   185 | loss: 2.0745809MixupTrain:  epoch  0, batch   186 | loss: 2.1196187MixupTrain:  epoch  0, batch   187 | loss: 2.0711694MixupTrain:  epoch  0, batch   188 | loss: 2.1406722MixupTrain:  epoch  0, batch   189 | loss: 2.0832176MixupTrain:  epoch  0, batch   190 | loss: 2.0257611MixupTrain:  epoch  0, batch   191 | loss: 2.0326757MixupTrain:  epoch  0, batch   192 | loss: 2.0112767MixupTrain:  epoch  0, batch   193 | loss: 2.0816381MixupTrain:  epoch  0, batch   194 | loss: 2.0230126MixupTrain:  epoch  0, batch   195 | loss: 2.0516181MixupTrain:  epoch  0, batch   196 | loss: 2.0139749MixupTrain:  epoch  0, batch   197 | loss: 2.0649555MixupTrain:  epoch  0, batch   198 | loss: 2.0966716MixupTrain:  epoch  0, batch   199 | loss: 2.0634162MixupTrain:  epoch  0, batch   200 | loss: 1.9975913MixupTrain:  epoch  0, batch   201 | loss: 2.0723200MixupTrain:  epoch  0, batch   202 | loss: 2.0591657MixupTrain:  epoch  0, batch   203 | loss: 2.1227896MixupTrain:  epoch  0, batch   204 | loss: 2.0735459MixupTrain:  epoch  0, batch   205 | loss: 1.9796450MixupTrain:  epoch  0, batch   206 | loss: 2.0733991MixupTrain:  epoch  0, batch   207 | loss: 2.1305437MixupTrain:  epoch  0, batch   208 | loss: 2.0507312MixupTrain:  epoch  0, batch   209 | loss: 2.1189108MixupTrain:  epoch  0, batch   210 | loss: 2.0700116MixupTrain:  epoch  0, batch   211 | loss: 2.0842905MixupTrain:  epoch  0, batch   212 | loss: 2.0397079MixupTrain:  epoch  0, batch   213 | loss: 2.0748825MixupTrain:  epoch  0, batch   214 | loss: 2.0557470MixupTrain:  epoch  0, batch   215 | loss: 2.0543275MixupTrain:  epoch  0, batch   216 | loss: 2.0106258MixupTrain:  epoch  0, batch   217 | loss: 2.0326200MixupTrain:  epoch  0, batch   218 | loss: 2.0498581MixupTrain:  epoch  0, batch   219 | loss: 2.0640345MixupTrain:  epoch  0, batch   220 | loss: 2.0637536MixupTrain:  epoch  0, batch   221 | loss: 2.0371165MixupTrain:  epoch  0, batch   222 | loss: 2.0828807MixupTrain:  epoch  0, batch   223 | loss: 2.0784836MixupTrain:  epoch  0, batch   224 | loss: 2.0516255MixupTrain:  epoch  0, batch   225 | loss: 2.0493519MixupTrain:  epoch  0, batch   226 | loss: 2.1200728MixupTrain:  epoch  0, batch   227 | loss: 2.0424113MixupTrain:  epoch  0, batch   228 | loss: 2.0035775MixupTrain:  epoch  0, batch   229 | loss: 2.0407813MixupTrain:  epoch  0, batch   230 | loss: 2.0733421MixupTrain:  epoch  0, batch   231 | loss: 2.0400467MixupTrain:  epoch  0, batch   232 | loss: 1.9941974MixupTrain:  epoch  0, batch   233 | loss: 1.9665657
MemoryTrain:  epoch  0, batch     0 | loss: 2.0294662MemoryTrain:  epoch  0, batch     1 | loss: 3.5892797MemoryTrain:  epoch  0, batch     2 | loss: 3.2440372MemoryTrain:  epoch  0, batch     3 | loss: 3.0500586MemoryTrain:  epoch  0, batch     4 | loss: 2.4844337MemoryTrain:  epoch  1, batch     0 | loss: 1.8942311MemoryTrain:  epoch  1, batch     1 | loss: 1.8827492MemoryTrain:  epoch  1, batch     2 | loss: 1.8704834MemoryTrain:  epoch  1, batch     3 | loss: 1.8669477MemoryTrain:  epoch  1, batch     4 | loss: 1.8616312MemoryTrain:  epoch  2, batch     0 | loss: 1.8513293MemoryTrain:  epoch  2, batch     1 | loss: 1.8613951MemoryTrain:  epoch  2, batch     2 | loss: 1.8650763MemoryTrain:  epoch  2, batch     3 | loss: 1.8533425MemoryTrain:  epoch  2, batch     4 | loss: 1.8823714MemoryTrain:  epoch  3, batch     0 | loss: 1.8597038MemoryTrain:  epoch  3, batch     1 | loss: 1.8616130MemoryTrain:  epoch  3, batch     2 | loss: 1.8635937MemoryTrain:  epoch  3, batch     3 | loss: 1.8541136MemoryTrain:  epoch  3, batch     4 | loss: 1.8223870MemoryTrain:  epoch  4, batch     0 | loss: 1.8473181MemoryTrain:  epoch  4, batch     1 | loss: 1.8512287MemoryTrain:  epoch  4, batch     2 | loss: 1.8509843MemoryTrain:  epoch  4, batch     3 | loss: 1.8741772MemoryTrain:  epoch  4, batch     4 | loss: 1.8440293MemoryTrain:  epoch  5, batch     0 | loss: 1.8461635MemoryTrain:  epoch  5, batch     1 | loss: 1.8702353MemoryTrain:  epoch  5, batch     2 | loss: 1.8662949MemoryTrain:  epoch  5, batch     3 | loss: 1.8523918MemoryTrain:  epoch  5, batch     4 | loss: 1.8129525MemoryTrain:  epoch  6, batch     0 | loss: 1.8583357MemoryTrain:  epoch  6, batch     1 | loss: 1.8418198MemoryTrain:  epoch  6, batch     2 | loss: 1.8394364MemoryTrain:  epoch  6, batch     3 | loss: 1.8558378MemoryTrain:  epoch  6, batch     4 | loss: 1.9078109MemoryTrain:  epoch  7, batch     0 | loss: 1.8558084MemoryTrain:  epoch  7, batch     1 | loss: 1.8340890MemoryTrain:  epoch  7, batch     2 | loss: 1.9053798MemoryTrain:  epoch  7, batch     3 | loss: 1.8442001MemoryTrain:  epoch  7, batch     4 | loss: 2.0805895MemoryTrain:  epoch  8, batch     0 | loss: 1.8605641MemoryTrain:  epoch  8, batch     1 | loss: 1.8599914MemoryTrain:  epoch  8, batch     2 | loss: 1.8417038MemoryTrain:  epoch  8, batch     3 | loss: 1.8607371MemoryTrain:  epoch  8, batch     4 | loss: 1.8109531MemoryTrain:  epoch  9, batch     0 | loss: 1.8617132MemoryTrain:  epoch  9, batch     1 | loss: 1.8772541MemoryTrain:  epoch  9, batch     2 | loss: 1.8601489MemoryTrain:  epoch  9, batch     3 | loss: 1.8293220MemoryTrain:  epoch  9, batch     4 | loss: 1.8514688
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    1 | acc: 87.50%,  total acc: 81.25%   [EVAL] batch:    2 | acc: 100.00%,  total acc: 87.50%   [EVAL] batch:    3 | acc: 93.75%,  total acc: 89.06%   [EVAL] batch:    4 | acc: 100.00%,  total acc: 91.25%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 92.71%   [EVAL] batch:    6 | acc: 87.50%,  total acc: 91.96%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 92.19%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 93.06%   [EVAL] batch:    9 | acc: 87.50%,  total acc: 92.50%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 92.61%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 92.71%   [EVAL] batch:   12 | acc: 100.00%,  total acc: 93.27%   [EVAL] batch:   13 | acc: 62.50%,  total acc: 91.07%   
[EVAL] batch:    0 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    1 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    2 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    3 | acc: 81.25%,  total acc: 85.94%   [EVAL] batch:    4 | acc: 93.75%,  total acc: 87.50%   [EVAL] batch:    5 | acc: 75.00%,  total acc: 85.42%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 87.50%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 88.28%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 89.58%   [EVAL] batch:    9 | acc: 87.50%,  total acc: 89.38%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 90.34%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 90.62%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 90.87%   [EVAL] batch:   13 | acc: 68.75%,  total acc: 89.29%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 88.33%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 86.33%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 85.66%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 84.38%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 83.22%   [EVAL] batch:   19 | acc: 87.50%,  total acc: 83.44%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 83.63%   [EVAL] batch:   21 | acc: 93.75%,  total acc: 84.09%   [EVAL] batch:   22 | acc: 87.50%,  total acc: 84.24%   [EVAL] batch:   23 | acc: 100.00%,  total acc: 84.90%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 85.25%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 85.82%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 86.11%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 86.61%   [EVAL] batch:   28 | acc: 93.75%,  total acc: 86.85%   [EVAL] batch:   29 | acc: 81.25%,  total acc: 86.67%   [EVAL] batch:   30 | acc: 81.25%,  total acc: 86.49%   [EVAL] batch:   31 | acc: 93.75%,  total acc: 86.72%   [EVAL] batch:   32 | acc: 93.75%,  total acc: 86.93%   [EVAL] batch:   33 | acc: 68.75%,  total acc: 86.40%   [EVAL] batch:   34 | acc: 100.00%,  total acc: 86.79%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 86.98%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 87.33%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 87.66%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 87.98%   [EVAL] batch:   39 | acc: 81.25%,  total acc: 87.81%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 88.11%   [EVAL] batch:   41 | acc: 93.75%,  total acc: 88.24%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 88.37%   [EVAL] batch:   43 | acc: 87.50%,  total acc: 88.35%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 88.61%   [EVAL] batch:   45 | acc: 93.75%,  total acc: 88.72%   [EVAL] batch:   46 | acc: 6.25%,  total acc: 86.97%   
cur_acc:  ['0.8712', '0.9107']
his_acc:  ['0.8712', '0.8697']
CurrentTrain: epoch  0, batch     0 | loss: 5.9222317CurrentTrain: epoch  0, batch     1 | loss: 8.0102816CurrentTrain: epoch  1, batch     0 | loss: 6.4585896CurrentTrain: epoch  1, batch     1 | loss: 5.5596871CurrentTrain: epoch  2, batch     0 | loss: 4.9445882CurrentTrain: epoch  2, batch     1 | loss: 5.3398032CurrentTrain: epoch  3, batch     0 | loss: 4.5119219CurrentTrain: epoch  3, batch     1 | loss: 4.2410159CurrentTrain: epoch  4, batch     0 | loss: 3.7488637CurrentTrain: epoch  4, batch     1 | loss: 3.6469295CurrentTrain: epoch  5, batch     0 | loss: 2.9907551CurrentTrain: epoch  5, batch     1 | loss: 3.2598886CurrentTrain: epoch  6, batch     0 | loss: 3.2879055CurrentTrain: epoch  6, batch     1 | loss: 2.1762161CurrentTrain: epoch  7, batch     0 | loss: 2.6118538CurrentTrain: epoch  7, batch     1 | loss: 3.1304877CurrentTrain: epoch  8, batch     0 | loss: 2.0767784CurrentTrain: epoch  8, batch     1 | loss: 3.3787842CurrentTrain: epoch  9, batch     0 | loss: 2.1475687CurrentTrain: epoch  9, batch     1 | loss: 2.2173007
#### person country of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person country of birth" means a person was born in a country.
Here is an example:
Relation: person country of birth
Context: iran 's atomic chief ali akbar salehi has expressed tehran 's readiness to swap 1,200 kilogrammes -lrb- 2,640 pounds -rrb- of low-enriched uranium -lrb- leu -rrb- in one-shot for enriched atomic fuel .
Head Entity: ali akbar salehi
Tail Entity: iran
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person country of birth":
Relation: person country of birth  
Context: renowned physicist stephen hawking was born in oxford, england, where he later pursued his studies.  
Head Entity: stephen hawking  
Tail Entity: england  

Relation: person country of birth  
Context: the famous author j.k. rowling was born in yate, gloucestershire, which is located in the united kingdom.  
Head Entity: j.k. rowling  
Tail Entity: united kingdom  

Relation: person country of birth  
Context: the legendary musician bob marley was born in nine mile, jamaica, and became a global icon of reggae music.  
Head Entity: bob marley  
Tail Entity: jamaica  

Relation: person country of birth  
Context: actress and humanitarian angelina jolie was born in los angeles, california, which is part of the united states.  
Head Entity: angelina jolie  
Tail Entity: united states  

Relation: person country of birth  
Context: the famous painter pablo picasso was born in malaga, spain, and is known for co-founding the cubist movement.  
Head Entity: pablo picasso  
Tail Entity: spain  
#### organization website ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization website" means an organization 's website is an url.
Here is an example:
Relation: organization website
Context: 11.30.08 2008 cma awards red carpet special http://www.cmt.com/shows/dyn/2008-cma-awards-red-carpet/1/episode.jhtml
Head Entity: cma
Tail Entity: http://www.cmt.com/shows/dyn/2008-cma-awards-red-carpet/1/episode.jhtml
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization website":
Relation: organization website  
Context: The official website for the American Red Cross can be found at https://www.redcross.org.  
Head Entity: American Red Cross  
Tail Entity: https://www.redcross.org  

Relation: organization website  
Context: For more information about the World Wildlife Fund, visit their site at https://www.worldwildlife.org.  
Head Entity: World Wildlife Fund  
Tail Entity: https://www.worldwildlife.org  

Relation: organization website  
Context: You can explore the latest research and initiatives at the National Institutes of Health by going to https://www.nih.gov.  
Head Entity: National Institutes of Health  
Tail Entity: https://www.nih.gov  

Relation: organization website  
Context: The website for the United Nations is accessible at https://www.un.org.  
Head Entity: United Nations  
Tail Entity: https://www.un.org  

Relation: organization website  
Context: Check out the latest updates from NASA on their official website at https://www.nasa.gov.  
Head Entity: NASA  
Tail Entity: https://www.nasa.gov  
#### organization shareholders ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization shareholders" means an organization was invested by a person.
Here is an example:
Relation: organization shareholders
Context: marsans already owns the madrid-based air comet and 95 percent of aerolineas argentinas .
Head Entity: aerolineas argentinas
Tail Entity: marsans
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization shareholders":
Relation: organization shareholders  
Context: tech giant Apple has seen significant investments from Warren Buffett's Berkshire Hathaway.  
Head Entity: Apple  
Tail Entity: Berkshire Hathaway  

Relation: organization shareholders  
Context: The investment firm Vanguard Group has acquired a substantial stake in the renewable energy company NextEra Energy.  
Head Entity: NextEra Energy  
Tail Entity: Vanguard Group  

Relation: organization shareholders  
Context: Tesla's stock has been heavily bought by BlackRock, making it one of the largest shareholders in the electric vehicle manufacturer.  
Head Entity: Tesla  
Tail Entity: BlackRock  

Relation: organization shareholders  
Context: The pharmaceutical company Pfizer has received major investments from the investment group Fidelity.  
Head Entity: Pfizer  
Tail Entity: Fidelity  

Relation: organization shareholders  
Context: Google parent company Alphabet has attracted significant funding from the investment firm T. Rowe Price.  
Head Entity: Alphabet  
Tail Entity: T. Rowe Price  
#### organization dissolved ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization dissolved" means an organization was dissolved in a date.
Here is an example:
Relation: organization dissolved
Context: the tse suffered its worst-ever system crash in november 2005 which paralyzed the world 's second largest bourse and forced it to shelve plan for a listing of its own .
Head Entity: tse
Tail Entity: november 2005
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization dissolved":
Relation: organization dissolved  
Context: The once-prominent tech startup, Innovatech, officially ceased operations in March 2020 after struggling to secure funding.  
Head Entity: Innovatech  
Tail Entity: March 2020  

Relation: organization dissolved  
Context: After years of financial difficulties, the local arts council announced its dissolution in January 2019, leaving many artists without support.  
Head Entity: local arts council  
Tail Entity: January 2019  

Relation: organization dissolved  
Context: The historic bookstore, Pages & Co., closed its doors for good in July 2021, marking the end of an era for the community.  
Head Entity: Pages & Co.  
Tail Entity: July 2021  

Relation: organization dissolved  
Context: Following a series of scandals, the charity organization, Helping Hands, was dissolved in February 2022, prompting an investigation into its finances.  
Head Entity: Helping Hands  
Tail Entity: February 2022  

Relation: organization dissolved  
Context: The environmental group, Green Future, announced its dissolution in October 2018 due to a lack of public support and funding.  
Head Entity: Green Future  
Tail Entity: October 2018  
#### organization founded by ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization founded by" means an organization was found by a person.
Here is an example:
Relation: organization founded by
Context: born in new york , she inherited most of her fortune from her father , ted arison , who founded carnival cruise lines and also owned the miami heat basketball team .
Head Entity: carnival cruise lines
Tail Entity: ted arison
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization founded by":
1. Relation: organization founded by  
   Context: in 1975, steve jobs and steve wozniak started apple inc., which revolutionized the personal computer industry.  
   Head Entity: apple inc.  
   Tail Entity: steve jobs  

2. Relation: organization founded by  
   Context: the famous fashion brand gucci was established in florence by guccio gucci in 1921, becoming a symbol of luxury and style.  
   Head Entity: gucci  
   Tail Entity: guccio gucci  

3. Relation: organization founded by  
   Context: in 1994, jeff bezos launched amazon.com from his garage, transforming the way people shop online.  
   Head Entity: amazon.com  
   Tail Entity: jeff bezos  

4. Relation: organization founded by  
   Context: the non-profit organization greenpeace was co-founded by a group of activists, including doris leuthard, to promote environmental awareness.  
   Head Entity: greenpeace  
   Tail Entity: doris leuthard  

5. Relation: organization founded by  
   Context: in 2004, mark zuckerberg, along with his college roommates, created facebook, which has since become one of the largest social media platforms in the world.  
   Head Entity: facebook  
   Tail Entity: mark zuckerberg  
Mixup data size:  6820
MixupTrain:  epoch  0, batch     0 | loss: 5.6370120MixupTrain:  epoch  0, batch     1 | loss: 5.3568144MixupTrain:  epoch  0, batch     2 | loss: 4.8357859MixupTrain:  epoch  0, batch     3 | loss: 5.8500261MixupTrain:  epoch  0, batch     6 | loss: 5.1931591MixupTrain:  epoch  0, batch     7 | loss: 5.0482416MixupTrain:  epoch  0, batch     8 | loss: 4.5601702MixupTrain:  epoch  0, batch     9 | loss: 4.7085114MixupTrain:  epoch  0, batch    10 | loss: 4.7912245MixupTrain:  epoch  0, batch    11 | loss: 5.0905395MixupTrain:  epoch  0, batch    12 | loss: 5.1634684MixupTrain:  epoch  0, batch    13 | loss: 5.0048370MixupTrain:  epoch  0, batch    14 | loss: 3.9052331MixupTrain:  epoch  0, batch    15 | loss: 5.6047363MixupTrain:  epoch  0, batch    16 | loss: 4.1285014MixupTrain:  epoch  0, batch    17 | loss: 4.8135309MixupTrain:  epoch  0, batch    19 | loss: 5.0031967MixupTrain:  epoch  0, batch    20 | loss: 4.7158570MixupTrain:  epoch  0, batch    21 | loss: 4.1573715MixupTrain:  epoch  0, batch    22 | loss: 4.3919144MixupTrain:  epoch  0, batch    23 | loss: 3.9259093MixupTrain:  epoch  0, batch    25 | loss: 4.2178650MixupTrain:  epoch  0, batch    26 | loss: 4.5795765MixupTrain:  epoch  0, batch    29 | loss: 4.2663002MixupTrain:  epoch  0, batch    31 | loss: 3.9273434MixupTrain:  epoch  0, batch    32 | loss: 4.4859910MixupTrain:  epoch  0, batch    33 | loss: 3.8648188MixupTrain:  epoch  0, batch    34 | loss: 4.3776073MixupTrain:  epoch  0, batch    35 | loss: 4.1557188MixupTrain:  epoch  0, batch    36 | loss: 3.3780932MixupTrain:  epoch  0, batch    37 | loss: 3.9890792MixupTrain:  epoch  0, batch    38 | loss: 3.8287334MixupTrain:  epoch  0, batch    39 | loss: 3.8400593MixupTrain:  epoch  0, batch    40 | loss: 3.5380821MixupTrain:  epoch  0, batch    42 | loss: 3.5188279MixupTrain:  epoch  0, batch    43 | loss: 3.8437011MixupTrain:  epoch  0, batch    44 | loss: 4.0521841MixupTrain:  epoch  0, batch    46 | loss: 3.4441917MixupTrain:  epoch  0, batch    47 | loss: 3.6476841MixupTrain:  epoch  0, batch    48 | loss: 3.5533228MixupTrain:  epoch  0, batch    49 | loss: 3.6279063MixupTrain:  epoch  0, batch    50 | loss: 3.3671789MixupTrain:  epoch  0, batch    51 | loss: 3.7677650MixupTrain:  epoch  0, batch    52 | loss: 3.2436223MixupTrain:  epoch  0, batch    53 | loss: 3.1963782MixupTrain:  epoch  0, batch    54 | loss: 4.0061693MixupTrain:  epoch  0, batch    57 | loss: 3.6233387MixupTrain:  epoch  0, batch    58 | loss: 3.1596560MixupTrain:  epoch  0, batch    59 | loss: 3.0994000MixupTrain:  epoch  0, batch    60 | loss: 4.0323644MixupTrain:  epoch  0, batch    61 | loss: 3.5146151MixupTrain:  epoch  0, batch    62 | loss: 3.0483217MixupTrain:  epoch  0, batch    63 | loss: 3.6583169MixupTrain:  epoch  0, batch    66 | loss: 2.6968961MixupTrain:  epoch  0, batch    67 | loss: 2.9002256MixupTrain:  epoch  0, batch    68 | loss: 3.1329362MixupTrain:  epoch  0, batch    69 | loss: 2.8798661MixupTrain:  epoch  0, batch    70 | loss: 3.0936842MixupTrain:  epoch  0, batch    71 | loss: 3.3092685MixupTrain:  epoch  0, batch    72 | loss: 3.2885938MixupTrain:  epoch  0, batch    73 | loss: 3.4350190MixupTrain:  epoch  0, batch    74 | loss: 2.8577583MixupTrain:  epoch  0, batch    75 | loss: 2.8044190MixupTrain:  epoch  0, batch    77 | loss: 3.9907260MixupTrain:  epoch  0, batch    78 | loss: 3.5544989MixupTrain:  epoch  0, batch    81 | loss: 3.3753121MixupTrain:  epoch  0, batch    83 | loss: 3.2398181MixupTrain:  epoch  0, batch    84 | loss: 2.8900955MixupTrain:  epoch  0, batch    87 | loss: 3.2244539MixupTrain:  epoch  0, batch    88 | loss: 3.2597923MixupTrain:  epoch  0, batch    89 | loss: 2.6372430MixupTrain:  epoch  0, batch    90 | loss: 3.4230862MixupTrain:  epoch  0, batch    91 | loss: 3.2975707MixupTrain:  epoch  0, batch    92 | loss: 2.8609016MixupTrain:  epoch  0, batch    93 | loss: 2.7450752MixupTrain:  epoch  0, batch    94 | loss: 2.4495661MixupTrain:  epoch  0, batch    95 | loss: 2.6408575MixupTrain:  epoch  0, batch    97 | loss: 3.1197352MixupTrain:  epoch  0, batch   100 | loss: 3.2340086MixupTrain:  epoch  0, batch   102 | loss: 3.1920261MixupTrain:  epoch  0, batch   105 | loss: 2.5826807MixupTrain:  epoch  0, batch   106 | loss: 2.7381241MixupTrain:  epoch  0, batch   107 | loss: 2.8749900MixupTrain:  epoch  0, batch   108 | loss: 3.1857615MixupTrain:  epoch  0, batch   109 | loss: 2.9704998MixupTrain:  epoch  0, batch   110 | loss: 3.0940511MixupTrain:  epoch  0, batch   111 | loss: 3.3639612MixupTrain:  epoch  0, batch   112 | loss: 2.9894309MixupTrain:  epoch  0, batch   113 | loss: 3.3363481MixupTrain:  epoch  0, batch   114 | loss: 3.1076674MixupTrain:  epoch  0, batch   115 | loss: 2.9381163MixupTrain:  epoch  0, batch   117 | loss: 3.4394386MixupTrain:  epoch  0, batch   118 | loss: 2.3639662MixupTrain:  epoch  0, batch   119 | loss: 2.8509724MixupTrain:  epoch  0, batch   121 | loss: 3.1965787MixupTrain:  epoch  0, batch   122 | loss: 3.2626433MixupTrain:  epoch  0, batch   123 | loss: 2.9467483MixupTrain:  epoch  0, batch   124 | loss: 2.9046907MixupTrain:  epoch  0, batch   125 | loss: 3.2266619MixupTrain:  epoch  0, batch   126 | loss: 2.8717041MixupTrain:  epoch  0, batch   127 | loss: 2.9734683MixupTrain:  epoch  0, batch   129 | loss: 2.6489365MixupTrain:  epoch  0, batch   130 | loss: 3.1885264MixupTrain:  epoch  0, batch   131 | loss: 3.0129561MixupTrain:  epoch  0, batch   132 | loss: 3.0886025MixupTrain:  epoch  0, batch   133 | loss: 2.8583841MixupTrain:  epoch  0, batch   135 | loss: 2.7681985MixupTrain:  epoch  0, batch   136 | loss: 2.2555580MixupTrain:  epoch  0, batch   137 | loss: 3.0752423MixupTrain:  epoch  0, batch   139 | loss: 2.9238670MixupTrain:  epoch  0, batch   140 | loss: 3.2233982MixupTrain:  epoch  0, batch   141 | loss: 3.3029830MixupTrain:  epoch  0, batch   142 | loss: 2.9371562MixupTrain:  epoch  0, batch   143 | loss: 3.2624073MixupTrain:  epoch  0, batch   144 | loss: 2.8742309MixupTrain:  epoch  0, batch   145 | loss: 3.0137610MixupTrain:  epoch  0, batch   146 | loss: 3.0913911MixupTrain:  epoch  0, batch   148 | loss: 2.5956454MixupTrain:  epoch  0, batch   150 | loss: 2.6186929MixupTrain:  epoch  0, batch   152 | loss: 2.6152053MixupTrain:  epoch  0, batch   153 | loss: 2.6479833MixupTrain:  epoch  0, batch   154 | loss: 3.0382483MixupTrain:  epoch  0, batch   156 | loss: 2.9223928MixupTrain:  epoch  0, batch   157 | loss: 2.4937649MixupTrain:  epoch  0, batch   158 | loss: 2.7351980MixupTrain:  epoch  0, batch   160 | loss: 2.6421044MixupTrain:  epoch  0, batch   161 | loss: 2.7034745MixupTrain:  epoch  0, batch   162 | loss: 3.0484667MixupTrain:  epoch  0, batch   163 | loss: 2.9398746MixupTrain:  epoch  0, batch   164 | loss: 2.9856613MixupTrain:  epoch  0, batch   167 | loss: 2.7683890MixupTrain:  epoch  0, batch   168 | loss: 2.5974994MixupTrain:  epoch  0, batch   169 | loss: 3.0764146MixupTrain:  epoch  0, batch   170 | loss: 2.8842013MixupTrain:  epoch  0, batch   171 | loss: 2.6044507MixupTrain:  epoch  0, batch   173 | loss: 2.5907671MixupTrain:  epoch  0, batch   175 | loss: 2.8174198MixupTrain:  epoch  0, batch   176 | loss: 2.9866827MixupTrain:  epoch  0, batch   177 | loss: 2.4980712MixupTrain:  epoch  0, batch   178 | loss: 2.9749782MixupTrain:  epoch  0, batch   180 | loss: 2.7943449MixupTrain:  epoch  0, batch   181 | loss: 2.6118860MixupTrain:  epoch  0, batch   186 | loss: 2.6796401MixupTrain:  epoch  0, batch   187 | loss: 2.6787524MixupTrain:  epoch  0, batch   188 | loss: 2.6790357MixupTrain:  epoch  0, batch   190 | loss: 3.4545858MixupTrain:  epoch  0, batch   191 | loss: 2.6900754MixupTrain:  epoch  0, batch   192 | loss: 2.4511580MixupTrain:  epoch  0, batch   193 | loss: 2.4303508MixupTrain:  epoch  0, batch   196 | loss: 2.6420949MixupTrain:  epoch  0, batch   198 | loss: 2.6487136MixupTrain:  epoch  0, batch   199 | loss: 2.8545036MixupTrain:  epoch  0, batch   200 | loss: 2.3486118MixupTrain:  epoch  0, batch   201 | loss: 2.8865900MixupTrain:  epoch  0, batch   202 | loss: 2.9045591MixupTrain:  epoch  0, batch   204 | loss: 2.8465137MixupTrain:  epoch  0, batch   205 | loss: 2.5009508MixupTrain:  epoch  0, batch   207 | loss: 2.7365229MixupTrain:  epoch  0, batch   208 | loss: 2.2857075MixupTrain:  epoch  0, batch   210 | loss: 2.4062316MixupTrain:  epoch  0, batch   211 | loss: 2.6143508MixupTrain:  epoch  0, batch   212 | loss: 3.3019972MixupTrain:  epoch  0, batch   213 | loss: 2.4838789MixupTrain:  epoch  0, batch   214 | loss: 2.7126064MixupTrain:  epoch  0, batch   216 | loss: 3.0237615MixupTrain:  epoch  0, batch   217 | loss: 2.6705372MixupTrain:  epoch  0, batch   218 | loss: 2.7146227MixupTrain:  epoch  0, batch   219 | loss: 2.3956032MixupTrain:  epoch  0, batch   220 | loss: 2.7272837MixupTrain:  epoch  0, batch   221 | loss: 2.8964736MixupTrain:  epoch  0, batch   222 | loss: 2.3374178MixupTrain:  epoch  0, batch   223 | loss: 2.5565400MixupTrain:  epoch  0, batch   225 | loss: 2.2912111MixupTrain:  epoch  0, batch   226 | loss: 2.8014207MixupTrain:  epoch  0, batch   227 | loss: 2.6468396MixupTrain:  epoch  0, batch   228 | loss: 2.2900000MixupTrain:  epoch  0, batch   229 | loss: 2.3215365MixupTrain:  epoch  0, batch   231 | loss: 2.6795971MixupTrain:  epoch  0, batch   232 | loss: 2.8651683MixupTrain:  epoch  0, batch   234 | loss: 2.6931493MixupTrain:  epoch  0, batch   235 | loss: 2.5956960MixupTrain:  epoch  0, batch   238 | loss: 2.3536167MixupTrain:  epoch  0, batch   239 | loss: 2.7210310MixupTrain:  epoch  0, batch   240 | loss: 2.6014299MixupTrain:  epoch  0, batch   241 | loss: 2.8460410MixupTrain:  epoch  0, batch   242 | loss: 2.6853559MixupTrain:  epoch  0, batch   243 | loss: 2.5623779MixupTrain:  epoch  0, batch   244 | loss: 2.4640999MixupTrain:  epoch  0, batch   245 | loss: 2.6090546MixupTrain:  epoch  0, batch   247 | loss: 2.2989554MixupTrain:  epoch  0, batch   248 | loss: 2.4814463MixupTrain:  epoch  0, batch   249 | loss: 2.8035316MixupTrain:  epoch  0, batch   250 | loss: 2.7161238MixupTrain:  epoch  0, batch   251 | loss: 2.3826058MixupTrain:  epoch  0, batch   252 | loss: 2.5925679MixupTrain:  epoch  0, batch   253 | loss: 2.6396284MixupTrain:  epoch  0, batch   254 | loss: 2.9014950MixupTrain:  epoch  0, batch   256 | loss: 2.6187558MixupTrain:  epoch  0, batch   257 | loss: 2.3063655MixupTrain:  epoch  0, batch   258 | loss: 2.5539489MixupTrain:  epoch  0, batch   259 | loss: 2.6629565MixupTrain:  epoch  0, batch   261 | loss: 2.6469665MixupTrain:  epoch  0, batch   262 | loss: 2.4279788MixupTrain:  epoch  0, batch   264 | loss: 2.5472605MixupTrain:  epoch  0, batch   266 | loss: 2.4241750MixupTrain:  epoch  0, batch   267 | loss: 2.4444246MixupTrain:  epoch  0, batch   268 | loss: 2.7109311MixupTrain:  epoch  0, batch   269 | loss: 2.6886814MixupTrain:  epoch  0, batch   270 | loss: 2.3760509MixupTrain:  epoch  0, batch   272 | loss: 2.3829596MixupTrain:  epoch  0, batch   273 | loss: 2.9747276MixupTrain:  epoch  0, batch   274 | loss: 2.4924700MixupTrain:  epoch  0, batch   275 | loss: 3.0207131MixupTrain:  epoch  0, batch   276 | loss: 2.5074480MixupTrain:  epoch  0, batch   277 | loss: 2.7842851MixupTrain:  epoch  0, batch   278 | loss: 2.6166615MixupTrain:  epoch  0, batch   279 | loss: 2.2361841MixupTrain:  epoch  0, batch   280 | loss: 2.8548052MixupTrain:  epoch  0, batch   282 | loss: 2.6630743MixupTrain:  epoch  0, batch   283 | loss: 2.6152389MixupTrain:  epoch  0, batch   284 | loss: 2.4605961MixupTrain:  epoch  0, batch   285 | loss: 2.5697446MixupTrain:  epoch  0, batch   286 | loss: 2.6728621MixupTrain:  epoch  0, batch   287 | loss: 2.3281550MixupTrain:  epoch  0, batch   288 | loss: 2.8839800MixupTrain:  epoch  0, batch   289 | loss: 2.4876480MixupTrain:  epoch  0, batch   290 | loss: 2.6798470MixupTrain:  epoch  0, batch   291 | loss: 2.8609819MixupTrain:  epoch  0, batch   292 | loss: 2.4893069MixupTrain:  epoch  0, batch   294 | loss: 2.6443675MixupTrain:  epoch  0, batch   295 | loss: 2.8299727MixupTrain:  epoch  0, batch   296 | loss: 2.5315137MixupTrain:  epoch  0, batch   297 | loss: 2.5660267MixupTrain:  epoch  0, batch   299 | loss: 2.1324925MixupTrain:  epoch  0, batch   300 | loss: 2.5448639MixupTrain:  epoch  0, batch   301 | loss: 2.3164225MixupTrain:  epoch  0, batch   303 | loss: 2.6693978MixupTrain:  epoch  0, batch   304 | loss: 2.2117810MixupTrain:  epoch  0, batch   306 | loss: 3.1158943MixupTrain:  epoch  0, batch   307 | loss: 2.9416041MixupTrain:  epoch  0, batch   308 | loss: 2.5837998MixupTrain:  epoch  0, batch   309 | loss: 2.1533303MixupTrain:  epoch  0, batch   310 | loss: 2.7502117MixupTrain:  epoch  0, batch   311 | loss: 2.3720469MixupTrain:  epoch  0, batch   312 | loss: 2.4531448MixupTrain:  epoch  0, batch   313 | loss: 2.2420201MixupTrain:  epoch  0, batch   314 | loss: 2.5655704MixupTrain:  epoch  0, batch   315 | loss: 2.4310591MixupTrain:  epoch  0, batch   316 | loss: 2.6065805MixupTrain:  epoch  0, batch   317 | loss: 2.5538006MixupTrain:  epoch  0, batch   318 | loss: 2.6678224MixupTrain:  epoch  0, batch   321 | loss: 2.6611638MixupTrain:  epoch  0, batch   323 | loss: 2.3770909MixupTrain:  epoch  0, batch   324 | loss: 2.6915340MixupTrain:  epoch  0, batch   325 | loss: 2.7340970MixupTrain:  epoch  0, batch   327 | loss: 2.7109752MixupTrain:  epoch  0, batch   328 | loss: 2.7322910MixupTrain:  epoch  0, batch   329 | loss: 2.9765220MixupTrain:  epoch  0, batch   331 | loss: 2.6090600MixupTrain:  epoch  0, batch   333 | loss: 2.4848893MixupTrain:  epoch  0, batch   334 | loss: 2.6021745MixupTrain:  epoch  0, batch   335 | loss: 2.3560739MixupTrain:  epoch  0, batch   339 | loss: 2.4907451MixupTrain:  epoch  0, batch   341 | loss: 2.3778410MixupTrain:  epoch  0, batch   343 | loss: 2.6597247MixupTrain:  epoch  0, batch   344 | loss: 2.5128250MixupTrain:  epoch  0, batch   345 | loss: 2.1746101MixupTrain:  epoch  0, batch   346 | loss: 2.2847085MixupTrain:  epoch  0, batch   347 | loss: 2.5722799MixupTrain:  epoch  0, batch   348 | loss: 2.7552469MixupTrain:  epoch  0, batch   349 | loss: 2.6817172MixupTrain:  epoch  0, batch   350 | loss: 2.5903554MixupTrain:  epoch  0, batch   351 | loss: 2.3357010MixupTrain:  epoch  0, batch   352 | loss: 2.6220484MixupTrain:  epoch  0, batch   353 | loss: 2.6871052MixupTrain:  epoch  0, batch   354 | loss: 2.9696090MixupTrain:  epoch  0, batch   355 | loss: 2.4237175MixupTrain:  epoch  0, batch   357 | loss: 2.3774636MixupTrain:  epoch  0, batch   359 | loss: 2.7311368MixupTrain:  epoch  0, batch   360 | loss: 2.4108219MixupTrain:  epoch  0, batch   361 | loss: 2.4294128MixupTrain:  epoch  0, batch   362 | loss: 2.5360870MixupTrain:  epoch  0, batch   363 | loss: 2.1713052MixupTrain:  epoch  0, batch   364 | loss: 2.3212562MixupTrain:  epoch  0, batch   365 | loss: 2.6150873MixupTrain:  epoch  0, batch   366 | loss: 2.5646293MixupTrain:  epoch  0, batch   368 | loss: 2.4221203MixupTrain:  epoch  0, batch   370 | loss: 2.5714343MixupTrain:  epoch  0, batch   371 | loss: 2.5761027MixupTrain:  epoch  0, batch   372 | loss: 2.2825608MixupTrain:  epoch  0, batch   373 | loss: 2.6591177MixupTrain:  epoch  0, batch   375 | loss: 2.6630626MixupTrain:  epoch  0, batch   377 | loss: 2.3582563MixupTrain:  epoch  0, batch   379 | loss: 2.7810776MixupTrain:  epoch  0, batch   380 | loss: 2.3244591MixupTrain:  epoch  0, batch   381 | loss: 2.5544558MixupTrain:  epoch  0, batch   383 | loss: 2.6601255MixupTrain:  epoch  0, batch   384 | loss: 2.6978092MixupTrain:  epoch  0, batch   385 | loss: 2.3455176MixupTrain:  epoch  0, batch   386 | loss: 2.5956922MixupTrain:  epoch  0, batch   387 | loss: 2.3999436MixupTrain:  epoch  0, batch   388 | loss: 2.3489122MixupTrain:  epoch  0, batch   389 | loss: 2.6613386MixupTrain:  epoch  0, batch   390 | loss: 2.4935837MixupTrain:  epoch  0, batch   391 | loss: 2.5328326MixupTrain:  epoch  0, batch   392 | loss: 2.6963856MixupTrain:  epoch  0, batch   394 | loss: 2.3838778MixupTrain:  epoch  0, batch   396 | loss: 2.3904023MixupTrain:  epoch  0, batch   397 | loss: 2.4882255MixupTrain:  epoch  0, batch   398 | loss: 2.3820977MixupTrain:  epoch  0, batch   400 | loss: 2.4529567MixupTrain:  epoch  0, batch   401 | loss: 2.4772527MixupTrain:  epoch  0, batch   402 | loss: 2.6804335MixupTrain:  epoch  0, batch   403 | loss: 2.6867609MixupTrain:  epoch  0, batch   404 | loss: 2.3385186MixupTrain:  epoch  0, batch   405 | loss: 2.5877585MixupTrain:  epoch  0, batch   406 | loss: 2.1344848MixupTrain:  epoch  0, batch   407 | loss: 2.6755230MixupTrain:  epoch  0, batch   408 | loss: 2.5320766MixupTrain:  epoch  0, batch   409 | loss: 2.7876787MixupTrain:  epoch  0, batch   410 | loss: 2.2983065MixupTrain:  epoch  0, batch   411 | loss: 2.4144001MixupTrain:  epoch  0, batch   415 | loss: 2.4417956MixupTrain:  epoch  0, batch   417 | loss: 2.6028047MixupTrain:  epoch  0, batch   418 | loss: 2.5159483MixupTrain:  epoch  0, batch   419 | loss: 2.5811768MixupTrain:  epoch  0, batch   420 | loss: 2.3267055MixupTrain:  epoch  0, batch   421 | loss: 2.6475532MixupTrain:  epoch  0, batch   422 | loss: 2.3660953MixupTrain:  epoch  0, batch   423 | loss: 2.9891567MixupTrain:  epoch  0, batch   424 | loss: 2.5180538MixupTrain:  epoch  0, batch   425 | loss: 2.2293077MixupTrain:  epoch  0, batch   426 | loss: 3.3059807
MemoryTrain:  epoch  0, batch     0 | loss: 2.3662658MemoryTrain:  epoch  0, batch     1 | loss: 2.9010468MemoryTrain:  epoch  0, batch     2 | loss: 3.8122680MemoryTrain:  epoch  0, batch     3 | loss: 2.5169888MemoryTrain:  epoch  0, batch     4 | loss: 2.8365791MemoryTrain:  epoch  0, batch     5 | loss: 2.1744390MemoryTrain:  epoch  1, batch     0 | loss: 1.8476112MemoryTrain:  epoch  1, batch     1 | loss: 1.8677176MemoryTrain:  epoch  1, batch     2 | loss: 1.8522316MemoryTrain:  epoch  1, batch     3 | loss: 1.8610418MemoryTrain:  epoch  1, batch     4 | loss: 1.8560379MemoryTrain:  epoch  1, batch     5 | loss: 1.8545955MemoryTrain:  epoch  2, batch     0 | loss: 1.8513538MemoryTrain:  epoch  2, batch     1 | loss: 1.8556476MemoryTrain:  epoch  2, batch     2 | loss: 1.8979568MemoryTrain:  epoch  2, batch     3 | loss: 1.8337548MemoryTrain:  epoch  2, batch     4 | loss: 1.8719337MemoryTrain:  epoch  2, batch     5 | loss: 1.8688078MemoryTrain:  epoch  3, batch     0 | loss: 1.8363268MemoryTrain:  epoch  3, batch     1 | loss: 1.8477879MemoryTrain:  epoch  3, batch     2 | loss: 1.8639202MemoryTrain:  epoch  3, batch     3 | loss: 1.9031177MemoryTrain:  epoch  3, batch     4 | loss: 1.8535614MemoryTrain:  epoch  3, batch     5 | loss: 1.8719816MemoryTrain:  epoch  4, batch     0 | loss: 1.8466789MemoryTrain:  epoch  4, batch     1 | loss: 1.8423736MemoryTrain:  epoch  4, batch     2 | loss: 1.8666259MemoryTrain:  epoch  4, batch     3 | loss: 1.8548577MemoryTrain:  epoch  4, batch     4 | loss: 1.8494653MemoryTrain:  epoch  4, batch     5 | loss: 1.8842208MemoryTrain:  epoch  5, batch     0 | loss: 1.8781140MemoryTrain:  epoch  5, batch     1 | loss: 1.8575968MemoryTrain:  epoch  5, batch     2 | loss: 1.9103985MemoryTrain:  epoch  5, batch     3 | loss: 1.8563414MemoryTrain:  epoch  5, batch     4 | loss: 1.8556259MemoryTrain:  epoch  5, batch     5 | loss: 1.8654388MemoryTrain:  epoch  6, batch     0 | loss: 1.8642974MemoryTrain:  epoch  6, batch     1 | loss: 1.8543229MemoryTrain:  epoch  6, batch     2 | loss: 1.8456933MemoryTrain:  epoch  6, batch     3 | loss: 1.8644576MemoryTrain:  epoch  6, batch     4 | loss: 1.8554934MemoryTrain:  epoch  6, batch     5 | loss: 1.8568599MemoryTrain:  epoch  7, batch     0 | loss: 1.8615192MemoryTrain:  epoch  7, batch     1 | loss: 1.8467920MemoryTrain:  epoch  7, batch     2 | loss: 1.8517551MemoryTrain:  epoch  7, batch     3 | loss: 1.8701519MemoryTrain:  epoch  7, batch     4 | loss: 1.8369256MemoryTrain:  epoch  7, batch     5 | loss: 1.8754470MemoryTrain:  epoch  8, batch     0 | loss: 1.8652300MemoryTrain:  epoch  8, batch     1 | loss: 1.8636669MemoryTrain:  epoch  8, batch     2 | loss: 1.8615751MemoryTrain:  epoch  8, batch     3 | loss: 1.8409150MemoryTrain:  epoch  8, batch     4 | loss: 1.8422310MemoryTrain:  epoch  8, batch     5 | loss: 1.8587672MemoryTrain:  epoch  9, batch     0 | loss: 1.8319557MemoryTrain:  epoch  9, batch     1 | loss: 1.8419309MemoryTrain:  epoch  9, batch     2 | loss: 1.8514476MemoryTrain:  epoch  9, batch     3 | loss: 1.8709791MemoryTrain:  epoch  9, batch     4 | loss: 1.8647518MemoryTrain:  epoch  9, batch     5 | loss: 1.8931488
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 84.38%   [EVAL] batch:    2 | acc: 93.75%,  total acc: 87.50%   [EVAL] batch:    3 | acc: 93.75%,  total acc: 89.06%   [EVAL] batch:    4 | acc: 100.00%,  total acc: 91.25%   [EVAL] batch:    5 | acc: 93.75%,  total acc: 91.67%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 92.86%   [EVAL] batch:    7 | acc: 12.50%,  total acc: 82.81%   
[EVAL] batch:    0 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:    1 | acc: 31.25%,  total acc: 18.75%   [EVAL] batch:    2 | acc: 25.00%,  total acc: 20.83%   [EVAL] batch:    3 | acc: 6.25%,  total acc: 17.19%   [EVAL] batch:    4 | acc: 12.50%,  total acc: 16.25%   [EVAL] batch:    5 | acc: 18.75%,  total acc: 16.67%   [EVAL] batch:    6 | acc: 18.75%,  total acc: 16.96%   [EVAL] batch:    7 | acc: 6.25%,  total acc: 15.62%   [EVAL] batch:    8 | acc: 31.25%,  total acc: 17.36%   [EVAL] batch:    9 | acc: 6.25%,  total acc: 16.25%   [EVAL] batch:   10 | acc: 12.50%,  total acc: 15.91%   [EVAL] batch:   11 | acc: 18.75%,  total acc: 16.15%   [EVAL] batch:   12 | acc: 12.50%,  total acc: 15.87%   [EVAL] batch:   13 | acc: 25.00%,  total acc: 16.52%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 20.42%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 22.66%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 25.74%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 27.78%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 29.61%   [EVAL] batch:   19 | acc: 87.50%,  total acc: 32.50%   [EVAL] batch:   20 | acc: 81.25%,  total acc: 34.82%   [EVAL] batch:   21 | acc: 93.75%,  total acc: 37.50%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 39.40%   [EVAL] batch:   23 | acc: 100.00%,  total acc: 41.93%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 44.00%   [EVAL] batch:   25 | acc: 93.75%,  total acc: 45.91%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 47.69%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 49.33%   [EVAL] batch:   28 | acc: 93.75%,  total acc: 50.86%   [EVAL] batch:   29 | acc: 81.25%,  total acc: 51.88%   [EVAL] batch:   30 | acc: 81.25%,  total acc: 52.82%   [EVAL] batch:   31 | acc: 93.75%,  total acc: 54.10%   [EVAL] batch:   32 | acc: 93.75%,  total acc: 55.30%   [EVAL] batch:   33 | acc: 62.50%,  total acc: 55.51%   [EVAL] batch:   34 | acc: 100.00%,  total acc: 56.79%   [EVAL] batch:   35 | acc: 87.50%,  total acc: 57.64%   [EVAL] batch:   36 | acc: 87.50%,  total acc: 58.45%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 59.54%   [EVAL] batch:   38 | acc: 93.75%,  total acc: 60.42%   [EVAL] batch:   39 | acc: 87.50%,  total acc: 61.09%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 62.04%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 62.95%   [EVAL] batch:   42 | acc: 87.50%,  total acc: 63.52%   [EVAL] batch:   43 | acc: 87.50%,  total acc: 64.06%   [EVAL] batch:   44 | acc: 93.75%,  total acc: 64.72%   [EVAL] batch:   45 | acc: 81.25%,  total acc: 65.08%   [EVAL] batch:   46 | acc: 68.75%,  total acc: 65.16%   [EVAL] batch:   47 | acc: 93.75%,  total acc: 65.76%   [EVAL] batch:   48 | acc: 93.75%,  total acc: 66.33%   [EVAL] batch:   49 | acc: 93.75%,  total acc: 66.88%   [EVAL] batch:   50 | acc: 100.00%,  total acc: 67.52%   [EVAL] batch:   51 | acc: 93.75%,  total acc: 68.03%   [EVAL] batch:   52 | acc: 100.00%,  total acc: 68.63%   [EVAL] batch:   53 | acc: 18.75%,  total acc: 67.71%   
cur_acc:  ['0.8712', '0.9107', '0.8281']
his_acc:  ['0.8712', '0.8697', '0.6771']
CurrentTrain: epoch  0, batch     0 | loss: 4.5362892CurrentTrain: epoch  0, batch     1 | loss: 4.6948228CurrentTrain: epoch  1, batch     0 | loss: 4.1428475CurrentTrain: epoch  1, batch     1 | loss: 3.8999753CurrentTrain: epoch  2, batch     0 | loss: 4.1752195CurrentTrain: epoch  2, batch     1 | loss: 3.7607007CurrentTrain: epoch  3, batch     0 | loss: 3.6556854CurrentTrain: epoch  3, batch     1 | loss: 2.4535866CurrentTrain: epoch  4, batch     0 | loss: 2.5500238CurrentTrain: epoch  4, batch     1 | loss: 2.3932559CurrentTrain: epoch  5, batch     0 | loss: 2.6582305CurrentTrain: epoch  5, batch     1 | loss: 2.0812247CurrentTrain: epoch  6, batch     0 | loss: 2.3625007CurrentTrain: epoch  6, batch     1 | loss: 2.5385945CurrentTrain: epoch  7, batch     0 | loss: 2.3564551CurrentTrain: epoch  7, batch     1 | loss: 2.1734309CurrentTrain: epoch  8, batch     0 | loss: 2.3286862CurrentTrain: epoch  8, batch     1 | loss: 2.1465797CurrentTrain: epoch  9, batch     0 | loss: 2.0556383CurrentTrain: epoch  9, batch     1 | loss: 2.4212990
#### person cause of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person cause of death" means a person was died of an event.
Here is an example:
Relation: person cause of death
Context: pamela gardner ahearn , who served nine years as chief of protocol at the us house of representatives after earlier experience with the state department 's office of protocol and as elizabeth taylor 's executive assistant , died march 26 of a heart attack at her home in alexandria , va .
Head Entity: pamela gardner ahearn
Tail Entity: heart attack
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person cause of death":
Relation: person cause of death  
Context: john smith, a renowned scientist known for his groundbreaking research in genetics, passed away on july 15 due to complications from pneumonia while receiving treatment at a local hospital.  
Head Entity: john smith  
Tail Entity: pneumonia  

Relation: person cause of death  
Context: the famous actor, robert downey jr., tragically lost his life in a car accident on february 10, leaving behind a legacy of memorable performances.  
Head Entity: robert downey jr.  
Tail Entity: car accident  

Relation: person cause of death  
Context: after a long battle with cancer, the beloved author, marie clark, succumbed to her illness on november 5, surrounded by family and friends.  
Head Entity: marie clark  
Tail Entity: cancer  

Relation: person cause of death  
Context: the legendary musician, freddie mercury, died on november 24, 1991, due to complications from aids, a disease he bravely fought for years.  
Head Entity: freddie mercury  
Tail Entity: aids  

Relation: person cause of death  
Context: in a tragic incident, the young athlete, jason lee, lost his life in a tragic drowning accident while on vacation with friends in the summer of 2022.  
Head Entity: jason lee  
Tail Entity: drowning accident  
#### organization political religious affiliation ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization political religious affiliation" means an organization is the member of a religion.
Here is an example:
Relation: organization political religious affiliation
Context: clashes in late august in karbala between the mahdi army and a rival shiite militia , the badr organization , left at least 50 people dead .
Head Entity: badr organization
Tail Entity: shiite
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization political religious affiliation":
Relation: organization political religious affiliation  
Context: The Christian Democratic Union has been a significant player in German politics, advocating for policies that align with its religious values.  
Head Entity: Christian Democratic Union  
Tail Entity: Christianity  

Relation: organization political religious affiliation  
Context: The Islamic Society of North America has been involved in various political discussions, promoting the interests of the Muslim community in the United States.  
Head Entity: Islamic Society of North America  
Tail Entity: Islam  

Relation: organization political religious affiliation  
Context: The National Council of Churches works to unite various Christian denominations in addressing social justice issues and promoting their shared beliefs.  
Head Entity: National Council of Churches  
Tail Entity: Christianity  

Relation: organization political religious affiliation  
Context: The Jewish Federation of North America plays a crucial role in advocating for Jewish interests and community welfare across the continent.  
Head Entity: Jewish Federation of North America  
Tail Entity: Judaism  

Relation: organization political religious affiliation  
Context: The Hindu American Foundation actively engages in political advocacy to represent the interests of the Hindu community in the U.S.  
Head Entity: Hindu American Foundation  
Tail Entity: Hinduism  
#### organization stateorprovince of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization stateorprovince of headquarters" means an organization is located in a state or province.
Here is an example:
Relation: organization stateorprovince of headquarters
Context: washington , nov 30 -lrb- xinhua -rrb- -- nasa has skipped space shuttle endeavour 's second landing opportunity at kennedy space center in florida on sunday afternoon due to bad weather , according to nasa tv .
Head Entity: kennedy space center
Tail Entity: florida
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization stateorprovince of headquarters":
Relation: organization stateorprovince of headquarters  
Context: the headquarters of the multinational technology company is located in cupertino, california, where it has been a significant player in the tech industry for decades.  
Head Entity: multinational technology company  
Tail Entity: california  

Relation: organization stateorprovince of headquarters  
Context: after years of expansion, the non-profit organization has established its main office in a historic building in downtown boston, massachusetts.  
Head Entity: non-profit organization  
Tail Entity: massachusetts  

Relation: organization stateorprovince of headquarters  
Context: the famous coffee chain has its corporate headquarters situated in seattle, washington, which is known for its vibrant coffee culture.  
Head Entity: coffee chain  
Tail Entity: washington  

Relation: organization stateorprovince of headquarters  
Context: the global automotive manufacturer announced that its new headquarters will be built in detroit, michigan, revitalizing the area with job opportunities.  
Head Entity: global automotive manufacturer  
Tail Entity: michigan  

Relation: organization stateorprovince of headquarters  
Context: the international humanitarian organization operates its main office in geneva, switzerland, coordinating efforts across various countries.  
Head Entity: international humanitarian organization  
Tail Entity: switzerland  
#### person other family ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person other family" means a person 's relative is a person.
Here is an example:
Relation: person other family
Context: parren mitchell 's sister-in-law , juanita jackson mitchell , was the long - time head and legal counsel of the maryland naacp .
Head Entity: parren mitchell
Tail Entity: juanita jackson mitchell
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person other family":
Relation: person other family  
Context: The famous actor, Tom Hanks, has a brother named Jim Hanks who is also involved in the film industry.  
Head Entity: Tom Hanks  
Tail Entity: Jim Hanks  

Relation: person other family  
Context: In her memoir, Michelle Obama writes about her close relationship with her brother, Craig Robinson, who has always been her confidant.  
Head Entity: Michelle Obama  
Tail Entity: Craig Robinson  

Relation: person other family  
Context: During the family reunion, Sarah introduced her cousin, Emily, who had just returned from studying abroad.  
Head Entity: Sarah  
Tail Entity: Emily  

Relation: person other family  
Context: The renowned scientist, Albert Einstein, had a sister named Maria, who played a significant role in his early life.  
Head Entity: Albert Einstein  
Tail Entity: Maria Einstein  

Relation: person other family  
Context: At the wedding, John was thrilled to see his uncle, who had traveled from overseas to celebrate the special day.  
Head Entity: John  
Tail Entity: Uncle
#### person city of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person city of death" means a person was died in a city.
Here is an example:
Relation: person city of death
Context: millender-mcdonald , who was 68 , died late saturday at her home in carson , california , said her chief of staff , bandele mcqueen .
Head Entity: millender-mcdonald
Tail Entity: carson
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person city of death":
Relation: person city of death  
Context: renowned author and activist, james baldwin, passed away in 1987 in the city of paris, france, where he had spent much of his later life.  
Head Entity: james baldwin  
Tail Entity: paris  

Relation: person city of death  
Context: the famous physicist, albert einstein, died in 1955 in the city of princeton, new jersey, where he had been living for many years.  
Head Entity: albert einstein  
Tail Entity: princeton  

Relation: person city of death  
Context: beloved singer and songwriter, amy winehouse, tragically died in 2011 at her home in london, england, leaving behind a legacy of music.  
Head Entity: amy winehouse  
Tail Entity: london  

Relation: person city of death  
Context: the legendary actor, marlon brando, passed away in 2004 in the city of los angeles, california, surrounded by family and friends.  
Head Entity: marlon brando  
Tail Entity: los angeles  

Relation: person city of death  
Context: the influential civil rights leader, martin luther king jr., was assassinated in 1968 in the city of memphis, tennessee, while advocating for social justice.  
Head Entity: martin luther king jr.  
Tail Entity: memphis  
Mixup data size:  10810
MixupTrain:  epoch  0, batch     0 | loss: 4.4401808MixupTrain:  epoch  0, batch     1 | loss: 4.9906001MixupTrain:  epoch  0, batch     2 | loss: 3.7703729MixupTrain:  epoch  0, batch     3 | loss: 3.6326737MixupTrain:  epoch  0, batch     4 | loss: 3.6676395MixupTrain:  epoch  0, batch     5 | loss: 4.7798071MixupTrain:  epoch  0, batch     6 | loss: 3.7097178MixupTrain:  epoch  0, batch     7 | loss: 3.6369932MixupTrain:  epoch  0, batch     8 | loss: 3.8932397MixupTrain:  epoch  0, batch     9 | loss: 3.2679410MixupTrain:  epoch  0, batch    10 | loss: 3.7915812MixupTrain:  epoch  0, batch    11 | loss: 3.6129329MixupTrain:  epoch  0, batch    12 | loss: 3.5562453MixupTrain:  epoch  0, batch    13 | loss: 3.1975751MixupTrain:  epoch  0, batch    14 | loss: 3.8424306MixupTrain:  epoch  0, batch    15 | loss: 3.6296349MixupTrain:  epoch  0, batch    16 | loss: 3.1736791MixupTrain:  epoch  0, batch    17 | loss: 3.2812982MixupTrain:  epoch  0, batch    18 | loss: 3.3387969MixupTrain:  epoch  0, batch    19 | loss: 3.2257657MixupTrain:  epoch  0, batch    20 | loss: 3.0184076MixupTrain:  epoch  0, batch    21 | loss: 2.8982337MixupTrain:  epoch  0, batch    22 | loss: 2.5990267MixupTrain:  epoch  0, batch    23 | loss: 3.4596746MixupTrain:  epoch  0, batch    24 | loss: 2.7824214MixupTrain:  epoch  0, batch    25 | loss: 2.8212953MixupTrain:  epoch  0, batch    26 | loss: 2.9858570MixupTrain:  epoch  0, batch    27 | loss: 3.2888961MixupTrain:  epoch  0, batch    28 | loss: 3.2424943MixupTrain:  epoch  0, batch    29 | loss: 2.7161303MixupTrain:  epoch  0, batch    30 | loss: 2.9350147MixupTrain:  epoch  0, batch    31 | loss: 2.9453053MixupTrain:  epoch  0, batch    32 | loss: 3.0286858MixupTrain:  epoch  0, batch    33 | loss: 3.4846759MixupTrain:  epoch  0, batch    34 | loss: 2.4102521MixupTrain:  epoch  0, batch    35 | loss: 2.9732349MixupTrain:  epoch  0, batch    36 | loss: 2.6325831MixupTrain:  epoch  0, batch    37 | loss: 2.8096063MixupTrain:  epoch  0, batch    38 | loss: 3.1254487MixupTrain:  epoch  0, batch    39 | loss: 3.3284025MixupTrain:  epoch  0, batch    40 | loss: 2.8358359MixupTrain:  epoch  0, batch    41 | loss: 2.6582229MixupTrain:  epoch  0, batch    42 | loss: 3.1314204MixupTrain:  epoch  0, batch    43 | loss: 2.6326976MixupTrain:  epoch  0, batch    44 | loss: 2.5321622MixupTrain:  epoch  0, batch    45 | loss: 2.9681425MixupTrain:  epoch  0, batch    46 | loss: 2.8071451MixupTrain:  epoch  0, batch    47 | loss: 3.0891712MixupTrain:  epoch  0, batch    48 | loss: 2.6958261MixupTrain:  epoch  0, batch    49 | loss: 2.5714531MixupTrain:  epoch  0, batch    50 | loss: 2.6621649MixupTrain:  epoch  0, batch    51 | loss: 2.9919157MixupTrain:  epoch  0, batch    52 | loss: 2.5147703MixupTrain:  epoch  0, batch    53 | loss: 2.4457188MixupTrain:  epoch  0, batch    54 | loss: 2.6747746MixupTrain:  epoch  0, batch    55 | loss: 2.4124722MixupTrain:  epoch  0, batch    56 | loss: 2.7116671MixupTrain:  epoch  0, batch    57 | loss: 2.9631538MixupTrain:  epoch  0, batch    58 | loss: 2.8264403MixupTrain:  epoch  0, batch    59 | loss: 2.8689523MixupTrain:  epoch  0, batch    60 | loss: 3.0913563MixupTrain:  epoch  0, batch    61 | loss: 2.8150053MixupTrain:  epoch  0, batch    62 | loss: 2.5022092MixupTrain:  epoch  0, batch    63 | loss: 2.8355131MixupTrain:  epoch  0, batch    64 | loss: 2.8368754MixupTrain:  epoch  0, batch    65 | loss: 2.7441299MixupTrain:  epoch  0, batch    66 | loss: 2.3121426MixupTrain:  epoch  0, batch    67 | loss: 2.6187656MixupTrain:  epoch  0, batch    68 | loss: 2.4749479MixupTrain:  epoch  0, batch    69 | loss: 2.6376290MixupTrain:  epoch  0, batch    70 | loss: 2.6218150MixupTrain:  epoch  0, batch    71 | loss: 2.6533208MixupTrain:  epoch  0, batch    72 | loss: 2.3788249MixupTrain:  epoch  0, batch    73 | loss: 2.6196232MixupTrain:  epoch  0, batch    74 | loss: 2.4296694MixupTrain:  epoch  0, batch    75 | loss: 2.5514295MixupTrain:  epoch  0, batch    76 | loss: 2.7194023MixupTrain:  epoch  0, batch    77 | loss: 2.6299608MixupTrain:  epoch  0, batch    78 | loss: 2.0079632MixupTrain:  epoch  0, batch    79 | loss: 2.2850378MixupTrain:  epoch  0, batch    80 | loss: 2.8536050MixupTrain:  epoch  0, batch    81 | loss: 2.5011544MixupTrain:  epoch  0, batch    82 | loss: 2.1920724MixupTrain:  epoch  0, batch    83 | loss: 2.1700454MixupTrain:  epoch  0, batch    84 | loss: 2.4531879MixupTrain:  epoch  0, batch    85 | loss: 2.6562762MixupTrain:  epoch  0, batch    86 | loss: 2.5566478MixupTrain:  epoch  0, batch    87 | loss: 2.5984774MixupTrain:  epoch  0, batch    88 | loss: 2.3810072MixupTrain:  epoch  0, batch    89 | loss: 2.4418707MixupTrain:  epoch  0, batch    90 | loss: 2.4376104MixupTrain:  epoch  0, batch    91 | loss: 2.3732431MixupTrain:  epoch  0, batch    92 | loss: 2.5951581MixupTrain:  epoch  0, batch    93 | loss: 2.2635908MixupTrain:  epoch  0, batch    94 | loss: 2.2959471MixupTrain:  epoch  0, batch    95 | loss: 2.4357562MixupTrain:  epoch  0, batch    96 | loss: 2.7276149MixupTrain:  epoch  0, batch    97 | loss: 2.3715725MixupTrain:  epoch  0, batch    98 | loss: 2.2585621MixupTrain:  epoch  0, batch    99 | loss: 2.4481688MixupTrain:  epoch  0, batch   100 | loss: 2.4881749MixupTrain:  epoch  0, batch   101 | loss: 2.2742758MixupTrain:  epoch  0, batch   102 | loss: 2.4124665MixupTrain:  epoch  0, batch   103 | loss: 2.4605141MixupTrain:  epoch  0, batch   104 | loss: 2.4189601MixupTrain:  epoch  0, batch   105 | loss: 2.1424677MixupTrain:  epoch  0, batch   106 | loss: 2.5818026MixupTrain:  epoch  0, batch   107 | loss: 2.2943423MixupTrain:  epoch  0, batch   108 | loss: 2.1590261MixupTrain:  epoch  0, batch   109 | loss: 2.5453062MixupTrain:  epoch  0, batch   110 | loss: 2.3689327MixupTrain:  epoch  0, batch   111 | loss: 2.5501881MixupTrain:  epoch  0, batch   112 | loss: 2.4517937MixupTrain:  epoch  0, batch   113 | loss: 2.2384279MixupTrain:  epoch  0, batch   114 | loss: 2.3508787MixupTrain:  epoch  0, batch   115 | loss: 2.1934505MixupTrain:  epoch  0, batch   116 | loss: 2.1641347MixupTrain:  epoch  0, batch   117 | loss: 2.2691417MixupTrain:  epoch  0, batch   118 | loss: 2.3824854MixupTrain:  epoch  0, batch   119 | loss: 2.2529798MixupTrain:  epoch  0, batch   120 | loss: 2.2377300MixupTrain:  epoch  0, batch   121 | loss: 2.3170142MixupTrain:  epoch  0, batch   122 | loss: 2.1394758MixupTrain:  epoch  0, batch   123 | loss: 2.3014839MixupTrain:  epoch  0, batch   124 | loss: 2.4041049MixupTrain:  epoch  0, batch   125 | loss: 2.3278260MixupTrain:  epoch  0, batch   126 | loss: 2.2503104MixupTrain:  epoch  0, batch   127 | loss: 2.0762899MixupTrain:  epoch  0, batch   128 | loss: 2.2328615MixupTrain:  epoch  0, batch   129 | loss: 2.1553011MixupTrain:  epoch  0, batch   130 | loss: 2.2735832MixupTrain:  epoch  0, batch   131 | loss: 2.0894945MixupTrain:  epoch  0, batch   132 | loss: 2.3759646MixupTrain:  epoch  0, batch   133 | loss: 2.2367547MixupTrain:  epoch  0, batch   134 | loss: 2.1580591MixupTrain:  epoch  0, batch   135 | loss: 2.2181034MixupTrain:  epoch  0, batch   136 | loss: 2.3877432MixupTrain:  epoch  0, batch   137 | loss: 2.3202124MixupTrain:  epoch  0, batch   138 | loss: 2.2927012MixupTrain:  epoch  0, batch   139 | loss: 2.2503786MixupTrain:  epoch  0, batch   140 | loss: 2.2938666MixupTrain:  epoch  0, batch   141 | loss: 2.1146202MixupTrain:  epoch  0, batch   142 | loss: 2.2863300MixupTrain:  epoch  0, batch   143 | loss: 2.4057386MixupTrain:  epoch  0, batch   144 | loss: 2.1664042MixupTrain:  epoch  0, batch   145 | loss: 2.1606693MixupTrain:  epoch  0, batch   146 | loss: 2.1389804MixupTrain:  epoch  0, batch   147 | loss: 2.1735716MixupTrain:  epoch  0, batch   148 | loss: 2.3499734MixupTrain:  epoch  0, batch   149 | loss: 2.1736817MixupTrain:  epoch  0, batch   150 | loss: 2.1630332MixupTrain:  epoch  0, batch   151 | loss: 2.0404088MixupTrain:  epoch  0, batch   152 | loss: 2.5389655MixupTrain:  epoch  0, batch   153 | loss: 2.2578003MixupTrain:  epoch  0, batch   154 | loss: 2.3313022MixupTrain:  epoch  0, batch   155 | loss: 2.2212422MixupTrain:  epoch  0, batch   156 | loss: 2.2118342MixupTrain:  epoch  0, batch   157 | loss: 2.2839308MixupTrain:  epoch  0, batch   158 | loss: 2.2247372MixupTrain:  epoch  0, batch   159 | loss: 2.1275678MixupTrain:  epoch  0, batch   160 | loss: 2.6545589MixupTrain:  epoch  0, batch   161 | loss: 2.3739796MixupTrain:  epoch  0, batch   162 | loss: 2.3251336MixupTrain:  epoch  0, batch   163 | loss: 2.2322810MixupTrain:  epoch  0, batch   164 | loss: 2.4108393MixupTrain:  epoch  0, batch   165 | loss: 2.2397733MixupTrain:  epoch  0, batch   166 | loss: 2.4849513MixupTrain:  epoch  0, batch   167 | loss: 2.3192606MixupTrain:  epoch  0, batch   168 | loss: 2.2847443MixupTrain:  epoch  0, batch   169 | loss: 2.0306258MixupTrain:  epoch  0, batch   170 | loss: 2.1660962MixupTrain:  epoch  0, batch   171 | loss: 2.2625854MixupTrain:  epoch  0, batch   172 | loss: 2.2551794MixupTrain:  epoch  0, batch   173 | loss: 2.2446573MixupTrain:  epoch  0, batch   174 | loss: 2.1177225MixupTrain:  epoch  0, batch   175 | loss: 2.1301298MixupTrain:  epoch  0, batch   176 | loss: 2.2500691MixupTrain:  epoch  0, batch   177 | loss: 2.2568474MixupTrain:  epoch  0, batch   178 | loss: 2.3042819MixupTrain:  epoch  0, batch   179 | loss: 2.1458859MixupTrain:  epoch  0, batch   180 | loss: 2.3191299MixupTrain:  epoch  0, batch   181 | loss: 2.1467085MixupTrain:  epoch  0, batch   182 | loss: 2.3190498MixupTrain:  epoch  0, batch   183 | loss: 2.4066596MixupTrain:  epoch  0, batch   184 | loss: 2.1919270MixupTrain:  epoch  0, batch   185 | loss: 2.3292274MixupTrain:  epoch  0, batch   186 | loss: 2.1661747MixupTrain:  epoch  0, batch   187 | loss: 2.3378873MixupTrain:  epoch  0, batch   188 | loss: 2.4577432MixupTrain:  epoch  0, batch   189 | loss: 2.2709060MixupTrain:  epoch  0, batch   190 | loss: 2.2195237MixupTrain:  epoch  0, batch   191 | loss: 2.1318896MixupTrain:  epoch  0, batch   192 | loss: 2.1121969MixupTrain:  epoch  0, batch   193 | loss: 2.1881194MixupTrain:  epoch  0, batch   194 | loss: 2.0487022MixupTrain:  epoch  0, batch   195 | loss: 2.1956482MixupTrain:  epoch  0, batch   196 | loss: 2.0949969MixupTrain:  epoch  0, batch   197 | loss: 2.3335061MixupTrain:  epoch  0, batch   198 | loss: 2.0653162MixupTrain:  epoch  0, batch   199 | loss: 2.2646332MixupTrain:  epoch  0, batch   200 | loss: 2.3363261MixupTrain:  epoch  0, batch   201 | loss: 2.2213204MixupTrain:  epoch  0, batch   202 | loss: 2.2118201MixupTrain:  epoch  0, batch   203 | loss: 2.4007096MixupTrain:  epoch  0, batch   204 | loss: 2.3835936MixupTrain:  epoch  0, batch   205 | loss: 2.1375823MixupTrain:  epoch  0, batch   206 | loss: 2.3986671MixupTrain:  epoch  0, batch   207 | loss: 2.1444149MixupTrain:  epoch  0, batch   208 | loss: 2.1033082MixupTrain:  epoch  0, batch   209 | loss: 2.3899508MixupTrain:  epoch  0, batch   210 | loss: 2.1793437MixupTrain:  epoch  0, batch   211 | loss: 2.1476932MixupTrain:  epoch  0, batch   212 | loss: 2.1743264MixupTrain:  epoch  0, batch   213 | loss: 2.1139762MixupTrain:  epoch  0, batch   214 | loss: 2.1563511MixupTrain:  epoch  0, batch   215 | loss: 2.2257359MixupTrain:  epoch  0, batch   216 | loss: 2.2459447MixupTrain:  epoch  0, batch   217 | loss: 2.2157595MixupTrain:  epoch  0, batch   218 | loss: 2.2845426MixupTrain:  epoch  0, batch   219 | loss: 2.1586175MixupTrain:  epoch  0, batch   220 | loss: 1.9910662MixupTrain:  epoch  0, batch   221 | loss: 2.3162920MixupTrain:  epoch  0, batch   222 | loss: 2.3456657MixupTrain:  epoch  0, batch   223 | loss: 2.3035078MixupTrain:  epoch  0, batch   224 | loss: 2.3024304MixupTrain:  epoch  0, batch   225 | loss: 2.2157989MixupTrain:  epoch  0, batch   226 | loss: 2.1246848MixupTrain:  epoch  0, batch   227 | loss: 2.0908127MixupTrain:  epoch  0, batch   228 | loss: 2.1978288MixupTrain:  epoch  0, batch   229 | loss: 2.2433600MixupTrain:  epoch  0, batch   230 | loss: 2.4370215MixupTrain:  epoch  0, batch   231 | loss: 2.3912969MixupTrain:  epoch  0, batch   232 | loss: 2.1548274MixupTrain:  epoch  0, batch   233 | loss: 2.1536033MixupTrain:  epoch  0, batch   234 | loss: 2.2081480MixupTrain:  epoch  0, batch   235 | loss: 2.2089834MixupTrain:  epoch  0, batch   236 | loss: 2.3246326MixupTrain:  epoch  0, batch   237 | loss: 2.3104239MixupTrain:  epoch  0, batch   238 | loss: 2.2458754MixupTrain:  epoch  0, batch   239 | loss: 2.1383200MixupTrain:  epoch  0, batch   240 | loss: 2.1405325MixupTrain:  epoch  0, batch   241 | loss: 2.1555164MixupTrain:  epoch  0, batch   242 | loss: 2.2651339MixupTrain:  epoch  0, batch   243 | loss: 2.2244709MixupTrain:  epoch  0, batch   244 | loss: 2.3089561MixupTrain:  epoch  0, batch   245 | loss: 2.1730552MixupTrain:  epoch  0, batch   246 | loss: 2.3359971MixupTrain:  epoch  0, batch   247 | loss: 2.1988623MixupTrain:  epoch  0, batch   248 | loss: 2.3407602MixupTrain:  epoch  0, batch   249 | loss: 2.2030187MixupTrain:  epoch  0, batch   250 | loss: 2.0379500MixupTrain:  epoch  0, batch   251 | loss: 2.1538420MixupTrain:  epoch  0, batch   252 | loss: 2.3130445MixupTrain:  epoch  0, batch   253 | loss: 2.1347513MixupTrain:  epoch  0, batch   254 | loss: 2.3310251MixupTrain:  epoch  0, batch   255 | loss: 2.0452132MixupTrain:  epoch  0, batch   256 | loss: 1.9226696MixupTrain:  epoch  0, batch   257 | loss: 2.3350377MixupTrain:  epoch  0, batch   258 | loss: 2.1236231MixupTrain:  epoch  0, batch   259 | loss: 2.0319247MixupTrain:  epoch  0, batch   260 | loss: 2.1810212MixupTrain:  epoch  0, batch   261 | loss: 2.1910207MixupTrain:  epoch  0, batch   262 | loss: 2.1999459MixupTrain:  epoch  0, batch   263 | loss: 2.2118752MixupTrain:  epoch  0, batch   264 | loss: 2.1755514MixupTrain:  epoch  0, batch   265 | loss: 2.1576235MixupTrain:  epoch  0, batch   266 | loss: 2.2128050MixupTrain:  epoch  0, batch   267 | loss: 2.1922612MixupTrain:  epoch  0, batch   268 | loss: 2.1529660MixupTrain:  epoch  0, batch   269 | loss: 2.0844870MixupTrain:  epoch  0, batch   270 | loss: 2.0302672MixupTrain:  epoch  0, batch   271 | loss: 2.2041473MixupTrain:  epoch  0, batch   272 | loss: 2.2669430MixupTrain:  epoch  0, batch   273 | loss: 2.1283858MixupTrain:  epoch  0, batch   274 | loss: 2.0242763MixupTrain:  epoch  0, batch   275 | loss: 2.0439270MixupTrain:  epoch  0, batch   276 | loss: 2.4436526MixupTrain:  epoch  0, batch   277 | loss: 1.9943484MixupTrain:  epoch  0, batch   278 | loss: 2.2097893MixupTrain:  epoch  0, batch   279 | loss: 2.1294389MixupTrain:  epoch  0, batch   280 | loss: 2.2196896MixupTrain:  epoch  0, batch   281 | loss: 2.1091461MixupTrain:  epoch  0, batch   282 | loss: 2.2404106MixupTrain:  epoch  0, batch   283 | loss: 2.0655806MixupTrain:  epoch  0, batch   284 | loss: 2.2211876MixupTrain:  epoch  0, batch   285 | loss: 2.0750942MixupTrain:  epoch  0, batch   286 | loss: 2.1749907MixupTrain:  epoch  0, batch   287 | loss: 2.2713811MixupTrain:  epoch  0, batch   288 | loss: 2.2427769MixupTrain:  epoch  0, batch   289 | loss: 2.1829505MixupTrain:  epoch  0, batch   290 | loss: 2.1209154MixupTrain:  epoch  0, batch   291 | loss: 2.1037245MixupTrain:  epoch  0, batch   292 | loss: 2.1095352MixupTrain:  epoch  0, batch   293 | loss: 2.2193284MixupTrain:  epoch  0, batch   294 | loss: 2.1009746MixupTrain:  epoch  0, batch   295 | loss: 2.1908255MixupTrain:  epoch  0, batch   296 | loss: 2.1592205MixupTrain:  epoch  0, batch   297 | loss: 2.1663814MixupTrain:  epoch  0, batch   298 | loss: 2.2300763MixupTrain:  epoch  0, batch   299 | loss: 2.3553865MixupTrain:  epoch  0, batch   300 | loss: 2.1175256MixupTrain:  epoch  0, batch   301 | loss: 2.1816392MixupTrain:  epoch  0, batch   302 | loss: 2.1519284MixupTrain:  epoch  0, batch   303 | loss: 2.3243699MixupTrain:  epoch  0, batch   304 | loss: 2.1299729MixupTrain:  epoch  0, batch   305 | loss: 2.3093669MixupTrain:  epoch  0, batch   306 | loss: 1.9225714MixupTrain:  epoch  0, batch   307 | loss: 2.3165517MixupTrain:  epoch  0, batch   308 | loss: 2.0703106MixupTrain:  epoch  0, batch   309 | loss: 2.1287127MixupTrain:  epoch  0, batch   310 | loss: 2.2342458MixupTrain:  epoch  0, batch   311 | loss: 2.1758556MixupTrain:  epoch  0, batch   312 | loss: 2.1904986MixupTrain:  epoch  0, batch   313 | loss: 2.3552084MixupTrain:  epoch  0, batch   314 | loss: 2.0856853MixupTrain:  epoch  0, batch   315 | loss: 2.2666492MixupTrain:  epoch  0, batch   316 | loss: 2.2607002MixupTrain:  epoch  0, batch   317 | loss: 2.3015037MixupTrain:  epoch  0, batch   318 | loss: 2.1612744MixupTrain:  epoch  0, batch   319 | loss: 2.3153362MixupTrain:  epoch  0, batch   320 | loss: 2.1138999MixupTrain:  epoch  0, batch   321 | loss: 2.1231904MixupTrain:  epoch  0, batch   322 | loss: 2.2571893MixupTrain:  epoch  0, batch   323 | loss: 2.0351064MixupTrain:  epoch  0, batch   324 | loss: 2.3526525MixupTrain:  epoch  0, batch   325 | loss: 2.2400475MixupTrain:  epoch  0, batch   326 | loss: 2.1019390MixupTrain:  epoch  0, batch   327 | loss: 2.2007060MixupTrain:  epoch  0, batch   328 | loss: 2.0660408MixupTrain:  epoch  0, batch   329 | loss: 1.9998870MixupTrain:  epoch  0, batch   330 | loss: 2.1399140MixupTrain:  epoch  0, batch   331 | loss: 2.0800090MixupTrain:  epoch  0, batch   332 | loss: 2.0457344MixupTrain:  epoch  0, batch   333 | loss: 2.1927738MixupTrain:  epoch  0, batch   334 | loss: 2.2915113MixupTrain:  epoch  0, batch   335 | loss: 2.1895952MixupTrain:  epoch  0, batch   336 | loss: 2.2136497MixupTrain:  epoch  0, batch   337 | loss: 2.1225572MixupTrain:  epoch  0, batch   338 | loss: 2.1046114MixupTrain:  epoch  0, batch   339 | loss: 2.2310538MixupTrain:  epoch  0, batch   340 | loss: 2.0213194MixupTrain:  epoch  0, batch   341 | loss: 2.2010379MixupTrain:  epoch  0, batch   342 | loss: 2.2556705MixupTrain:  epoch  0, batch   343 | loss: 2.0356457MixupTrain:  epoch  0, batch   344 | loss: 1.9940128MixupTrain:  epoch  0, batch   345 | loss: 2.2731385MixupTrain:  epoch  0, batch   346 | loss: 2.1995151MixupTrain:  epoch  0, batch   347 | loss: 2.0552683MixupTrain:  epoch  0, batch   348 | loss: 2.2305684MixupTrain:  epoch  0, batch   349 | loss: 2.1822252MixupTrain:  epoch  0, batch   350 | loss: 2.1368685MixupTrain:  epoch  0, batch   351 | loss: 2.1276424MixupTrain:  epoch  0, batch   352 | loss: 2.3375373MixupTrain:  epoch  0, batch   353 | loss: 1.9943335MixupTrain:  epoch  0, batch   354 | loss: 2.0487154MixupTrain:  epoch  0, batch   355 | loss: 1.9874365MixupTrain:  epoch  0, batch   356 | loss: 2.2355781MixupTrain:  epoch  0, batch   357 | loss: 2.3356626MixupTrain:  epoch  0, batch   358 | loss: 2.2286515MixupTrain:  epoch  0, batch   359 | loss: 2.0482893MixupTrain:  epoch  0, batch   360 | loss: 2.0854113MixupTrain:  epoch  0, batch   361 | loss: 2.1838470MixupTrain:  epoch  0, batch   362 | loss: 2.0593038MixupTrain:  epoch  0, batch   363 | loss: 2.2503009MixupTrain:  epoch  0, batch   364 | loss: 2.0278461MixupTrain:  epoch  0, batch   365 | loss: 2.2146721MixupTrain:  epoch  0, batch   366 | loss: 2.1389756MixupTrain:  epoch  0, batch   367 | loss: 2.1539445MixupTrain:  epoch  0, batch   368 | loss: 2.1799209MixupTrain:  epoch  0, batch   369 | loss: 2.1520858MixupTrain:  epoch  0, batch   370 | loss: 2.0533857MixupTrain:  epoch  0, batch   371 | loss: 2.1279676MixupTrain:  epoch  0, batch   372 | loss: 2.3733375MixupTrain:  epoch  0, batch   373 | loss: 2.1704991MixupTrain:  epoch  0, batch   374 | loss: 2.1465297MixupTrain:  epoch  0, batch   375 | loss: 2.0776749MixupTrain:  epoch  0, batch   376 | loss: 1.9159714MixupTrain:  epoch  0, batch   377 | loss: 2.2126951MixupTrain:  epoch  0, batch   378 | loss: 2.1449969MixupTrain:  epoch  0, batch   379 | loss: 2.1641445MixupTrain:  epoch  0, batch   380 | loss: 2.1814151MixupTrain:  epoch  0, batch   381 | loss: 2.1538582MixupTrain:  epoch  0, batch   382 | loss: 2.0118389MixupTrain:  epoch  0, batch   383 | loss: 2.2886477MixupTrain:  epoch  0, batch   384 | loss: 2.2030144MixupTrain:  epoch  0, batch   385 | loss: 2.1173477MixupTrain:  epoch  0, batch   386 | loss: 2.0284410MixupTrain:  epoch  0, batch   387 | loss: 2.1320395MixupTrain:  epoch  0, batch   388 | loss: 2.1286664MixupTrain:  epoch  0, batch   389 | loss: 2.0924368MixupTrain:  epoch  0, batch   390 | loss: 2.0587680MixupTrain:  epoch  0, batch   391 | loss: 2.2181396MixupTrain:  epoch  0, batch   392 | loss: 1.9981244MixupTrain:  epoch  0, batch   393 | loss: 2.2744958MixupTrain:  epoch  0, batch   394 | loss: 2.0754840MixupTrain:  epoch  0, batch   395 | loss: 2.0331571MixupTrain:  epoch  0, batch   396 | loss: 2.0476325MixupTrain:  epoch  0, batch   397 | loss: 2.1685650MixupTrain:  epoch  0, batch   398 | loss: 1.9911777MixupTrain:  epoch  0, batch   399 | loss: 2.1814985MixupTrain:  epoch  0, batch   400 | loss: 2.2429378MixupTrain:  epoch  0, batch   401 | loss: 2.0011921MixupTrain:  epoch  0, batch   402 | loss: 2.1320367MixupTrain:  epoch  0, batch   403 | loss: 2.1854098MixupTrain:  epoch  0, batch   404 | loss: 2.2084508MixupTrain:  epoch  0, batch   405 | loss: 2.1773338MixupTrain:  epoch  0, batch   406 | loss: 2.0312467MixupTrain:  epoch  0, batch   407 | loss: 1.9901718MixupTrain:  epoch  0, batch   408 | loss: 2.0995262MixupTrain:  epoch  0, batch   409 | loss: 2.1486359MixupTrain:  epoch  0, batch   410 | loss: 2.1105690MixupTrain:  epoch  0, batch   411 | loss: 2.0846801MixupTrain:  epoch  0, batch   412 | loss: 2.1397882MixupTrain:  epoch  0, batch   413 | loss: 2.3820868MixupTrain:  epoch  0, batch   414 | loss: 2.0691984MixupTrain:  epoch  0, batch   415 | loss: 2.2021008MixupTrain:  epoch  0, batch   416 | loss: 2.2005138MixupTrain:  epoch  0, batch   417 | loss: 2.2481456MixupTrain:  epoch  0, batch   418 | loss: 2.1767621MixupTrain:  epoch  0, batch   419 | loss: 2.1201785MixupTrain:  epoch  0, batch   420 | loss: 2.0254927MixupTrain:  epoch  0, batch   421 | loss: 2.1776981MixupTrain:  epoch  0, batch   422 | loss: 2.0280724MixupTrain:  epoch  0, batch   423 | loss: 1.9735140MixupTrain:  epoch  0, batch   424 | loss: 2.2116666MixupTrain:  epoch  0, batch   425 | loss: 2.1447210MixupTrain:  epoch  0, batch   426 | loss: 2.0697374MixupTrain:  epoch  0, batch   427 | loss: 2.1747499MixupTrain:  epoch  0, batch   428 | loss: 1.9791923MixupTrain:  epoch  0, batch   429 | loss: 2.2790568MixupTrain:  epoch  0, batch   430 | loss: 2.1869519MixupTrain:  epoch  0, batch   431 | loss: 2.2638636MixupTrain:  epoch  0, batch   432 | loss: 2.2815564MixupTrain:  epoch  0, batch   433 | loss: 2.0418639MixupTrain:  epoch  0, batch   434 | loss: 2.0098310MixupTrain:  epoch  0, batch   435 | loss: 2.1305768MixupTrain:  epoch  0, batch   436 | loss: 2.1536818MixupTrain:  epoch  0, batch   437 | loss: 2.2758865MixupTrain:  epoch  0, batch   438 | loss: 2.0239248MixupTrain:  epoch  0, batch   439 | loss: 2.1685519MixupTrain:  epoch  0, batch   440 | loss: 2.1277061MixupTrain:  epoch  0, batch   441 | loss: 2.3085976MixupTrain:  epoch  0, batch   442 | loss: 1.9743032MixupTrain:  epoch  0, batch   443 | loss: 2.2039318MixupTrain:  epoch  0, batch   444 | loss: 2.2075796MixupTrain:  epoch  0, batch   445 | loss: 2.0930123MixupTrain:  epoch  0, batch   446 | loss: 2.0593297MixupTrain:  epoch  0, batch   447 | loss: 2.0385008MixupTrain:  epoch  0, batch   448 | loss: 2.1673892MixupTrain:  epoch  0, batch   449 | loss: 2.1701188MixupTrain:  epoch  0, batch   450 | loss: 1.9479522MixupTrain:  epoch  0, batch   451 | loss: 2.3420947MixupTrain:  epoch  0, batch   452 | loss: 2.0642405MixupTrain:  epoch  0, batch   453 | loss: 2.0471473MixupTrain:  epoch  0, batch   454 | loss: 2.1865997MixupTrain:  epoch  0, batch   455 | loss: 2.2982183MixupTrain:  epoch  0, batch   456 | loss: 2.0428519MixupTrain:  epoch  0, batch   457 | loss: 2.3345928MixupTrain:  epoch  0, batch   458 | loss: 2.1191843MixupTrain:  epoch  0, batch   459 | loss: 2.2743435MixupTrain:  epoch  0, batch   460 | loss: 2.1631999MixupTrain:  epoch  0, batch   461 | loss: 2.0706086MixupTrain:  epoch  0, batch   462 | loss: 2.0300927MixupTrain:  epoch  0, batch   463 | loss: 2.0202274MixupTrain:  epoch  0, batch   464 | loss: 2.0428095MixupTrain:  epoch  0, batch   465 | loss: 2.0664761MixupTrain:  epoch  0, batch   466 | loss: 2.1026406MixupTrain:  epoch  0, batch   467 | loss: 2.0523601MixupTrain:  epoch  0, batch   468 | loss: 2.0976715MixupTrain:  epoch  0, batch   469 | loss: 2.1768308MixupTrain:  epoch  0, batch   470 | loss: 2.3085341MixupTrain:  epoch  0, batch   471 | loss: 2.1068995MixupTrain:  epoch  0, batch   472 | loss: 2.0560865MixupTrain:  epoch  0, batch   473 | loss: 2.1595418MixupTrain:  epoch  0, batch   474 | loss: 2.0558159MixupTrain:  epoch  0, batch   475 | loss: 2.0905404MixupTrain:  epoch  0, batch   476 | loss: 2.1243782MixupTrain:  epoch  0, batch   477 | loss: 2.1769509MixupTrain:  epoch  0, batch   478 | loss: 2.0703614MixupTrain:  epoch  0, batch   479 | loss: 2.0366163MixupTrain:  epoch  0, batch   480 | loss: 2.1819625MixupTrain:  epoch  0, batch   481 | loss: 2.1353154MixupTrain:  epoch  0, batch   482 | loss: 2.1808689MixupTrain:  epoch  0, batch   483 | loss: 2.2264931MixupTrain:  epoch  0, batch   484 | loss: 2.1789231MixupTrain:  epoch  0, batch   485 | loss: 1.9639815MixupTrain:  epoch  0, batch   486 | loss: 2.3282433MixupTrain:  epoch  0, batch   487 | loss: 2.0507863MixupTrain:  epoch  0, batch   488 | loss: 2.1082568MixupTrain:  epoch  0, batch   489 | loss: 2.1320894MixupTrain:  epoch  0, batch   490 | loss: 2.1883872MixupTrain:  epoch  0, batch   491 | loss: 2.1993895MixupTrain:  epoch  0, batch   492 | loss: 2.1765616MixupTrain:  epoch  0, batch   493 | loss: 2.2738523MixupTrain:  epoch  0, batch   494 | loss: 2.0577950MixupTrain:  epoch  0, batch   495 | loss: 2.0453248MixupTrain:  epoch  0, batch   496 | loss: 2.1615300MixupTrain:  epoch  0, batch   497 | loss: 2.2727509MixupTrain:  epoch  0, batch   498 | loss: 2.1040115MixupTrain:  epoch  0, batch   499 | loss: 2.0043683MixupTrain:  epoch  0, batch   500 | loss: 2.0029583MixupTrain:  epoch  0, batch   501 | loss: 2.1571403MixupTrain:  epoch  0, batch   502 | loss: 2.2073097MixupTrain:  epoch  0, batch   503 | loss: 2.3811536MixupTrain:  epoch  0, batch   504 | loss: 2.0137577MixupTrain:  epoch  0, batch   505 | loss: 2.0439758MixupTrain:  epoch  0, batch   506 | loss: 2.2313571MixupTrain:  epoch  0, batch   507 | loss: 2.0670886MixupTrain:  epoch  0, batch   508 | loss: 2.0931213MixupTrain:  epoch  0, batch   509 | loss: 2.1601546MixupTrain:  epoch  0, batch   510 | loss: 2.2063570MixupTrain:  epoch  0, batch   511 | loss: 2.0903146MixupTrain:  epoch  0, batch   512 | loss: 2.0995431MixupTrain:  epoch  0, batch   513 | loss: 2.0454407MixupTrain:  epoch  0, batch   514 | loss: 2.1283498MixupTrain:  epoch  0, batch   515 | loss: 2.1014946MixupTrain:  epoch  0, batch   516 | loss: 2.0104418MixupTrain:  epoch  0, batch   517 | loss: 2.1407084MixupTrain:  epoch  0, batch   518 | loss: 2.0145731MixupTrain:  epoch  0, batch   519 | loss: 1.9657290MixupTrain:  epoch  0, batch   520 | loss: 2.0418034MixupTrain:  epoch  0, batch   521 | loss: 2.0857267MixupTrain:  epoch  0, batch   522 | loss: 2.0918858MixupTrain:  epoch  0, batch   523 | loss: 2.0374486MixupTrain:  epoch  0, batch   524 | loss: 2.0583253MixupTrain:  epoch  0, batch   525 | loss: 2.0868540MixupTrain:  epoch  0, batch   526 | loss: 1.9854207MixupTrain:  epoch  0, batch   527 | loss: 2.1446424MixupTrain:  epoch  0, batch   528 | loss: 2.1464071MixupTrain:  epoch  0, batch   529 | loss: 2.1099014MixupTrain:  epoch  0, batch   530 | loss: 2.2211051MixupTrain:  epoch  0, batch   531 | loss: 2.0057085MixupTrain:  epoch  0, batch   532 | loss: 2.0290527MixupTrain:  epoch  0, batch   533 | loss: 2.1104243MixupTrain:  epoch  0, batch   534 | loss: 2.1533797MixupTrain:  epoch  0, batch   535 | loss: 2.0610414MixupTrain:  epoch  0, batch   536 | loss: 2.2958715MixupTrain:  epoch  0, batch   537 | loss: 2.0217073MixupTrain:  epoch  0, batch   538 | loss: 2.1265039MixupTrain:  epoch  0, batch   539 | loss: 2.1900668MixupTrain:  epoch  0, batch   540 | loss: 2.2313714MixupTrain:  epoch  0, batch   541 | loss: 2.3106275MixupTrain:  epoch  0, batch   542 | loss: 2.0960691MixupTrain:  epoch  0, batch   543 | loss: 2.0636148MixupTrain:  epoch  0, batch   544 | loss: 2.1028872MixupTrain:  epoch  0, batch   545 | loss: 2.3714333MixupTrain:  epoch  0, batch   546 | loss: 2.0656884MixupTrain:  epoch  0, batch   547 | loss: 2.1445975MixupTrain:  epoch  0, batch   548 | loss: 2.0323048MixupTrain:  epoch  0, batch   549 | loss: 2.0038314MixupTrain:  epoch  0, batch   550 | loss: 2.2880168MixupTrain:  epoch  0, batch   551 | loss: 2.0784087MixupTrain:  epoch  0, batch   552 | loss: 2.1012831MixupTrain:  epoch  0, batch   553 | loss: 2.1805382MixupTrain:  epoch  0, batch   554 | loss: 2.2249925MixupTrain:  epoch  0, batch   555 | loss: 2.0248311MixupTrain:  epoch  0, batch   556 | loss: 2.0884731MixupTrain:  epoch  0, batch   557 | loss: 2.1335795MixupTrain:  epoch  0, batch   558 | loss: 2.2045741MixupTrain:  epoch  0, batch   559 | loss: 2.0846400MixupTrain:  epoch  0, batch   560 | loss: 2.1356814MixupTrain:  epoch  0, batch   561 | loss: 1.9689647MixupTrain:  epoch  0, batch   562 | loss: 2.0419445MixupTrain:  epoch  0, batch   563 | loss: 2.3019571MixupTrain:  epoch  0, batch   564 | loss: 2.2598698MixupTrain:  epoch  0, batch   565 | loss: 1.9825877MixupTrain:  epoch  0, batch   566 | loss: 2.0444949MixupTrain:  epoch  0, batch   567 | loss: 2.2547326MixupTrain:  epoch  0, batch   568 | loss: 1.9987371MixupTrain:  epoch  0, batch   569 | loss: 2.1335218MixupTrain:  epoch  0, batch   570 | loss: 2.0468411MixupTrain:  epoch  0, batch   571 | loss: 2.1356113MixupTrain:  epoch  0, batch   572 | loss: 2.0665429MixupTrain:  epoch  0, batch   573 | loss: 1.8843813MixupTrain:  epoch  0, batch   574 | loss: 2.2469907MixupTrain:  epoch  0, batch   575 | loss: 1.9761548MixupTrain:  epoch  0, batch   576 | loss: 2.1658392MixupTrain:  epoch  0, batch   577 | loss: 2.1214030MixupTrain:  epoch  0, batch   578 | loss: 2.1022863MixupTrain:  epoch  0, batch   579 | loss: 2.1268432MixupTrain:  epoch  0, batch   580 | loss: 2.0661216MixupTrain:  epoch  0, batch   581 | loss: 2.0093775MixupTrain:  epoch  0, batch   582 | loss: 2.0224242MixupTrain:  epoch  0, batch   583 | loss: 2.1798267MixupTrain:  epoch  0, batch   584 | loss: 2.2185562MixupTrain:  epoch  0, batch   585 | loss: 2.1540599MixupTrain:  epoch  0, batch   586 | loss: 2.2658913MixupTrain:  epoch  0, batch   587 | loss: 2.2830491MixupTrain:  epoch  0, batch   588 | loss: 2.1624675MixupTrain:  epoch  0, batch   589 | loss: 2.0213575MixupTrain:  epoch  0, batch   590 | loss: 2.1549459MixupTrain:  epoch  0, batch   591 | loss: 2.0934131MixupTrain:  epoch  0, batch   592 | loss: 2.0941629MixupTrain:  epoch  0, batch   593 | loss: 1.9813619MixupTrain:  epoch  0, batch   594 | loss: 2.1784391MixupTrain:  epoch  0, batch   595 | loss: 2.2500067MixupTrain:  epoch  0, batch   596 | loss: 2.1244321MixupTrain:  epoch  0, batch   597 | loss: 2.0199864MixupTrain:  epoch  0, batch   598 | loss: 2.4308436MixupTrain:  epoch  0, batch   599 | loss: 2.2993491MixupTrain:  epoch  0, batch   600 | loss: 2.2007608MixupTrain:  epoch  0, batch   601 | loss: 2.0102320MixupTrain:  epoch  0, batch   602 | loss: 2.2329330MixupTrain:  epoch  0, batch   603 | loss: 2.0535016MixupTrain:  epoch  0, batch   604 | loss: 2.1268733MixupTrain:  epoch  0, batch   605 | loss: 2.0974019MixupTrain:  epoch  0, batch   606 | loss: 2.0510774MixupTrain:  epoch  0, batch   607 | loss: 2.1539817MixupTrain:  epoch  0, batch   608 | loss: 2.1202354MixupTrain:  epoch  0, batch   609 | loss: 2.1384139MixupTrain:  epoch  0, batch   610 | loss: 2.2150643MixupTrain:  epoch  0, batch   611 | loss: 2.0091975MixupTrain:  epoch  0, batch   612 | loss: 2.0748162MixupTrain:  epoch  0, batch   613 | loss: 1.9785603MixupTrain:  epoch  0, batch   614 | loss: 2.1258273MixupTrain:  epoch  0, batch   615 | loss: 2.0776381MixupTrain:  epoch  0, batch   616 | loss: 2.0090535MixupTrain:  epoch  0, batch   617 | loss: 2.1920688MixupTrain:  epoch  0, batch   618 | loss: 1.9862617MixupTrain:  epoch  0, batch   619 | loss: 2.2060249MixupTrain:  epoch  0, batch   620 | loss: 2.2850201MixupTrain:  epoch  0, batch   621 | loss: 2.1758184MixupTrain:  epoch  0, batch   622 | loss: 2.1118779MixupTrain:  epoch  0, batch   623 | loss: 1.9438422MixupTrain:  epoch  0, batch   624 | loss: 2.0495846MixupTrain:  epoch  0, batch   625 | loss: 2.2857790MixupTrain:  epoch  0, batch   626 | loss: 2.1096020MixupTrain:  epoch  0, batch   627 | loss: 2.0041385MixupTrain:  epoch  0, batch   628 | loss: 2.0133631MixupTrain:  epoch  0, batch   629 | loss: 1.9697582MixupTrain:  epoch  0, batch   630 | loss: 2.2313056MixupTrain:  epoch  0, batch   631 | loss: 2.0625360MixupTrain:  epoch  0, batch   632 | loss: 2.1281633MixupTrain:  epoch  0, batch   633 | loss: 2.1488156MixupTrain:  epoch  0, batch   634 | loss: 2.0312214MixupTrain:  epoch  0, batch   635 | loss: 2.1139507MixupTrain:  epoch  0, batch   636 | loss: 2.2182541MixupTrain:  epoch  0, batch   637 | loss: 1.9769189MixupTrain:  epoch  0, batch   638 | loss: 2.2359319MixupTrain:  epoch  0, batch   639 | loss: 2.1766856MixupTrain:  epoch  0, batch   640 | loss: 2.0915518MixupTrain:  epoch  0, batch   641 | loss: 2.0934882MixupTrain:  epoch  0, batch   642 | loss: 2.1589642MixupTrain:  epoch  0, batch   643 | loss: 2.2006192MixupTrain:  epoch  0, batch   644 | loss: 2.2506149MixupTrain:  epoch  0, batch   645 | loss: 2.2220762MixupTrain:  epoch  0, batch   646 | loss: 2.1494250MixupTrain:  epoch  0, batch   647 | loss: 2.0389569MixupTrain:  epoch  0, batch   648 | loss: 2.0647202MixupTrain:  epoch  0, batch   649 | loss: 2.2813644MixupTrain:  epoch  0, batch   650 | loss: 2.0385292MixupTrain:  epoch  0, batch   651 | loss: 2.3297801MixupTrain:  epoch  0, batch   652 | loss: 2.1506062MixupTrain:  epoch  0, batch   653 | loss: 2.0724847MixupTrain:  epoch  0, batch   654 | loss: 2.0865288MixupTrain:  epoch  0, batch   655 | loss: 2.1687126MixupTrain:  epoch  0, batch   656 | loss: 2.0098329MixupTrain:  epoch  0, batch   657 | loss: 2.2277284MixupTrain:  epoch  0, batch   658 | loss: 2.0650845MixupTrain:  epoch  0, batch   659 | loss: 2.0279901MixupTrain:  epoch  0, batch   660 | loss: 2.1540153MixupTrain:  epoch  0, batch   661 | loss: 2.1160259MixupTrain:  epoch  0, batch   662 | loss: 2.0013719MixupTrain:  epoch  0, batch   663 | loss: 2.1365123MixupTrain:  epoch  0, batch   664 | loss: 2.0576985MixupTrain:  epoch  0, batch   665 | loss: 1.9621083MixupTrain:  epoch  0, batch   666 | loss: 2.1663425MixupTrain:  epoch  0, batch   667 | loss: 2.0273936MixupTrain:  epoch  0, batch   668 | loss: 2.1571393MixupTrain:  epoch  0, batch   669 | loss: 2.0985596MixupTrain:  epoch  0, batch   670 | loss: 2.0120573MixupTrain:  epoch  0, batch   671 | loss: 2.1075950MixupTrain:  epoch  0, batch   672 | loss: 2.0271223MixupTrain:  epoch  0, batch   673 | loss: 2.0953898MixupTrain:  epoch  0, batch   674 | loss: 2.1745243MixupTrain:  epoch  0, batch   675 | loss: 1.9290386
MemoryTrain:  epoch  0, batch     0 | loss: 1.9473161MemoryTrain:  epoch  0, batch     1 | loss: 2.2364256MemoryTrain:  epoch  0, batch     2 | loss: 2.4959035MemoryTrain:  epoch  0, batch     3 | loss: 2.0451016MemoryTrain:  epoch  0, batch     4 | loss: 2.9843071MemoryTrain:  epoch  0, batch     5 | loss: 2.5789466MemoryTrain:  epoch  0, batch     6 | loss: 2.5387495MemoryTrain:  epoch  0, batch     7 | loss: 2.1330688MemoryTrain:  epoch  1, batch     0 | loss: 1.8441536MemoryTrain:  epoch  1, batch     1 | loss: 1.8448670MemoryTrain:  epoch  1, batch     2 | loss: 1.8552411MemoryTrain:  epoch  1, batch     3 | loss: 1.8660409MemoryTrain:  epoch  1, batch     4 | loss: 1.8374319MemoryTrain:  epoch  1, batch     5 | loss: 1.8571441MemoryTrain:  epoch  1, batch     6 | loss: 1.8470144MemoryTrain:  epoch  1, batch     7 | loss: 1.8453695MemoryTrain:  epoch  2, batch     0 | loss: 1.8295437MemoryTrain:  epoch  2, batch     1 | loss: 1.8371370MemoryTrain:  epoch  2, batch     2 | loss: 1.8262426MemoryTrain:  epoch  2, batch     3 | loss: 1.8237731MemoryTrain:  epoch  2, batch     4 | loss: 1.8355863MemoryTrain:  epoch  2, batch     5 | loss: 1.8150822MemoryTrain:  epoch  2, batch     6 | loss: 1.8295357MemoryTrain:  epoch  2, batch     7 | loss: 1.8340136MemoryTrain:  epoch  3, batch     0 | loss: 1.8248403MemoryTrain:  epoch  3, batch     1 | loss: 1.8234193MemoryTrain:  epoch  3, batch     2 | loss: 1.8168017MemoryTrain:  epoch  3, batch     3 | loss: 1.8328207MemoryTrain:  epoch  3, batch     4 | loss: 1.8255149MemoryTrain:  epoch  3, batch     5 | loss: 1.8221526MemoryTrain:  epoch  3, batch     6 | loss: 1.8256375MemoryTrain:  epoch  3, batch     7 | loss: 1.8284166MemoryTrain:  epoch  4, batch     0 | loss: 1.8170190MemoryTrain:  epoch  4, batch     1 | loss: 1.8164642MemoryTrain:  epoch  4, batch     2 | loss: 1.8270566MemoryTrain:  epoch  4, batch     3 | loss: 1.8249028MemoryTrain:  epoch  4, batch     4 | loss: 1.8197055MemoryTrain:  epoch  4, batch     5 | loss: 1.8265152MemoryTrain:  epoch  4, batch     6 | loss: 1.8232038MemoryTrain:  epoch  4, batch     7 | loss: 1.8200674MemoryTrain:  epoch  5, batch     0 | loss: 1.8173370MemoryTrain:  epoch  5, batch     1 | loss: 1.8211832MemoryTrain:  epoch  5, batch     2 | loss: 1.8328619MemoryTrain:  epoch  5, batch     3 | loss: 1.8282051MemoryTrain:  epoch  5, batch     4 | loss: 1.8210719MemoryTrain:  epoch  5, batch     5 | loss: 1.8345070MemoryTrain:  epoch  5, batch     6 | loss: 1.8152270MemoryTrain:  epoch  5, batch     7 | loss: 1.8210508MemoryTrain:  epoch  6, batch     0 | loss: 1.8159289MemoryTrain:  epoch  6, batch     1 | loss: 1.8294246MemoryTrain:  epoch  6, batch     2 | loss: 1.8283787MemoryTrain:  epoch  6, batch     3 | loss: 1.8175232MemoryTrain:  epoch  6, batch     4 | loss: 1.8370690MemoryTrain:  epoch  6, batch     5 | loss: 1.8222662MemoryTrain:  epoch  6, batch     6 | loss: 1.8249083MemoryTrain:  epoch  6, batch     7 | loss: 1.8377657MemoryTrain:  epoch  7, batch     0 | loss: 1.8207026MemoryTrain:  epoch  7, batch     1 | loss: 1.8210490MemoryTrain:  epoch  7, batch     2 | loss: 1.8203411MemoryTrain:  epoch  7, batch     3 | loss: 1.8106952MemoryTrain:  epoch  7, batch     4 | loss: 1.8144931MemoryTrain:  epoch  7, batch     5 | loss: 1.8199246MemoryTrain:  epoch  7, batch     6 | loss: 1.8273699MemoryTrain:  epoch  7, batch     7 | loss: 1.8137611MemoryTrain:  epoch  8, batch     0 | loss: 1.8155955MemoryTrain:  epoch  8, batch     1 | loss: 1.8119420MemoryTrain:  epoch  8, batch     2 | loss: 1.8169837MemoryTrain:  epoch  8, batch     3 | loss: 1.8140404MemoryTrain:  epoch  8, batch     4 | loss: 1.8182085MemoryTrain:  epoch  8, batch     5 | loss: 1.8158108MemoryTrain:  epoch  8, batch     6 | loss: 1.8116779MemoryTrain:  epoch  8, batch     7 | loss: 1.8214715MemoryTrain:  epoch  9, batch     0 | loss: 1.8179432MemoryTrain:  epoch  9, batch     1 | loss: 1.8229330MemoryTrain:  epoch  9, batch     2 | loss: 1.8130615MemoryTrain:  epoch  9, batch     3 | loss: 1.8188465MemoryTrain:  epoch  9, batch     4 | loss: 1.8202413MemoryTrain:  epoch  9, batch     5 | loss: 1.8252165MemoryTrain:  epoch  9, batch     6 | loss: 1.8165269MemoryTrain:  epoch  9, batch     7 | loss: 1.8257167
[EVAL] batch:    0 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    2 | acc: 87.50%,  total acc: 91.67%   [EVAL] batch:    3 | acc: 75.00%,  total acc: 87.50%   [EVAL] batch:    4 | acc: 100.00%,  total acc: 90.00%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 91.67%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 91.96%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 92.97%   [EVAL] batch:    8 | acc: 87.50%,  total acc: 92.36%   [EVAL] batch:    9 | acc: 87.50%,  total acc: 91.88%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 92.05%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 92.19%   [EVAL] batch:   12 | acc: 43.75%,  total acc: 88.46%   
[EVAL] batch:    0 | acc: 0.00%,  total acc: 0.00%   [EVAL] batch:    1 | acc: 12.50%,  total acc: 6.25%   [EVAL] batch:    2 | acc: 12.50%,  total acc: 8.33%   [EVAL] batch:    3 | acc: 0.00%,  total acc: 6.25%   [EVAL] batch:    4 | acc: 0.00%,  total acc: 5.00%   [EVAL] batch:    5 | acc: 12.50%,  total acc: 6.25%   [EVAL] batch:    6 | acc: 37.50%,  total acc: 10.71%   [EVAL] batch:    7 | acc: 18.75%,  total acc: 11.72%   [EVAL] batch:    8 | acc: 56.25%,  total acc: 16.67%   [EVAL] batch:    9 | acc: 25.00%,  total acc: 17.50%   [EVAL] batch:   10 | acc: 31.25%,  total acc: 18.75%   [EVAL] batch:   11 | acc: 50.00%,  total acc: 21.35%   [EVAL] batch:   12 | acc: 18.75%,  total acc: 21.15%   [EVAL] batch:   13 | acc: 31.25%,  total acc: 21.88%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 25.42%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 27.34%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 30.15%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 31.94%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 33.55%   [EVAL] batch:   19 | acc: 87.50%,  total acc: 36.25%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 38.69%   [EVAL] batch:   21 | acc: 81.25%,  total acc: 40.62%   [EVAL] batch:   22 | acc: 75.00%,  total acc: 42.12%   [EVAL] batch:   23 | acc: 87.50%,  total acc: 44.01%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 46.00%   [EVAL] batch:   25 | acc: 93.75%,  total acc: 47.84%   [EVAL] batch:   26 | acc: 43.75%,  total acc: 47.69%   [EVAL] batch:   27 | acc: 31.25%,  total acc: 47.10%   [EVAL] batch:   28 | acc: 12.50%,  total acc: 45.91%   [EVAL] batch:   29 | acc: 25.00%,  total acc: 45.21%   [EVAL] batch:   30 | acc: 25.00%,  total acc: 44.56%   [EVAL] batch:   31 | acc: 25.00%,  total acc: 43.95%   [EVAL] batch:   32 | acc: 62.50%,  total acc: 44.51%   [EVAL] batch:   33 | acc: 18.75%,  total acc: 43.75%   [EVAL] batch:   34 | acc: 12.50%,  total acc: 42.86%   [EVAL] batch:   35 | acc: 0.00%,  total acc: 41.67%   [EVAL] batch:   36 | acc: 0.00%,  total acc: 40.54%   [EVAL] batch:   37 | acc: 6.25%,  total acc: 39.64%   [EVAL] batch:   38 | acc: 6.25%,  total acc: 38.78%   [EVAL] batch:   39 | acc: 75.00%,  total acc: 39.69%   [EVAL] batch:   40 | acc: 100.00%,  total acc: 41.16%   [EVAL] batch:   41 | acc: 87.50%,  total acc: 42.26%   [EVAL] batch:   42 | acc: 87.50%,  total acc: 43.31%   [EVAL] batch:   43 | acc: 81.25%,  total acc: 44.18%   [EVAL] batch:   44 | acc: 93.75%,  total acc: 45.28%   [EVAL] batch:   45 | acc: 81.25%,  total acc: 46.06%   [EVAL] batch:   46 | acc: 75.00%,  total acc: 46.68%   [EVAL] batch:   47 | acc: 93.75%,  total acc: 47.66%   [EVAL] batch:   48 | acc: 87.50%,  total acc: 48.47%   [EVAL] batch:   49 | acc: 81.25%,  total acc: 49.12%   [EVAL] batch:   50 | acc: 68.75%,  total acc: 49.51%   [EVAL] batch:   51 | acc: 87.50%,  total acc: 50.24%   [EVAL] batch:   52 | acc: 87.50%,  total acc: 50.94%   [EVAL] batch:   53 | acc: 93.75%,  total acc: 51.74%   [EVAL] batch:   54 | acc: 93.75%,  total acc: 52.50%   [EVAL] batch:   55 | acc: 87.50%,  total acc: 53.12%   [EVAL] batch:   56 | acc: 81.25%,  total acc: 53.62%   [EVAL] batch:   57 | acc: 93.75%,  total acc: 54.31%   [EVAL] batch:   58 | acc: 100.00%,  total acc: 55.08%   [EVAL] batch:   59 | acc: 93.75%,  total acc: 55.73%   [EVAL] batch:   60 | acc: 100.00%,  total acc: 56.45%   [EVAL] batch:   61 | acc: 93.75%,  total acc: 57.06%   [EVAL] batch:   62 | acc: 81.25%,  total acc: 57.44%   [EVAL] batch:   63 | acc: 100.00%,  total acc: 58.11%   [EVAL] batch:   64 | acc: 87.50%,  total acc: 58.56%   [EVAL] batch:   65 | acc: 62.50%,  total acc: 58.62%   
cur_acc:  ['0.8712', '0.9107', '0.8281', '0.8846']
his_acc:  ['0.8712', '0.8697', '0.6771', '0.5862']
CurrentTrain: epoch  0, batch     0 | loss: 7.8299999CurrentTrain: epoch  0, batch     1 | loss: 7.6174555CurrentTrain: epoch  1, batch     0 | loss: 5.8802958CurrentTrain: epoch  1, batch     1 | loss: 9.5575123CurrentTrain: epoch  2, batch     0 | loss: 7.3325410CurrentTrain: epoch  2, batch     1 | loss: 6.9810405CurrentTrain: epoch  3, batch     0 | loss: 6.1729465CurrentTrain: epoch  3, batch     1 | loss: 8.0001040CurrentTrain: epoch  4, batch     0 | loss: 5.5392590CurrentTrain: epoch  4, batch     1 | loss: 7.8099594CurrentTrain: epoch  5, batch     0 | loss: 6.3596916CurrentTrain: epoch  5, batch     1 | loss: 5.7600198CurrentTrain: epoch  6, batch     0 | loss: 5.8010082CurrentTrain: epoch  6, batch     1 | loss: 6.7065635CurrentTrain: epoch  7, batch     0 | loss: 4.4935904CurrentTrain: epoch  7, batch     1 | loss: 8.1931791CurrentTrain: epoch  8, batch     0 | loss: 5.4355578CurrentTrain: epoch  8, batch     1 | loss: 6.3262749CurrentTrain: epoch  9, batch     0 | loss: 5.3564711CurrentTrain: epoch  9, batch     1 | loss: 6.1782880
#### organization subsidiaries ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization subsidiaries" means an organization 's subsidiary is an organization.
Here is an example:
Relation: organization subsidiaries
Context: venture fund buys sporting chain highland capital 's consumer fund includes lululemon athletica , a yoga retailer , and o beverages , a flavored water company developed by tom first , one of the two `` juice guys '' who cofounded nantucket nectars .
Head Entity: highland capital
Tail Entity: o beverages
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization subsidiaries":
Relation: organization subsidiaries  
Context: The tech giant Alphabet Inc. has several subsidiaries, including YouTube, which has transformed the way we consume video content online.  
Head Entity: Alphabet Inc.  
Tail Entity: YouTube  

Relation: organization subsidiaries  
Context: The automotive manufacturer General Motors has a number of subsidiaries, one of which is Chevrolet, known for its popular line of trucks and cars.  
Head Entity: General Motors  
Tail Entity: Chevrolet  

Relation: organization subsidiaries  
Context: The multinational conglomerate Procter & Gamble owns various subsidiaries, including Gillette, which specializes in personal care products.  
Head Entity: Procter & Gamble  
Tail Entity: Gillette  

Relation: organization subsidiaries  
Context: The beverage company Coca-Cola has several subsidiaries, one of which is Minute Maid, famous for its fruit juices and drinks.  
Head Entity: Coca-Cola  
Tail Entity: Minute Maid  

Relation: organization subsidiaries  
Context: The financial services corporation Berkshire Hathaway has numerous subsidiaries, including Geico, which is well-known for its auto insurance services.  
Head Entity: Berkshire Hathaway  
Tail Entity: Geico  
#### organization parents ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization parents" means an organization 's parent is an organization.
Here is an example:
Relation: organization parents
Context: those who try to salvage possessions from the debris of their homes can easily turn into victims too , said dr. irwin redlener , director of the national center for disaster preparedness at columbia university mailman school of medicine .
Head Entity: national center for disaster preparedness
Tail Entity: columbia university mailman school of medicine
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization parents":
Relation: organization parents  
Context: The tech giant Google has been a subsidiary of Alphabet Inc. since its restructuring in 2015, allowing for greater focus on its various ventures.  
Head Entity: Google  
Tail Entity: Alphabet Inc.  

Relation: organization parents  
Context: The renowned automotive manufacturer Ford Motor Company has its roots in the Ford family, which played a significant role in its establishment and growth.  
Head Entity: Ford Motor Company  
Tail Entity: Ford family  

Relation: organization parents  
Context: The popular social media platform Instagram was acquired by Facebook in 2012, becoming part of the larger family of services under the Facebook umbrella.  
Head Entity: Instagram  
Tail Entity: Facebook  

Relation: organization parents  
Context: The prestigious research institution MIT is part of the larger Massachusetts Institute of Technology system, which encompasses various educational and research initiatives.  
Head Entity: MIT  
Tail Entity: Massachusetts Institute of Technology  

Relation: organization parents  
Context: The global fast-food chain McDonald's operates under the umbrella of its parent company, Golden Arches Holdings, which oversees its franchises worldwide.  
Head Entity: McDonald's  
Tail Entity: Golden Arches Holdings  
#### organization alternate names ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization alternate names" means a person 's alias is a person.
Here is an example:
Relation: organization alternate names
Context: the talks between graham and pak ui-chun were held in a `` friendly '' manner , the official korean central news agency -lrb- kcna -rrb- said , without giving details .
Head Entity: kcna
Tail Entity: korean central news agency
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization alternate names":
Relation: organization alternate names  
Context: The International Monetary Fund, often referred to as the IMF, has released its latest economic forecast.  
Head Entity: IMF  
Tail Entity: International Monetary Fund  

Relation: organization alternate names  
Context: The World Health Organization, commonly known as WHO, has declared a public health emergency.  
Head Entity: WHO  
Tail Entity: World Health Organization  

Relation: organization alternate names  
Context: The National Aeronautics and Space Administration, abbreviated as NASA, is planning a new mission to Mars.  
Head Entity: NASA  
Tail Entity: National Aeronautics and Space Administration  

Relation: organization alternate names  
Context: The Federal Bureau of Investigation, or FBI, has launched an investigation into the matter.  
Head Entity: FBI  
Tail Entity: Federal Bureau of Investigation  

Relation: organization alternate names  
Context: The Central Intelligence Agency, often called the CIA, has been involved in various covert operations.  
Head Entity: CIA  
Tail Entity: Central Intelligence Agency  
#### organization city of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization city of headquarters" means an organization is located in a city.
Here is an example:
Relation: organization city of headquarters
Context: sts-127 space shuttle endeavour launches from launch pad 39a at kennedy space center july 15 , in cape canaveral , florida .
Head Entity: kennedy space center
Tail Entity: cape canaveral
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization city of headquarters":
1. Relation: organization city of headquarters  
   Context: the headquarters of the tech giant apple inc. is located in cupertino, california, where it has been since the 1990s.  
   Head Entity: apple inc.  
   Tail Entity: cupertino  

2. Relation: organization city of headquarters  
   Context: the multinational corporation samsung electronics has its main office in suwon, south korea, which is known for its advanced technology.  
   Head Entity: samsung electronics  
   Tail Entity: suwon  

3. Relation: organization city of headquarters  
   Context: the famous car manufacturer toyota motor corporation is headquartered in toyota city, aichi prefecture, japan, where it was founded.  
   Head Entity: toyota motor corporation  
   Tail Entity: toyota city  

4. Relation: organization city of headquarters  
   Context: the global consulting firm accenture has its headquarters in dublin, ireland, which serves as a hub for its European operations.  
   Head Entity: accenture  
   Tail Entity: dublin  

5. Relation: organization city of headquarters  
   Context: the well-known social media platform facebook, now known as meta platforms, has its headquarters in menlo park, california, a center for innovation.  
   Head Entity: meta platforms  
   Tail Entity: menlo park  
#### person siblings ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person siblings" means a person 's sibling is a person.
Here is an example:
Relation: person siblings
Context: forsberg , a political science professor at city college of new york , died oct. 19 in a bronx hospital of cancer , said her sister , celia seupel .
Head Entity: forsberg
Tail Entity: celia seupel
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person siblings":
Relation: person siblings  
Context: During the family reunion, John introduced his sister, Emily, who had just returned from studying abroad.  
Head Entity: John  
Tail Entity: Emily  

Relation: person siblings  
Context: After the game, Sarah celebrated her victory with her brother, Michael, who had been cheering for her from the stands.  
Head Entity: Sarah  
Tail Entity: Michael  

Relation: person siblings  
Context: In her memoir, Lisa writes fondly about her childhood adventures with her brother, Tom, who always had her back.  
Head Entity: Lisa  
Tail Entity: Tom  

Relation: person siblings  
Context: At the wedding, Anna was thrilled to see her brother, David, who had flown in from another state to be her best man.  
Head Entity: Anna  
Tail Entity: David  

Relation: person siblings  
Context: The documentary featured interviews with Rachel and her sister, Jessica, discussing their close bond and shared experiences growing up.  
Head Entity: Rachel  
Tail Entity: Jessica  
Mixup data size:  15700
MixupTrain:  epoch  0, batch     0 | loss: 4.5612640MixupTrain:  epoch  0, batch     1 | loss: 5.5048733MixupTrain:  epoch  0, batch     2 | loss: 5.0719719MixupTrain:  epoch  0, batch     3 | loss: 5.0975122MixupTrain:  epoch  0, batch     4 | loss: 5.2790718MixupTrain:  epoch  0, batch     5 | loss: 5.4689322MixupTrain:  epoch  0, batch     6 | loss: 4.9060636MixupTrain:  epoch  0, batch     7 | loss: 5.4051805MixupTrain:  epoch  0, batch     8 | loss: 5.8899221MixupTrain:  epoch  0, batch     9 | loss: 4.9906921MixupTrain:  epoch  0, batch    10 | loss: 5.9004378MixupTrain:  epoch  0, batch    11 | loss: 5.4017534MixupTrain:  epoch  0, batch    12 | loss: 3.2043366MixupTrain:  epoch  0, batch    13 | loss: 5.9964862MixupTrain:  epoch  0, batch    14 | loss: 4.5647483MixupTrain:  epoch  0, batch    15 | loss: 5.2566514MixupTrain:  epoch  0, batch    16 | loss: 5.6242065MixupTrain:  epoch  0, batch    17 | loss: 4.0869160MixupTrain:  epoch  0, batch    18 | loss: 3.6554604MixupTrain:  epoch  0, batch    19 | loss: 4.6288681MixupTrain:  epoch  0, batch    20 | loss: 3.8903246MixupTrain:  epoch  0, batch    21 | loss: 4.7371655MixupTrain:  epoch  0, batch    22 | loss: 4.3814554MixupTrain:  epoch  0, batch    23 | loss: 3.9311135MixupTrain:  epoch  0, batch    24 | loss: 5.0604577MixupTrain:  epoch  0, batch    25 | loss: 4.9263620MixupTrain:  epoch  0, batch    26 | loss: 4.7278290MixupTrain:  epoch  0, batch    27 | loss: 4.1714625MixupTrain:  epoch  0, batch    28 | loss: 5.1670637MixupTrain:  epoch  0, batch    29 | loss: 5.2396955MixupTrain:  epoch  0, batch    30 | loss: 3.9945831MixupTrain:  epoch  0, batch    31 | loss: 4.2237730MixupTrain:  epoch  0, batch    32 | loss: 3.9439459MixupTrain:  epoch  0, batch    33 | loss: 4.4534121MixupTrain:  epoch  0, batch    34 | loss: 3.6870868MixupTrain:  epoch  0, batch    35 | loss: 4.8679276MixupTrain:  epoch  0, batch    36 | loss: 3.8629065MixupTrain:  epoch  0, batch    37 | loss: 4.0945644MixupTrain:  epoch  0, batch    38 | loss: 4.7090054MixupTrain:  epoch  0, batch    39 | loss: 3.2913728MixupTrain:  epoch  0, batch    40 | loss: 4.6683559MixupTrain:  epoch  0, batch    41 | loss: 4.0977535MixupTrain:  epoch  0, batch    42 | loss: 4.4846320MixupTrain:  epoch  0, batch    43 | loss: 3.5666094MixupTrain:  epoch  0, batch    44 | loss: 3.9437156MixupTrain:  epoch  0, batch    45 | loss: 4.3222380MixupTrain:  epoch  0, batch    46 | loss: 3.3511176MixupTrain:  epoch  0, batch    47 | loss: 4.5951853MixupTrain:  epoch  0, batch    48 | loss: 4.5432644MixupTrain:  epoch  0, batch    49 | loss: 3.4902244MixupTrain:  epoch  0, batch    50 | loss: 3.3430934MixupTrain:  epoch  0, batch    51 | loss: 4.2793102MixupTrain:  epoch  0, batch    52 | loss: 3.7916083MixupTrain:  epoch  0, batch    53 | loss: 4.2596178MixupTrain:  epoch  0, batch    54 | loss: 3.3480577MixupTrain:  epoch  0, batch    55 | loss: 4.5396471MixupTrain:  epoch  0, batch    56 | loss: 4.8285599MixupTrain:  epoch  0, batch    57 | loss: 3.4414959MixupTrain:  epoch  0, batch    58 | loss: 3.9560678MixupTrain:  epoch  0, batch    59 | loss: 3.4041152MixupTrain:  epoch  0, batch    60 | loss: 3.4382710MixupTrain:  epoch  0, batch    61 | loss: 3.8304291MixupTrain:  epoch  0, batch    62 | loss: 4.7153721MixupTrain:  epoch  0, batch    63 | loss: 3.7092991MixupTrain:  epoch  0, batch    64 | loss: 3.8310626MixupTrain:  epoch  0, batch    65 | loss: 3.7791424MixupTrain:  epoch  0, batch    66 | loss: 4.0678310MixupTrain:  epoch  0, batch    67 | loss: 4.2145953MixupTrain:  epoch  0, batch    68 | loss: 3.0214844MixupTrain:  epoch  0, batch    69 | loss: 3.8498533MixupTrain:  epoch  0, batch    70 | loss: 4.4354186MixupTrain:  epoch  0, batch    71 | loss: 4.0166216MixupTrain:  epoch  0, batch    72 | loss: 3.7779293MixupTrain:  epoch  0, batch    73 | loss: 4.6645474MixupTrain:  epoch  0, batch    74 | loss: 2.7430449MixupTrain:  epoch  0, batch    75 | loss: 2.3503580MixupTrain:  epoch  0, batch    76 | loss: 3.3935165MixupTrain:  epoch  0, batch    77 | loss: 3.9727919MixupTrain:  epoch  0, batch    78 | loss: 4.2283587MixupTrain:  epoch  0, batch    79 | loss: 3.6008036MixupTrain:  epoch  0, batch    80 | loss: 3.1010654MixupTrain:  epoch  0, batch    81 | loss: 3.7155542MixupTrain:  epoch  0, batch    82 | loss: 4.2012100MixupTrain:  epoch  0, batch    83 | loss: 4.6812201MixupTrain:  epoch  0, batch    84 | loss: 3.0290756MixupTrain:  epoch  0, batch    85 | loss: 3.8636475MixupTrain:  epoch  0, batch    86 | loss: 4.0465336MixupTrain:  epoch  0, batch    87 | loss: 3.8191266MixupTrain:  epoch  0, batch    88 | loss: 3.4272709MixupTrain:  epoch  0, batch    89 | loss: 3.6536636MixupTrain:  epoch  0, batch    90 | loss: 3.4136379MixupTrain:  epoch  0, batch    91 | loss: 3.2695460MixupTrain:  epoch  0, batch    92 | loss: 4.6117477MixupTrain:  epoch  0, batch    93 | loss: 3.0677481MixupTrain:  epoch  0, batch    94 | loss: 3.2122750MixupTrain:  epoch  0, batch    95 | loss: 3.0214381MixupTrain:  epoch  0, batch    96 | loss: 3.4011428MixupTrain:  epoch  0, batch    97 | loss: 3.3318634MixupTrain:  epoch  0, batch    98 | loss: 3.3825839MixupTrain:  epoch  0, batch    99 | loss: 4.0821781MixupTrain:  epoch  0, batch   100 | loss: 3.7033589MixupTrain:  epoch  0, batch   101 | loss: 2.8403149MixupTrain:  epoch  0, batch   102 | loss: 2.9126890MixupTrain:  epoch  0, batch   103 | loss: 3.4981298MixupTrain:  epoch  0, batch   104 | loss: 3.7921553MixupTrain:  epoch  0, batch   105 | loss: 3.9508231MixupTrain:  epoch  0, batch   106 | loss: 3.4942484MixupTrain:  epoch  0, batch   107 | loss: 3.3341508MixupTrain:  epoch  0, batch   108 | loss: 3.9463573MixupTrain:  epoch  0, batch   109 | loss: 2.8533072MixupTrain:  epoch  0, batch   110 | loss: 2.9927750MixupTrain:  epoch  0, batch   111 | loss: 2.5072269MixupTrain:  epoch  0, batch   112 | loss: 3.9658511MixupTrain:  epoch  0, batch   113 | loss: 2.8540716MixupTrain:  epoch  0, batch   114 | loss: 3.3083472MixupTrain:  epoch  0, batch   115 | loss: 4.1902432MixupTrain:  epoch  0, batch   116 | loss: 3.2711563MixupTrain:  epoch  0, batch   117 | loss: 3.1712072MixupTrain:  epoch  0, batch   118 | loss: 2.9263854MixupTrain:  epoch  0, batch   119 | loss: 3.8386917MixupTrain:  epoch  0, batch   120 | loss: 3.4116702MixupTrain:  epoch  0, batch   121 | loss: 3.2928042MixupTrain:  epoch  0, batch   122 | loss: 3.9122691MixupTrain:  epoch  0, batch   123 | loss: 3.5285349MixupTrain:  epoch  0, batch   124 | loss: 4.0555010MixupTrain:  epoch  0, batch   125 | loss: 3.1843657MixupTrain:  epoch  0, batch   126 | loss: 2.9315109MixupTrain:  epoch  0, batch   127 | loss: 3.3462257MixupTrain:  epoch  0, batch   128 | loss: 3.3743465MixupTrain:  epoch  0, batch   129 | loss: 3.2498703MixupTrain:  epoch  0, batch   130 | loss: 2.7645326MixupTrain:  epoch  0, batch   131 | loss: 3.0083225MixupTrain:  epoch  0, batch   132 | loss: 3.8802845MixupTrain:  epoch  0, batch   133 | loss: 3.6507905MixupTrain:  epoch  0, batch   134 | loss: 3.4965477MixupTrain:  epoch  0, batch   135 | loss: 3.1626978MixupTrain:  epoch  0, batch   136 | loss: 3.2150702MixupTrain:  epoch  0, batch   137 | loss: 3.5768046MixupTrain:  epoch  0, batch   138 | loss: 3.1182017MixupTrain:  epoch  0, batch   139 | loss: 3.0706749MixupTrain:  epoch  0, batch   140 | loss: 2.9747772MixupTrain:  epoch  0, batch   141 | loss: 3.4529309MixupTrain:  epoch  0, batch   142 | loss: 3.1928008MixupTrain:  epoch  0, batch   143 | loss: 3.6526299MixupTrain:  epoch  0, batch   144 | loss: 3.3938684MixupTrain:  epoch  0, batch   145 | loss: 3.1738634MixupTrain:  epoch  0, batch   146 | loss: 3.1257310MixupTrain:  epoch  0, batch   147 | loss: 3.3037274MixupTrain:  epoch  0, batch   148 | loss: 3.1446452MixupTrain:  epoch  0, batch   149 | loss: 2.8632822MixupTrain:  epoch  0, batch   150 | loss: 3.5586286MixupTrain:  epoch  0, batch   151 | loss: 3.1804519MixupTrain:  epoch  0, batch   152 | loss: 3.9078903MixupTrain:  epoch  0, batch   153 | loss: 3.5292063MixupTrain:  epoch  0, batch   154 | loss: 3.0035276MixupTrain:  epoch  0, batch   155 | loss: 2.6180840MixupTrain:  epoch  0, batch   156 | loss: 3.8591554MixupTrain:  epoch  0, batch   157 | loss: 3.5029426MixupTrain:  epoch  0, batch   158 | loss: 2.9959285MixupTrain:  epoch  0, batch   159 | loss: 3.3941135MixupTrain:  epoch  0, batch   160 | loss: 3.0434527MixupTrain:  epoch  0, batch   161 | loss: 3.4258327MixupTrain:  epoch  0, batch   162 | loss: 3.2539158MixupTrain:  epoch  0, batch   163 | loss: 2.4681249MixupTrain:  epoch  0, batch   164 | loss: 3.2355278MixupTrain:  epoch  0, batch   165 | loss: 3.3859053MixupTrain:  epoch  0, batch   166 | loss: 2.6556797MixupTrain:  epoch  0, batch   167 | loss: 2.9484344MixupTrain:  epoch  0, batch   168 | loss: 3.2214839MixupTrain:  epoch  0, batch   169 | loss: 3.0074117MixupTrain:  epoch  0, batch   170 | loss: 2.8855762MixupTrain:  epoch  0, batch   171 | loss: 3.6179373MixupTrain:  epoch  0, batch   172 | loss: 3.7005086MixupTrain:  epoch  0, batch   173 | loss: 2.7705002MixupTrain:  epoch  0, batch   174 | loss: 3.8756113MixupTrain:  epoch  0, batch   175 | loss: 2.3389943MixupTrain:  epoch  0, batch   176 | loss: 3.0780036MixupTrain:  epoch  0, batch   177 | loss: 2.8224497MixupTrain:  epoch  0, batch   178 | loss: 3.6585670MixupTrain:  epoch  0, batch   179 | loss: 3.8327818MixupTrain:  epoch  0, batch   180 | loss: 3.3212488MixupTrain:  epoch  0, batch   181 | loss: 3.1561403MixupTrain:  epoch  0, batch   182 | loss: 3.7162004MixupTrain:  epoch  0, batch   183 | loss: 2.6698046MixupTrain:  epoch  0, batch   184 | loss: 3.0794187MixupTrain:  epoch  0, batch   185 | loss: 3.2613778MixupTrain:  epoch  0, batch   186 | loss: 2.7339370MixupTrain:  epoch  0, batch   187 | loss: 3.7949059MixupTrain:  epoch  0, batch   188 | loss: 3.1171126MixupTrain:  epoch  0, batch   189 | loss: 3.2940741MixupTrain:  epoch  0, batch   190 | loss: 3.2933621MixupTrain:  epoch  0, batch   191 | loss: 3.5186052MixupTrain:  epoch  0, batch   192 | loss: 3.4910665MixupTrain:  epoch  0, batch   193 | loss: 2.8521321MixupTrain:  epoch  0, batch   194 | loss: 3.1817625MixupTrain:  epoch  0, batch   195 | loss: 3.1275494MixupTrain:  epoch  0, batch   196 | loss: 2.5271177MixupTrain:  epoch  0, batch   197 | loss: 2.9360092MixupTrain:  epoch  0, batch   198 | loss: 3.4802225MixupTrain:  epoch  0, batch   199 | loss: 2.3364868MixupTrain:  epoch  0, batch   200 | loss: 3.2401171MixupTrain:  epoch  0, batch   201 | loss: 3.2393723MixupTrain:  epoch  0, batch   202 | loss: 2.7010860MixupTrain:  epoch  0, batch   203 | loss: 3.5188191MixupTrain:  epoch  0, batch   204 | loss: 3.0465820MixupTrain:  epoch  0, batch   205 | loss: 3.1452446MixupTrain:  epoch  0, batch   206 | loss: 3.5654411MixupTrain:  epoch  0, batch   207 | loss: 2.9751148MixupTrain:  epoch  0, batch   208 | loss: 3.5344591MixupTrain:  epoch  0, batch   209 | loss: 2.5641198MixupTrain:  epoch  0, batch   210 | loss: 3.2787604MixupTrain:  epoch  0, batch   211 | loss: 3.7609918MixupTrain:  epoch  0, batch   212 | loss: 2.9231782MixupTrain:  epoch  0, batch   213 | loss: 2.9618261MixupTrain:  epoch  0, batch   214 | loss: 2.5732350MixupTrain:  epoch  0, batch   215 | loss: 3.2218478MixupTrain:  epoch  0, batch   216 | loss: 3.2309151MixupTrain:  epoch  0, batch   217 | loss: 2.8616457MixupTrain:  epoch  0, batch   218 | loss: 3.1343832MixupTrain:  epoch  0, batch   219 | loss: 2.6601753MixupTrain:  epoch  0, batch   220 | loss: 3.3405721MixupTrain:  epoch  0, batch   221 | loss: 3.6599474MixupTrain:  epoch  0, batch   222 | loss: 3.3901472MixupTrain:  epoch  0, batch   223 | loss: 3.2271395MixupTrain:  epoch  0, batch   224 | loss: 3.4904361MixupTrain:  epoch  0, batch   225 | loss: 3.1815274MixupTrain:  epoch  0, batch   226 | loss: 3.2380228MixupTrain:  epoch  0, batch   227 | loss: 3.7726758MixupTrain:  epoch  0, batch   228 | loss: 2.9480309MixupTrain:  epoch  0, batch   229 | loss: 3.1369884MixupTrain:  epoch  0, batch   230 | loss: 3.5864830MixupTrain:  epoch  0, batch   231 | loss: 3.8905146MixupTrain:  epoch  0, batch   232 | loss: 3.4971991MixupTrain:  epoch  0, batch   233 | loss: 2.3631620MixupTrain:  epoch  0, batch   234 | loss: 3.1673918MixupTrain:  epoch  0, batch   235 | loss: 2.6140237MixupTrain:  epoch  0, batch   236 | loss: 3.9063296MixupTrain:  epoch  0, batch   237 | loss: 2.5671411MixupTrain:  epoch  0, batch   238 | loss: 3.3055682MixupTrain:  epoch  0, batch   239 | loss: 3.0246217MixupTrain:  epoch  0, batch   240 | loss: 3.3548460MixupTrain:  epoch  0, batch   241 | loss: 2.6554713MixupTrain:  epoch  0, batch   242 | loss: 3.4446201MixupTrain:  epoch  0, batch   243 | loss: 2.4088836MixupTrain:  epoch  0, batch   244 | loss: 3.3641493MixupTrain:  epoch  0, batch   245 | loss: 3.6771171MixupTrain:  epoch  0, batch   246 | loss: 2.6800706MixupTrain:  epoch  0, batch   247 | loss: 3.6655703MixupTrain:  epoch  0, batch   248 | loss: 3.6826966MixupTrain:  epoch  0, batch   249 | loss: 3.2380378MixupTrain:  epoch  0, batch   250 | loss: 3.5208592MixupTrain:  epoch  0, batch   251 | loss: 3.1836872MixupTrain:  epoch  0, batch   252 | loss: 2.4388924MixupTrain:  epoch  0, batch   253 | loss: 3.4562490MixupTrain:  epoch  0, batch   254 | loss: 3.1040337MixupTrain:  epoch  0, batch   255 | loss: 2.8222692MixupTrain:  epoch  0, batch   256 | loss: 2.5268605MixupTrain:  epoch  0, batch   257 | loss: 3.4029469MixupTrain:  epoch  0, batch   258 | loss: 2.5711818MixupTrain:  epoch  0, batch   259 | loss: 2.8781800MixupTrain:  epoch  0, batch   260 | loss: 3.2151706MixupTrain:  epoch  0, batch   261 | loss: 2.8861041MixupTrain:  epoch  0, batch   262 | loss: 3.0668013MixupTrain:  epoch  0, batch   263 | loss: 2.5178757MixupTrain:  epoch  0, batch   264 | loss: 3.5537219MixupTrain:  epoch  0, batch   265 | loss: 2.9483101MixupTrain:  epoch  0, batch   266 | loss: 3.1371765MixupTrain:  epoch  0, batch   267 | loss: 2.9119844MixupTrain:  epoch  0, batch   268 | loss: 3.0001211MixupTrain:  epoch  0, batch   269 | loss: 3.5437768MixupTrain:  epoch  0, batch   270 | loss: 2.9558423MixupTrain:  epoch  0, batch   271 | loss: 2.9088731MixupTrain:  epoch  0, batch   272 | loss: 2.5917454MixupTrain:  epoch  0, batch   273 | loss: 2.8900733MixupTrain:  epoch  0, batch   274 | loss: 2.7629685MixupTrain:  epoch  0, batch   275 | loss: 3.4619315MixupTrain:  epoch  0, batch   276 | loss: 3.3287148MixupTrain:  epoch  0, batch   277 | loss: 3.3803296MixupTrain:  epoch  0, batch   278 | loss: 2.4166007MixupTrain:  epoch  0, batch   279 | loss: 3.3297813MixupTrain:  epoch  0, batch   280 | loss: 2.8707683MixupTrain:  epoch  0, batch   281 | loss: 3.6470475MixupTrain:  epoch  0, batch   282 | loss: 2.7680402MixupTrain:  epoch  0, batch   283 | loss: 3.1360114MixupTrain:  epoch  0, batch   284 | loss: 2.6254923MixupTrain:  epoch  0, batch   285 | loss: 2.7571709MixupTrain:  epoch  0, batch   286 | loss: 2.9140282MixupTrain:  epoch  0, batch   287 | loss: 2.7344332MixupTrain:  epoch  0, batch   288 | loss: 3.4925225MixupTrain:  epoch  0, batch   289 | loss: 2.7924232MixupTrain:  epoch  0, batch   290 | loss: 2.9066577MixupTrain:  epoch  0, batch   291 | loss: 3.5215616MixupTrain:  epoch  0, batch   292 | loss: 2.9707804MixupTrain:  epoch  0, batch   293 | loss: 3.2862904MixupTrain:  epoch  0, batch   294 | loss: 2.8029120MixupTrain:  epoch  0, batch   295 | loss: 2.5434556MixupTrain:  epoch  0, batch   296 | loss: 3.3750968MixupTrain:  epoch  0, batch   297 | loss: 2.8682637MixupTrain:  epoch  0, batch   298 | loss: 3.2033110MixupTrain:  epoch  0, batch   299 | loss: 2.8279552MixupTrain:  epoch  0, batch   300 | loss: 2.9569917MixupTrain:  epoch  0, batch   301 | loss: 2.9723196MixupTrain:  epoch  0, batch   302 | loss: 3.1136565MixupTrain:  epoch  0, batch   303 | loss: 2.9543538MixupTrain:  epoch  0, batch   304 | loss: 3.5568986MixupTrain:  epoch  0, batch   305 | loss: 3.6447783MixupTrain:  epoch  0, batch   306 | loss: 2.9880817MixupTrain:  epoch  0, batch   307 | loss: 3.6611404MixupTrain:  epoch  0, batch   308 | loss: 3.0612178MixupTrain:  epoch  0, batch   309 | loss: 2.8152552MixupTrain:  epoch  0, batch   310 | loss: 3.1881673MixupTrain:  epoch  0, batch   311 | loss: 3.2222984MixupTrain:  epoch  0, batch   312 | loss: 2.7663736MixupTrain:  epoch  0, batch   313 | loss: 2.4118233MixupTrain:  epoch  0, batch   314 | loss: 2.8690155MixupTrain:  epoch  0, batch   315 | loss: 2.7865927MixupTrain:  epoch  0, batch   316 | loss: 2.8062694MixupTrain:  epoch  0, batch   317 | loss: 2.6429427MixupTrain:  epoch  0, batch   318 | loss: 3.2699525MixupTrain:  epoch  0, batch   319 | loss: 3.0202613MixupTrain:  epoch  0, batch   320 | loss: 2.6140110MixupTrain:  epoch  0, batch   321 | loss: 3.6710615MixupTrain:  epoch  0, batch   322 | loss: 3.0623131MixupTrain:  epoch  0, batch   323 | loss: 2.6559939MixupTrain:  epoch  0, batch   324 | loss: 2.4053893MixupTrain:  epoch  0, batch   325 | loss: 2.5641351MixupTrain:  epoch  0, batch   326 | loss: 2.9618759MixupTrain:  epoch  0, batch   327 | loss: 3.0510738MixupTrain:  epoch  0, batch   328 | loss: 2.6704435MixupTrain:  epoch  0, batch   329 | loss: 2.8663840MixupTrain:  epoch  0, batch   330 | loss: 2.8443308MixupTrain:  epoch  0, batch   331 | loss: 3.1503212MixupTrain:  epoch  0, batch   332 | loss: 3.7476788MixupTrain:  epoch  0, batch   333 | loss: 3.4304283MixupTrain:  epoch  0, batch   334 | loss: 3.1730623MixupTrain:  epoch  0, batch   335 | loss: 2.6534021MixupTrain:  epoch  0, batch   336 | loss: 3.1463718MixupTrain:  epoch  0, batch   337 | loss: 3.3295026MixupTrain:  epoch  0, batch   338 | loss: 3.2935038MixupTrain:  epoch  0, batch   339 | loss: 2.8234081MixupTrain:  epoch  0, batch   340 | loss: 3.1752903MixupTrain:  epoch  0, batch   341 | loss: 3.1976988MixupTrain:  epoch  0, batch   342 | loss: 2.9346118MixupTrain:  epoch  0, batch   343 | loss: 2.7670000MixupTrain:  epoch  0, batch   344 | loss: 2.6604137MixupTrain:  epoch  0, batch   345 | loss: 3.3836808MixupTrain:  epoch  0, batch   346 | loss: 2.3902826MixupTrain:  epoch  0, batch   347 | loss: 2.8925343MixupTrain:  epoch  0, batch   348 | loss: 2.6884167MixupTrain:  epoch  0, batch   349 | loss: 3.0042582MixupTrain:  epoch  0, batch   350 | loss: 3.6079423MixupTrain:  epoch  0, batch   351 | loss: 3.1141739MixupTrain:  epoch  0, batch   352 | loss: 3.3969426MixupTrain:  epoch  0, batch   353 | loss: 3.0352159MixupTrain:  epoch  0, batch   354 | loss: 2.8366191MixupTrain:  epoch  0, batch   355 | loss: 2.8661144MixupTrain:  epoch  0, batch   356 | loss: 2.9651589MixupTrain:  epoch  0, batch   357 | loss: 2.4622655MixupTrain:  epoch  0, batch   358 | loss: 3.3038788MixupTrain:  epoch  0, batch   359 | loss: 2.5472975MixupTrain:  epoch  0, batch   360 | loss: 3.5088873MixupTrain:  epoch  0, batch   361 | loss: 2.9963098MixupTrain:  epoch  0, batch   362 | loss: 2.8902030MixupTrain:  epoch  0, batch   363 | loss: 2.4851613MixupTrain:  epoch  0, batch   364 | loss: 3.4217300MixupTrain:  epoch  0, batch   365 | loss: 3.1437020MixupTrain:  epoch  0, batch   366 | loss: 2.5708141MixupTrain:  epoch  0, batch   367 | loss: 3.7531967MixupTrain:  epoch  0, batch   368 | loss: 2.8713350MixupTrain:  epoch  0, batch   369 | loss: 2.2931309MixupTrain:  epoch  0, batch   370 | loss: 2.6694062MixupTrain:  epoch  0, batch   371 | loss: 2.6509523MixupTrain:  epoch  0, batch   372 | loss: 3.1060719MixupTrain:  epoch  0, batch   373 | loss: 3.3390200MixupTrain:  epoch  0, batch   374 | loss: 3.4460192MixupTrain:  epoch  0, batch   375 | loss: 2.9543886MixupTrain:  epoch  0, batch   376 | loss: 2.4334393MixupTrain:  epoch  0, batch   377 | loss: 2.5641890MixupTrain:  epoch  0, batch   378 | loss: 2.9587297MixupTrain:  epoch  0, batch   379 | loss: 3.0192769MixupTrain:  epoch  0, batch   380 | loss: 3.1546977MixupTrain:  epoch  0, batch   381 | loss: 2.7340112MixupTrain:  epoch  0, batch   382 | loss: 3.2958658MixupTrain:  epoch  0, batch   383 | loss: 3.5480514MixupTrain:  epoch  0, batch   384 | loss: 2.5277934MixupTrain:  epoch  0, batch   385 | loss: 2.9320042MixupTrain:  epoch  0, batch   386 | loss: 3.4080839MixupTrain:  epoch  0, batch   387 | loss: 2.6958671MixupTrain:  epoch  0, batch   388 | loss: 2.6529665MixupTrain:  epoch  0, batch   389 | loss: 3.1897182MixupTrain:  epoch  0, batch   390 | loss: 3.1483424MixupTrain:  epoch  0, batch   391 | loss: 2.4578125MixupTrain:  epoch  0, batch   392 | loss: 2.7736757MixupTrain:  epoch  0, batch   393 | loss: 2.7576523MixupTrain:  epoch  0, batch   394 | loss: 2.2817755MixupTrain:  epoch  0, batch   395 | loss: 2.8836856MixupTrain:  epoch  0, batch   396 | loss: 3.5116062MixupTrain:  epoch  0, batch   397 | loss: 3.2529147MixupTrain:  epoch  0, batch   398 | loss: 2.9744415MixupTrain:  epoch  0, batch   399 | loss: 3.4372160MixupTrain:  epoch  0, batch   400 | loss: 2.9473975MixupTrain:  epoch  0, batch   401 | loss: 2.7529120MixupTrain:  epoch  0, batch   402 | loss: 2.8591557MixupTrain:  epoch  0, batch   403 | loss: 2.8116689MixupTrain:  epoch  0, batch   404 | loss: 2.8352697MixupTrain:  epoch  0, batch   405 | loss: 2.4886074MixupTrain:  epoch  0, batch   406 | loss: 3.0008845MixupTrain:  epoch  0, batch   407 | loss: 2.8970571MixupTrain:  epoch  0, batch   408 | loss: 2.6454306MixupTrain:  epoch  0, batch   409 | loss: 2.8221030MixupTrain:  epoch  0, batch   410 | loss: 2.9354081MixupTrain:  epoch  0, batch   411 | loss: 3.3122969MixupTrain:  epoch  0, batch   412 | loss: 2.9067104MixupTrain:  epoch  0, batch   413 | loss: 3.2741404MixupTrain:  epoch  0, batch   414 | loss: 2.8168039MixupTrain:  epoch  0, batch   415 | loss: 2.7202830MixupTrain:  epoch  0, batch   416 | loss: 3.1602187MixupTrain:  epoch  0, batch   417 | loss: 3.2113936MixupTrain:  epoch  0, batch   418 | loss: 2.4474177MixupTrain:  epoch  0, batch   419 | loss: 2.5924211MixupTrain:  epoch  0, batch   420 | loss: 2.8367891MixupTrain:  epoch  0, batch   421 | loss: 2.5410769MixupTrain:  epoch  0, batch   422 | loss: 3.5412326MixupTrain:  epoch  0, batch   423 | loss: 3.1207895MixupTrain:  epoch  0, batch   424 | loss: 2.9971023MixupTrain:  epoch  0, batch   425 | loss: 2.9050694MixupTrain:  epoch  0, batch   426 | loss: 3.0420151MixupTrain:  epoch  0, batch   427 | loss: 2.7964032MixupTrain:  epoch  0, batch   428 | loss: 3.0752535MixupTrain:  epoch  0, batch   429 | loss: 3.5033925MixupTrain:  epoch  0, batch   430 | loss: 3.0487196MixupTrain:  epoch  0, batch   431 | loss: 2.9374816MixupTrain:  epoch  0, batch   432 | loss: 2.9426112MixupTrain:  epoch  0, batch   433 | loss: 2.8574958MixupTrain:  epoch  0, batch   434 | loss: 3.1028740MixupTrain:  epoch  0, batch   435 | loss: 3.3737767MixupTrain:  epoch  0, batch   436 | loss: 3.2893519MixupTrain:  epoch  0, batch   437 | loss: 2.7662780MixupTrain:  epoch  0, batch   438 | loss: 2.7138186MixupTrain:  epoch  0, batch   439 | loss: 2.5867152MixupTrain:  epoch  0, batch   440 | loss: 2.7165818MixupTrain:  epoch  0, batch   441 | loss: 2.7579665MixupTrain:  epoch  0, batch   442 | loss: 3.1387610MixupTrain:  epoch  0, batch   443 | loss: 3.0625033MixupTrain:  epoch  0, batch   444 | loss: 2.9220521MixupTrain:  epoch  0, batch   445 | loss: 2.6489084MixupTrain:  epoch  0, batch   446 | loss: 2.6867175MixupTrain:  epoch  0, batch   447 | loss: 3.1860414MixupTrain:  epoch  0, batch   448 | loss: 2.6198132MixupTrain:  epoch  0, batch   449 | loss: 3.0939353MixupTrain:  epoch  0, batch   450 | loss: 3.4988923MixupTrain:  epoch  0, batch   451 | loss: 3.1642635MixupTrain:  epoch  0, batch   452 | loss: 2.8332274MixupTrain:  epoch  0, batch   453 | loss: 2.5798173MixupTrain:  epoch  0, batch   454 | loss: 2.7007811MixupTrain:  epoch  0, batch   455 | loss: 3.0569134MixupTrain:  epoch  0, batch   456 | loss: 2.4837737MixupTrain:  epoch  0, batch   457 | loss: 2.9368806MixupTrain:  epoch  0, batch   458 | loss: 2.6889215MixupTrain:  epoch  0, batch   459 | loss: 2.9171262MixupTrain:  epoch  0, batch   460 | loss: 3.1434317MixupTrain:  epoch  0, batch   461 | loss: 3.1743498MixupTrain:  epoch  0, batch   462 | loss: 3.1824467MixupTrain:  epoch  0, batch   463 | loss: 3.2421956MixupTrain:  epoch  0, batch   464 | loss: 2.3521309MixupTrain:  epoch  0, batch   465 | loss: 3.1115005MixupTrain:  epoch  0, batch   466 | loss: 3.6069140MixupTrain:  epoch  0, batch   467 | loss: 3.2377734MixupTrain:  epoch  0, batch   468 | loss: 2.5848417MixupTrain:  epoch  0, batch   469 | loss: 3.3075123MixupTrain:  epoch  0, batch   470 | loss: 2.6825228MixupTrain:  epoch  0, batch   471 | loss: 2.8595788MixupTrain:  epoch  0, batch   472 | loss: 2.8716981MixupTrain:  epoch  0, batch   473 | loss: 3.5206134MixupTrain:  epoch  0, batch   474 | loss: 2.8916593MixupTrain:  epoch  0, batch   475 | loss: 2.7367523MixupTrain:  epoch  0, batch   476 | loss: 2.9851570MixupTrain:  epoch  0, batch   477 | loss: 3.1794114MixupTrain:  epoch  0, batch   478 | loss: 3.3584971MixupTrain:  epoch  0, batch   479 | loss: 2.9413064MixupTrain:  epoch  0, batch   480 | loss: 2.7905583MixupTrain:  epoch  0, batch   481 | loss: 3.0608931MixupTrain:  epoch  0, batch   482 | loss: 3.2363715MixupTrain:  epoch  0, batch   483 | loss: 3.0895205MixupTrain:  epoch  0, batch   484 | loss: 3.1855838MixupTrain:  epoch  0, batch   485 | loss: 3.0355449MixupTrain:  epoch  0, batch   486 | loss: 2.1326375MixupTrain:  epoch  0, batch   487 | loss: 3.1371267MixupTrain:  epoch  0, batch   488 | loss: 3.2072229MixupTrain:  epoch  0, batch   489 | loss: 2.8274710MixupTrain:  epoch  0, batch   490 | loss: 2.5866661MixupTrain:  epoch  0, batch   491 | loss: 2.8882618MixupTrain:  epoch  0, batch   492 | loss: 2.9970369MixupTrain:  epoch  0, batch   493 | loss: 2.9524763MixupTrain:  epoch  0, batch   494 | loss: 3.2494526MixupTrain:  epoch  0, batch   495 | loss: 3.1759853MixupTrain:  epoch  0, batch   496 | loss: 3.5438976MixupTrain:  epoch  0, batch   497 | loss: 2.6185927MixupTrain:  epoch  0, batch   498 | loss: 2.7918606MixupTrain:  epoch  0, batch   499 | loss: 2.7606637MixupTrain:  epoch  0, batch   500 | loss: 2.8172789MixupTrain:  epoch  0, batch   501 | loss: 3.1515465MixupTrain:  epoch  0, batch   502 | loss: 2.9672511MixupTrain:  epoch  0, batch   503 | loss: 2.5574553MixupTrain:  epoch  0, batch   504 | loss: 3.2045002MixupTrain:  epoch  0, batch   505 | loss: 3.0373418MixupTrain:  epoch  0, batch   506 | loss: 3.1540437MixupTrain:  epoch  0, batch   507 | loss: 2.8669477MixupTrain:  epoch  0, batch   508 | loss: 3.0281529MixupTrain:  epoch  0, batch   509 | loss: 2.9340425MixupTrain:  epoch  0, batch   510 | loss: 2.8673306MixupTrain:  epoch  0, batch   511 | loss: 2.9882212MixupTrain:  epoch  0, batch   512 | loss: 2.9455645MixupTrain:  epoch  0, batch   513 | loss: 2.8735113MixupTrain:  epoch  0, batch   514 | loss: 3.1148062MixupTrain:  epoch  0, batch   515 | loss: 3.2670352MixupTrain:  epoch  0, batch   516 | loss: 2.8643303MixupTrain:  epoch  0, batch   517 | loss: 2.8421497MixupTrain:  epoch  0, batch   518 | loss: 2.5592067MixupTrain:  epoch  0, batch   519 | loss: 3.5984130MixupTrain:  epoch  0, batch   520 | loss: 3.2839119MixupTrain:  epoch  0, batch   521 | loss: 2.8002748MixupTrain:  epoch  0, batch   522 | loss: 3.3315182MixupTrain:  epoch  0, batch   523 | loss: 2.7767770MixupTrain:  epoch  0, batch   524 | loss: 2.3822880MixupTrain:  epoch  0, batch   525 | loss: 3.2373567MixupTrain:  epoch  0, batch   526 | loss: 2.9003615MixupTrain:  epoch  0, batch   527 | loss: 2.9749947MixupTrain:  epoch  0, batch   528 | loss: 2.8012443MixupTrain:  epoch  0, batch   529 | loss: 3.0097106MixupTrain:  epoch  0, batch   530 | loss: 3.0886793MixupTrain:  epoch  0, batch   531 | loss: 3.0209723MixupTrain:  epoch  0, batch   532 | loss: 2.9919908MixupTrain:  epoch  0, batch   533 | loss: 2.6668887MixupTrain:  epoch  0, batch   534 | loss: 3.3747556MixupTrain:  epoch  0, batch   535 | loss: 2.9800267MixupTrain:  epoch  0, batch   536 | loss: 2.7863858MixupTrain:  epoch  0, batch   537 | loss: 2.6755357MixupTrain:  epoch  0, batch   538 | loss: 3.3472977MixupTrain:  epoch  0, batch   539 | loss: 2.4989414MixupTrain:  epoch  0, batch   540 | loss: 2.4832413MixupTrain:  epoch  0, batch   541 | loss: 2.7730694MixupTrain:  epoch  0, batch   542 | loss: 2.8260458MixupTrain:  epoch  0, batch   543 | loss: 2.9763927MixupTrain:  epoch  0, batch   544 | loss: 2.9917450MixupTrain:  epoch  0, batch   545 | loss: 2.9158082MixupTrain:  epoch  0, batch   546 | loss: 2.6344681MixupTrain:  epoch  0, batch   547 | loss: 2.8021898MixupTrain:  epoch  0, batch   548 | loss: 2.9418459MixupTrain:  epoch  0, batch   549 | loss: 2.8051677MixupTrain:  epoch  0, batch   550 | loss: 2.6815772MixupTrain:  epoch  0, batch   551 | loss: 2.9842162MixupTrain:  epoch  0, batch   552 | loss: 2.7550735MixupTrain:  epoch  0, batch   553 | loss: 3.8773923MixupTrain:  epoch  0, batch   554 | loss: 2.6744406MixupTrain:  epoch  0, batch   555 | loss: 3.1241674MixupTrain:  epoch  0, batch   556 | loss: 2.9240999MixupTrain:  epoch  0, batch   557 | loss: 3.3213787MixupTrain:  epoch  0, batch   558 | loss: 3.1804218MixupTrain:  epoch  0, batch   559 | loss: 2.8447690MixupTrain:  epoch  0, batch   560 | loss: 3.7934647MixupTrain:  epoch  0, batch   561 | loss: 2.5278468MixupTrain:  epoch  0, batch   562 | loss: 2.8643188MixupTrain:  epoch  0, batch   563 | loss: 2.7620356MixupTrain:  epoch  0, batch   564 | loss: 3.2102151MixupTrain:  epoch  0, batch   565 | loss: 3.0186608MixupTrain:  epoch  0, batch   566 | loss: 2.6472321MixupTrain:  epoch  0, batch   567 | loss: 2.7694659MixupTrain:  epoch  0, batch   568 | loss: 2.7886524MixupTrain:  epoch  0, batch   569 | loss: 3.1983290MixupTrain:  epoch  0, batch   570 | loss: 2.7124224MixupTrain:  epoch  0, batch   571 | loss: 2.9798517MixupTrain:  epoch  0, batch   572 | loss: 3.1706631MixupTrain:  epoch  0, batch   573 | loss: 3.3008828MixupTrain:  epoch  0, batch   574 | loss: 2.6317954MixupTrain:  epoch  0, batch   575 | loss: 3.0755310MixupTrain:  epoch  0, batch   576 | loss: 2.6803880MixupTrain:  epoch  0, batch   577 | loss: 2.9507990MixupTrain:  epoch  0, batch   578 | loss: 2.9542403MixupTrain:  epoch  0, batch   579 | loss: 3.1069655MixupTrain:  epoch  0, batch   580 | loss: 2.3934429MixupTrain:  epoch  0, batch   581 | loss: 2.8863440MixupTrain:  epoch  0, batch   582 | loss: 3.1660881MixupTrain:  epoch  0, batch   583 | loss: 2.6481404MixupTrain:  epoch  0, batch   584 | loss: 3.4447196MixupTrain:  epoch  0, batch   585 | loss: 2.7883208MixupTrain:  epoch  0, batch   586 | loss: 2.7806213MixupTrain:  epoch  0, batch   587 | loss: 2.5999618MixupTrain:  epoch  0, batch   588 | loss: 3.1361990MixupTrain:  epoch  0, batch   589 | loss: 3.0578322MixupTrain:  epoch  0, batch   590 | loss: 2.6376112MixupTrain:  epoch  0, batch   591 | loss: 2.8637061MixupTrain:  epoch  0, batch   592 | loss: 2.6037979MixupTrain:  epoch  0, batch   593 | loss: 3.1118162MixupTrain:  epoch  0, batch   594 | loss: 2.5584784MixupTrain:  epoch  0, batch   595 | loss: 3.3925562MixupTrain:  epoch  0, batch   596 | loss: 2.9230702MixupTrain:  epoch  0, batch   597 | loss: 3.0546851MixupTrain:  epoch  0, batch   598 | loss: 2.8182580MixupTrain:  epoch  0, batch   599 | loss: 2.3312359MixupTrain:  epoch  0, batch   600 | loss: 2.5751948MixupTrain:  epoch  0, batch   601 | loss: 2.7012751MixupTrain:  epoch  0, batch   602 | loss: 2.8668447MixupTrain:  epoch  0, batch   603 | loss: 2.4754109MixupTrain:  epoch  0, batch   604 | loss: 3.4213011MixupTrain:  epoch  0, batch   605 | loss: 2.8363433MixupTrain:  epoch  0, batch   606 | loss: 3.3490980MixupTrain:  epoch  0, batch   607 | loss: 2.8684869MixupTrain:  epoch  0, batch   608 | loss: 3.1611671MixupTrain:  epoch  0, batch   609 | loss: 2.0080342MixupTrain:  epoch  0, batch   610 | loss: 3.1858716MixupTrain:  epoch  0, batch   611 | loss: 2.7056251MixupTrain:  epoch  0, batch   612 | loss: 2.8803530MixupTrain:  epoch  0, batch   613 | loss: 2.5173049MixupTrain:  epoch  0, batch   614 | loss: 2.7361715MixupTrain:  epoch  0, batch   615 | loss: 2.8077431MixupTrain:  epoch  0, batch   616 | loss: 2.5484953MixupTrain:  epoch  0, batch   617 | loss: 2.8457265MixupTrain:  epoch  0, batch   618 | loss: 3.2580233MixupTrain:  epoch  0, batch   619 | loss: 2.6884604MixupTrain:  epoch  0, batch   620 | loss: 3.2414050MixupTrain:  epoch  0, batch   621 | loss: 2.7336054MixupTrain:  epoch  0, batch   622 | loss: 2.8061082MixupTrain:  epoch  0, batch   623 | loss: 3.2395263MixupTrain:  epoch  0, batch   624 | loss: 2.9582391MixupTrain:  epoch  0, batch   625 | loss: 3.2099047MixupTrain:  epoch  0, batch   626 | loss: 2.4724638MixupTrain:  epoch  0, batch   627 | loss: 3.4101312MixupTrain:  epoch  0, batch   628 | loss: 2.8657765MixupTrain:  epoch  0, batch   629 | loss: 3.1174259MixupTrain:  epoch  0, batch   630 | loss: 2.7563133MixupTrain:  epoch  0, batch   631 | loss: 2.3412297MixupTrain:  epoch  0, batch   632 | loss: 3.3225677MixupTrain:  epoch  0, batch   633 | loss: 2.4295363MixupTrain:  epoch  0, batch   634 | loss: 2.7600222MixupTrain:  epoch  0, batch   635 | loss: 2.7641759MixupTrain:  epoch  0, batch   636 | loss: 3.0941441MixupTrain:  epoch  0, batch   637 | loss: 2.5958614MixupTrain:  epoch  0, batch   638 | loss: 2.8404512MixupTrain:  epoch  0, batch   639 | loss: 2.6750817MixupTrain:  epoch  0, batch   640 | loss: 2.5584133MixupTrain:  epoch  0, batch   641 | loss: 3.1538391MixupTrain:  epoch  0, batch   642 | loss: 2.9132185MixupTrain:  epoch  0, batch   643 | loss: 2.7885900MixupTrain:  epoch  0, batch   644 | loss: 2.8191185MixupTrain:  epoch  0, batch   645 | loss: 2.7846441MixupTrain:  epoch  0, batch   646 | loss: 3.1075630MixupTrain:  epoch  0, batch   647 | loss: 3.0373106MixupTrain:  epoch  0, batch   648 | loss: 2.7155530MixupTrain:  epoch  0, batch   649 | loss: 3.3744626MixupTrain:  epoch  0, batch   650 | loss: 3.6246784MixupTrain:  epoch  0, batch   651 | loss: 3.2149358MixupTrain:  epoch  0, batch   652 | loss: 3.3543873MixupTrain:  epoch  0, batch   653 | loss: 2.8560333MixupTrain:  epoch  0, batch   654 | loss: 2.8470707MixupTrain:  epoch  0, batch   655 | loss: 3.0412722MixupTrain:  epoch  0, batch   656 | loss: 2.5853367MixupTrain:  epoch  0, batch   657 | loss: 2.8280625MixupTrain:  epoch  0, batch   658 | loss: 2.5522189MixupTrain:  epoch  0, batch   659 | loss: 2.8387074MixupTrain:  epoch  0, batch   660 | loss: 2.7650647MixupTrain:  epoch  0, batch   661 | loss: 3.3412986MixupTrain:  epoch  0, batch   662 | loss: 2.8858986MixupTrain:  epoch  0, batch   663 | loss: 2.5211520MixupTrain:  epoch  0, batch   664 | loss: 2.8976507MixupTrain:  epoch  0, batch   665 | loss: 3.0804913MixupTrain:  epoch  0, batch   666 | loss: 2.9549117MixupTrain:  epoch  0, batch   667 | loss: 3.1491456MixupTrain:  epoch  0, batch   668 | loss: 2.9098160MixupTrain:  epoch  0, batch   669 | loss: 2.8131607MixupTrain:  epoch  0, batch   670 | loss: 2.7973568MixupTrain:  epoch  0, batch   671 | loss: 2.4884572MixupTrain:  epoch  0, batch   672 | loss: 2.7570190MixupTrain:  epoch  0, batch   673 | loss: 3.1432252MixupTrain:  epoch  0, batch   674 | loss: 3.7563159MixupTrain:  epoch  0, batch   675 | loss: 2.6125150MixupTrain:  epoch  0, batch   676 | loss: 2.6834574MixupTrain:  epoch  0, batch   677 | loss: 2.8012938MixupTrain:  epoch  0, batch   678 | loss: 2.4821537MixupTrain:  epoch  0, batch   679 | loss: 2.9795730MixupTrain:  epoch  0, batch   680 | loss: 2.3744912MixupTrain:  epoch  0, batch   681 | loss: 2.7199869MixupTrain:  epoch  0, batch   682 | loss: 2.0410118MixupTrain:  epoch  0, batch   683 | loss: 3.0855265MixupTrain:  epoch  0, batch   684 | loss: 2.8507004MixupTrain:  epoch  0, batch   685 | loss: 2.6410289MixupTrain:  epoch  0, batch   686 | loss: 3.4636693MixupTrain:  epoch  0, batch   687 | loss: 3.0524886MixupTrain:  epoch  0, batch   688 | loss: 2.6277289MixupTrain:  epoch  0, batch   689 | loss: 3.0143390MixupTrain:  epoch  0, batch   690 | loss: 3.1349306MixupTrain:  epoch  0, batch   691 | loss: 2.5984714MixupTrain:  epoch  0, batch   692 | loss: 2.5336635MixupTrain:  epoch  0, batch   693 | loss: 2.7615280MixupTrain:  epoch  0, batch   694 | loss: 2.2782607MixupTrain:  epoch  0, batch   695 | loss: 3.6159449MixupTrain:  epoch  0, batch   696 | loss: 3.0251701MixupTrain:  epoch  0, batch   697 | loss: 2.8126047MixupTrain:  epoch  0, batch   698 | loss: 2.1266115MixupTrain:  epoch  0, batch   699 | loss: 3.1514695MixupTrain:  epoch  0, batch   700 | loss: 3.2147369MixupTrain:  epoch  0, batch   701 | loss: 2.7294188MixupTrain:  epoch  0, batch   702 | loss: 3.1450491MixupTrain:  epoch  0, batch   703 | loss: 2.5303221MixupTrain:  epoch  0, batch   704 | loss: 2.3425317MixupTrain:  epoch  0, batch   705 | loss: 2.6412849MixupTrain:  epoch  0, batch   706 | loss: 2.8461030MixupTrain:  epoch  0, batch   707 | loss: 2.6671810MixupTrain:  epoch  0, batch   708 | loss: 2.6449513MixupTrain:  epoch  0, batch   709 | loss: 2.6821518MixupTrain:  epoch  0, batch   710 | loss: 2.7361455MixupTrain:  epoch  0, batch   711 | loss: 2.4092667MixupTrain:  epoch  0, batch   712 | loss: 2.7340512MixupTrain:  epoch  0, batch   713 | loss: 3.0045881MixupTrain:  epoch  0, batch   714 | loss: 3.0200496MixupTrain:  epoch  0, batch   715 | loss: 2.9370401MixupTrain:  epoch  0, batch   716 | loss: 3.1914864MixupTrain:  epoch  0, batch   717 | loss: 3.0285804MixupTrain:  epoch  0, batch   718 | loss: 3.2355146MixupTrain:  epoch  0, batch   719 | loss: 2.5294693MixupTrain:  epoch  0, batch   720 | loss: 2.7867761MixupTrain:  epoch  0, batch   721 | loss: 3.0149717MixupTrain:  epoch  0, batch   722 | loss: 3.1367588MixupTrain:  epoch  0, batch   723 | loss: 3.2625544MixupTrain:  epoch  0, batch   724 | loss: 3.1739311MixupTrain:  epoch  0, batch   725 | loss: 2.7850647MixupTrain:  epoch  0, batch   726 | loss: 3.1715591MixupTrain:  epoch  0, batch   727 | loss: 2.7524033MixupTrain:  epoch  0, batch   728 | loss: 3.0212328MixupTrain:  epoch  0, batch   729 | loss: 2.6750717MixupTrain:  epoch  0, batch   730 | loss: 2.5858943MixupTrain:  epoch  0, batch   731 | loss: 2.8118837MixupTrain:  epoch  0, batch   732 | loss: 2.7385173MixupTrain:  epoch  0, batch   733 | loss: 3.0292454MixupTrain:  epoch  0, batch   734 | loss: 2.7279625MixupTrain:  epoch  0, batch   735 | loss: 2.6722670MixupTrain:  epoch  0, batch   736 | loss: 3.0861025MixupTrain:  epoch  0, batch   737 | loss: 2.6701841MixupTrain:  epoch  0, batch   738 | loss: 3.0321324MixupTrain:  epoch  0, batch   739 | loss: 2.3765252MixupTrain:  epoch  0, batch   740 | loss: 2.7814946MixupTrain:  epoch  0, batch   741 | loss: 3.1256430MixupTrain:  epoch  0, batch   742 | loss: 3.0405898MixupTrain:  epoch  0, batch   743 | loss: 3.0061817MixupTrain:  epoch  0, batch   744 | loss: 2.8830161MixupTrain:  epoch  0, batch   745 | loss: 3.3454132MixupTrain:  epoch  0, batch   746 | loss: 2.5299661MixupTrain:  epoch  0, batch   747 | loss: 3.0094602MixupTrain:  epoch  0, batch   748 | loss: 3.2132928MixupTrain:  epoch  0, batch   749 | loss: 2.8024714MixupTrain:  epoch  0, batch   750 | loss: 3.1909955MixupTrain:  epoch  0, batch   751 | loss: 2.7272019MixupTrain:  epoch  0, batch   752 | loss: 2.7119794MixupTrain:  epoch  0, batch   753 | loss: 2.7745659MixupTrain:  epoch  0, batch   754 | loss: 2.7572896MixupTrain:  epoch  0, batch   755 | loss: 2.5849140MixupTrain:  epoch  0, batch   756 | loss: 2.4035354MixupTrain:  epoch  0, batch   757 | loss: 2.8893828MixupTrain:  epoch  0, batch   758 | loss: 2.5033493MixupTrain:  epoch  0, batch   759 | loss: 3.1083763MixupTrain:  epoch  0, batch   760 | loss: 2.7998385MixupTrain:  epoch  0, batch   761 | loss: 2.3356524MixupTrain:  epoch  0, batch   762 | loss: 3.0708864MixupTrain:  epoch  0, batch   763 | loss: 2.9771037MixupTrain:  epoch  0, batch   764 | loss: 2.6678710MixupTrain:  epoch  0, batch   765 | loss: 2.7250366MixupTrain:  epoch  0, batch   766 | loss: 3.0176105MixupTrain:  epoch  0, batch   767 | loss: 2.7214696MixupTrain:  epoch  0, batch   768 | loss: 2.5060086MixupTrain:  epoch  0, batch   769 | loss: 2.7889605MixupTrain:  epoch  0, batch   770 | loss: 2.6912067MixupTrain:  epoch  0, batch   771 | loss: 3.0691044MixupTrain:  epoch  0, batch   772 | loss: 2.7053008MixupTrain:  epoch  0, batch   773 | loss: 3.3256588MixupTrain:  epoch  0, batch   774 | loss: 2.8491039MixupTrain:  epoch  0, batch   775 | loss: 2.5389686MixupTrain:  epoch  0, batch   776 | loss: 2.4722850MixupTrain:  epoch  0, batch   777 | loss: 2.5218635MixupTrain:  epoch  0, batch   778 | loss: 2.6034341MixupTrain:  epoch  0, batch   779 | loss: 2.9628921MixupTrain:  epoch  0, batch   780 | loss: 3.5391452MixupTrain:  epoch  0, batch   781 | loss: 3.0277662MixupTrain:  epoch  0, batch   782 | loss: 2.5844979MixupTrain:  epoch  0, batch   783 | loss: 2.5849071MixupTrain:  epoch  0, batch   784 | loss: 3.1529608MixupTrain:  epoch  0, batch   785 | loss: 2.8672738MixupTrain:  epoch  0, batch   786 | loss: 3.1586170MixupTrain:  epoch  0, batch   787 | loss: 2.9947050MixupTrain:  epoch  0, batch   788 | loss: 3.0314889MixupTrain:  epoch  0, batch   789 | loss: 2.3093569MixupTrain:  epoch  0, batch   790 | loss: 3.5870376MixupTrain:  epoch  0, batch   791 | loss: 2.9144659MixupTrain:  epoch  0, batch   792 | loss: 2.5973978MixupTrain:  epoch  0, batch   793 | loss: 2.8934960MixupTrain:  epoch  0, batch   794 | loss: 2.8149786MixupTrain:  epoch  0, batch   795 | loss: 2.8124652MixupTrain:  epoch  0, batch   796 | loss: 2.9108539MixupTrain:  epoch  0, batch   797 | loss: 3.0237017MixupTrain:  epoch  0, batch   798 | loss: 2.5127811MixupTrain:  epoch  0, batch   799 | loss: 2.2755158MixupTrain:  epoch  0, batch   800 | loss: 3.3971078MixupTrain:  epoch  0, batch   801 | loss: 2.6216068MixupTrain:  epoch  0, batch   802 | loss: 2.9661922MixupTrain:  epoch  0, batch   803 | loss: 2.4191229MixupTrain:  epoch  0, batch   804 | loss: 2.3846886MixupTrain:  epoch  0, batch   805 | loss: 2.7396221MixupTrain:  epoch  0, batch   806 | loss: 2.7684526MixupTrain:  epoch  0, batch   807 | loss: 2.9390678MixupTrain:  epoch  0, batch   808 | loss: 2.6777267MixupTrain:  epoch  0, batch   809 | loss: 2.9905112MixupTrain:  epoch  0, batch   810 | loss: 2.6927185MixupTrain:  epoch  0, batch   811 | loss: 2.8353677MixupTrain:  epoch  0, batch   812 | loss: 3.3336306MixupTrain:  epoch  0, batch   813 | loss: 3.0342815MixupTrain:  epoch  0, batch   814 | loss: 3.0380545MixupTrain:  epoch  0, batch   815 | loss: 3.1844621MixupTrain:  epoch  0, batch   816 | loss: 2.6989121MixupTrain:  epoch  0, batch   817 | loss: 3.0265374MixupTrain:  epoch  0, batch   818 | loss: 2.3812842MixupTrain:  epoch  0, batch   819 | loss: 2.8016753MixupTrain:  epoch  0, batch   820 | loss: 2.8004041MixupTrain:  epoch  0, batch   821 | loss: 2.6652541MixupTrain:  epoch  0, batch   822 | loss: 2.8242745MixupTrain:  epoch  0, batch   823 | loss: 2.3703449MixupTrain:  epoch  0, batch   824 | loss: 3.1583376MixupTrain:  epoch  0, batch   825 | loss: 2.8544431MixupTrain:  epoch  0, batch   826 | loss: 2.5675066MixupTrain:  epoch  0, batch   827 | loss: 2.5744460MixupTrain:  epoch  0, batch   828 | loss: 2.5050020MixupTrain:  epoch  0, batch   829 | loss: 2.7771375MixupTrain:  epoch  0, batch   830 | loss: 3.0125465MixupTrain:  epoch  0, batch   831 | loss: 2.5215497MixupTrain:  epoch  0, batch   832 | loss: 3.0148141MixupTrain:  epoch  0, batch   833 | loss: 3.1453934MixupTrain:  epoch  0, batch   834 | loss: 2.8847859MixupTrain:  epoch  0, batch   835 | loss: 2.8242254MixupTrain:  epoch  0, batch   836 | loss: 3.0633612MixupTrain:  epoch  0, batch   837 | loss: 2.9493353MixupTrain:  epoch  0, batch   838 | loss: 2.4337354MixupTrain:  epoch  0, batch   839 | loss: 3.0949144MixupTrain:  epoch  0, batch   840 | loss: 2.5019236MixupTrain:  epoch  0, batch   841 | loss: 2.3569515MixupTrain:  epoch  0, batch   842 | loss: 3.2866306MixupTrain:  epoch  0, batch   843 | loss: 2.9543290MixupTrain:  epoch  0, batch   844 | loss: 2.5728159MixupTrain:  epoch  0, batch   845 | loss: 3.2065086MixupTrain:  epoch  0, batch   846 | loss: 2.9027123MixupTrain:  epoch  0, batch   847 | loss: 2.9818587MixupTrain:  epoch  0, batch   848 | loss: 2.9988594MixupTrain:  epoch  0, batch   849 | loss: 2.6883245MixupTrain:  epoch  0, batch   850 | loss: 2.7406878MixupTrain:  epoch  0, batch   851 | loss: 2.8515341MixupTrain:  epoch  0, batch   852 | loss: 2.5641103MixupTrain:  epoch  0, batch   853 | loss: 3.0426130MixupTrain:  epoch  0, batch   854 | loss: 3.0488858MixupTrain:  epoch  0, batch   855 | loss: 2.9441419MixupTrain:  epoch  0, batch   856 | loss: 2.7223830MixupTrain:  epoch  0, batch   857 | loss: 3.0079427MixupTrain:  epoch  0, batch   858 | loss: 3.0307693MixupTrain:  epoch  0, batch   859 | loss: 3.1873109MixupTrain:  epoch  0, batch   860 | loss: 3.0260293MixupTrain:  epoch  0, batch   861 | loss: 3.5315204MixupTrain:  epoch  0, batch   862 | loss: 2.3603449MixupTrain:  epoch  0, batch   863 | loss: 2.8899202MixupTrain:  epoch  0, batch   864 | loss: 2.8579516MixupTrain:  epoch  0, batch   865 | loss: 2.8421497MixupTrain:  epoch  0, batch   866 | loss: 3.0258675MixupTrain:  epoch  0, batch   867 | loss: 2.5337656MixupTrain:  epoch  0, batch   868 | loss: 2.8739653MixupTrain:  epoch  0, batch   869 | loss: 2.6739936MixupTrain:  epoch  0, batch   870 | loss: 2.8370845MixupTrain:  epoch  0, batch   871 | loss: 2.2873240MixupTrain:  epoch  0, batch   872 | loss: 2.7953434MixupTrain:  epoch  0, batch   873 | loss: 3.0185001MixupTrain:  epoch  0, batch   874 | loss: 2.6138701MixupTrain:  epoch  0, batch   875 | loss: 2.7557502MixupTrain:  epoch  0, batch   876 | loss: 3.4158506MixupTrain:  epoch  0, batch   877 | loss: 2.8852139MixupTrain:  epoch  0, batch   878 | loss: 3.1743436MixupTrain:  epoch  0, batch   879 | loss: 2.5741982MixupTrain:  epoch  0, batch   880 | loss: 2.8993814MixupTrain:  epoch  0, batch   881 | loss: 2.8715482MixupTrain:  epoch  0, batch   882 | loss: 3.2289736MixupTrain:  epoch  0, batch   883 | loss: 2.4025183MixupTrain:  epoch  0, batch   884 | loss: 2.7456970MixupTrain:  epoch  0, batch   885 | loss: 2.6814244MixupTrain:  epoch  0, batch   886 | loss: 2.9825184MixupTrain:  epoch  0, batch   887 | loss: 2.3627038MixupTrain:  epoch  0, batch   888 | loss: 2.8109145MixupTrain:  epoch  0, batch   889 | loss: 2.9658089MixupTrain:  epoch  0, batch   890 | loss: 3.2835238MixupTrain:  epoch  0, batch   891 | loss: 3.0894089MixupTrain:  epoch  0, batch   892 | loss: 2.2818446MixupTrain:  epoch  0, batch   893 | loss: 3.4588642MixupTrain:  epoch  0, batch   894 | loss: 2.6279597MixupTrain:  epoch  0, batch   895 | loss: 2.5920935MixupTrain:  epoch  0, batch   896 | loss: 3.0021152MixupTrain:  epoch  0, batch   897 | loss: 2.5045667MixupTrain:  epoch  0, batch   898 | loss: 2.6239994MixupTrain:  epoch  0, batch   899 | loss: 2.8777905MixupTrain:  epoch  0, batch   900 | loss: 3.0380809MixupTrain:  epoch  0, batch   901 | loss: 2.8311353MixupTrain:  epoch  0, batch   902 | loss: 2.4774189MixupTrain:  epoch  0, batch   903 | loss: 2.5295925MixupTrain:  epoch  0, batch   904 | loss: 2.5109909MixupTrain:  epoch  0, batch   905 | loss: 2.5748718MixupTrain:  epoch  0, batch   906 | loss: 2.4666204MixupTrain:  epoch  0, batch   907 | loss: 2.8159227MixupTrain:  epoch  0, batch   908 | loss: 2.9006593MixupTrain:  epoch  0, batch   909 | loss: 3.0303440MixupTrain:  epoch  0, batch   910 | loss: 2.9790969MixupTrain:  epoch  0, batch   911 | loss: 2.8631277MixupTrain:  epoch  0, batch   912 | loss: 2.7691994MixupTrain:  epoch  0, batch   913 | loss: 3.0269589MixupTrain:  epoch  0, batch   914 | loss: 2.3886733MixupTrain:  epoch  0, batch   915 | loss: 2.7530632MixupTrain:  epoch  0, batch   916 | loss: 2.8638110MixupTrain:  epoch  0, batch   917 | loss: 2.7309442MixupTrain:  epoch  0, batch   918 | loss: 2.6860285MixupTrain:  epoch  0, batch   919 | loss: 2.6427083MixupTrain:  epoch  0, batch   920 | loss: 2.5289850MixupTrain:  epoch  0, batch   921 | loss: 3.0671082MixupTrain:  epoch  0, batch   922 | loss: 2.5475421MixupTrain:  epoch  0, batch   923 | loss: 2.8628845MixupTrain:  epoch  0, batch   924 | loss: 2.4380693MixupTrain:  epoch  0, batch   925 | loss: 3.0501018MixupTrain:  epoch  0, batch   926 | loss: 3.0343845MixupTrain:  epoch  0, batch   927 | loss: 2.4557700MixupTrain:  epoch  0, batch   928 | loss: 2.6432977MixupTrain:  epoch  0, batch   929 | loss: 2.5091438MixupTrain:  epoch  0, batch   930 | loss: 3.0295901MixupTrain:  epoch  0, batch   931 | loss: 3.4744258MixupTrain:  epoch  0, batch   932 | loss: 2.9503813MixupTrain:  epoch  0, batch   933 | loss: 2.3635597MixupTrain:  epoch  0, batch   934 | loss: 3.1026492MixupTrain:  epoch  0, batch   935 | loss: 2.4858747MixupTrain:  epoch  0, batch   936 | loss: 3.2213302MixupTrain:  epoch  0, batch   937 | loss: 3.2086766MixupTrain:  epoch  0, batch   938 | loss: 2.9612615MixupTrain:  epoch  0, batch   939 | loss: 3.4874473MixupTrain:  epoch  0, batch   940 | loss: 2.9931049MixupTrain:  epoch  0, batch   941 | loss: 2.6155920MixupTrain:  epoch  0, batch   942 | loss: 3.6192226MixupTrain:  epoch  0, batch   943 | loss: 2.4870675MixupTrain:  epoch  0, batch   944 | loss: 2.7006016MixupTrain:  epoch  0, batch   945 | loss: 2.6911502MixupTrain:  epoch  0, batch   946 | loss: 2.6871789MixupTrain:  epoch  0, batch   947 | loss: 2.5662613MixupTrain:  epoch  0, batch   948 | loss: 2.7945151MixupTrain:  epoch  0, batch   949 | loss: 2.9687796MixupTrain:  epoch  0, batch   950 | loss: 3.2778797MixupTrain:  epoch  0, batch   951 | loss: 2.4019885MixupTrain:  epoch  0, batch   952 | loss: 3.1038837MixupTrain:  epoch  0, batch   953 | loss: 3.1330986MixupTrain:  epoch  0, batch   954 | loss: 2.8423264MixupTrain:  epoch  0, batch   955 | loss: 2.9960790MixupTrain:  epoch  0, batch   956 | loss: 2.6371977MixupTrain:  epoch  0, batch   957 | loss: 3.1201057MixupTrain:  epoch  0, batch   958 | loss: 2.7127504MixupTrain:  epoch  0, batch   959 | loss: 2.7826207MixupTrain:  epoch  0, batch   960 | loss: 2.5889225MixupTrain:  epoch  0, batch   961 | loss: 2.7664714MixupTrain:  epoch  0, batch   962 | loss: 2.9383230MixupTrain:  epoch  0, batch   963 | loss: 2.8830109MixupTrain:  epoch  0, batch   964 | loss: 2.7651739MixupTrain:  epoch  0, batch   965 | loss: 2.5658140MixupTrain:  epoch  0, batch   966 | loss: 3.0085444MixupTrain:  epoch  0, batch   967 | loss: 2.7674737MixupTrain:  epoch  0, batch   968 | loss: 2.5152607MixupTrain:  epoch  0, batch   969 | loss: 2.8909194MixupTrain:  epoch  0, batch   970 | loss: 2.8859954MixupTrain:  epoch  0, batch   971 | loss: 3.0992889MixupTrain:  epoch  0, batch   972 | loss: 3.1201863MixupTrain:  epoch  0, batch   973 | loss: 2.9607496MixupTrain:  epoch  0, batch   974 | loss: 2.4329135MixupTrain:  epoch  0, batch   975 | loss: 3.1647379MixupTrain:  epoch  0, batch   976 | loss: 2.7316303MixupTrain:  epoch  0, batch   977 | loss: 2.6505518MixupTrain:  epoch  0, batch   978 | loss: 3.0375600MixupTrain:  epoch  0, batch   979 | loss: 2.7763801MixupTrain:  epoch  0, batch   980 | loss: 2.6018338MixupTrain:  epoch  0, batch   981 | loss: 2.4867115
MemoryTrain:  epoch  0, batch     0 | loss: 2.6897430MemoryTrain:  epoch  0, batch     1 | loss: 3.0200310MemoryTrain:  epoch  0, batch     2 | loss: 3.9441128MemoryTrain:  epoch  0, batch     3 | loss: 4.0303316MemoryTrain:  epoch  0, batch     4 | loss: 2.6231122MemoryTrain:  epoch  0, batch     5 | loss: 2.5036147MemoryTrain:  epoch  0, batch     6 | loss: 2.3879309MemoryTrain:  epoch  0, batch     7 | loss: 4.4554911MemoryTrain:  epoch  0, batch     8 | loss: 3.6264303MemoryTrain:  epoch  0, batch     9 | loss: 2.0883029MemoryTrain:  epoch  1, batch     0 | loss: 2.1547873MemoryTrain:  epoch  1, batch     1 | loss: 2.0376911MemoryTrain:  epoch  1, batch     2 | loss: 1.8240404MemoryTrain:  epoch  1, batch     3 | loss: 1.8283292MemoryTrain:  epoch  1, batch     4 | loss: 3.0420699MemoryTrain:  epoch  1, batch     5 | loss: 2.4071496MemoryTrain:  epoch  1, batch     6 | loss: 2.1454427MemoryTrain:  epoch  1, batch     7 | loss: 1.8483919MemoryTrain:  epoch  1, batch     8 | loss: 2.3913436MemoryTrain:  epoch  1, batch     9 | loss: 1.9806465MemoryTrain:  epoch  2, batch     0 | loss: 1.8326395MemoryTrain:  epoch  2, batch     1 | loss: 1.9448687MemoryTrain:  epoch  2, batch     2 | loss: 1.9922088MemoryTrain:  epoch  2, batch     3 | loss: 1.8186853MemoryTrain:  epoch  2, batch     4 | loss: 2.6980205MemoryTrain:  epoch  2, batch     5 | loss: 2.0477061MemoryTrain:  epoch  2, batch     6 | loss: 1.8169832MemoryTrain:  epoch  2, batch     7 | loss: 1.8345146MemoryTrain:  epoch  2, batch     8 | loss: 1.8139210MemoryTrain:  epoch  2, batch     9 | loss: 1.9428682MemoryTrain:  epoch  3, batch     0 | loss: 1.8312266MemoryTrain:  epoch  3, batch     1 | loss: 1.8343123MemoryTrain:  epoch  3, batch     2 | loss: 1.8610632MemoryTrain:  epoch  3, batch     3 | loss: 1.8569719MemoryTrain:  epoch  3, batch     4 | loss: 1.8248755MemoryTrain:  epoch  3, batch     5 | loss: 1.8201642MemoryTrain:  epoch  3, batch     6 | loss: 1.8796144MemoryTrain:  epoch  3, batch     7 | loss: 1.8201814MemoryTrain:  epoch  3, batch     8 | loss: 1.9102666MemoryTrain:  epoch  3, batch     9 | loss: 1.8090986MemoryTrain:  epoch  4, batch     0 | loss: 1.8221672MemoryTrain:  epoch  4, batch     1 | loss: 1.8340809MemoryTrain:  epoch  4, batch     2 | loss: 1.8294954MemoryTrain:  epoch  4, batch     3 | loss: 1.8469076MemoryTrain:  epoch  4, batch     4 | loss: 1.8494794MemoryTrain:  epoch  4, batch     5 | loss: 1.8158296MemoryTrain:  epoch  4, batch     6 | loss: 1.8218830MemoryTrain:  epoch  4, batch     7 | loss: 1.8260467MemoryTrain:  epoch  4, batch     8 | loss: 1.8946106MemoryTrain:  epoch  4, batch     9 | loss: 1.9030857MemoryTrain:  epoch  5, batch     0 | loss: 1.8459176MemoryTrain:  epoch  5, batch     1 | loss: 1.8470161MemoryTrain:  epoch  5, batch     2 | loss: 1.9467659MemoryTrain:  epoch  5, batch     3 | loss: 1.8384225MemoryTrain:  epoch  5, batch     4 | loss: 1.8170618MemoryTrain:  epoch  5, batch     5 | loss: 1.8178749MemoryTrain:  epoch  5, batch     6 | loss: 1.8337402MemoryTrain:  epoch  5, batch     7 | loss: 1.8146167MemoryTrain:  epoch  5, batch     8 | loss: 1.8285365MemoryTrain:  epoch  5, batch     9 | loss: 1.8856248MemoryTrain:  epoch  6, batch     0 | loss: 1.8223631MemoryTrain:  epoch  6, batch     1 | loss: 1.8857043MemoryTrain:  epoch  6, batch     2 | loss: 1.8361001MemoryTrain:  epoch  6, batch     3 | loss: 1.8565440MemoryTrain:  epoch  6, batch     4 | loss: 1.8597469MemoryTrain:  epoch  6, batch     5 | loss: 1.8339897MemoryTrain:  epoch  6, batch     6 | loss: 1.8545613MemoryTrain:  epoch  6, batch     7 | loss: 1.8285594MemoryTrain:  epoch  6, batch     8 | loss: 1.8559158MemoryTrain:  epoch  6, batch     9 | loss: 1.8100545MemoryTrain:  epoch  7, batch     0 | loss: 1.8306558MemoryTrain:  epoch  7, batch     1 | loss: 1.8326321MemoryTrain:  epoch  7, batch     2 | loss: 1.8419045MemoryTrain:  epoch  7, batch     3 | loss: 1.8341873MemoryTrain:  epoch  7, batch     4 | loss: 1.8216647MemoryTrain:  epoch  7, batch     5 | loss: 1.8186843MemoryTrain:  epoch  7, batch     6 | loss: 1.8156790MemoryTrain:  epoch  7, batch     7 | loss: 1.8264856MemoryTrain:  epoch  7, batch     8 | loss: 1.8228500MemoryTrain:  epoch  7, batch     9 | loss: 1.8224010MemoryTrain:  epoch  8, batch     0 | loss: 1.8228111MemoryTrain:  epoch  8, batch     1 | loss: 1.8248608MemoryTrain:  epoch  8, batch     2 | loss: 1.8193824MemoryTrain:  epoch  8, batch     3 | loss: 1.8126924MemoryTrain:  epoch  8, batch     4 | loss: 1.8195231MemoryTrain:  epoch  8, batch     5 | loss: 1.8228542MemoryTrain:  epoch  8, batch     6 | loss: 1.8343058MemoryTrain:  epoch  8, batch     7 | loss: 1.8213218MemoryTrain:  epoch  8, batch     8 | loss: 1.8289708MemoryTrain:  epoch  8, batch     9 | loss: 1.8166984MemoryTrain:  epoch  9, batch     0 | loss: 1.8183405MemoryTrain:  epoch  9, batch     1 | loss: 1.8330375MemoryTrain:  epoch  9, batch     2 | loss: 1.8273960MemoryTrain:  epoch  9, batch     3 | loss: 1.8262657MemoryTrain:  epoch  9, batch     4 | loss: 1.8213028MemoryTrain:  epoch  9, batch     5 | loss: 1.8200073MemoryTrain:  epoch  9, batch     6 | loss: 1.8224263MemoryTrain:  epoch  9, batch     7 | loss: 1.8316754MemoryTrain:  epoch  9, batch     8 | loss: 1.8184996MemoryTrain:  epoch  9, batch     9 | loss: 1.8173063
[EVAL] batch:    0 | acc: 12.50%,  total acc: 12.50%   [EVAL] batch:    1 | acc: 31.25%,  total acc: 21.88%   [EVAL] batch:    2 | acc: 12.50%,  total acc: 18.75%   [EVAL] batch:    3 | acc: 25.00%,  total acc: 20.31%   [EVAL] batch:    4 | acc: 50.00%,  total acc: 26.25%   [EVAL] batch:    5 | acc: 43.75%,  total acc: 29.17%   [EVAL] batch:    6 | acc: 62.50%,  total acc: 33.93%   [EVAL] batch:    7 | acc: 62.50%,  total acc: 37.50%   [EVAL] batch:    8 | acc: 18.75%,  total acc: 35.42%   [EVAL] batch:    9 | acc: 68.75%,  total acc: 38.75%   [EVAL] batch:   10 | acc: 62.50%,  total acc: 40.91%   [EVAL] batch:   11 | acc: 56.25%,  total acc: 42.19%   [EVAL] batch:   12 | acc: 56.25%,  total acc: 43.27%   [EVAL] batch:   13 | acc: 100.00%,  total acc: 47.32%   [EVAL] batch:   14 | acc: 100.00%,  total acc: 50.83%   [EVAL] batch:   15 | acc: 93.75%,  total acc: 53.52%   [EVAL] batch:   16 | acc: 100.00%,  total acc: 56.25%   [EVAL] batch:   17 | acc: 81.25%,  total acc: 57.64%   [EVAL] batch:   18 | acc: 43.75%,  total acc: 56.91%   [EVAL] batch:   19 | acc: 62.50%,  total acc: 57.19%   [EVAL] batch:   20 | acc: 50.00%,  total acc: 56.85%   [EVAL] batch:   21 | acc: 31.25%,  total acc: 55.68%   
[EVAL] batch:    0 | acc: 12.50%,  total acc: 12.50%   [EVAL] batch:    1 | acc: 31.25%,  total acc: 21.88%   [EVAL] batch:    2 | acc: 37.50%,  total acc: 27.08%   [EVAL] batch:    3 | acc: 6.25%,  total acc: 21.88%   [EVAL] batch:    4 | acc: 25.00%,  total acc: 22.50%   [EVAL] batch:    5 | acc: 31.25%,  total acc: 23.96%   [EVAL] batch:    6 | acc: 37.50%,  total acc: 25.89%   [EVAL] batch:    7 | acc: 18.75%,  total acc: 25.00%   [EVAL] batch:    8 | acc: 43.75%,  total acc: 27.08%   [EVAL] batch:    9 | acc: 12.50%,  total acc: 25.62%   [EVAL] batch:   10 | acc: 25.00%,  total acc: 25.57%   [EVAL] batch:   11 | acc: 50.00%,  total acc: 27.60%   [EVAL] batch:   12 | acc: 12.50%,  total acc: 26.44%   [EVAL] batch:   13 | acc: 25.00%,  total acc: 26.34%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 29.58%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 31.25%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 33.82%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 35.42%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 36.84%   [EVAL] batch:   19 | acc: 87.50%,  total acc: 39.38%   [EVAL] batch:   20 | acc: 93.75%,  total acc: 41.96%   [EVAL] batch:   21 | acc: 87.50%,  total acc: 44.03%   [EVAL] batch:   22 | acc: 87.50%,  total acc: 45.92%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 47.92%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 49.75%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 51.68%   [EVAL] batch:   26 | acc: 43.75%,  total acc: 51.39%   [EVAL] batch:   27 | acc: 12.50%,  total acc: 50.00%   [EVAL] batch:   28 | acc: 0.00%,  total acc: 48.28%   [EVAL] batch:   29 | acc: 18.75%,  total acc: 47.29%   [EVAL] batch:   30 | acc: 25.00%,  total acc: 46.57%   [EVAL] batch:   31 | acc: 6.25%,  total acc: 45.31%   [EVAL] batch:   32 | acc: 62.50%,  total acc: 45.83%   [EVAL] batch:   33 | acc: 18.75%,  total acc: 45.04%   [EVAL] batch:   34 | acc: 25.00%,  total acc: 44.46%   [EVAL] batch:   35 | acc: 12.50%,  total acc: 43.58%   [EVAL] batch:   36 | acc: 0.00%,  total acc: 42.40%   [EVAL] batch:   37 | acc: 18.75%,  total acc: 41.78%   [EVAL] batch:   38 | acc: 18.75%,  total acc: 41.19%   [EVAL] batch:   39 | acc: 75.00%,  total acc: 42.03%   [EVAL] batch:   40 | acc: 93.75%,  total acc: 43.29%   [EVAL] batch:   41 | acc: 87.50%,  total acc: 44.35%   [EVAL] batch:   42 | acc: 93.75%,  total acc: 45.49%   [EVAL] batch:   43 | acc: 81.25%,  total acc: 46.31%   [EVAL] batch:   44 | acc: 93.75%,  total acc: 47.36%   [EVAL] batch:   45 | acc: 75.00%,  total acc: 47.96%   [EVAL] batch:   46 | acc: 68.75%,  total acc: 48.40%   [EVAL] batch:   47 | acc: 81.25%,  total acc: 49.09%   [EVAL] batch:   48 | acc: 31.25%,  total acc: 48.72%   [EVAL] batch:   49 | acc: 93.75%,  total acc: 49.62%   [EVAL] batch:   50 | acc: 81.25%,  total acc: 50.25%   [EVAL] batch:   51 | acc: 93.75%,  total acc: 51.08%   [EVAL] batch:   52 | acc: 93.75%,  total acc: 51.89%   [EVAL] batch:   53 | acc: 100.00%,  total acc: 52.78%   [EVAL] batch:   54 | acc: 100.00%,  total acc: 53.64%   [EVAL] batch:   55 | acc: 100.00%,  total acc: 54.46%   [EVAL] batch:   56 | acc: 87.50%,  total acc: 55.04%   [EVAL] batch:   57 | acc: 75.00%,  total acc: 55.39%   [EVAL] batch:   58 | acc: 93.75%,  total acc: 56.04%   [EVAL] batch:   59 | acc: 93.75%,  total acc: 56.67%   [EVAL] batch:   60 | acc: 31.25%,  total acc: 56.25%   [EVAL] batch:   61 | acc: 6.25%,  total acc: 55.44%   [EVAL] batch:   62 | acc: 12.50%,  total acc: 54.76%   [EVAL] batch:   63 | acc: 37.50%,  total acc: 54.49%   [EVAL] batch:   64 | acc: 93.75%,  total acc: 55.10%   [EVAL] batch:   65 | acc: 75.00%,  total acc: 55.40%   [EVAL] batch:   66 | acc: 18.75%,  total acc: 54.85%   [EVAL] batch:   67 | acc: 31.25%,  total acc: 54.50%   [EVAL] batch:   68 | acc: 6.25%,  total acc: 53.80%   [EVAL] batch:   69 | acc: 25.00%,  total acc: 53.39%   [EVAL] batch:   70 | acc: 56.25%,  total acc: 53.43%   [EVAL] batch:   71 | acc: 43.75%,  total acc: 53.30%   [EVAL] batch:   72 | acc: 62.50%,  total acc: 53.42%   [EVAL] batch:   73 | acc: 50.00%,  total acc: 53.38%   [EVAL] batch:   74 | acc: 31.25%,  total acc: 53.08%   [EVAL] batch:   75 | acc: 81.25%,  total acc: 53.45%   [EVAL] batch:   76 | acc: 43.75%,  total acc: 53.33%   [EVAL] batch:   77 | acc: 68.75%,  total acc: 53.53%   [EVAL] batch:   78 | acc: 62.50%,  total acc: 53.64%   [EVAL] batch:   79 | acc: 100.00%,  total acc: 54.22%   [EVAL] batch:   80 | acc: 100.00%,  total acc: 54.78%   [EVAL] batch:   81 | acc: 93.75%,  total acc: 55.26%   [EVAL] batch:   82 | acc: 93.75%,  total acc: 55.72%   [EVAL] batch:   83 | acc: 75.00%,  total acc: 55.95%   [EVAL] batch:   84 | acc: 50.00%,  total acc: 55.88%   [EVAL] batch:   85 | acc: 56.25%,  total acc: 55.89%   [EVAL] batch:   86 | acc: 56.25%,  total acc: 55.89%   [EVAL] batch:   87 | acc: 12.50%,  total acc: 55.40%   
cur_acc:  ['0.8712', '0.9107', '0.8281', '0.8846', '0.5568']
his_acc:  ['0.8712', '0.8697', '0.6771', '0.5862', '0.5540']
CurrentTrain: epoch  0, batch     0 | loss: 3.7572038CurrentTrain: epoch  0, batch     1 | loss: 3.6342986CurrentTrain: epoch  1, batch     0 | loss: 2.7895756CurrentTrain: epoch  1, batch     1 | loss: 2.5799737CurrentTrain: epoch  2, batch     0 | loss: 2.3223946CurrentTrain: epoch  2, batch     1 | loss: 1.9846390CurrentTrain: epoch  3, batch     0 | loss: 1.9911386CurrentTrain: epoch  3, batch     1 | loss: 2.0806694CurrentTrain: epoch  4, batch     0 | loss: 1.9570315CurrentTrain: epoch  4, batch     1 | loss: 1.7909859CurrentTrain: epoch  5, batch     0 | loss: 1.7834448CurrentTrain: epoch  5, batch     1 | loss: 1.7317433CurrentTrain: epoch  6, batch     0 | loss: 1.7388721CurrentTrain: epoch  6, batch     1 | loss: 1.7742954CurrentTrain: epoch  7, batch     0 | loss: 1.7204969CurrentTrain: epoch  7, batch     1 | loss: 1.7229563CurrentTrain: epoch  8, batch     0 | loss: 1.7388017CurrentTrain: epoch  8, batch     1 | loss: 1.7108091CurrentTrain: epoch  9, batch     0 | loss: 1.7075560CurrentTrain: epoch  9, batch     1 | loss: 1.7036246
#### organization founded ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization founded" means an organization was found in a date.
Here is an example:
Relation: organization founded
Context: the jnf was founded in 1901 to buy plots in palestine , then ruled by the ottomans .
Head Entity: jnf
Tail Entity: 1901
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization founded":
Relation: organization founded  
Context: the united nations was established in 1945 to promote international cooperation and peace.  
Head Entity: united nations  
Tail Entity: 1945  

Relation: organization founded  
Context: apple inc. was founded in 1976 by steve jobs, steve wozniak, and ronald wayne.  
Head Entity: apple inc.  
Tail Entity: 1976  

Relation: organization founded  
Context: the world health organization was created in 1948 to coordinate global health efforts.  
Head Entity: world health organization  
Tail Entity: 1948  

Relation: organization founded  
Context: the national aeronautics and space administration was formed in 1958 to oversee the nation's civilian space program.  
Head Entity: national aeronautics and space administration  
Tail Entity: 1958  

Relation: organization founded  
Context: the european union was established by the maastricht treaty in 1993 to enhance political and economic integration among member states.  
Head Entity: european union  
Tail Entity: 1993  
#### person age ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person age" means a person 's age is a number.
Here is an example:
Relation: person age
Context: virginia republican jo ann davis passed away on saturday at the age of 57 .
Head Entity: jo ann davis
Tail Entity: 57
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person age":
Relation: person age  
Context: the famous actor robert downey jr. celebrated his 56th birthday last week.  
Head Entity: robert downey jr.  
Tail Entity: 56  

Relation: person age  
Context: on her 30th birthday, emily decided to throw a big party for her friends.  
Head Entity: emily  
Tail Entity: 30  

Relation: person age  
Context: the renowned scientist dr. jane goodall is currently 89 years old.  
Head Entity: dr. jane goodall  
Tail Entity: 89  

Relation: person age  
Context: last year, my grandfather turned 80, and we had a family reunion to celebrate.  
Head Entity: my grandfather  
Tail Entity: 80  

Relation: person age  
Context: the youngest member of the team, 22-year-old sarah, impressed everyone with her skills.  
Head Entity: sarah  
Tail Entity: 22  
#### person city of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person city of birth" means a person was born in a city.
Here is an example:
Relation: person city of birth
Context: rothman was born in san francisco in 1932 in an orthodox jewish family .
Head Entity: rothman
Tail Entity: san francisco
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person city of birth":
Relation: person city of birth  
Context: elena was born in barcelona and spent her childhood there before moving to madrid.  
Head Entity: elena  
Tail Entity: barcelona  

Relation: person city of birth  
Context: during the summer of 1985, john was born in new orleans, a city known for its vibrant culture.  
Head Entity: john  
Tail Entity: new orleans  

Relation: person city of birth  
Context: after years of research, we discovered that the famous artist was born in florence, a city rich in art history.  
Head Entity: the famous artist  
Tail Entity: florence  

Relation: person city of birth  
Context: in a small town near the coast, maria was born in san diego, where the sun shines almost every day.  
Head Entity: maria  
Tail Entity: san diego  

Relation: person city of birth  
Context: the renowned scientist was born in tokyo, a bustling metropolis that blends tradition and modernity.  
Head Entity: the renowned scientist  
Tail Entity: tokyo  
#### organization members ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization members" means an organization 's member is an organization.
Here is an example:
Relation: organization members
Context: sun plays for the grand rapids flight of the international basketball league after toiling for the maryland nighthawks of the american basketball association , both development leagues for those who dream of an nba career .
Head Entity: american basketball association
Tail Entity: maryland nighthawks
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization members":
Relation: organization members  
Context: The New York Philharmonic is one of the oldest orchestras in the United States, and it has a long history of collaboration with various chamber music groups, including the New York String Orchestra.  
Head Entity: New York Philharmonic  
Tail Entity: New York String Orchestra  

Relation: organization members  
Context: The National Football League has numerous teams, and the Dallas Cowboys are one of its most famous franchises, known for their loyal fan base and rich history.  
Head Entity: National Football League  
Tail Entity: Dallas Cowboys  

Relation: organization members  
Context: The United Nations consists of various specialized agencies, including the World Health Organization, which focuses on global health issues.  
Head Entity: United Nations  
Tail Entity: World Health Organization  

Relation: organization members  
Context: The International Olympic Committee oversees the Olympic Games and has many national committees, such as the United States Olympic and Paralympic Committee.  
Head Entity: International Olympic Committee  
Tail Entity: United States Olympic and Paralympic Committee  

Relation: organization members  
Context: The European Union is made up of several member states, including Germany, which plays a significant role in the EU's economic policies.  
Head Entity: European Union  
Tail Entity: Germany  
#### person religion ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person religion" means an person is the member of a religion.
Here is an example:
Relation: person religion
Context: the pope defended his action on the grounds that he could not refuse an audience to a head of state from a country with a strong catholic tradition unless he had clear-cut proof of the allegations against him .
Head Entity: he
Tail Entity: catholic
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person religion":
Relation: person religion  
Context: During the ceremony, the rabbi spoke about the importance of faith and community in Judaism, emphasizing how every member plays a vital role.  
Head Entity: rabbi  
Tail Entity: Judaism  

Relation: person religion  
Context: The famous author often discussed her experiences growing up in a Muslim household and how it shaped her worldview.  
Head Entity: author  
Tail Entity: Muslim  

Relation: person religion  
Context: As a devout follower, he regularly attends services at the local church and participates in various community outreach programs.  
Head Entity: he  
Tail Entity: church  

Relation: person religion  
Context: The activist shared her journey of converting to Buddhism and how it has influenced her approach to life and social justice.  
Head Entity: activist  
Tail Entity: Buddhism  

Relation: person religion  
Context: The historian noted that many of the founding fathers were influenced by their Christian beliefs when drafting the Constitution.  
Head Entity: founding fathers  
Tail Entity: Christian  
Mixup data size:  21490
MixupTrain:  epoch  0, batch     0 | loss: 5.4397798MixupTrain:  epoch  0, batch     1 | loss: 4.8160348MixupTrain:  epoch  0, batch     2 | loss: 4.8083620MixupTrain:  epoch  0, batch     3 | loss: 4.1167197MixupTrain:  epoch  0, batch     4 | loss: 3.6677666MixupTrain:  epoch  0, batch     5 | loss: 3.8319764MixupTrain:  epoch  0, batch     6 | loss: 4.0008554MixupTrain:  epoch  0, batch     7 | loss: 4.1066642MixupTrain:  epoch  0, batch     8 | loss: 3.1882250MixupTrain:  epoch  0, batch     9 | loss: 4.0808706MixupTrain:  epoch  0, batch    10 | loss: 3.9699841MixupTrain:  epoch  0, batch    11 | loss: 3.9153910MixupTrain:  epoch  0, batch    12 | loss: 3.7282867MixupTrain:  epoch  0, batch    13 | loss: 4.0531349MixupTrain:  epoch  0, batch    14 | loss: 4.2822151MixupTrain:  epoch  0, batch    15 | loss: 4.1311440MixupTrain:  epoch  0, batch    16 | loss: 4.6229095MixupTrain:  epoch  0, batch    17 | loss: 4.7392092MixupTrain:  epoch  0, batch    18 | loss: 3.4284201MixupTrain:  epoch  0, batch    19 | loss: 4.0079827MixupTrain:  epoch  0, batch    20 | loss: 3.9816029MixupTrain:  epoch  0, batch    21 | loss: 3.4919057MixupTrain:  epoch  0, batch    22 | loss: 2.9126601MixupTrain:  epoch  0, batch    23 | loss: 4.0943952MixupTrain:  epoch  0, batch    24 | loss: 4.0711417MixupTrain:  epoch  0, batch    25 | loss: 3.6568580MixupTrain:  epoch  0, batch    26 | loss: 3.8876882MixupTrain:  epoch  0, batch    27 | loss: 3.5687351MixupTrain:  epoch  0, batch    28 | loss: 3.7232099MixupTrain:  epoch  0, batch    29 | loss: 4.1825418MixupTrain:  epoch  0, batch    30 | loss: 3.4454379MixupTrain:  epoch  0, batch    31 | loss: 3.3016119MixupTrain:  epoch  0, batch    32 | loss: 3.7550778MixupTrain:  epoch  0, batch    33 | loss: 3.6276860MixupTrain:  epoch  0, batch    34 | loss: 4.1034107MixupTrain:  epoch  0, batch    35 | loss: 3.2534792MixupTrain:  epoch  0, batch    36 | loss: 3.1718078MixupTrain:  epoch  0, batch    37 | loss: 3.4280696MixupTrain:  epoch  0, batch    38 | loss: 3.4212596MixupTrain:  epoch  0, batch    39 | loss: 3.3812413MixupTrain:  epoch  0, batch    40 | loss: 3.5432687MixupTrain:  epoch  0, batch    41 | loss: 3.3137963MixupTrain:  epoch  0, batch    42 | loss: 2.8227885MixupTrain:  epoch  0, batch    43 | loss: 3.4456768MixupTrain:  epoch  0, batch    44 | loss: 2.7661295MixupTrain:  epoch  0, batch    45 | loss: 3.2866116MixupTrain:  epoch  0, batch    46 | loss: 2.7353039MixupTrain:  epoch  0, batch    47 | loss: 3.2414820MixupTrain:  epoch  0, batch    48 | loss: 3.2398658MixupTrain:  epoch  0, batch    49 | loss: 3.0564132MixupTrain:  epoch  0, batch    50 | loss: 3.2849174MixupTrain:  epoch  0, batch    51 | loss: 3.4290972MixupTrain:  epoch  0, batch    52 | loss: 3.1662669MixupTrain:  epoch  0, batch    53 | loss: 3.1782088MixupTrain:  epoch  0, batch    54 | loss: 3.5902412MixupTrain:  epoch  0, batch    55 | loss: 2.9436176MixupTrain:  epoch  0, batch    56 | loss: 3.5175195MixupTrain:  epoch  0, batch    57 | loss: 2.5909190MixupTrain:  epoch  0, batch    58 | loss: 2.6256227MixupTrain:  epoch  0, batch    59 | loss: 3.3240337MixupTrain:  epoch  0, batch    60 | loss: 2.8074150MixupTrain:  epoch  0, batch    61 | loss: 3.1166186MixupTrain:  epoch  0, batch    62 | loss: 2.9192266MixupTrain:  epoch  0, batch    63 | loss: 3.2691894MixupTrain:  epoch  0, batch    64 | loss: 3.8650970MixupTrain:  epoch  0, batch    65 | loss: 3.0985069MixupTrain:  epoch  0, batch    66 | loss: 3.3503027MixupTrain:  epoch  0, batch    67 | loss: 3.5368433MixupTrain:  epoch  0, batch    68 | loss: 2.9922152MixupTrain:  epoch  0, batch    69 | loss: 3.1591406MixupTrain:  epoch  0, batch    70 | loss: 2.9332962MixupTrain:  epoch  0, batch    71 | loss: 2.7873054MixupTrain:  epoch  0, batch    72 | loss: 2.7097678MixupTrain:  epoch  0, batch    73 | loss: 2.6762257MixupTrain:  epoch  0, batch    74 | loss: 3.0885053MixupTrain:  epoch  0, batch    75 | loss: 2.6669769MixupTrain:  epoch  0, batch    76 | loss: 2.9041438MixupTrain:  epoch  0, batch    77 | loss: 2.5382378MixupTrain:  epoch  0, batch    78 | loss: 2.7352729MixupTrain:  epoch  0, batch    79 | loss: 2.4182968MixupTrain:  epoch  0, batch    80 | loss: 3.4451299MixupTrain:  epoch  0, batch    81 | loss: 3.1531024MixupTrain:  epoch  0, batch    82 | loss: 2.7079701MixupTrain:  epoch  0, batch    83 | loss: 2.8742216MixupTrain:  epoch  0, batch    84 | loss: 3.1289463MixupTrain:  epoch  0, batch    85 | loss: 2.2874298MixupTrain:  epoch  0, batch    86 | loss: 2.8627791MixupTrain:  epoch  0, batch    87 | loss: 2.9993587MixupTrain:  epoch  0, batch    88 | loss: 2.8451047MixupTrain:  epoch  0, batch    89 | loss: 2.8590622MixupTrain:  epoch  0, batch    90 | loss: 2.9833832MixupTrain:  epoch  0, batch    91 | loss: 2.8694267MixupTrain:  epoch  0, batch    92 | loss: 2.5849290MixupTrain:  epoch  0, batch    93 | loss: 2.2879672MixupTrain:  epoch  0, batch    94 | loss: 2.7744384MixupTrain:  epoch  0, batch    95 | loss: 2.7352924MixupTrain:  epoch  0, batch    96 | loss: 2.7850168MixupTrain:  epoch  0, batch    97 | loss: 2.6405857MixupTrain:  epoch  0, batch    98 | loss: 2.8012497MixupTrain:  epoch  0, batch    99 | loss: 2.9518161MixupTrain:  epoch  0, batch   100 | loss: 2.5596809MixupTrain:  epoch  0, batch   101 | loss: 2.5176554MixupTrain:  epoch  0, batch   102 | loss: 2.7712450MixupTrain:  epoch  0, batch   103 | loss: 2.7832227MixupTrain:  epoch  0, batch   104 | loss: 2.8384032MixupTrain:  epoch  0, batch   105 | loss: 2.8298693MixupTrain:  epoch  0, batch   106 | loss: 2.5471232MixupTrain:  epoch  0, batch   107 | loss: 2.6009855MixupTrain:  epoch  0, batch   108 | loss: 2.8483589MixupTrain:  epoch  0, batch   109 | loss: 2.7377017MixupTrain:  epoch  0, batch   110 | loss: 2.6493039MixupTrain:  epoch  0, batch   111 | loss: 2.8545675MixupTrain:  epoch  0, batch   112 | loss: 2.8282840MixupTrain:  epoch  0, batch   113 | loss: 3.0979190MixupTrain:  epoch  0, batch   114 | loss: 2.3804226MixupTrain:  epoch  0, batch   115 | loss: 2.7420938MixupTrain:  epoch  0, batch   116 | loss: 2.6153371MixupTrain:  epoch  0, batch   117 | loss: 2.6402421MixupTrain:  epoch  0, batch   118 | loss: 2.9393108MixupTrain:  epoch  0, batch   119 | loss: 3.1406422MixupTrain:  epoch  0, batch   120 | loss: 2.4229202MixupTrain:  epoch  0, batch   121 | loss: 2.5868034MixupTrain:  epoch  0, batch   122 | loss: 2.6446095MixupTrain:  epoch  0, batch   123 | loss: 2.6708112MixupTrain:  epoch  0, batch   124 | loss: 2.2264180MixupTrain:  epoch  0, batch   125 | loss: 2.6107328MixupTrain:  epoch  0, batch   126 | loss: 2.5005584MixupTrain:  epoch  0, batch   127 | loss: 2.3129458MixupTrain:  epoch  0, batch   128 | loss: 2.6172037MixupTrain:  epoch  0, batch   129 | loss: 2.6773384MixupTrain:  epoch  0, batch   130 | loss: 2.5702131MixupTrain:  epoch  0, batch   131 | loss: 2.4139993MixupTrain:  epoch  0, batch   132 | loss: 2.9548645MixupTrain:  epoch  0, batch   133 | loss: 2.6988935MixupTrain:  epoch  0, batch   134 | loss: 2.5903869MixupTrain:  epoch  0, batch   135 | loss: 2.8606215MixupTrain:  epoch  0, batch   136 | loss: 2.7923501MixupTrain:  epoch  0, batch   137 | loss: 2.7030241MixupTrain:  epoch  0, batch   138 | loss: 2.6757927MixupTrain:  epoch  0, batch   139 | loss: 2.6234679MixupTrain:  epoch  0, batch   140 | loss: 2.4230881MixupTrain:  epoch  0, batch   141 | loss: 2.4167073MixupTrain:  epoch  0, batch   142 | loss: 2.8455212MixupTrain:  epoch  0, batch   143 | loss: 2.7673779MixupTrain:  epoch  0, batch   144 | loss: 2.5833883MixupTrain:  epoch  0, batch   145 | loss: 2.5490842MixupTrain:  epoch  0, batch   146 | loss: 2.4975338MixupTrain:  epoch  0, batch   147 | loss: 2.8047521MixupTrain:  epoch  0, batch   148 | loss: 2.4934688MixupTrain:  epoch  0, batch   149 | loss: 2.5001457MixupTrain:  epoch  0, batch   150 | loss: 2.4131522MixupTrain:  epoch  0, batch   151 | loss: 2.3763316MixupTrain:  epoch  0, batch   152 | loss: 2.2800074MixupTrain:  epoch  0, batch   153 | loss: 2.5610788MixupTrain:  epoch  0, batch   154 | loss: 2.5425220MixupTrain:  epoch  0, batch   155 | loss: 2.6182747MixupTrain:  epoch  0, batch   156 | loss: 2.3358212MixupTrain:  epoch  0, batch   157 | loss: 2.5474648MixupTrain:  epoch  0, batch   158 | loss: 2.8111730MixupTrain:  epoch  0, batch   159 | loss: 2.4230545MixupTrain:  epoch  0, batch   160 | loss: 2.4306812MixupTrain:  epoch  0, batch   161 | loss: 2.2434278MixupTrain:  epoch  0, batch   162 | loss: 2.3005185MixupTrain:  epoch  0, batch   163 | loss: 2.7721753MixupTrain:  epoch  0, batch   164 | loss: 2.6028790MixupTrain:  epoch  0, batch   165 | loss: 2.8431516MixupTrain:  epoch  0, batch   166 | loss: 2.8888903MixupTrain:  epoch  0, batch   167 | loss: 2.0711191MixupTrain:  epoch  0, batch   168 | loss: 2.2635465MixupTrain:  epoch  0, batch   169 | loss: 2.4250746MixupTrain:  epoch  0, batch   170 | loss: 2.8731301MixupTrain:  epoch  0, batch   171 | loss: 2.1871586MixupTrain:  epoch  0, batch   172 | loss: 2.9058492MixupTrain:  epoch  0, batch   173 | loss: 2.7240071MixupTrain:  epoch  0, batch   174 | loss: 2.8010631MixupTrain:  epoch  0, batch   175 | loss: 2.6275225MixupTrain:  epoch  0, batch   176 | loss: 2.5504894MixupTrain:  epoch  0, batch   177 | loss: 2.3992193MixupTrain:  epoch  0, batch   178 | loss: 2.7348146MixupTrain:  epoch  0, batch   179 | loss: 3.0626535MixupTrain:  epoch  0, batch   180 | loss: 2.8221798MixupTrain:  epoch  0, batch   181 | loss: 2.4718404MixupTrain:  epoch  0, batch   182 | loss: 2.5692964MixupTrain:  epoch  0, batch   183 | loss: 2.5955749MixupTrain:  epoch  0, batch   184 | loss: 2.5234842MixupTrain:  epoch  0, batch   185 | loss: 2.8685827MixupTrain:  epoch  0, batch   186 | loss: 2.6259203MixupTrain:  epoch  0, batch   187 | loss: 2.4523396MixupTrain:  epoch  0, batch   188 | loss: 2.3999672MixupTrain:  epoch  0, batch   189 | loss: 2.7618995MixupTrain:  epoch  0, batch   190 | loss: 2.3958206MixupTrain:  epoch  0, batch   191 | loss: 2.4362445MixupTrain:  epoch  0, batch   192 | loss: 2.2644622MixupTrain:  epoch  0, batch   193 | loss: 2.4362197MixupTrain:  epoch  0, batch   194 | loss: 2.5244489MixupTrain:  epoch  0, batch   195 | loss: 2.5133488MixupTrain:  epoch  0, batch   196 | loss: 2.2240524MixupTrain:  epoch  0, batch   197 | loss: 2.3831267MixupTrain:  epoch  0, batch   198 | loss: 2.6908147MixupTrain:  epoch  0, batch   199 | loss: 2.4957647MixupTrain:  epoch  0, batch   200 | loss: 2.5148149MixupTrain:  epoch  0, batch   201 | loss: 2.6484499MixupTrain:  epoch  0, batch   202 | loss: 2.5820048MixupTrain:  epoch  0, batch   203 | loss: 2.5384884MixupTrain:  epoch  0, batch   204 | loss: 2.4830549MixupTrain:  epoch  0, batch   205 | loss: 2.5825090MixupTrain:  epoch  0, batch   206 | loss: 2.5662422MixupTrain:  epoch  0, batch   207 | loss: 2.7933273MixupTrain:  epoch  0, batch   208 | loss: 2.3486857MixupTrain:  epoch  0, batch   209 | loss: 2.7010233MixupTrain:  epoch  0, batch   210 | loss: 2.3871732MixupTrain:  epoch  0, batch   211 | loss: 2.4200847MixupTrain:  epoch  0, batch   212 | loss: 2.3773551MixupTrain:  epoch  0, batch   213 | loss: 2.6220660MixupTrain:  epoch  0, batch   214 | loss: 2.6741815MixupTrain:  epoch  0, batch   215 | loss: 2.5328145MixupTrain:  epoch  0, batch   216 | loss: 2.4093735MixupTrain:  epoch  0, batch   217 | loss: 2.1772146MixupTrain:  epoch  0, batch   218 | loss: 2.6936398MixupTrain:  epoch  0, batch   219 | loss: 2.3633308MixupTrain:  epoch  0, batch   220 | loss: 2.7020612MixupTrain:  epoch  0, batch   221 | loss: 2.4641147MixupTrain:  epoch  0, batch   222 | loss: 2.6604524MixupTrain:  epoch  0, batch   223 | loss: 2.7333541MixupTrain:  epoch  0, batch   224 | loss: 2.6913922MixupTrain:  epoch  0, batch   225 | loss: 2.5060215MixupTrain:  epoch  0, batch   226 | loss: 2.5897307MixupTrain:  epoch  0, batch   227 | loss: 2.5020082MixupTrain:  epoch  0, batch   228 | loss: 2.6212900MixupTrain:  epoch  0, batch   229 | loss: 2.5356345MixupTrain:  epoch  0, batch   230 | loss: 2.4124770MixupTrain:  epoch  0, batch   231 | loss: 2.4709756MixupTrain:  epoch  0, batch   232 | loss: 2.6326852MixupTrain:  epoch  0, batch   233 | loss: 2.4969826MixupTrain:  epoch  0, batch   234 | loss: 2.2760959MixupTrain:  epoch  0, batch   235 | loss: 2.1797192MixupTrain:  epoch  0, batch   236 | loss: 2.5237985MixupTrain:  epoch  0, batch   237 | loss: 2.8273337MixupTrain:  epoch  0, batch   238 | loss: 2.3402202MixupTrain:  epoch  0, batch   239 | loss: 2.6091018MixupTrain:  epoch  0, batch   240 | loss: 2.2906682MixupTrain:  epoch  0, batch   241 | loss: 2.4694636MixupTrain:  epoch  0, batch   242 | loss: 2.1197951MixupTrain:  epoch  0, batch   243 | loss: 2.3514054MixupTrain:  epoch  0, batch   244 | loss: 2.5109415MixupTrain:  epoch  0, batch   245 | loss: 2.6475995MixupTrain:  epoch  0, batch   246 | loss: 2.6423321MixupTrain:  epoch  0, batch   247 | loss: 2.3378773MixupTrain:  epoch  0, batch   248 | loss: 2.4347942MixupTrain:  epoch  0, batch   249 | loss: 2.8278155MixupTrain:  epoch  0, batch   250 | loss: 2.5620289MixupTrain:  epoch  0, batch   251 | loss: 2.4431300MixupTrain:  epoch  0, batch   252 | loss: 2.3544414MixupTrain:  epoch  0, batch   253 | loss: 2.4001923MixupTrain:  epoch  0, batch   254 | loss: 2.8048129MixupTrain:  epoch  0, batch   255 | loss: 2.2347803MixupTrain:  epoch  0, batch   256 | loss: 2.5203602MixupTrain:  epoch  0, batch   257 | loss: 2.2831514MixupTrain:  epoch  0, batch   258 | loss: 2.6697931MixupTrain:  epoch  0, batch   259 | loss: 2.3305511MixupTrain:  epoch  0, batch   260 | loss: 2.3356512MixupTrain:  epoch  0, batch   261 | loss: 2.4893861MixupTrain:  epoch  0, batch   262 | loss: 2.4648643MixupTrain:  epoch  0, batch   263 | loss: 2.3092694MixupTrain:  epoch  0, batch   264 | loss: 2.3496654MixupTrain:  epoch  0, batch   265 | loss: 2.5956318MixupTrain:  epoch  0, batch   266 | loss: 2.6488607MixupTrain:  epoch  0, batch   267 | loss: 2.5435746MixupTrain:  epoch  0, batch   268 | loss: 2.4909332MixupTrain:  epoch  0, batch   269 | loss: 2.4974895MixupTrain:  epoch  0, batch   270 | loss: 2.2302330MixupTrain:  epoch  0, batch   271 | loss: 2.5731623MixupTrain:  epoch  0, batch   272 | loss: 2.7022505MixupTrain:  epoch  0, batch   273 | loss: 2.5272503MixupTrain:  epoch  0, batch   274 | loss: 2.2280912MixupTrain:  epoch  0, batch   275 | loss: 2.2660360MixupTrain:  epoch  0, batch   276 | loss: 2.4843154MixupTrain:  epoch  0, batch   277 | loss: 2.2238190MixupTrain:  epoch  0, batch   278 | loss: 2.6953363MixupTrain:  epoch  0, batch   279 | loss: 2.7571170MixupTrain:  epoch  0, batch   280 | loss: 2.4117956MixupTrain:  epoch  0, batch   281 | loss: 2.7405286MixupTrain:  epoch  0, batch   282 | loss: 2.4594178MixupTrain:  epoch  0, batch   283 | loss: 2.3057568MixupTrain:  epoch  0, batch   284 | loss: 2.6876318MixupTrain:  epoch  0, batch   285 | loss: 2.4938641MixupTrain:  epoch  0, batch   286 | loss: 2.2232568MixupTrain:  epoch  0, batch   287 | loss: 2.4081066MixupTrain:  epoch  0, batch   288 | loss: 2.3170793MixupTrain:  epoch  0, batch   289 | loss: 2.8867967MixupTrain:  epoch  0, batch   290 | loss: 2.2293205MixupTrain:  epoch  0, batch   291 | loss: 2.6046791MixupTrain:  epoch  0, batch   292 | loss: 2.4966102MixupTrain:  epoch  0, batch   293 | loss: 2.8514285MixupTrain:  epoch  0, batch   294 | loss: 2.4666452MixupTrain:  epoch  0, batch   295 | loss: 2.5264807MixupTrain:  epoch  0, batch   296 | loss: 2.7276509MixupTrain:  epoch  0, batch   297 | loss: 1.9496905MixupTrain:  epoch  0, batch   298 | loss: 2.1399555MixupTrain:  epoch  0, batch   299 | loss: 2.3672843MixupTrain:  epoch  0, batch   300 | loss: 2.6265230MixupTrain:  epoch  0, batch   301 | loss: 2.4536500MixupTrain:  epoch  0, batch   302 | loss: 2.3332825MixupTrain:  epoch  0, batch   303 | loss: 2.4071388MixupTrain:  epoch  0, batch   304 | loss: 2.6119156MixupTrain:  epoch  0, batch   305 | loss: 2.4698226MixupTrain:  epoch  0, batch   306 | loss: 2.5561008MixupTrain:  epoch  0, batch   307 | loss: 2.2579434MixupTrain:  epoch  0, batch   308 | loss: 2.3050945MixupTrain:  epoch  0, batch   309 | loss: 2.3167083MixupTrain:  epoch  0, batch   310 | loss: 2.3990154MixupTrain:  epoch  0, batch   311 | loss: 2.4408898MixupTrain:  epoch  0, batch   312 | loss: 2.7616282MixupTrain:  epoch  0, batch   313 | loss: 2.6037049MixupTrain:  epoch  0, batch   314 | loss: 2.2502172MixupTrain:  epoch  0, batch   315 | loss: 2.2968287MixupTrain:  epoch  0, batch   316 | loss: 2.3537216MixupTrain:  epoch  0, batch   317 | loss: 2.2554798MixupTrain:  epoch  0, batch   318 | loss: 2.4277382MixupTrain:  epoch  0, batch   319 | loss: 2.3703303MixupTrain:  epoch  0, batch   320 | loss: 2.4536562MixupTrain:  epoch  0, batch   321 | loss: 2.5286403MixupTrain:  epoch  0, batch   322 | loss: 2.4776039MixupTrain:  epoch  0, batch   323 | loss: 2.4372356MixupTrain:  epoch  0, batch   324 | loss: 2.5665841MixupTrain:  epoch  0, batch   325 | loss: 2.3177762MixupTrain:  epoch  0, batch   326 | loss: 2.5254593MixupTrain:  epoch  0, batch   327 | loss: 2.3924575MixupTrain:  epoch  0, batch   328 | loss: 2.6333814MixupTrain:  epoch  0, batch   329 | loss: 2.4567962MixupTrain:  epoch  0, batch   330 | loss: 2.8055849MixupTrain:  epoch  0, batch   331 | loss: 2.3379855MixupTrain:  epoch  0, batch   332 | loss: 2.4786501MixupTrain:  epoch  0, batch   333 | loss: 2.4215758MixupTrain:  epoch  0, batch   334 | loss: 2.3141341MixupTrain:  epoch  0, batch   335 | loss: 2.2606859MixupTrain:  epoch  0, batch   336 | loss: 2.4868884MixupTrain:  epoch  0, batch   337 | loss: 2.3628998MixupTrain:  epoch  0, batch   338 | loss: 2.3990381MixupTrain:  epoch  0, batch   339 | loss: 2.6538024MixupTrain:  epoch  0, batch   340 | loss: 2.6966815MixupTrain:  epoch  0, batch   341 | loss: 2.4933839MixupTrain:  epoch  0, batch   342 | loss: 2.5950265MixupTrain:  epoch  0, batch   343 | loss: 2.3901663MixupTrain:  epoch  0, batch   344 | loss: 2.5320771MixupTrain:  epoch  0, batch   345 | loss: 2.4131329MixupTrain:  epoch  0, batch   346 | loss: 2.3143802MixupTrain:  epoch  0, batch   347 | loss: 2.4645905MixupTrain:  epoch  0, batch   348 | loss: 2.0672979MixupTrain:  epoch  0, batch   349 | loss: 2.4443645MixupTrain:  epoch  0, batch   350 | loss: 2.4240491MixupTrain:  epoch  0, batch   351 | loss: 2.5800817MixupTrain:  epoch  0, batch   352 | loss: 2.5044348MixupTrain:  epoch  0, batch   353 | loss: 2.2404656MixupTrain:  epoch  0, batch   354 | loss: 2.4107971MixupTrain:  epoch  0, batch   355 | loss: 2.4971063MixupTrain:  epoch  0, batch   356 | loss: 2.4483404MixupTrain:  epoch  0, batch   357 | loss: 2.1258917MixupTrain:  epoch  0, batch   358 | loss: 2.3238349MixupTrain:  epoch  0, batch   359 | loss: 2.4897172MixupTrain:  epoch  0, batch   360 | loss: 2.3550367MixupTrain:  epoch  0, batch   361 | loss: 2.3724484MixupTrain:  epoch  0, batch   362 | loss: 2.4553804MixupTrain:  epoch  0, batch   363 | loss: 2.5554748MixupTrain:  epoch  0, batch   364 | loss: 2.3289280MixupTrain:  epoch  0, batch   365 | loss: 2.2813995MixupTrain:  epoch  0, batch   366 | loss: 2.3838696MixupTrain:  epoch  0, batch   367 | loss: 2.2918625MixupTrain:  epoch  0, batch   368 | loss: 2.3593175MixupTrain:  epoch  0, batch   369 | loss: 2.4724076MixupTrain:  epoch  0, batch   370 | loss: 2.3251088MixupTrain:  epoch  0, batch   371 | loss: 2.5187104MixupTrain:  epoch  0, batch   372 | loss: 2.3461044MixupTrain:  epoch  0, batch   373 | loss: 2.4278326MixupTrain:  epoch  0, batch   374 | loss: 2.5539765MixupTrain:  epoch  0, batch   375 | loss: 2.4433985MixupTrain:  epoch  0, batch   376 | loss: 2.5593944MixupTrain:  epoch  0, batch   377 | loss: 2.3866017MixupTrain:  epoch  0, batch   378 | loss: 2.3479223MixupTrain:  epoch  0, batch   379 | loss: 2.6999691MixupTrain:  epoch  0, batch   380 | loss: 2.4631057MixupTrain:  epoch  0, batch   381 | loss: 2.3555231MixupTrain:  epoch  0, batch   382 | loss: 2.5347829MixupTrain:  epoch  0, batch   383 | loss: 2.3954172MixupTrain:  epoch  0, batch   384 | loss: 2.4199796MixupTrain:  epoch  0, batch   385 | loss: 2.5832181MixupTrain:  epoch  0, batch   386 | loss: 2.3090649MixupTrain:  epoch  0, batch   387 | loss: 2.4568806MixupTrain:  epoch  0, batch   388 | loss: 2.6433902MixupTrain:  epoch  0, batch   389 | loss: 2.6126204MixupTrain:  epoch  0, batch   390 | loss: 2.4026875MixupTrain:  epoch  0, batch   391 | loss: 2.4224110MixupTrain:  epoch  0, batch   392 | loss: 2.2698543MixupTrain:  epoch  0, batch   393 | loss: 2.6545212MixupTrain:  epoch  0, batch   394 | loss: 2.2169380MixupTrain:  epoch  0, batch   395 | loss: 2.3523822MixupTrain:  epoch  0, batch   396 | loss: 2.4175601MixupTrain:  epoch  0, batch   397 | loss: 2.0642362MixupTrain:  epoch  0, batch   398 | loss: 2.3950925MixupTrain:  epoch  0, batch   399 | loss: 2.3477402MixupTrain:  epoch  0, batch   400 | loss: 2.4437411MixupTrain:  epoch  0, batch   401 | loss: 2.4882011MixupTrain:  epoch  0, batch   402 | loss: 2.1934891MixupTrain:  epoch  0, batch   403 | loss: 2.1727147MixupTrain:  epoch  0, batch   404 | loss: 2.3588030MixupTrain:  epoch  0, batch   405 | loss: 2.9243217MixupTrain:  epoch  0, batch   406 | loss: 2.2489119MixupTrain:  epoch  0, batch   407 | loss: 2.6883042MixupTrain:  epoch  0, batch   408 | loss: 2.2056847MixupTrain:  epoch  0, batch   409 | loss: 2.0624032MixupTrain:  epoch  0, batch   410 | loss: 2.1584282MixupTrain:  epoch  0, batch   411 | loss: 2.3904924MixupTrain:  epoch  0, batch   412 | loss: 2.2633805MixupTrain:  epoch  0, batch   413 | loss: 2.3916030MixupTrain:  epoch  0, batch   414 | loss: 2.4253082MixupTrain:  epoch  0, batch   415 | loss: 2.5037205MixupTrain:  epoch  0, batch   416 | loss: 2.4385030MixupTrain:  epoch  0, batch   417 | loss: 2.2776151MixupTrain:  epoch  0, batch   418 | loss: 2.3599372MixupTrain:  epoch  0, batch   419 | loss: 2.4580219MixupTrain:  epoch  0, batch   420 | loss: 2.5091290MixupTrain:  epoch  0, batch   421 | loss: 2.4509366MixupTrain:  epoch  0, batch   422 | loss: 2.6443834MixupTrain:  epoch  0, batch   423 | loss: 2.2972374MixupTrain:  epoch  0, batch   424 | loss: 2.8078976MixupTrain:  epoch  0, batch   425 | loss: 2.3943372MixupTrain:  epoch  0, batch   426 | loss: 2.5988996MixupTrain:  epoch  0, batch   427 | loss: 2.5413949MixupTrain:  epoch  0, batch   428 | loss: 2.3887265MixupTrain:  epoch  0, batch   429 | loss: 2.7105467MixupTrain:  epoch  0, batch   430 | loss: 2.3540688MixupTrain:  epoch  0, batch   431 | loss: 2.6862774MixupTrain:  epoch  0, batch   432 | loss: 2.1032548MixupTrain:  epoch  0, batch   433 | loss: 2.5522358MixupTrain:  epoch  0, batch   434 | loss: 2.5408337MixupTrain:  epoch  0, batch   435 | loss: 2.3652134MixupTrain:  epoch  0, batch   436 | loss: 2.3396258MixupTrain:  epoch  0, batch   437 | loss: 2.6608224MixupTrain:  epoch  0, batch   438 | loss: 2.3574739MixupTrain:  epoch  0, batch   439 | loss: 2.3372746MixupTrain:  epoch  0, batch   440 | loss: 2.1947627MixupTrain:  epoch  0, batch   441 | loss: 2.3160527MixupTrain:  epoch  0, batch   442 | loss: 2.2492714MixupTrain:  epoch  0, batch   443 | loss: 2.2179976MixupTrain:  epoch  0, batch   444 | loss: 2.7160361MixupTrain:  epoch  0, batch   445 | loss: 2.7793107MixupTrain:  epoch  0, batch   446 | loss: 2.6496243MixupTrain:  epoch  0, batch   447 | loss: 2.3737521MixupTrain:  epoch  0, batch   448 | loss: 2.5039897MixupTrain:  epoch  0, batch   449 | loss: 2.4433939MixupTrain:  epoch  0, batch   450 | loss: 2.3413591MixupTrain:  epoch  0, batch   451 | loss: 2.4909081MixupTrain:  epoch  0, batch   452 | loss: 2.6362109MixupTrain:  epoch  0, batch   453 | loss: 2.3423605MixupTrain:  epoch  0, batch   454 | loss: 2.4173694MixupTrain:  epoch  0, batch   455 | loss: 2.5390606MixupTrain:  epoch  0, batch   456 | loss: 2.3193262MixupTrain:  epoch  0, batch   457 | loss: 2.4053903MixupTrain:  epoch  0, batch   458 | loss: 2.4188690MixupTrain:  epoch  0, batch   459 | loss: 2.2012553MixupTrain:  epoch  0, batch   460 | loss: 2.7826049MixupTrain:  epoch  0, batch   461 | loss: 2.1057022MixupTrain:  epoch  0, batch   462 | loss: 2.1567731MixupTrain:  epoch  0, batch   463 | loss: 2.7247229MixupTrain:  epoch  0, batch   464 | loss: 2.5820270MixupTrain:  epoch  0, batch   465 | loss: 2.4587147MixupTrain:  epoch  0, batch   466 | loss: 2.3308182MixupTrain:  epoch  0, batch   467 | loss: 2.3306422MixupTrain:  epoch  0, batch   468 | loss: 2.5885220MixupTrain:  epoch  0, batch   469 | loss: 2.5117984MixupTrain:  epoch  0, batch   470 | loss: 2.4758232MixupTrain:  epoch  0, batch   471 | loss: 2.3012185MixupTrain:  epoch  0, batch   472 | loss: 2.4353778MixupTrain:  epoch  0, batch   473 | loss: 2.5664663MixupTrain:  epoch  0, batch   474 | loss: 2.0786002MixupTrain:  epoch  0, batch   475 | loss: 2.3494453MixupTrain:  epoch  0, batch   476 | loss: 2.3443203MixupTrain:  epoch  0, batch   477 | loss: 2.4551694MixupTrain:  epoch  0, batch   478 | loss: 2.3148735MixupTrain:  epoch  0, batch   479 | loss: 2.3363290MixupTrain:  epoch  0, batch   480 | loss: 2.4993329MixupTrain:  epoch  0, batch   481 | loss: 2.0856285MixupTrain:  epoch  0, batch   482 | loss: 2.4054718MixupTrain:  epoch  0, batch   483 | loss: 2.5147057MixupTrain:  epoch  0, batch   484 | loss: 2.3173966MixupTrain:  epoch  0, batch   485 | loss: 2.4847093MixupTrain:  epoch  0, batch   486 | loss: 2.6320310MixupTrain:  epoch  0, batch   487 | loss: 2.1980331MixupTrain:  epoch  0, batch   488 | loss: 2.4743590MixupTrain:  epoch  0, batch   489 | loss: 2.4162941MixupTrain:  epoch  0, batch   490 | loss: 2.5080113MixupTrain:  epoch  0, batch   491 | loss: 2.3169746MixupTrain:  epoch  0, batch   492 | loss: 2.3995972MixupTrain:  epoch  0, batch   493 | loss: 2.3552246MixupTrain:  epoch  0, batch   494 | loss: 2.3010988MixupTrain:  epoch  0, batch   495 | loss: 2.4747891MixupTrain:  epoch  0, batch   496 | loss: 2.4878194MixupTrain:  epoch  0, batch   497 | loss: 2.4113755MixupTrain:  epoch  0, batch   498 | loss: 2.4089739MixupTrain:  epoch  0, batch   499 | loss: 2.2634728MixupTrain:  epoch  0, batch   500 | loss: 2.1239727MixupTrain:  epoch  0, batch   501 | loss: 2.2671041MixupTrain:  epoch  0, batch   502 | loss: 2.4623227MixupTrain:  epoch  0, batch   503 | loss: 2.4399552MixupTrain:  epoch  0, batch   504 | loss: 2.4016788MixupTrain:  epoch  0, batch   505 | loss: 2.1775017MixupTrain:  epoch  0, batch   506 | loss: 2.7686529MixupTrain:  epoch  0, batch   507 | loss: 2.4919245MixupTrain:  epoch  0, batch   508 | loss: 2.5569899MixupTrain:  epoch  0, batch   509 | loss: 2.5909548MixupTrain:  epoch  0, batch   510 | loss: 2.2613091MixupTrain:  epoch  0, batch   511 | loss: 2.2243028MixupTrain:  epoch  0, batch   512 | loss: 2.2398701MixupTrain:  epoch  0, batch   513 | loss: 3.0302892MixupTrain:  epoch  0, batch   514 | loss: 2.5304735MixupTrain:  epoch  0, batch   515 | loss: 2.6826560MixupTrain:  epoch  0, batch   516 | loss: 2.4281011MixupTrain:  epoch  0, batch   517 | loss: 2.5069323MixupTrain:  epoch  0, batch   518 | loss: 2.4164705MixupTrain:  epoch  0, batch   519 | loss: 2.5260744MixupTrain:  epoch  0, batch   520 | loss: 2.2890611MixupTrain:  epoch  0, batch   521 | loss: 2.2739744MixupTrain:  epoch  0, batch   522 | loss: 2.4176464MixupTrain:  epoch  0, batch   523 | loss: 2.3965645MixupTrain:  epoch  0, batch   524 | loss: 2.3879883MixupTrain:  epoch  0, batch   525 | loss: 2.3588977MixupTrain:  epoch  0, batch   526 | loss: 2.4118307MixupTrain:  epoch  0, batch   527 | loss: 2.4939005MixupTrain:  epoch  0, batch   528 | loss: 2.2833230MixupTrain:  epoch  0, batch   529 | loss: 2.4981477MixupTrain:  epoch  0, batch   530 | loss: 2.2675197MixupTrain:  epoch  0, batch   531 | loss: 2.4550207MixupTrain:  epoch  0, batch   532 | loss: 2.3091230MixupTrain:  epoch  0, batch   533 | loss: 2.4051991MixupTrain:  epoch  0, batch   534 | loss: 2.2529573MixupTrain:  epoch  0, batch   535 | loss: 2.5881073MixupTrain:  epoch  0, batch   536 | loss: 2.6064484MixupTrain:  epoch  0, batch   537 | loss: 2.3332486MixupTrain:  epoch  0, batch   538 | loss: 2.6927924MixupTrain:  epoch  0, batch   539 | loss: 2.4925570MixupTrain:  epoch  0, batch   540 | loss: 2.4171848MixupTrain:  epoch  0, batch   541 | loss: 2.2281549MixupTrain:  epoch  0, batch   542 | loss: 2.5286343MixupTrain:  epoch  0, batch   543 | loss: 2.3308344MixupTrain:  epoch  0, batch   544 | loss: 2.0547154MixupTrain:  epoch  0, batch   545 | loss: 2.5718327MixupTrain:  epoch  0, batch   546 | loss: 2.2327137MixupTrain:  epoch  0, batch   547 | loss: 2.3050113MixupTrain:  epoch  0, batch   548 | loss: 2.3032427MixupTrain:  epoch  0, batch   549 | loss: 2.3593884MixupTrain:  epoch  0, batch   550 | loss: 2.3404064MixupTrain:  epoch  0, batch   551 | loss: 2.5832758MixupTrain:  epoch  0, batch   552 | loss: 2.3940148MixupTrain:  epoch  0, batch   553 | loss: 2.3994989MixupTrain:  epoch  0, batch   554 | loss: 2.4007382MixupTrain:  epoch  0, batch   555 | loss: 2.3884344MixupTrain:  epoch  0, batch   556 | loss: 2.6344099MixupTrain:  epoch  0, batch   557 | loss: 2.4017544MixupTrain:  epoch  0, batch   558 | loss: 2.3201990MixupTrain:  epoch  0, batch   559 | loss: 2.3351583MixupTrain:  epoch  0, batch   560 | loss: 2.4885588MixupTrain:  epoch  0, batch   561 | loss: 2.5100045MixupTrain:  epoch  0, batch   562 | loss: 2.1273506MixupTrain:  epoch  0, batch   563 | loss: 2.3820317MixupTrain:  epoch  0, batch   564 | loss: 2.2020810MixupTrain:  epoch  0, batch   565 | loss: 2.1927156MixupTrain:  epoch  0, batch   566 | loss: 2.3747084MixupTrain:  epoch  0, batch   567 | loss: 2.5056543MixupTrain:  epoch  0, batch   568 | loss: 2.5645571MixupTrain:  epoch  0, batch   569 | loss: 2.3635569MixupTrain:  epoch  0, batch   570 | loss: 2.3822451MixupTrain:  epoch  0, batch   571 | loss: 1.9195161MixupTrain:  epoch  0, batch   572 | loss: 2.4546466MixupTrain:  epoch  0, batch   573 | loss: 2.5171740MixupTrain:  epoch  0, batch   574 | loss: 2.6280656MixupTrain:  epoch  0, batch   575 | loss: 2.3287907MixupTrain:  epoch  0, batch   576 | loss: 2.3956003MixupTrain:  epoch  0, batch   577 | loss: 2.2209883MixupTrain:  epoch  0, batch   578 | loss: 2.4136076MixupTrain:  epoch  0, batch   579 | loss: 2.3962293MixupTrain:  epoch  0, batch   580 | loss: 2.3784688MixupTrain:  epoch  0, batch   581 | loss: 2.5789638MixupTrain:  epoch  0, batch   582 | loss: 2.2605553MixupTrain:  epoch  0, batch   583 | loss: 2.3723140MixupTrain:  epoch  0, batch   584 | loss: 2.2994065MixupTrain:  epoch  0, batch   585 | loss: 2.3046808MixupTrain:  epoch  0, batch   586 | loss: 2.2591267MixupTrain:  epoch  0, batch   587 | loss: 2.3506327MixupTrain:  epoch  0, batch   588 | loss: 2.4168534MixupTrain:  epoch  0, batch   589 | loss: 2.2958498MixupTrain:  epoch  0, batch   590 | loss: 2.5009518MixupTrain:  epoch  0, batch   591 | loss: 2.4425480MixupTrain:  epoch  0, batch   592 | loss: 2.2247293MixupTrain:  epoch  0, batch   593 | loss: 2.1472273MixupTrain:  epoch  0, batch   594 | loss: 2.1277573MixupTrain:  epoch  0, batch   595 | loss: 2.4949889MixupTrain:  epoch  0, batch   596 | loss: 2.4172795MixupTrain:  epoch  0, batch   597 | loss: 2.4991567MixupTrain:  epoch  0, batch   598 | loss: 2.4079680MixupTrain:  epoch  0, batch   599 | loss: 2.2903507MixupTrain:  epoch  0, batch   600 | loss: 2.4464641MixupTrain:  epoch  0, batch   601 | loss: 2.3985758MixupTrain:  epoch  0, batch   602 | loss: 2.3256392MixupTrain:  epoch  0, batch   603 | loss: 2.5438261MixupTrain:  epoch  0, batch   604 | loss: 2.4126754MixupTrain:  epoch  0, batch   605 | loss: 2.5452461MixupTrain:  epoch  0, batch   606 | loss: 2.4040382MixupTrain:  epoch  0, batch   607 | loss: 2.1925111MixupTrain:  epoch  0, batch   608 | loss: 2.3742366MixupTrain:  epoch  0, batch   609 | loss: 2.3168900MixupTrain:  epoch  0, batch   610 | loss: 2.3772688MixupTrain:  epoch  0, batch   611 | loss: 2.0757747MixupTrain:  epoch  0, batch   612 | loss: 2.2890429MixupTrain:  epoch  0, batch   613 | loss: 2.5068336MixupTrain:  epoch  0, batch   614 | loss: 2.2304485MixupTrain:  epoch  0, batch   615 | loss: 2.3390181MixupTrain:  epoch  0, batch   616 | loss: 2.4980192MixupTrain:  epoch  0, batch   617 | loss: 2.4359722MixupTrain:  epoch  0, batch   618 | loss: 2.1510115MixupTrain:  epoch  0, batch   619 | loss: 2.4179859MixupTrain:  epoch  0, batch   620 | loss: 2.3794150MixupTrain:  epoch  0, batch   621 | loss: 2.4796722MixupTrain:  epoch  0, batch   622 | loss: 2.2780833MixupTrain:  epoch  0, batch   623 | loss: 2.2950616MixupTrain:  epoch  0, batch   624 | loss: 2.4192729MixupTrain:  epoch  0, batch   625 | loss: 2.4131403MixupTrain:  epoch  0, batch   626 | loss: 2.2450681MixupTrain:  epoch  0, batch   627 | loss: 2.6760399MixupTrain:  epoch  0, batch   628 | loss: 2.0123267MixupTrain:  epoch  0, batch   629 | loss: 2.2475719MixupTrain:  epoch  0, batch   630 | loss: 2.0674627MixupTrain:  epoch  0, batch   631 | loss: 2.4064844MixupTrain:  epoch  0, batch   632 | loss: 2.1750085MixupTrain:  epoch  0, batch   633 | loss: 2.3048005MixupTrain:  epoch  0, batch   634 | loss: 2.4890828MixupTrain:  epoch  0, batch   635 | loss: 2.1637657MixupTrain:  epoch  0, batch   636 | loss: 2.3233354MixupTrain:  epoch  0, batch   637 | loss: 2.5358086MixupTrain:  epoch  0, batch   638 | loss: 2.6205730MixupTrain:  epoch  0, batch   639 | loss: 2.3886175MixupTrain:  epoch  0, batch   640 | loss: 2.5376611MixupTrain:  epoch  0, batch   641 | loss: 2.7351475MixupTrain:  epoch  0, batch   642 | loss: 2.3402045MixupTrain:  epoch  0, batch   643 | loss: 2.2688169MixupTrain:  epoch  0, batch   644 | loss: 2.6081228MixupTrain:  epoch  0, batch   645 | loss: 2.3519735MixupTrain:  epoch  0, batch   646 | loss: 2.4718149MixupTrain:  epoch  0, batch   647 | loss: 2.3629968MixupTrain:  epoch  0, batch   648 | loss: 2.4751561MixupTrain:  epoch  0, batch   649 | loss: 2.5069857MixupTrain:  epoch  0, batch   650 | loss: 2.1083636MixupTrain:  epoch  0, batch   651 | loss: 2.4582698MixupTrain:  epoch  0, batch   652 | loss: 2.6085477MixupTrain:  epoch  0, batch   653 | loss: 2.2901447MixupTrain:  epoch  0, batch   654 | loss: 2.8664694MixupTrain:  epoch  0, batch   655 | loss: 2.3216810MixupTrain:  epoch  0, batch   656 | loss: 2.4442148MixupTrain:  epoch  0, batch   657 | loss: 2.2863746MixupTrain:  epoch  0, batch   658 | loss: 2.2298546MixupTrain:  epoch  0, batch   659 | loss: 2.6162200MixupTrain:  epoch  0, batch   660 | loss: 2.2724316MixupTrain:  epoch  0, batch   661 | loss: 2.1796083MixupTrain:  epoch  0, batch   662 | loss: 2.5676107MixupTrain:  epoch  0, batch   663 | loss: 2.2912030MixupTrain:  epoch  0, batch   664 | loss: 2.8652678MixupTrain:  epoch  0, batch   665 | loss: 2.7183442MixupTrain:  epoch  0, batch   666 | loss: 2.3915267MixupTrain:  epoch  0, batch   667 | loss: 2.5423329MixupTrain:  epoch  0, batch   668 | loss: 2.5003841MixupTrain:  epoch  0, batch   669 | loss: 2.4989374MixupTrain:  epoch  0, batch   670 | loss: 2.2779932MixupTrain:  epoch  0, batch   671 | loss: 2.2597668MixupTrain:  epoch  0, batch   672 | loss: 2.3086786MixupTrain:  epoch  0, batch   673 | loss: 2.6490798MixupTrain:  epoch  0, batch   674 | loss: 2.2158053MixupTrain:  epoch  0, batch   675 | loss: 2.5251715MixupTrain:  epoch  0, batch   676 | loss: 2.2073491MixupTrain:  epoch  0, batch   677 | loss: 2.1349058MixupTrain:  epoch  0, batch   678 | loss: 2.4561031MixupTrain:  epoch  0, batch   679 | loss: 2.2459109MixupTrain:  epoch  0, batch   680 | loss: 2.4928727MixupTrain:  epoch  0, batch   681 | loss: 2.1707032MixupTrain:  epoch  0, batch   682 | loss: 2.1623983MixupTrain:  epoch  0, batch   683 | loss: 2.2503958MixupTrain:  epoch  0, batch   684 | loss: 2.2045078MixupTrain:  epoch  0, batch   685 | loss: 2.5131299MixupTrain:  epoch  0, batch   686 | loss: 2.3188939MixupTrain:  epoch  0, batch   687 | loss: 2.4244456MixupTrain:  epoch  0, batch   688 | loss: 2.2898998MixupTrain:  epoch  0, batch   689 | loss: 2.4132290MixupTrain:  epoch  0, batch   690 | loss: 2.2002168MixupTrain:  epoch  0, batch   691 | loss: 2.7711029MixupTrain:  epoch  0, batch   692 | loss: 2.2883945MixupTrain:  epoch  0, batch   693 | loss: 2.4603436MixupTrain:  epoch  0, batch   694 | loss: 2.2533131MixupTrain:  epoch  0, batch   695 | loss: 2.6037946MixupTrain:  epoch  0, batch   696 | loss: 2.5932260MixupTrain:  epoch  0, batch   697 | loss: 2.3003695MixupTrain:  epoch  0, batch   698 | loss: 2.2160044MixupTrain:  epoch  0, batch   699 | loss: 2.5467634MixupTrain:  epoch  0, batch   700 | loss: 2.6744533MixupTrain:  epoch  0, batch   701 | loss: 2.6215057MixupTrain:  epoch  0, batch   702 | loss: 2.4938688MixupTrain:  epoch  0, batch   703 | loss: 2.2769814MixupTrain:  epoch  0, batch   704 | loss: 2.2573874MixupTrain:  epoch  0, batch   705 | loss: 2.3597014MixupTrain:  epoch  0, batch   706 | loss: 2.2565675MixupTrain:  epoch  0, batch   707 | loss: 2.4192312MixupTrain:  epoch  0, batch   708 | loss: 2.3853593MixupTrain:  epoch  0, batch   709 | loss: 2.4111452MixupTrain:  epoch  0, batch   710 | loss: 2.5068364MixupTrain:  epoch  0, batch   711 | loss: 2.2914717MixupTrain:  epoch  0, batch   712 | loss: 2.4045880MixupTrain:  epoch  0, batch   713 | loss: 2.3757031MixupTrain:  epoch  0, batch   714 | loss: 2.2616453MixupTrain:  epoch  0, batch   715 | loss: 2.2200351MixupTrain:  epoch  0, batch   716 | loss: 2.1726840MixupTrain:  epoch  0, batch   717 | loss: 2.2238259MixupTrain:  epoch  0, batch   718 | loss: 2.2887697MixupTrain:  epoch  0, batch   719 | loss: 2.2865057MixupTrain:  epoch  0, batch   720 | loss: 2.2316742MixupTrain:  epoch  0, batch   721 | loss: 2.1701813MixupTrain:  epoch  0, batch   722 | loss: 2.4473181MixupTrain:  epoch  0, batch   723 | loss: 2.3267477MixupTrain:  epoch  0, batch   724 | loss: 2.1463294MixupTrain:  epoch  0, batch   725 | loss: 2.2676501MixupTrain:  epoch  0, batch   726 | loss: 2.2583179MixupTrain:  epoch  0, batch   727 | loss: 2.6481688MixupTrain:  epoch  0, batch   728 | loss: 2.3739424MixupTrain:  epoch  0, batch   729 | loss: 2.5407896MixupTrain:  epoch  0, batch   730 | loss: 2.5825839MixupTrain:  epoch  0, batch   731 | loss: 2.2305496MixupTrain:  epoch  0, batch   732 | loss: 2.3282373MixupTrain:  epoch  0, batch   733 | loss: 2.3205137MixupTrain:  epoch  0, batch   734 | loss: 2.5907865MixupTrain:  epoch  0, batch   735 | loss: 2.2080052MixupTrain:  epoch  0, batch   736 | loss: 2.6442156MixupTrain:  epoch  0, batch   737 | loss: 2.7480757MixupTrain:  epoch  0, batch   738 | loss: 2.2026854MixupTrain:  epoch  0, batch   739 | loss: 2.1887846MixupTrain:  epoch  0, batch   740 | loss: 2.2165554MixupTrain:  epoch  0, batch   741 | loss: 2.5147071MixupTrain:  epoch  0, batch   742 | loss: 2.2055979MixupTrain:  epoch  0, batch   743 | loss: 2.2854922MixupTrain:  epoch  0, batch   744 | loss: 2.3814309MixupTrain:  epoch  0, batch   745 | loss: 2.3195343MixupTrain:  epoch  0, batch   746 | loss: 2.2275178MixupTrain:  epoch  0, batch   747 | loss: 2.4647613MixupTrain:  epoch  0, batch   748 | loss: 2.0987482MixupTrain:  epoch  0, batch   749 | loss: 2.4345331MixupTrain:  epoch  0, batch   750 | loss: 2.1283379MixupTrain:  epoch  0, batch   751 | loss: 2.5677149MixupTrain:  epoch  0, batch   752 | loss: 2.3685966MixupTrain:  epoch  0, batch   753 | loss: 2.2129965MixupTrain:  epoch  0, batch   754 | loss: 2.8418155MixupTrain:  epoch  0, batch   755 | loss: 2.3977892MixupTrain:  epoch  0, batch   756 | loss: 2.3045540MixupTrain:  epoch  0, batch   757 | loss: 2.4833064MixupTrain:  epoch  0, batch   758 | loss: 2.4803753MixupTrain:  epoch  0, batch   759 | loss: 2.1390007MixupTrain:  epoch  0, batch   760 | loss: 2.4746025MixupTrain:  epoch  0, batch   761 | loss: 2.3192229MixupTrain:  epoch  0, batch   762 | loss: 2.3789043MixupTrain:  epoch  0, batch   763 | loss: 2.3707585MixupTrain:  epoch  0, batch   764 | loss: 2.1063776MixupTrain:  epoch  0, batch   765 | loss: 2.4266443MixupTrain:  epoch  0, batch   766 | loss: 2.5223699MixupTrain:  epoch  0, batch   767 | loss: 2.4112563MixupTrain:  epoch  0, batch   768 | loss: 2.0360222MixupTrain:  epoch  0, batch   769 | loss: 2.2589879MixupTrain:  epoch  0, batch   770 | loss: 2.3510590MixupTrain:  epoch  0, batch   771 | loss: 2.1717877MixupTrain:  epoch  0, batch   772 | loss: 2.3069816MixupTrain:  epoch  0, batch   773 | loss: 2.5517001MixupTrain:  epoch  0, batch   774 | loss: 2.2408290MixupTrain:  epoch  0, batch   775 | loss: 2.4593768MixupTrain:  epoch  0, batch   776 | loss: 2.2990911MixupTrain:  epoch  0, batch   777 | loss: 2.5359073MixupTrain:  epoch  0, batch   778 | loss: 2.5681791MixupTrain:  epoch  0, batch   779 | loss: 2.2982852MixupTrain:  epoch  0, batch   780 | loss: 2.2681751MixupTrain:  epoch  0, batch   781 | loss: 2.1121135MixupTrain:  epoch  0, batch   782 | loss: 2.1259904MixupTrain:  epoch  0, batch   783 | loss: 2.2850747MixupTrain:  epoch  0, batch   784 | loss: 2.2038555MixupTrain:  epoch  0, batch   785 | loss: 2.2453609MixupTrain:  epoch  0, batch   786 | loss: 2.4175663MixupTrain:  epoch  0, batch   787 | loss: 2.6232219MixupTrain:  epoch  0, batch   788 | loss: 2.2355700MixupTrain:  epoch  0, batch   789 | loss: 2.3687611MixupTrain:  epoch  0, batch   790 | loss: 2.8323040MixupTrain:  epoch  0, batch   791 | loss: 2.4143586MixupTrain:  epoch  0, batch   792 | loss: 2.4646473MixupTrain:  epoch  0, batch   793 | loss: 2.5453205MixupTrain:  epoch  0, batch   794 | loss: 2.2374105MixupTrain:  epoch  0, batch   795 | loss: 2.3700182MixupTrain:  epoch  0, batch   796 | loss: 2.6119401MixupTrain:  epoch  0, batch   797 | loss: 2.5007420MixupTrain:  epoch  0, batch   798 | loss: 2.4131768MixupTrain:  epoch  0, batch   799 | loss: 2.1609025MixupTrain:  epoch  0, batch   800 | loss: 2.0189734MixupTrain:  epoch  0, batch   801 | loss: 2.4908679MixupTrain:  epoch  0, batch   802 | loss: 2.2795582MixupTrain:  epoch  0, batch   803 | loss: 2.4478569MixupTrain:  epoch  0, batch   804 | loss: 2.5447767MixupTrain:  epoch  0, batch   805 | loss: 2.1770730MixupTrain:  epoch  0, batch   806 | loss: 2.3889718MixupTrain:  epoch  0, batch   807 | loss: 2.1262584MixupTrain:  epoch  0, batch   808 | loss: 2.5819480MixupTrain:  epoch  0, batch   809 | loss: 2.5759039MixupTrain:  epoch  0, batch   810 | loss: 2.2970252MixupTrain:  epoch  0, batch   811 | loss: 2.3652239MixupTrain:  epoch  0, batch   812 | loss: 2.5576930MixupTrain:  epoch  0, batch   813 | loss: 2.1713097MixupTrain:  epoch  0, batch   814 | loss: 2.2201204MixupTrain:  epoch  0, batch   815 | loss: 2.2516823MixupTrain:  epoch  0, batch   816 | loss: 2.2113795MixupTrain:  epoch  0, batch   817 | loss: 2.2783666MixupTrain:  epoch  0, batch   818 | loss: 2.5791302MixupTrain:  epoch  0, batch   819 | loss: 2.6382027MixupTrain:  epoch  0, batch   820 | loss: 2.4005287MixupTrain:  epoch  0, batch   821 | loss: 2.3723960MixupTrain:  epoch  0, batch   822 | loss: 2.6839600MixupTrain:  epoch  0, batch   823 | loss: 2.3919542MixupTrain:  epoch  0, batch   824 | loss: 2.2568457MixupTrain:  epoch  0, batch   825 | loss: 2.4686470MixupTrain:  epoch  0, batch   826 | loss: 2.6033959MixupTrain:  epoch  0, batch   827 | loss: 2.3498664MixupTrain:  epoch  0, batch   828 | loss: 2.3660896MixupTrain:  epoch  0, batch   829 | loss: 2.3300519MixupTrain:  epoch  0, batch   830 | loss: 2.2963631MixupTrain:  epoch  0, batch   831 | loss: 2.5342507MixupTrain:  epoch  0, batch   832 | loss: 2.3949156MixupTrain:  epoch  0, batch   833 | loss: 2.3332009MixupTrain:  epoch  0, batch   834 | loss: 2.0323653MixupTrain:  epoch  0, batch   835 | loss: 2.5439658MixupTrain:  epoch  0, batch   836 | loss: 2.4639266MixupTrain:  epoch  0, batch   837 | loss: 2.1082211MixupTrain:  epoch  0, batch   838 | loss: 2.2753539MixupTrain:  epoch  0, batch   839 | loss: 2.3790708MixupTrain:  epoch  0, batch   840 | loss: 2.4354043MixupTrain:  epoch  0, batch   841 | loss: 2.3780942MixupTrain:  epoch  0, batch   842 | loss: 2.1359005MixupTrain:  epoch  0, batch   843 | loss: 2.6231694MixupTrain:  epoch  0, batch   844 | loss: 2.2869160MixupTrain:  epoch  0, batch   845 | loss: 2.4216061MixupTrain:  epoch  0, batch   846 | loss: 2.4414392MixupTrain:  epoch  0, batch   847 | loss: 2.4173417MixupTrain:  epoch  0, batch   848 | loss: 2.3012176MixupTrain:  epoch  0, batch   849 | loss: 2.0433562MixupTrain:  epoch  0, batch   850 | loss: 2.3265736MixupTrain:  epoch  0, batch   851 | loss: 2.3163109MixupTrain:  epoch  0, batch   852 | loss: 2.2288404MixupTrain:  epoch  0, batch   853 | loss: 2.5363762MixupTrain:  epoch  0, batch   854 | loss: 2.1035719MixupTrain:  epoch  0, batch   855 | loss: 2.3523588MixupTrain:  epoch  0, batch   856 | loss: 2.3569629MixupTrain:  epoch  0, batch   857 | loss: 2.4277978MixupTrain:  epoch  0, batch   858 | loss: 2.2438684MixupTrain:  epoch  0, batch   859 | loss: 2.4832640MixupTrain:  epoch  0, batch   860 | loss: 2.4481406MixupTrain:  epoch  0, batch   861 | loss: 2.2114055MixupTrain:  epoch  0, batch   862 | loss: 2.4587297MixupTrain:  epoch  0, batch   863 | loss: 2.4055033MixupTrain:  epoch  0, batch   864 | loss: 2.3084219MixupTrain:  epoch  0, batch   865 | loss: 2.1092300MixupTrain:  epoch  0, batch   866 | loss: 2.4235861MixupTrain:  epoch  0, batch   867 | loss: 2.3594790MixupTrain:  epoch  0, batch   868 | loss: 2.5685811MixupTrain:  epoch  0, batch   869 | loss: 2.5013773MixupTrain:  epoch  0, batch   870 | loss: 2.5988326MixupTrain:  epoch  0, batch   871 | loss: 2.3514071MixupTrain:  epoch  0, batch   872 | loss: 2.0676696MixupTrain:  epoch  0, batch   873 | loss: 2.4441977MixupTrain:  epoch  0, batch   874 | loss: 2.4379778MixupTrain:  epoch  0, batch   875 | loss: 2.3969917MixupTrain:  epoch  0, batch   876 | loss: 2.4737039MixupTrain:  epoch  0, batch   877 | loss: 2.3070564MixupTrain:  epoch  0, batch   878 | loss: 2.6155171MixupTrain:  epoch  0, batch   879 | loss: 2.3158402MixupTrain:  epoch  0, batch   880 | loss: 2.3622842MixupTrain:  epoch  0, batch   881 | loss: 2.3259273MixupTrain:  epoch  0, batch   882 | loss: 2.4855497MixupTrain:  epoch  0, batch   883 | loss: 2.4687057MixupTrain:  epoch  0, batch   884 | loss: 2.2000484MixupTrain:  epoch  0, batch   885 | loss: 2.4268410MixupTrain:  epoch  0, batch   886 | loss: 2.3039408MixupTrain:  epoch  0, batch   887 | loss: 2.1841528MixupTrain:  epoch  0, batch   888 | loss: 2.1768622MixupTrain:  epoch  0, batch   889 | loss: 2.3642929MixupTrain:  epoch  0, batch   890 | loss: 2.5566928MixupTrain:  epoch  0, batch   891 | loss: 2.4896426MixupTrain:  epoch  0, batch   892 | loss: 2.1139379MixupTrain:  epoch  0, batch   893 | loss: 2.2854540MixupTrain:  epoch  0, batch   894 | loss: 2.3768673MixupTrain:  epoch  0, batch   895 | loss: 2.6354580MixupTrain:  epoch  0, batch   896 | loss: 2.2637239MixupTrain:  epoch  0, batch   897 | loss: 2.2690711MixupTrain:  epoch  0, batch   898 | loss: 2.5156212MixupTrain:  epoch  0, batch   899 | loss: 2.8806674MixupTrain:  epoch  0, batch   900 | loss: 2.8359940MixupTrain:  epoch  0, batch   901 | loss: 2.2659073MixupTrain:  epoch  0, batch   902 | loss: 2.7790513MixupTrain:  epoch  0, batch   903 | loss: 2.1936152MixupTrain:  epoch  0, batch   904 | loss: 2.2772949MixupTrain:  epoch  0, batch   905 | loss: 3.7784696MixupTrain:  epoch  0, batch   906 | loss: 2.4922628MixupTrain:  epoch  0, batch   907 | loss: 2.9666243MixupTrain:  epoch  0, batch   908 | loss: 2.9295564MixupTrain:  epoch  0, batch   909 | loss: 2.9960642MixupTrain:  epoch  0, batch   910 | loss: 2.1439180MixupTrain:  epoch  0, batch   911 | loss: 2.7371674MixupTrain:  epoch  0, batch   912 | loss: 2.7535105MixupTrain:  epoch  0, batch   913 | loss: 2.1340475MixupTrain:  epoch  0, batch   914 | loss: 2.2806048MixupTrain:  epoch  0, batch   915 | loss: 2.3269091MixupTrain:  epoch  0, batch   916 | loss: 2.1212564MixupTrain:  epoch  0, batch   917 | loss: 2.7692180MixupTrain:  epoch  0, batch   918 | loss: 4.9582677MixupTrain:  epoch  0, batch   919 | loss: 2.4501929MixupTrain:  epoch  0, batch   920 | loss: 3.4139178MixupTrain:  epoch  0, batch   921 | loss: 2.3904071MixupTrain:  epoch  0, batch   922 | loss: 2.5677187MixupTrain:  epoch  0, batch   923 | loss: 3.2436533MixupTrain:  epoch  0, batch   924 | loss: 2.2930789MixupTrain:  epoch  0, batch   925 | loss: 2.9516039MixupTrain:  epoch  0, batch   926 | loss: 2.2995839MixupTrain:  epoch  0, batch   927 | loss: 3.0786521MixupTrain:  epoch  0, batch   928 | loss: 2.2094519MixupTrain:  epoch  0, batch   929 | loss: 2.6113441MixupTrain:  epoch  0, batch   930 | loss: 2.1381454MixupTrain:  epoch  0, batch   931 | loss: 2.5722685MixupTrain:  epoch  0, batch   932 | loss: 2.4949284MixupTrain:  epoch  0, batch   933 | loss: 2.5496793MixupTrain:  epoch  0, batch   934 | loss: 2.6322124MixupTrain:  epoch  0, batch   935 | loss: 2.5802011MixupTrain:  epoch  0, batch   936 | loss: 2.5199573MixupTrain:  epoch  0, batch   937 | loss: 2.3828914MixupTrain:  epoch  0, batch   938 | loss: 2.4659328MixupTrain:  epoch  0, batch   939 | loss: 2.1052999MixupTrain:  epoch  0, batch   940 | loss: 2.5714736MixupTrain:  epoch  0, batch   941 | loss: 2.1387658MixupTrain:  epoch  0, batch   942 | loss: 2.3870022MixupTrain:  epoch  0, batch   943 | loss: 2.2889338MixupTrain:  epoch  0, batch   944 | loss: 2.5257304MixupTrain:  epoch  0, batch   945 | loss: 2.5979052MixupTrain:  epoch  0, batch   946 | loss: 2.2912548MixupTrain:  epoch  0, batch   947 | loss: 2.6286399MixupTrain:  epoch  0, batch   948 | loss: 2.5838108MixupTrain:  epoch  0, batch   949 | loss: 2.4798357MixupTrain:  epoch  0, batch   950 | loss: 2.1857128MixupTrain:  epoch  0, batch   951 | loss: 2.5437632MixupTrain:  epoch  0, batch   952 | loss: 2.1934791MixupTrain:  epoch  0, batch   953 | loss: 2.4458070MixupTrain:  epoch  0, batch   954 | loss: 2.1412034MixupTrain:  epoch  0, batch   955 | loss: 2.2447476MixupTrain:  epoch  0, batch   956 | loss: 2.5374727MixupTrain:  epoch  0, batch   957 | loss: 2.3196716MixupTrain:  epoch  0, batch   958 | loss: 2.5991764MixupTrain:  epoch  0, batch   959 | loss: 2.3736689MixupTrain:  epoch  0, batch   960 | loss: 2.4715309MixupTrain:  epoch  0, batch   961 | loss: 2.2238238MixupTrain:  epoch  0, batch   962 | loss: 2.1008747MixupTrain:  epoch  0, batch   963 | loss: 2.2037210MixupTrain:  epoch  0, batch   964 | loss: 2.6637063MixupTrain:  epoch  0, batch   965 | loss: 2.4647188MixupTrain:  epoch  0, batch   966 | loss: 2.6360302MixupTrain:  epoch  0, batch   967 | loss: 2.5595932MixupTrain:  epoch  0, batch   968 | loss: 2.3991010MixupTrain:  epoch  0, batch   969 | loss: 2.5824599MixupTrain:  epoch  0, batch   970 | loss: 2.6519856MixupTrain:  epoch  0, batch   971 | loss: 2.3288345MixupTrain:  epoch  0, batch   972 | loss: 2.0735140MixupTrain:  epoch  0, batch   973 | loss: 2.4188197MixupTrain:  epoch  0, batch   974 | loss: 2.3500204MixupTrain:  epoch  0, batch   975 | loss: 2.5061326MixupTrain:  epoch  0, batch   976 | loss: 2.3762209MixupTrain:  epoch  0, batch   977 | loss: 2.3678908MixupTrain:  epoch  0, batch   978 | loss: 2.3078227MixupTrain:  epoch  0, batch   979 | loss: 1.9996873MixupTrain:  epoch  0, batch   980 | loss: 2.4865162MixupTrain:  epoch  0, batch   981 | loss: 2.4001226MixupTrain:  epoch  0, batch   982 | loss: 2.5248027MixupTrain:  epoch  0, batch   983 | loss: 2.2815042MixupTrain:  epoch  0, batch   984 | loss: 2.3696790MixupTrain:  epoch  0, batch   985 | loss: 2.4233599MixupTrain:  epoch  0, batch   986 | loss: 2.2610822MixupTrain:  epoch  0, batch   987 | loss: 2.3427782MixupTrain:  epoch  0, batch   988 | loss: 2.4255166MixupTrain:  epoch  0, batch   989 | loss: 2.5552437MixupTrain:  epoch  0, batch   990 | loss: 2.5245352MixupTrain:  epoch  0, batch   991 | loss: 2.4936402MixupTrain:  epoch  0, batch   992 | loss: 2.5186529MixupTrain:  epoch  0, batch   993 | loss: 2.1926389MixupTrain:  epoch  0, batch   994 | loss: 2.7312164MixupTrain:  epoch  0, batch   995 | loss: 1.9867890MixupTrain:  epoch  0, batch   996 | loss: 2.2103105MixupTrain:  epoch  0, batch   997 | loss: 2.4354091MixupTrain:  epoch  0, batch   998 | loss: 2.2523582MixupTrain:  epoch  0, batch   999 | loss: 2.1013727MixupTrain:  epoch  0, batch  1000 | loss: 2.2699168MixupTrain:  epoch  0, batch  1001 | loss: 2.3169384MixupTrain:  epoch  0, batch  1002 | loss: 2.6421254MixupTrain:  epoch  0, batch  1003 | loss: 2.2564902MixupTrain:  epoch  0, batch  1004 | loss: 2.0295873MixupTrain:  epoch  0, batch  1005 | loss: 2.2346644MixupTrain:  epoch  0, batch  1006 | loss: 2.3337865MixupTrain:  epoch  0, batch  1007 | loss: 2.2757959MixupTrain:  epoch  0, batch  1008 | loss: 2.6577001MixupTrain:  epoch  0, batch  1009 | loss: 2.4328024MixupTrain:  epoch  0, batch  1010 | loss: 2.7088237MixupTrain:  epoch  0, batch  1011 | loss: 2.3401937MixupTrain:  epoch  0, batch  1012 | loss: 2.3685739MixupTrain:  epoch  0, batch  1013 | loss: 2.4709780MixupTrain:  epoch  0, batch  1014 | loss: 2.4430766MixupTrain:  epoch  0, batch  1015 | loss: 2.4103684MixupTrain:  epoch  0, batch  1016 | loss: 2.3552394MixupTrain:  epoch  0, batch  1017 | loss: 2.5695305MixupTrain:  epoch  0, batch  1018 | loss: 2.3454690MixupTrain:  epoch  0, batch  1019 | loss: 2.5643852MixupTrain:  epoch  0, batch  1020 | loss: 2.3774152MixupTrain:  epoch  0, batch  1021 | loss: 2.6464639MixupTrain:  epoch  0, batch  1022 | loss: 2.3492153MixupTrain:  epoch  0, batch  1023 | loss: 2.4222591MixupTrain:  epoch  0, batch  1024 | loss: 2.3411140MixupTrain:  epoch  0, batch  1025 | loss: 2.3824430MixupTrain:  epoch  0, batch  1026 | loss: 2.6434896MixupTrain:  epoch  0, batch  1027 | loss: 2.3892679MixupTrain:  epoch  0, batch  1028 | loss: 2.4657540MixupTrain:  epoch  0, batch  1029 | loss: 2.2712674MixupTrain:  epoch  0, batch  1030 | loss: 2.4953749MixupTrain:  epoch  0, batch  1031 | loss: 2.4062006MixupTrain:  epoch  0, batch  1032 | loss: 2.2122288MixupTrain:  epoch  0, batch  1033 | loss: 2.1789551MixupTrain:  epoch  0, batch  1034 | loss: 2.4312634MixupTrain:  epoch  0, batch  1035 | loss: 2.1995523MixupTrain:  epoch  0, batch  1036 | loss: 2.5581284MixupTrain:  epoch  0, batch  1037 | loss: 2.5630217MixupTrain:  epoch  0, batch  1038 | loss: 2.2235250MixupTrain:  epoch  0, batch  1039 | loss: 2.4559243MixupTrain:  epoch  0, batch  1040 | loss: 2.7556620MixupTrain:  epoch  0, batch  1041 | loss: 2.3283021MixupTrain:  epoch  0, batch  1042 | loss: 2.5498576MixupTrain:  epoch  0, batch  1043 | loss: 2.5256104MixupTrain:  epoch  0, batch  1044 | loss: 2.4115362MixupTrain:  epoch  0, batch  1045 | loss: 2.3314571MixupTrain:  epoch  0, batch  1046 | loss: 2.3527255MixupTrain:  epoch  0, batch  1047 | loss: 2.2088168MixupTrain:  epoch  0, batch  1048 | loss: 2.7447813MixupTrain:  epoch  0, batch  1049 | loss: 2.5668097MixupTrain:  epoch  0, batch  1050 | loss: 2.4118254MixupTrain:  epoch  0, batch  1051 | loss: 2.5074620MixupTrain:  epoch  0, batch  1052 | loss: 2.3701749MixupTrain:  epoch  0, batch  1053 | loss: 2.1693497MixupTrain:  epoch  0, batch  1054 | loss: 2.4744072MixupTrain:  epoch  0, batch  1055 | loss: 2.6037741MixupTrain:  epoch  0, batch  1056 | loss: 2.4358058MixupTrain:  epoch  0, batch  1057 | loss: 2.5165591MixupTrain:  epoch  0, batch  1058 | loss: 2.4820399MixupTrain:  epoch  0, batch  1059 | loss: 2.7162914MixupTrain:  epoch  0, batch  1060 | loss: 2.2429719MixupTrain:  epoch  0, batch  1061 | loss: 2.2989178MixupTrain:  epoch  0, batch  1062 | loss: 2.1776593MixupTrain:  epoch  0, batch  1063 | loss: 2.3239329MixupTrain:  epoch  0, batch  1064 | loss: 2.2809870MixupTrain:  epoch  0, batch  1065 | loss: 2.5188396MixupTrain:  epoch  0, batch  1066 | loss: 2.5199413MixupTrain:  epoch  0, batch  1067 | loss: 2.6242251MixupTrain:  epoch  0, batch  1068 | loss: 2.1501236MixupTrain:  epoch  0, batch  1069 | loss: 2.4613588MixupTrain:  epoch  0, batch  1070 | loss: 2.2760301MixupTrain:  epoch  0, batch  1071 | loss: 2.3980455MixupTrain:  epoch  0, batch  1072 | loss: 2.2241397MixupTrain:  epoch  0, batch  1073 | loss: 2.2621756MixupTrain:  epoch  0, batch  1074 | loss: 2.2104256MixupTrain:  epoch  0, batch  1075 | loss: 2.4228652MixupTrain:  epoch  0, batch  1076 | loss: 2.3251781MixupTrain:  epoch  0, batch  1077 | loss: 2.5505445MixupTrain:  epoch  0, batch  1078 | loss: 2.2385569MixupTrain:  epoch  0, batch  1079 | loss: 2.1116922MixupTrain:  epoch  0, batch  1080 | loss: 2.5156698MixupTrain:  epoch  0, batch  1081 | loss: 2.3486969MixupTrain:  epoch  0, batch  1082 | loss: 2.2331533MixupTrain:  epoch  0, batch  1083 | loss: 2.0946441MixupTrain:  epoch  0, batch  1084 | loss: 2.6035366MixupTrain:  epoch  0, batch  1085 | loss: 2.5881984MixupTrain:  epoch  0, batch  1086 | loss: 2.5326054MixupTrain:  epoch  0, batch  1087 | loss: 2.5333152MixupTrain:  epoch  0, batch  1088 | loss: 2.5591145MixupTrain:  epoch  0, batch  1089 | loss: 2.2423575MixupTrain:  epoch  0, batch  1090 | loss: 2.3609633MixupTrain:  epoch  0, batch  1091 | loss: 2.1622515MixupTrain:  epoch  0, batch  1092 | loss: 2.3578808MixupTrain:  epoch  0, batch  1093 | loss: 2.5735149MixupTrain:  epoch  0, batch  1094 | loss: 2.2000127MixupTrain:  epoch  0, batch  1095 | loss: 2.3137131MixupTrain:  epoch  0, batch  1096 | loss: 2.3569992MixupTrain:  epoch  0, batch  1097 | loss: 2.2495289MixupTrain:  epoch  0, batch  1098 | loss: 2.3332117MixupTrain:  epoch  0, batch  1099 | loss: 2.1593976MixupTrain:  epoch  0, batch  1100 | loss: 2.5202308MixupTrain:  epoch  0, batch  1101 | loss: 2.5751579MixupTrain:  epoch  0, batch  1102 | loss: 2.1137514MixupTrain:  epoch  0, batch  1103 | loss: 2.3719294MixupTrain:  epoch  0, batch  1104 | loss: 2.4587169MixupTrain:  epoch  0, batch  1105 | loss: 2.6466262MixupTrain:  epoch  0, batch  1106 | loss: 2.2900088MixupTrain:  epoch  0, batch  1107 | loss: 2.5292726MixupTrain:  epoch  0, batch  1108 | loss: 2.1524148MixupTrain:  epoch  0, batch  1109 | loss: 2.4561493MixupTrain:  epoch  0, batch  1110 | loss: 2.1314378MixupTrain:  epoch  0, batch  1111 | loss: 2.5417118MixupTrain:  epoch  0, batch  1112 | loss: 2.4590788MixupTrain:  epoch  0, batch  1113 | loss: 2.3988831MixupTrain:  epoch  0, batch  1114 | loss: 2.5117111MixupTrain:  epoch  0, batch  1115 | loss: 2.4479628MixupTrain:  epoch  0, batch  1116 | loss: 2.3534584MixupTrain:  epoch  0, batch  1117 | loss: 2.4020455MixupTrain:  epoch  0, batch  1118 | loss: 2.2287927MixupTrain:  epoch  0, batch  1119 | loss: 2.4106436MixupTrain:  epoch  0, batch  1120 | loss: 2.4914074MixupTrain:  epoch  0, batch  1121 | loss: 2.2498131MixupTrain:  epoch  0, batch  1122 | loss: 2.3915761MixupTrain:  epoch  0, batch  1123 | loss: 2.2078829MixupTrain:  epoch  0, batch  1124 | loss: 2.3905199MixupTrain:  epoch  0, batch  1125 | loss: 2.2710290MixupTrain:  epoch  0, batch  1126 | loss: 2.4353678MixupTrain:  epoch  0, batch  1127 | loss: 2.2148414MixupTrain:  epoch  0, batch  1128 | loss: 2.2527034MixupTrain:  epoch  0, batch  1129 | loss: 2.1028287MixupTrain:  epoch  0, batch  1130 | loss: 2.1294107MixupTrain:  epoch  0, batch  1131 | loss: 2.2203193MixupTrain:  epoch  0, batch  1132 | loss: 2.5340505MixupTrain:  epoch  0, batch  1133 | loss: 2.5658550MixupTrain:  epoch  0, batch  1134 | loss: 2.8399918MixupTrain:  epoch  0, batch  1135 | loss: 2.3579640MixupTrain:  epoch  0, batch  1136 | loss: 2.1632600MixupTrain:  epoch  0, batch  1137 | loss: 2.2479677MixupTrain:  epoch  0, batch  1138 | loss: 2.2060337MixupTrain:  epoch  0, batch  1139 | loss: 2.1993551MixupTrain:  epoch  0, batch  1140 | loss: 2.2318256MixupTrain:  epoch  0, batch  1141 | loss: 2.2080522MixupTrain:  epoch  0, batch  1142 | loss: 2.4380417MixupTrain:  epoch  0, batch  1143 | loss: 2.4811640MixupTrain:  epoch  0, batch  1144 | loss: 2.3513684MixupTrain:  epoch  0, batch  1145 | loss: 2.5969286MixupTrain:  epoch  0, batch  1146 | loss: 2.3898513MixupTrain:  epoch  0, batch  1147 | loss: 2.5499747MixupTrain:  epoch  0, batch  1148 | loss: 2.3911290MixupTrain:  epoch  0, batch  1149 | loss: 2.1646228MixupTrain:  epoch  0, batch  1150 | loss: 2.7659769MixupTrain:  epoch  0, batch  1151 | loss: 2.3542194MixupTrain:  epoch  0, batch  1152 | loss: 2.1755245MixupTrain:  epoch  0, batch  1153 | loss: 2.4541788MixupTrain:  epoch  0, batch  1154 | loss: 2.2662396MixupTrain:  epoch  0, batch  1155 | loss: 2.4814425MixupTrain:  epoch  0, batch  1156 | loss: 2.4425201MixupTrain:  epoch  0, batch  1157 | loss: 2.2986846MixupTrain:  epoch  0, batch  1158 | loss: 2.0600209MixupTrain:  epoch  0, batch  1159 | loss: 2.8074203MixupTrain:  epoch  0, batch  1160 | loss: 2.3708177MixupTrain:  epoch  0, batch  1161 | loss: 2.0859103MixupTrain:  epoch  0, batch  1162 | loss: 2.2112489MixupTrain:  epoch  0, batch  1163 | loss: 2.3196950MixupTrain:  epoch  0, batch  1164 | loss: 2.2301683MixupTrain:  epoch  0, batch  1165 | loss: 2.5559907MixupTrain:  epoch  0, batch  1166 | loss: 2.2280195MixupTrain:  epoch  0, batch  1167 | loss: 2.5577512MixupTrain:  epoch  0, batch  1168 | loss: 2.1334805MixupTrain:  epoch  0, batch  1169 | loss: 2.3949695MixupTrain:  epoch  0, batch  1170 | loss: 2.3307538MixupTrain:  epoch  0, batch  1171 | loss: 2.2745674MixupTrain:  epoch  0, batch  1172 | loss: 2.1390581MixupTrain:  epoch  0, batch  1173 | loss: 2.3990741MixupTrain:  epoch  0, batch  1174 | loss: 2.1090355MixupTrain:  epoch  0, batch  1175 | loss: 2.1458883MixupTrain:  epoch  0, batch  1176 | loss: 2.7553527MixupTrain:  epoch  0, batch  1177 | loss: 2.2572696MixupTrain:  epoch  0, batch  1178 | loss: 2.1711342MixupTrain:  epoch  0, batch  1179 | loss: 2.1518929MixupTrain:  epoch  0, batch  1180 | loss: 2.3621969MixupTrain:  epoch  0, batch  1181 | loss: 2.2485244MixupTrain:  epoch  0, batch  1182 | loss: 2.0615399MixupTrain:  epoch  0, batch  1183 | loss: 2.2618022MixupTrain:  epoch  0, batch  1184 | loss: 2.6160524MixupTrain:  epoch  0, batch  1185 | loss: 2.1581621MixupTrain:  epoch  0, batch  1186 | loss: 2.1104145MixupTrain:  epoch  0, batch  1187 | loss: 2.5861182MixupTrain:  epoch  0, batch  1188 | loss: 2.0089297MixupTrain:  epoch  0, batch  1189 | loss: 2.4919205MixupTrain:  epoch  0, batch  1190 | loss: 2.5795271MixupTrain:  epoch  0, batch  1191 | loss: 2.3690591MixupTrain:  epoch  0, batch  1192 | loss: 2.5339909MixupTrain:  epoch  0, batch  1193 | loss: 2.5419664MixupTrain:  epoch  0, batch  1194 | loss: 2.2653933MixupTrain:  epoch  0, batch  1195 | loss: 2.3564935MixupTrain:  epoch  0, batch  1196 | loss: 2.1635218MixupTrain:  epoch  0, batch  1197 | loss: 2.3312969MixupTrain:  epoch  0, batch  1198 | loss: 2.3069720MixupTrain:  epoch  0, batch  1199 | loss: 2.3740873MixupTrain:  epoch  0, batch  1200 | loss: 2.2031755MixupTrain:  epoch  0, batch  1201 | loss: 2.3727527MixupTrain:  epoch  0, batch  1202 | loss: 2.2976291MixupTrain:  epoch  0, batch  1203 | loss: 2.1132226MixupTrain:  epoch  0, batch  1204 | loss: 2.1994820MixupTrain:  epoch  0, batch  1205 | loss: 2.2262616MixupTrain:  epoch  0, batch  1206 | loss: 2.5419660MixupTrain:  epoch  0, batch  1207 | loss: 2.4212034MixupTrain:  epoch  0, batch  1208 | loss: 2.3534088MixupTrain:  epoch  0, batch  1209 | loss: 2.4603381MixupTrain:  epoch  0, batch  1210 | loss: 2.6339159MixupTrain:  epoch  0, batch  1211 | loss: 2.2255063MixupTrain:  epoch  0, batch  1212 | loss: 2.1797109MixupTrain:  epoch  0, batch  1213 | loss: 2.2444057MixupTrain:  epoch  0, batch  1214 | loss: 2.6102557MixupTrain:  epoch  0, batch  1215 | loss: 2.2977555MixupTrain:  epoch  0, batch  1216 | loss: 2.2932324MixupTrain:  epoch  0, batch  1217 | loss: 2.2222567MixupTrain:  epoch  0, batch  1218 | loss: 2.0313427MixupTrain:  epoch  0, batch  1219 | loss: 2.3036566MixupTrain:  epoch  0, batch  1220 | loss: 2.3812180MixupTrain:  epoch  0, batch  1221 | loss: 2.4951651MixupTrain:  epoch  0, batch  1222 | loss: 2.3062730MixupTrain:  epoch  0, batch  1223 | loss: 2.5586543MixupTrain:  epoch  0, batch  1224 | loss: 2.4889364MixupTrain:  epoch  0, batch  1225 | loss: 2.2573924MixupTrain:  epoch  0, batch  1226 | loss: 2.1780682MixupTrain:  epoch  0, batch  1227 | loss: 2.2992356MixupTrain:  epoch  0, batch  1228 | loss: 2.2432389MixupTrain:  epoch  0, batch  1229 | loss: 2.3975658MixupTrain:  epoch  0, batch  1230 | loss: 2.4159112MixupTrain:  epoch  0, batch  1231 | loss: 2.2755055MixupTrain:  epoch  0, batch  1232 | loss: 2.3790112MixupTrain:  epoch  0, batch  1233 | loss: 2.1766477MixupTrain:  epoch  0, batch  1234 | loss: 2.5045495MixupTrain:  epoch  0, batch  1235 | loss: 2.5274467MixupTrain:  epoch  0, batch  1236 | loss: 2.3718874MixupTrain:  epoch  0, batch  1237 | loss: 2.3304954MixupTrain:  epoch  0, batch  1238 | loss: 2.4825871MixupTrain:  epoch  0, batch  1239 | loss: 2.3802185MixupTrain:  epoch  0, batch  1240 | loss: 2.4003148MixupTrain:  epoch  0, batch  1241 | loss: 2.4769440MixupTrain:  epoch  0, batch  1242 | loss: 2.3614776MixupTrain:  epoch  0, batch  1243 | loss: 2.3993678MixupTrain:  epoch  0, batch  1244 | loss: 2.2795463MixupTrain:  epoch  0, batch  1245 | loss: 2.3227572MixupTrain:  epoch  0, batch  1246 | loss: 2.3726604MixupTrain:  epoch  0, batch  1247 | loss: 2.6092596MixupTrain:  epoch  0, batch  1248 | loss: 2.4726140MixupTrain:  epoch  0, batch  1249 | loss: 2.1953864MixupTrain:  epoch  0, batch  1250 | loss: 2.1790988MixupTrain:  epoch  0, batch  1251 | loss: 2.4002912MixupTrain:  epoch  0, batch  1252 | loss: 2.6470819MixupTrain:  epoch  0, batch  1253 | loss: 2.7072685MixupTrain:  epoch  0, batch  1254 | loss: 2.6724846MixupTrain:  epoch  0, batch  1255 | loss: 2.4167037MixupTrain:  epoch  0, batch  1256 | loss: 2.2696795MixupTrain:  epoch  0, batch  1257 | loss: 2.1528060MixupTrain:  epoch  0, batch  1258 | loss: 2.1182964MixupTrain:  epoch  0, batch  1259 | loss: 2.4161990MixupTrain:  epoch  0, batch  1260 | loss: 2.2064176MixupTrain:  epoch  0, batch  1261 | loss: 2.3726029MixupTrain:  epoch  0, batch  1262 | loss: 2.2714210MixupTrain:  epoch  0, batch  1263 | loss: 2.2535043MixupTrain:  epoch  0, batch  1264 | loss: 2.3189714MixupTrain:  epoch  0, batch  1265 | loss: 2.0828636MixupTrain:  epoch  0, batch  1266 | loss: 2.1757154MixupTrain:  epoch  0, batch  1267 | loss: 2.3133106MixupTrain:  epoch  0, batch  1268 | loss: 2.4685993MixupTrain:  epoch  0, batch  1269 | loss: 2.2722633MixupTrain:  epoch  0, batch  1270 | loss: 2.5463145MixupTrain:  epoch  0, batch  1271 | loss: 2.3957849MixupTrain:  epoch  0, batch  1272 | loss: 2.4833035MixupTrain:  epoch  0, batch  1273 | loss: 2.1956871MixupTrain:  epoch  0, batch  1274 | loss: 2.2304235MixupTrain:  epoch  0, batch  1275 | loss: 2.4252572MixupTrain:  epoch  0, batch  1276 | loss: 2.1001115MixupTrain:  epoch  0, batch  1277 | loss: 2.3755400MixupTrain:  epoch  0, batch  1278 | loss: 2.5299349MixupTrain:  epoch  0, batch  1279 | loss: 2.4892046MixupTrain:  epoch  0, batch  1280 | loss: 2.1202159MixupTrain:  epoch  0, batch  1281 | loss: 2.4162776MixupTrain:  epoch  0, batch  1282 | loss: 2.4837778MixupTrain:  epoch  0, batch  1283 | loss: 2.5875807MixupTrain:  epoch  0, batch  1284 | loss: 2.3880739MixupTrain:  epoch  0, batch  1285 | loss: 2.6201725MixupTrain:  epoch  0, batch  1286 | loss: 2.7636337MixupTrain:  epoch  0, batch  1287 | loss: 2.3913050MixupTrain:  epoch  0, batch  1288 | loss: 2.6185889MixupTrain:  epoch  0, batch  1289 | loss: 2.3313558MixupTrain:  epoch  0, batch  1290 | loss: 2.3110447MixupTrain:  epoch  0, batch  1291 | loss: 2.3388846MixupTrain:  epoch  0, batch  1292 | loss: 2.4846365MixupTrain:  epoch  0, batch  1293 | loss: 2.6139610MixupTrain:  epoch  0, batch  1294 | loss: 2.3309989MixupTrain:  epoch  0, batch  1295 | loss: 2.4102669MixupTrain:  epoch  0, batch  1296 | loss: 2.2488978MixupTrain:  epoch  0, batch  1297 | loss: 2.4684029MixupTrain:  epoch  0, batch  1298 | loss: 2.4744956MixupTrain:  epoch  0, batch  1299 | loss: 2.2972646MixupTrain:  epoch  0, batch  1300 | loss: 2.3169012MixupTrain:  epoch  0, batch  1301 | loss: 2.2365398MixupTrain:  epoch  0, batch  1302 | loss: 2.6097984MixupTrain:  epoch  0, batch  1303 | loss: 2.5541050MixupTrain:  epoch  0, batch  1304 | loss: 2.4550524MixupTrain:  epoch  0, batch  1305 | loss: 2.5445428MixupTrain:  epoch  0, batch  1306 | loss: 2.3934245MixupTrain:  epoch  0, batch  1307 | loss: 2.3413670MixupTrain:  epoch  0, batch  1308 | loss: 2.4897468MixupTrain:  epoch  0, batch  1309 | loss: 2.7341290MixupTrain:  epoch  0, batch  1310 | loss: 2.2423489MixupTrain:  epoch  0, batch  1311 | loss: 2.3372009MixupTrain:  epoch  0, batch  1312 | loss: 2.1968987MixupTrain:  epoch  0, batch  1313 | loss: 2.3390608MixupTrain:  epoch  0, batch  1314 | loss: 2.3528662MixupTrain:  epoch  0, batch  1315 | loss: 2.1370473MixupTrain:  epoch  0, batch  1316 | loss: 2.4380589MixupTrain:  epoch  0, batch  1317 | loss: 2.2984896MixupTrain:  epoch  0, batch  1318 | loss: 2.3816838MixupTrain:  epoch  0, batch  1319 | loss: 2.1792934MixupTrain:  epoch  0, batch  1320 | loss: 2.5304792MixupTrain:  epoch  0, batch  1321 | loss: 2.0991430MixupTrain:  epoch  0, batch  1322 | loss: 2.5825310MixupTrain:  epoch  0, batch  1323 | loss: 2.4238966MixupTrain:  epoch  0, batch  1324 | loss: 2.3846827MixupTrain:  epoch  0, batch  1325 | loss: 2.1108251MixupTrain:  epoch  0, batch  1326 | loss: 2.3911824MixupTrain:  epoch  0, batch  1327 | loss: 2.6424913MixupTrain:  epoch  0, batch  1328 | loss: 2.1713929MixupTrain:  epoch  0, batch  1329 | loss: 2.5022347MixupTrain:  epoch  0, batch  1330 | loss: 2.3544459MixupTrain:  epoch  0, batch  1331 | loss: 2.3536589MixupTrain:  epoch  0, batch  1332 | loss: 2.4010682MixupTrain:  epoch  0, batch  1333 | loss: 2.6257885MixupTrain:  epoch  0, batch  1334 | loss: 2.4326379MixupTrain:  epoch  0, batch  1335 | loss: 2.3956909MixupTrain:  epoch  0, batch  1336 | loss: 2.0489106MixupTrain:  epoch  0, batch  1337 | loss: 2.5833647MixupTrain:  epoch  0, batch  1338 | loss: 2.5501633MixupTrain:  epoch  0, batch  1339 | loss: 2.2961874MixupTrain:  epoch  0, batch  1340 | loss: 2.3057184MixupTrain:  epoch  0, batch  1341 | loss: 2.1495547MixupTrain:  epoch  0, batch  1342 | loss: 2.2958374MixupTrain:  epoch  0, batch  1343 | loss: 2.4297602
MemoryTrain:  epoch  0, batch     0 | loss: 2.4516506MemoryTrain:  epoch  0, batch     1 | loss: 3.0093639MemoryTrain:  epoch  0, batch     2 | loss: 2.6674864MemoryTrain:  epoch  0, batch     3 | loss: 2.7524233MemoryTrain:  epoch  0, batch     4 | loss: 2.3453445MemoryTrain:  epoch  0, batch     5 | loss: 2.3868520MemoryTrain:  epoch  0, batch     6 | loss: 3.1252747MemoryTrain:  epoch  0, batch     7 | loss: 2.6878834MemoryTrain:  epoch  0, batch     8 | loss: 2.2961831MemoryTrain:  epoch  0, batch     9 | loss: 2.5926101MemoryTrain:  epoch  0, batch    10 | loss: 2.2992420MemoryTrain:  epoch  0, batch    11 | loss: 1.9706414MemoryTrain:  epoch  1, batch     0 | loss: 1.8568726MemoryTrain:  epoch  1, batch     1 | loss: 1.8712854MemoryTrain:  epoch  1, batch     2 | loss: 1.8324568MemoryTrain:  epoch  1, batch     3 | loss: 1.8852251MemoryTrain:  epoch  1, batch     4 | loss: 1.8728113MemoryTrain:  epoch  1, batch     5 | loss: 1.8423340MemoryTrain:  epoch  1, batch     6 | loss: 1.8499910MemoryTrain:  epoch  1, batch     7 | loss: 1.8279772MemoryTrain:  epoch  1, batch     8 | loss: 1.8577194MemoryTrain:  epoch  1, batch     9 | loss: 1.8344488MemoryTrain:  epoch  1, batch    10 | loss: 1.8660522MemoryTrain:  epoch  1, batch    11 | loss: 1.8203589MemoryTrain:  epoch  2, batch     0 | loss: 1.8239557MemoryTrain:  epoch  2, batch     1 | loss: 1.8255987MemoryTrain:  epoch  2, batch     2 | loss: 1.8360565MemoryTrain:  epoch  2, batch     3 | loss: 1.8572420MemoryTrain:  epoch  2, batch     4 | loss: 1.8212200MemoryTrain:  epoch  2, batch     5 | loss: 1.8242532MemoryTrain:  epoch  2, batch     6 | loss: 1.8193218MemoryTrain:  epoch  2, batch     7 | loss: 1.8374746MemoryTrain:  epoch  2, batch     8 | loss: 1.8295679MemoryTrain:  epoch  2, batch     9 | loss: 1.8309014MemoryTrain:  epoch  2, batch    10 | loss: 1.8176540MemoryTrain:  epoch  2, batch    11 | loss: 1.8060194MemoryTrain:  epoch  3, batch     0 | loss: 1.8178823MemoryTrain:  epoch  3, batch     1 | loss: 1.8122426MemoryTrain:  epoch  3, batch     2 | loss: 1.8093611MemoryTrain:  epoch  3, batch     3 | loss: 1.8365788MemoryTrain:  epoch  3, batch     4 | loss: 1.8214110MemoryTrain:  epoch  3, batch     5 | loss: 1.8129129MemoryTrain:  epoch  3, batch     6 | loss: 1.8142823MemoryTrain:  epoch  3, batch     7 | loss: 1.8117564MemoryTrain:  epoch  3, batch     8 | loss: 1.8160100MemoryTrain:  epoch  3, batch     9 | loss: 1.8145504MemoryTrain:  epoch  3, batch    10 | loss: 1.8164798MemoryTrain:  epoch  3, batch    11 | loss: 1.8156204MemoryTrain:  epoch  4, batch     0 | loss: 1.8137374MemoryTrain:  epoch  4, batch     1 | loss: 1.8120217MemoryTrain:  epoch  4, batch     2 | loss: 1.8110206MemoryTrain:  epoch  4, batch     3 | loss: 1.8129380MemoryTrain:  epoch  4, batch     4 | loss: 1.8134537MemoryTrain:  epoch  4, batch     5 | loss: 1.8113964MemoryTrain:  epoch  4, batch     6 | loss: 1.8159723MemoryTrain:  epoch  4, batch     7 | loss: 1.8113062MemoryTrain:  epoch  4, batch     8 | loss: 1.8195083MemoryTrain:  epoch  4, batch     9 | loss: 1.8110054MemoryTrain:  epoch  4, batch    10 | loss: 1.8174388MemoryTrain:  epoch  4, batch    11 | loss: 1.8069180MemoryTrain:  epoch  5, batch     0 | loss: 1.8118825MemoryTrain:  epoch  5, batch     1 | loss: 1.8206539MemoryTrain:  epoch  5, batch     2 | loss: 1.8311903MemoryTrain:  epoch  5, batch     3 | loss: 1.8122107MemoryTrain:  epoch  5, batch     4 | loss: 1.8158188MemoryTrain:  epoch  5, batch     5 | loss: 1.8197924MemoryTrain:  epoch  5, batch     6 | loss: 1.8088863MemoryTrain:  epoch  5, batch     7 | loss: 1.8258295MemoryTrain:  epoch  5, batch     8 | loss: 1.8138318MemoryTrain:  epoch  5, batch     9 | loss: 1.8350024MemoryTrain:  epoch  5, batch    10 | loss: 1.8184404MemoryTrain:  epoch  5, batch    11 | loss: 1.8218358MemoryTrain:  epoch  6, batch     0 | loss: 1.8255715MemoryTrain:  epoch  6, batch     1 | loss: 1.8136481MemoryTrain:  epoch  6, batch     2 | loss: 1.8165736MemoryTrain:  epoch  6, batch     3 | loss: 1.8142068MemoryTrain:  epoch  6, batch     4 | loss: 1.8352768MemoryTrain:  epoch  6, batch     5 | loss: 1.8175768MemoryTrain:  epoch  6, batch     6 | loss: 1.8222566MemoryTrain:  epoch  6, batch     7 | loss: 1.8074443MemoryTrain:  epoch  6, batch     8 | loss: 1.8132280MemoryTrain:  epoch  6, batch     9 | loss: 1.8099756MemoryTrain:  epoch  6, batch    10 | loss: 1.8100375MemoryTrain:  epoch  6, batch    11 | loss: 1.8316336MemoryTrain:  epoch  7, batch     0 | loss: 1.8204159MemoryTrain:  epoch  7, batch     1 | loss: 1.8139801MemoryTrain:  epoch  7, batch     2 | loss: 1.8187679MemoryTrain:  epoch  7, batch     3 | loss: 1.8077564MemoryTrain:  epoch  7, batch     4 | loss: 1.8237498MemoryTrain:  epoch  7, batch     5 | loss: 1.8171700MemoryTrain:  epoch  7, batch     6 | loss: 1.8144358MemoryTrain:  epoch  7, batch     7 | loss: 1.8115145MemoryTrain:  epoch  7, batch     8 | loss: 1.8184996MemoryTrain:  epoch  7, batch     9 | loss: 1.8108994MemoryTrain:  epoch  7, batch    10 | loss: 1.8099129MemoryTrain:  epoch  7, batch    11 | loss: 1.8259182MemoryTrain:  epoch  8, batch     0 | loss: 1.8185555MemoryTrain:  epoch  8, batch     1 | loss: 1.8087317MemoryTrain:  epoch  8, batch     2 | loss: 1.8107212MemoryTrain:  epoch  8, batch     3 | loss: 1.8201923MemoryTrain:  epoch  8, batch     4 | loss: 1.8223758MemoryTrain:  epoch  8, batch     5 | loss: 1.8211064MemoryTrain:  epoch  8, batch     6 | loss: 1.8114078MemoryTrain:  epoch  8, batch     7 | loss: 1.8127167MemoryTrain:  epoch  8, batch     8 | loss: 1.8151834MemoryTrain:  epoch  8, batch     9 | loss: 1.8169808MemoryTrain:  epoch  8, batch    10 | loss: 1.8273182MemoryTrain:  epoch  8, batch    11 | loss: 1.8100506MemoryTrain:  epoch  9, batch     0 | loss: 1.8150784MemoryTrain:  epoch  9, batch     1 | loss: 1.8097510MemoryTrain:  epoch  9, batch     2 | loss: 1.8076354MemoryTrain:  epoch  9, batch     3 | loss: 1.8174758MemoryTrain:  epoch  9, batch     4 | loss: 1.8142245MemoryTrain:  epoch  9, batch     5 | loss: 1.8166043MemoryTrain:  epoch  9, batch     6 | loss: 1.8220923MemoryTrain:  epoch  9, batch     7 | loss: 1.8102698MemoryTrain:  epoch  9, batch     8 | loss: 1.8075020MemoryTrain:  epoch  9, batch     9 | loss: 1.8185134MemoryTrain:  epoch  9, batch    10 | loss: 1.8155178MemoryTrain:  epoch  9, batch    11 | loss: 1.8139143
[EVAL] batch:    0 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    1 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    2 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    3 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    4 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    9 | acc: 81.25%,  total acc: 98.12%   [EVAL] batch:   10 | acc: 81.25%,  total acc: 96.59%   [EVAL] batch:   11 | acc: 100.00%,  total acc: 96.88%   [EVAL] batch:   12 | acc: 100.00%,  total acc: 97.12%   [EVAL] batch:   13 | acc: 75.00%,  total acc: 95.54%   
[EVAL] batch:    0 | acc: 12.50%,  total acc: 12.50%   [EVAL] batch:    1 | acc: 12.50%,  total acc: 12.50%   [EVAL] batch:    2 | acc: 12.50%,  total acc: 12.50%   [EVAL] batch:    3 | acc: 6.25%,  total acc: 10.94%   [EVAL] batch:    4 | acc: 18.75%,  total acc: 12.50%   [EVAL] batch:    5 | acc: 31.25%,  total acc: 15.62%   [EVAL] batch:    6 | acc: 25.00%,  total acc: 16.96%   [EVAL] batch:    7 | acc: 37.50%,  total acc: 19.53%   [EVAL] batch:    8 | acc: 62.50%,  total acc: 24.31%   [EVAL] batch:    9 | acc: 12.50%,  total acc: 23.12%   [EVAL] batch:   10 | acc: 25.00%,  total acc: 23.30%   [EVAL] batch:   11 | acc: 37.50%,  total acc: 24.48%   [EVAL] batch:   12 | acc: 12.50%,  total acc: 23.56%   [EVAL] batch:   13 | acc: 25.00%,  total acc: 23.66%   [EVAL] batch:   14 | acc: 37.50%,  total acc: 24.58%   [EVAL] batch:   15 | acc: 43.75%,  total acc: 25.78%   [EVAL] batch:   16 | acc: 43.75%,  total acc: 26.84%   [EVAL] batch:   17 | acc: 56.25%,  total acc: 28.47%   [EVAL] batch:   18 | acc: 56.25%,  total acc: 29.93%   [EVAL] batch:   19 | acc: 50.00%,  total acc: 30.94%   [EVAL] batch:   20 | acc: 75.00%,  total acc: 33.04%   [EVAL] batch:   21 | acc: 87.50%,  total acc: 35.51%   [EVAL] batch:   22 | acc: 56.25%,  total acc: 36.41%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 38.80%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 41.00%   [EVAL] batch:   25 | acc: 81.25%,  total acc: 42.55%   [EVAL] batch:   26 | acc: 50.00%,  total acc: 42.82%   [EVAL] batch:   27 | acc: 31.25%,  total acc: 42.41%   [EVAL] batch:   28 | acc: 12.50%,  total acc: 41.38%   [EVAL] batch:   29 | acc: 25.00%,  total acc: 40.83%   [EVAL] batch:   30 | acc: 18.75%,  total acc: 40.12%   [EVAL] batch:   31 | acc: 31.25%,  total acc: 39.84%   [EVAL] batch:   32 | acc: 62.50%,  total acc: 40.53%   [EVAL] batch:   33 | acc: 12.50%,  total acc: 39.71%   [EVAL] batch:   34 | acc: 18.75%,  total acc: 39.11%   [EVAL] batch:   35 | acc: 0.00%,  total acc: 38.02%   [EVAL] batch:   36 | acc: 0.00%,  total acc: 36.99%   [EVAL] batch:   37 | acc: 6.25%,  total acc: 36.18%   [EVAL] batch:   38 | acc: 6.25%,  total acc: 35.42%   [EVAL] batch:   39 | acc: 75.00%,  total acc: 36.41%   [EVAL] batch:   40 | acc: 75.00%,  total acc: 37.35%   [EVAL] batch:   41 | acc: 81.25%,  total acc: 38.39%   [EVAL] batch:   42 | acc: 87.50%,  total acc: 39.53%   [EVAL] batch:   43 | acc: 81.25%,  total acc: 40.48%   [EVAL] batch:   44 | acc: 75.00%,  total acc: 41.25%   [EVAL] batch:   45 | acc: 43.75%,  total acc: 41.30%   [EVAL] batch:   46 | acc: 68.75%,  total acc: 41.89%   [EVAL] batch:   47 | acc: 81.25%,  total acc: 42.71%   [EVAL] batch:   48 | acc: 37.50%,  total acc: 42.60%   [EVAL] batch:   49 | acc: 93.75%,  total acc: 43.62%   [EVAL] batch:   50 | acc: 87.50%,  total acc: 44.49%   [EVAL] batch:   51 | acc: 100.00%,  total acc: 45.55%   [EVAL] batch:   52 | acc: 100.00%,  total acc: 46.58%   [EVAL] batch:   53 | acc: 100.00%,  total acc: 47.57%   [EVAL] batch:   54 | acc: 100.00%,  total acc: 48.52%   [EVAL] batch:   55 | acc: 93.75%,  total acc: 49.33%   [EVAL] batch:   56 | acc: 81.25%,  total acc: 49.89%   [EVAL] batch:   57 | acc: 68.75%,  total acc: 50.22%   [EVAL] batch:   58 | acc: 87.50%,  total acc: 50.85%   [EVAL] batch:   59 | acc: 56.25%,  total acc: 50.94%   [EVAL] batch:   60 | acc: 31.25%,  total acc: 50.61%   [EVAL] batch:   61 | acc: 6.25%,  total acc: 49.90%   [EVAL] batch:   62 | acc: 12.50%,  total acc: 49.31%   [EVAL] batch:   63 | acc: 31.25%,  total acc: 49.02%   [EVAL] batch:   64 | acc: 31.25%,  total acc: 48.75%   [EVAL] batch:   65 | acc: 31.25%,  total acc: 48.48%   [EVAL] batch:   66 | acc: 18.75%,  total acc: 48.04%   [EVAL] batch:   67 | acc: 37.50%,  total acc: 47.89%   [EVAL] batch:   68 | acc: 0.00%,  total acc: 47.19%   [EVAL] batch:   69 | acc: 6.25%,  total acc: 46.61%   [EVAL] batch:   70 | acc: 12.50%,  total acc: 46.13%   [EVAL] batch:   71 | acc: 12.50%,  total acc: 45.66%   [EVAL] batch:   72 | acc: 31.25%,  total acc: 45.46%   [EVAL] batch:   73 | acc: 18.75%,  total acc: 45.10%   [EVAL] batch:   74 | acc: 25.00%,  total acc: 44.83%   [EVAL] batch:   75 | acc: 37.50%,  total acc: 44.74%   [EVAL] batch:   76 | acc: 12.50%,  total acc: 44.32%   [EVAL] batch:   77 | acc: 31.25%,  total acc: 44.15%   [EVAL] batch:   78 | acc: 43.75%,  total acc: 44.15%   [EVAL] batch:   79 | acc: 100.00%,  total acc: 44.84%   [EVAL] batch:   80 | acc: 93.75%,  total acc: 45.45%   [EVAL] batch:   81 | acc: 93.75%,  total acc: 46.04%   [EVAL] batch:   82 | acc: 93.75%,  total acc: 46.61%   [EVAL] batch:   83 | acc: 87.50%,  total acc: 47.10%   [EVAL] batch:   84 | acc: 68.75%,  total acc: 47.35%   [EVAL] batch:   85 | acc: 75.00%,  total acc: 47.67%   [EVAL] batch:   86 | acc: 68.75%,  total acc: 47.92%   [EVAL] batch:   87 | acc: 93.75%,  total acc: 48.44%   [EVAL] batch:   88 | acc: 100.00%,  total acc: 49.02%   [EVAL] batch:   89 | acc: 100.00%,  total acc: 49.58%   [EVAL] batch:   90 | acc: 100.00%,  total acc: 50.14%   [EVAL] batch:   91 | acc: 100.00%,  total acc: 50.68%   [EVAL] batch:   92 | acc: 100.00%,  total acc: 51.21%   [EVAL] batch:   93 | acc: 100.00%,  total acc: 51.73%   [EVAL] batch:   94 | acc: 100.00%,  total acc: 52.24%   [EVAL] batch:   95 | acc: 100.00%,  total acc: 52.73%   [EVAL] batch:   96 | acc: 87.50%,  total acc: 53.09%   [EVAL] batch:   97 | acc: 75.00%,  total acc: 53.32%   [EVAL] batch:   98 | acc: 100.00%,  total acc: 53.79%   [EVAL] batch:   99 | acc: 100.00%,  total acc: 54.25%   [EVAL] batch:  100 | acc: 93.75%,  total acc: 54.64%   
cur_acc:  ['0.8712', '0.9107', '0.8281', '0.8846', '0.5568', '0.9554']
his_acc:  ['0.8712', '0.8697', '0.6771', '0.5862', '0.5540', '0.5464']
CurrentTrain: epoch  0, batch     0 | loss: 6.3286324CurrentTrain: epoch  0, batch     1 | loss: 5.6863961CurrentTrain: epoch  1, batch     0 | loss: 5.2257500CurrentTrain: epoch  1, batch     1 | loss: 5.7902098CurrentTrain: epoch  2, batch     0 | loss: 4.9360919CurrentTrain: epoch  2, batch     1 | loss: 5.2847314CurrentTrain: epoch  3, batch     0 | loss: 4.4247255CurrentTrain: epoch  3, batch     1 | loss: 4.5413041CurrentTrain: epoch  4, batch     0 | loss: 4.2339368CurrentTrain: epoch  4, batch     1 | loss: 4.2499084CurrentTrain: epoch  5, batch     0 | loss: 4.4331694CurrentTrain: epoch  5, batch     1 | loss: 3.1918702CurrentTrain: epoch  6, batch     0 | loss: 3.3540668CurrentTrain: epoch  6, batch     1 | loss: 3.5678856CurrentTrain: epoch  7, batch     0 | loss: 3.1307931CurrentTrain: epoch  7, batch     1 | loss: 2.7778919CurrentTrain: epoch  8, batch     0 | loss: 2.8171430CurrentTrain: epoch  8, batch     1 | loss: 2.6637824CurrentTrain: epoch  9, batch     0 | loss: 2.4287400CurrentTrain: epoch  9, batch     1 | loss: 2.7729995
#### person stateorprovinces of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovinces of residence" means a person is living in a state or province.
Here is an example:
Relation: person stateorprovinces of residence
Context: the chairman of the senate foreign relations committee , massachusetts democrat john kerry , and the panel 's top republican , richard lugar of indiana , were at the white house meeting , which was led by vice president joe biden , a former chairman of the foreign relations panel .
Head Entity: john kerry
Tail Entity: massachusetts
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovinces of residence":
Relation: person stateorprovinces of residence  
Context: After moving to California for his new job, actor Tom Hanks quickly fell in love with the vibrant culture and beautiful landscapes of the state.  
Head Entity: Tom Hanks  
Tail Entity: California  

Relation: person stateorprovinces of residence  
Context: The famous author, J.K. Rowling, has spent many years living in Edinburgh, where she found inspiration for her beloved Harry Potter series.  
Head Entity: J.K. Rowling  
Tail Entity: Edinburgh  

Relation: person stateorprovinces of residence  
Context: Following his retirement, former basketball player Michael Jordan decided to settle down in Florida, enjoying the warm weather and golf courses.  
Head Entity: Michael Jordan  
Tail Entity: Florida  

Relation: person stateorprovinces of residence  
Context: Renowned scientist Albert Einstein spent a significant part of his life in Princeton, New Jersey, where he conducted groundbreaking research.  
Head Entity: Albert Einstein  
Tail Entity: Princeton  

Relation: person stateorprovinces of residence  
Context: After years of touring, singer Taylor Swift finally bought a home in Nashville, Tennessee, where she started her music career.  
Head Entity: Taylor Swift  
Tail Entity: Nashville  
#### person date of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person date of death" means a person was died on a date.
Here is an example:
Relation: person date of death
Context: today the nypd upgraded the charges to include murder , in the case of brooklyn gay-bashing/robbery victim michael sandy , who died on friday after being taken off life-support .
Head Entity: michael sandy
Tail Entity: friday
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person date of death":
Relation: person date of death  
Context: The renowned physicist Stephen Hawking passed away peacefully at his home in Cambridge on March 14, 2018, at the age of 76.  
Head Entity: Stephen Hawking  
Tail Entity: March 14, 2018  

Relation: person date of death  
Context: The beloved actor Robin Williams was found dead in his home in Paradise Cay, California, on August 11, 2014, which shocked fans around the world.  
Head Entity: Robin Williams  
Tail Entity: August 11, 2014  

Relation: person date of death  
Context: The famous singer Whitney Houston was found dead in a bathtub at the Beverly Hilton Hotel on February 11, 2012, just a day before the Grammy Awards.  
Head Entity: Whitney Houston  
Tail Entity: February 11, 2012  

Relation: person date of death  
Context: The legendary civil rights leader Martin Luther King Jr. was assassinated on April 4, 1968, in Memphis, Tennessee, leaving a lasting legacy.  
Head Entity: Martin Luther King Jr.  
Tail Entity: April 4, 1968  

Relation: person date of death  
Context: The iconic fashion designer Karl Lagerfeld passed away on February 19, 2019, in Paris, leaving behind a remarkable influence on the fashion industry.  
Head Entity: Karl Lagerfeld  
Tail Entity: February 19, 2019  
#### organization number of employees members ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization number of employees members" means the number of an organization 's employees is a number.
Here is an example:
Relation: organization number of employees members
Context: covidien , which posted revenue of more than $ 10 billion last year , has about 42,000 employees worldwide .
Head Entity: covidien
Tail Entity: 42,000
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization number of employees members":
Relation: organization number of employees members  
Context: TechCorp, a leading software development company, employs approximately 5,500 people across its global offices.  
Head Entity: TechCorp  
Tail Entity: 5,500  

Relation: organization number of employees members  
Context: The nonprofit organization Helping Hands has grown significantly and now has over 1,200 volunteers working on various community projects.  
Head Entity: Helping Hands  
Tail Entity: 1,200  

Relation: organization number of employees members  
Context: With a workforce of around 3,000, Green Energy Solutions is committed to sustainable practices and innovation in the renewable energy sector.  
Head Entity: Green Energy Solutions  
Tail Entity: 3,000  

Relation: organization number of employees members  
Context: After a recent expansion, Global Logistics now boasts a team of 10,000 employees dedicated to improving supply chain efficiency.  
Head Entity: Global Logistics  
Tail Entity: 10,000  

Relation: organization number of employees members  
Context: The prestigious university, Knowledge Institute, has a staff of nearly 2,500 faculty and administrative members.  
Head Entity: Knowledge Institute  
Tail Entity: 2,500  
#### person alternate names ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person alternate names" means a person 's alias is a person.
Here is an example:
Relation: person alternate names
Context: a judge in new york city said remy ma , whose real name is remy smith , said thursday that the hip-hopper could not leave the united states for a five-country european concert tour .
Head Entity: remy smith
Tail Entity: remy ma
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person alternate names":
Relation: person alternate names  
Context: The famous author Samuel Langhorne Clemens, better known by his pen name Mark Twain, is celebrated for his novels like "The Adventures of Tom Sawyer."  
Head Entity: Samuel Langhorne Clemens  
Tail Entity: Mark Twain  

Relation: person alternate names  
Context: The musician Stefani Joanne Angelina Germanotta, who is widely recognized as Lady Gaga, has made a significant impact on the pop music scene.  
Head Entity: Stefani Joanne Angelina Germanotta  
Tail Entity: Lady Gaga  

Relation: person alternate names  
Context: The actor and filmmaker known as Orson Welles was born George Orson Welles and is famous for his groundbreaking work in cinema.  
Head Entity: George Orson Welles  
Tail Entity: Orson Welles  

Relation: person alternate names  
Context: The renowned physicist Albert Einstein, who is often referred to simply as Einstein, developed the theory of relativity.  
Head Entity: Albert Einstein  
Tail Entity: Einstein  

Relation: person alternate names  
Context: The pop star Robyn Rihanna Fenty, better known as Rihanna, has won numerous awards for her music and philanthropy.  
Head Entity: Robyn Rihanna Fenty  
Tail Entity: Rihanna  
#### person spouse ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person spouse" means a person 's spouse is a person.
Here is an example:
Relation: person spouse
Context: smits stands at the center of this multigenerational saga as alex vega , the adopted son of rum and sugar baron pancho duque -lrb- elizondo -rrb- and his wife , amalia -lrb- moreno -rrb- .
Head Entity: elizondo
Tail Entity: moreno
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person spouse":
Relation: person spouse  
Context: After years of friendship, Sarah finally married her college sweetheart, John, who has always been her biggest supporter.  
Head Entity: Sarah  
Tail Entity: John  

Relation: person spouse  
Context: In the royal family, Queen Elizabeth II was married to Prince Philip, who played a significant role in her reign.  
Head Entity: Elizabeth II  
Tail Entity: Prince Philip  

Relation: person spouse  
Context: During the gala, everyone admired the beautiful couple, where Michael was seen dancing with his lovely wife, Jessica.  
Head Entity: Michael  
Tail Entity: Jessica  

Relation: person spouse  
Context: The documentary highlighted the life of famous actor Tom Hanks and his enduring love for his wife, Rita Wilson.  
Head Entity: Tom Hanks  
Tail Entity: Rita Wilson  

Relation: person spouse  
Context: At the family reunion, everyone gathered to celebrate the anniversary of David and his beloved partner, Lisa.  
Head Entity: David  
Tail Entity: Lisa  
Mixup data size:  28180
MixupTrain:  epoch  0, batch     0 | loss: 3.1517403MixupTrain:  epoch  0, batch     1 | loss: 2.9237318MixupTrain:  epoch  0, batch     2 | loss: 4.0943460MixupTrain:  epoch  0, batch     3 | loss: 3.3665917MixupTrain:  epoch  0, batch     4 | loss: 3.4684792MixupTrain:  epoch  0, batch     5 | loss: 4.0239968MixupTrain:  epoch  0, batch     6 | loss: 3.3918977MixupTrain:  epoch  0, batch     7 | loss: 3.8620176MixupTrain:  epoch  0, batch     8 | loss: 3.7288518MixupTrain:  epoch  0, batch     9 | loss: 3.8396192MixupTrain:  epoch  0, batch    10 | loss: 3.8816550MixupTrain:  epoch  0, batch    11 | loss: 3.2766180MixupTrain:  epoch  0, batch    12 | loss: 3.9479194MixupTrain:  epoch  0, batch    13 | loss: 3.1381848MixupTrain:  epoch  0, batch    14 | loss: 3.2976809MixupTrain:  epoch  0, batch    15 | loss: 3.0723262MixupTrain:  epoch  0, batch    16 | loss: 3.0675883MixupTrain:  epoch  0, batch    17 | loss: 3.2202597MixupTrain:  epoch  0, batch    18 | loss: 4.2225504MixupTrain:  epoch  0, batch    19 | loss: 3.2221417MixupTrain:  epoch  0, batch    20 | loss: 2.2859316MixupTrain:  epoch  0, batch    21 | loss: 3.4716754MixupTrain:  epoch  0, batch    22 | loss: 2.7176156MixupTrain:  epoch  0, batch    23 | loss: 3.1478190MixupTrain:  epoch  0, batch    24 | loss: 3.6459219MixupTrain:  epoch  0, batch    25 | loss: 2.7135458MixupTrain:  epoch  0, batch    26 | loss: 3.0124927MixupTrain:  epoch  0, batch    27 | loss: 3.0410781MixupTrain:  epoch  0, batch    28 | loss: 3.5656934MixupTrain:  epoch  0, batch    29 | loss: 2.7885835MixupTrain:  epoch  0, batch    30 | loss: 3.0190213MixupTrain:  epoch  0, batch    31 | loss: 3.0950913MixupTrain:  epoch  0, batch    32 | loss: 3.9380977MixupTrain:  epoch  0, batch    33 | loss: 2.8257549MixupTrain:  epoch  0, batch    34 | loss: 4.1155224MixupTrain:  epoch  0, batch    35 | loss: 3.1292341MixupTrain:  epoch  0, batch    36 | loss: 3.4280872MixupTrain:  epoch  0, batch    37 | loss: 3.0819073MixupTrain:  epoch  0, batch    38 | loss: 2.6271892MixupTrain:  epoch  0, batch    39 | loss: 3.7732286MixupTrain:  epoch  0, batch    40 | loss: 3.4938624MixupTrain:  epoch  0, batch    41 | loss: 3.9026368MixupTrain:  epoch  0, batch    42 | loss: 3.0148365MixupTrain:  epoch  0, batch    43 | loss: 3.2215648MixupTrain:  epoch  0, batch    44 | loss: 2.6571751MixupTrain:  epoch  0, batch    45 | loss: 3.7046623MixupTrain:  epoch  0, batch    46 | loss: 2.9807036MixupTrain:  epoch  0, batch    47 | loss: 2.9123254MixupTrain:  epoch  0, batch    48 | loss: 3.1492062MixupTrain:  epoch  0, batch    49 | loss: 2.7453661MixupTrain:  epoch  0, batch    50 | loss: 2.2634847MixupTrain:  epoch  0, batch    51 | loss: 2.6487150MixupTrain:  epoch  0, batch    52 | loss: 3.2942672MixupTrain:  epoch  0, batch    53 | loss: 2.8735702MixupTrain:  epoch  0, batch    54 | loss: 3.0189712MixupTrain:  epoch  0, batch    55 | loss: 2.6026013MixupTrain:  epoch  0, batch    56 | loss: 3.5152450MixupTrain:  epoch  0, batch    57 | loss: 3.2875304MixupTrain:  epoch  0, batch    58 | loss: 3.5997849MixupTrain:  epoch  0, batch    59 | loss: 2.7543750MixupTrain:  epoch  0, batch    60 | loss: 2.3691974MixupTrain:  epoch  0, batch    61 | loss: 3.1269581MixupTrain:  epoch  0, batch    62 | loss: 3.0533285MixupTrain:  epoch  0, batch    63 | loss: 3.4382234MixupTrain:  epoch  0, batch    64 | loss: 2.4247050MixupTrain:  epoch  0, batch    65 | loss: 3.1005220MixupTrain:  epoch  0, batch    66 | loss: 3.3724041MixupTrain:  epoch  0, batch    67 | loss: 2.6384940MixupTrain:  epoch  0, batch    68 | loss: 2.3493001MixupTrain:  epoch  0, batch    69 | loss: 2.2747278MixupTrain:  epoch  0, batch    70 | loss: 2.6859329MixupTrain:  epoch  0, batch    71 | loss: 2.8401599MixupTrain:  epoch  0, batch    72 | loss: 2.6949987MixupTrain:  epoch  0, batch    73 | loss: 2.7398524MixupTrain:  epoch  0, batch    74 | loss: 3.0901408MixupTrain:  epoch  0, batch    75 | loss: 2.3363435MixupTrain:  epoch  0, batch    76 | loss: 2.6969109MixupTrain:  epoch  0, batch    77 | loss: 2.2424233MixupTrain:  epoch  0, batch    78 | loss: 2.8815122MixupTrain:  epoch  0, batch    79 | loss: 2.5545812MixupTrain:  epoch  0, batch    80 | loss: 2.9501123MixupTrain:  epoch  0, batch    81 | loss: 2.5778737MixupTrain:  epoch  0, batch    82 | loss: 2.5679083MixupTrain:  epoch  0, batch    83 | loss: 2.9382772MixupTrain:  epoch  0, batch    84 | loss: 2.6983409MixupTrain:  epoch  0, batch    85 | loss: 2.8882587MixupTrain:  epoch  0, batch    86 | loss: 2.4270887MixupTrain:  epoch  0, batch    87 | loss: 2.4558201MixupTrain:  epoch  0, batch    88 | loss: 2.2750583MixupTrain:  epoch  0, batch    89 | loss: 2.4985604MixupTrain:  epoch  0, batch    90 | loss: 2.5776472MixupTrain:  epoch  0, batch    91 | loss: 2.7312379MixupTrain:  epoch  0, batch    92 | loss: 2.1388555MixupTrain:  epoch  0, batch    93 | loss: 2.6494069MixupTrain:  epoch  0, batch    94 | loss: 2.8455234MixupTrain:  epoch  0, batch    95 | loss: 3.0916820MixupTrain:  epoch  0, batch    96 | loss: 2.8156040MixupTrain:  epoch  0, batch    97 | loss: 2.4940772MixupTrain:  epoch  0, batch    98 | loss: 3.0298982MixupTrain:  epoch  0, batch    99 | loss: 2.7529321MixupTrain:  epoch  0, batch   100 | loss: 2.7466357MixupTrain:  epoch  0, batch   101 | loss: 2.8946352MixupTrain:  epoch  0, batch   102 | loss: 2.4626541MixupTrain:  epoch  0, batch   103 | loss: 2.4161854MixupTrain:  epoch  0, batch   104 | loss: 2.2509770MixupTrain:  epoch  0, batch   105 | loss: 2.4039459MixupTrain:  epoch  0, batch   106 | loss: 2.4411337MixupTrain:  epoch  0, batch   107 | loss: 2.4872298MixupTrain:  epoch  0, batch   108 | loss: 2.6494050MixupTrain:  epoch  0, batch   109 | loss: 2.3880777MixupTrain:  epoch  0, batch   110 | loss: 2.1460345MixupTrain:  epoch  0, batch   111 | loss: 2.3798256MixupTrain:  epoch  0, batch   112 | loss: 2.3448677MixupTrain:  epoch  0, batch   113 | loss: 2.3422735MixupTrain:  epoch  0, batch   114 | loss: 2.5348468MixupTrain:  epoch  0, batch   115 | loss: 2.6649423MixupTrain:  epoch  0, batch   116 | loss: 2.1629648MixupTrain:  epoch  0, batch   117 | loss: 2.5068550MixupTrain:  epoch  0, batch   118 | loss: 2.8123512MixupTrain:  epoch  0, batch   119 | loss: 2.9170291MixupTrain:  epoch  0, batch   120 | loss: 2.5095649MixupTrain:  epoch  0, batch   121 | loss: 2.7485065MixupTrain:  epoch  0, batch   122 | loss: 2.4518161MixupTrain:  epoch  0, batch   123 | loss: 2.6832941MixupTrain:  epoch  0, batch   124 | loss: 2.3317022MixupTrain:  epoch  0, batch   125 | loss: 2.0386360MixupTrain:  epoch  0, batch   126 | loss: 2.6293139MixupTrain:  epoch  0, batch   127 | loss: 2.1201477MixupTrain:  epoch  0, batch   128 | loss: 2.6452928MixupTrain:  epoch  0, batch   129 | loss: 2.2883027MixupTrain:  epoch  0, batch   130 | loss: 2.8187962MixupTrain:  epoch  0, batch   131 | loss: 2.3565068MixupTrain:  epoch  0, batch   132 | loss: 2.6209321MixupTrain:  epoch  0, batch   133 | loss: 2.6044562MixupTrain:  epoch  0, batch   134 | loss: 2.3035178MixupTrain:  epoch  0, batch   135 | loss: 2.5462165MixupTrain:  epoch  0, batch   136 | loss: 2.8709226MixupTrain:  epoch  0, batch   137 | loss: 2.2835517MixupTrain:  epoch  0, batch   138 | loss: 2.4472454MixupTrain:  epoch  0, batch   139 | loss: 2.5526981MixupTrain:  epoch  0, batch   140 | loss: 2.5270827MixupTrain:  epoch  0, batch   141 | loss: 2.6092286MixupTrain:  epoch  0, batch   142 | loss: 2.3480341MixupTrain:  epoch  0, batch   143 | loss: 2.4974720MixupTrain:  epoch  0, batch   144 | loss: 2.3254187MixupTrain:  epoch  0, batch   145 | loss: 2.7270551MixupTrain:  epoch  0, batch   146 | loss: 2.5068340MixupTrain:  epoch  0, batch   147 | loss: 2.2348595MixupTrain:  epoch  0, batch   148 | loss: 2.4792132MixupTrain:  epoch  0, batch   149 | loss: 2.6720607MixupTrain:  epoch  0, batch   150 | loss: 2.3572123MixupTrain:  epoch  0, batch   151 | loss: 2.8243384MixupTrain:  epoch  0, batch   152 | loss: 2.3329864MixupTrain:  epoch  0, batch   153 | loss: 2.3870373MixupTrain:  epoch  0, batch   154 | loss: 2.7185822MixupTrain:  epoch  0, batch   155 | loss: 2.5565414MixupTrain:  epoch  0, batch   156 | loss: 2.5495391MixupTrain:  epoch  0, batch   157 | loss: 2.2377803MixupTrain:  epoch  0, batch   158 | loss: 2.5377483MixupTrain:  epoch  0, batch   159 | loss: 2.5203638MixupTrain:  epoch  0, batch   160 | loss: 2.6249409MixupTrain:  epoch  0, batch   161 | loss: 2.3421192MixupTrain:  epoch  0, batch   162 | loss: 2.1982670MixupTrain:  epoch  0, batch   163 | loss: 2.6710675MixupTrain:  epoch  0, batch   164 | loss: 2.6836181MixupTrain:  epoch  0, batch   165 | loss: 2.5021393MixupTrain:  epoch  0, batch   166 | loss: 2.5529571MixupTrain:  epoch  0, batch   167 | loss: 2.2209923MixupTrain:  epoch  0, batch   168 | loss: 2.4831300MixupTrain:  epoch  0, batch   169 | loss: 2.2458050MixupTrain:  epoch  0, batch   170 | loss: 2.5187907MixupTrain:  epoch  0, batch   171 | loss: 2.8896389MixupTrain:  epoch  0, batch   172 | loss: 2.5578771MixupTrain:  epoch  0, batch   173 | loss: 2.3211906MixupTrain:  epoch  0, batch   174 | loss: 2.4476380MixupTrain:  epoch  0, batch   175 | loss: 2.3541992MixupTrain:  epoch  0, batch   176 | loss: 2.1792495MixupTrain:  epoch  0, batch   177 | loss: 2.4221356MixupTrain:  epoch  0, batch   178 | loss: 2.1783261MixupTrain:  epoch  0, batch   179 | loss: 2.2891772MixupTrain:  epoch  0, batch   180 | loss: 2.7445905MixupTrain:  epoch  0, batch   181 | loss: 2.2760677MixupTrain:  epoch  0, batch   182 | loss: 2.1297150MixupTrain:  epoch  0, batch   183 | loss: 2.5073118MixupTrain:  epoch  0, batch   184 | loss: 1.9824717MixupTrain:  epoch  0, batch   185 | loss: 2.4936152MixupTrain:  epoch  0, batch   186 | loss: 2.4371619MixupTrain:  epoch  0, batch   187 | loss: 2.3451095MixupTrain:  epoch  0, batch   188 | loss: 2.6035764MixupTrain:  epoch  0, batch   189 | loss: 2.3477130MixupTrain:  epoch  0, batch   190 | loss: 2.2995753MixupTrain:  epoch  0, batch   191 | loss: 2.1580293MixupTrain:  epoch  0, batch   192 | loss: 2.9044933MixupTrain:  epoch  0, batch   193 | loss: 2.6552582MixupTrain:  epoch  0, batch   194 | loss: 2.6623704MixupTrain:  epoch  0, batch   195 | loss: 2.2160993MixupTrain:  epoch  0, batch   196 | loss: 2.3757405MixupTrain:  epoch  0, batch   197 | loss: 2.7325144MixupTrain:  epoch  0, batch   198 | loss: 2.4830203MixupTrain:  epoch  0, batch   199 | loss: 2.4913356MixupTrain:  epoch  0, batch   200 | loss: 2.6140289MixupTrain:  epoch  0, batch   201 | loss: 2.2136288MixupTrain:  epoch  0, batch   202 | loss: 2.2524922MixupTrain:  epoch  0, batch   203 | loss: 2.4483280MixupTrain:  epoch  0, batch   204 | loss: 2.5399036MixupTrain:  epoch  0, batch   205 | loss: 2.0290160MixupTrain:  epoch  0, batch   206 | loss: 2.1512167MixupTrain:  epoch  0, batch   207 | loss: 2.1095645MixupTrain:  epoch  0, batch   208 | loss: 2.0546577MixupTrain:  epoch  0, batch   209 | loss: 2.4854453MixupTrain:  epoch  0, batch   210 | loss: 2.2675245MixupTrain:  epoch  0, batch   211 | loss: 2.5981994MixupTrain:  epoch  0, batch   212 | loss: 2.5002036MixupTrain:  epoch  0, batch   213 | loss: 2.3609219MixupTrain:  epoch  0, batch   214 | loss: 2.0370641MixupTrain:  epoch  0, batch   215 | loss: 2.1774251MixupTrain:  epoch  0, batch   216 | loss: 2.7880652MixupTrain:  epoch  0, batch   217 | loss: 2.1190619MixupTrain:  epoch  0, batch   218 | loss: 2.0025373MixupTrain:  epoch  0, batch   219 | loss: 2.5340166MixupTrain:  epoch  0, batch   220 | loss: 2.4897161MixupTrain:  epoch  0, batch   221 | loss: 2.3340213MixupTrain:  epoch  0, batch   222 | loss: 2.2590947MixupTrain:  epoch  0, batch   223 | loss: 2.3804035MixupTrain:  epoch  0, batch   224 | loss: 2.3564377MixupTrain:  epoch  0, batch   225 | loss: 2.1724787MixupTrain:  epoch  0, batch   226 | loss: 2.4815438MixupTrain:  epoch  0, batch   227 | loss: 2.5726159MixupTrain:  epoch  0, batch   228 | loss: 2.0868561MixupTrain:  epoch  0, batch   229 | loss: 2.3003597MixupTrain:  epoch  0, batch   230 | loss: 2.1470828MixupTrain:  epoch  0, batch   231 | loss: 2.3746340MixupTrain:  epoch  0, batch   232 | loss: 2.5137973MixupTrain:  epoch  0, batch   233 | loss: 2.6567047MixupTrain:  epoch  0, batch   234 | loss: 2.6965914MixupTrain:  epoch  0, batch   235 | loss: 2.1124802MixupTrain:  epoch  0, batch   236 | loss: 2.2743897MixupTrain:  epoch  0, batch   237 | loss: 2.5453548MixupTrain:  epoch  0, batch   238 | loss: 2.5054209MixupTrain:  epoch  0, batch   239 | loss: 2.0523698MixupTrain:  epoch  0, batch   240 | loss: 2.2161324MixupTrain:  epoch  0, batch   241 | loss: 2.2651763MixupTrain:  epoch  0, batch   242 | loss: 2.0945106MixupTrain:  epoch  0, batch   243 | loss: 2.2995269MixupTrain:  epoch  0, batch   244 | loss: 2.4465761MixupTrain:  epoch  0, batch   245 | loss: 2.3492827MixupTrain:  epoch  0, batch   246 | loss: 2.1060319MixupTrain:  epoch  0, batch   247 | loss: 2.2177925MixupTrain:  epoch  0, batch   248 | loss: 2.2032747MixupTrain:  epoch  0, batch   249 | loss: 2.3875155MixupTrain:  epoch  0, batch   250 | loss: 2.1060715MixupTrain:  epoch  0, batch   251 | loss: 2.4346602MixupTrain:  epoch  0, batch   252 | loss: 2.4509692MixupTrain:  epoch  0, batch   253 | loss: 2.1857693MixupTrain:  epoch  0, batch   254 | loss: 2.0319860MixupTrain:  epoch  0, batch   255 | loss: 2.3431892MixupTrain:  epoch  0, batch   256 | loss: 2.4824367MixupTrain:  epoch  0, batch   257 | loss: 2.0592678MixupTrain:  epoch  0, batch   258 | loss: 2.1369560MixupTrain:  epoch  0, batch   259 | loss: 2.2160530MixupTrain:  epoch  0, batch   260 | loss: 2.1683183MixupTrain:  epoch  0, batch   261 | loss: 2.6500120MixupTrain:  epoch  0, batch   262 | loss: 2.1941774MixupTrain:  epoch  0, batch   263 | loss: 2.2588146MixupTrain:  epoch  0, batch   264 | loss: 2.2519193MixupTrain:  epoch  0, batch   265 | loss: 2.2671516MixupTrain:  epoch  0, batch   266 | loss: 2.3858206MixupTrain:  epoch  0, batch   267 | loss: 2.3554201MixupTrain:  epoch  0, batch   268 | loss: 2.2563589MixupTrain:  epoch  0, batch   269 | loss: 2.3837242MixupTrain:  epoch  0, batch   270 | loss: 2.2979312MixupTrain:  epoch  0, batch   271 | loss: 2.6108241MixupTrain:  epoch  0, batch   272 | loss: 2.2315979MixupTrain:  epoch  0, batch   273 | loss: 2.0684700MixupTrain:  epoch  0, batch   274 | loss: 2.4184229MixupTrain:  epoch  0, batch   275 | loss: 2.4033270MixupTrain:  epoch  0, batch   276 | loss: 2.0449691MixupTrain:  epoch  0, batch   277 | loss: 2.1989708MixupTrain:  epoch  0, batch   278 | loss: 2.0761940MixupTrain:  epoch  0, batch   279 | loss: 2.0455332MixupTrain:  epoch  0, batch   280 | loss: 2.1810031MixupTrain:  epoch  0, batch   281 | loss: 2.2036619MixupTrain:  epoch  0, batch   282 | loss: 1.9532682MixupTrain:  epoch  0, batch   283 | loss: 2.2352271MixupTrain:  epoch  0, batch   284 | loss: 2.4778659MixupTrain:  epoch  0, batch   285 | loss: 2.2254577MixupTrain:  epoch  0, batch   286 | loss: 2.5080881MixupTrain:  epoch  0, batch   287 | loss: 2.2023144MixupTrain:  epoch  0, batch   288 | loss: 2.6035957MixupTrain:  epoch  0, batch   289 | loss: 2.0543485MixupTrain:  epoch  0, batch   290 | loss: 2.5660648MixupTrain:  epoch  0, batch   291 | loss: 2.1612558MixupTrain:  epoch  0, batch   292 | loss: 2.2901835MixupTrain:  epoch  0, batch   293 | loss: 2.0693221MixupTrain:  epoch  0, batch   294 | loss: 2.1864443MixupTrain:  epoch  0, batch   295 | loss: 2.3591466MixupTrain:  epoch  0, batch   296 | loss: 2.4959245MixupTrain:  epoch  0, batch   297 | loss: 2.1511579MixupTrain:  epoch  0, batch   298 | loss: 2.1892891MixupTrain:  epoch  0, batch   299 | loss: 2.2554860MixupTrain:  epoch  0, batch   300 | loss: 2.1497278MixupTrain:  epoch  0, batch   301 | loss: 2.0126650MixupTrain:  epoch  0, batch   302 | loss: 2.1406088MixupTrain:  epoch  0, batch   303 | loss: 2.3158484MixupTrain:  epoch  0, batch   304 | loss: 2.1380589MixupTrain:  epoch  0, batch   305 | loss: 2.4160337MixupTrain:  epoch  0, batch   306 | loss: 2.2643709MixupTrain:  epoch  0, batch   307 | loss: 2.3688283MixupTrain:  epoch  0, batch   308 | loss: 2.2809997MixupTrain:  epoch  0, batch   309 | loss: 2.3666463MixupTrain:  epoch  0, batch   310 | loss: 2.3047891MixupTrain:  epoch  0, batch   311 | loss: 2.2230363MixupTrain:  epoch  0, batch   312 | loss: 2.3242438MixupTrain:  epoch  0, batch   313 | loss: 2.2684174MixupTrain:  epoch  0, batch   314 | loss: 2.4457598MixupTrain:  epoch  0, batch   315 | loss: 2.1495106MixupTrain:  epoch  0, batch   316 | loss: 2.3432755MixupTrain:  epoch  0, batch   317 | loss: 2.4514637MixupTrain:  epoch  0, batch   318 | loss: 2.0858722MixupTrain:  epoch  0, batch   319 | loss: 2.4898515MixupTrain:  epoch  0, batch   320 | loss: 2.1721864MixupTrain:  epoch  0, batch   321 | loss: 2.2188697MixupTrain:  epoch  0, batch   322 | loss: 2.2780468MixupTrain:  epoch  0, batch   323 | loss: 2.0833213MixupTrain:  epoch  0, batch   324 | loss: 2.0635192MixupTrain:  epoch  0, batch   325 | loss: 2.4812779MixupTrain:  epoch  0, batch   326 | loss: 2.1760001MixupTrain:  epoch  0, batch   327 | loss: 2.7509036MixupTrain:  epoch  0, batch   328 | loss: 2.1380079MixupTrain:  epoch  0, batch   329 | loss: 2.2741170MixupTrain:  epoch  0, batch   330 | loss: 2.3309884MixupTrain:  epoch  0, batch   331 | loss: 2.4647186MixupTrain:  epoch  0, batch   332 | loss: 2.0427294MixupTrain:  epoch  0, batch   333 | loss: 2.0807934MixupTrain:  epoch  0, batch   334 | loss: 2.5868497MixupTrain:  epoch  0, batch   335 | loss: 2.0403614MixupTrain:  epoch  0, batch   336 | loss: 2.6079144MixupTrain:  epoch  0, batch   337 | loss: 2.1314046MixupTrain:  epoch  0, batch   338 | loss: 2.2836015MixupTrain:  epoch  0, batch   339 | loss: 2.2456646MixupTrain:  epoch  0, batch   340 | loss: 2.0865569MixupTrain:  epoch  0, batch   341 | loss: 2.1993947MixupTrain:  epoch  0, batch   342 | loss: 2.2320929MixupTrain:  epoch  0, batch   343 | loss: 2.1036325MixupTrain:  epoch  0, batch   344 | loss: 2.1866651MixupTrain:  epoch  0, batch   345 | loss: 2.3684309MixupTrain:  epoch  0, batch   346 | loss: 2.1790962MixupTrain:  epoch  0, batch   347 | loss: 2.2527204MixupTrain:  epoch  0, batch   348 | loss: 2.2737668MixupTrain:  epoch  0, batch   349 | loss: 2.2922108MixupTrain:  epoch  0, batch   350 | loss: 2.0325165MixupTrain:  epoch  0, batch   351 | loss: 2.1300919MixupTrain:  epoch  0, batch   352 | loss: 1.9804820MixupTrain:  epoch  0, batch   353 | loss: 2.0752685MixupTrain:  epoch  0, batch   354 | loss: 2.2072432MixupTrain:  epoch  0, batch   355 | loss: 2.3723953MixupTrain:  epoch  0, batch   356 | loss: 2.4155383MixupTrain:  epoch  0, batch   357 | loss: 2.4056520MixupTrain:  epoch  0, batch   358 | loss: 2.1253779MixupTrain:  epoch  0, batch   359 | loss: 2.0480571MixupTrain:  epoch  0, batch   360 | loss: 2.2872596MixupTrain:  epoch  0, batch   361 | loss: 2.0666342MixupTrain:  epoch  0, batch   362 | loss: 2.0162804MixupTrain:  epoch  0, batch   363 | loss: 2.1691020MixupTrain:  epoch  0, batch   364 | loss: 2.3681669MixupTrain:  epoch  0, batch   365 | loss: 2.0941176MixupTrain:  epoch  0, batch   366 | loss: 2.1775715MixupTrain:  epoch  0, batch   367 | loss: 2.3560591MixupTrain:  epoch  0, batch   368 | loss: 2.0530763MixupTrain:  epoch  0, batch   369 | loss: 2.2045221MixupTrain:  epoch  0, batch   370 | loss: 2.3203363MixupTrain:  epoch  0, batch   371 | loss: 2.3318944MixupTrain:  epoch  0, batch   372 | loss: 2.2781968MixupTrain:  epoch  0, batch   373 | loss: 2.0524676MixupTrain:  epoch  0, batch   374 | loss: 2.2828112MixupTrain:  epoch  0, batch   375 | loss: 2.4167037MixupTrain:  epoch  0, batch   376 | loss: 2.1903274MixupTrain:  epoch  0, batch   377 | loss: 2.1172163MixupTrain:  epoch  0, batch   378 | loss: 2.2044082MixupTrain:  epoch  0, batch   379 | loss: 2.2750521MixupTrain:  epoch  0, batch   380 | loss: 2.2107949MixupTrain:  epoch  0, batch   381 | loss: 2.0359251MixupTrain:  epoch  0, batch   382 | loss: 2.1303020MixupTrain:  epoch  0, batch   383 | loss: 2.1627035MixupTrain:  epoch  0, batch   384 | loss: 2.4020648MixupTrain:  epoch  0, batch   385 | loss: 2.1205201MixupTrain:  epoch  0, batch   386 | loss: 2.1894319MixupTrain:  epoch  0, batch   387 | loss: 2.2569938MixupTrain:  epoch  0, batch   388 | loss: 2.1874878MixupTrain:  epoch  0, batch   389 | loss: 2.5694470MixupTrain:  epoch  0, batch   390 | loss: 2.3413873MixupTrain:  epoch  0, batch   391 | loss: 2.1820850MixupTrain:  epoch  0, batch   392 | loss: 2.2401133MixupTrain:  epoch  0, batch   393 | loss: 2.3727605MixupTrain:  epoch  0, batch   394 | loss: 2.3506732MixupTrain:  epoch  0, batch   395 | loss: 2.2330992MixupTrain:  epoch  0, batch   396 | loss: 2.2736537MixupTrain:  epoch  0, batch   397 | loss: 2.2112675MixupTrain:  epoch  0, batch   398 | loss: 2.2988970MixupTrain:  epoch  0, batch   399 | loss: 2.3067355MixupTrain:  epoch  0, batch   400 | loss: 2.2437706MixupTrain:  epoch  0, batch   401 | loss: 2.0896904MixupTrain:  epoch  0, batch   402 | loss: 2.4182942MixupTrain:  epoch  0, batch   403 | loss: 2.2920382MixupTrain:  epoch  0, batch   404 | loss: 2.1258531MixupTrain:  epoch  0, batch   405 | loss: 1.9696140MixupTrain:  epoch  0, batch   406 | loss: 2.2235746MixupTrain:  epoch  0, batch   407 | loss: 2.3075035MixupTrain:  epoch  0, batch   408 | loss: 2.4873157MixupTrain:  epoch  0, batch   409 | loss: 2.0675101MixupTrain:  epoch  0, batch   410 | loss: 1.9991668MixupTrain:  epoch  0, batch   411 | loss: 2.3231246MixupTrain:  epoch  0, batch   412 | loss: 2.1413608MixupTrain:  epoch  0, batch   413 | loss: 2.3780985MixupTrain:  epoch  0, batch   414 | loss: 2.1455994MixupTrain:  epoch  0, batch   415 | loss: 2.4939084MixupTrain:  epoch  0, batch   416 | loss: 2.0644152MixupTrain:  epoch  0, batch   417 | loss: 2.4117231MixupTrain:  epoch  0, batch   418 | loss: 2.1097984MixupTrain:  epoch  0, batch   419 | loss: 2.1672599MixupTrain:  epoch  0, batch   420 | loss: 2.5603621MixupTrain:  epoch  0, batch   421 | loss: 2.2756796MixupTrain:  epoch  0, batch   422 | loss: 2.2164431MixupTrain:  epoch  0, batch   423 | loss: 2.4561782MixupTrain:  epoch  0, batch   424 | loss: 2.0640345MixupTrain:  epoch  0, batch   425 | loss: 2.6058576MixupTrain:  epoch  0, batch   426 | loss: 2.0148923MixupTrain:  epoch  0, batch   427 | loss: 1.9603715MixupTrain:  epoch  0, batch   428 | loss: 2.1712933MixupTrain:  epoch  0, batch   429 | loss: 1.9739940MixupTrain:  epoch  0, batch   430 | loss: 2.3596258MixupTrain:  epoch  0, batch   431 | loss: 2.0851586MixupTrain:  epoch  0, batch   432 | loss: 2.2499249MixupTrain:  epoch  0, batch   433 | loss: 2.0705953MixupTrain:  epoch  0, batch   434 | loss: 2.2859631MixupTrain:  epoch  0, batch   435 | loss: 1.9819263MixupTrain:  epoch  0, batch   436 | loss: 2.4645996MixupTrain:  epoch  0, batch   437 | loss: 2.2510519MixupTrain:  epoch  0, batch   438 | loss: 2.0190973MixupTrain:  epoch  0, batch   439 | loss: 2.2229366MixupTrain:  epoch  0, batch   440 | loss: 2.4157066MixupTrain:  epoch  0, batch   441 | loss: 1.9972742MixupTrain:  epoch  0, batch   442 | loss: 2.3186302MixupTrain:  epoch  0, batch   443 | loss: 2.1849270MixupTrain:  epoch  0, batch   444 | loss: 2.4597425MixupTrain:  epoch  0, batch   445 | loss: 2.2924860MixupTrain:  epoch  0, batch   446 | loss: 2.1296883MixupTrain:  epoch  0, batch   447 | loss: 2.5077372MixupTrain:  epoch  0, batch   448 | loss: 2.4633212MixupTrain:  epoch  0, batch   449 | loss: 2.0522289MixupTrain:  epoch  0, batch   450 | loss: 2.4463892MixupTrain:  epoch  0, batch   451 | loss: 2.2931354MixupTrain:  epoch  0, batch   452 | loss: 2.1855917MixupTrain:  epoch  0, batch   453 | loss: 2.2405779MixupTrain:  epoch  0, batch   454 | loss: 2.1798632MixupTrain:  epoch  0, batch   455 | loss: 2.1831741MixupTrain:  epoch  0, batch   456 | loss: 2.1941776MixupTrain:  epoch  0, batch   457 | loss: 2.1371295MixupTrain:  epoch  0, batch   458 | loss: 2.2082953MixupTrain:  epoch  0, batch   459 | loss: 2.3267970MixupTrain:  epoch  0, batch   460 | loss: 2.0443740MixupTrain:  epoch  0, batch   461 | loss: 2.3384392MixupTrain:  epoch  0, batch   462 | loss: 2.3176372MixupTrain:  epoch  0, batch   463 | loss: 2.2566421MixupTrain:  epoch  0, batch   464 | loss: 2.2181456MixupTrain:  epoch  0, batch   465 | loss: 2.3939574MixupTrain:  epoch  0, batch   466 | loss: 2.3768010MixupTrain:  epoch  0, batch   467 | loss: 2.3818710MixupTrain:  epoch  0, batch   468 | loss: 2.4365926MixupTrain:  epoch  0, batch   469 | loss: 2.0335517MixupTrain:  epoch  0, batch   470 | loss: 2.1307406MixupTrain:  epoch  0, batch   471 | loss: 2.0370159MixupTrain:  epoch  0, batch   472 | loss: 2.0833545MixupTrain:  epoch  0, batch   473 | loss: 2.3909535MixupTrain:  epoch  0, batch   474 | loss: 2.2374344MixupTrain:  epoch  0, batch   475 | loss: 2.1244731MixupTrain:  epoch  0, batch   476 | loss: 2.1479023MixupTrain:  epoch  0, batch   477 | loss: 2.2120080MixupTrain:  epoch  0, batch   478 | loss: 2.1840844MixupTrain:  epoch  0, batch   479 | loss: 2.2448850MixupTrain:  epoch  0, batch   480 | loss: 2.3997242MixupTrain:  epoch  0, batch   481 | loss: 2.2166851MixupTrain:  epoch  0, batch   482 | loss: 2.0972903MixupTrain:  epoch  0, batch   483 | loss: 2.1255465MixupTrain:  epoch  0, batch   484 | loss: 2.3996401MixupTrain:  epoch  0, batch   485 | loss: 2.0854864MixupTrain:  epoch  0, batch   486 | loss: 2.3146830MixupTrain:  epoch  0, batch   487 | loss: 2.1599226MixupTrain:  epoch  0, batch   488 | loss: 2.4263513MixupTrain:  epoch  0, batch   489 | loss: 2.1185722MixupTrain:  epoch  0, batch   490 | loss: 2.3607180MixupTrain:  epoch  0, batch   491 | loss: 2.3853393MixupTrain:  epoch  0, batch   492 | loss: 2.2617621MixupTrain:  epoch  0, batch   493 | loss: 2.3643441MixupTrain:  epoch  0, batch   494 | loss: 2.1987038MixupTrain:  epoch  0, batch   495 | loss: 2.4820428MixupTrain:  epoch  0, batch   496 | loss: 2.0306516MixupTrain:  epoch  0, batch   497 | loss: 2.2350287MixupTrain:  epoch  0, batch   498 | loss: 2.1039517MixupTrain:  epoch  0, batch   499 | loss: 2.4183867MixupTrain:  epoch  0, batch   500 | loss: 2.3981605MixupTrain:  epoch  0, batch   501 | loss: 2.4320633MixupTrain:  epoch  0, batch   502 | loss: 2.0312457MixupTrain:  epoch  0, batch   503 | loss: 2.0444453MixupTrain:  epoch  0, batch   504 | loss: 2.4161773MixupTrain:  epoch  0, batch   505 | loss: 2.1078377MixupTrain:  epoch  0, batch   506 | loss: 2.2750392MixupTrain:  epoch  0, batch   507 | loss: 2.1413488MixupTrain:  epoch  0, batch   508 | loss: 2.1533198MixupTrain:  epoch  0, batch   509 | loss: 2.4123869MixupTrain:  epoch  0, batch   510 | loss: 2.2808557MixupTrain:  epoch  0, batch   511 | loss: 2.3172197MixupTrain:  epoch  0, batch   512 | loss: 2.5493855MixupTrain:  epoch  0, batch   513 | loss: 2.0395575MixupTrain:  epoch  0, batch   514 | loss: 2.5753260MixupTrain:  epoch  0, batch   515 | loss: 2.1662118MixupTrain:  epoch  0, batch   516 | loss: 2.0767984MixupTrain:  epoch  0, batch   517 | loss: 2.2999249MixupTrain:  epoch  0, batch   518 | loss: 2.3904824MixupTrain:  epoch  0, batch   519 | loss: 1.9960847MixupTrain:  epoch  0, batch   520 | loss: 2.3245442MixupTrain:  epoch  0, batch   521 | loss: 2.0923707MixupTrain:  epoch  0, batch   522 | loss: 2.1343269MixupTrain:  epoch  0, batch   523 | loss: 2.2703533MixupTrain:  epoch  0, batch   524 | loss: 2.2464566MixupTrain:  epoch  0, batch   525 | loss: 2.3773370MixupTrain:  epoch  0, batch   526 | loss: 2.2566655MixupTrain:  epoch  0, batch   527 | loss: 2.3676221MixupTrain:  epoch  0, batch   528 | loss: 1.9683757MixupTrain:  epoch  0, batch   529 | loss: 2.2461796MixupTrain:  epoch  0, batch   530 | loss: 2.0677786MixupTrain:  epoch  0, batch   531 | loss: 2.2843912MixupTrain:  epoch  0, batch   532 | loss: 2.1397350MixupTrain:  epoch  0, batch   533 | loss: 2.0447555MixupTrain:  epoch  0, batch   534 | loss: 2.1088951MixupTrain:  epoch  0, batch   535 | loss: 2.2814488MixupTrain:  epoch  0, batch   536 | loss: 2.1799212MixupTrain:  epoch  0, batch   537 | loss: 2.2028618MixupTrain:  epoch  0, batch   538 | loss: 1.9450526MixupTrain:  epoch  0, batch   539 | loss: 2.2731473MixupTrain:  epoch  0, batch   540 | loss: 2.0273843MixupTrain:  epoch  0, batch   541 | loss: 2.1096714MixupTrain:  epoch  0, batch   542 | loss: 2.0414717MixupTrain:  epoch  0, batch   543 | loss: 2.2191267MixupTrain:  epoch  0, batch   544 | loss: 2.2008474MixupTrain:  epoch  0, batch   545 | loss: 2.0150259MixupTrain:  epoch  0, batch   546 | loss: 2.0196707MixupTrain:  epoch  0, batch   547 | loss: 2.0381513MixupTrain:  epoch  0, batch   548 | loss: 2.3163691MixupTrain:  epoch  0, batch   549 | loss: 2.4040647MixupTrain:  epoch  0, batch   550 | loss: 2.0573750MixupTrain:  epoch  0, batch   551 | loss: 2.1421642MixupTrain:  epoch  0, batch   552 | loss: 2.5610051MixupTrain:  epoch  0, batch   553 | loss: 2.1752710MixupTrain:  epoch  0, batch   554 | loss: 2.0790782MixupTrain:  epoch  0, batch   555 | loss: 2.0827203MixupTrain:  epoch  0, batch   556 | loss: 2.2697611MixupTrain:  epoch  0, batch   557 | loss: 2.3533354MixupTrain:  epoch  0, batch   558 | loss: 2.3603907MixupTrain:  epoch  0, batch   559 | loss: 2.1133907MixupTrain:  epoch  0, batch   560 | loss: 2.0565372MixupTrain:  epoch  0, batch   561 | loss: 2.0998149MixupTrain:  epoch  0, batch   562 | loss: 2.2696571MixupTrain:  epoch  0, batch   563 | loss: 2.1988387MixupTrain:  epoch  0, batch   564 | loss: 2.3833866MixupTrain:  epoch  0, batch   565 | loss: 2.1789567MixupTrain:  epoch  0, batch   566 | loss: 2.3364606MixupTrain:  epoch  0, batch   567 | loss: 1.9278982MixupTrain:  epoch  0, batch   568 | loss: 2.3507981MixupTrain:  epoch  0, batch   569 | loss: 2.2516494MixupTrain:  epoch  0, batch   570 | loss: 2.2970004MixupTrain:  epoch  0, batch   571 | loss: 2.2856441MixupTrain:  epoch  0, batch   572 | loss: 2.2070794MixupTrain:  epoch  0, batch   573 | loss: 2.1692181MixupTrain:  epoch  0, batch   574 | loss: 1.9952956MixupTrain:  epoch  0, batch   575 | loss: 2.1834126MixupTrain:  epoch  0, batch   576 | loss: 2.2467427MixupTrain:  epoch  0, batch   577 | loss: 2.0250163MixupTrain:  epoch  0, batch   578 | loss: 2.1241503MixupTrain:  epoch  0, batch   579 | loss: 2.4665112MixupTrain:  epoch  0, batch   580 | loss: 2.2498150MixupTrain:  epoch  0, batch   581 | loss: 2.2102246MixupTrain:  epoch  0, batch   582 | loss: 2.4519367MixupTrain:  epoch  0, batch   583 | loss: 2.1605582MixupTrain:  epoch  0, batch   584 | loss: 2.1836786MixupTrain:  epoch  0, batch   585 | loss: 2.0232153MixupTrain:  epoch  0, batch   586 | loss: 2.3533268MixupTrain:  epoch  0, batch   587 | loss: 2.0963297MixupTrain:  epoch  0, batch   588 | loss: 2.2462888MixupTrain:  epoch  0, batch   589 | loss: 2.3725197MixupTrain:  epoch  0, batch   590 | loss: 2.3047352MixupTrain:  epoch  0, batch   591 | loss: 2.1886804MixupTrain:  epoch  0, batch   592 | loss: 2.4159343MixupTrain:  epoch  0, batch   593 | loss: 2.0948951MixupTrain:  epoch  0, batch   594 | loss: 2.3722227MixupTrain:  epoch  0, batch   595 | loss: 2.0348909MixupTrain:  epoch  0, batch   596 | loss: 2.1002932MixupTrain:  epoch  0, batch   597 | loss: 2.1865354MixupTrain:  epoch  0, batch   598 | loss: 2.0365467MixupTrain:  epoch  0, batch   599 | loss: 2.2788124MixupTrain:  epoch  0, batch   600 | loss: 2.3459172MixupTrain:  epoch  0, batch   601 | loss: 2.1990471MixupTrain:  epoch  0, batch   602 | loss: 2.1233754MixupTrain:  epoch  0, batch   603 | loss: 2.4955013MixupTrain:  epoch  0, batch   604 | loss: 2.0515766MixupTrain:  epoch  0, batch   605 | loss: 2.3069220MixupTrain:  epoch  0, batch   606 | loss: 2.1254566MixupTrain:  epoch  0, batch   607 | loss: 2.2628536MixupTrain:  epoch  0, batch   608 | loss: 2.2120333MixupTrain:  epoch  0, batch   609 | loss: 2.1070228MixupTrain:  epoch  0, batch   610 | loss: 2.1681335MixupTrain:  epoch  0, batch   611 | loss: 2.0861788MixupTrain:  epoch  0, batch   612 | loss: 2.2362459MixupTrain:  epoch  0, batch   613 | loss: 2.1239130MixupTrain:  epoch  0, batch   614 | loss: 2.1761868MixupTrain:  epoch  0, batch   615 | loss: 2.4182696MixupTrain:  epoch  0, batch   616 | loss: 2.2340243MixupTrain:  epoch  0, batch   617 | loss: 2.1450534MixupTrain:  epoch  0, batch   618 | loss: 2.1772082MixupTrain:  epoch  0, batch   619 | loss: 2.2139406MixupTrain:  epoch  0, batch   620 | loss: 2.1231017MixupTrain:  epoch  0, batch   621 | loss: 2.0027785MixupTrain:  epoch  0, batch   622 | loss: 2.2055998MixupTrain:  epoch  0, batch   623 | loss: 2.1475496MixupTrain:  epoch  0, batch   624 | loss: 2.0553989MixupTrain:  epoch  0, batch   625 | loss: 2.1241534MixupTrain:  epoch  0, batch   626 | loss: 2.3663893MixupTrain:  epoch  0, batch   627 | loss: 2.4626937MixupTrain:  epoch  0, batch   628 | loss: 2.1750801MixupTrain:  epoch  0, batch   629 | loss: 2.5569134MixupTrain:  epoch  0, batch   630 | loss: 2.1859317MixupTrain:  epoch  0, batch   631 | loss: 2.2468629MixupTrain:  epoch  0, batch   632 | loss: 2.1628003MixupTrain:  epoch  0, batch   633 | loss: 2.1420603MixupTrain:  epoch  0, batch   634 | loss: 1.9928577MixupTrain:  epoch  0, batch   635 | loss: 2.0859349MixupTrain:  epoch  0, batch   636 | loss: 2.0304580MixupTrain:  epoch  0, batch   637 | loss: 2.1446202MixupTrain:  epoch  0, batch   638 | loss: 2.0465717MixupTrain:  epoch  0, batch   639 | loss: 2.2758601MixupTrain:  epoch  0, batch   640 | loss: 2.2516470MixupTrain:  epoch  0, batch   641 | loss: 2.1345329MixupTrain:  epoch  0, batch   642 | loss: 2.3895473MixupTrain:  epoch  0, batch   643 | loss: 2.0394630MixupTrain:  epoch  0, batch   644 | loss: 2.0410733MixupTrain:  epoch  0, batch   645 | loss: 2.1595759MixupTrain:  epoch  0, batch   646 | loss: 2.3914337MixupTrain:  epoch  0, batch   647 | loss: 2.2115626MixupTrain:  epoch  0, batch   648 | loss: 2.1520782MixupTrain:  epoch  0, batch   649 | loss: 1.9377654MixupTrain:  epoch  0, batch   650 | loss: 2.4023037MixupTrain:  epoch  0, batch   651 | loss: 2.1296642MixupTrain:  epoch  0, batch   652 | loss: 2.1718495MixupTrain:  epoch  0, batch   653 | loss: 2.0880189MixupTrain:  epoch  0, batch   654 | loss: 2.1742330MixupTrain:  epoch  0, batch   655 | loss: 2.2160592MixupTrain:  epoch  0, batch   656 | loss: 2.1012716MixupTrain:  epoch  0, batch   657 | loss: 2.2501559MixupTrain:  epoch  0, batch   658 | loss: 2.5195994MixupTrain:  epoch  0, batch   659 | loss: 2.4515841MixupTrain:  epoch  0, batch   660 | loss: 2.1297481MixupTrain:  epoch  0, batch   661 | loss: 2.0055690MixupTrain:  epoch  0, batch   662 | loss: 2.2630312MixupTrain:  epoch  0, batch   663 | loss: 2.1960390MixupTrain:  epoch  0, batch   664 | loss: 1.9286227MixupTrain:  epoch  0, batch   665 | loss: 2.3104782MixupTrain:  epoch  0, batch   666 | loss: 2.1250081MixupTrain:  epoch  0, batch   667 | loss: 2.2832465MixupTrain:  epoch  0, batch   668 | loss: 2.3767154MixupTrain:  epoch  0, batch   669 | loss: 2.3093064MixupTrain:  epoch  0, batch   670 | loss: 1.9942546MixupTrain:  epoch  0, batch   671 | loss: 2.2168193MixupTrain:  epoch  0, batch   672 | loss: 2.0363708MixupTrain:  epoch  0, batch   673 | loss: 2.0911484MixupTrain:  epoch  0, batch   674 | loss: 2.2197299MixupTrain:  epoch  0, batch   675 | loss: 2.3272123MixupTrain:  epoch  0, batch   676 | loss: 2.1829708MixupTrain:  epoch  0, batch   677 | loss: 2.0662684MixupTrain:  epoch  0, batch   678 | loss: 2.2477922MixupTrain:  epoch  0, batch   679 | loss: 2.2109826MixupTrain:  epoch  0, batch   680 | loss: 2.0125651MixupTrain:  epoch  0, batch   681 | loss: 2.2639606MixupTrain:  epoch  0, batch   682 | loss: 1.9659991MixupTrain:  epoch  0, batch   683 | loss: 2.1553302MixupTrain:  epoch  0, batch   684 | loss: 2.1759772MixupTrain:  epoch  0, batch   685 | loss: 2.2484741MixupTrain:  epoch  0, batch   686 | loss: 2.3457854MixupTrain:  epoch  0, batch   687 | loss: 2.1169307MixupTrain:  epoch  0, batch   688 | loss: 1.9857373MixupTrain:  epoch  0, batch   689 | loss: 2.1687903MixupTrain:  epoch  0, batch   690 | loss: 2.1950245MixupTrain:  epoch  0, batch   691 | loss: 2.1525106MixupTrain:  epoch  0, batch   692 | loss: 2.1652288MixupTrain:  epoch  0, batch   693 | loss: 2.1173401MixupTrain:  epoch  0, batch   694 | loss: 2.2171412MixupTrain:  epoch  0, batch   695 | loss: 2.1345742MixupTrain:  epoch  0, batch   696 | loss: 2.0864487MixupTrain:  epoch  0, batch   697 | loss: 2.3611641MixupTrain:  epoch  0, batch   698 | loss: 2.0498948MixupTrain:  epoch  0, batch   699 | loss: 2.1940575MixupTrain:  epoch  0, batch   700 | loss: 2.2908092MixupTrain:  epoch  0, batch   701 | loss: 2.1210480MixupTrain:  epoch  0, batch   702 | loss: 2.1481090MixupTrain:  epoch  0, batch   703 | loss: 2.2821159MixupTrain:  epoch  0, batch   704 | loss: 2.3898973MixupTrain:  epoch  0, batch   705 | loss: 2.1200476MixupTrain:  epoch  0, batch   706 | loss: 2.1352262MixupTrain:  epoch  0, batch   707 | loss: 2.3844500MixupTrain:  epoch  0, batch   708 | loss: 2.1067259MixupTrain:  epoch  0, batch   709 | loss: 2.2210891MixupTrain:  epoch  0, batch   710 | loss: 2.2941072MixupTrain:  epoch  0, batch   711 | loss: 2.1694660MixupTrain:  epoch  0, batch   712 | loss: 2.4031098MixupTrain:  epoch  0, batch   713 | loss: 1.9775593MixupTrain:  epoch  0, batch   714 | loss: 2.3556519MixupTrain:  epoch  0, batch   715 | loss: 2.6155300MixupTrain:  epoch  0, batch   716 | loss: 2.0727994MixupTrain:  epoch  0, batch   717 | loss: 2.1657619MixupTrain:  epoch  0, batch   718 | loss: 2.0481133MixupTrain:  epoch  0, batch   719 | loss: 2.2642412MixupTrain:  epoch  0, batch   720 | loss: 2.2002625MixupTrain:  epoch  0, batch   721 | loss: 2.2124925MixupTrain:  epoch  0, batch   722 | loss: 2.2859395MixupTrain:  epoch  0, batch   723 | loss: 2.3836944MixupTrain:  epoch  0, batch   724 | loss: 2.2143202MixupTrain:  epoch  0, batch   725 | loss: 2.3119755MixupTrain:  epoch  0, batch   726 | loss: 2.3810902MixupTrain:  epoch  0, batch   727 | loss: 2.0951741MixupTrain:  epoch  0, batch   728 | loss: 2.1992378MixupTrain:  epoch  0, batch   729 | loss: 2.0514340MixupTrain:  epoch  0, batch   730 | loss: 2.0602369MixupTrain:  epoch  0, batch   731 | loss: 2.5473900MixupTrain:  epoch  0, batch   732 | loss: 2.3321517MixupTrain:  epoch  0, batch   733 | loss: 2.2339027MixupTrain:  epoch  0, batch   734 | loss: 2.3124819MixupTrain:  epoch  0, batch   735 | loss: 1.9701948MixupTrain:  epoch  0, batch   736 | loss: 2.3734903MixupTrain:  epoch  0, batch   737 | loss: 2.0461040MixupTrain:  epoch  0, batch   738 | loss: 2.2669375MixupTrain:  epoch  0, batch   739 | loss: 2.0685277MixupTrain:  epoch  0, batch   740 | loss: 1.9746423MixupTrain:  epoch  0, batch   741 | loss: 2.3404627MixupTrain:  epoch  0, batch   742 | loss: 2.3270290MixupTrain:  epoch  0, batch   743 | loss: 2.0913470MixupTrain:  epoch  0, batch   744 | loss: 2.0675499MixupTrain:  epoch  0, batch   745 | loss: 2.1344485MixupTrain:  epoch  0, batch   746 | loss: 2.0905199MixupTrain:  epoch  0, batch   747 | loss: 2.2658134MixupTrain:  epoch  0, batch   748 | loss: 2.2967043MixupTrain:  epoch  0, batch   749 | loss: 2.2893903MixupTrain:  epoch  0, batch   750 | loss: 1.9603786MixupTrain:  epoch  0, batch   751 | loss: 2.2574940MixupTrain:  epoch  0, batch   752 | loss: 2.2329440MixupTrain:  epoch  0, batch   753 | loss: 2.0958588MixupTrain:  epoch  0, batch   754 | loss: 2.1429782MixupTrain:  epoch  0, batch   755 | loss: 2.3670888MixupTrain:  epoch  0, batch   756 | loss: 1.9245850MixupTrain:  epoch  0, batch   757 | loss: 2.3145051MixupTrain:  epoch  0, batch   758 | loss: 1.9920428MixupTrain:  epoch  0, batch   759 | loss: 1.9426222MixupTrain:  epoch  0, batch   760 | loss: 2.2077532MixupTrain:  epoch  0, batch   761 | loss: 2.1379340MixupTrain:  epoch  0, batch   762 | loss: 2.1567249MixupTrain:  epoch  0, batch   763 | loss: 2.2260571MixupTrain:  epoch  0, batch   764 | loss: 1.9733220MixupTrain:  epoch  0, batch   765 | loss: 2.0581424MixupTrain:  epoch  0, batch   766 | loss: 2.1952648MixupTrain:  epoch  0, batch   767 | loss: 2.1326632MixupTrain:  epoch  0, batch   768 | loss: 2.3408904MixupTrain:  epoch  0, batch   769 | loss: 2.1896458MixupTrain:  epoch  0, batch   770 | loss: 2.2818391MixupTrain:  epoch  0, batch   771 | loss: 2.1407101MixupTrain:  epoch  0, batch   772 | loss: 2.5220399MixupTrain:  epoch  0, batch   773 | loss: 2.3010345MixupTrain:  epoch  0, batch   774 | loss: 2.0682664MixupTrain:  epoch  0, batch   775 | loss: 2.1556396MixupTrain:  epoch  0, batch   776 | loss: 1.9987147MixupTrain:  epoch  0, batch   777 | loss: 2.3607879MixupTrain:  epoch  0, batch   778 | loss: 2.4068666MixupTrain:  epoch  0, batch   779 | loss: 2.0304108MixupTrain:  epoch  0, batch   780 | loss: 2.1724339MixupTrain:  epoch  0, batch   781 | loss: 2.2138381MixupTrain:  epoch  0, batch   782 | loss: 2.1140203MixupTrain:  epoch  0, batch   783 | loss: 2.2855914MixupTrain:  epoch  0, batch   784 | loss: 2.1758556MixupTrain:  epoch  0, batch   785 | loss: 2.1974759MixupTrain:  epoch  0, batch   786 | loss: 2.0897613MixupTrain:  epoch  0, batch   787 | loss: 2.2647126MixupTrain:  epoch  0, batch   788 | loss: 2.6183367MixupTrain:  epoch  0, batch   789 | loss: 2.0871217MixupTrain:  epoch  0, batch   790 | loss: 2.0653379MixupTrain:  epoch  0, batch   791 | loss: 1.9185777MixupTrain:  epoch  0, batch   792 | loss: 2.1758537MixupTrain:  epoch  0, batch   793 | loss: 2.1769636MixupTrain:  epoch  0, batch   794 | loss: 2.1002469MixupTrain:  epoch  0, batch   795 | loss: 2.1797709MixupTrain:  epoch  0, batch   796 | loss: 1.9977201MixupTrain:  epoch  0, batch   797 | loss: 2.1250806MixupTrain:  epoch  0, batch   798 | loss: 2.2394054MixupTrain:  epoch  0, batch   799 | loss: 2.3752208MixupTrain:  epoch  0, batch   800 | loss: 2.0191259MixupTrain:  epoch  0, batch   801 | loss: 2.0431905MixupTrain:  epoch  0, batch   802 | loss: 2.3437743MixupTrain:  epoch  0, batch   803 | loss: 2.0270767MixupTrain:  epoch  0, batch   804 | loss: 2.2828863MixupTrain:  epoch  0, batch   805 | loss: 2.1269453MixupTrain:  epoch  0, batch   806 | loss: 2.2087231MixupTrain:  epoch  0, batch   807 | loss: 2.2211525MixupTrain:  epoch  0, batch   808 | loss: 2.2942288MixupTrain:  epoch  0, batch   809 | loss: 1.9576232MixupTrain:  epoch  0, batch   810 | loss: 2.1829677MixupTrain:  epoch  0, batch   811 | loss: 2.0356183MixupTrain:  epoch  0, batch   812 | loss: 2.1377196MixupTrain:  epoch  0, batch   813 | loss: 1.9610732MixupTrain:  epoch  0, batch   814 | loss: 2.1429176MixupTrain:  epoch  0, batch   815 | loss: 2.3222351MixupTrain:  epoch  0, batch   816 | loss: 2.2046571MixupTrain:  epoch  0, batch   817 | loss: 2.1254294MixupTrain:  epoch  0, batch   818 | loss: 2.3997486MixupTrain:  epoch  0, batch   819 | loss: 2.0027092MixupTrain:  epoch  0, batch   820 | loss: 2.0756197MixupTrain:  epoch  0, batch   821 | loss: 2.1376705MixupTrain:  epoch  0, batch   822 | loss: 2.1664472MixupTrain:  epoch  0, batch   823 | loss: 2.1986995MixupTrain:  epoch  0, batch   824 | loss: 2.1220746MixupTrain:  epoch  0, batch   825 | loss: 2.2221439MixupTrain:  epoch  0, batch   826 | loss: 2.2931533MixupTrain:  epoch  0, batch   827 | loss: 1.9869368MixupTrain:  epoch  0, batch   828 | loss: 2.5506766MixupTrain:  epoch  0, batch   829 | loss: 2.2111444MixupTrain:  epoch  0, batch   830 | loss: 2.1098509MixupTrain:  epoch  0, batch   831 | loss: 2.2106683MixupTrain:  epoch  0, batch   832 | loss: 2.1689320MixupTrain:  epoch  0, batch   833 | loss: 2.2304878MixupTrain:  epoch  0, batch   834 | loss: 2.2224493MixupTrain:  epoch  0, batch   835 | loss: 2.3550978MixupTrain:  epoch  0, batch   836 | loss: 2.4825964MixupTrain:  epoch  0, batch   837 | loss: 2.2170167MixupTrain:  epoch  0, batch   838 | loss: 2.1873596MixupTrain:  epoch  0, batch   839 | loss: 2.1951013MixupTrain:  epoch  0, batch   840 | loss: 2.1463778MixupTrain:  epoch  0, batch   841 | loss: 2.1836920MixupTrain:  epoch  0, batch   842 | loss: 2.2503958MixupTrain:  epoch  0, batch   843 | loss: 2.0553641MixupTrain:  epoch  0, batch   844 | loss: 1.9414425MixupTrain:  epoch  0, batch   845 | loss: 2.1348431MixupTrain:  epoch  0, batch   846 | loss: 2.1649833MixupTrain:  epoch  0, batch   847 | loss: 2.1003630MixupTrain:  epoch  0, batch   848 | loss: 1.9789982MixupTrain:  epoch  0, batch   849 | loss: 2.2277248MixupTrain:  epoch  0, batch   850 | loss: 2.0672593MixupTrain:  epoch  0, batch   851 | loss: 2.0211010MixupTrain:  epoch  0, batch   852 | loss: 2.2374415MixupTrain:  epoch  0, batch   853 | loss: 2.0440505MixupTrain:  epoch  0, batch   854 | loss: 2.3331251MixupTrain:  epoch  0, batch   855 | loss: 2.1222348MixupTrain:  epoch  0, batch   856 | loss: 2.2519646MixupTrain:  epoch  0, batch   857 | loss: 2.1877217MixupTrain:  epoch  0, batch   858 | loss: 2.1636419MixupTrain:  epoch  0, batch   859 | loss: 2.2710114MixupTrain:  epoch  0, batch   860 | loss: 2.3880749MixupTrain:  epoch  0, batch   861 | loss: 2.2172074MixupTrain:  epoch  0, batch   862 | loss: 2.2877553MixupTrain:  epoch  0, batch   863 | loss: 2.2668064MixupTrain:  epoch  0, batch   864 | loss: 2.2512453MixupTrain:  epoch  0, batch   865 | loss: 2.1939480MixupTrain:  epoch  0, batch   866 | loss: 2.1795454MixupTrain:  epoch  0, batch   867 | loss: 2.2497180MixupTrain:  epoch  0, batch   868 | loss: 2.2990165MixupTrain:  epoch  0, batch   869 | loss: 2.3494840MixupTrain:  epoch  0, batch   870 | loss: 2.1645520MixupTrain:  epoch  0, batch   871 | loss: 2.0699387MixupTrain:  epoch  0, batch   872 | loss: 2.3359149MixupTrain:  epoch  0, batch   873 | loss: 2.2077420MixupTrain:  epoch  0, batch   874 | loss: 2.1056430MixupTrain:  epoch  0, batch   875 | loss: 2.0953026MixupTrain:  epoch  0, batch   876 | loss: 2.1059723MixupTrain:  epoch  0, batch   877 | loss: 2.3254137MixupTrain:  epoch  0, batch   878 | loss: 2.2018228MixupTrain:  epoch  0, batch   879 | loss: 2.3533978MixupTrain:  epoch  0, batch   880 | loss: 2.2958398MixupTrain:  epoch  0, batch   881 | loss: 2.0849450MixupTrain:  epoch  0, batch   882 | loss: 2.2547669MixupTrain:  epoch  0, batch   883 | loss: 2.2329736MixupTrain:  epoch  0, batch   884 | loss: 2.1818662MixupTrain:  epoch  0, batch   885 | loss: 2.2556620MixupTrain:  epoch  0, batch   886 | loss: 2.3343620MixupTrain:  epoch  0, batch   887 | loss: 2.1467311MixupTrain:  epoch  0, batch   888 | loss: 2.0439208MixupTrain:  epoch  0, batch   889 | loss: 2.1315010MixupTrain:  epoch  0, batch   890 | loss: 2.0835528MixupTrain:  epoch  0, batch   891 | loss: 2.1766140MixupTrain:  epoch  0, batch   892 | loss: 2.1855416MixupTrain:  epoch  0, batch   893 | loss: 2.1519341MixupTrain:  epoch  0, batch   894 | loss: 2.2065048MixupTrain:  epoch  0, batch   895 | loss: 2.2952430MixupTrain:  epoch  0, batch   896 | loss: 2.1304705MixupTrain:  epoch  0, batch   897 | loss: 2.1552200MixupTrain:  epoch  0, batch   898 | loss: 2.3611624MixupTrain:  epoch  0, batch   899 | loss: 2.1880360MixupTrain:  epoch  0, batch   900 | loss: 1.9623002MixupTrain:  epoch  0, batch   901 | loss: 2.3468673MixupTrain:  epoch  0, batch   902 | loss: 2.2638018MixupTrain:  epoch  0, batch   903 | loss: 2.2142589MixupTrain:  epoch  0, batch   904 | loss: 2.3384881MixupTrain:  epoch  0, batch   905 | loss: 2.0504527MixupTrain:  epoch  0, batch   906 | loss: 2.1209176MixupTrain:  epoch  0, batch   907 | loss: 2.2640629MixupTrain:  epoch  0, batch   908 | loss: 2.1022930MixupTrain:  epoch  0, batch   909 | loss: 2.0863695MixupTrain:  epoch  0, batch   910 | loss: 2.0043747MixupTrain:  epoch  0, batch   911 | loss: 2.1699705MixupTrain:  epoch  0, batch   912 | loss: 2.0283310MixupTrain:  epoch  0, batch   913 | loss: 2.2970879MixupTrain:  epoch  0, batch   914 | loss: 2.1152897MixupTrain:  epoch  0, batch   915 | loss: 1.9855593MixupTrain:  epoch  0, batch   916 | loss: 2.1826234MixupTrain:  epoch  0, batch   917 | loss: 2.3869600MixupTrain:  epoch  0, batch   918 | loss: 2.0502236MixupTrain:  epoch  0, batch   919 | loss: 2.0689440MixupTrain:  epoch  0, batch   920 | loss: 2.0591462MixupTrain:  epoch  0, batch   921 | loss: 2.2481534MixupTrain:  epoch  0, batch   922 | loss: 2.0173020MixupTrain:  epoch  0, batch   923 | loss: 2.3777251MixupTrain:  epoch  0, batch   924 | loss: 1.9328978MixupTrain:  epoch  0, batch   925 | loss: 2.1749835MixupTrain:  epoch  0, batch   926 | loss: 2.3363860MixupTrain:  epoch  0, batch   927 | loss: 2.2272820MixupTrain:  epoch  0, batch   928 | loss: 2.0860047MixupTrain:  epoch  0, batch   929 | loss: 2.3273995MixupTrain:  epoch  0, batch   930 | loss: 2.1050355MixupTrain:  epoch  0, batch   931 | loss: 2.2035458MixupTrain:  epoch  0, batch   932 | loss: 2.4734678MixupTrain:  epoch  0, batch   933 | loss: 2.2169638MixupTrain:  epoch  0, batch   934 | loss: 2.1116099MixupTrain:  epoch  0, batch   935 | loss: 2.2602220MixupTrain:  epoch  0, batch   936 | loss: 2.0098615MixupTrain:  epoch  0, batch   937 | loss: 2.2340517MixupTrain:  epoch  0, batch   938 | loss: 2.1225832MixupTrain:  epoch  0, batch   939 | loss: 2.2744784MixupTrain:  epoch  0, batch   940 | loss: 1.9577677MixupTrain:  epoch  0, batch   941 | loss: 2.4051242MixupTrain:  epoch  0, batch   942 | loss: 1.9869940MixupTrain:  epoch  0, batch   943 | loss: 2.1548705MixupTrain:  epoch  0, batch   944 | loss: 1.9145838MixupTrain:  epoch  0, batch   945 | loss: 2.0623586MixupTrain:  epoch  0, batch   946 | loss: 2.3068719MixupTrain:  epoch  0, batch   947 | loss: 2.0334666MixupTrain:  epoch  0, batch   948 | loss: 2.2083197MixupTrain:  epoch  0, batch   949 | loss: 1.9291254MixupTrain:  epoch  0, batch   950 | loss: 2.0584087MixupTrain:  epoch  0, batch   951 | loss: 2.0617702MixupTrain:  epoch  0, batch   952 | loss: 2.2196991MixupTrain:  epoch  0, batch   953 | loss: 2.0214071MixupTrain:  epoch  0, batch   954 | loss: 2.5652089MixupTrain:  epoch  0, batch   955 | loss: 2.0690017MixupTrain:  epoch  0, batch   956 | loss: 2.2828813MixupTrain:  epoch  0, batch   957 | loss: 2.3199525MixupTrain:  epoch  0, batch   958 | loss: 2.0905361MixupTrain:  epoch  0, batch   959 | loss: 2.1584582MixupTrain:  epoch  0, batch   960 | loss: 2.1822686MixupTrain:  epoch  0, batch   961 | loss: 2.1142683MixupTrain:  epoch  0, batch   962 | loss: 2.0156801MixupTrain:  epoch  0, batch   963 | loss: 2.3153028MixupTrain:  epoch  0, batch   964 | loss: 2.2108746MixupTrain:  epoch  0, batch   965 | loss: 2.1005180MixupTrain:  epoch  0, batch   966 | loss: 2.2776287MixupTrain:  epoch  0, batch   967 | loss: 2.2174244MixupTrain:  epoch  0, batch   968 | loss: 2.1293104MixupTrain:  epoch  0, batch   969 | loss: 2.0791945MixupTrain:  epoch  0, batch   970 | loss: 2.1206255MixupTrain:  epoch  0, batch   971 | loss: 2.2759588MixupTrain:  epoch  0, batch   972 | loss: 2.1908693MixupTrain:  epoch  0, batch   973 | loss: 2.0560451MixupTrain:  epoch  0, batch   974 | loss: 2.1964455MixupTrain:  epoch  0, batch   975 | loss: 2.3783660MixupTrain:  epoch  0, batch   976 | loss: 2.0961325MixupTrain:  epoch  0, batch   977 | loss: 2.3375392MixupTrain:  epoch  0, batch   978 | loss: 2.3800700MixupTrain:  epoch  0, batch   979 | loss: 2.2827656MixupTrain:  epoch  0, batch   980 | loss: 2.3121076MixupTrain:  epoch  0, batch   981 | loss: 2.2811656MixupTrain:  epoch  0, batch   982 | loss: 2.1203873MixupTrain:  epoch  0, batch   983 | loss: 2.2864854MixupTrain:  epoch  0, batch   984 | loss: 2.2514079MixupTrain:  epoch  0, batch   985 | loss: 2.1172636MixupTrain:  epoch  0, batch   986 | loss: 2.3529799MixupTrain:  epoch  0, batch   987 | loss: 2.1402779MixupTrain:  epoch  0, batch   988 | loss: 2.1837578MixupTrain:  epoch  0, batch   989 | loss: 2.2007484MixupTrain:  epoch  0, batch   990 | loss: 2.2537222MixupTrain:  epoch  0, batch   991 | loss: 2.2274799MixupTrain:  epoch  0, batch   992 | loss: 2.1251624MixupTrain:  epoch  0, batch   993 | loss: 2.2102764MixupTrain:  epoch  0, batch   994 | loss: 1.9586968MixupTrain:  epoch  0, batch   995 | loss: 1.9643453MixupTrain:  epoch  0, batch   996 | loss: 2.1559346MixupTrain:  epoch  0, batch   997 | loss: 2.0668745MixupTrain:  epoch  0, batch   998 | loss: 2.1094699MixupTrain:  epoch  0, batch   999 | loss: 2.2334077MixupTrain:  epoch  0, batch  1000 | loss: 2.2558687MixupTrain:  epoch  0, batch  1001 | loss: 2.2769608MixupTrain:  epoch  0, batch  1002 | loss: 2.2784119MixupTrain:  epoch  0, batch  1003 | loss: 2.2920551MixupTrain:  epoch  0, batch  1004 | loss: 2.0816450MixupTrain:  epoch  0, batch  1005 | loss: 2.3002276MixupTrain:  epoch  0, batch  1006 | loss: 2.1369369MixupTrain:  epoch  0, batch  1007 | loss: 2.5355010MixupTrain:  epoch  0, batch  1008 | loss: 2.1615603MixupTrain:  epoch  0, batch  1009 | loss: 2.1199427MixupTrain:  epoch  0, batch  1010 | loss: 2.4208119MixupTrain:  epoch  0, batch  1011 | loss: 1.9314313MixupTrain:  epoch  0, batch  1012 | loss: 2.2009127MixupTrain:  epoch  0, batch  1013 | loss: 2.3541465MixupTrain:  epoch  0, batch  1014 | loss: 2.1976838MixupTrain:  epoch  0, batch  1015 | loss: 2.3080354MixupTrain:  epoch  0, batch  1016 | loss: 2.1999056MixupTrain:  epoch  0, batch  1017 | loss: 2.1626592MixupTrain:  epoch  0, batch  1018 | loss: 2.4590936MixupTrain:  epoch  0, batch  1019 | loss: 2.0433097MixupTrain:  epoch  0, batch  1020 | loss: 2.3011370MixupTrain:  epoch  0, batch  1021 | loss: 2.1919954MixupTrain:  epoch  0, batch  1022 | loss: 2.0559030MixupTrain:  epoch  0, batch  1023 | loss: 2.1530397MixupTrain:  epoch  0, batch  1024 | loss: 2.0369558MixupTrain:  epoch  0, batch  1025 | loss: 2.2337480MixupTrain:  epoch  0, batch  1026 | loss: 2.1818364MixupTrain:  epoch  0, batch  1027 | loss: 2.3650789MixupTrain:  epoch  0, batch  1028 | loss: 2.0966444MixupTrain:  epoch  0, batch  1029 | loss: 2.3968225MixupTrain:  epoch  0, batch  1030 | loss: 2.3094466MixupTrain:  epoch  0, batch  1031 | loss: 2.0693352MixupTrain:  epoch  0, batch  1032 | loss: 2.0342145MixupTrain:  epoch  0, batch  1033 | loss: 2.1484747MixupTrain:  epoch  0, batch  1034 | loss: 2.2579663MixupTrain:  epoch  0, batch  1035 | loss: 2.2008772MixupTrain:  epoch  0, batch  1036 | loss: 2.0828872MixupTrain:  epoch  0, batch  1037 | loss: 2.0862679MixupTrain:  epoch  0, batch  1038 | loss: 2.2627251MixupTrain:  epoch  0, batch  1039 | loss: 2.0553515MixupTrain:  epoch  0, batch  1040 | loss: 2.1318011MixupTrain:  epoch  0, batch  1041 | loss: 2.3827186MixupTrain:  epoch  0, batch  1042 | loss: 2.2340934MixupTrain:  epoch  0, batch  1043 | loss: 2.3519962MixupTrain:  epoch  0, batch  1044 | loss: 2.1477733MixupTrain:  epoch  0, batch  1045 | loss: 2.0029671MixupTrain:  epoch  0, batch  1046 | loss: 2.1986117MixupTrain:  epoch  0, batch  1047 | loss: 2.2186184MixupTrain:  epoch  0, batch  1048 | loss: 2.0850697MixupTrain:  epoch  0, batch  1049 | loss: 2.1590056MixupTrain:  epoch  0, batch  1050 | loss: 2.0462680MixupTrain:  epoch  0, batch  1051 | loss: 2.1325445MixupTrain:  epoch  0, batch  1052 | loss: 2.0604892MixupTrain:  epoch  0, batch  1053 | loss: 2.1121306MixupTrain:  epoch  0, batch  1054 | loss: 2.2272358MixupTrain:  epoch  0, batch  1055 | loss: 2.0492449MixupTrain:  epoch  0, batch  1056 | loss: 2.1488543MixupTrain:  epoch  0, batch  1057 | loss: 2.3960166MixupTrain:  epoch  0, batch  1058 | loss: 2.0302644MixupTrain:  epoch  0, batch  1059 | loss: 2.2285821MixupTrain:  epoch  0, batch  1060 | loss: 2.3394761MixupTrain:  epoch  0, batch  1061 | loss: 2.4111376MixupTrain:  epoch  0, batch  1062 | loss: 2.1405993MixupTrain:  epoch  0, batch  1063 | loss: 1.9551146MixupTrain:  epoch  0, batch  1064 | loss: 2.1569033MixupTrain:  epoch  0, batch  1065 | loss: 2.1272726MixupTrain:  epoch  0, batch  1066 | loss: 2.2811356MixupTrain:  epoch  0, batch  1067 | loss: 1.9804101MixupTrain:  epoch  0, batch  1068 | loss: 2.1698189MixupTrain:  epoch  0, batch  1069 | loss: 2.0738277MixupTrain:  epoch  0, batch  1070 | loss: 2.2962480MixupTrain:  epoch  0, batch  1071 | loss: 2.2794693MixupTrain:  epoch  0, batch  1072 | loss: 2.0299783MixupTrain:  epoch  0, batch  1073 | loss: 2.2692358MixupTrain:  epoch  0, batch  1074 | loss: 2.2294064MixupTrain:  epoch  0, batch  1075 | loss: 2.1905079MixupTrain:  epoch  0, batch  1076 | loss: 1.9806161MixupTrain:  epoch  0, batch  1077 | loss: 2.1918278MixupTrain:  epoch  0, batch  1078 | loss: 2.1191926MixupTrain:  epoch  0, batch  1079 | loss: 2.1390843MixupTrain:  epoch  0, batch  1080 | loss: 2.2004099MixupTrain:  epoch  0, batch  1081 | loss: 2.1225393MixupTrain:  epoch  0, batch  1082 | loss: 2.0236864MixupTrain:  epoch  0, batch  1083 | loss: 2.3233190MixupTrain:  epoch  0, batch  1084 | loss: 2.2158275MixupTrain:  epoch  0, batch  1085 | loss: 2.2490330MixupTrain:  epoch  0, batch  1086 | loss: 2.4573743MixupTrain:  epoch  0, batch  1087 | loss: 2.2078700MixupTrain:  epoch  0, batch  1088 | loss: 1.9145353MixupTrain:  epoch  0, batch  1089 | loss: 2.0726922MixupTrain:  epoch  0, batch  1090 | loss: 2.1806283MixupTrain:  epoch  0, batch  1091 | loss: 2.2753024MixupTrain:  epoch  0, batch  1092 | loss: 2.3623853MixupTrain:  epoch  0, batch  1093 | loss: 2.1578732MixupTrain:  epoch  0, batch  1094 | loss: 2.1815884MixupTrain:  epoch  0, batch  1095 | loss: 2.0735540MixupTrain:  epoch  0, batch  1096 | loss: 2.0621314MixupTrain:  epoch  0, batch  1097 | loss: 2.1427441MixupTrain:  epoch  0, batch  1098 | loss: 2.2618673MixupTrain:  epoch  0, batch  1099 | loss: 2.2474117MixupTrain:  epoch  0, batch  1100 | loss: 2.2270176MixupTrain:  epoch  0, batch  1101 | loss: 2.0236011MixupTrain:  epoch  0, batch  1102 | loss: 2.2087498MixupTrain:  epoch  0, batch  1103 | loss: 2.0697222MixupTrain:  epoch  0, batch  1104 | loss: 2.4330068MixupTrain:  epoch  0, batch  1105 | loss: 2.3278241MixupTrain:  epoch  0, batch  1106 | loss: 2.1917593MixupTrain:  epoch  0, batch  1107 | loss: 2.2914073MixupTrain:  epoch  0, batch  1108 | loss: 2.0431461MixupTrain:  epoch  0, batch  1109 | loss: 2.1555424MixupTrain:  epoch  0, batch  1110 | loss: 2.2465701MixupTrain:  epoch  0, batch  1111 | loss: 2.0973091MixupTrain:  epoch  0, batch  1112 | loss: 2.0989695MixupTrain:  epoch  0, batch  1113 | loss: 2.1980729MixupTrain:  epoch  0, batch  1114 | loss: 2.1717119MixupTrain:  epoch  0, batch  1115 | loss: 2.1561794MixupTrain:  epoch  0, batch  1116 | loss: 2.0535583MixupTrain:  epoch  0, batch  1117 | loss: 2.3246610MixupTrain:  epoch  0, batch  1118 | loss: 2.4468665MixupTrain:  epoch  0, batch  1119 | loss: 2.0538762MixupTrain:  epoch  0, batch  1120 | loss: 2.3042741MixupTrain:  epoch  0, batch  1121 | loss: 2.2109561MixupTrain:  epoch  0, batch  1122 | loss: 2.1996694MixupTrain:  epoch  0, batch  1123 | loss: 2.1931520MixupTrain:  epoch  0, batch  1124 | loss: 2.2695150MixupTrain:  epoch  0, batch  1125 | loss: 2.2472501MixupTrain:  epoch  0, batch  1126 | loss: 2.3137841MixupTrain:  epoch  0, batch  1127 | loss: 2.1916499MixupTrain:  epoch  0, batch  1128 | loss: 2.0810614MixupTrain:  epoch  0, batch  1129 | loss: 2.6226382MixupTrain:  epoch  0, batch  1130 | loss: 2.0987670MixupTrain:  epoch  0, batch  1131 | loss: 2.0058732MixupTrain:  epoch  0, batch  1132 | loss: 1.9951049MixupTrain:  epoch  0, batch  1133 | loss: 2.2314763MixupTrain:  epoch  0, batch  1134 | loss: 2.3531356MixupTrain:  epoch  0, batch  1135 | loss: 1.9971955MixupTrain:  epoch  0, batch  1136 | loss: 2.1680572MixupTrain:  epoch  0, batch  1137 | loss: 2.4484830MixupTrain:  epoch  0, batch  1138 | loss: 2.1247416MixupTrain:  epoch  0, batch  1139 | loss: 2.0152557MixupTrain:  epoch  0, batch  1140 | loss: 2.2080536MixupTrain:  epoch  0, batch  1141 | loss: 2.1674092MixupTrain:  epoch  0, batch  1142 | loss: 2.1999326MixupTrain:  epoch  0, batch  1143 | loss: 1.9765750MixupTrain:  epoch  0, batch  1144 | loss: 2.2803838MixupTrain:  epoch  0, batch  1145 | loss: 2.2707686MixupTrain:  epoch  0, batch  1146 | loss: 2.3499904MixupTrain:  epoch  0, batch  1147 | loss: 2.2752552MixupTrain:  epoch  0, batch  1148 | loss: 2.0078564MixupTrain:  epoch  0, batch  1149 | loss: 2.1766796MixupTrain:  epoch  0, batch  1150 | loss: 1.9899569MixupTrain:  epoch  0, batch  1151 | loss: 2.1387558MixupTrain:  epoch  0, batch  1152 | loss: 2.2324681MixupTrain:  epoch  0, batch  1153 | loss: 2.2295928MixupTrain:  epoch  0, batch  1154 | loss: 2.1081066MixupTrain:  epoch  0, batch  1155 | loss: 2.1089189MixupTrain:  epoch  0, batch  1156 | loss: 2.3754454MixupTrain:  epoch  0, batch  1157 | loss: 2.3249917MixupTrain:  epoch  0, batch  1158 | loss: 2.0458717MixupTrain:  epoch  0, batch  1159 | loss: 2.0176418MixupTrain:  epoch  0, batch  1160 | loss: 2.0000143MixupTrain:  epoch  0, batch  1161 | loss: 2.0462894MixupTrain:  epoch  0, batch  1162 | loss: 1.9985141MixupTrain:  epoch  0, batch  1163 | loss: 2.4394021MixupTrain:  epoch  0, batch  1164 | loss: 2.1654813MixupTrain:  epoch  0, batch  1165 | loss: 2.1067038MixupTrain:  epoch  0, batch  1166 | loss: 2.1938255MixupTrain:  epoch  0, batch  1167 | loss: 2.1592698MixupTrain:  epoch  0, batch  1168 | loss: 2.2249157MixupTrain:  epoch  0, batch  1169 | loss: 2.1400871MixupTrain:  epoch  0, batch  1170 | loss: 2.3323827MixupTrain:  epoch  0, batch  1171 | loss: 2.1850376MixupTrain:  epoch  0, batch  1172 | loss: 2.3477011MixupTrain:  epoch  0, batch  1173 | loss: 1.9736328MixupTrain:  epoch  0, batch  1174 | loss: 2.5026331MixupTrain:  epoch  0, batch  1175 | loss: 2.3056545MixupTrain:  epoch  0, batch  1176 | loss: 2.1935186MixupTrain:  epoch  0, batch  1177 | loss: 2.1134410MixupTrain:  epoch  0, batch  1178 | loss: 1.9882720MixupTrain:  epoch  0, batch  1179 | loss: 2.3464108MixupTrain:  epoch  0, batch  1180 | loss: 2.3360181MixupTrain:  epoch  0, batch  1181 | loss: 1.9494739MixupTrain:  epoch  0, batch  1182 | loss: 2.1397295MixupTrain:  epoch  0, batch  1183 | loss: 2.0947032MixupTrain:  epoch  0, batch  1184 | loss: 2.2666950MixupTrain:  epoch  0, batch  1185 | loss: 2.2106869MixupTrain:  epoch  0, batch  1186 | loss: 2.2024238MixupTrain:  epoch  0, batch  1187 | loss: 2.2729378MixupTrain:  epoch  0, batch  1188 | loss: 2.2054765MixupTrain:  epoch  0, batch  1189 | loss: 2.1041374MixupTrain:  epoch  0, batch  1190 | loss: 2.2232156MixupTrain:  epoch  0, batch  1191 | loss: 2.0352826MixupTrain:  epoch  0, batch  1192 | loss: 2.2539625MixupTrain:  epoch  0, batch  1193 | loss: 2.2051814MixupTrain:  epoch  0, batch  1194 | loss: 1.9150939MixupTrain:  epoch  0, batch  1195 | loss: 2.1603198MixupTrain:  epoch  0, batch  1196 | loss: 2.2812145MixupTrain:  epoch  0, batch  1197 | loss: 2.3456941MixupTrain:  epoch  0, batch  1198 | loss: 2.1261845MixupTrain:  epoch  0, batch  1199 | loss: 2.0899808MixupTrain:  epoch  0, batch  1200 | loss: 2.1631899MixupTrain:  epoch  0, batch  1201 | loss: 2.2956069MixupTrain:  epoch  0, batch  1202 | loss: 2.0124505MixupTrain:  epoch  0, batch  1203 | loss: 2.1326723MixupTrain:  epoch  0, batch  1204 | loss: 2.0757060MixupTrain:  epoch  0, batch  1205 | loss: 1.9586351MixupTrain:  epoch  0, batch  1206 | loss: 2.1708198MixupTrain:  epoch  0, batch  1207 | loss: 2.2054195MixupTrain:  epoch  0, batch  1208 | loss: 2.0408750MixupTrain:  epoch  0, batch  1209 | loss: 2.0641942MixupTrain:  epoch  0, batch  1210 | loss: 2.2885692MixupTrain:  epoch  0, batch  1211 | loss: 2.1595652MixupTrain:  epoch  0, batch  1212 | loss: 2.2111931MixupTrain:  epoch  0, batch  1213 | loss: 2.2299285MixupTrain:  epoch  0, batch  1214 | loss: 2.5495129MixupTrain:  epoch  0, batch  1215 | loss: 2.2756064MixupTrain:  epoch  0, batch  1216 | loss: 2.3253040MixupTrain:  epoch  0, batch  1217 | loss: 2.1238456MixupTrain:  epoch  0, batch  1218 | loss: 2.1251416MixupTrain:  epoch  0, batch  1219 | loss: 2.0347338MixupTrain:  epoch  0, batch  1220 | loss: 2.2559600MixupTrain:  epoch  0, batch  1221 | loss: 1.9747576MixupTrain:  epoch  0, batch  1222 | loss: 2.3252153MixupTrain:  epoch  0, batch  1223 | loss: 2.1732583MixupTrain:  epoch  0, batch  1224 | loss: 2.1163001MixupTrain:  epoch  0, batch  1225 | loss: 2.1783109MixupTrain:  epoch  0, batch  1226 | loss: 2.0906179MixupTrain:  epoch  0, batch  1227 | loss: 2.0888350MixupTrain:  epoch  0, batch  1228 | loss: 2.1332161MixupTrain:  epoch  0, batch  1229 | loss: 2.2540803MixupTrain:  epoch  0, batch  1230 | loss: 2.1166463MixupTrain:  epoch  0, batch  1231 | loss: 2.0487521MixupTrain:  epoch  0, batch  1232 | loss: 2.1275470MixupTrain:  epoch  0, batch  1233 | loss: 1.9548812MixupTrain:  epoch  0, batch  1234 | loss: 2.1797342MixupTrain:  epoch  0, batch  1235 | loss: 2.2567544MixupTrain:  epoch  0, batch  1236 | loss: 2.1186814MixupTrain:  epoch  0, batch  1237 | loss: 2.0231092MixupTrain:  epoch  0, batch  1238 | loss: 2.3448086MixupTrain:  epoch  0, batch  1239 | loss: 2.2858984MixupTrain:  epoch  0, batch  1240 | loss: 2.3654361MixupTrain:  epoch  0, batch  1241 | loss: 2.1418929MixupTrain:  epoch  0, batch  1242 | loss: 2.1286685MixupTrain:  epoch  0, batch  1243 | loss: 2.0465422MixupTrain:  epoch  0, batch  1244 | loss: 2.4257574MixupTrain:  epoch  0, batch  1245 | loss: 2.1539099MixupTrain:  epoch  0, batch  1246 | loss: 2.1207893MixupTrain:  epoch  0, batch  1247 | loss: 2.1844282MixupTrain:  epoch  0, batch  1248 | loss: 2.5090578MixupTrain:  epoch  0, batch  1249 | loss: 2.0597298MixupTrain:  epoch  0, batch  1250 | loss: 2.5150142MixupTrain:  epoch  0, batch  1251 | loss: 2.2896945MixupTrain:  epoch  0, batch  1252 | loss: 2.2839355MixupTrain:  epoch  0, batch  1253 | loss: 2.1520908MixupTrain:  epoch  0, batch  1254 | loss: 2.0853331MixupTrain:  epoch  0, batch  1255 | loss: 2.3405511MixupTrain:  epoch  0, batch  1256 | loss: 1.9670285MixupTrain:  epoch  0, batch  1257 | loss: 2.0420816MixupTrain:  epoch  0, batch  1258 | loss: 2.3442841MixupTrain:  epoch  0, batch  1259 | loss: 2.2022595MixupTrain:  epoch  0, batch  1260 | loss: 2.1485395MixupTrain:  epoch  0, batch  1261 | loss: 2.2505240MixupTrain:  epoch  0, batch  1262 | loss: 2.1017852MixupTrain:  epoch  0, batch  1263 | loss: 2.0813017MixupTrain:  epoch  0, batch  1264 | loss: 2.3572197MixupTrain:  epoch  0, batch  1265 | loss: 2.0774846MixupTrain:  epoch  0, batch  1266 | loss: 2.3879292MixupTrain:  epoch  0, batch  1267 | loss: 2.1216035MixupTrain:  epoch  0, batch  1268 | loss: 2.1803937MixupTrain:  epoch  0, batch  1269 | loss: 2.2115951MixupTrain:  epoch  0, batch  1270 | loss: 2.2323849MixupTrain:  epoch  0, batch  1271 | loss: 2.0681591MixupTrain:  epoch  0, batch  1272 | loss: 2.3432572MixupTrain:  epoch  0, batch  1273 | loss: 2.2399950MixupTrain:  epoch  0, batch  1274 | loss: 2.2291684MixupTrain:  epoch  0, batch  1275 | loss: 2.1548772MixupTrain:  epoch  0, batch  1276 | loss: 2.1652124MixupTrain:  epoch  0, batch  1277 | loss: 2.3481462MixupTrain:  epoch  0, batch  1278 | loss: 2.1295333MixupTrain:  epoch  0, batch  1279 | loss: 2.1546059MixupTrain:  epoch  0, batch  1280 | loss: 2.1665745MixupTrain:  epoch  0, batch  1281 | loss: 2.1233399MixupTrain:  epoch  0, batch  1282 | loss: 2.6075034MixupTrain:  epoch  0, batch  1283 | loss: 2.2410975MixupTrain:  epoch  0, batch  1284 | loss: 2.2068126MixupTrain:  epoch  0, batch  1285 | loss: 2.1161699MixupTrain:  epoch  0, batch  1286 | loss: 2.2970252MixupTrain:  epoch  0, batch  1287 | loss: 2.2675824MixupTrain:  epoch  0, batch  1288 | loss: 2.2120781MixupTrain:  epoch  0, batch  1289 | loss: 2.1948628MixupTrain:  epoch  0, batch  1290 | loss: 2.1369178MixupTrain:  epoch  0, batch  1291 | loss: 2.4655550MixupTrain:  epoch  0, batch  1292 | loss: 2.6458552MixupTrain:  epoch  0, batch  1293 | loss: 2.3248851MixupTrain:  epoch  0, batch  1294 | loss: 2.1969178MixupTrain:  epoch  0, batch  1295 | loss: 2.1405497MixupTrain:  epoch  0, batch  1296 | loss: 2.0796032MixupTrain:  epoch  0, batch  1297 | loss: 2.2813766MixupTrain:  epoch  0, batch  1298 | loss: 2.2387204MixupTrain:  epoch  0, batch  1299 | loss: 2.1391959MixupTrain:  epoch  0, batch  1300 | loss: 2.0234456MixupTrain:  epoch  0, batch  1301 | loss: 2.3914053MixupTrain:  epoch  0, batch  1302 | loss: 2.2706878MixupTrain:  epoch  0, batch  1303 | loss: 2.2640352MixupTrain:  epoch  0, batch  1304 | loss: 2.3449430MixupTrain:  epoch  0, batch  1305 | loss: 2.3467181MixupTrain:  epoch  0, batch  1306 | loss: 2.2100883MixupTrain:  epoch  0, batch  1307 | loss: 1.9053173MixupTrain:  epoch  0, batch  1308 | loss: 2.4476366MixupTrain:  epoch  0, batch  1309 | loss: 2.4861658MixupTrain:  epoch  0, batch  1310 | loss: 2.2685692MixupTrain:  epoch  0, batch  1311 | loss: 2.3850558MixupTrain:  epoch  0, batch  1312 | loss: 2.1102479MixupTrain:  epoch  0, batch  1313 | loss: 1.9951391MixupTrain:  epoch  0, batch  1314 | loss: 1.9465952MixupTrain:  epoch  0, batch  1315 | loss: 2.1087494MixupTrain:  epoch  0, batch  1316 | loss: 2.4547777MixupTrain:  epoch  0, batch  1317 | loss: 2.1465094MixupTrain:  epoch  0, batch  1318 | loss: 2.1798434MixupTrain:  epoch  0, batch  1319 | loss: 2.2375772MixupTrain:  epoch  0, batch  1320 | loss: 2.4684393MixupTrain:  epoch  0, batch  1321 | loss: 1.9886317MixupTrain:  epoch  0, batch  1322 | loss: 2.0014286MixupTrain:  epoch  0, batch  1323 | loss: 2.1603556MixupTrain:  epoch  0, batch  1324 | loss: 2.0999928MixupTrain:  epoch  0, batch  1325 | loss: 2.0395062MixupTrain:  epoch  0, batch  1326 | loss: 1.9867280MixupTrain:  epoch  0, batch  1327 | loss: 2.2210395MixupTrain:  epoch  0, batch  1328 | loss: 2.3446832MixupTrain:  epoch  0, batch  1329 | loss: 2.0211709MixupTrain:  epoch  0, batch  1330 | loss: 2.0745282MixupTrain:  epoch  0, batch  1331 | loss: 2.2976263MixupTrain:  epoch  0, batch  1332 | loss: 2.1125050MixupTrain:  epoch  0, batch  1333 | loss: 2.2828889MixupTrain:  epoch  0, batch  1334 | loss: 2.0398710MixupTrain:  epoch  0, batch  1335 | loss: 2.0574162MixupTrain:  epoch  0, batch  1336 | loss: 1.9897801MixupTrain:  epoch  0, batch  1337 | loss: 2.0531716MixupTrain:  epoch  0, batch  1338 | loss: 2.1241820MixupTrain:  epoch  0, batch  1339 | loss: 2.2256560MixupTrain:  epoch  0, batch  1340 | loss: 2.0906293MixupTrain:  epoch  0, batch  1341 | loss: 2.1856611MixupTrain:  epoch  0, batch  1342 | loss: 2.1732898MixupTrain:  epoch  0, batch  1343 | loss: 2.2249064MixupTrain:  epoch  0, batch  1344 | loss: 2.2167804MixupTrain:  epoch  0, batch  1345 | loss: 2.2715712MixupTrain:  epoch  0, batch  1346 | loss: 2.4604821MixupTrain:  epoch  0, batch  1347 | loss: 2.2907891MixupTrain:  epoch  0, batch  1348 | loss: 2.0914364MixupTrain:  epoch  0, batch  1349 | loss: 2.1318350MixupTrain:  epoch  0, batch  1350 | loss: 2.2380328MixupTrain:  epoch  0, batch  1351 | loss: 2.1505430MixupTrain:  epoch  0, batch  1352 | loss: 2.3162670MixupTrain:  epoch  0, batch  1353 | loss: 2.1374230MixupTrain:  epoch  0, batch  1354 | loss: 1.9679930MixupTrain:  epoch  0, batch  1355 | loss: 2.0117531MixupTrain:  epoch  0, batch  1356 | loss: 2.1118939MixupTrain:  epoch  0, batch  1357 | loss: 2.1485040MixupTrain:  epoch  0, batch  1358 | loss: 2.4525261MixupTrain:  epoch  0, batch  1359 | loss: 2.2684259MixupTrain:  epoch  0, batch  1360 | loss: 2.5291915MixupTrain:  epoch  0, batch  1361 | loss: 2.2295961MixupTrain:  epoch  0, batch  1362 | loss: 2.3144855MixupTrain:  epoch  0, batch  1363 | loss: 1.9991255MixupTrain:  epoch  0, batch  1364 | loss: 2.1047404MixupTrain:  epoch  0, batch  1365 | loss: 1.8692857MixupTrain:  epoch  0, batch  1366 | loss: 1.9550341MixupTrain:  epoch  0, batch  1367 | loss: 2.2513466MixupTrain:  epoch  0, batch  1368 | loss: 2.3830218MixupTrain:  epoch  0, batch  1369 | loss: 2.3020329MixupTrain:  epoch  0, batch  1370 | loss: 2.4288030MixupTrain:  epoch  0, batch  1371 | loss: 2.3407395MixupTrain:  epoch  0, batch  1372 | loss: 2.3257656MixupTrain:  epoch  0, batch  1373 | loss: 2.2746968MixupTrain:  epoch  0, batch  1374 | loss: 2.0103626MixupTrain:  epoch  0, batch  1375 | loss: 2.3506479MixupTrain:  epoch  0, batch  1376 | loss: 2.2888196MixupTrain:  epoch  0, batch  1377 | loss: 2.0038235MixupTrain:  epoch  0, batch  1378 | loss: 2.3815176MixupTrain:  epoch  0, batch  1379 | loss: 2.2043324MixupTrain:  epoch  0, batch  1380 | loss: 2.3647385MixupTrain:  epoch  0, batch  1381 | loss: 2.2158279MixupTrain:  epoch  0, batch  1382 | loss: 2.0305552MixupTrain:  epoch  0, batch  1383 | loss: 2.3258727MixupTrain:  epoch  0, batch  1384 | loss: 2.1803350MixupTrain:  epoch  0, batch  1385 | loss: 2.1802866MixupTrain:  epoch  0, batch  1386 | loss: 2.0421934MixupTrain:  epoch  0, batch  1387 | loss: 2.1766679MixupTrain:  epoch  0, batch  1388 | loss: 2.1989443MixupTrain:  epoch  0, batch  1389 | loss: 1.9936535MixupTrain:  epoch  0, batch  1390 | loss: 2.4207859MixupTrain:  epoch  0, batch  1391 | loss: 2.1181631MixupTrain:  epoch  0, batch  1392 | loss: 2.0209925MixupTrain:  epoch  0, batch  1393 | loss: 2.0758777MixupTrain:  epoch  0, batch  1394 | loss: 2.1146722MixupTrain:  epoch  0, batch  1395 | loss: 2.0531158MixupTrain:  epoch  0, batch  1396 | loss: 2.3132899MixupTrain:  epoch  0, batch  1397 | loss: 2.1073420MixupTrain:  epoch  0, batch  1398 | loss: 2.1422582MixupTrain:  epoch  0, batch  1399 | loss: 1.9625336MixupTrain:  epoch  0, batch  1400 | loss: 2.0052958MixupTrain:  epoch  0, batch  1401 | loss: 2.2920084MixupTrain:  epoch  0, batch  1402 | loss: 2.1939821MixupTrain:  epoch  0, batch  1403 | loss: 2.0804813MixupTrain:  epoch  0, batch  1404 | loss: 2.5371091MixupTrain:  epoch  0, batch  1405 | loss: 2.1926260MixupTrain:  epoch  0, batch  1406 | loss: 1.8736465MixupTrain:  epoch  0, batch  1407 | loss: 2.2630887MixupTrain:  epoch  0, batch  1408 | loss: 2.1484261MixupTrain:  epoch  0, batch  1409 | loss: 2.0479369MixupTrain:  epoch  0, batch  1410 | loss: 2.2622843MixupTrain:  epoch  0, batch  1411 | loss: 2.3064585MixupTrain:  epoch  0, batch  1412 | loss: 2.0338526MixupTrain:  epoch  0, batch  1413 | loss: 2.5643129MixupTrain:  epoch  0, batch  1414 | loss: 2.1600316MixupTrain:  epoch  0, batch  1415 | loss: 2.1269209MixupTrain:  epoch  0, batch  1416 | loss: 2.0453629MixupTrain:  epoch  0, batch  1417 | loss: 2.2381177MixupTrain:  epoch  0, batch  1418 | loss: 2.4237666MixupTrain:  epoch  0, batch  1419 | loss: 2.3036938MixupTrain:  epoch  0, batch  1420 | loss: 2.0060120MixupTrain:  epoch  0, batch  1421 | loss: 2.1877778MixupTrain:  epoch  0, batch  1422 | loss: 2.3445873MixupTrain:  epoch  0, batch  1423 | loss: 1.9643393MixupTrain:  epoch  0, batch  1424 | loss: 2.1308165MixupTrain:  epoch  0, batch  1425 | loss: 2.1767774MixupTrain:  epoch  0, batch  1426 | loss: 2.3645918MixupTrain:  epoch  0, batch  1427 | loss: 2.1442060MixupTrain:  epoch  0, batch  1428 | loss: 2.3075633MixupTrain:  epoch  0, batch  1429 | loss: 2.0654564MixupTrain:  epoch  0, batch  1430 | loss: 2.4263520MixupTrain:  epoch  0, batch  1431 | loss: 1.9814684MixupTrain:  epoch  0, batch  1432 | loss: 2.3075747MixupTrain:  epoch  0, batch  1433 | loss: 2.1579461MixupTrain:  epoch  0, batch  1434 | loss: 2.2959599MixupTrain:  epoch  0, batch  1435 | loss: 1.9148633MixupTrain:  epoch  0, batch  1436 | loss: 2.2062869MixupTrain:  epoch  0, batch  1437 | loss: 2.2075341MixupTrain:  epoch  0, batch  1438 | loss: 2.2588229MixupTrain:  epoch  0, batch  1439 | loss: 1.9975853MixupTrain:  epoch  0, batch  1440 | loss: 2.0964878MixupTrain:  epoch  0, batch  1441 | loss: 2.2827811MixupTrain:  epoch  0, batch  1442 | loss: 1.9416642MixupTrain:  epoch  0, batch  1443 | loss: 2.1168995MixupTrain:  epoch  0, batch  1444 | loss: 1.9804447MixupTrain:  epoch  0, batch  1445 | loss: 2.4117441MixupTrain:  epoch  0, batch  1446 | loss: 2.1069150MixupTrain:  epoch  0, batch  1447 | loss: 2.2444901MixupTrain:  epoch  0, batch  1448 | loss: 2.0600629MixupTrain:  epoch  0, batch  1449 | loss: 2.1841044MixupTrain:  epoch  0, batch  1450 | loss: 2.3566170MixupTrain:  epoch  0, batch  1451 | loss: 2.3689916MixupTrain:  epoch  0, batch  1452 | loss: 2.1385250MixupTrain:  epoch  0, batch  1453 | loss: 1.9290607MixupTrain:  epoch  0, batch  1454 | loss: 2.2831554MixupTrain:  epoch  0, batch  1455 | loss: 2.2605858MixupTrain:  epoch  0, batch  1456 | loss: 1.9587301MixupTrain:  epoch  0, batch  1457 | loss: 2.2173617MixupTrain:  epoch  0, batch  1458 | loss: 2.2994723MixupTrain:  epoch  0, batch  1459 | loss: 2.2438231MixupTrain:  epoch  0, batch  1460 | loss: 2.0999939MixupTrain:  epoch  0, batch  1461 | loss: 2.2559671MixupTrain:  epoch  0, batch  1462 | loss: 1.9542181MixupTrain:  epoch  0, batch  1463 | loss: 2.0203288MixupTrain:  epoch  0, batch  1464 | loss: 2.3515782MixupTrain:  epoch  0, batch  1465 | loss: 1.9480116MixupTrain:  epoch  0, batch  1466 | loss: 2.0825224MixupTrain:  epoch  0, batch  1467 | loss: 2.1204393MixupTrain:  epoch  0, batch  1468 | loss: 2.1737618MixupTrain:  epoch  0, batch  1469 | loss: 2.4277515MixupTrain:  epoch  0, batch  1470 | loss: 2.0648603MixupTrain:  epoch  0, batch  1471 | loss: 2.4015899MixupTrain:  epoch  0, batch  1472 | loss: 2.0102961MixupTrain:  epoch  0, batch  1473 | loss: 2.0803137MixupTrain:  epoch  0, batch  1474 | loss: 1.9863727MixupTrain:  epoch  0, batch  1475 | loss: 1.9869422MixupTrain:  epoch  0, batch  1476 | loss: 1.9654148MixupTrain:  epoch  0, batch  1477 | loss: 2.0037467MixupTrain:  epoch  0, batch  1478 | loss: 2.0256884MixupTrain:  epoch  0, batch  1479 | loss: 2.1719580MixupTrain:  epoch  0, batch  1480 | loss: 2.1695361MixupTrain:  epoch  0, batch  1481 | loss: 2.1417441MixupTrain:  epoch  0, batch  1482 | loss: 2.2825422MixupTrain:  epoch  0, batch  1483 | loss: 2.0836575MixupTrain:  epoch  0, batch  1484 | loss: 2.0061193MixupTrain:  epoch  0, batch  1485 | loss: 1.9280552MixupTrain:  epoch  0, batch  1486 | loss: 2.1848803MixupTrain:  epoch  0, batch  1487 | loss: 2.3380604MixupTrain:  epoch  0, batch  1488 | loss: 2.0756261MixupTrain:  epoch  0, batch  1489 | loss: 2.0972877MixupTrain:  epoch  0, batch  1490 | loss: 2.0613680MixupTrain:  epoch  0, batch  1491 | loss: 1.9900314MixupTrain:  epoch  0, batch  1492 | loss: 2.2022445MixupTrain:  epoch  0, batch  1493 | loss: 2.2907605MixupTrain:  epoch  0, batch  1494 | loss: 1.8864806MixupTrain:  epoch  0, batch  1495 | loss: 2.1124830MixupTrain:  epoch  0, batch  1496 | loss: 2.1353092MixupTrain:  epoch  0, batch  1497 | loss: 2.3528607MixupTrain:  epoch  0, batch  1498 | loss: 2.1618152MixupTrain:  epoch  0, batch  1499 | loss: 2.2371960MixupTrain:  epoch  0, batch  1500 | loss: 2.3038054MixupTrain:  epoch  0, batch  1501 | loss: 2.1902697MixupTrain:  epoch  0, batch  1502 | loss: 2.2301011MixupTrain:  epoch  0, batch  1503 | loss: 2.0402336MixupTrain:  epoch  0, batch  1504 | loss: 2.0944815MixupTrain:  epoch  0, batch  1505 | loss: 2.0085890MixupTrain:  epoch  0, batch  1506 | loss: 2.0902007MixupTrain:  epoch  0, batch  1507 | loss: 2.3122602MixupTrain:  epoch  0, batch  1508 | loss: 2.0811007MixupTrain:  epoch  0, batch  1509 | loss: 2.3051867MixupTrain:  epoch  0, batch  1510 | loss: 2.3183091MixupTrain:  epoch  0, batch  1511 | loss: 1.8893363MixupTrain:  epoch  0, batch  1512 | loss: 2.4508615MixupTrain:  epoch  0, batch  1513 | loss: 2.2199492MixupTrain:  epoch  0, batch  1514 | loss: 2.0909710MixupTrain:  epoch  0, batch  1515 | loss: 1.9878690MixupTrain:  epoch  0, batch  1516 | loss: 2.1296055MixupTrain:  epoch  0, batch  1517 | loss: 2.2039943MixupTrain:  epoch  0, batch  1518 | loss: 2.2001424MixupTrain:  epoch  0, batch  1519 | loss: 2.2685149MixupTrain:  epoch  0, batch  1520 | loss: 2.2198060MixupTrain:  epoch  0, batch  1521 | loss: 2.1657000MixupTrain:  epoch  0, batch  1522 | loss: 2.0237906MixupTrain:  epoch  0, batch  1523 | loss: 1.9589992MixupTrain:  epoch  0, batch  1524 | loss: 2.2095051MixupTrain:  epoch  0, batch  1525 | loss: 2.0095906MixupTrain:  epoch  0, batch  1526 | loss: 2.0830626MixupTrain:  epoch  0, batch  1527 | loss: 1.9657310MixupTrain:  epoch  0, batch  1528 | loss: 1.9327059MixupTrain:  epoch  0, batch  1529 | loss: 2.1946321MixupTrain:  epoch  0, batch  1530 | loss: 2.0919394MixupTrain:  epoch  0, batch  1531 | loss: 2.0835564MixupTrain:  epoch  0, batch  1532 | loss: 2.2448511MixupTrain:  epoch  0, batch  1533 | loss: 2.2273264MixupTrain:  epoch  0, batch  1534 | loss: 2.0199828MixupTrain:  epoch  0, batch  1535 | loss: 2.3534112MixupTrain:  epoch  0, batch  1536 | loss: 2.1404347MixupTrain:  epoch  0, batch  1537 | loss: 2.1363926MixupTrain:  epoch  0, batch  1538 | loss: 2.1908131MixupTrain:  epoch  0, batch  1539 | loss: 1.8711436MixupTrain:  epoch  0, batch  1540 | loss: 2.2716184MixupTrain:  epoch  0, batch  1541 | loss: 1.9636416MixupTrain:  epoch  0, batch  1542 | loss: 2.0522180MixupTrain:  epoch  0, batch  1543 | loss: 2.1866913MixupTrain:  epoch  0, batch  1544 | loss: 2.0735776MixupTrain:  epoch  0, batch  1545 | loss: 1.9032309MixupTrain:  epoch  0, batch  1546 | loss: 2.1100044MixupTrain:  epoch  0, batch  1547 | loss: 2.1263654MixupTrain:  epoch  0, batch  1548 | loss: 2.1602788MixupTrain:  epoch  0, batch  1549 | loss: 2.0905361MixupTrain:  epoch  0, batch  1550 | loss: 2.0797324MixupTrain:  epoch  0, batch  1551 | loss: 2.2334738MixupTrain:  epoch  0, batch  1552 | loss: 2.2516718MixupTrain:  epoch  0, batch  1553 | loss: 2.1669006MixupTrain:  epoch  0, batch  1554 | loss: 2.2542591MixupTrain:  epoch  0, batch  1555 | loss: 1.9043475MixupTrain:  epoch  0, batch  1556 | loss: 2.2421460MixupTrain:  epoch  0, batch  1557 | loss: 2.2543814MixupTrain:  epoch  0, batch  1558 | loss: 2.1126313MixupTrain:  epoch  0, batch  1559 | loss: 2.2706208MixupTrain:  epoch  0, batch  1560 | loss: 2.2241321MixupTrain:  epoch  0, batch  1561 | loss: 2.1130590MixupTrain:  epoch  0, batch  1562 | loss: 1.9450544MixupTrain:  epoch  0, batch  1563 | loss: 1.9296074MixupTrain:  epoch  0, batch  1564 | loss: 2.1685739MixupTrain:  epoch  0, batch  1565 | loss: 2.4104493MixupTrain:  epoch  0, batch  1566 | loss: 2.1866884MixupTrain:  epoch  0, batch  1567 | loss: 2.1319985MixupTrain:  epoch  0, batch  1568 | loss: 2.2904778MixupTrain:  epoch  0, batch  1569 | loss: 2.1087809MixupTrain:  epoch  0, batch  1570 | loss: 2.1119099MixupTrain:  epoch  0, batch  1571 | loss: 2.2692404MixupTrain:  epoch  0, batch  1572 | loss: 2.3593340MixupTrain:  epoch  0, batch  1573 | loss: 2.0542872MixupTrain:  epoch  0, batch  1574 | loss: 2.1084149MixupTrain:  epoch  0, batch  1575 | loss: 2.2299612MixupTrain:  epoch  0, batch  1576 | loss: 2.0678988MixupTrain:  epoch  0, batch  1577 | loss: 2.1312001MixupTrain:  epoch  0, batch  1578 | loss: 2.3123989MixupTrain:  epoch  0, batch  1579 | loss: 2.2855670MixupTrain:  epoch  0, batch  1580 | loss: 2.0185239MixupTrain:  epoch  0, batch  1581 | loss: 2.3526170MixupTrain:  epoch  0, batch  1582 | loss: 2.0347614MixupTrain:  epoch  0, batch  1583 | loss: 2.4329844MixupTrain:  epoch  0, batch  1584 | loss: 1.9721138MixupTrain:  epoch  0, batch  1585 | loss: 2.1624680MixupTrain:  epoch  0, batch  1586 | loss: 2.1210063MixupTrain:  epoch  0, batch  1587 | loss: 2.2220647MixupTrain:  epoch  0, batch  1588 | loss: 1.8659703MixupTrain:  epoch  0, batch  1589 | loss: 2.2551541MixupTrain:  epoch  0, batch  1590 | loss: 2.2484720MixupTrain:  epoch  0, batch  1591 | loss: 2.1062593MixupTrain:  epoch  0, batch  1592 | loss: 2.0389152MixupTrain:  epoch  0, batch  1593 | loss: 1.9713521MixupTrain:  epoch  0, batch  1594 | loss: 2.2872787MixupTrain:  epoch  0, batch  1595 | loss: 2.2417369MixupTrain:  epoch  0, batch  1596 | loss: 2.0625064MixupTrain:  epoch  0, batch  1597 | loss: 2.2566533MixupTrain:  epoch  0, batch  1598 | loss: 2.1085005MixupTrain:  epoch  0, batch  1599 | loss: 2.3309436MixupTrain:  epoch  0, batch  1600 | loss: 1.9906135MixupTrain:  epoch  0, batch  1601 | loss: 1.9387157MixupTrain:  epoch  0, batch  1602 | loss: 2.0372119MixupTrain:  epoch  0, batch  1603 | loss: 2.1217690MixupTrain:  epoch  0, batch  1604 | loss: 2.1370802MixupTrain:  epoch  0, batch  1605 | loss: 2.0461643MixupTrain:  epoch  0, batch  1606 | loss: 2.2711627MixupTrain:  epoch  0, batch  1607 | loss: 2.1048994MixupTrain:  epoch  0, batch  1608 | loss: 2.0637465MixupTrain:  epoch  0, batch  1609 | loss: 2.1179628MixupTrain:  epoch  0, batch  1610 | loss: 2.1392205MixupTrain:  epoch  0, batch  1611 | loss: 2.3098547MixupTrain:  epoch  0, batch  1612 | loss: 2.4732947MixupTrain:  epoch  0, batch  1613 | loss: 2.0711217MixupTrain:  epoch  0, batch  1614 | loss: 1.9678028MixupTrain:  epoch  0, batch  1615 | loss: 2.1314864MixupTrain:  epoch  0, batch  1616 | loss: 2.0605378MixupTrain:  epoch  0, batch  1617 | loss: 2.1931112MixupTrain:  epoch  0, batch  1618 | loss: 2.0212688MixupTrain:  epoch  0, batch  1619 | loss: 2.0024204MixupTrain:  epoch  0, batch  1620 | loss: 2.1922665MixupTrain:  epoch  0, batch  1621 | loss: 2.1524725MixupTrain:  epoch  0, batch  1622 | loss: 2.2787464MixupTrain:  epoch  0, batch  1623 | loss: 2.1048980MixupTrain:  epoch  0, batch  1624 | loss: 2.1688683MixupTrain:  epoch  0, batch  1625 | loss: 1.9647361MixupTrain:  epoch  0, batch  1626 | loss: 2.2454524MixupTrain:  epoch  0, batch  1627 | loss: 2.1727977MixupTrain:  epoch  0, batch  1628 | loss: 1.9825903MixupTrain:  epoch  0, batch  1629 | loss: 2.1959894MixupTrain:  epoch  0, batch  1630 | loss: 2.1383228MixupTrain:  epoch  0, batch  1631 | loss: 2.2342498MixupTrain:  epoch  0, batch  1632 | loss: 2.3604314MixupTrain:  epoch  0, batch  1633 | loss: 1.9529047MixupTrain:  epoch  0, batch  1634 | loss: 1.9493954MixupTrain:  epoch  0, batch  1635 | loss: 2.0196228MixupTrain:  epoch  0, batch  1636 | loss: 2.1015792MixupTrain:  epoch  0, batch  1637 | loss: 2.1698797MixupTrain:  epoch  0, batch  1638 | loss: 2.3097374MixupTrain:  epoch  0, batch  1639 | loss: 2.2438056MixupTrain:  epoch  0, batch  1640 | loss: 2.2126923MixupTrain:  epoch  0, batch  1641 | loss: 2.1478918MixupTrain:  epoch  0, batch  1642 | loss: 2.2458951MixupTrain:  epoch  0, batch  1643 | loss: 1.9972500MixupTrain:  epoch  0, batch  1644 | loss: 2.3918617MixupTrain:  epoch  0, batch  1645 | loss: 1.9754353MixupTrain:  epoch  0, batch  1646 | loss: 2.2057817MixupTrain:  epoch  0, batch  1647 | loss: 2.2237058MixupTrain:  epoch  0, batch  1648 | loss: 1.9241303MixupTrain:  epoch  0, batch  1649 | loss: 2.2183414MixupTrain:  epoch  0, batch  1650 | loss: 2.2627320MixupTrain:  epoch  0, batch  1651 | loss: 2.3787115MixupTrain:  epoch  0, batch  1652 | loss: 2.2109032MixupTrain:  epoch  0, batch  1653 | loss: 2.0500927MixupTrain:  epoch  0, batch  1654 | loss: 2.2900882MixupTrain:  epoch  0, batch  1655 | loss: 2.3004675MixupTrain:  epoch  0, batch  1656 | loss: 1.8944163MixupTrain:  epoch  0, batch  1657 | loss: 2.1125095MixupTrain:  epoch  0, batch  1658 | loss: 1.9007890MixupTrain:  epoch  0, batch  1659 | loss: 2.3944917MixupTrain:  epoch  0, batch  1660 | loss: 2.0204272MixupTrain:  epoch  0, batch  1661 | loss: 2.0304322MixupTrain:  epoch  0, batch  1662 | loss: 2.0034337MixupTrain:  epoch  0, batch  1663 | loss: 2.0335779MixupTrain:  epoch  0, batch  1664 | loss: 2.3031454MixupTrain:  epoch  0, batch  1665 | loss: 1.9492503MixupTrain:  epoch  0, batch  1666 | loss: 2.1162829MixupTrain:  epoch  0, batch  1667 | loss: 2.0255508MixupTrain:  epoch  0, batch  1668 | loss: 1.9751086MixupTrain:  epoch  0, batch  1669 | loss: 2.3103542MixupTrain:  epoch  0, batch  1670 | loss: 2.1326609MixupTrain:  epoch  0, batch  1671 | loss: 2.3806176MixupTrain:  epoch  0, batch  1672 | loss: 2.0832329MixupTrain:  epoch  0, batch  1673 | loss: 2.1462965MixupTrain:  epoch  0, batch  1674 | loss: 2.0482826MixupTrain:  epoch  0, batch  1675 | loss: 2.1589699MixupTrain:  epoch  0, batch  1676 | loss: 2.0963821MixupTrain:  epoch  0, batch  1677 | loss: 2.3101540MixupTrain:  epoch  0, batch  1678 | loss: 2.0191526MixupTrain:  epoch  0, batch  1679 | loss: 2.1544156MixupTrain:  epoch  0, batch  1680 | loss: 2.2060320MixupTrain:  epoch  0, batch  1681 | loss: 2.2024150MixupTrain:  epoch  0, batch  1682 | loss: 2.3476427MixupTrain:  epoch  0, batch  1683 | loss: 2.0827103MixupTrain:  epoch  0, batch  1684 | loss: 2.5108213MixupTrain:  epoch  0, batch  1685 | loss: 2.2662663MixupTrain:  epoch  0, batch  1686 | loss: 2.1361351MixupTrain:  epoch  0, batch  1687 | loss: 2.2439427MixupTrain:  epoch  0, batch  1688 | loss: 2.1722212MixupTrain:  epoch  0, batch  1689 | loss: 2.0805454MixupTrain:  epoch  0, batch  1690 | loss: 2.2114649MixupTrain:  epoch  0, batch  1691 | loss: 2.2112732MixupTrain:  epoch  0, batch  1692 | loss: 1.9891677MixupTrain:  epoch  0, batch  1693 | loss: 2.2114496MixupTrain:  epoch  0, batch  1694 | loss: 2.4692302MixupTrain:  epoch  0, batch  1695 | loss: 2.1537561MixupTrain:  epoch  0, batch  1696 | loss: 2.1837931MixupTrain:  epoch  0, batch  1697 | loss: 2.3395462MixupTrain:  epoch  0, batch  1698 | loss: 2.1221936MixupTrain:  epoch  0, batch  1699 | loss: 2.3271620MixupTrain:  epoch  0, batch  1700 | loss: 2.2617297MixupTrain:  epoch  0, batch  1701 | loss: 2.0010097MixupTrain:  epoch  0, batch  1702 | loss: 2.0329807MixupTrain:  epoch  0, batch  1703 | loss: 2.0297041MixupTrain:  epoch  0, batch  1704 | loss: 2.3063064MixupTrain:  epoch  0, batch  1705 | loss: 2.0559831MixupTrain:  epoch  0, batch  1706 | loss: 2.4500818MixupTrain:  epoch  0, batch  1707 | loss: 1.9470901MixupTrain:  epoch  0, batch  1708 | loss: 2.2291467MixupTrain:  epoch  0, batch  1709 | loss: 2.1681376MixupTrain:  epoch  0, batch  1710 | loss: 2.2655351MixupTrain:  epoch  0, batch  1711 | loss: 2.0987904MixupTrain:  epoch  0, batch  1712 | loss: 2.1415992MixupTrain:  epoch  0, batch  1713 | loss: 2.0707693MixupTrain:  epoch  0, batch  1714 | loss: 2.0465639MixupTrain:  epoch  0, batch  1715 | loss: 2.3231049MixupTrain:  epoch  0, batch  1716 | loss: 2.1932831MixupTrain:  epoch  0, batch  1717 | loss: 2.0825472MixupTrain:  epoch  0, batch  1718 | loss: 2.0686252MixupTrain:  epoch  0, batch  1719 | loss: 2.2276554MixupTrain:  epoch  0, batch  1720 | loss: 2.3885407MixupTrain:  epoch  0, batch  1721 | loss: 2.1257463MixupTrain:  epoch  0, batch  1722 | loss: 2.2705522MixupTrain:  epoch  0, batch  1723 | loss: 2.1364994MixupTrain:  epoch  0, batch  1724 | loss: 2.0669477MixupTrain:  epoch  0, batch  1725 | loss: 2.1051111MixupTrain:  epoch  0, batch  1726 | loss: 2.1211171MixupTrain:  epoch  0, batch  1727 | loss: 2.2165365MixupTrain:  epoch  0, batch  1728 | loss: 2.0711770MixupTrain:  epoch  0, batch  1729 | loss: 2.2172580MixupTrain:  epoch  0, batch  1730 | loss: 2.3184125MixupTrain:  epoch  0, batch  1731 | loss: 1.9288183MixupTrain:  epoch  0, batch  1732 | loss: 2.3501840MixupTrain:  epoch  0, batch  1733 | loss: 2.5031562MixupTrain:  epoch  0, batch  1734 | loss: 2.1766748MixupTrain:  epoch  0, batch  1735 | loss: 2.2823658MixupTrain:  epoch  0, batch  1736 | loss: 2.0793808MixupTrain:  epoch  0, batch  1737 | loss: 2.1170201MixupTrain:  epoch  0, batch  1738 | loss: 2.2156253MixupTrain:  epoch  0, batch  1739 | loss: 2.1044319MixupTrain:  epoch  0, batch  1740 | loss: 2.0248761MixupTrain:  epoch  0, batch  1741 | loss: 2.0572758MixupTrain:  epoch  0, batch  1742 | loss: 2.3279052MixupTrain:  epoch  0, batch  1743 | loss: 2.2653968MixupTrain:  epoch  0, batch  1744 | loss: 2.0494328MixupTrain:  epoch  0, batch  1745 | loss: 2.1377888MixupTrain:  epoch  0, batch  1746 | loss: 2.1514506MixupTrain:  epoch  0, batch  1747 | loss: 2.0828118MixupTrain:  epoch  0, batch  1748 | loss: 2.0883322MixupTrain:  epoch  0, batch  1749 | loss: 2.0903323MixupTrain:  epoch  0, batch  1750 | loss: 2.0647228MixupTrain:  epoch  0, batch  1751 | loss: 2.5209050MixupTrain:  epoch  0, batch  1752 | loss: 2.1792529MixupTrain:  epoch  0, batch  1753 | loss: 2.2718241MixupTrain:  epoch  0, batch  1754 | loss: 2.0610874MixupTrain:  epoch  0, batch  1755 | loss: 2.1648164MixupTrain:  epoch  0, batch  1756 | loss: 1.9229603MixupTrain:  epoch  0, batch  1757 | loss: 2.2332544MixupTrain:  epoch  0, batch  1758 | loss: 2.2149222MixupTrain:  epoch  0, batch  1759 | loss: 2.0499740MixupTrain:  epoch  0, batch  1760 | loss: 2.4083874MixupTrain:  epoch  0, batch  1761 | loss: 2.4485154
MemoryTrain:  epoch  0, batch     0 | loss: 1.8450534MemoryTrain:  epoch  0, batch     1 | loss: 2.4110780MemoryTrain:  epoch  0, batch     2 | loss: 2.5517793MemoryTrain:  epoch  0, batch     3 | loss: 2.4253945MemoryTrain:  epoch  0, batch     4 | loss: 2.4533653MemoryTrain:  epoch  0, batch     5 | loss: 2.2509665MemoryTrain:  epoch  0, batch     6 | loss: 2.6945400MemoryTrain:  epoch  0, batch     7 | loss: 2.3024433MemoryTrain:  epoch  0, batch     8 | loss: 2.4955111MemoryTrain:  epoch  0, batch     9 | loss: 1.9503334MemoryTrain:  epoch  0, batch    10 | loss: 1.9929731MemoryTrain:  epoch  0, batch    11 | loss: 2.3989310MemoryTrain:  epoch  0, batch    12 | loss: 1.9218528MemoryTrain:  epoch  0, batch    13 | loss: 1.8919157MemoryTrain:  epoch  1, batch     0 | loss: 1.8735962MemoryTrain:  epoch  1, batch     1 | loss: 2.0387759MemoryTrain:  epoch  1, batch     2 | loss: 1.8359241MemoryTrain:  epoch  1, batch     3 | loss: 1.8307881MemoryTrain:  epoch  1, batch     4 | loss: 1.8938658MemoryTrain:  epoch  1, batch     5 | loss: 1.8139757MemoryTrain:  epoch  1, batch     6 | loss: 1.8152919MemoryTrain:  epoch  1, batch     7 | loss: 1.8247619MemoryTrain:  epoch  1, batch     8 | loss: 1.8412758MemoryTrain:  epoch  1, batch     9 | loss: 1.8221827MemoryTrain:  epoch  1, batch    10 | loss: 1.8795406MemoryTrain:  epoch  1, batch    11 | loss: 1.8142062MemoryTrain:  epoch  1, batch    12 | loss: 1.8591526MemoryTrain:  epoch  1, batch    13 | loss: 1.8050877MemoryTrain:  epoch  2, batch     0 | loss: 1.8177204MemoryTrain:  epoch  2, batch     1 | loss: 1.9267387MemoryTrain:  epoch  2, batch     2 | loss: 1.8155334MemoryTrain:  epoch  2, batch     3 | loss: 1.8170571MemoryTrain:  epoch  2, batch     4 | loss: 1.8158631MemoryTrain:  epoch  2, batch     5 | loss: 1.8299530MemoryTrain:  epoch  2, batch     6 | loss: 1.8137900MemoryTrain:  epoch  2, batch     7 | loss: 1.8144318MemoryTrain:  epoch  2, batch     8 | loss: 1.8131728MemoryTrain:  epoch  2, batch     9 | loss: 1.8199131MemoryTrain:  epoch  2, batch    10 | loss: 1.8122833MemoryTrain:  epoch  2, batch    11 | loss: 1.8171544MemoryTrain:  epoch  2, batch    12 | loss: 1.8106492MemoryTrain:  epoch  2, batch    13 | loss: 1.8225406MemoryTrain:  epoch  3, batch     0 | loss: 1.8111638MemoryTrain:  epoch  3, batch     1 | loss: 1.8098968MemoryTrain:  epoch  3, batch     2 | loss: 1.8069172MemoryTrain:  epoch  3, batch     3 | loss: 1.8080090MemoryTrain:  epoch  3, batch     4 | loss: 1.8240557MemoryTrain:  epoch  3, batch     5 | loss: 1.8125122MemoryTrain:  epoch  3, batch     6 | loss: 1.8163359MemoryTrain:  epoch  3, batch     7 | loss: 1.8151894MemoryTrain:  epoch  3, batch     8 | loss: 1.8199021MemoryTrain:  epoch  3, batch     9 | loss: 1.8035023MemoryTrain:  epoch  3, batch    10 | loss: 1.8092606MemoryTrain:  epoch  3, batch    11 | loss: 1.8130436MemoryTrain:  epoch  3, batch    12 | loss: 1.8090816MemoryTrain:  epoch  3, batch    13 | loss: 1.8180363MemoryTrain:  epoch  4, batch     0 | loss: 1.8085365MemoryTrain:  epoch  4, batch     1 | loss: 1.8159927MemoryTrain:  epoch  4, batch     2 | loss: 1.8090738MemoryTrain:  epoch  4, batch     3 | loss: 1.8158104MemoryTrain:  epoch  4, batch     4 | loss: 1.8058906MemoryTrain:  epoch  4, batch     5 | loss: 1.8192109MemoryTrain:  epoch  4, batch     6 | loss: 1.8131601MemoryTrain:  epoch  4, batch     7 | loss: 1.8118582MemoryTrain:  epoch  4, batch     8 | loss: 1.8144414MemoryTrain:  epoch  4, batch     9 | loss: 1.8142515MemoryTrain:  epoch  4, batch    10 | loss: 1.8138686MemoryTrain:  epoch  4, batch    11 | loss: 1.8188815MemoryTrain:  epoch  4, batch    12 | loss: 1.8130867MemoryTrain:  epoch  4, batch    13 | loss: 1.8141998MemoryTrain:  epoch  5, batch     0 | loss: 1.8115673MemoryTrain:  epoch  5, batch     1 | loss: 1.8221122MemoryTrain:  epoch  5, batch     2 | loss: 1.8183417MemoryTrain:  epoch  5, batch     3 | loss: 1.8086822MemoryTrain:  epoch  5, batch     4 | loss: 1.8055054MemoryTrain:  epoch  5, batch     5 | loss: 1.8223245MemoryTrain:  epoch  5, batch     6 | loss: 1.8165654MemoryTrain:  epoch  5, batch     7 | loss: 1.8106079MemoryTrain:  epoch  5, batch     8 | loss: 1.8101704MemoryTrain:  epoch  5, batch     9 | loss: 1.8264425MemoryTrain:  epoch  5, batch    10 | loss: 1.8130798MemoryTrain:  epoch  5, batch    11 | loss: 1.8120228MemoryTrain:  epoch  5, batch    12 | loss: 1.8124187MemoryTrain:  epoch  5, batch    13 | loss: 1.8168639MemoryTrain:  epoch  6, batch     0 | loss: 1.8212950MemoryTrain:  epoch  6, batch     1 | loss: 1.8101690MemoryTrain:  epoch  6, batch     2 | loss: 1.8050630MemoryTrain:  epoch  6, batch     3 | loss: 1.8183061MemoryTrain:  epoch  6, batch     4 | loss: 1.8090839MemoryTrain:  epoch  6, batch     5 | loss: 1.8167448MemoryTrain:  epoch  6, batch     6 | loss: 1.8310106MemoryTrain:  epoch  6, batch     7 | loss: 1.8227711MemoryTrain:  epoch  6, batch     8 | loss: 1.8096882MemoryTrain:  epoch  6, batch     9 | loss: 1.8205647MemoryTrain:  epoch  6, batch    10 | loss: 1.8154975MemoryTrain:  epoch  6, batch    11 | loss: 1.8070601MemoryTrain:  epoch  6, batch    12 | loss: 1.8129671MemoryTrain:  epoch  6, batch    13 | loss: 1.8247292MemoryTrain:  epoch  7, batch     0 | loss: 1.8127395MemoryTrain:  epoch  7, batch     1 | loss: 1.8124387MemoryTrain:  epoch  7, batch     2 | loss: 1.8210566MemoryTrain:  epoch  7, batch     3 | loss: 1.8197098MemoryTrain:  epoch  7, batch     4 | loss: 1.8237760MemoryTrain:  epoch  7, batch     5 | loss: 1.8105161MemoryTrain:  epoch  7, batch     6 | loss: 1.8076867MemoryTrain:  epoch  7, batch     7 | loss: 1.8280959MemoryTrain:  epoch  7, batch     8 | loss: 1.8101063MemoryTrain:  epoch  7, batch     9 | loss: 1.8149202MemoryTrain:  epoch  7, batch    10 | loss: 1.8166378MemoryTrain:  epoch  7, batch    11 | loss: 1.8078234MemoryTrain:  epoch  7, batch    12 | loss: 1.8059696MemoryTrain:  epoch  7, batch    13 | loss: 1.8208741MemoryTrain:  epoch  8, batch     0 | loss: 1.8032050MemoryTrain:  epoch  8, batch     1 | loss: 1.8198862MemoryTrain:  epoch  8, batch     2 | loss: 1.8139238MemoryTrain:  epoch  8, batch     3 | loss: 1.8101076MemoryTrain:  epoch  8, batch     4 | loss: 1.8075674MemoryTrain:  epoch  8, batch     5 | loss: 1.8173373MemoryTrain:  epoch  8, batch     6 | loss: 1.8125485MemoryTrain:  epoch  8, batch     7 | loss: 1.8122287MemoryTrain:  epoch  8, batch     8 | loss: 1.8081498MemoryTrain:  epoch  8, batch     9 | loss: 1.8293819MemoryTrain:  epoch  8, batch    10 | loss: 1.8119556MemoryTrain:  epoch  8, batch    11 | loss: 1.8117723MemoryTrain:  epoch  8, batch    12 | loss: 1.8141525MemoryTrain:  epoch  8, batch    13 | loss: 1.8189453MemoryTrain:  epoch  9, batch     0 | loss: 1.8116956MemoryTrain:  epoch  9, batch     1 | loss: 1.8184283MemoryTrain:  epoch  9, batch     2 | loss: 1.8077461MemoryTrain:  epoch  9, batch     3 | loss: 1.8087512MemoryTrain:  epoch  9, batch     4 | loss: 1.8147116MemoryTrain:  epoch  9, batch     5 | loss: 1.8068986MemoryTrain:  epoch  9, batch     6 | loss: 1.8101840MemoryTrain:  epoch  9, batch     7 | loss: 1.8158202MemoryTrain:  epoch  9, batch     8 | loss: 1.8066730MemoryTrain:  epoch  9, batch     9 | loss: 1.8121716MemoryTrain:  epoch  9, batch    10 | loss: 1.8061974MemoryTrain:  epoch  9, batch    11 | loss: 1.8053823MemoryTrain:  epoch  9, batch    12 | loss: 1.8108544MemoryTrain:  epoch  9, batch    13 | loss: 1.8039565
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    1 | acc: 87.50%,  total acc: 81.25%   [EVAL] batch:    2 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    3 | acc: 75.00%,  total acc: 79.69%   [EVAL] batch:    4 | acc: 87.50%,  total acc: 81.25%   [EVAL] batch:    5 | acc: 93.75%,  total acc: 83.33%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 84.82%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 85.94%   [EVAL] batch:    8 | acc: 87.50%,  total acc: 86.11%   [EVAL] batch:    9 | acc: 87.50%,  total acc: 86.25%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 86.93%   [EVAL] batch:   11 | acc: 100.00%,  total acc: 88.02%   [EVAL] batch:   12 | acc: 100.00%,  total acc: 88.94%   [EVAL] batch:   13 | acc: 100.00%,  total acc: 89.73%   [EVAL] batch:   14 | acc: 43.75%,  total acc: 86.67%   
[EVAL] batch:    0 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:    1 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:    2 | acc: 12.50%,  total acc: 8.33%   [EVAL] batch:    3 | acc: 6.25%,  total acc: 7.81%   [EVAL] batch:    4 | acc: 6.25%,  total acc: 7.50%   [EVAL] batch:    5 | acc: 25.00%,  total acc: 10.42%   [EVAL] batch:    6 | acc: 43.75%,  total acc: 15.18%   [EVAL] batch:    7 | acc: 50.00%,  total acc: 19.53%   [EVAL] batch:    8 | acc: 62.50%,  total acc: 24.31%   [EVAL] batch:    9 | acc: 37.50%,  total acc: 25.62%   [EVAL] batch:   10 | acc: 37.50%,  total acc: 26.70%   [EVAL] batch:   11 | acc: 50.00%,  total acc: 28.65%   [EVAL] batch:   12 | acc: 18.75%,  total acc: 27.88%   [EVAL] batch:   13 | acc: 25.00%,  total acc: 27.68%   [EVAL] batch:   14 | acc: 43.75%,  total acc: 28.75%   [EVAL] batch:   15 | acc: 50.00%,  total acc: 30.08%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 32.72%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 34.38%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 35.86%   [EVAL] batch:   19 | acc: 75.00%,  total acc: 37.81%   [EVAL] batch:   20 | acc: 75.00%,  total acc: 39.58%   [EVAL] batch:   21 | acc: 50.00%,  total acc: 40.06%   [EVAL] batch:   22 | acc: 56.25%,  total acc: 40.76%   [EVAL] batch:   23 | acc: 87.50%,  total acc: 42.71%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 44.75%   [EVAL] batch:   25 | acc: 81.25%,  total acc: 46.15%   [EVAL] batch:   26 | acc: 50.00%,  total acc: 46.30%   [EVAL] batch:   27 | acc: 56.25%,  total acc: 46.65%   [EVAL] batch:   28 | acc: 25.00%,  total acc: 45.91%   [EVAL] batch:   29 | acc: 31.25%,  total acc: 45.42%   [EVAL] batch:   30 | acc: 37.50%,  total acc: 45.16%   [EVAL] batch:   31 | acc: 31.25%,  total acc: 44.73%   [EVAL] batch:   32 | acc: 56.25%,  total acc: 45.08%   [EVAL] batch:   33 | acc: 6.25%,  total acc: 43.93%   [EVAL] batch:   34 | acc: 6.25%,  total acc: 42.86%   [EVAL] batch:   35 | acc: 0.00%,  total acc: 41.67%   [EVAL] batch:   36 | acc: 0.00%,  total acc: 40.54%   [EVAL] batch:   37 | acc: 6.25%,  total acc: 39.64%   [EVAL] batch:   38 | acc: 6.25%,  total acc: 38.78%   [EVAL] batch:   39 | acc: 62.50%,  total acc: 39.38%   [EVAL] batch:   40 | acc: 68.75%,  total acc: 40.09%   [EVAL] batch:   41 | acc: 68.75%,  total acc: 40.77%   [EVAL] batch:   42 | acc: 87.50%,  total acc: 41.86%   [EVAL] batch:   43 | acc: 68.75%,  total acc: 42.47%   [EVAL] batch:   44 | acc: 62.50%,  total acc: 42.92%   [EVAL] batch:   45 | acc: 56.25%,  total acc: 43.21%   [EVAL] batch:   46 | acc: 56.25%,  total acc: 43.48%   [EVAL] batch:   47 | acc: 75.00%,  total acc: 44.14%   [EVAL] batch:   48 | acc: 43.75%,  total acc: 44.13%   [EVAL] batch:   49 | acc: 75.00%,  total acc: 44.75%   [EVAL] batch:   50 | acc: 56.25%,  total acc: 44.98%   [EVAL] batch:   51 | acc: 75.00%,  total acc: 45.55%   [EVAL] batch:   52 | acc: 68.75%,  total acc: 45.99%   [EVAL] batch:   53 | acc: 93.75%,  total acc: 46.88%   [EVAL] batch:   54 | acc: 87.50%,  total acc: 47.61%   [EVAL] batch:   55 | acc: 93.75%,  total acc: 48.44%   [EVAL] batch:   56 | acc: 81.25%,  total acc: 49.01%   [EVAL] batch:   57 | acc: 62.50%,  total acc: 49.25%   [EVAL] batch:   58 | acc: 87.50%,  total acc: 49.89%   [EVAL] batch:   59 | acc: 68.75%,  total acc: 50.21%   [EVAL] batch:   60 | acc: 18.75%,  total acc: 49.69%   [EVAL] batch:   61 | acc: 0.00%,  total acc: 48.89%   [EVAL] batch:   62 | acc: 0.00%,  total acc: 48.12%   [EVAL] batch:   63 | acc: 0.00%,  total acc: 47.36%   [EVAL] batch:   64 | acc: 37.50%,  total acc: 47.21%   [EVAL] batch:   65 | acc: 31.25%,  total acc: 46.97%   [EVAL] batch:   66 | acc: 31.25%,  total acc: 46.74%   [EVAL] batch:   67 | acc: 37.50%,  total acc: 46.60%   [EVAL] batch:   68 | acc: 0.00%,  total acc: 45.92%   [EVAL] batch:   69 | acc: 0.00%,  total acc: 45.27%   [EVAL] batch:   70 | acc: 12.50%,  total acc: 44.81%   [EVAL] batch:   71 | acc: 12.50%,  total acc: 44.36%   [EVAL] batch:   72 | acc: 43.75%,  total acc: 44.35%   [EVAL] batch:   73 | acc: 56.25%,  total acc: 44.51%   [EVAL] batch:   74 | acc: 62.50%,  total acc: 44.75%   [EVAL] batch:   75 | acc: 81.25%,  total acc: 45.23%   [EVAL] batch:   76 | acc: 62.50%,  total acc: 45.45%   [EVAL] batch:   77 | acc: 62.50%,  total acc: 45.67%   [EVAL] batch:   78 | acc: 62.50%,  total acc: 45.89%   [EVAL] batch:   79 | acc: 100.00%,  total acc: 46.56%   [EVAL] batch:   80 | acc: 93.75%,  total acc: 47.15%   [EVAL] batch:   81 | acc: 100.00%,  total acc: 47.79%   [EVAL] batch:   82 | acc: 93.75%,  total acc: 48.34%   [EVAL] batch:   83 | acc: 68.75%,  total acc: 48.59%   [EVAL] batch:   84 | acc: 37.50%,  total acc: 48.46%   [EVAL] batch:   85 | acc: 25.00%,  total acc: 48.18%   [EVAL] batch:   86 | acc: 43.75%,  total acc: 48.13%   [EVAL] batch:   87 | acc: 93.75%,  total acc: 48.65%   [EVAL] batch:   88 | acc: 93.75%,  total acc: 49.16%   [EVAL] batch:   89 | acc: 100.00%,  total acc: 49.72%   [EVAL] batch:   90 | acc: 100.00%,  total acc: 50.27%   [EVAL] batch:   91 | acc: 100.00%,  total acc: 50.82%   [EVAL] batch:   92 | acc: 100.00%,  total acc: 51.34%   [EVAL] batch:   93 | acc: 100.00%,  total acc: 51.86%   [EVAL] batch:   94 | acc: 100.00%,  total acc: 52.37%   [EVAL] batch:   95 | acc: 81.25%,  total acc: 52.67%   [EVAL] batch:   96 | acc: 50.00%,  total acc: 52.64%   [EVAL] batch:   97 | acc: 43.75%,  total acc: 52.55%   [EVAL] batch:   98 | acc: 93.75%,  total acc: 52.97%   [EVAL] batch:   99 | acc: 100.00%,  total acc: 53.44%   [EVAL] batch:  100 | acc: 100.00%,  total acc: 53.90%   [EVAL] batch:  101 | acc: 75.00%,  total acc: 54.11%   [EVAL] batch:  102 | acc: 87.50%,  total acc: 54.43%   [EVAL] batch:  103 | acc: 81.25%,  total acc: 54.69%   [EVAL] batch:  104 | acc: 75.00%,  total acc: 54.88%   [EVAL] batch:  105 | acc: 87.50%,  total acc: 55.19%   [EVAL] batch:  106 | acc: 93.75%,  total acc: 55.55%   [EVAL] batch:  107 | acc: 93.75%,  total acc: 55.90%   [EVAL] batch:  108 | acc: 93.75%,  total acc: 56.25%   [EVAL] batch:  109 | acc: 87.50%,  total acc: 56.53%   [EVAL] batch:  110 | acc: 87.50%,  total acc: 56.81%   [EVAL] batch:  111 | acc: 93.75%,  total acc: 57.14%   [EVAL] batch:  112 | acc: 100.00%,  total acc: 57.52%   [EVAL] batch:  113 | acc: 100.00%,  total acc: 57.89%   [EVAL] batch:  114 | acc: 100.00%,  total acc: 58.26%   [EVAL] batch:  115 | acc: 37.50%,  total acc: 58.08%   
cur_acc:  ['0.8712', '0.9107', '0.8281', '0.8846', '0.5568', '0.9554', '0.8667']
his_acc:  ['0.8712', '0.8697', '0.6771', '0.5862', '0.5540', '0.5464', '0.5808']
CurrentTrain: epoch  0, batch     0 | loss: 6.3758874CurrentTrain: epoch  0, batch     1 | loss: 4.9176035CurrentTrain: epoch  1, batch     0 | loss: 4.9791684CurrentTrain: epoch  1, batch     1 | loss: 5.1997528CurrentTrain: epoch  2, batch     0 | loss: 4.5683517CurrentTrain: epoch  2, batch     1 | loss: 3.2020173CurrentTrain: epoch  3, batch     0 | loss: 3.4831986CurrentTrain: epoch  3, batch     1 | loss: 2.2649758CurrentTrain: epoch  4, batch     0 | loss: 3.0761516CurrentTrain: epoch  4, batch     1 | loss: 2.3580294CurrentTrain: epoch  5, batch     0 | loss: 2.4553218CurrentTrain: epoch  5, batch     1 | loss: 3.0295918CurrentTrain: epoch  6, batch     0 | loss: 2.5229497CurrentTrain: epoch  6, batch     1 | loss: 3.1796124CurrentTrain: epoch  7, batch     0 | loss: 3.0908670CurrentTrain: epoch  7, batch     1 | loss: 1.8788944CurrentTrain: epoch  8, batch     0 | loss: 2.4772055CurrentTrain: epoch  8, batch     1 | loss: 2.5296953CurrentTrain: epoch  9, batch     0 | loss: 2.5458496CurrentTrain: epoch  9, batch     1 | loss: 1.9931859
#### person cities of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person cities of residence" means a person is living in a city.
Here is an example:
Relation: person cities of residence
Context: tv-idol-johns -- atlanta -- `` american idol '' finalist michael johns moved to los angeles several years ago , but his heart is still in atlanta .
Head Entity: his
Tail Entity: atlanta
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person cities of residence":
Relation: person cities of residence  
Context: after years of living in new york city, the famous author decided to settle down in boston, where he found inspiration for his next novel.  
Head Entity: he  
Tail Entity: boston  

Relation: person cities of residence  
Context: despite being born in chicago, the musician has always considered nashville his true home, where he has spent most of his adult life.  
Head Entity: he  
Tail Entity: nashville  

Relation: person cities of residence  
Context: the renowned scientist, originally from san francisco, has made a significant impact in the field while residing in cambridge for over a decade.  
Head Entity: he  
Tail Entity: cambridge  

Relation: person cities of residence  
Context: after moving from seattle to austin, the tech entrepreneur found a vibrant community that matched his innovative spirit.  
Head Entity: he  
Tail Entity: austin  

Relation: person cities of residence  
Context: although she grew up in miami, the actress has spent the last few years living in los angeles to pursue her career in film.  
Head Entity: she  
Tail Entity: los angeles  
#### person schools attended ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person schools attended" means a person 's school is an organization.
Here is an example:
Relation: person schools attended
Context: after world war ii , he attended the university of southern california , where he became editor of a college magazine .
Head Entity: he
Tail Entity: university of southern california
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person schools attended":
Relation: person schools attended  
Context: She graduated from Harvard University with a degree in economics before pursuing her career in finance.  
Head Entity: She  
Tail Entity: Harvard University  

Relation: person schools attended  
Context: After completing his high school education, John enrolled at Stanford University to study computer science.  
Head Entity: John  
Tail Entity: Stanford University  

Relation: person schools attended  
Context: Maria attended the University of Oxford for her postgraduate studies in literature, where she developed her passion for writing.  
Head Entity: Maria  
Tail Entity: University of Oxford  

Relation: person schools attended  
Context: Following his time at the local community college, David transferred to the University of California, Berkeley to finish his degree.  
Head Entity: David  
Tail Entity: University of California, Berkeley  

Relation: person schools attended  
Context: During her youth, Emily spent four years at the Massachusetts Institute of Technology, focusing on engineering and technology.  
Head Entity: Emily  
Tail Entity: Massachusetts Institute of Technology  
#### person country of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person country of death" means a person was died in a country.
Here is an example:
Relation: person country of death
Context: u.s. rep. parren mitchell , founding member of congressional black caucus , dies at 85
Head Entity: parren mitchell
Tail Entity: u.s.
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person country of death":
Relation: person country of death  
Context: renowned physicist stephen hawking passes away in cambridge, england at the age of 76  
Head Entity: stephen hawking  
Tail Entity: england  

Relation: person country of death  
Context: famous author gabriel garcia marquez dies in mexico city, mexico, leaving behind a legacy of magical realism  
Head Entity: gabriel garcia marquez  
Tail Entity: mexico  

Relation: person country of death  
Context: legendary musician david bowie succumbs to cancer in new york city, united states  
Head Entity: david bowie  
Tail Entity: united states  

Relation: person country of death  
Context: beloved actress audrey hepburn passes away in tarrant county, texas, after a long battle with cancer  
Head Entity: audrey hepburn  
Tail Entity: texas  

Relation: person country of death  
Context: influential civil rights leader nelson mandela dies peacefully at his home in johannesburg, south africa  
Head Entity: nelson mandela  
Tail Entity: south africa  
#### person children ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person children" means a person 's children is a person.
Here is an example:
Relation: person children
Context: he is survived by two stepdaughters , barbara a. hammond and brenda l. stevenson ; a stepson , michael a. taylor ; two grandchildren and one great-grandchild .
Head Entity: he
Tail Entity: brenda l. stevenson
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person children":
Relation: person children  
Context: she has three children, including her son, john, and her daughters, emily and sarah, who are both very talented.  
Head Entity: she  
Tail Entity: emily  

Relation: person children  
Context: after the divorce, he took custody of his two daughters, lily and rose, who are now thriving in school.  
Head Entity: he  
Tail Entity: rose  

Relation: person children  
Context: the famous author often mentioned his son, alex, in interviews, highlighting their close relationship.  
Head Entity: the famous author  
Tail Entity: alex  

Relation: person children  
Context: during the family reunion, she proudly introduced her children, including her youngest, max, who just graduated from high school.  
Head Entity: she  
Tail Entity: max  

Relation: person children  
Context: he often shares stories about his daughter, mia, who is an aspiring artist and loves to paint.  
Head Entity: he  
Tail Entity: mia  
#### person charges ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person charges" means a person was charged with an event.
Here is an example:
Relation: person charges
Context: ferrara said he was innocent of limoli 's slaying , but he pleaded guilty in 1992 to murder , along with racketeering charges , under a deal that sent him to prison for 22 years , rather than go to trial and risk a conviction that could lead to life in prison .
Head Entity: ferrara
Tail Entity: racketeering
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person charges":
Relation: person charges  
Context: After a lengthy investigation, the authorities announced that Johnson was charged with embezzlement, which shocked his colleagues at the firm.  
Head Entity: Johnson  
Tail Entity: embezzlement  

Relation: person charges  
Context: The district attorney confirmed that Smith was charged with assault following the altercation at the downtown bar last weekend.  
Head Entity: Smith  
Tail Entity: assault  

Relation: person charges  
Context: In a surprising turn of events, the police revealed that Martinez was charged with fraud after an extensive audit of his business practices.  
Head Entity: Martinez  
Tail Entity: fraud  

Relation: person charges  
Context: Following the protests, the city council announced that Thompson was charged with inciting violence during the demonstration.  
Head Entity: Thompson  
Tail Entity: inciting violence  

Relation: person charges  
Context: The court documents indicated that Lee was charged with theft after being caught on surveillance cameras stealing merchandise from the store.  
Head Entity: Lee  
Tail Entity: theft  
Mixup data size:  35770
MixupTrain:  epoch  0, batch     0 | loss: 3.6758118MixupTrain:  epoch  0, batch     1 | loss: 3.2903605MixupTrain:  epoch  0, batch     2 | loss: 3.1617715MixupTrain:  epoch  0, batch     3 | loss: 2.8411429MixupTrain:  epoch  0, batch     4 | loss: 3.8685701MixupTrain:  epoch  0, batch     5 | loss: 4.1539574MixupTrain:  epoch  0, batch     6 | loss: 3.4874647MixupTrain:  epoch  0, batch     7 | loss: 4.0149975MixupTrain:  epoch  0, batch     8 | loss: 3.3121724MixupTrain:  epoch  0, batch     9 | loss: 4.2336569MixupTrain:  epoch  0, batch    10 | loss: 3.9388764MixupTrain:  epoch  0, batch    11 | loss: 2.9575512MixupTrain:  epoch  0, batch    12 | loss: 3.0604796MixupTrain:  epoch  0, batch    13 | loss: 3.1953757MixupTrain:  epoch  0, batch    14 | loss: 3.5326724MixupTrain:  epoch  0, batch    15 | loss: 3.2603664MixupTrain:  epoch  0, batch    16 | loss: 3.0489140MixupTrain:  epoch  0, batch    17 | loss: 3.8206930MixupTrain:  epoch  0, batch    18 | loss: 4.1707830MixupTrain:  epoch  0, batch    19 | loss: 3.2283721MixupTrain:  epoch  0, batch    20 | loss: 3.8601599MixupTrain:  epoch  0, batch    21 | loss: 2.6798940MixupTrain:  epoch  0, batch    22 | loss: 3.5938983MixupTrain:  epoch  0, batch    23 | loss: 3.1915040MixupTrain:  epoch  0, batch    24 | loss: 3.3987179MixupTrain:  epoch  0, batch    25 | loss: 3.7993333MixupTrain:  epoch  0, batch    26 | loss: 2.9089148MixupTrain:  epoch  0, batch    27 | loss: 3.7134974MixupTrain:  epoch  0, batch    28 | loss: 3.2341514MixupTrain:  epoch  0, batch    29 | loss: 4.1587048MixupTrain:  epoch  0, batch    30 | loss: 3.1691635MixupTrain:  epoch  0, batch    31 | loss: 3.0448983MixupTrain:  epoch  0, batch    32 | loss: 2.9708288MixupTrain:  epoch  0, batch    33 | loss: 2.8039322MixupTrain:  epoch  0, batch    34 | loss: 3.3847125MixupTrain:  epoch  0, batch    35 | loss: 3.2197540MixupTrain:  epoch  0, batch    36 | loss: 2.6312919MixupTrain:  epoch  0, batch    37 | loss: 3.3397639MixupTrain:  epoch  0, batch    38 | loss: 2.9418941MixupTrain:  epoch  0, batch    39 | loss: 2.7670133MixupTrain:  epoch  0, batch    40 | loss: 2.7124929MixupTrain:  epoch  0, batch    41 | loss: 2.9150186MixupTrain:  epoch  0, batch    42 | loss: 2.6527863MixupTrain:  epoch  0, batch    43 | loss: 2.9740810MixupTrain:  epoch  0, batch    44 | loss: 3.3899560MixupTrain:  epoch  0, batch    45 | loss: 3.4277763MixupTrain:  epoch  0, batch    46 | loss: 3.2942638MixupTrain:  epoch  0, batch    47 | loss: 3.2584276MixupTrain:  epoch  0, batch    48 | loss: 3.2196307MixupTrain:  epoch  0, batch    49 | loss: 3.1552160MixupTrain:  epoch  0, batch    50 | loss: 2.9268136MixupTrain:  epoch  0, batch    51 | loss: 3.0813050MixupTrain:  epoch  0, batch    52 | loss: 3.2503283MixupTrain:  epoch  0, batch    53 | loss: 3.5039303MixupTrain:  epoch  0, batch    54 | loss: 3.5998278MixupTrain:  epoch  0, batch    55 | loss: 3.3062811MixupTrain:  epoch  0, batch    56 | loss: 2.5733962MixupTrain:  epoch  0, batch    57 | loss: 3.0192204MixupTrain:  epoch  0, batch    58 | loss: 2.9127104MixupTrain:  epoch  0, batch    59 | loss: 3.2424614MixupTrain:  epoch  0, batch    60 | loss: 3.2678876MixupTrain:  epoch  0, batch    61 | loss: 3.0123286MixupTrain:  epoch  0, batch    62 | loss: 3.1988420MixupTrain:  epoch  0, batch    63 | loss: 2.8811693MixupTrain:  epoch  0, batch    64 | loss: 2.8332777MixupTrain:  epoch  0, batch    65 | loss: 2.8746009MixupTrain:  epoch  0, batch    66 | loss: 2.1979332MixupTrain:  epoch  0, batch    67 | loss: 2.5955720MixupTrain:  epoch  0, batch    68 | loss: 2.2687528MixupTrain:  epoch  0, batch    69 | loss: 2.8492188MixupTrain:  epoch  0, batch    70 | loss: 2.9203427MixupTrain:  epoch  0, batch    71 | loss: 2.5045691MixupTrain:  epoch  0, batch    72 | loss: 2.8193984MixupTrain:  epoch  0, batch    73 | loss: 3.2043805MixupTrain:  epoch  0, batch    74 | loss: 2.1666465MixupTrain:  epoch  0, batch    75 | loss: 2.9381542MixupTrain:  epoch  0, batch    76 | loss: 2.9379728MixupTrain:  epoch  0, batch    77 | loss: 2.5882123MixupTrain:  epoch  0, batch    78 | loss: 2.8346486MixupTrain:  epoch  0, batch    79 | loss: 2.8368051MixupTrain:  epoch  0, batch    80 | loss: 3.0884314MixupTrain:  epoch  0, batch    81 | loss: 2.4462991MixupTrain:  epoch  0, batch    82 | loss: 3.1230235MixupTrain:  epoch  0, batch    83 | loss: 2.5037456MixupTrain:  epoch  0, batch    84 | loss: 2.9844205MixupTrain:  epoch  0, batch    85 | loss: 2.6353903MixupTrain:  epoch  0, batch    86 | loss: 3.4971597MixupTrain:  epoch  0, batch    87 | loss: 2.7649565MixupTrain:  epoch  0, batch    88 | loss: 3.0827084MixupTrain:  epoch  0, batch    89 | loss: 2.4217298MixupTrain:  epoch  0, batch    90 | loss: 2.7188137MixupTrain:  epoch  0, batch    91 | loss: 2.9566154MixupTrain:  epoch  0, batch    92 | loss: 2.5933223MixupTrain:  epoch  0, batch    93 | loss: 2.5270371MixupTrain:  epoch  0, batch    94 | loss: 2.9539309MixupTrain:  epoch  0, batch    95 | loss: 3.0941565MixupTrain:  epoch  0, batch    96 | loss: 2.9288471MixupTrain:  epoch  0, batch    97 | loss: 2.6961918MixupTrain:  epoch  0, batch    98 | loss: 2.8624458MixupTrain:  epoch  0, batch    99 | loss: 2.8124402MixupTrain:  epoch  0, batch   100 | loss: 3.1452651MixupTrain:  epoch  0, batch   101 | loss: 2.9029756MixupTrain:  epoch  0, batch   102 | loss: 2.6853251MixupTrain:  epoch  0, batch   103 | loss: 2.9456544MixupTrain:  epoch  0, batch   104 | loss: 2.6712971MixupTrain:  epoch  0, batch   105 | loss: 2.3948226MixupTrain:  epoch  0, batch   106 | loss: 2.6459932MixupTrain:  epoch  0, batch   107 | loss: 3.1980896MixupTrain:  epoch  0, batch   108 | loss: 2.6901445MixupTrain:  epoch  0, batch   109 | loss: 2.3606720MixupTrain:  epoch  0, batch   110 | loss: 2.1876786MixupTrain:  epoch  0, batch   111 | loss: 2.5068238MixupTrain:  epoch  0, batch   112 | loss: 3.7787268MixupTrain:  epoch  0, batch   113 | loss: 2.2942524MixupTrain:  epoch  0, batch   114 | loss: 2.5192204MixupTrain:  epoch  0, batch   115 | loss: 3.1209574MixupTrain:  epoch  0, batch   116 | loss: 2.9891431MixupTrain:  epoch  0, batch   117 | loss: 2.5005155MixupTrain:  epoch  0, batch   118 | loss: 2.9186687MixupTrain:  epoch  0, batch   119 | loss: 3.1318462MixupTrain:  epoch  0, batch   120 | loss: 2.6308706MixupTrain:  epoch  0, batch   121 | loss: 2.6509233MixupTrain:  epoch  0, batch   122 | loss: 2.8567071MixupTrain:  epoch  0, batch   123 | loss: 2.9268560MixupTrain:  epoch  0, batch   124 | loss: 2.2832928MixupTrain:  epoch  0, batch   125 | loss: 2.9559319MixupTrain:  epoch  0, batch   126 | loss: 2.8362012MixupTrain:  epoch  0, batch   127 | loss: 2.7470217MixupTrain:  epoch  0, batch   128 | loss: 2.2087479MixupTrain:  epoch  0, batch   129 | loss: 2.9741406MixupTrain:  epoch  0, batch   130 | loss: 2.4557118MixupTrain:  epoch  0, batch   131 | loss: 2.8922181MixupTrain:  epoch  0, batch   132 | loss: 2.9161108MixupTrain:  epoch  0, batch   133 | loss: 2.9446354MixupTrain:  epoch  0, batch   134 | loss: 2.9242516MixupTrain:  epoch  0, batch   135 | loss: 2.2369008MixupTrain:  epoch  0, batch   136 | loss: 2.6665721MixupTrain:  epoch  0, batch   137 | loss: 2.6244774MixupTrain:  epoch  0, batch   138 | loss: 2.6349068MixupTrain:  epoch  0, batch   139 | loss: 2.3456872MixupTrain:  epoch  0, batch   140 | loss: 2.4784687MixupTrain:  epoch  0, batch   141 | loss: 2.8189559MixupTrain:  epoch  0, batch   142 | loss: 2.4316278MixupTrain:  epoch  0, batch   143 | loss: 2.3769081MixupTrain:  epoch  0, batch   144 | loss: 2.7388391MixupTrain:  epoch  0, batch   145 | loss: 2.0784574MixupTrain:  epoch  0, batch   146 | loss: 2.6767702MixupTrain:  epoch  0, batch   147 | loss: 2.5880842MixupTrain:  epoch  0, batch   148 | loss: 2.6457791MixupTrain:  epoch  0, batch   149 | loss: 3.0541935MixupTrain:  epoch  0, batch   150 | loss: 2.3243427MixupTrain:  epoch  0, batch   151 | loss: 2.4255018MixupTrain:  epoch  0, batch   152 | loss: 2.7894297MixupTrain:  epoch  0, batch   153 | loss: 2.9014211MixupTrain:  epoch  0, batch   154 | loss: 2.8577671MixupTrain:  epoch  0, batch   155 | loss: 2.6584573MixupTrain:  epoch  0, batch   156 | loss: 2.3183982MixupTrain:  epoch  0, batch   157 | loss: 2.4703188MixupTrain:  epoch  0, batch   158 | loss: 2.9419837MixupTrain:  epoch  0, batch   159 | loss: 2.7383924MixupTrain:  epoch  0, batch   160 | loss: 2.5397105MixupTrain:  epoch  0, batch   161 | loss: 2.6130280MixupTrain:  epoch  0, batch   162 | loss: 3.3340039MixupTrain:  epoch  0, batch   163 | loss: 2.8553324MixupTrain:  epoch  0, batch   164 | loss: 2.5020022MixupTrain:  epoch  0, batch   165 | loss: 2.5065536MixupTrain:  epoch  0, batch   166 | loss: 3.1457930MixupTrain:  epoch  0, batch   167 | loss: 2.7548375MixupTrain:  epoch  0, batch   168 | loss: 2.4696031MixupTrain:  epoch  0, batch   169 | loss: 2.4201927MixupTrain:  epoch  0, batch   170 | loss: 2.4927073MixupTrain:  epoch  0, batch   171 | loss: 2.9515867MixupTrain:  epoch  0, batch   172 | loss: 2.3682902MixupTrain:  epoch  0, batch   173 | loss: 2.3599052MixupTrain:  epoch  0, batch   174 | loss: 2.3756866MixupTrain:  epoch  0, batch   175 | loss: 2.5620527MixupTrain:  epoch  0, batch   176 | loss: 2.9546819MixupTrain:  epoch  0, batch   177 | loss: 2.4784050MixupTrain:  epoch  0, batch   178 | loss: 2.5095463MixupTrain:  epoch  0, batch   179 | loss: 2.3403907MixupTrain:  epoch  0, batch   180 | loss: 2.3354325MixupTrain:  epoch  0, batch   181 | loss: 2.4335918MixupTrain:  epoch  0, batch   182 | loss: 2.0368681MixupTrain:  epoch  0, batch   183 | loss: 2.4995575MixupTrain:  epoch  0, batch   184 | loss: 2.4496217MixupTrain:  epoch  0, batch   185 | loss: 2.4623506MixupTrain:  epoch  0, batch   186 | loss: 2.3199239MixupTrain:  epoch  0, batch   187 | loss: 2.5158720MixupTrain:  epoch  0, batch   188 | loss: 3.0828881MixupTrain:  epoch  0, batch   189 | loss: 2.3878713MixupTrain:  epoch  0, batch   190 | loss: 2.5321426MixupTrain:  epoch  0, batch   191 | loss: 2.2171934MixupTrain:  epoch  0, batch   192 | loss: 2.5260010MixupTrain:  epoch  0, batch   193 | loss: 2.5558653MixupTrain:  epoch  0, batch   194 | loss: 2.1833727MixupTrain:  epoch  0, batch   195 | loss: 2.4939775MixupTrain:  epoch  0, batch   196 | loss: 2.2130294MixupTrain:  epoch  0, batch   197 | loss: 2.7247372MixupTrain:  epoch  0, batch   198 | loss: 2.7958472MixupTrain:  epoch  0, batch   199 | loss: 2.8775039MixupTrain:  epoch  0, batch   200 | loss: 3.0541592MixupTrain:  epoch  0, batch   201 | loss: 2.5096447MixupTrain:  epoch  0, batch   202 | loss: 2.6047971MixupTrain:  epoch  0, batch   203 | loss: 3.0371490MixupTrain:  epoch  0, batch   204 | loss: 2.2880402MixupTrain:  epoch  0, batch   205 | loss: 2.2284300MixupTrain:  epoch  0, batch   206 | loss: 2.3453074MixupTrain:  epoch  0, batch   207 | loss: 2.5982084MixupTrain:  epoch  0, batch   208 | loss: 2.2804089MixupTrain:  epoch  0, batch   209 | loss: 2.5282440MixupTrain:  epoch  0, batch   210 | loss: 2.2584472MixupTrain:  epoch  0, batch   211 | loss: 2.3946495MixupTrain:  epoch  0, batch   212 | loss: 2.5069976MixupTrain:  epoch  0, batch   213 | loss: 2.5444613MixupTrain:  epoch  0, batch   214 | loss: 2.7668853MixupTrain:  epoch  0, batch   215 | loss: 2.6239023MixupTrain:  epoch  0, batch   216 | loss: 2.5370808MixupTrain:  epoch  0, batch   217 | loss: 2.5750532MixupTrain:  epoch  0, batch   218 | loss: 2.4042175MixupTrain:  epoch  0, batch   219 | loss: 2.4517395MixupTrain:  epoch  0, batch   220 | loss: 2.3844831MixupTrain:  epoch  0, batch   221 | loss: 2.1386590MixupTrain:  epoch  0, batch   222 | loss: 2.5653448MixupTrain:  epoch  0, batch   223 | loss: 2.6844020MixupTrain:  epoch  0, batch   224 | loss: 2.2380521MixupTrain:  epoch  0, batch   225 | loss: 2.5631971MixupTrain:  epoch  0, batch   226 | loss: 2.3225908MixupTrain:  epoch  0, batch   227 | loss: 2.3184257MixupTrain:  epoch  0, batch   228 | loss: 2.8978331MixupTrain:  epoch  0, batch   229 | loss: 2.4933317MixupTrain:  epoch  0, batch   230 | loss: 2.0514710MixupTrain:  epoch  0, batch   231 | loss: 2.4360986MixupTrain:  epoch  0, batch   232 | loss: 2.2377419MixupTrain:  epoch  0, batch   233 | loss: 2.3693111MixupTrain:  epoch  0, batch   234 | loss: 2.3861623MixupTrain:  epoch  0, batch   235 | loss: 2.5282638MixupTrain:  epoch  0, batch   236 | loss: 2.7777991MixupTrain:  epoch  0, batch   237 | loss: 2.5304604MixupTrain:  epoch  0, batch   238 | loss: 2.3716331MixupTrain:  epoch  0, batch   239 | loss: 1.9896072MixupTrain:  epoch  0, batch   240 | loss: 2.4457138MixupTrain:  epoch  0, batch   241 | loss: 2.3204958MixupTrain:  epoch  0, batch   242 | loss: 2.6115632MixupTrain:  epoch  0, batch   243 | loss: 2.3125763MixupTrain:  epoch  0, batch   244 | loss: 2.3914154MixupTrain:  epoch  0, batch   245 | loss: 2.1127470MixupTrain:  epoch  0, batch   246 | loss: 2.3391657MixupTrain:  epoch  0, batch   247 | loss: 2.4739351MixupTrain:  epoch  0, batch   248 | loss: 2.7583294MixupTrain:  epoch  0, batch   249 | loss: 2.7435813MixupTrain:  epoch  0, batch   250 | loss: 2.2149818MixupTrain:  epoch  0, batch   251 | loss: 2.2826459MixupTrain:  epoch  0, batch   252 | loss: 2.1317494MixupTrain:  epoch  0, batch   253 | loss: 2.2313609MixupTrain:  epoch  0, batch   254 | loss: 2.6041734MixupTrain:  epoch  0, batch   255 | loss: 2.2636194MixupTrain:  epoch  0, batch   256 | loss: 2.5410504MixupTrain:  epoch  0, batch   257 | loss: 2.1678410MixupTrain:  epoch  0, batch   258 | loss: 2.3162742MixupTrain:  epoch  0, batch   259 | loss: 2.3916965MixupTrain:  epoch  0, batch   260 | loss: 2.3391120MixupTrain:  epoch  0, batch   261 | loss: 2.7212582MixupTrain:  epoch  0, batch   262 | loss: 2.6755853MixupTrain:  epoch  0, batch   263 | loss: 2.2975726MixupTrain:  epoch  0, batch   264 | loss: 2.4126782MixupTrain:  epoch  0, batch   265 | loss: 2.4550917MixupTrain:  epoch  0, batch   266 | loss: 2.3792002MixupTrain:  epoch  0, batch   267 | loss: 2.1994107MixupTrain:  epoch  0, batch   268 | loss: 2.3965445MixupTrain:  epoch  0, batch   269 | loss: 2.3017559MixupTrain:  epoch  0, batch   270 | loss: 2.2984877MixupTrain:  epoch  0, batch   271 | loss: 2.4421539MixupTrain:  epoch  0, batch   272 | loss: 2.1651657MixupTrain:  epoch  0, batch   273 | loss: 2.2979178MixupTrain:  epoch  0, batch   274 | loss: 2.0604091MixupTrain:  epoch  0, batch   275 | loss: 2.3684916MixupTrain:  epoch  0, batch   276 | loss: 2.1804650MixupTrain:  epoch  0, batch   277 | loss: 2.3944907MixupTrain:  epoch  0, batch   278 | loss: 2.4471829MixupTrain:  epoch  0, batch   279 | loss: 2.4572191MixupTrain:  epoch  0, batch   280 | loss: 2.6207862MixupTrain:  epoch  0, batch   281 | loss: 2.2991199MixupTrain:  epoch  0, batch   282 | loss: 2.8415191MixupTrain:  epoch  0, batch   283 | loss: 2.5987687MixupTrain:  epoch  0, batch   284 | loss: 2.4343355MixupTrain:  epoch  0, batch   285 | loss: 2.2501020MixupTrain:  epoch  0, batch   286 | loss: 2.0190413MixupTrain:  epoch  0, batch   287 | loss: 2.5841622MixupTrain:  epoch  0, batch   288 | loss: 2.4167066MixupTrain:  epoch  0, batch   289 | loss: 2.6161354MixupTrain:  epoch  0, batch   290 | loss: 2.5870736MixupTrain:  epoch  0, batch   291 | loss: 2.4647002MixupTrain:  epoch  0, batch   292 | loss: 2.5145297MixupTrain:  epoch  0, batch   293 | loss: 2.5168300MixupTrain:  epoch  0, batch   294 | loss: 2.3229027MixupTrain:  epoch  0, batch   295 | loss: 2.6254392MixupTrain:  epoch  0, batch   296 | loss: 2.4871204MixupTrain:  epoch  0, batch   297 | loss: 2.5412045MixupTrain:  epoch  0, batch   298 | loss: 2.7823696MixupTrain:  epoch  0, batch   299 | loss: 2.2816675MixupTrain:  epoch  0, batch   300 | loss: 2.4460330MixupTrain:  epoch  0, batch   301 | loss: 2.3542666MixupTrain:  epoch  0, batch   302 | loss: 2.2732143MixupTrain:  epoch  0, batch   303 | loss: 2.2946661MixupTrain:  epoch  0, batch   304 | loss: 2.9313960MixupTrain:  epoch  0, batch   305 | loss: 2.2760794MixupTrain:  epoch  0, batch   306 | loss: 2.2215567MixupTrain:  epoch  0, batch   307 | loss: 2.5189590MixupTrain:  epoch  0, batch   308 | loss: 1.9177039MixupTrain:  epoch  0, batch   309 | loss: 2.4972370MixupTrain:  epoch  0, batch   310 | loss: 2.2183104MixupTrain:  epoch  0, batch   311 | loss: 2.2778416MixupTrain:  epoch  0, batch   312 | loss: 2.5495899MixupTrain:  epoch  0, batch   313 | loss: 2.5683398MixupTrain:  epoch  0, batch   314 | loss: 2.3768520MixupTrain:  epoch  0, batch   315 | loss: 2.6670969MixupTrain:  epoch  0, batch   316 | loss: 2.6111169MixupTrain:  epoch  0, batch   317 | loss: 2.1766491MixupTrain:  epoch  0, batch   318 | loss: 2.5413299MixupTrain:  epoch  0, batch   319 | loss: 2.4687135MixupTrain:  epoch  0, batch   320 | loss: 2.4323108MixupTrain:  epoch  0, batch   321 | loss: 2.7781448MixupTrain:  epoch  0, batch   322 | loss: 2.4339430MixupTrain:  epoch  0, batch   323 | loss: 2.4077330MixupTrain:  epoch  0, batch   324 | loss: 2.2849784MixupTrain:  epoch  0, batch   325 | loss: 2.2033997MixupTrain:  epoch  0, batch   326 | loss: 2.5345278MixupTrain:  epoch  0, batch   327 | loss: 2.2323017MixupTrain:  epoch  0, batch   328 | loss: 2.1412897MixupTrain:  epoch  0, batch   329 | loss: 2.4299037MixupTrain:  epoch  0, batch   330 | loss: 2.3622570MixupTrain:  epoch  0, batch   331 | loss: 2.2750225MixupTrain:  epoch  0, batch   332 | loss: 2.3482277MixupTrain:  epoch  0, batch   333 | loss: 2.2239988MixupTrain:  epoch  0, batch   334 | loss: 2.4592996MixupTrain:  epoch  0, batch   335 | loss: 2.5402615MixupTrain:  epoch  0, batch   336 | loss: 2.4812796MixupTrain:  epoch  0, batch   337 | loss: 2.2083859MixupTrain:  epoch  0, batch   338 | loss: 2.3628492MixupTrain:  epoch  0, batch   339 | loss: 2.3719182MixupTrain:  epoch  0, batch   340 | loss: 2.1063476MixupTrain:  epoch  0, batch   341 | loss: 2.4563890MixupTrain:  epoch  0, batch   342 | loss: 2.4196107MixupTrain:  epoch  0, batch   343 | loss: 2.1322396MixupTrain:  epoch  0, batch   344 | loss: 2.8119600MixupTrain:  epoch  0, batch   345 | loss: 2.2327747MixupTrain:  epoch  0, batch   346 | loss: 2.2723336MixupTrain:  epoch  0, batch   347 | loss: 2.5364690MixupTrain:  epoch  0, batch   348 | loss: 2.3530848MixupTrain:  epoch  0, batch   349 | loss: 2.4599864MixupTrain:  epoch  0, batch   350 | loss: 2.1451917MixupTrain:  epoch  0, batch   351 | loss: 2.1383753MixupTrain:  epoch  0, batch   352 | loss: 2.3953938MixupTrain:  epoch  0, batch   353 | loss: 2.4483342MixupTrain:  epoch  0, batch   354 | loss: 2.5125151MixupTrain:  epoch  0, batch   355 | loss: 2.2900336MixupTrain:  epoch  0, batch   356 | loss: 2.7763658MixupTrain:  epoch  0, batch   357 | loss: 2.2847486MixupTrain:  epoch  0, batch   358 | loss: 2.3359871MixupTrain:  epoch  0, batch   359 | loss: 2.1715100MixupTrain:  epoch  0, batch   360 | loss: 2.5902262MixupTrain:  epoch  0, batch   361 | loss: 2.4751444MixupTrain:  epoch  0, batch   362 | loss: 2.2388124MixupTrain:  epoch  0, batch   363 | loss: 2.5787382MixupTrain:  epoch  0, batch   364 | loss: 2.5274801MixupTrain:  epoch  0, batch   365 | loss: 2.1273255MixupTrain:  epoch  0, batch   366 | loss: 2.5371885MixupTrain:  epoch  0, batch   367 | loss: 2.3975973MixupTrain:  epoch  0, batch   368 | loss: 2.3311906MixupTrain:  epoch  0, batch   369 | loss: 2.3679128MixupTrain:  epoch  0, batch   370 | loss: 2.2570553MixupTrain:  epoch  0, batch   371 | loss: 2.3146701MixupTrain:  epoch  0, batch   372 | loss: 2.2450190MixupTrain:  epoch  0, batch   373 | loss: 2.2656913MixupTrain:  epoch  0, batch   374 | loss: 2.5305593MixupTrain:  epoch  0, batch   375 | loss: 2.4201941MixupTrain:  epoch  0, batch   376 | loss: 2.2351499MixupTrain:  epoch  0, batch   377 | loss: 2.2285888MixupTrain:  epoch  0, batch   378 | loss: 2.2534337MixupTrain:  epoch  0, batch   379 | loss: 2.3657274MixupTrain:  epoch  0, batch   380 | loss: 2.9118757MixupTrain:  epoch  0, batch   381 | loss: 2.3515260MixupTrain:  epoch  0, batch   382 | loss: 2.2233696MixupTrain:  epoch  0, batch   383 | loss: 2.6092451MixupTrain:  epoch  0, batch   384 | loss: 2.2746868MixupTrain:  epoch  0, batch   385 | loss: 2.5130582MixupTrain:  epoch  0, batch   386 | loss: 2.3396602MixupTrain:  epoch  0, batch   387 | loss: 2.6222236MixupTrain:  epoch  0, batch   388 | loss: 2.3025513MixupTrain:  epoch  0, batch   389 | loss: 1.8557997MixupTrain:  epoch  0, batch   390 | loss: 2.3868222MixupTrain:  epoch  0, batch   391 | loss: 2.3461320MixupTrain:  epoch  0, batch   392 | loss: 2.4684951MixupTrain:  epoch  0, batch   393 | loss: 2.2663784MixupTrain:  epoch  0, batch   394 | loss: 2.9628036MixupTrain:  epoch  0, batch   395 | loss: 2.6130221MixupTrain:  epoch  0, batch   396 | loss: 1.8872998MixupTrain:  epoch  0, batch   397 | loss: 2.3673332MixupTrain:  epoch  0, batch   398 | loss: 2.4233069MixupTrain:  epoch  0, batch   399 | loss: 2.4601433MixupTrain:  epoch  0, batch   400 | loss: 2.5744700MixupTrain:  epoch  0, batch   401 | loss: 2.3399482MixupTrain:  epoch  0, batch   402 | loss: 2.4400787MixupTrain:  epoch  0, batch   403 | loss: 2.3809981MixupTrain:  epoch  0, batch   404 | loss: 2.2442017MixupTrain:  epoch  0, batch   405 | loss: 2.2984266MixupTrain:  epoch  0, batch   406 | loss: 2.2317533MixupTrain:  epoch  0, batch   407 | loss: 2.0398831MixupTrain:  epoch  0, batch   408 | loss: 2.5382750MixupTrain:  epoch  0, batch   409 | loss: 2.2308607MixupTrain:  epoch  0, batch   410 | loss: 2.3646779MixupTrain:  epoch  0, batch   411 | loss: 2.2217476MixupTrain:  epoch  0, batch   412 | loss: 2.2746267MixupTrain:  epoch  0, batch   413 | loss: 2.3243184MixupTrain:  epoch  0, batch   414 | loss: 2.2089708MixupTrain:  epoch  0, batch   415 | loss: 2.1941686MixupTrain:  epoch  0, batch   416 | loss: 2.3260472MixupTrain:  epoch  0, batch   417 | loss: 2.4663794MixupTrain:  epoch  0, batch   418 | loss: 2.3796406MixupTrain:  epoch  0, batch   419 | loss: 2.3906977MixupTrain:  epoch  0, batch   420 | loss: 2.1697927MixupTrain:  epoch  0, batch   421 | loss: 2.5084109MixupTrain:  epoch  0, batch   422 | loss: 2.2024050MixupTrain:  epoch  0, batch   423 | loss: 2.3486450MixupTrain:  epoch  0, batch   424 | loss: 2.4155777MixupTrain:  epoch  0, batch   425 | loss: 2.3542538MixupTrain:  epoch  0, batch   426 | loss: 2.4136100MixupTrain:  epoch  0, batch   427 | loss: 2.2411535MixupTrain:  epoch  0, batch   428 | loss: 2.3941348MixupTrain:  epoch  0, batch   429 | loss: 2.2301157MixupTrain:  epoch  0, batch   430 | loss: 2.4995053MixupTrain:  epoch  0, batch   431 | loss: 2.0399365MixupTrain:  epoch  0, batch   432 | loss: 2.1287558MixupTrain:  epoch  0, batch   433 | loss: 2.1330161MixupTrain:  epoch  0, batch   434 | loss: 2.5177679MixupTrain:  epoch  0, batch   435 | loss: 2.3266542MixupTrain:  epoch  0, batch   436 | loss: 2.1727118MixupTrain:  epoch  0, batch   437 | loss: 2.1356030MixupTrain:  epoch  0, batch   438 | loss: 2.6273785MixupTrain:  epoch  0, batch   439 | loss: 2.1663806MixupTrain:  epoch  0, batch   440 | loss: 2.4273295MixupTrain:  epoch  0, batch   441 | loss: 2.1516283MixupTrain:  epoch  0, batch   442 | loss: 2.3144445MixupTrain:  epoch  0, batch   443 | loss: 2.3893337MixupTrain:  epoch  0, batch   444 | loss: 2.2370629MixupTrain:  epoch  0, batch   445 | loss: 2.4585068MixupTrain:  epoch  0, batch   446 | loss: 2.6745980MixupTrain:  epoch  0, batch   447 | loss: 2.3688359MixupTrain:  epoch  0, batch   448 | loss: 2.0374107MixupTrain:  epoch  0, batch   449 | loss: 2.3331165MixupTrain:  epoch  0, batch   450 | loss: 2.4357059MixupTrain:  epoch  0, batch   451 | loss: 2.2404826MixupTrain:  epoch  0, batch   452 | loss: 2.4148669MixupTrain:  epoch  0, batch   453 | loss: 2.2775474MixupTrain:  epoch  0, batch   454 | loss: 2.3423591MixupTrain:  epoch  0, batch   455 | loss: 2.1287255MixupTrain:  epoch  0, batch   456 | loss: 2.3014028MixupTrain:  epoch  0, batch   457 | loss: 2.1366072MixupTrain:  epoch  0, batch   458 | loss: 2.3713598MixupTrain:  epoch  0, batch   459 | loss: 2.5613184MixupTrain:  epoch  0, batch   460 | loss: 2.3168201MixupTrain:  epoch  0, batch   461 | loss: 2.5562136MixupTrain:  epoch  0, batch   462 | loss: 2.4941778MixupTrain:  epoch  0, batch   463 | loss: 2.5098326MixupTrain:  epoch  0, batch   464 | loss: 2.7230039MixupTrain:  epoch  0, batch   465 | loss: 2.1246033MixupTrain:  epoch  0, batch   466 | loss: 2.3525662MixupTrain:  epoch  0, batch   467 | loss: 2.2939696MixupTrain:  epoch  0, batch   468 | loss: 2.3623319MixupTrain:  epoch  0, batch   469 | loss: 2.3485894MixupTrain:  epoch  0, batch   470 | loss: 2.3460321MixupTrain:  epoch  0, batch   471 | loss: 2.5904260MixupTrain:  epoch  0, batch   472 | loss: 2.2499719MixupTrain:  epoch  0, batch   473 | loss: 2.3408351MixupTrain:  epoch  0, batch   474 | loss: 2.1537600MixupTrain:  epoch  0, batch   475 | loss: 2.4820108MixupTrain:  epoch  0, batch   476 | loss: 2.3163984MixupTrain:  epoch  0, batch   477 | loss: 2.5270584MixupTrain:  epoch  0, batch   478 | loss: 2.5118999MixupTrain:  epoch  0, batch   479 | loss: 2.1172929MixupTrain:  epoch  0, batch   480 | loss: 2.4123638MixupTrain:  epoch  0, batch   481 | loss: 2.4174659MixupTrain:  epoch  0, batch   482 | loss: 2.1143451MixupTrain:  epoch  0, batch   483 | loss: 2.1796474MixupTrain:  epoch  0, batch   484 | loss: 2.4600830MixupTrain:  epoch  0, batch   485 | loss: 2.3137007MixupTrain:  epoch  0, batch   486 | loss: 1.9863821MixupTrain:  epoch  0, batch   487 | loss: 2.4214754MixupTrain:  epoch  0, batch   488 | loss: 2.5108118MixupTrain:  epoch  0, batch   489 | loss: 2.1896329MixupTrain:  epoch  0, batch   490 | loss: 2.0526879MixupTrain:  epoch  0, batch   491 | loss: 2.6303535MixupTrain:  epoch  0, batch   492 | loss: 2.5913093MixupTrain:  epoch  0, batch   493 | loss: 2.4308400MixupTrain:  epoch  0, batch   494 | loss: 2.4258425MixupTrain:  epoch  0, batch   495 | loss: 2.3500710MixupTrain:  epoch  0, batch   496 | loss: 2.3873556MixupTrain:  epoch  0, batch   497 | loss: 2.3017406MixupTrain:  epoch  0, batch   498 | loss: 2.6716890MixupTrain:  epoch  0, batch   499 | loss: 2.1941381MixupTrain:  epoch  0, batch   500 | loss: 2.3978271MixupTrain:  epoch  0, batch   501 | loss: 2.2329340MixupTrain:  epoch  0, batch   502 | loss: 2.2712324MixupTrain:  epoch  0, batch   503 | loss: 2.3182025MixupTrain:  epoch  0, batch   504 | loss: 2.3103080MixupTrain:  epoch  0, batch   505 | loss: 2.1205778MixupTrain:  epoch  0, batch   506 | loss: 2.4129920MixupTrain:  epoch  0, batch   507 | loss: 2.4222033MixupTrain:  epoch  0, batch   508 | loss: 2.1777835MixupTrain:  epoch  0, batch   509 | loss: 2.4626517MixupTrain:  epoch  0, batch   510 | loss: 2.3176384MixupTrain:  epoch  0, batch   511 | loss: 2.1285303MixupTrain:  epoch  0, batch   512 | loss: 2.4743600MixupTrain:  epoch  0, batch   513 | loss: 2.2265911MixupTrain:  epoch  0, batch   514 | loss: 2.3818445MixupTrain:  epoch  0, batch   515 | loss: 2.1962171MixupTrain:  epoch  0, batch   516 | loss: 2.3744359MixupTrain:  epoch  0, batch   517 | loss: 2.5448418MixupTrain:  epoch  0, batch   518 | loss: 2.1814489MixupTrain:  epoch  0, batch   519 | loss: 2.2458556MixupTrain:  epoch  0, batch   520 | loss: 2.3686421MixupTrain:  epoch  0, batch   521 | loss: 2.2361822MixupTrain:  epoch  0, batch   522 | loss: 2.5658388MixupTrain:  epoch  0, batch   523 | loss: 2.5733256MixupTrain:  epoch  0, batch   524 | loss: 2.5171685MixupTrain:  epoch  0, batch   525 | loss: 2.4073749MixupTrain:  epoch  0, batch   526 | loss: 2.3481269MixupTrain:  epoch  0, batch   527 | loss: 2.5371575MixupTrain:  epoch  0, batch   528 | loss: 2.2084873MixupTrain:  epoch  0, batch   529 | loss: 2.1652744MixupTrain:  epoch  0, batch   530 | loss: 2.3770938MixupTrain:  epoch  0, batch   531 | loss: 2.0841773MixupTrain:  epoch  0, batch   532 | loss: 2.3500447MixupTrain:  epoch  0, batch   533 | loss: 2.3260450MixupTrain:  epoch  0, batch   534 | loss: 2.1234016MixupTrain:  epoch  0, batch   535 | loss: 1.9779516MixupTrain:  epoch  0, batch   536 | loss: 2.3125606MixupTrain:  epoch  0, batch   537 | loss: 2.2332296MixupTrain:  epoch  0, batch   538 | loss: 2.3355865MixupTrain:  epoch  0, batch   539 | loss: 2.0465360MixupTrain:  epoch  0, batch   540 | loss: 2.4468064MixupTrain:  epoch  0, batch   541 | loss: 2.1984744MixupTrain:  epoch  0, batch   542 | loss: 2.2687964MixupTrain:  epoch  0, batch   543 | loss: 2.6112933MixupTrain:  epoch  0, batch   544 | loss: 2.1530342MixupTrain:  epoch  0, batch   545 | loss: 2.4620097MixupTrain:  epoch  0, batch   546 | loss: 2.0436161MixupTrain:  epoch  0, batch   547 | loss: 2.1641819MixupTrain:  epoch  0, batch   548 | loss: 2.3608742MixupTrain:  epoch  0, batch   549 | loss: 2.5732002MixupTrain:  epoch  0, batch   550 | loss: 2.4874887MixupTrain:  epoch  0, batch   551 | loss: 2.1532173MixupTrain:  epoch  0, batch   552 | loss: 2.2487106MixupTrain:  epoch  0, batch   553 | loss: 2.3294196MixupTrain:  epoch  0, batch   554 | loss: 2.3709226MixupTrain:  epoch  0, batch   555 | loss: 1.9587985MixupTrain:  epoch  0, batch   556 | loss: 2.4852571MixupTrain:  epoch  0, batch   557 | loss: 2.4082913MixupTrain:  epoch  0, batch   558 | loss: 2.6696692MixupTrain:  epoch  0, batch   559 | loss: 2.1050375MixupTrain:  epoch  0, batch   560 | loss: 2.4825320MixupTrain:  epoch  0, batch   561 | loss: 2.2120779MixupTrain:  epoch  0, batch   562 | loss: 2.3217790MixupTrain:  epoch  0, batch   563 | loss: 2.2291460MixupTrain:  epoch  0, batch   564 | loss: 2.3435063MixupTrain:  epoch  0, batch   565 | loss: 2.2125049MixupTrain:  epoch  0, batch   566 | loss: 2.4085088MixupTrain:  epoch  0, batch   567 | loss: 2.4214842MixupTrain:  epoch  0, batch   568 | loss: 2.2769694MixupTrain:  epoch  0, batch   569 | loss: 2.1628084MixupTrain:  epoch  0, batch   570 | loss: 2.3000822MixupTrain:  epoch  0, batch   571 | loss: 2.2134209MixupTrain:  epoch  0, batch   572 | loss: 2.2820227MixupTrain:  epoch  0, batch   573 | loss: 2.2962217MixupTrain:  epoch  0, batch   574 | loss: 2.1878128MixupTrain:  epoch  0, batch   575 | loss: 2.2908936MixupTrain:  epoch  0, batch   576 | loss: 2.2050819MixupTrain:  epoch  0, batch   577 | loss: 2.2279143MixupTrain:  epoch  0, batch   578 | loss: 2.5010278MixupTrain:  epoch  0, batch   579 | loss: 2.0886812MixupTrain:  epoch  0, batch   580 | loss: 2.4204056MixupTrain:  epoch  0, batch   581 | loss: 2.2685184MixupTrain:  epoch  0, batch   582 | loss: 2.4167619MixupTrain:  epoch  0, batch   583 | loss: 2.3858125MixupTrain:  epoch  0, batch   584 | loss: 2.0871885MixupTrain:  epoch  0, batch   585 | loss: 2.5476041MixupTrain:  epoch  0, batch   586 | loss: 2.1699302MixupTrain:  epoch  0, batch   587 | loss: 2.3382106MixupTrain:  epoch  0, batch   588 | loss: 2.1762943MixupTrain:  epoch  0, batch   589 | loss: 2.4779925MixupTrain:  epoch  0, batch   590 | loss: 2.3426771MixupTrain:  epoch  0, batch   591 | loss: 2.2717450MixupTrain:  epoch  0, batch   592 | loss: 2.0339248MixupTrain:  epoch  0, batch   593 | loss: 2.1168950MixupTrain:  epoch  0, batch   594 | loss: 2.5863616MixupTrain:  epoch  0, batch   595 | loss: 2.2385054MixupTrain:  epoch  0, batch   596 | loss: 2.4130535MixupTrain:  epoch  0, batch   597 | loss: 2.0520267MixupTrain:  epoch  0, batch   598 | loss: 2.4996338MixupTrain:  epoch  0, batch   599 | loss: 2.1162980MixupTrain:  epoch  0, batch   600 | loss: 2.2211757MixupTrain:  epoch  0, batch   601 | loss: 2.0707984MixupTrain:  epoch  0, batch   602 | loss: 2.1963317MixupTrain:  epoch  0, batch   603 | loss: 2.1136613MixupTrain:  epoch  0, batch   604 | loss: 2.2410102MixupTrain:  epoch  0, batch   605 | loss: 2.1211438MixupTrain:  epoch  0, batch   606 | loss: 2.6713603MixupTrain:  epoch  0, batch   607 | loss: 2.0064886MixupTrain:  epoch  0, batch   608 | loss: 2.4193978MixupTrain:  epoch  0, batch   609 | loss: 2.0303872MixupTrain:  epoch  0, batch   610 | loss: 2.3151782MixupTrain:  epoch  0, batch   611 | loss: 2.2579429MixupTrain:  epoch  0, batch   612 | loss: 2.1932917MixupTrain:  epoch  0, batch   613 | loss: 2.2192061MixupTrain:  epoch  0, batch   614 | loss: 2.2004137MixupTrain:  epoch  0, batch   615 | loss: 2.2172668MixupTrain:  epoch  0, batch   616 | loss: 2.4903398MixupTrain:  epoch  0, batch   617 | loss: 2.4539347MixupTrain:  epoch  0, batch   618 | loss: 2.3120906MixupTrain:  epoch  0, batch   619 | loss: 2.5393953MixupTrain:  epoch  0, batch   620 | loss: 2.3778634MixupTrain:  epoch  0, batch   621 | loss: 2.4090896MixupTrain:  epoch  0, batch   622 | loss: 2.4157176MixupTrain:  epoch  0, batch   623 | loss: 2.1514187MixupTrain:  epoch  0, batch   624 | loss: 2.5753210MixupTrain:  epoch  0, batch   625 | loss: 2.1946771MixupTrain:  epoch  0, batch   626 | loss: 2.3016815MixupTrain:  epoch  0, batch   627 | loss: 2.5890114MixupTrain:  epoch  0, batch   628 | loss: 2.4752707MixupTrain:  epoch  0, batch   629 | loss: 1.9555471MixupTrain:  epoch  0, batch   630 | loss: 2.0088687MixupTrain:  epoch  0, batch   631 | loss: 2.2707300MixupTrain:  epoch  0, batch   632 | loss: 2.3525279MixupTrain:  epoch  0, batch   633 | loss: 2.1953821MixupTrain:  epoch  0, batch   634 | loss: 2.2553954MixupTrain:  epoch  0, batch   635 | loss: 2.4761925MixupTrain:  epoch  0, batch   636 | loss: 2.5016387MixupTrain:  epoch  0, batch   637 | loss: 2.4748750MixupTrain:  epoch  0, batch   638 | loss: 2.2238758MixupTrain:  epoch  0, batch   639 | loss: 2.3318400MixupTrain:  epoch  0, batch   640 | loss: 2.1348510MixupTrain:  epoch  0, batch   641 | loss: 2.1913514MixupTrain:  epoch  0, batch   642 | loss: 2.1874113MixupTrain:  epoch  0, batch   643 | loss: 2.3214722MixupTrain:  epoch  0, batch   644 | loss: 2.4438210MixupTrain:  epoch  0, batch   645 | loss: 2.3302155MixupTrain:  epoch  0, batch   646 | loss: 2.4460187MixupTrain:  epoch  0, batch   647 | loss: 2.2494519MixupTrain:  epoch  0, batch   648 | loss: 2.2528405MixupTrain:  epoch  0, batch   649 | loss: 2.1382060MixupTrain:  epoch  0, batch   650 | loss: 2.1604900MixupTrain:  epoch  0, batch   651 | loss: 2.2909980MixupTrain:  epoch  0, batch   652 | loss: 2.6162977MixupTrain:  epoch  0, batch   653 | loss: 2.3305075MixupTrain:  epoch  0, batch   654 | loss: 2.3819122MixupTrain:  epoch  0, batch   655 | loss: 2.3509741MixupTrain:  epoch  0, batch   656 | loss: 2.1740069MixupTrain:  epoch  0, batch   657 | loss: 2.2095623MixupTrain:  epoch  0, batch   658 | loss: 2.2311182MixupTrain:  epoch  0, batch   659 | loss: 2.4733381MixupTrain:  epoch  0, batch   660 | loss: 2.4011126MixupTrain:  epoch  0, batch   661 | loss: 2.0012126MixupTrain:  epoch  0, batch   662 | loss: 2.3059075MixupTrain:  epoch  0, batch   663 | loss: 2.2906344MixupTrain:  epoch  0, batch   664 | loss: 2.3508258MixupTrain:  epoch  0, batch   665 | loss: 2.2915885MixupTrain:  epoch  0, batch   666 | loss: 2.4375303MixupTrain:  epoch  0, batch   667 | loss: 2.3566980MixupTrain:  epoch  0, batch   668 | loss: 2.5280483MixupTrain:  epoch  0, batch   669 | loss: 2.3439474MixupTrain:  epoch  0, batch   670 | loss: 2.0558877MixupTrain:  epoch  0, batch   671 | loss: 2.5438461MixupTrain:  epoch  0, batch   672 | loss: 2.4861641MixupTrain:  epoch  0, batch   673 | loss: 2.3223391MixupTrain:  epoch  0, batch   674 | loss: 2.1534171MixupTrain:  epoch  0, batch   675 | loss: 2.2534280MixupTrain:  epoch  0, batch   676 | loss: 2.2142272MixupTrain:  epoch  0, batch   677 | loss: 2.3738289MixupTrain:  epoch  0, batch   678 | loss: 2.2104146MixupTrain:  epoch  0, batch   679 | loss: 2.2734165MixupTrain:  epoch  0, batch   680 | loss: 2.2997103MixupTrain:  epoch  0, batch   681 | loss: 2.2612901MixupTrain:  epoch  0, batch   682 | loss: 2.1158872MixupTrain:  epoch  0, batch   683 | loss: 2.1823306MixupTrain:  epoch  0, batch   684 | loss: 2.3548298MixupTrain:  epoch  0, batch   685 | loss: 2.1606741MixupTrain:  epoch  0, batch   686 | loss: 2.3707304MixupTrain:  epoch  0, batch   687 | loss: 2.2953897MixupTrain:  epoch  0, batch   688 | loss: 2.1012874MixupTrain:  epoch  0, batch   689 | loss: 2.3062077MixupTrain:  epoch  0, batch   690 | loss: 2.3391614MixupTrain:  epoch  0, batch   691 | loss: 2.1380684MixupTrain:  epoch  0, batch   692 | loss: 2.3362160MixupTrain:  epoch  0, batch   693 | loss: 2.2022781MixupTrain:  epoch  0, batch   694 | loss: 2.3371391MixupTrain:  epoch  0, batch   695 | loss: 2.1065929MixupTrain:  epoch  0, batch   696 | loss: 2.3584437MixupTrain:  epoch  0, batch   697 | loss: 2.2292018MixupTrain:  epoch  0, batch   698 | loss: 2.3657365MixupTrain:  epoch  0, batch   699 | loss: 2.1955047MixupTrain:  epoch  0, batch   700 | loss: 2.2474988MixupTrain:  epoch  0, batch   701 | loss: 2.2733645MixupTrain:  epoch  0, batch   702 | loss: 2.2984209MixupTrain:  epoch  0, batch   703 | loss: 2.1882284MixupTrain:  epoch  0, batch   704 | loss: 2.6103761MixupTrain:  epoch  0, batch   705 | loss: 2.5222535MixupTrain:  epoch  0, batch   706 | loss: 2.3864179MixupTrain:  epoch  0, batch   707 | loss: 2.1285231MixupTrain:  epoch  0, batch   708 | loss: 2.0307751MixupTrain:  epoch  0, batch   709 | loss: 2.2244081MixupTrain:  epoch  0, batch   710 | loss: 2.2567813MixupTrain:  epoch  0, batch   711 | loss: 2.4959490MixupTrain:  epoch  0, batch   712 | loss: 2.2581143MixupTrain:  epoch  0, batch   713 | loss: 2.4295921MixupTrain:  epoch  0, batch   714 | loss: 2.3403704MixupTrain:  epoch  0, batch   715 | loss: 2.0923047MixupTrain:  epoch  0, batch   716 | loss: 2.1798115MixupTrain:  epoch  0, batch   717 | loss: 2.0951562MixupTrain:  epoch  0, batch   718 | loss: 2.3872290MixupTrain:  epoch  0, batch   719 | loss: 2.3836384MixupTrain:  epoch  0, batch   720 | loss: 2.0769718MixupTrain:  epoch  0, batch   721 | loss: 2.3498309MixupTrain:  epoch  0, batch   722 | loss: 2.2151144MixupTrain:  epoch  0, batch   723 | loss: 2.2069821MixupTrain:  epoch  0, batch   724 | loss: 2.2588382MixupTrain:  epoch  0, batch   725 | loss: 2.2911994MixupTrain:  epoch  0, batch   726 | loss: 2.2752116MixupTrain:  epoch  0, batch   727 | loss: 2.3255248MixupTrain:  epoch  0, batch   728 | loss: 2.3323402MixupTrain:  epoch  0, batch   729 | loss: 2.2860413MixupTrain:  epoch  0, batch   730 | loss: 2.2595525MixupTrain:  epoch  0, batch   731 | loss: 2.1322467MixupTrain:  epoch  0, batch   732 | loss: 2.0921097MixupTrain:  epoch  0, batch   733 | loss: 2.2569923MixupTrain:  epoch  0, batch   734 | loss: 2.2700768MixupTrain:  epoch  0, batch   735 | loss: 2.2750678MixupTrain:  epoch  0, batch   736 | loss: 2.2577055MixupTrain:  epoch  0, batch   737 | loss: 2.2818866MixupTrain:  epoch  0, batch   738 | loss: 2.3103762MixupTrain:  epoch  0, batch   739 | loss: 2.6730554MixupTrain:  epoch  0, batch   740 | loss: 2.2234983MixupTrain:  epoch  0, batch   741 | loss: 2.3833015MixupTrain:  epoch  0, batch   742 | loss: 2.5437584MixupTrain:  epoch  0, batch   743 | loss: 2.2985897MixupTrain:  epoch  0, batch   744 | loss: 2.1920905MixupTrain:  epoch  0, batch   745 | loss: 2.3110981MixupTrain:  epoch  0, batch   746 | loss: 2.3761265MixupTrain:  epoch  0, batch   747 | loss: 2.3388629MixupTrain:  epoch  0, batch   748 | loss: 2.2721100MixupTrain:  epoch  0, batch   749 | loss: 2.7706811MixupTrain:  epoch  0, batch   750 | loss: 2.5888941MixupTrain:  epoch  0, batch   751 | loss: 1.9796766MixupTrain:  epoch  0, batch   752 | loss: 2.1606610MixupTrain:  epoch  0, batch   753 | loss: 2.4500999MixupTrain:  epoch  0, batch   754 | loss: 2.0699811MixupTrain:  epoch  0, batch   755 | loss: 2.7626810MixupTrain:  epoch  0, batch   756 | loss: 2.2465959MixupTrain:  epoch  0, batch   757 | loss: 2.2863588MixupTrain:  epoch  0, batch   758 | loss: 2.1888490MixupTrain:  epoch  0, batch   759 | loss: 2.2967601MixupTrain:  epoch  0, batch   760 | loss: 2.5652683MixupTrain:  epoch  0, batch   761 | loss: 2.0852952MixupTrain:  epoch  0, batch   762 | loss: 2.2395349MixupTrain:  epoch  0, batch   763 | loss: 2.1625223MixupTrain:  epoch  0, batch   764 | loss: 2.0761948MixupTrain:  epoch  0, batch   765 | loss: 2.1954665MixupTrain:  epoch  0, batch   766 | loss: 2.1509364MixupTrain:  epoch  0, batch   767 | loss: 2.3216896MixupTrain:  epoch  0, batch   768 | loss: 2.4033451MixupTrain:  epoch  0, batch   769 | loss: 2.4501529MixupTrain:  epoch  0, batch   770 | loss: 2.4879570MixupTrain:  epoch  0, batch   771 | loss: 2.5192366MixupTrain:  epoch  0, batch   772 | loss: 2.3081605MixupTrain:  epoch  0, batch   773 | loss: 2.5485795MixupTrain:  epoch  0, batch   774 | loss: 2.3380334MixupTrain:  epoch  0, batch   775 | loss: 2.2258444MixupTrain:  epoch  0, batch   776 | loss: 2.7629762MixupTrain:  epoch  0, batch   777 | loss: 2.2587192MixupTrain:  epoch  0, batch   778 | loss: 2.1539912MixupTrain:  epoch  0, batch   779 | loss: 2.3035276MixupTrain:  epoch  0, batch   780 | loss: 2.3341703MixupTrain:  epoch  0, batch   781 | loss: 2.2427945MixupTrain:  epoch  0, batch   782 | loss: 2.1413419MixupTrain:  epoch  0, batch   783 | loss: 2.3475821MixupTrain:  epoch  0, batch   784 | loss: 2.1234899MixupTrain:  epoch  0, batch   785 | loss: 2.3754623MixupTrain:  epoch  0, batch   786 | loss: 2.4970102MixupTrain:  epoch  0, batch   787 | loss: 2.2736232MixupTrain:  epoch  0, batch   788 | loss: 2.1452708MixupTrain:  epoch  0, batch   789 | loss: 2.1789985MixupTrain:  epoch  0, batch   790 | loss: 2.1452942MixupTrain:  epoch  0, batch   791 | loss: 2.2244096MixupTrain:  epoch  0, batch   792 | loss: 2.2953782MixupTrain:  epoch  0, batch   793 | loss: 2.5105929MixupTrain:  epoch  0, batch   794 | loss: 2.4494317MixupTrain:  epoch  0, batch   795 | loss: 2.1406217MixupTrain:  epoch  0, batch   796 | loss: 2.3547797MixupTrain:  epoch  0, batch   797 | loss: 2.1245546MixupTrain:  epoch  0, batch   798 | loss: 2.2315881MixupTrain:  epoch  0, batch   799 | loss: 2.5069866MixupTrain:  epoch  0, batch   800 | loss: 2.4729922MixupTrain:  epoch  0, batch   801 | loss: 2.3087940MixupTrain:  epoch  0, batch   802 | loss: 2.3729668MixupTrain:  epoch  0, batch   803 | loss: 2.0350158MixupTrain:  epoch  0, batch   804 | loss: 1.9361461MixupTrain:  epoch  0, batch   805 | loss: 2.1995707MixupTrain:  epoch  0, batch   806 | loss: 2.3473620MixupTrain:  epoch  0, batch   807 | loss: 2.2899811MixupTrain:  epoch  0, batch   808 | loss: 2.4490528MixupTrain:  epoch  0, batch   809 | loss: 2.3204398MixupTrain:  epoch  0, batch   810 | loss: 2.4217763MixupTrain:  epoch  0, batch   811 | loss: 2.3579803MixupTrain:  epoch  0, batch   812 | loss: 2.3803358MixupTrain:  epoch  0, batch   813 | loss: 2.3789270MixupTrain:  epoch  0, batch   814 | loss: 2.3189249MixupTrain:  epoch  0, batch   815 | loss: 2.0669291MixupTrain:  epoch  0, batch   816 | loss: 2.1858058MixupTrain:  epoch  0, batch   817 | loss: 2.3252854MixupTrain:  epoch  0, batch   818 | loss: 2.2017169MixupTrain:  epoch  0, batch   819 | loss: 2.1938710MixupTrain:  epoch  0, batch   820 | loss: 1.9701980MixupTrain:  epoch  0, batch   821 | loss: 2.3991785MixupTrain:  epoch  0, batch   822 | loss: 2.1689315MixupTrain:  epoch  0, batch   823 | loss: 2.0091004MixupTrain:  epoch  0, batch   824 | loss: 2.3692446MixupTrain:  epoch  0, batch   825 | loss: 2.4321699MixupTrain:  epoch  0, batch   826 | loss: 2.3292971MixupTrain:  epoch  0, batch   827 | loss: 2.4087350MixupTrain:  epoch  0, batch   828 | loss: 2.4347980MixupTrain:  epoch  0, batch   829 | loss: 2.1311641MixupTrain:  epoch  0, batch   830 | loss: 2.4350228MixupTrain:  epoch  0, batch   831 | loss: 2.3105733MixupTrain:  epoch  0, batch   832 | loss: 2.4646211MixupTrain:  epoch  0, batch   833 | loss: 2.2160602MixupTrain:  epoch  0, batch   834 | loss: 2.1483030MixupTrain:  epoch  0, batch   835 | loss: 2.4511297MixupTrain:  epoch  0, batch   836 | loss: 2.2413902MixupTrain:  epoch  0, batch   837 | loss: 2.1122880MixupTrain:  epoch  0, batch   838 | loss: 2.1580632MixupTrain:  epoch  0, batch   839 | loss: 2.4326932MixupTrain:  epoch  0, batch   840 | loss: 2.1711087MixupTrain:  epoch  0, batch   841 | loss: 2.7688923MixupTrain:  epoch  0, batch   842 | loss: 2.3993621MixupTrain:  epoch  0, batch   843 | loss: 2.3777833MixupTrain:  epoch  0, batch   844 | loss: 2.2897301MixupTrain:  epoch  0, batch   845 | loss: 2.2387533MixupTrain:  epoch  0, batch   846 | loss: 2.3293250MixupTrain:  epoch  0, batch   847 | loss: 2.2410080MixupTrain:  epoch  0, batch   848 | loss: 1.9962951MixupTrain:  epoch  0, batch   849 | loss: 2.1827819MixupTrain:  epoch  0, batch   850 | loss: 2.1569195MixupTrain:  epoch  0, batch   851 | loss: 2.4456482MixupTrain:  epoch  0, batch   852 | loss: 2.1221337MixupTrain:  epoch  0, batch   853 | loss: 2.5513725MixupTrain:  epoch  0, batch   854 | loss: 2.3074498MixupTrain:  epoch  0, batch   855 | loss: 2.2238445MixupTrain:  epoch  0, batch   856 | loss: 2.2607584MixupTrain:  epoch  0, batch   857 | loss: 2.2812119MixupTrain:  epoch  0, batch   858 | loss: 2.4873581MixupTrain:  epoch  0, batch   859 | loss: 2.2518959MixupTrain:  epoch  0, batch   860 | loss: 2.1820996MixupTrain:  epoch  0, batch   861 | loss: 2.3234200MixupTrain:  epoch  0, batch   862 | loss: 2.1438296MixupTrain:  epoch  0, batch   863 | loss: 2.3772640MixupTrain:  epoch  0, batch   864 | loss: 2.3580756MixupTrain:  epoch  0, batch   865 | loss: 2.4355614MixupTrain:  epoch  0, batch   866 | loss: 2.1313901MixupTrain:  epoch  0, batch   867 | loss: 2.2169437MixupTrain:  epoch  0, batch   868 | loss: 2.4230072MixupTrain:  epoch  0, batch   869 | loss: 2.2835569MixupTrain:  epoch  0, batch   870 | loss: 2.2872348MixupTrain:  epoch  0, batch   871 | loss: 2.2771497MixupTrain:  epoch  0, batch   872 | loss: 2.1196384MixupTrain:  epoch  0, batch   873 | loss: 2.4035094MixupTrain:  epoch  0, batch   874 | loss: 2.1927705MixupTrain:  epoch  0, batch   875 | loss: 2.6623037MixupTrain:  epoch  0, batch   876 | loss: 2.4604456MixupTrain:  epoch  0, batch   877 | loss: 2.6556497MixupTrain:  epoch  0, batch   878 | loss: 2.2058103MixupTrain:  epoch  0, batch   879 | loss: 2.2922912MixupTrain:  epoch  0, batch   880 | loss: 2.5005579MixupTrain:  epoch  0, batch   881 | loss: 2.2403574MixupTrain:  epoch  0, batch   882 | loss: 2.1421113MixupTrain:  epoch  0, batch   883 | loss: 2.1411312MixupTrain:  epoch  0, batch   884 | loss: 2.2985950MixupTrain:  epoch  0, batch   885 | loss: 2.2756610MixupTrain:  epoch  0, batch   886 | loss: 2.2924919MixupTrain:  epoch  0, batch   887 | loss: 2.2096381MixupTrain:  epoch  0, batch   888 | loss: 2.3051376MixupTrain:  epoch  0, batch   889 | loss: 2.0506692MixupTrain:  epoch  0, batch   890 | loss: 2.1700287MixupTrain:  epoch  0, batch   891 | loss: 2.3129053MixupTrain:  epoch  0, batch   892 | loss: 2.3092442MixupTrain:  epoch  0, batch   893 | loss: 2.0467868MixupTrain:  epoch  0, batch   894 | loss: 2.3062530MixupTrain:  epoch  0, batch   895 | loss: 2.0949652MixupTrain:  epoch  0, batch   896 | loss: 2.2844083MixupTrain:  epoch  0, batch   897 | loss: 2.0883622MixupTrain:  epoch  0, batch   898 | loss: 2.2906756MixupTrain:  epoch  0, batch   899 | loss: 2.2079930MixupTrain:  epoch  0, batch   900 | loss: 2.4542451MixupTrain:  epoch  0, batch   901 | loss: 2.2917566MixupTrain:  epoch  0, batch   902 | loss: 2.1911693MixupTrain:  epoch  0, batch   903 | loss: 2.1072121MixupTrain:  epoch  0, batch   904 | loss: 2.2151418MixupTrain:  epoch  0, batch   905 | loss: 2.4160111MixupTrain:  epoch  0, batch   906 | loss: 2.2436275MixupTrain:  epoch  0, batch   907 | loss: 2.2327440MixupTrain:  epoch  0, batch   908 | loss: 2.5620193MixupTrain:  epoch  0, batch   909 | loss: 2.2945089MixupTrain:  epoch  0, batch   910 | loss: 2.1682863MixupTrain:  epoch  0, batch   911 | loss: 2.4854894MixupTrain:  epoch  0, batch   912 | loss: 2.2555556MixupTrain:  epoch  0, batch   913 | loss: 2.2970753MixupTrain:  epoch  0, batch   914 | loss: 2.4747553MixupTrain:  epoch  0, batch   915 | loss: 2.4822354MixupTrain:  epoch  0, batch   916 | loss: 2.2372978MixupTrain:  epoch  0, batch   917 | loss: 2.4222116MixupTrain:  epoch  0, batch   918 | loss: 2.4664114MixupTrain:  epoch  0, batch   919 | loss: 2.3149071MixupTrain:  epoch  0, batch   920 | loss: 1.9586233MixupTrain:  epoch  0, batch   921 | loss: 2.5760841MixupTrain:  epoch  0, batch   922 | loss: 2.3970203MixupTrain:  epoch  0, batch   923 | loss: 2.3960519MixupTrain:  epoch  0, batch   924 | loss: 2.2064950MixupTrain:  epoch  0, batch   925 | loss: 2.2837639MixupTrain:  epoch  0, batch   926 | loss: 2.2103794MixupTrain:  epoch  0, batch   927 | loss: 2.3599219MixupTrain:  epoch  0, batch   928 | loss: 2.2777214MixupTrain:  epoch  0, batch   929 | loss: 2.2335930MixupTrain:  epoch  0, batch   930 | loss: 2.5886755MixupTrain:  epoch  0, batch   931 | loss: 2.2641647MixupTrain:  epoch  0, batch   932 | loss: 2.3999336MixupTrain:  epoch  0, batch   933 | loss: 2.2696428MixupTrain:  epoch  0, batch   934 | loss: 2.0625987MixupTrain:  epoch  0, batch   935 | loss: 2.3627591MixupTrain:  epoch  0, batch   936 | loss: 2.2057009MixupTrain:  epoch  0, batch   937 | loss: 2.3528037MixupTrain:  epoch  0, batch   938 | loss: 2.3370516MixupTrain:  epoch  0, batch   939 | loss: 2.1910300MixupTrain:  epoch  0, batch   940 | loss: 2.4758835MixupTrain:  epoch  0, batch   941 | loss: 2.3275521MixupTrain:  epoch  0, batch   942 | loss: 2.2091646MixupTrain:  epoch  0, batch   943 | loss: 2.4592521MixupTrain:  epoch  0, batch   944 | loss: 2.6504700MixupTrain:  epoch  0, batch   945 | loss: 2.1077790MixupTrain:  epoch  0, batch   946 | loss: 2.2767522MixupTrain:  epoch  0, batch   947 | loss: 2.3759518MixupTrain:  epoch  0, batch   948 | loss: 2.0093365MixupTrain:  epoch  0, batch   949 | loss: 1.9627813MixupTrain:  epoch  0, batch   950 | loss: 2.3225632MixupTrain:  epoch  0, batch   951 | loss: 2.3112357MixupTrain:  epoch  0, batch   952 | loss: 2.2171957MixupTrain:  epoch  0, batch   953 | loss: 2.7421126MixupTrain:  epoch  0, batch   954 | loss: 2.1432204MixupTrain:  epoch  0, batch   955 | loss: 2.2153389MixupTrain:  epoch  0, batch   956 | loss: 2.2636466MixupTrain:  epoch  0, batch   957 | loss: 2.4571798MixupTrain:  epoch  0, batch   958 | loss: 2.1000466MixupTrain:  epoch  0, batch   959 | loss: 2.3527412MixupTrain:  epoch  0, batch   960 | loss: 2.2897367MixupTrain:  epoch  0, batch   961 | loss: 1.9275905MixupTrain:  epoch  0, batch   962 | loss: 2.5392220MixupTrain:  epoch  0, batch   963 | loss: 2.6712561MixupTrain:  epoch  0, batch   964 | loss: 2.0860834MixupTrain:  epoch  0, batch   965 | loss: 2.1380129MixupTrain:  epoch  0, batch   966 | loss: 2.0968490MixupTrain:  epoch  0, batch   967 | loss: 2.2660236MixupTrain:  epoch  0, batch   968 | loss: 2.4290395MixupTrain:  epoch  0, batch   969 | loss: 2.2460051MixupTrain:  epoch  0, batch   970 | loss: 2.4021618MixupTrain:  epoch  0, batch   971 | loss: 2.1215732MixupTrain:  epoch  0, batch   972 | loss: 2.3171933MixupTrain:  epoch  0, batch   973 | loss: 2.3475707MixupTrain:  epoch  0, batch   974 | loss: 2.2449510MixupTrain:  epoch  0, batch   975 | loss: 2.1484447MixupTrain:  epoch  0, batch   976 | loss: 2.2934737MixupTrain:  epoch  0, batch   977 | loss: 2.5211859MixupTrain:  epoch  0, batch   978 | loss: 2.4656138MixupTrain:  epoch  0, batch   979 | loss: 2.6706371MixupTrain:  epoch  0, batch   980 | loss: 2.2471969MixupTrain:  epoch  0, batch   981 | loss: 2.2786291MixupTrain:  epoch  0, batch   982 | loss: 2.0041904MixupTrain:  epoch  0, batch   983 | loss: 2.0183330MixupTrain:  epoch  0, batch   984 | loss: 2.0151064MixupTrain:  epoch  0, batch   985 | loss: 2.3346100MixupTrain:  epoch  0, batch   986 | loss: 2.4711688MixupTrain:  epoch  0, batch   987 | loss: 2.3213246MixupTrain:  epoch  0, batch   988 | loss: 2.3581939MixupTrain:  epoch  0, batch   989 | loss: 2.4404423MixupTrain:  epoch  0, batch   990 | loss: 2.1470695MixupTrain:  epoch  0, batch   991 | loss: 2.1117144MixupTrain:  epoch  0, batch   992 | loss: 2.2275791MixupTrain:  epoch  0, batch   993 | loss: 2.2159672MixupTrain:  epoch  0, batch   994 | loss: 2.1836936MixupTrain:  epoch  0, batch   995 | loss: 2.6210175MixupTrain:  epoch  0, batch   996 | loss: 2.4205899MixupTrain:  epoch  0, batch   997 | loss: 2.3157015MixupTrain:  epoch  0, batch   998 | loss: 2.0777643MixupTrain:  epoch  0, batch   999 | loss: 2.2119517MixupTrain:  epoch  0, batch  1000 | loss: 1.9637890MixupTrain:  epoch  0, batch  1001 | loss: 2.2872338MixupTrain:  epoch  0, batch  1002 | loss: 2.0326774MixupTrain:  epoch  0, batch  1003 | loss: 2.6795468MixupTrain:  epoch  0, batch  1004 | loss: 2.2890372MixupTrain:  epoch  0, batch  1005 | loss: 2.3106341MixupTrain:  epoch  0, batch  1006 | loss: 2.1273828MixupTrain:  epoch  0, batch  1007 | loss: 2.1167538MixupTrain:  epoch  0, batch  1008 | loss: 2.2297163MixupTrain:  epoch  0, batch  1009 | loss: 2.3353305MixupTrain:  epoch  0, batch  1010 | loss: 2.2142053MixupTrain:  epoch  0, batch  1011 | loss: 2.1940439MixupTrain:  epoch  0, batch  1012 | loss: 2.2319310MixupTrain:  epoch  0, batch  1013 | loss: 2.1312113MixupTrain:  epoch  0, batch  1014 | loss: 1.9043703MixupTrain:  epoch  0, batch  1015 | loss: 2.3676481MixupTrain:  epoch  0, batch  1016 | loss: 2.3974428MixupTrain:  epoch  0, batch  1017 | loss: 2.1109352MixupTrain:  epoch  0, batch  1018 | loss: 2.4301867MixupTrain:  epoch  0, batch  1019 | loss: 2.3641734MixupTrain:  epoch  0, batch  1020 | loss: 2.0929542MixupTrain:  epoch  0, batch  1021 | loss: 2.1976221MixupTrain:  epoch  0, batch  1022 | loss: 2.2048447MixupTrain:  epoch  0, batch  1023 | loss: 2.4438200MixupTrain:  epoch  0, batch  1024 | loss: 2.0994928MixupTrain:  epoch  0, batch  1025 | loss: 2.2798948MixupTrain:  epoch  0, batch  1026 | loss: 2.3864417MixupTrain:  epoch  0, batch  1027 | loss: 2.1092312MixupTrain:  epoch  0, batch  1028 | loss: 2.4238002MixupTrain:  epoch  0, batch  1029 | loss: 2.6050200MixupTrain:  epoch  0, batch  1030 | loss: 2.2286739MixupTrain:  epoch  0, batch  1031 | loss: 2.3797817MixupTrain:  epoch  0, batch  1032 | loss: 2.0358415MixupTrain:  epoch  0, batch  1033 | loss: 2.1257360MixupTrain:  epoch  0, batch  1034 | loss: 2.3562374MixupTrain:  epoch  0, batch  1035 | loss: 2.1690059MixupTrain:  epoch  0, batch  1036 | loss: 2.3802192MixupTrain:  epoch  0, batch  1037 | loss: 2.1166921MixupTrain:  epoch  0, batch  1038 | loss: 2.0814667MixupTrain:  epoch  0, batch  1039 | loss: 2.3875179MixupTrain:  epoch  0, batch  1040 | loss: 2.4721098MixupTrain:  epoch  0, batch  1041 | loss: 2.2734566MixupTrain:  epoch  0, batch  1042 | loss: 2.2784135MixupTrain:  epoch  0, batch  1043 | loss: 2.3924155MixupTrain:  epoch  0, batch  1044 | loss: 2.4024501MixupTrain:  epoch  0, batch  1045 | loss: 2.4442906MixupTrain:  epoch  0, batch  1046 | loss: 2.4557483MixupTrain:  epoch  0, batch  1047 | loss: 2.3691516MixupTrain:  epoch  0, batch  1048 | loss: 2.4530776MixupTrain:  epoch  0, batch  1049 | loss: 2.0439208MixupTrain:  epoch  0, batch  1050 | loss: 2.1970959MixupTrain:  epoch  0, batch  1051 | loss: 2.3815832MixupTrain:  epoch  0, batch  1052 | loss: 2.3618181MixupTrain:  epoch  0, batch  1053 | loss: 2.0730143MixupTrain:  epoch  0, batch  1054 | loss: 2.1549489MixupTrain:  epoch  0, batch  1055 | loss: 2.2522874MixupTrain:  epoch  0, batch  1056 | loss: 2.1140623MixupTrain:  epoch  0, batch  1057 | loss: 2.3827405MixupTrain:  epoch  0, batch  1058 | loss: 2.2656488MixupTrain:  epoch  0, batch  1059 | loss: 2.6378787MixupTrain:  epoch  0, batch  1060 | loss: 2.1111939MixupTrain:  epoch  0, batch  1061 | loss: 2.0114377MixupTrain:  epoch  0, batch  1062 | loss: 2.3276594MixupTrain:  epoch  0, batch  1063 | loss: 2.6052332MixupTrain:  epoch  0, batch  1064 | loss: 2.2239208MixupTrain:  epoch  0, batch  1065 | loss: 2.3854132MixupTrain:  epoch  0, batch  1066 | loss: 2.2874656MixupTrain:  epoch  0, batch  1067 | loss: 2.2448235MixupTrain:  epoch  0, batch  1068 | loss: 2.2646437MixupTrain:  epoch  0, batch  1069 | loss: 2.1422987MixupTrain:  epoch  0, batch  1070 | loss: 2.2169008MixupTrain:  epoch  0, batch  1071 | loss: 2.4747877MixupTrain:  epoch  0, batch  1072 | loss: 2.3117518MixupTrain:  epoch  0, batch  1073 | loss: 2.4410205MixupTrain:  epoch  0, batch  1074 | loss: 2.1680717MixupTrain:  epoch  0, batch  1075 | loss: 2.5071888MixupTrain:  epoch  0, batch  1076 | loss: 2.1023793MixupTrain:  epoch  0, batch  1077 | loss: 2.1945188MixupTrain:  epoch  0, batch  1078 | loss: 2.4127860MixupTrain:  epoch  0, batch  1079 | loss: 2.4239142MixupTrain:  epoch  0, batch  1080 | loss: 2.4890556MixupTrain:  epoch  0, batch  1081 | loss: 2.4030089MixupTrain:  epoch  0, batch  1082 | loss: 2.7019482MixupTrain:  epoch  0, batch  1083 | loss: 2.0154700MixupTrain:  epoch  0, batch  1084 | loss: 2.6635690MixupTrain:  epoch  0, batch  1085 | loss: 2.3650458MixupTrain:  epoch  0, batch  1086 | loss: 2.1510487MixupTrain:  epoch  0, batch  1087 | loss: 2.4998517MixupTrain:  epoch  0, batch  1088 | loss: 2.0999136MixupTrain:  epoch  0, batch  1089 | loss: 2.3893814MixupTrain:  epoch  0, batch  1090 | loss: 2.0077498MixupTrain:  epoch  0, batch  1091 | loss: 2.3371267MixupTrain:  epoch  0, batch  1092 | loss: 1.9840138MixupTrain:  epoch  0, batch  1093 | loss: 2.2922966MixupTrain:  epoch  0, batch  1094 | loss: 2.0214734MixupTrain:  epoch  0, batch  1095 | loss: 2.1064405MixupTrain:  epoch  0, batch  1096 | loss: 2.2859178MixupTrain:  epoch  0, batch  1097 | loss: 2.2135694MixupTrain:  epoch  0, batch  1098 | loss: 2.2991228MixupTrain:  epoch  0, batch  1099 | loss: 2.2948148MixupTrain:  epoch  0, batch  1100 | loss: 2.2555125MixupTrain:  epoch  0, batch  1101 | loss: 2.2584169MixupTrain:  epoch  0, batch  1102 | loss: 2.3780017MixupTrain:  epoch  0, batch  1103 | loss: 2.2617111MixupTrain:  epoch  0, batch  1104 | loss: 2.4112601MixupTrain:  epoch  0, batch  1105 | loss: 2.4778416MixupTrain:  epoch  0, batch  1106 | loss: 2.2684803MixupTrain:  epoch  0, batch  1107 | loss: 2.5419326MixupTrain:  epoch  0, batch  1108 | loss: 2.2224312MixupTrain:  epoch  0, batch  1109 | loss: 2.3533304MixupTrain:  epoch  0, batch  1110 | loss: 2.1374917MixupTrain:  epoch  0, batch  1111 | loss: 2.2577968MixupTrain:  epoch  0, batch  1112 | loss: 2.2284780MixupTrain:  epoch  0, batch  1113 | loss: 2.2839203MixupTrain:  epoch  0, batch  1114 | loss: 2.2268114MixupTrain:  epoch  0, batch  1115 | loss: 2.4064991MixupTrain:  epoch  0, batch  1116 | loss: 2.4567654MixupTrain:  epoch  0, batch  1117 | loss: 2.4472194MixupTrain:  epoch  0, batch  1118 | loss: 2.2879534MixupTrain:  epoch  0, batch  1119 | loss: 2.4635577MixupTrain:  epoch  0, batch  1120 | loss: 2.1977363MixupTrain:  epoch  0, batch  1121 | loss: 2.1137550MixupTrain:  epoch  0, batch  1122 | loss: 2.4768658MixupTrain:  epoch  0, batch  1123 | loss: 2.3200490MixupTrain:  epoch  0, batch  1124 | loss: 2.4928403MixupTrain:  epoch  0, batch  1125 | loss: 2.6280169MixupTrain:  epoch  0, batch  1126 | loss: 2.1573710MixupTrain:  epoch  0, batch  1127 | loss: 2.3671679MixupTrain:  epoch  0, batch  1128 | loss: 2.2348516MixupTrain:  epoch  0, batch  1129 | loss: 2.1882544MixupTrain:  epoch  0, batch  1130 | loss: 2.3724272MixupTrain:  epoch  0, batch  1131 | loss: 2.2121601MixupTrain:  epoch  0, batch  1132 | loss: 2.1997495MixupTrain:  epoch  0, batch  1133 | loss: 2.4904604MixupTrain:  epoch  0, batch  1134 | loss: 2.1483788MixupTrain:  epoch  0, batch  1135 | loss: 2.2372496MixupTrain:  epoch  0, batch  1136 | loss: 2.4798665MixupTrain:  epoch  0, batch  1137 | loss: 2.4180059MixupTrain:  epoch  0, batch  1138 | loss: 2.3838706MixupTrain:  epoch  0, batch  1139 | loss: 2.3522804MixupTrain:  epoch  0, batch  1140 | loss: 2.3182237MixupTrain:  epoch  0, batch  1141 | loss: 2.1548181MixupTrain:  epoch  0, batch  1142 | loss: 2.4862552MixupTrain:  epoch  0, batch  1143 | loss: 2.3909092MixupTrain:  epoch  0, batch  1144 | loss: 2.2921524MixupTrain:  epoch  0, batch  1145 | loss: 2.4671097MixupTrain:  epoch  0, batch  1146 | loss: 2.0742629MixupTrain:  epoch  0, batch  1147 | loss: 2.3730757MixupTrain:  epoch  0, batch  1148 | loss: 2.1738439MixupTrain:  epoch  0, batch  1149 | loss: 2.4710362MixupTrain:  epoch  0, batch  1150 | loss: 2.4237189MixupTrain:  epoch  0, batch  1151 | loss: 2.3405194MixupTrain:  epoch  0, batch  1152 | loss: 2.1012709MixupTrain:  epoch  0, batch  1153 | loss: 2.5410972MixupTrain:  epoch  0, batch  1154 | loss: 2.0366201MixupTrain:  epoch  0, batch  1155 | loss: 2.4538724MixupTrain:  epoch  0, batch  1156 | loss: 2.0237055MixupTrain:  epoch  0, batch  1157 | loss: 2.1667504MixupTrain:  epoch  0, batch  1158 | loss: 2.2082310MixupTrain:  epoch  0, batch  1159 | loss: 2.1875796MixupTrain:  epoch  0, batch  1160 | loss: 2.1881220MixupTrain:  epoch  0, batch  1161 | loss: 2.4238563MixupTrain:  epoch  0, batch  1162 | loss: 2.2757232MixupTrain:  epoch  0, batch  1163 | loss: 2.1358988MixupTrain:  epoch  0, batch  1164 | loss: 2.3787446MixupTrain:  epoch  0, batch  1165 | loss: 2.3085656MixupTrain:  epoch  0, batch  1166 | loss: 2.1574254MixupTrain:  epoch  0, batch  1167 | loss: 2.5686598MixupTrain:  epoch  0, batch  1168 | loss: 2.5484028MixupTrain:  epoch  0, batch  1169 | loss: 1.8954914MixupTrain:  epoch  0, batch  1170 | loss: 2.3221745MixupTrain:  epoch  0, batch  1171 | loss: 2.3060288MixupTrain:  epoch  0, batch  1172 | loss: 2.4435692MixupTrain:  epoch  0, batch  1173 | loss: 2.3718071MixupTrain:  epoch  0, batch  1174 | loss: 2.2089231MixupTrain:  epoch  0, batch  1175 | loss: 2.2435062MixupTrain:  epoch  0, batch  1176 | loss: 2.5661922MixupTrain:  epoch  0, batch  1177 | loss: 2.2793140MixupTrain:  epoch  0, batch  1178 | loss: 2.6002724MixupTrain:  epoch  0, batch  1179 | loss: 2.4559929MixupTrain:  epoch  0, batch  1180 | loss: 1.9396547MixupTrain:  epoch  0, batch  1181 | loss: 2.2436473MixupTrain:  epoch  0, batch  1182 | loss: 2.2043023MixupTrain:  epoch  0, batch  1183 | loss: 2.2602682MixupTrain:  epoch  0, batch  1184 | loss: 2.6384139MixupTrain:  epoch  0, batch  1185 | loss: 2.2365322MixupTrain:  epoch  0, batch  1186 | loss: 2.0079699MixupTrain:  epoch  0, batch  1187 | loss: 2.2638049MixupTrain:  epoch  0, batch  1188 | loss: 2.2870734MixupTrain:  epoch  0, batch  1189 | loss: 2.6229672MixupTrain:  epoch  0, batch  1190 | loss: 2.2693496MixupTrain:  epoch  0, batch  1191 | loss: 2.4558570MixupTrain:  epoch  0, batch  1192 | loss: 2.3163648MixupTrain:  epoch  0, batch  1193 | loss: 2.0840545MixupTrain:  epoch  0, batch  1194 | loss: 2.3474422MixupTrain:  epoch  0, batch  1195 | loss: 2.0443022MixupTrain:  epoch  0, batch  1196 | loss: 2.1140268MixupTrain:  epoch  0, batch  1197 | loss: 2.4799356MixupTrain:  epoch  0, batch  1198 | loss: 2.0368390MixupTrain:  epoch  0, batch  1199 | loss: 1.8640921MixupTrain:  epoch  0, batch  1200 | loss: 2.2583275MixupTrain:  epoch  0, batch  1201 | loss: 2.2119856MixupTrain:  epoch  0, batch  1202 | loss: 2.3062627MixupTrain:  epoch  0, batch  1203 | loss: 2.0314260MixupTrain:  epoch  0, batch  1204 | loss: 2.2728994MixupTrain:  epoch  0, batch  1205 | loss: 2.1685824MixupTrain:  epoch  0, batch  1206 | loss: 2.1984415MixupTrain:  epoch  0, batch  1207 | loss: 2.2569461MixupTrain:  epoch  0, batch  1208 | loss: 2.3628120MixupTrain:  epoch  0, batch  1209 | loss: 2.0958228MixupTrain:  epoch  0, batch  1210 | loss: 2.1619840MixupTrain:  epoch  0, batch  1211 | loss: 2.4746156MixupTrain:  epoch  0, batch  1212 | loss: 2.3334632MixupTrain:  epoch  0, batch  1213 | loss: 2.2980371MixupTrain:  epoch  0, batch  1214 | loss: 2.2584891MixupTrain:  epoch  0, batch  1215 | loss: 1.9683518MixupTrain:  epoch  0, batch  1216 | loss: 2.3539901MixupTrain:  epoch  0, batch  1217 | loss: 2.0402241MixupTrain:  epoch  0, batch  1218 | loss: 2.2890720MixupTrain:  epoch  0, batch  1219 | loss: 2.2123671MixupTrain:  epoch  0, batch  1220 | loss: 2.1243739MixupTrain:  epoch  0, batch  1221 | loss: 2.1799338MixupTrain:  epoch  0, batch  1222 | loss: 2.2711980MixupTrain:  epoch  0, batch  1223 | loss: 2.2093153MixupTrain:  epoch  0, batch  1224 | loss: 2.2498896MixupTrain:  epoch  0, batch  1225 | loss: 2.4244318MixupTrain:  epoch  0, batch  1226 | loss: 2.0222697MixupTrain:  epoch  0, batch  1227 | loss: 2.2627878MixupTrain:  epoch  0, batch  1228 | loss: 2.0893700MixupTrain:  epoch  0, batch  1229 | loss: 2.3647366MixupTrain:  epoch  0, batch  1230 | loss: 2.1745439MixupTrain:  epoch  0, batch  1231 | loss: 2.1545544MixupTrain:  epoch  0, batch  1232 | loss: 2.3272359MixupTrain:  epoch  0, batch  1233 | loss: 2.3945069MixupTrain:  epoch  0, batch  1234 | loss: 2.0701733MixupTrain:  epoch  0, batch  1235 | loss: 2.3810945MixupTrain:  epoch  0, batch  1236 | loss: 2.3630767MixupTrain:  epoch  0, batch  1237 | loss: 2.1509895MixupTrain:  epoch  0, batch  1238 | loss: 2.1097407MixupTrain:  epoch  0, batch  1239 | loss: 2.3206649MixupTrain:  epoch  0, batch  1240 | loss: 2.0764871MixupTrain:  epoch  0, batch  1241 | loss: 2.0139537MixupTrain:  epoch  0, batch  1242 | loss: 2.0609350MixupTrain:  epoch  0, batch  1243 | loss: 2.1969423MixupTrain:  epoch  0, batch  1244 | loss: 2.2529233MixupTrain:  epoch  0, batch  1245 | loss: 2.1181536MixupTrain:  epoch  0, batch  1246 | loss: 2.4424024MixupTrain:  epoch  0, batch  1247 | loss: 2.1499581MixupTrain:  epoch  0, batch  1248 | loss: 2.3563988MixupTrain:  epoch  0, batch  1249 | loss: 2.3594556MixupTrain:  epoch  0, batch  1250 | loss: 2.3591638MixupTrain:  epoch  0, batch  1251 | loss: 2.1763194MixupTrain:  epoch  0, batch  1252 | loss: 2.1846824MixupTrain:  epoch  0, batch  1253 | loss: 2.4553208MixupTrain:  epoch  0, batch  1254 | loss: 2.2380660MixupTrain:  epoch  0, batch  1255 | loss: 2.0810699MixupTrain:  epoch  0, batch  1256 | loss: 2.4756081MixupTrain:  epoch  0, batch  1257 | loss: 2.3332691MixupTrain:  epoch  0, batch  1258 | loss: 2.3183866MixupTrain:  epoch  0, batch  1259 | loss: 2.2557955MixupTrain:  epoch  0, batch  1260 | loss: 2.2236695MixupTrain:  epoch  0, batch  1261 | loss: 2.3914351MixupTrain:  epoch  0, batch  1262 | loss: 2.2188084MixupTrain:  epoch  0, batch  1263 | loss: 2.3303363MixupTrain:  epoch  0, batch  1264 | loss: 2.2222388MixupTrain:  epoch  0, batch  1265 | loss: 2.1182139MixupTrain:  epoch  0, batch  1266 | loss: 2.4811158MixupTrain:  epoch  0, batch  1267 | loss: 2.3024883MixupTrain:  epoch  0, batch  1268 | loss: 2.2009785MixupTrain:  epoch  0, batch  1269 | loss: 2.3414674MixupTrain:  epoch  0, batch  1270 | loss: 2.3693838MixupTrain:  epoch  0, batch  1271 | loss: 2.0285137MixupTrain:  epoch  0, batch  1272 | loss: 2.5625653MixupTrain:  epoch  0, batch  1273 | loss: 2.1197653MixupTrain:  epoch  0, batch  1274 | loss: 2.6063244MixupTrain:  epoch  0, batch  1275 | loss: 2.0748255MixupTrain:  epoch  0, batch  1276 | loss: 2.2167306MixupTrain:  epoch  0, batch  1277 | loss: 2.2549651MixupTrain:  epoch  0, batch  1278 | loss: 2.2382038MixupTrain:  epoch  0, batch  1279 | loss: 2.2730529MixupTrain:  epoch  0, batch  1280 | loss: 2.6533206MixupTrain:  epoch  0, batch  1281 | loss: 2.3714187MixupTrain:  epoch  0, batch  1282 | loss: 2.2463579MixupTrain:  epoch  0, batch  1283 | loss: 2.3125935MixupTrain:  epoch  0, batch  1284 | loss: 2.2642539MixupTrain:  epoch  0, batch  1285 | loss: 2.2223899MixupTrain:  epoch  0, batch  1286 | loss: 2.3864076MixupTrain:  epoch  0, batch  1287 | loss: 2.3366749MixupTrain:  epoch  0, batch  1288 | loss: 2.3839350MixupTrain:  epoch  0, batch  1289 | loss: 2.3928308MixupTrain:  epoch  0, batch  1290 | loss: 2.1961150MixupTrain:  epoch  0, batch  1291 | loss: 2.1348205MixupTrain:  epoch  0, batch  1292 | loss: 2.1004815MixupTrain:  epoch  0, batch  1293 | loss: 2.1959987MixupTrain:  epoch  0, batch  1294 | loss: 2.4007056MixupTrain:  epoch  0, batch  1295 | loss: 2.4743450MixupTrain:  epoch  0, batch  1296 | loss: 2.1460767MixupTrain:  epoch  0, batch  1297 | loss: 2.3402181MixupTrain:  epoch  0, batch  1298 | loss: 2.2547734MixupTrain:  epoch  0, batch  1299 | loss: 2.5443454MixupTrain:  epoch  0, batch  1300 | loss: 2.3608346MixupTrain:  epoch  0, batch  1301 | loss: 2.2057390MixupTrain:  epoch  0, batch  1302 | loss: 2.4206595MixupTrain:  epoch  0, batch  1303 | loss: 2.4923880MixupTrain:  epoch  0, batch  1304 | loss: 2.0328712MixupTrain:  epoch  0, batch  1305 | loss: 2.3788900MixupTrain:  epoch  0, batch  1306 | loss: 2.3402328MixupTrain:  epoch  0, batch  1307 | loss: 2.3990965MixupTrain:  epoch  0, batch  1308 | loss: 2.1961019MixupTrain:  epoch  0, batch  1309 | loss: 2.1519995MixupTrain:  epoch  0, batch  1310 | loss: 2.1773491MixupTrain:  epoch  0, batch  1311 | loss: 2.4151056MixupTrain:  epoch  0, batch  1312 | loss: 2.0915151MixupTrain:  epoch  0, batch  1313 | loss: 2.2338786MixupTrain:  epoch  0, batch  1314 | loss: 2.3491573MixupTrain:  epoch  0, batch  1315 | loss: 2.3716962MixupTrain:  epoch  0, batch  1316 | loss: 2.3256865MixupTrain:  epoch  0, batch  1317 | loss: 2.0722942MixupTrain:  epoch  0, batch  1318 | loss: 2.1496475MixupTrain:  epoch  0, batch  1319 | loss: 2.3371720MixupTrain:  epoch  0, batch  1320 | loss: 2.4744124MixupTrain:  epoch  0, batch  1321 | loss: 2.4882569MixupTrain:  epoch  0, batch  1322 | loss: 2.1925805MixupTrain:  epoch  0, batch  1323 | loss: 2.3632042MixupTrain:  epoch  0, batch  1324 | loss: 2.5112956MixupTrain:  epoch  0, batch  1325 | loss: 2.2243474MixupTrain:  epoch  0, batch  1326 | loss: 2.1918812MixupTrain:  epoch  0, batch  1327 | loss: 2.3789055MixupTrain:  epoch  0, batch  1328 | loss: 2.2338059MixupTrain:  epoch  0, batch  1329 | loss: 2.4574072MixupTrain:  epoch  0, batch  1330 | loss: 2.3203106MixupTrain:  epoch  0, batch  1331 | loss: 2.2147474MixupTrain:  epoch  0, batch  1332 | loss: 2.0970268MixupTrain:  epoch  0, batch  1333 | loss: 2.4811673MixupTrain:  epoch  0, batch  1334 | loss: 2.4418113MixupTrain:  epoch  0, batch  1335 | loss: 2.2760897MixupTrain:  epoch  0, batch  1336 | loss: 2.3280084MixupTrain:  epoch  0, batch  1337 | loss: 1.9783617MixupTrain:  epoch  0, batch  1338 | loss: 2.3378062MixupTrain:  epoch  0, batch  1339 | loss: 2.5081711MixupTrain:  epoch  0, batch  1340 | loss: 2.3259430MixupTrain:  epoch  0, batch  1341 | loss: 2.4632390MixupTrain:  epoch  0, batch  1342 | loss: 2.4908361MixupTrain:  epoch  0, batch  1343 | loss: 2.3710556MixupTrain:  epoch  0, batch  1344 | loss: 2.5643840MixupTrain:  epoch  0, batch  1345 | loss: 2.2138376MixupTrain:  epoch  0, batch  1346 | loss: 2.2300878MixupTrain:  epoch  0, batch  1347 | loss: 2.4675212MixupTrain:  epoch  0, batch  1348 | loss: 2.3047688MixupTrain:  epoch  0, batch  1349 | loss: 2.5568500MixupTrain:  epoch  0, batch  1350 | loss: 2.4504325MixupTrain:  epoch  0, batch  1351 | loss: 2.4410002MixupTrain:  epoch  0, batch  1352 | loss: 2.1832004MixupTrain:  epoch  0, batch  1353 | loss: 2.3178239MixupTrain:  epoch  0, batch  1354 | loss: 2.3817904MixupTrain:  epoch  0, batch  1355 | loss: 2.2552159MixupTrain:  epoch  0, batch  1356 | loss: 2.2789605MixupTrain:  epoch  0, batch  1357 | loss: 2.5853443MixupTrain:  epoch  0, batch  1358 | loss: 2.2430477MixupTrain:  epoch  0, batch  1359 | loss: 2.3780630MixupTrain:  epoch  0, batch  1360 | loss: 2.4765096MixupTrain:  epoch  0, batch  1361 | loss: 2.4088809MixupTrain:  epoch  0, batch  1362 | loss: 2.3742282MixupTrain:  epoch  0, batch  1363 | loss: 2.1534820MixupTrain:  epoch  0, batch  1364 | loss: 2.1069264MixupTrain:  epoch  0, batch  1365 | loss: 2.2671118MixupTrain:  epoch  0, batch  1366 | loss: 2.1179152MixupTrain:  epoch  0, batch  1367 | loss: 2.4047341MixupTrain:  epoch  0, batch  1368 | loss: 2.3881049MixupTrain:  epoch  0, batch  1369 | loss: 2.1556382MixupTrain:  epoch  0, batch  1370 | loss: 2.0650892MixupTrain:  epoch  0, batch  1371 | loss: 2.2788460MixupTrain:  epoch  0, batch  1372 | loss: 2.2129755MixupTrain:  epoch  0, batch  1373 | loss: 2.2229452MixupTrain:  epoch  0, batch  1374 | loss: 2.0977066MixupTrain:  epoch  0, batch  1375 | loss: 2.3018808MixupTrain:  epoch  0, batch  1376 | loss: 2.3010933MixupTrain:  epoch  0, batch  1377 | loss: 2.1548095MixupTrain:  epoch  0, batch  1378 | loss: 2.2353702MixupTrain:  epoch  0, batch  1379 | loss: 2.4472587MixupTrain:  epoch  0, batch  1380 | loss: 2.2008228MixupTrain:  epoch  0, batch  1381 | loss: 2.1495690MixupTrain:  epoch  0, batch  1382 | loss: 2.1692605MixupTrain:  epoch  0, batch  1383 | loss: 2.3159022MixupTrain:  epoch  0, batch  1384 | loss: 2.3515992MixupTrain:  epoch  0, batch  1385 | loss: 2.1973977MixupTrain:  epoch  0, batch  1386 | loss: 2.3972640MixupTrain:  epoch  0, batch  1387 | loss: 2.2024102MixupTrain:  epoch  0, batch  1388 | loss: 2.2962899MixupTrain:  epoch  0, batch  1389 | loss: 2.1540627MixupTrain:  epoch  0, batch  1390 | loss: 2.0377789MixupTrain:  epoch  0, batch  1391 | loss: 2.5187495MixupTrain:  epoch  0, batch  1392 | loss: 1.9591516MixupTrain:  epoch  0, batch  1393 | loss: 2.1479774MixupTrain:  epoch  0, batch  1394 | loss: 2.0901871MixupTrain:  epoch  0, batch  1395 | loss: 2.0600533MixupTrain:  epoch  0, batch  1396 | loss: 2.2798212MixupTrain:  epoch  0, batch  1397 | loss: 2.0860422MixupTrain:  epoch  0, batch  1398 | loss: 2.4217527MixupTrain:  epoch  0, batch  1399 | loss: 2.3402305MixupTrain:  epoch  0, batch  1400 | loss: 2.2497010MixupTrain:  epoch  0, batch  1401 | loss: 2.4229999MixupTrain:  epoch  0, batch  1402 | loss: 2.3248858MixupTrain:  epoch  0, batch  1403 | loss: 2.3886704MixupTrain:  epoch  0, batch  1404 | loss: 2.3335929MixupTrain:  epoch  0, batch  1405 | loss: 2.3821907MixupTrain:  epoch  0, batch  1406 | loss: 2.2630813MixupTrain:  epoch  0, batch  1407 | loss: 2.1766324MixupTrain:  epoch  0, batch  1408 | loss: 2.5585442MixupTrain:  epoch  0, batch  1409 | loss: 2.1486804MixupTrain:  epoch  0, batch  1410 | loss: 2.2678144MixupTrain:  epoch  0, batch  1411 | loss: 2.1700594MixupTrain:  epoch  0, batch  1412 | loss: 2.2613699MixupTrain:  epoch  0, batch  1413 | loss: 2.4751847MixupTrain:  epoch  0, batch  1414 | loss: 2.4206553MixupTrain:  epoch  0, batch  1415 | loss: 2.3181407MixupTrain:  epoch  0, batch  1416 | loss: 2.1821461MixupTrain:  epoch  0, batch  1417 | loss: 2.2587881MixupTrain:  epoch  0, batch  1418 | loss: 2.3474364MixupTrain:  epoch  0, batch  1419 | loss: 2.2876978MixupTrain:  epoch  0, batch  1420 | loss: 2.3927379MixupTrain:  epoch  0, batch  1421 | loss: 2.3358941MixupTrain:  epoch  0, batch  1422 | loss: 2.2221789MixupTrain:  epoch  0, batch  1423 | loss: 2.1723485MixupTrain:  epoch  0, batch  1424 | loss: 2.0310245MixupTrain:  epoch  0, batch  1425 | loss: 2.2186601MixupTrain:  epoch  0, batch  1426 | loss: 2.4734511MixupTrain:  epoch  0, batch  1427 | loss: 2.5226550MixupTrain:  epoch  0, batch  1428 | loss: 2.4451909MixupTrain:  epoch  0, batch  1429 | loss: 2.5155630MixupTrain:  epoch  0, batch  1430 | loss: 2.2165005MixupTrain:  epoch  0, batch  1431 | loss: 2.0270817MixupTrain:  epoch  0, batch  1432 | loss: 2.2656631MixupTrain:  epoch  0, batch  1433 | loss: 2.3221755MixupTrain:  epoch  0, batch  1434 | loss: 2.2562673MixupTrain:  epoch  0, batch  1435 | loss: 2.2218916MixupTrain:  epoch  0, batch  1436 | loss: 2.4489377MixupTrain:  epoch  0, batch  1437 | loss: 2.1776304MixupTrain:  epoch  0, batch  1438 | loss: 2.4680214MixupTrain:  epoch  0, batch  1439 | loss: 2.2277646MixupTrain:  epoch  0, batch  1440 | loss: 2.0916591MixupTrain:  epoch  0, batch  1441 | loss: 1.9765222MixupTrain:  epoch  0, batch  1442 | loss: 2.1428218MixupTrain:  epoch  0, batch  1443 | loss: 2.1182842MixupTrain:  epoch  0, batch  1444 | loss: 2.4831080MixupTrain:  epoch  0, batch  1445 | loss: 2.0992036MixupTrain:  epoch  0, batch  1446 | loss: 2.2841308MixupTrain:  epoch  0, batch  1447 | loss: 2.2985845MixupTrain:  epoch  0, batch  1448 | loss: 2.3620114MixupTrain:  epoch  0, batch  1449 | loss: 2.1959031MixupTrain:  epoch  0, batch  1450 | loss: 2.2865000MixupTrain:  epoch  0, batch  1451 | loss: 2.3098273MixupTrain:  epoch  0, batch  1452 | loss: 2.5301871MixupTrain:  epoch  0, batch  1453 | loss: 2.2401309MixupTrain:  epoch  0, batch  1454 | loss: 2.1928504MixupTrain:  epoch  0, batch  1455 | loss: 1.9641973MixupTrain:  epoch  0, batch  1456 | loss: 2.2265983MixupTrain:  epoch  0, batch  1457 | loss: 2.4224966MixupTrain:  epoch  0, batch  1458 | loss: 2.1411946MixupTrain:  epoch  0, batch  1459 | loss: 2.1860905MixupTrain:  epoch  0, batch  1460 | loss: 1.9262302MixupTrain:  epoch  0, batch  1461 | loss: 2.0671153MixupTrain:  epoch  0, batch  1462 | loss: 2.4892967MixupTrain:  epoch  0, batch  1463 | loss: 2.3886986MixupTrain:  epoch  0, batch  1464 | loss: 2.2325740MixupTrain:  epoch  0, batch  1465 | loss: 2.3415785MixupTrain:  epoch  0, batch  1466 | loss: 2.2443419MixupTrain:  epoch  0, batch  1467 | loss: 2.5288701MixupTrain:  epoch  0, batch  1468 | loss: 2.2025867MixupTrain:  epoch  0, batch  1469 | loss: 2.4459968MixupTrain:  epoch  0, batch  1470 | loss: 2.3176889MixupTrain:  epoch  0, batch  1471 | loss: 2.3444247MixupTrain:  epoch  0, batch  1472 | loss: 1.9596137MixupTrain:  epoch  0, batch  1473 | loss: 2.0578001MixupTrain:  epoch  0, batch  1474 | loss: 2.1287124MixupTrain:  epoch  0, batch  1475 | loss: 2.2524011MixupTrain:  epoch  0, batch  1476 | loss: 2.3473797MixupTrain:  epoch  0, batch  1477 | loss: 2.3413038MixupTrain:  epoch  0, batch  1478 | loss: 2.3543224MixupTrain:  epoch  0, batch  1479 | loss: 2.0840318MixupTrain:  epoch  0, batch  1480 | loss: 2.2396142MixupTrain:  epoch  0, batch  1481 | loss: 2.3974371MixupTrain:  epoch  0, batch  1482 | loss: 2.6572478MixupTrain:  epoch  0, batch  1483 | loss: 2.0074472MixupTrain:  epoch  0, batch  1484 | loss: 2.3588457MixupTrain:  epoch  0, batch  1485 | loss: 2.1297798MixupTrain:  epoch  0, batch  1486 | loss: 2.1271737MixupTrain:  epoch  0, batch  1487 | loss: 2.1887367MixupTrain:  epoch  0, batch  1488 | loss: 2.2137644MixupTrain:  epoch  0, batch  1489 | loss: 2.5905199MixupTrain:  epoch  0, batch  1490 | loss: 2.1188045MixupTrain:  epoch  0, batch  1491 | loss: 2.0340433MixupTrain:  epoch  0, batch  1492 | loss: 2.4278820MixupTrain:  epoch  0, batch  1493 | loss: 2.2248695MixupTrain:  epoch  0, batch  1494 | loss: 2.0414746MixupTrain:  epoch  0, batch  1495 | loss: 2.2757277MixupTrain:  epoch  0, batch  1496 | loss: 2.4071116MixupTrain:  epoch  0, batch  1497 | loss: 2.0636671MixupTrain:  epoch  0, batch  1498 | loss: 2.2363918MixupTrain:  epoch  0, batch  1499 | loss: 2.2954078MixupTrain:  epoch  0, batch  1500 | loss: 2.2818384MixupTrain:  epoch  0, batch  1501 | loss: 2.3506069MixupTrain:  epoch  0, batch  1502 | loss: 2.0291877MixupTrain:  epoch  0, batch  1503 | loss: 2.1336808MixupTrain:  epoch  0, batch  1504 | loss: 2.1890047MixupTrain:  epoch  0, batch  1505 | loss: 2.2610235MixupTrain:  epoch  0, batch  1506 | loss: 2.2855420MixupTrain:  epoch  0, batch  1507 | loss: 2.2082419MixupTrain:  epoch  0, batch  1508 | loss: 2.0876150MixupTrain:  epoch  0, batch  1509 | loss: 2.3398564MixupTrain:  epoch  0, batch  1510 | loss: 2.5295372MixupTrain:  epoch  0, batch  1511 | loss: 2.4850898MixupTrain:  epoch  0, batch  1512 | loss: 2.2248609MixupTrain:  epoch  0, batch  1513 | loss: 2.4644001MixupTrain:  epoch  0, batch  1514 | loss: 2.4384305MixupTrain:  epoch  0, batch  1515 | loss: 2.2852106MixupTrain:  epoch  0, batch  1516 | loss: 2.3198566MixupTrain:  epoch  0, batch  1517 | loss: 2.5360804MixupTrain:  epoch  0, batch  1518 | loss: 2.4195876MixupTrain:  epoch  0, batch  1519 | loss: 2.3504097MixupTrain:  epoch  0, batch  1520 | loss: 2.2054338MixupTrain:  epoch  0, batch  1521 | loss: 2.1795721MixupTrain:  epoch  0, batch  1522 | loss: 2.2791405MixupTrain:  epoch  0, batch  1523 | loss: 2.1877408MixupTrain:  epoch  0, batch  1524 | loss: 2.3346076MixupTrain:  epoch  0, batch  1525 | loss: 2.5853591MixupTrain:  epoch  0, batch  1526 | loss: 2.3799138MixupTrain:  epoch  0, batch  1527 | loss: 2.3419838MixupTrain:  epoch  0, batch  1528 | loss: 2.3786540MixupTrain:  epoch  0, batch  1529 | loss: 2.0387976MixupTrain:  epoch  0, batch  1530 | loss: 2.2043662MixupTrain:  epoch  0, batch  1531 | loss: 2.3316915MixupTrain:  epoch  0, batch  1532 | loss: 2.3261373MixupTrain:  epoch  0, batch  1533 | loss: 2.1176503MixupTrain:  epoch  0, batch  1534 | loss: 2.1874335MixupTrain:  epoch  0, batch  1535 | loss: 2.2150798MixupTrain:  epoch  0, batch  1536 | loss: 2.1146488MixupTrain:  epoch  0, batch  1537 | loss: 2.3054268MixupTrain:  epoch  0, batch  1538 | loss: 2.2042646MixupTrain:  epoch  0, batch  1539 | loss: 1.9575678MixupTrain:  epoch  0, batch  1540 | loss: 2.2637379MixupTrain:  epoch  0, batch  1541 | loss: 2.1373510MixupTrain:  epoch  0, batch  1542 | loss: 2.3196273MixupTrain:  epoch  0, batch  1543 | loss: 2.4583368MixupTrain:  epoch  0, batch  1544 | loss: 2.2041793MixupTrain:  epoch  0, batch  1545 | loss: 2.4457181MixupTrain:  epoch  0, batch  1546 | loss: 2.4184611MixupTrain:  epoch  0, batch  1547 | loss: 2.0961862MixupTrain:  epoch  0, batch  1548 | loss: 2.7596500MixupTrain:  epoch  0, batch  1549 | loss: 2.5239751MixupTrain:  epoch  0, batch  1550 | loss: 2.3259501MixupTrain:  epoch  0, batch  1551 | loss: 2.2466791MixupTrain:  epoch  0, batch  1552 | loss: 2.2860322MixupTrain:  epoch  0, batch  1553 | loss: 2.2157247MixupTrain:  epoch  0, batch  1554 | loss: 2.1899662MixupTrain:  epoch  0, batch  1555 | loss: 2.4140000MixupTrain:  epoch  0, batch  1556 | loss: 2.2036743MixupTrain:  epoch  0, batch  1557 | loss: 2.3117132MixupTrain:  epoch  0, batch  1558 | loss: 2.0718527MixupTrain:  epoch  0, batch  1559 | loss: 2.0215130MixupTrain:  epoch  0, batch  1560 | loss: 2.3773196MixupTrain:  epoch  0, batch  1561 | loss: 2.1793196MixupTrain:  epoch  0, batch  1562 | loss: 2.2029552MixupTrain:  epoch  0, batch  1563 | loss: 2.2672334MixupTrain:  epoch  0, batch  1564 | loss: 2.2290878MixupTrain:  epoch  0, batch  1565 | loss: 2.2696934MixupTrain:  epoch  0, batch  1566 | loss: 2.2192149MixupTrain:  epoch  0, batch  1567 | loss: 2.4178648MixupTrain:  epoch  0, batch  1568 | loss: 2.5069680MixupTrain:  epoch  0, batch  1569 | loss: 2.1733537MixupTrain:  epoch  0, batch  1570 | loss: 1.9511745MixupTrain:  epoch  0, batch  1571 | loss: 2.4424908MixupTrain:  epoch  0, batch  1572 | loss: 2.2908397MixupTrain:  epoch  0, batch  1573 | loss: 2.2993288MixupTrain:  epoch  0, batch  1574 | loss: 2.5143130MixupTrain:  epoch  0, batch  1575 | loss: 2.4254963MixupTrain:  epoch  0, batch  1576 | loss: 2.1568193MixupTrain:  epoch  0, batch  1577 | loss: 2.1147695MixupTrain:  epoch  0, batch  1578 | loss: 2.3108397MixupTrain:  epoch  0, batch  1579 | loss: 2.2572610MixupTrain:  epoch  0, batch  1580 | loss: 2.1662548MixupTrain:  epoch  0, batch  1581 | loss: 2.4667776MixupTrain:  epoch  0, batch  1582 | loss: 2.1611533MixupTrain:  epoch  0, batch  1583 | loss: 2.2634835MixupTrain:  epoch  0, batch  1584 | loss: 1.9382417MixupTrain:  epoch  0, batch  1585 | loss: 2.1275425MixupTrain:  epoch  0, batch  1586 | loss: 2.3571200MixupTrain:  epoch  0, batch  1587 | loss: 2.4932184MixupTrain:  epoch  0, batch  1588 | loss: 2.0787330MixupTrain:  epoch  0, batch  1589 | loss: 2.3572793MixupTrain:  epoch  0, batch  1590 | loss: 2.1740444MixupTrain:  epoch  0, batch  1591 | loss: 2.3210256MixupTrain:  epoch  0, batch  1592 | loss: 2.2189989MixupTrain:  epoch  0, batch  1593 | loss: 2.2982237MixupTrain:  epoch  0, batch  1594 | loss: 2.1377468MixupTrain:  epoch  0, batch  1595 | loss: 2.2654581MixupTrain:  epoch  0, batch  1596 | loss: 2.0676932MixupTrain:  epoch  0, batch  1597 | loss: 2.1538510MixupTrain:  epoch  0, batch  1598 | loss: 2.5665302MixupTrain:  epoch  0, batch  1599 | loss: 2.2449312MixupTrain:  epoch  0, batch  1600 | loss: 2.1151628MixupTrain:  epoch  0, batch  1601 | loss: 2.1795588MixupTrain:  epoch  0, batch  1602 | loss: 2.0721233MixupTrain:  epoch  0, batch  1603 | loss: 2.2931998MixupTrain:  epoch  0, batch  1604 | loss: 2.3835173MixupTrain:  epoch  0, batch  1605 | loss: 2.1298413MixupTrain:  epoch  0, batch  1606 | loss: 2.4938507MixupTrain:  epoch  0, batch  1607 | loss: 2.3169689MixupTrain:  epoch  0, batch  1608 | loss: 2.2194822MixupTrain:  epoch  0, batch  1609 | loss: 2.3533068MixupTrain:  epoch  0, batch  1610 | loss: 2.2992616MixupTrain:  epoch  0, batch  1611 | loss: 2.3263733MixupTrain:  epoch  0, batch  1612 | loss: 2.5781262MixupTrain:  epoch  0, batch  1613 | loss: 2.2541811MixupTrain:  epoch  0, batch  1614 | loss: 2.4074702MixupTrain:  epoch  0, batch  1615 | loss: 2.0420871MixupTrain:  epoch  0, batch  1616 | loss: 2.3220191MixupTrain:  epoch  0, batch  1617 | loss: 2.1531527MixupTrain:  epoch  0, batch  1618 | loss: 2.4740496MixupTrain:  epoch  0, batch  1619 | loss: 2.2179456MixupTrain:  epoch  0, batch  1620 | loss: 2.0999875MixupTrain:  epoch  0, batch  1621 | loss: 2.1973581MixupTrain:  epoch  0, batch  1622 | loss: 2.2624295MixupTrain:  epoch  0, batch  1623 | loss: 2.5114851MixupTrain:  epoch  0, batch  1624 | loss: 2.1362135MixupTrain:  epoch  0, batch  1625 | loss: 2.4780347MixupTrain:  epoch  0, batch  1626 | loss: 2.3266208MixupTrain:  epoch  0, batch  1627 | loss: 2.4770083MixupTrain:  epoch  0, batch  1628 | loss: 2.4056191MixupTrain:  epoch  0, batch  1629 | loss: 2.0879683MixupTrain:  epoch  0, batch  1630 | loss: 2.4646521MixupTrain:  epoch  0, batch  1631 | loss: 2.3347292MixupTrain:  epoch  0, batch  1632 | loss: 2.1131897MixupTrain:  epoch  0, batch  1633 | loss: 2.2785664MixupTrain:  epoch  0, batch  1634 | loss: 2.0864580MixupTrain:  epoch  0, batch  1635 | loss: 2.5088332MixupTrain:  epoch  0, batch  1636 | loss: 2.2433867MixupTrain:  epoch  0, batch  1637 | loss: 2.2553024MixupTrain:  epoch  0, batch  1638 | loss: 2.0686347MixupTrain:  epoch  0, batch  1639 | loss: 2.3484025MixupTrain:  epoch  0, batch  1640 | loss: 2.3166809MixupTrain:  epoch  0, batch  1641 | loss: 2.1651702MixupTrain:  epoch  0, batch  1642 | loss: 2.1181641MixupTrain:  epoch  0, batch  1643 | loss: 2.3072324MixupTrain:  epoch  0, batch  1644 | loss: 2.3866889MixupTrain:  epoch  0, batch  1645 | loss: 2.2454638MixupTrain:  epoch  0, batch  1646 | loss: 2.3508587MixupTrain:  epoch  0, batch  1647 | loss: 2.1312838MixupTrain:  epoch  0, batch  1648 | loss: 2.3527770MixupTrain:  epoch  0, batch  1649 | loss: 2.2655513MixupTrain:  epoch  0, batch  1650 | loss: 2.1853986MixupTrain:  epoch  0, batch  1651 | loss: 2.2230005MixupTrain:  epoch  0, batch  1652 | loss: 2.4172487MixupTrain:  epoch  0, batch  1653 | loss: 2.4295239MixupTrain:  epoch  0, batch  1654 | loss: 2.1610198MixupTrain:  epoch  0, batch  1655 | loss: 2.3343616MixupTrain:  epoch  0, batch  1656 | loss: 2.3505213MixupTrain:  epoch  0, batch  1657 | loss: 2.1980057MixupTrain:  epoch  0, batch  1658 | loss: 2.2199030MixupTrain:  epoch  0, batch  1659 | loss: 2.2193265MixupTrain:  epoch  0, batch  1660 | loss: 1.9829745MixupTrain:  epoch  0, batch  1661 | loss: 2.3379235MixupTrain:  epoch  0, batch  1662 | loss: 2.0409064MixupTrain:  epoch  0, batch  1663 | loss: 2.1774030MixupTrain:  epoch  0, batch  1664 | loss: 2.1675591MixupTrain:  epoch  0, batch  1665 | loss: 2.2803669MixupTrain:  epoch  0, batch  1666 | loss: 2.2548857MixupTrain:  epoch  0, batch  1667 | loss: 2.2652640MixupTrain:  epoch  0, batch  1668 | loss: 2.3238535MixupTrain:  epoch  0, batch  1669 | loss: 2.4091337MixupTrain:  epoch  0, batch  1670 | loss: 2.3270335MixupTrain:  epoch  0, batch  1671 | loss: 2.0637498MixupTrain:  epoch  0, batch  1672 | loss: 2.6330080MixupTrain:  epoch  0, batch  1673 | loss: 2.4017310MixupTrain:  epoch  0, batch  1674 | loss: 2.4083738MixupTrain:  epoch  0, batch  1675 | loss: 2.1771245MixupTrain:  epoch  0, batch  1676 | loss: 2.3435130MixupTrain:  epoch  0, batch  1677 | loss: 2.1586914MixupTrain:  epoch  0, batch  1678 | loss: 2.2388453MixupTrain:  epoch  0, batch  1679 | loss: 2.0763667MixupTrain:  epoch  0, batch  1680 | loss: 2.3951161MixupTrain:  epoch  0, batch  1681 | loss: 2.5140729MixupTrain:  epoch  0, batch  1682 | loss: 2.3561013MixupTrain:  epoch  0, batch  1683 | loss: 2.3804879MixupTrain:  epoch  0, batch  1684 | loss: 2.2860966MixupTrain:  epoch  0, batch  1685 | loss: 2.2575929MixupTrain:  epoch  0, batch  1686 | loss: 2.0924358MixupTrain:  epoch  0, batch  1687 | loss: 1.9679489MixupTrain:  epoch  0, batch  1688 | loss: 2.5140228MixupTrain:  epoch  0, batch  1689 | loss: 2.3483620MixupTrain:  epoch  0, batch  1690 | loss: 2.3883817MixupTrain:  epoch  0, batch  1691 | loss: 2.0122957MixupTrain:  epoch  0, batch  1692 | loss: 2.4746034MixupTrain:  epoch  0, batch  1693 | loss: 2.1382329MixupTrain:  epoch  0, batch  1694 | loss: 2.3745909MixupTrain:  epoch  0, batch  1695 | loss: 2.2534704MixupTrain:  epoch  0, batch  1696 | loss: 2.1026096MixupTrain:  epoch  0, batch  1697 | loss: 2.3828874MixupTrain:  epoch  0, batch  1698 | loss: 2.2882812MixupTrain:  epoch  0, batch  1699 | loss: 2.2727542MixupTrain:  epoch  0, batch  1700 | loss: 2.3406348MixupTrain:  epoch  0, batch  1701 | loss: 2.3256946MixupTrain:  epoch  0, batch  1702 | loss: 2.2995439MixupTrain:  epoch  0, batch  1703 | loss: 2.3865542MixupTrain:  epoch  0, batch  1704 | loss: 2.1144438MixupTrain:  epoch  0, batch  1705 | loss: 2.0632129MixupTrain:  epoch  0, batch  1706 | loss: 2.1153357MixupTrain:  epoch  0, batch  1707 | loss: 2.1938004MixupTrain:  epoch  0, batch  1708 | loss: 2.2868099MixupTrain:  epoch  0, batch  1709 | loss: 2.0528860MixupTrain:  epoch  0, batch  1710 | loss: 2.4536176MixupTrain:  epoch  0, batch  1711 | loss: 2.4323609MixupTrain:  epoch  0, batch  1712 | loss: 2.4259996MixupTrain:  epoch  0, batch  1713 | loss: 2.2539392MixupTrain:  epoch  0, batch  1714 | loss: 2.1670597MixupTrain:  epoch  0, batch  1715 | loss: 2.2002175MixupTrain:  epoch  0, batch  1716 | loss: 2.2063432MixupTrain:  epoch  0, batch  1717 | loss: 2.2909145MixupTrain:  epoch  0, batch  1718 | loss: 2.2706358MixupTrain:  epoch  0, batch  1719 | loss: 2.2989233MixupTrain:  epoch  0, batch  1720 | loss: 2.2134147MixupTrain:  epoch  0, batch  1721 | loss: 2.0299406MixupTrain:  epoch  0, batch  1722 | loss: 2.1956639MixupTrain:  epoch  0, batch  1723 | loss: 1.9825383MixupTrain:  epoch  0, batch  1724 | loss: 2.4686134MixupTrain:  epoch  0, batch  1725 | loss: 2.3495045MixupTrain:  epoch  0, batch  1726 | loss: 2.2268496MixupTrain:  epoch  0, batch  1727 | loss: 2.1762180MixupTrain:  epoch  0, batch  1728 | loss: 2.2142813MixupTrain:  epoch  0, batch  1729 | loss: 2.4522076MixupTrain:  epoch  0, batch  1730 | loss: 2.2800572MixupTrain:  epoch  0, batch  1731 | loss: 2.1146350MixupTrain:  epoch  0, batch  1732 | loss: 2.4276156MixupTrain:  epoch  0, batch  1733 | loss: 2.1998787MixupTrain:  epoch  0, batch  1734 | loss: 2.2689614MixupTrain:  epoch  0, batch  1735 | loss: 2.2731080MixupTrain:  epoch  0, batch  1736 | loss: 2.3134608MixupTrain:  epoch  0, batch  1737 | loss: 2.4418631MixupTrain:  epoch  0, batch  1738 | loss: 2.6257520MixupTrain:  epoch  0, batch  1739 | loss: 2.1169360MixupTrain:  epoch  0, batch  1740 | loss: 2.2449055MixupTrain:  epoch  0, batch  1741 | loss: 2.1669436MixupTrain:  epoch  0, batch  1742 | loss: 2.3902907MixupTrain:  epoch  0, batch  1743 | loss: 2.1624441MixupTrain:  epoch  0, batch  1744 | loss: 2.2034552MixupTrain:  epoch  0, batch  1745 | loss: 2.4868169MixupTrain:  epoch  0, batch  1746 | loss: 2.2789688MixupTrain:  epoch  0, batch  1747 | loss: 2.4302583MixupTrain:  epoch  0, batch  1748 | loss: 2.4727466MixupTrain:  epoch  0, batch  1749 | loss: 2.0756612MixupTrain:  epoch  0, batch  1750 | loss: 2.1921387MixupTrain:  epoch  0, batch  1751 | loss: 2.0105281MixupTrain:  epoch  0, batch  1752 | loss: 2.3687420MixupTrain:  epoch  0, batch  1753 | loss: 2.4687428MixupTrain:  epoch  0, batch  1754 | loss: 2.1989913MixupTrain:  epoch  0, batch  1755 | loss: 2.2857175MixupTrain:  epoch  0, batch  1756 | loss: 2.2990394MixupTrain:  epoch  0, batch  1757 | loss: 2.1509962MixupTrain:  epoch  0, batch  1758 | loss: 2.3455887MixupTrain:  epoch  0, batch  1759 | loss: 2.2639971MixupTrain:  epoch  0, batch  1760 | loss: 2.3743982MixupTrain:  epoch  0, batch  1761 | loss: 2.3082821MixupTrain:  epoch  0, batch  1762 | loss: 2.2838130MixupTrain:  epoch  0, batch  1763 | loss: 2.5226407MixupTrain:  epoch  0, batch  1764 | loss: 2.3569195MixupTrain:  epoch  0, batch  1765 | loss: 2.2277069MixupTrain:  epoch  0, batch  1766 | loss: 2.2825947MixupTrain:  epoch  0, batch  1767 | loss: 2.4327579MixupTrain:  epoch  0, batch  1768 | loss: 2.2540488MixupTrain:  epoch  0, batch  1769 | loss: 2.1269510MixupTrain:  epoch  0, batch  1770 | loss: 2.4757342MixupTrain:  epoch  0, batch  1771 | loss: 2.1390116MixupTrain:  epoch  0, batch  1772 | loss: 2.1486704MixupTrain:  epoch  0, batch  1773 | loss: 2.1905284MixupTrain:  epoch  0, batch  1774 | loss: 2.3731112MixupTrain:  epoch  0, batch  1775 | loss: 2.1666341MixupTrain:  epoch  0, batch  1776 | loss: 2.4933624MixupTrain:  epoch  0, batch  1777 | loss: 2.3474853MixupTrain:  epoch  0, batch  1778 | loss: 2.5974000MixupTrain:  epoch  0, batch  1779 | loss: 2.4807003MixupTrain:  epoch  0, batch  1780 | loss: 2.1872196MixupTrain:  epoch  0, batch  1781 | loss: 2.1567218MixupTrain:  epoch  0, batch  1782 | loss: 2.4807496MixupTrain:  epoch  0, batch  1783 | loss: 2.0670934MixupTrain:  epoch  0, batch  1784 | loss: 2.3783925MixupTrain:  epoch  0, batch  1785 | loss: 2.1237464MixupTrain:  epoch  0, batch  1786 | loss: 2.1750693MixupTrain:  epoch  0, batch  1787 | loss: 2.2748437MixupTrain:  epoch  0, batch  1788 | loss: 2.1970582MixupTrain:  epoch  0, batch  1789 | loss: 2.0639443MixupTrain:  epoch  0, batch  1790 | loss: 1.9966953MixupTrain:  epoch  0, batch  1791 | loss: 2.1978297MixupTrain:  epoch  0, batch  1792 | loss: 2.1514912MixupTrain:  epoch  0, batch  1793 | loss: 2.2678616MixupTrain:  epoch  0, batch  1794 | loss: 2.3267148MixupTrain:  epoch  0, batch  1795 | loss: 2.4029579MixupTrain:  epoch  0, batch  1796 | loss: 2.2065759MixupTrain:  epoch  0, batch  1797 | loss: 2.1364610MixupTrain:  epoch  0, batch  1798 | loss: 2.4500885MixupTrain:  epoch  0, batch  1799 | loss: 2.1183760MixupTrain:  epoch  0, batch  1800 | loss: 2.3493757MixupTrain:  epoch  0, batch  1801 | loss: 2.2140172MixupTrain:  epoch  0, batch  1802 | loss: 2.4486704MixupTrain:  epoch  0, batch  1803 | loss: 2.3284748MixupTrain:  epoch  0, batch  1804 | loss: 2.2582655MixupTrain:  epoch  0, batch  1805 | loss: 2.3031416MixupTrain:  epoch  0, batch  1806 | loss: 2.2704909MixupTrain:  epoch  0, batch  1807 | loss: 2.2212429MixupTrain:  epoch  0, batch  1808 | loss: 2.2458506MixupTrain:  epoch  0, batch  1809 | loss: 2.4888604MixupTrain:  epoch  0, batch  1810 | loss: 2.1892757MixupTrain:  epoch  0, batch  1811 | loss: 2.4619651MixupTrain:  epoch  0, batch  1812 | loss: 2.1078353MixupTrain:  epoch  0, batch  1813 | loss: 2.4735975MixupTrain:  epoch  0, batch  1814 | loss: 2.1768920MixupTrain:  epoch  0, batch  1815 | loss: 2.4287164MixupTrain:  epoch  0, batch  1816 | loss: 2.4260566MixupTrain:  epoch  0, batch  1817 | loss: 2.5441813MixupTrain:  epoch  0, batch  1818 | loss: 2.6364126MixupTrain:  epoch  0, batch  1819 | loss: 2.2701740MixupTrain:  epoch  0, batch  1820 | loss: 2.1589580MixupTrain:  epoch  0, batch  1821 | loss: 2.5735488MixupTrain:  epoch  0, batch  1822 | loss: 2.2354963MixupTrain:  epoch  0, batch  1823 | loss: 2.0802684MixupTrain:  epoch  0, batch  1824 | loss: 2.3124349MixupTrain:  epoch  0, batch  1825 | loss: 2.3026698MixupTrain:  epoch  0, batch  1826 | loss: 2.1241732MixupTrain:  epoch  0, batch  1827 | loss: 2.5758715MixupTrain:  epoch  0, batch  1828 | loss: 2.3364253MixupTrain:  epoch  0, batch  1829 | loss: 2.3169627MixupTrain:  epoch  0, batch  1830 | loss: 2.2696133MixupTrain:  epoch  0, batch  1831 | loss: 2.1062555MixupTrain:  epoch  0, batch  1832 | loss: 2.3490312MixupTrain:  epoch  0, batch  1833 | loss: 2.3709998MixupTrain:  epoch  0, batch  1834 | loss: 2.3036427MixupTrain:  epoch  0, batch  1835 | loss: 2.3995807MixupTrain:  epoch  0, batch  1836 | loss: 2.3128963MixupTrain:  epoch  0, batch  1837 | loss: 2.1944098MixupTrain:  epoch  0, batch  1838 | loss: 2.3629522MixupTrain:  epoch  0, batch  1839 | loss: 2.3071139MixupTrain:  epoch  0, batch  1840 | loss: 2.2877076MixupTrain:  epoch  0, batch  1841 | loss: 2.5141351MixupTrain:  epoch  0, batch  1842 | loss: 2.0967364MixupTrain:  epoch  0, batch  1843 | loss: 2.0591216MixupTrain:  epoch  0, batch  1844 | loss: 2.2245433MixupTrain:  epoch  0, batch  1845 | loss: 2.2182419MixupTrain:  epoch  0, batch  1846 | loss: 2.2565055MixupTrain:  epoch  0, batch  1847 | loss: 2.4921935MixupTrain:  epoch  0, batch  1848 | loss: 2.3642275MixupTrain:  epoch  0, batch  1849 | loss: 2.5402665MixupTrain:  epoch  0, batch  1850 | loss: 2.2927346MixupTrain:  epoch  0, batch  1851 | loss: 2.3850982MixupTrain:  epoch  0, batch  1852 | loss: 2.3620996MixupTrain:  epoch  0, batch  1853 | loss: 2.2072642MixupTrain:  epoch  0, batch  1854 | loss: 2.1133132MixupTrain:  epoch  0, batch  1855 | loss: 2.2690897MixupTrain:  epoch  0, batch  1856 | loss: 2.0826635MixupTrain:  epoch  0, batch  1857 | loss: 2.0044847MixupTrain:  epoch  0, batch  1858 | loss: 2.2914982MixupTrain:  epoch  0, batch  1859 | loss: 2.0159330MixupTrain:  epoch  0, batch  1860 | loss: 2.3515911MixupTrain:  epoch  0, batch  1861 | loss: 2.6144228MixupTrain:  epoch  0, batch  1862 | loss: 2.1221313MixupTrain:  epoch  0, batch  1863 | loss: 2.2835770MixupTrain:  epoch  0, batch  1864 | loss: 2.1772161MixupTrain:  epoch  0, batch  1865 | loss: 2.2262690MixupTrain:  epoch  0, batch  1866 | loss: 2.1726053MixupTrain:  epoch  0, batch  1867 | loss: 2.2717524MixupTrain:  epoch  0, batch  1868 | loss: 2.3106470MixupTrain:  epoch  0, batch  1869 | loss: 2.0623426MixupTrain:  epoch  0, batch  1870 | loss: 2.3783779MixupTrain:  epoch  0, batch  1871 | loss: 2.3693764MixupTrain:  epoch  0, batch  1872 | loss: 2.2266431MixupTrain:  epoch  0, batch  1873 | loss: 2.5166798MixupTrain:  epoch  0, batch  1874 | loss: 2.3221667MixupTrain:  epoch  0, batch  1875 | loss: 2.3668098MixupTrain:  epoch  0, batch  1876 | loss: 2.2170863MixupTrain:  epoch  0, batch  1877 | loss: 2.1765933MixupTrain:  epoch  0, batch  1878 | loss: 2.1412895MixupTrain:  epoch  0, batch  1879 | loss: 2.5194921MixupTrain:  epoch  0, batch  1880 | loss: 1.9419280MixupTrain:  epoch  0, batch  1881 | loss: 2.2203569MixupTrain:  epoch  0, batch  1882 | loss: 2.1934209MixupTrain:  epoch  0, batch  1883 | loss: 2.2170343MixupTrain:  epoch  0, batch  1884 | loss: 2.1578674MixupTrain:  epoch  0, batch  1885 | loss: 2.2555137MixupTrain:  epoch  0, batch  1886 | loss: 2.3926945MixupTrain:  epoch  0, batch  1887 | loss: 2.2185555MixupTrain:  epoch  0, batch  1888 | loss: 2.2547803MixupTrain:  epoch  0, batch  1889 | loss: 2.0949869MixupTrain:  epoch  0, batch  1890 | loss: 2.2092340MixupTrain:  epoch  0, batch  1891 | loss: 2.1587043MixupTrain:  epoch  0, batch  1892 | loss: 2.2694383MixupTrain:  epoch  0, batch  1893 | loss: 2.1984940MixupTrain:  epoch  0, batch  1894 | loss: 2.5238128MixupTrain:  epoch  0, batch  1895 | loss: 2.2424092MixupTrain:  epoch  0, batch  1896 | loss: 2.2595482MixupTrain:  epoch  0, batch  1897 | loss: 2.5222867MixupTrain:  epoch  0, batch  1898 | loss: 2.4198606MixupTrain:  epoch  0, batch  1899 | loss: 2.0533342MixupTrain:  epoch  0, batch  1900 | loss: 2.3616576MixupTrain:  epoch  0, batch  1901 | loss: 2.3085051MixupTrain:  epoch  0, batch  1902 | loss: 2.4172356MixupTrain:  epoch  0, batch  1903 | loss: 2.4047532MixupTrain:  epoch  0, batch  1904 | loss: 2.6595299MixupTrain:  epoch  0, batch  1905 | loss: 2.4072864MixupTrain:  epoch  0, batch  1906 | loss: 2.4996278MixupTrain:  epoch  0, batch  1907 | loss: 2.0390863MixupTrain:  epoch  0, batch  1908 | loss: 2.2279010MixupTrain:  epoch  0, batch  1909 | loss: 2.1953650MixupTrain:  epoch  0, batch  1910 | loss: 2.3713894MixupTrain:  epoch  0, batch  1911 | loss: 2.1031902MixupTrain:  epoch  0, batch  1912 | loss: 2.2440875MixupTrain:  epoch  0, batch  1913 | loss: 2.1203017MixupTrain:  epoch  0, batch  1914 | loss: 2.4873776MixupTrain:  epoch  0, batch  1915 | loss: 2.3995302MixupTrain:  epoch  0, batch  1916 | loss: 2.3176699MixupTrain:  epoch  0, batch  1917 | loss: 2.2353878MixupTrain:  epoch  0, batch  1918 | loss: 2.2989569MixupTrain:  epoch  0, batch  1919 | loss: 2.2277532MixupTrain:  epoch  0, batch  1920 | loss: 2.2738323MixupTrain:  epoch  0, batch  1921 | loss: 1.9752767MixupTrain:  epoch  0, batch  1922 | loss: 2.0780091MixupTrain:  epoch  0, batch  1923 | loss: 2.2427864MixupTrain:  epoch  0, batch  1924 | loss: 2.3882444MixupTrain:  epoch  0, batch  1925 | loss: 2.0695632MixupTrain:  epoch  0, batch  1926 | loss: 2.2695696MixupTrain:  epoch  0, batch  1927 | loss: 2.0616546MixupTrain:  epoch  0, batch  1928 | loss: 2.3191180MixupTrain:  epoch  0, batch  1929 | loss: 2.0007885MixupTrain:  epoch  0, batch  1930 | loss: 2.2289088MixupTrain:  epoch  0, batch  1931 | loss: 2.4723008MixupTrain:  epoch  0, batch  1932 | loss: 1.9359452MixupTrain:  epoch  0, batch  1933 | loss: 2.3036661MixupTrain:  epoch  0, batch  1934 | loss: 2.3704910MixupTrain:  epoch  0, batch  1935 | loss: 2.3956423MixupTrain:  epoch  0, batch  1936 | loss: 2.1989918MixupTrain:  epoch  0, batch  1937 | loss: 2.1552806MixupTrain:  epoch  0, batch  1938 | loss: 2.3386979MixupTrain:  epoch  0, batch  1939 | loss: 2.1692073MixupTrain:  epoch  0, batch  1940 | loss: 2.2845278MixupTrain:  epoch  0, batch  1941 | loss: 2.3770318MixupTrain:  epoch  0, batch  1942 | loss: 2.2212410MixupTrain:  epoch  0, batch  1943 | loss: 2.1568556MixupTrain:  epoch  0, batch  1944 | loss: 2.4743199MixupTrain:  epoch  0, batch  1945 | loss: 2.2707584MixupTrain:  epoch  0, batch  1946 | loss: 2.3776405MixupTrain:  epoch  0, batch  1947 | loss: 2.4406958MixupTrain:  epoch  0, batch  1948 | loss: 2.0731580MixupTrain:  epoch  0, batch  1949 | loss: 2.3452368MixupTrain:  epoch  0, batch  1950 | loss: 2.1199281MixupTrain:  epoch  0, batch  1951 | loss: 2.4737802MixupTrain:  epoch  0, batch  1952 | loss: 2.2948976MixupTrain:  epoch  0, batch  1953 | loss: 2.0094914MixupTrain:  epoch  0, batch  1954 | loss: 1.9928896MixupTrain:  epoch  0, batch  1955 | loss: 2.5761642MixupTrain:  epoch  0, batch  1956 | loss: 2.1767974MixupTrain:  epoch  0, batch  1957 | loss: 2.2594173MixupTrain:  epoch  0, batch  1958 | loss: 2.4840951MixupTrain:  epoch  0, batch  1959 | loss: 2.3863883MixupTrain:  epoch  0, batch  1960 | loss: 2.2748175MixupTrain:  epoch  0, batch  1961 | loss: 2.2151599MixupTrain:  epoch  0, batch  1962 | loss: 2.2163229MixupTrain:  epoch  0, batch  1963 | loss: 2.4481773MixupTrain:  epoch  0, batch  1964 | loss: 2.4801564MixupTrain:  epoch  0, batch  1965 | loss: 2.2418079MixupTrain:  epoch  0, batch  1966 | loss: 2.0142639MixupTrain:  epoch  0, batch  1967 | loss: 2.0655036MixupTrain:  epoch  0, batch  1968 | loss: 2.0781024MixupTrain:  epoch  0, batch  1969 | loss: 2.1545951MixupTrain:  epoch  0, batch  1970 | loss: 2.0694389MixupTrain:  epoch  0, batch  1971 | loss: 2.1362081MixupTrain:  epoch  0, batch  1972 | loss: 2.0772047MixupTrain:  epoch  0, batch  1973 | loss: 2.0125856MixupTrain:  epoch  0, batch  1974 | loss: 2.2327147MixupTrain:  epoch  0, batch  1975 | loss: 2.1684172MixupTrain:  epoch  0, batch  1976 | loss: 2.0216222MixupTrain:  epoch  0, batch  1977 | loss: 2.3702874MixupTrain:  epoch  0, batch  1978 | loss: 2.4716322MixupTrain:  epoch  0, batch  1979 | loss: 2.3632360MixupTrain:  epoch  0, batch  1980 | loss: 2.7524266MixupTrain:  epoch  0, batch  1981 | loss: 2.1681888MixupTrain:  epoch  0, batch  1982 | loss: 2.2013960MixupTrain:  epoch  0, batch  1983 | loss: 2.1641531MixupTrain:  epoch  0, batch  1984 | loss: 2.1430347MixupTrain:  epoch  0, batch  1985 | loss: 2.2103658MixupTrain:  epoch  0, batch  1986 | loss: 2.1952333MixupTrain:  epoch  0, batch  1987 | loss: 2.0463028MixupTrain:  epoch  0, batch  1988 | loss: 2.4043341MixupTrain:  epoch  0, batch  1989 | loss: 2.5672169MixupTrain:  epoch  0, batch  1990 | loss: 2.3293731MixupTrain:  epoch  0, batch  1991 | loss: 2.2583628MixupTrain:  epoch  0, batch  1992 | loss: 2.4053814MixupTrain:  epoch  0, batch  1993 | loss: 2.3359251MixupTrain:  epoch  0, batch  1994 | loss: 2.1968074MixupTrain:  epoch  0, batch  1995 | loss: 2.1185760MixupTrain:  epoch  0, batch  1996 | loss: 2.3542171MixupTrain:  epoch  0, batch  1997 | loss: 2.3898187MixupTrain:  epoch  0, batch  1998 | loss: 2.2049150MixupTrain:  epoch  0, batch  1999 | loss: 2.4088066MixupTrain:  epoch  0, batch  2000 | loss: 2.1618290MixupTrain:  epoch  0, batch  2001 | loss: 2.0638430MixupTrain:  epoch  0, batch  2002 | loss: 2.1125631MixupTrain:  epoch  0, batch  2003 | loss: 2.2771223MixupTrain:  epoch  0, batch  2004 | loss: 2.4455562MixupTrain:  epoch  0, batch  2005 | loss: 2.1284261MixupTrain:  epoch  0, batch  2006 | loss: 2.4248142MixupTrain:  epoch  0, batch  2007 | loss: 2.2235055MixupTrain:  epoch  0, batch  2008 | loss: 2.1725812MixupTrain:  epoch  0, batch  2009 | loss: 2.3988380MixupTrain:  epoch  0, batch  2010 | loss: 2.3226733MixupTrain:  epoch  0, batch  2011 | loss: 2.1624644MixupTrain:  epoch  0, batch  2012 | loss: 2.3749180MixupTrain:  epoch  0, batch  2013 | loss: 2.3170447MixupTrain:  epoch  0, batch  2014 | loss: 2.2134652MixupTrain:  epoch  0, batch  2015 | loss: 2.4012494MixupTrain:  epoch  0, batch  2016 | loss: 2.3450081MixupTrain:  epoch  0, batch  2017 | loss: 2.4063179MixupTrain:  epoch  0, batch  2018 | loss: 2.2834756MixupTrain:  epoch  0, batch  2019 | loss: 1.9833051MixupTrain:  epoch  0, batch  2020 | loss: 2.3803654MixupTrain:  epoch  0, batch  2021 | loss: 2.4637494MixupTrain:  epoch  0, batch  2022 | loss: 2.3224230MixupTrain:  epoch  0, batch  2023 | loss: 2.2195458MixupTrain:  epoch  0, batch  2024 | loss: 2.1384454MixupTrain:  epoch  0, batch  2025 | loss: 2.1843913MixupTrain:  epoch  0, batch  2026 | loss: 2.3063164MixupTrain:  epoch  0, batch  2027 | loss: 2.4726758MixupTrain:  epoch  0, batch  2028 | loss: 2.5191336MixupTrain:  epoch  0, batch  2029 | loss: 2.1539230MixupTrain:  epoch  0, batch  2030 | loss: 2.4187217MixupTrain:  epoch  0, batch  2031 | loss: 2.1814175MixupTrain:  epoch  0, batch  2032 | loss: 2.4382963MixupTrain:  epoch  0, batch  2033 | loss: 2.5713620MixupTrain:  epoch  0, batch  2034 | loss: 2.2468920MixupTrain:  epoch  0, batch  2035 | loss: 2.2812366MixupTrain:  epoch  0, batch  2036 | loss: 2.3928084MixupTrain:  epoch  0, batch  2037 | loss: 2.3627393MixupTrain:  epoch  0, batch  2038 | loss: 2.2456162MixupTrain:  epoch  0, batch  2039 | loss: 2.2842870MixupTrain:  epoch  0, batch  2040 | loss: 2.0893142MixupTrain:  epoch  0, batch  2041 | loss: 2.4869442MixupTrain:  epoch  0, batch  2042 | loss: 2.2496548MixupTrain:  epoch  0, batch  2043 | loss: 1.9761691MixupTrain:  epoch  0, batch  2044 | loss: 2.4172359MixupTrain:  epoch  0, batch  2045 | loss: 2.3761935MixupTrain:  epoch  0, batch  2046 | loss: 1.9819590MixupTrain:  epoch  0, batch  2047 | loss: 2.1945815MixupTrain:  epoch  0, batch  2048 | loss: 2.2433558MixupTrain:  epoch  0, batch  2049 | loss: 2.5257068MixupTrain:  epoch  0, batch  2050 | loss: 2.3205903MixupTrain:  epoch  0, batch  2051 | loss: 2.5564992MixupTrain:  epoch  0, batch  2052 | loss: 2.3387659MixupTrain:  epoch  0, batch  2053 | loss: 2.1464932MixupTrain:  epoch  0, batch  2054 | loss: 1.9466095MixupTrain:  epoch  0, batch  2055 | loss: 2.1723042MixupTrain:  epoch  0, batch  2056 | loss: 2.2202404MixupTrain:  epoch  0, batch  2057 | loss: 2.1049781MixupTrain:  epoch  0, batch  2058 | loss: 2.5716317MixupTrain:  epoch  0, batch  2059 | loss: 2.2378612MixupTrain:  epoch  0, batch  2060 | loss: 2.3199759MixupTrain:  epoch  0, batch  2061 | loss: 2.2806652MixupTrain:  epoch  0, batch  2062 | loss: 2.1380126MixupTrain:  epoch  0, batch  2063 | loss: 2.4748719MixupTrain:  epoch  0, batch  2064 | loss: 2.2078819MixupTrain:  epoch  0, batch  2065 | loss: 2.3510170MixupTrain:  epoch  0, batch  2066 | loss: 2.3443382MixupTrain:  epoch  0, batch  2067 | loss: 2.2668285MixupTrain:  epoch  0, batch  2068 | loss: 2.0949001MixupTrain:  epoch  0, batch  2069 | loss: 2.2383347MixupTrain:  epoch  0, batch  2070 | loss: 2.2746880MixupTrain:  epoch  0, batch  2071 | loss: 2.4158459MixupTrain:  epoch  0, batch  2072 | loss: 2.3349848MixupTrain:  epoch  0, batch  2073 | loss: 2.3600154MixupTrain:  epoch  0, batch  2074 | loss: 2.2134175MixupTrain:  epoch  0, batch  2075 | loss: 2.0051336MixupTrain:  epoch  0, batch  2076 | loss: 2.0895374MixupTrain:  epoch  0, batch  2077 | loss: 2.4113889MixupTrain:  epoch  0, batch  2078 | loss: 2.4105840MixupTrain:  epoch  0, batch  2079 | loss: 2.2867332MixupTrain:  epoch  0, batch  2080 | loss: 2.2307954MixupTrain:  epoch  0, batch  2081 | loss: 2.4132357MixupTrain:  epoch  0, batch  2082 | loss: 2.2740850MixupTrain:  epoch  0, batch  2083 | loss: 2.4470186MixupTrain:  epoch  0, batch  2084 | loss: 2.3012483MixupTrain:  epoch  0, batch  2085 | loss: 2.0966179MixupTrain:  epoch  0, batch  2086 | loss: 2.1248732MixupTrain:  epoch  0, batch  2087 | loss: 2.3848608MixupTrain:  epoch  0, batch  2088 | loss: 2.4805040MixupTrain:  epoch  0, batch  2089 | loss: 2.3044868MixupTrain:  epoch  0, batch  2090 | loss: 2.4333036MixupTrain:  epoch  0, batch  2091 | loss: 2.1374907MixupTrain:  epoch  0, batch  2092 | loss: 2.3346567MixupTrain:  epoch  0, batch  2093 | loss: 2.4191115MixupTrain:  epoch  0, batch  2094 | loss: 2.1487124MixupTrain:  epoch  0, batch  2095 | loss: 2.3695245MixupTrain:  epoch  0, batch  2096 | loss: 2.3204226MixupTrain:  epoch  0, batch  2097 | loss: 2.6241527MixupTrain:  epoch  0, batch  2098 | loss: 2.3816571MixupTrain:  epoch  0, batch  2099 | loss: 2.4953942MixupTrain:  epoch  0, batch  2100 | loss: 2.1827946MixupTrain:  epoch  0, batch  2101 | loss: 2.0764022MixupTrain:  epoch  0, batch  2102 | loss: 2.2217669MixupTrain:  epoch  0, batch  2103 | loss: 2.3011556MixupTrain:  epoch  0, batch  2104 | loss: 2.2798429MixupTrain:  epoch  0, batch  2105 | loss: 2.3918107MixupTrain:  epoch  0, batch  2106 | loss: 2.2016070MixupTrain:  epoch  0, batch  2107 | loss: 2.4605851MixupTrain:  epoch  0, batch  2108 | loss: 2.1617203MixupTrain:  epoch  0, batch  2109 | loss: 2.6335568MixupTrain:  epoch  0, batch  2110 | loss: 2.2688944MixupTrain:  epoch  0, batch  2111 | loss: 2.4687300MixupTrain:  epoch  0, batch  2112 | loss: 2.3651767MixupTrain:  epoch  0, batch  2113 | loss: 2.3433113MixupTrain:  epoch  0, batch  2114 | loss: 2.1216836MixupTrain:  epoch  0, batch  2115 | loss: 2.2120938MixupTrain:  epoch  0, batch  2116 | loss: 2.4927559MixupTrain:  epoch  0, batch  2117 | loss: 2.2301965MixupTrain:  epoch  0, batch  2118 | loss: 2.1069028MixupTrain:  epoch  0, batch  2119 | loss: 2.4610071MixupTrain:  epoch  0, batch  2120 | loss: 2.2204068MixupTrain:  epoch  0, batch  2121 | loss: 2.1344185MixupTrain:  epoch  0, batch  2122 | loss: 2.3796339MixupTrain:  epoch  0, batch  2123 | loss: 2.1725104MixupTrain:  epoch  0, batch  2124 | loss: 2.5991077MixupTrain:  epoch  0, batch  2125 | loss: 2.0008821MixupTrain:  epoch  0, batch  2126 | loss: 2.2050481MixupTrain:  epoch  0, batch  2127 | loss: 2.2170386MixupTrain:  epoch  0, batch  2128 | loss: 2.2572629MixupTrain:  epoch  0, batch  2129 | loss: 2.3042426MixupTrain:  epoch  0, batch  2130 | loss: 2.0614467MixupTrain:  epoch  0, batch  2131 | loss: 2.1197720MixupTrain:  epoch  0, batch  2132 | loss: 2.1272631MixupTrain:  epoch  0, batch  2133 | loss: 2.4123659MixupTrain:  epoch  0, batch  2134 | loss: 2.0491762MixupTrain:  epoch  0, batch  2135 | loss: 2.1569211MixupTrain:  epoch  0, batch  2136 | loss: 2.1549969MixupTrain:  epoch  0, batch  2137 | loss: 2.3911331MixupTrain:  epoch  0, batch  2138 | loss: 2.1572278MixupTrain:  epoch  0, batch  2139 | loss: 2.0133469MixupTrain:  epoch  0, batch  2140 | loss: 2.1808643MixupTrain:  epoch  0, batch  2141 | loss: 2.3924341MixupTrain:  epoch  0, batch  2142 | loss: 2.3170609MixupTrain:  epoch  0, batch  2143 | loss: 2.1262980MixupTrain:  epoch  0, batch  2144 | loss: 2.3192239MixupTrain:  epoch  0, batch  2145 | loss: 1.9915073MixupTrain:  epoch  0, batch  2146 | loss: 2.0471611MixupTrain:  epoch  0, batch  2147 | loss: 2.3431439MixupTrain:  epoch  0, batch  2148 | loss: 2.3802280MixupTrain:  epoch  0, batch  2149 | loss: 2.2212777MixupTrain:  epoch  0, batch  2150 | loss: 2.1350133MixupTrain:  epoch  0, batch  2151 | loss: 2.3324318MixupTrain:  epoch  0, batch  2152 | loss: 2.4248309MixupTrain:  epoch  0, batch  2153 | loss: 2.0806878MixupTrain:  epoch  0, batch  2154 | loss: 2.2381492MixupTrain:  epoch  0, batch  2155 | loss: 2.2891815MixupTrain:  epoch  0, batch  2156 | loss: 2.2622848MixupTrain:  epoch  0, batch  2157 | loss: 2.1337695MixupTrain:  epoch  0, batch  2158 | loss: 2.4981279MixupTrain:  epoch  0, batch  2159 | loss: 2.2827051MixupTrain:  epoch  0, batch  2160 | loss: 2.2760804MixupTrain:  epoch  0, batch  2161 | loss: 2.5722327MixupTrain:  epoch  0, batch  2162 | loss: 2.2196038MixupTrain:  epoch  0, batch  2163 | loss: 2.6474667MixupTrain:  epoch  0, batch  2164 | loss: 2.3424823MixupTrain:  epoch  0, batch  2165 | loss: 2.2202260MixupTrain:  epoch  0, batch  2166 | loss: 2.2903261MixupTrain:  epoch  0, batch  2167 | loss: 2.2521365MixupTrain:  epoch  0, batch  2168 | loss: 2.0553780MixupTrain:  epoch  0, batch  2169 | loss: 2.4344749MixupTrain:  epoch  0, batch  2170 | loss: 2.1988461MixupTrain:  epoch  0, batch  2171 | loss: 2.2588420MixupTrain:  epoch  0, batch  2172 | loss: 2.4080081MixupTrain:  epoch  0, batch  2173 | loss: 2.3385847MixupTrain:  epoch  0, batch  2174 | loss: 2.3840022MixupTrain:  epoch  0, batch  2175 | loss: 2.4416876MixupTrain:  epoch  0, batch  2176 | loss: 2.5213606MixupTrain:  epoch  0, batch  2177 | loss: 2.1105938MixupTrain:  epoch  0, batch  2178 | loss: 2.0413160MixupTrain:  epoch  0, batch  2179 | loss: 2.2691860MixupTrain:  epoch  0, batch  2180 | loss: 2.2372713MixupTrain:  epoch  0, batch  2181 | loss: 2.0574672MixupTrain:  epoch  0, batch  2182 | loss: 2.4371338MixupTrain:  epoch  0, batch  2183 | loss: 2.2979591MixupTrain:  epoch  0, batch  2184 | loss: 2.1219187MixupTrain:  epoch  0, batch  2185 | loss: 2.3675652MixupTrain:  epoch  0, batch  2186 | loss: 2.1678092MixupTrain:  epoch  0, batch  2187 | loss: 2.2696023MixupTrain:  epoch  0, batch  2188 | loss: 2.0433924MixupTrain:  epoch  0, batch  2189 | loss: 2.3023496MixupTrain:  epoch  0, batch  2190 | loss: 2.4627440MixupTrain:  epoch  0, batch  2191 | loss: 2.0537486MixupTrain:  epoch  0, batch  2192 | loss: 2.0770791MixupTrain:  epoch  0, batch  2193 | loss: 2.3765874MixupTrain:  epoch  0, batch  2194 | loss: 2.0466566MixupTrain:  epoch  0, batch  2195 | loss: 2.3790395MixupTrain:  epoch  0, batch  2196 | loss: 2.3251576MixupTrain:  epoch  0, batch  2197 | loss: 2.1540782MixupTrain:  epoch  0, batch  2198 | loss: 2.1527529MixupTrain:  epoch  0, batch  2199 | loss: 2.5571923MixupTrain:  epoch  0, batch  2200 | loss: 2.3058982MixupTrain:  epoch  0, batch  2201 | loss: 2.1471348MixupTrain:  epoch  0, batch  2202 | loss: 2.2409146MixupTrain:  epoch  0, batch  2203 | loss: 2.3081443MixupTrain:  epoch  0, batch  2204 | loss: 1.9514542MixupTrain:  epoch  0, batch  2205 | loss: 2.3403051MixupTrain:  epoch  0, batch  2206 | loss: 2.1603284MixupTrain:  epoch  0, batch  2207 | loss: 2.4794967MixupTrain:  epoch  0, batch  2208 | loss: 2.2400999MixupTrain:  epoch  0, batch  2209 | loss: 2.1870031MixupTrain:  epoch  0, batch  2210 | loss: 2.4283361MixupTrain:  epoch  0, batch  2211 | loss: 2.4072037MixupTrain:  epoch  0, batch  2212 | loss: 2.3096204MixupTrain:  epoch  0, batch  2213 | loss: 2.0660124MixupTrain:  epoch  0, batch  2214 | loss: 2.1896963MixupTrain:  epoch  0, batch  2215 | loss: 2.4742553MixupTrain:  epoch  0, batch  2216 | loss: 2.1637208MixupTrain:  epoch  0, batch  2217 | loss: 2.2755485MixupTrain:  epoch  0, batch  2218 | loss: 2.5771778MixupTrain:  epoch  0, batch  2219 | loss: 2.3669477MixupTrain:  epoch  0, batch  2220 | loss: 2.2451594MixupTrain:  epoch  0, batch  2221 | loss: 2.2225826MixupTrain:  epoch  0, batch  2222 | loss: 2.0902605MixupTrain:  epoch  0, batch  2223 | loss: 2.1393409MixupTrain:  epoch  0, batch  2224 | loss: 2.4371271MixupTrain:  epoch  0, batch  2225 | loss: 2.1638308MixupTrain:  epoch  0, batch  2226 | loss: 2.3032517MixupTrain:  epoch  0, batch  2227 | loss: 2.2502589MixupTrain:  epoch  0, batch  2228 | loss: 2.2652488MixupTrain:  epoch  0, batch  2229 | loss: 2.0989919MixupTrain:  epoch  0, batch  2230 | loss: 2.1878538MixupTrain:  epoch  0, batch  2231 | loss: 2.5495143MixupTrain:  epoch  0, batch  2232 | loss: 2.3263688MixupTrain:  epoch  0, batch  2233 | loss: 2.3123574MixupTrain:  epoch  0, batch  2234 | loss: 2.3380027MixupTrain:  epoch  0, batch  2235 | loss: 2.5451946
MemoryTrain:  epoch  0, batch     0 | loss: 1.7943871MemoryTrain:  epoch  0, batch     1 | loss: 2.3796263MemoryTrain:  epoch  0, batch     2 | loss: 2.0877781MemoryTrain:  epoch  0, batch     3 | loss: 2.8440509MemoryTrain:  epoch  0, batch     4 | loss: 2.6737390MemoryTrain:  epoch  0, batch     5 | loss: 2.8161850MemoryTrain:  epoch  0, batch     6 | loss: 2.3553562MemoryTrain:  epoch  0, batch     7 | loss: 3.2039685MemoryTrain:  epoch  0, batch     8 | loss: 2.1801996MemoryTrain:  epoch  0, batch     9 | loss: 2.5085046MemoryTrain:  epoch  0, batch    10 | loss: 2.2746418MemoryTrain:  epoch  0, batch    11 | loss: 2.4852238MemoryTrain:  epoch  0, batch    12 | loss: 2.1248274MemoryTrain:  epoch  0, batch    13 | loss: 2.1422267MemoryTrain:  epoch  0, batch    14 | loss: 2.3688941MemoryTrain:  epoch  0, batch    15 | loss: 1.9224758MemoryTrain:  epoch  1, batch     0 | loss: 1.8136179MemoryTrain:  epoch  1, batch     1 | loss: 1.8405572MemoryTrain:  epoch  1, batch     2 | loss: 1.8272326MemoryTrain:  epoch  1, batch     3 | loss: 1.8076320MemoryTrain:  epoch  1, batch     4 | loss: 1.8077047MemoryTrain:  epoch  1, batch     5 | loss: 1.8380477MemoryTrain:  epoch  1, batch     6 | loss: 1.8396406MemoryTrain:  epoch  1, batch     7 | loss: 1.8165154MemoryTrain:  epoch  1, batch     8 | loss: 1.8211454MemoryTrain:  epoch  1, batch     9 | loss: 1.8121800MemoryTrain:  epoch  1, batch    10 | loss: 1.8122679MemoryTrain:  epoch  1, batch    11 | loss: 1.8292994MemoryTrain:  epoch  1, batch    12 | loss: 1.8300947MemoryTrain:  epoch  1, batch    13 | loss: 1.8400697MemoryTrain:  epoch  1, batch    14 | loss: 1.8274641MemoryTrain:  epoch  1, batch    15 | loss: 1.8227171MemoryTrain:  epoch  2, batch     0 | loss: 1.8172641MemoryTrain:  epoch  2, batch     1 | loss: 1.8097613MemoryTrain:  epoch  2, batch     2 | loss: 1.8136957MemoryTrain:  epoch  2, batch     3 | loss: 1.8246841MemoryTrain:  epoch  2, batch     4 | loss: 1.8099245MemoryTrain:  epoch  2, batch     5 | loss: 1.8274109MemoryTrain:  epoch  2, batch     6 | loss: 1.8362212MemoryTrain:  epoch  2, batch     7 | loss: 1.8112785MemoryTrain:  epoch  2, batch     8 | loss: 1.8372827MemoryTrain:  epoch  2, batch     9 | loss: 1.8078769MemoryTrain:  epoch  2, batch    10 | loss: 1.8074317MemoryTrain:  epoch  2, batch    11 | loss: 1.8070590MemoryTrain:  epoch  2, batch    12 | loss: 1.8404980MemoryTrain:  epoch  2, batch    13 | loss: 1.8049071MemoryTrain:  epoch  2, batch    14 | loss: 1.8062121MemoryTrain:  epoch  2, batch    15 | loss: 1.8095870MemoryTrain:  epoch  3, batch     0 | loss: 1.8438151MemoryTrain:  epoch  3, batch     1 | loss: 1.8084631MemoryTrain:  epoch  3, batch     2 | loss: 1.8624818MemoryTrain:  epoch  3, batch     3 | loss: 1.8054821MemoryTrain:  epoch  3, batch     4 | loss: 1.8040593MemoryTrain:  epoch  3, batch     5 | loss: 1.8060282MemoryTrain:  epoch  3, batch     6 | loss: 1.8071353MemoryTrain:  epoch  3, batch     7 | loss: 1.8084779MemoryTrain:  epoch  3, batch     8 | loss: 1.8081534MemoryTrain:  epoch  3, batch     9 | loss: 1.8090960MemoryTrain:  epoch  3, batch    10 | loss: 1.8072631MemoryTrain:  epoch  3, batch    11 | loss: 1.8102778MemoryTrain:  epoch  3, batch    12 | loss: 1.8074528MemoryTrain:  epoch  3, batch    13 | loss: 1.8054112MemoryTrain:  epoch  3, batch    14 | loss: 1.8030992MemoryTrain:  epoch  3, batch    15 | loss: 1.8058532MemoryTrain:  epoch  4, batch     0 | loss: 1.8048806MemoryTrain:  epoch  4, batch     1 | loss: 1.8071332MemoryTrain:  epoch  4, batch     2 | loss: 1.8130002MemoryTrain:  epoch  4, batch     3 | loss: 1.8062365MemoryTrain:  epoch  4, batch     4 | loss: 1.8134668MemoryTrain:  epoch  4, batch     5 | loss: 1.8089557MemoryTrain:  epoch  4, batch     6 | loss: 1.8096097MemoryTrain:  epoch  4, batch     7 | loss: 1.8051808MemoryTrain:  epoch  4, batch     8 | loss: 1.8073974MemoryTrain:  epoch  4, batch     9 | loss: 1.8053944MemoryTrain:  epoch  4, batch    10 | loss: 1.8073798MemoryTrain:  epoch  4, batch    11 | loss: 1.8029113MemoryTrain:  epoch  4, batch    12 | loss: 1.8099360MemoryTrain:  epoch  4, batch    13 | loss: 1.8051789MemoryTrain:  epoch  4, batch    14 | loss: 1.8055999MemoryTrain:  epoch  4, batch    15 | loss: 1.8024063MemoryTrain:  epoch  5, batch     0 | loss: 1.8050225MemoryTrain:  epoch  5, batch     1 | loss: 1.8091069MemoryTrain:  epoch  5, batch     2 | loss: 1.8063507MemoryTrain:  epoch  5, batch     3 | loss: 1.8091719MemoryTrain:  epoch  5, batch     4 | loss: 1.8055239MemoryTrain:  epoch  5, batch     5 | loss: 1.8079958MemoryTrain:  epoch  5, batch     6 | loss: 1.8052381MemoryTrain:  epoch  5, batch     7 | loss: 1.8067780MemoryTrain:  epoch  5, batch     8 | loss: 1.8049793MemoryTrain:  epoch  5, batch     9 | loss: 1.8082485MemoryTrain:  epoch  5, batch    10 | loss: 1.8047631MemoryTrain:  epoch  5, batch    11 | loss: 1.8044137MemoryTrain:  epoch  5, batch    12 | loss: 1.8047260MemoryTrain:  epoch  5, batch    13 | loss: 1.8114471MemoryTrain:  epoch  5, batch    14 | loss: 1.8056035MemoryTrain:  epoch  5, batch    15 | loss: 1.8050259MemoryTrain:  epoch  6, batch     0 | loss: 1.8091120MemoryTrain:  epoch  6, batch     1 | loss: 1.8058774MemoryTrain:  epoch  6, batch     2 | loss: 1.8114436MemoryTrain:  epoch  6, batch     3 | loss: 1.8045809MemoryTrain:  epoch  6, batch     4 | loss: 1.8054883MemoryTrain:  epoch  6, batch     5 | loss: 1.8054900MemoryTrain:  epoch  6, batch     6 | loss: 1.8072869MemoryTrain:  epoch  6, batch     7 | loss: 1.8063318MemoryTrain:  epoch  6, batch     8 | loss: 1.8106666MemoryTrain:  epoch  6, batch     9 | loss: 1.8082798MemoryTrain:  epoch  6, batch    10 | loss: 1.8055668MemoryTrain:  epoch  6, batch    11 | loss: 1.8013543MemoryTrain:  epoch  6, batch    12 | loss: 1.8049536MemoryTrain:  epoch  6, batch    13 | loss: 1.8100760MemoryTrain:  epoch  6, batch    14 | loss: 1.8044382MemoryTrain:  epoch  6, batch    15 | loss: 1.8055575MemoryTrain:  epoch  7, batch     0 | loss: 1.8049915MemoryTrain:  epoch  7, batch     1 | loss: 1.8034381MemoryTrain:  epoch  7, batch     2 | loss: 1.8087432MemoryTrain:  epoch  7, batch     3 | loss: 1.8086069MemoryTrain:  epoch  7, batch     4 | loss: 1.8066794MemoryTrain:  epoch  7, batch     5 | loss: 1.8035469MemoryTrain:  epoch  7, batch     6 | loss: 1.8034933MemoryTrain:  epoch  7, batch     7 | loss: 1.8002429MemoryTrain:  epoch  7, batch     8 | loss: 1.8027177MemoryTrain:  epoch  7, batch     9 | loss: 1.8060179MemoryTrain:  epoch  7, batch    10 | loss: 1.8017524MemoryTrain:  epoch  7, batch    11 | loss: 1.8028057MemoryTrain:  epoch  7, batch    12 | loss: 1.8038238MemoryTrain:  epoch  7, batch    13 | loss: 1.8034289MemoryTrain:  epoch  7, batch    14 | loss: 1.8031330MemoryTrain:  epoch  7, batch    15 | loss: 1.8046589MemoryTrain:  epoch  8, batch     0 | loss: 1.8032171MemoryTrain:  epoch  8, batch     1 | loss: 1.8080362MemoryTrain:  epoch  8, batch     2 | loss: 1.8081459MemoryTrain:  epoch  8, batch     3 | loss: 1.8071074MemoryTrain:  epoch  8, batch     4 | loss: 1.8026969MemoryTrain:  epoch  8, batch     5 | loss: 1.8065044MemoryTrain:  epoch  8, batch     6 | loss: 1.8049556MemoryTrain:  epoch  8, batch     7 | loss: 1.8027830MemoryTrain:  epoch  8, batch     8 | loss: 1.8040617MemoryTrain:  epoch  8, batch     9 | loss: 1.8032424MemoryTrain:  epoch  8, batch    10 | loss: 1.8064140MemoryTrain:  epoch  8, batch    11 | loss: 1.8103637MemoryTrain:  epoch  8, batch    12 | loss: 1.8055909MemoryTrain:  epoch  8, batch    13 | loss: 1.8073111MemoryTrain:  epoch  8, batch    14 | loss: 1.8081696MemoryTrain:  epoch  8, batch    15 | loss: 1.8028467MemoryTrain:  epoch  9, batch     0 | loss: 1.8053019MemoryTrain:  epoch  9, batch     1 | loss: 1.8043205MemoryTrain:  epoch  9, batch     2 | loss: 1.8020902MemoryTrain:  epoch  9, batch     3 | loss: 1.8079534MemoryTrain:  epoch  9, batch     4 | loss: 1.8032272MemoryTrain:  epoch  9, batch     5 | loss: 1.8055086MemoryTrain:  epoch  9, batch     6 | loss: 1.8061718MemoryTrain:  epoch  9, batch     7 | loss: 1.8074007MemoryTrain:  epoch  9, batch     8 | loss: 1.8061144MemoryTrain:  epoch  9, batch     9 | loss: 1.8026330MemoryTrain:  epoch  9, batch    10 | loss: 1.8055930MemoryTrain:  epoch  9, batch    11 | loss: 1.8075378MemoryTrain:  epoch  9, batch    12 | loss: 1.8057101MemoryTrain:  epoch  9, batch    13 | loss: 1.8047366MemoryTrain:  epoch  9, batch    14 | loss: 1.8041763MemoryTrain:  epoch  9, batch    15 | loss: 1.8090042
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 87.50%   [EVAL] batch:    2 | acc: 81.25%,  total acc: 85.42%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 85.94%   [EVAL] batch:    4 | acc: 75.00%,  total acc: 83.75%   [EVAL] batch:    5 | acc: 68.75%,  total acc: 81.25%   [EVAL] batch:    6 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    7 | acc: 87.50%,  total acc: 82.03%   [EVAL] batch:    8 | acc: 93.75%,  total acc: 83.33%   [EVAL] batch:    9 | acc: 100.00%,  total acc: 85.00%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 85.80%   [EVAL] batch:   11 | acc: 100.00%,  total acc: 86.98%   [EVAL] batch:   12 | acc: 100.00%,  total acc: 87.98%   [EVAL] batch:   13 | acc: 100.00%,  total acc: 88.84%   [EVAL] batch:   14 | acc: 100.00%,  total acc: 89.58%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 90.23%   [EVAL] batch:   16 | acc: 100.00%,  total acc: 90.81%   [EVAL] batch:   17 | acc: 25.00%,  total acc: 87.15%   
[EVAL] batch:    0 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:    1 | acc: 12.50%,  total acc: 9.38%   [EVAL] batch:    2 | acc: 18.75%,  total acc: 12.50%   [EVAL] batch:    3 | acc: 6.25%,  total acc: 10.94%   [EVAL] batch:    4 | acc: 18.75%,  total acc: 12.50%   [EVAL] batch:    5 | acc: 25.00%,  total acc: 14.58%   [EVAL] batch:    6 | acc: 43.75%,  total acc: 18.75%   [EVAL] batch:    7 | acc: 50.00%,  total acc: 22.66%   [EVAL] batch:    8 | acc: 62.50%,  total acc: 27.08%   [EVAL] batch:    9 | acc: 37.50%,  total acc: 28.12%   [EVAL] batch:   10 | acc: 37.50%,  total acc: 28.98%   [EVAL] batch:   11 | acc: 50.00%,  total acc: 30.73%   [EVAL] batch:   12 | acc: 18.75%,  total acc: 29.81%   [EVAL] batch:   13 | acc: 25.00%,  total acc: 29.46%   [EVAL] batch:   14 | acc: 56.25%,  total acc: 31.25%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 32.81%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 35.29%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 36.81%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 38.16%   [EVAL] batch:   19 | acc: 81.25%,  total acc: 40.31%   [EVAL] batch:   20 | acc: 81.25%,  total acc: 42.26%   [EVAL] batch:   21 | acc: 68.75%,  total acc: 43.47%   [EVAL] batch:   22 | acc: 68.75%,  total acc: 44.57%   [EVAL] batch:   23 | acc: 87.50%,  total acc: 46.35%   [EVAL] batch:   24 | acc: 100.00%,  total acc: 48.50%   [EVAL] batch:   25 | acc: 81.25%,  total acc: 49.76%   [EVAL] batch:   26 | acc: 50.00%,  total acc: 49.77%   [EVAL] batch:   27 | acc: 56.25%,  total acc: 50.00%   [EVAL] batch:   28 | acc: 25.00%,  total acc: 49.14%   [EVAL] batch:   29 | acc: 31.25%,  total acc: 48.54%   [EVAL] batch:   30 | acc: 50.00%,  total acc: 48.59%   [EVAL] batch:   31 | acc: 31.25%,  total acc: 48.05%   [EVAL] batch:   32 | acc: 56.25%,  total acc: 48.30%   [EVAL] batch:   33 | acc: 12.50%,  total acc: 47.24%   [EVAL] batch:   34 | acc: 0.00%,  total acc: 45.89%   [EVAL] batch:   35 | acc: 0.00%,  total acc: 44.62%   [EVAL] batch:   36 | acc: 0.00%,  total acc: 43.41%   [EVAL] batch:   37 | acc: 0.00%,  total acc: 42.27%   [EVAL] batch:   38 | acc: 6.25%,  total acc: 41.35%   [EVAL] batch:   39 | acc: 50.00%,  total acc: 41.56%   [EVAL] batch:   40 | acc: 50.00%,  total acc: 41.77%   [EVAL] batch:   41 | acc: 62.50%,  total acc: 42.26%   [EVAL] batch:   42 | acc: 50.00%,  total acc: 42.44%   [EVAL] batch:   43 | acc: 31.25%,  total acc: 42.19%   [EVAL] batch:   44 | acc: 43.75%,  total acc: 42.22%   [EVAL] batch:   45 | acc: 31.25%,  total acc: 41.98%   [EVAL] batch:   46 | acc: 50.00%,  total acc: 42.15%   [EVAL] batch:   47 | acc: 81.25%,  total acc: 42.97%   [EVAL] batch:   48 | acc: 43.75%,  total acc: 42.98%   [EVAL] batch:   49 | acc: 75.00%,  total acc: 43.62%   [EVAL] batch:   50 | acc: 56.25%,  total acc: 43.87%   [EVAL] batch:   51 | acc: 81.25%,  total acc: 44.59%   [EVAL] batch:   52 | acc: 81.25%,  total acc: 45.28%   [EVAL] batch:   53 | acc: 37.50%,  total acc: 45.14%   [EVAL] batch:   54 | acc: 31.25%,  total acc: 44.89%   [EVAL] batch:   55 | acc: 43.75%,  total acc: 44.87%   [EVAL] batch:   56 | acc: 56.25%,  total acc: 45.07%   [EVAL] batch:   57 | acc: 81.25%,  total acc: 45.69%   [EVAL] batch:   58 | acc: 93.75%,  total acc: 46.50%   [EVAL] batch:   59 | acc: 93.75%,  total acc: 47.29%   [EVAL] batch:   60 | acc: 18.75%,  total acc: 46.82%   [EVAL] batch:   61 | acc: 0.00%,  total acc: 46.07%   [EVAL] batch:   62 | acc: 0.00%,  total acc: 45.34%   [EVAL] batch:   63 | acc: 0.00%,  total acc: 44.63%   [EVAL] batch:   64 | acc: 31.25%,  total acc: 44.42%   [EVAL] batch:   65 | acc: 25.00%,  total acc: 44.13%   [EVAL] batch:   66 | acc: 0.00%,  total acc: 43.47%   [EVAL] batch:   67 | acc: 25.00%,  total acc: 43.20%   [EVAL] batch:   68 | acc: 0.00%,  total acc: 42.57%   [EVAL] batch:   69 | acc: 12.50%,  total acc: 42.14%   [EVAL] batch:   70 | acc: 18.75%,  total acc: 41.81%   [EVAL] batch:   71 | acc: 18.75%,  total acc: 41.49%   [EVAL] batch:   72 | acc: 56.25%,  total acc: 41.70%   [EVAL] batch:   73 | acc: 56.25%,  total acc: 41.89%   [EVAL] batch:   74 | acc: 68.75%,  total acc: 42.25%   [EVAL] batch:   75 | acc: 87.50%,  total acc: 42.85%   [EVAL] batch:   76 | acc: 62.50%,  total acc: 43.10%   [EVAL] batch:   77 | acc: 75.00%,  total acc: 43.51%   [EVAL] batch:   78 | acc: 68.75%,  total acc: 43.83%   [EVAL] batch:   79 | acc: 100.00%,  total acc: 44.53%   [EVAL] batch:   80 | acc: 100.00%,  total acc: 45.22%   [EVAL] batch:   81 | acc: 100.00%,  total acc: 45.88%   [EVAL] batch:   82 | acc: 87.50%,  total acc: 46.39%   [EVAL] batch:   83 | acc: 81.25%,  total acc: 46.80%   [EVAL] batch:   84 | acc: 31.25%,  total acc: 46.62%   [EVAL] batch:   85 | acc: 25.00%,  total acc: 46.37%   [EVAL] batch:   86 | acc: 31.25%,  total acc: 46.19%   [EVAL] batch:   87 | acc: 87.50%,  total acc: 46.66%   [EVAL] batch:   88 | acc: 93.75%,  total acc: 47.19%   [EVAL] batch:   89 | acc: 100.00%,  total acc: 47.78%   [EVAL] batch:   90 | acc: 100.00%,  total acc: 48.35%   [EVAL] batch:   91 | acc: 100.00%,  total acc: 48.91%   [EVAL] batch:   92 | acc: 100.00%,  total acc: 49.46%   [EVAL] batch:   93 | acc: 100.00%,  total acc: 50.00%   [EVAL] batch:   94 | acc: 100.00%,  total acc: 50.53%   [EVAL] batch:   95 | acc: 81.25%,  total acc: 50.85%   [EVAL] batch:   96 | acc: 37.50%,  total acc: 50.71%   [EVAL] batch:   97 | acc: 31.25%,  total acc: 50.51%   [EVAL] batch:   98 | acc: 93.75%,  total acc: 50.95%   [EVAL] batch:   99 | acc: 87.50%,  total acc: 51.31%   [EVAL] batch:  100 | acc: 93.75%,  total acc: 51.73%   [EVAL] batch:  101 | acc: 75.00%,  total acc: 51.96%   [EVAL] batch:  102 | acc: 75.00%,  total acc: 52.18%   [EVAL] batch:  103 | acc: 87.50%,  total acc: 52.52%   [EVAL] batch:  104 | acc: 81.25%,  total acc: 52.80%   [EVAL] batch:  105 | acc: 87.50%,  total acc: 53.12%   [EVAL] batch:  106 | acc: 87.50%,  total acc: 53.45%   [EVAL] batch:  107 | acc: 93.75%,  total acc: 53.82%   [EVAL] batch:  108 | acc: 93.75%,  total acc: 54.19%   [EVAL] batch:  109 | acc: 81.25%,  total acc: 54.43%   [EVAL] batch:  110 | acc: 87.50%,  total acc: 54.73%   [EVAL] batch:  111 | acc: 62.50%,  total acc: 54.80%   [EVAL] batch:  112 | acc: 81.25%,  total acc: 55.03%   [EVAL] batch:  113 | acc: 68.75%,  total acc: 55.15%   [EVAL] batch:  114 | acc: 87.50%,  total acc: 55.43%   [EVAL] batch:  115 | acc: 87.50%,  total acc: 55.71%   [EVAL] batch:  116 | acc: 87.50%,  total acc: 55.98%   [EVAL] batch:  117 | acc: 87.50%,  total acc: 56.25%   [EVAL] batch:  118 | acc: 81.25%,  total acc: 56.46%   [EVAL] batch:  119 | acc: 81.25%,  total acc: 56.67%   [EVAL] batch:  120 | acc: 68.75%,  total acc: 56.77%   [EVAL] batch:  121 | acc: 75.00%,  total acc: 56.92%   [EVAL] batch:  122 | acc: 100.00%,  total acc: 57.27%   [EVAL] batch:  123 | acc: 87.50%,  total acc: 57.51%   [EVAL] batch:  124 | acc: 93.75%,  total acc: 57.80%   [EVAL] batch:  125 | acc: 93.75%,  total acc: 58.09%   [EVAL] batch:  126 | acc: 100.00%,  total acc: 58.42%   [EVAL] batch:  127 | acc: 100.00%,  total acc: 58.74%   [EVAL] batch:  128 | acc: 100.00%,  total acc: 59.06%   [EVAL] batch:  129 | acc: 100.00%,  total acc: 59.38%   [EVAL] batch:  130 | acc: 100.00%,  total acc: 59.69%   [EVAL] batch:  131 | acc: 100.00%,  total acc: 59.99%   [EVAL] batch:  132 | acc: 62.50%,  total acc: 60.01%   
cur_acc:  ['0.8712', '0.9107', '0.8281', '0.8846', '0.5568', '0.9554', '0.8667', '0.8715']
his_acc:  ['0.8712', '0.8697', '0.6771', '0.5862', '0.5540', '0.5464', '0.5808', '0.6001']
--------Round  1
seed:  200
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 6 3 2 4 0 5 1]
prepared data!
CurrentTrain: epoch  0, batch     0 | loss: 11.9064808CurrentTrain: epoch  0, batch     1 | loss: 11.8639908CurrentTrain: epoch  0, batch     2 | loss: 11.6686869CurrentTrain: epoch  0, batch     3 | loss: 11.3898478CurrentTrain: epoch  0, batch     4 | loss: 11.2384148CurrentTrain: epoch  0, batch     5 | loss: 11.5131741CurrentTrain: epoch  0, batch     6 | loss: 10.5715294CurrentTrain: epoch  0, batch     7 | loss: 11.7395077CurrentTrain: epoch  0, batch     8 | loss: 10.9299088CurrentTrain: epoch  0, batch     9 | loss: 10.5581970CurrentTrain: epoch  0, batch    10 | loss: 11.2648773CurrentTrain: epoch  0, batch    11 | loss: 9.8903036CurrentTrain: epoch  0, batch    12 | loss: 10.1122046CurrentTrain: epoch  0, batch    13 | loss: 10.2800989CurrentTrain: epoch  0, batch    14 | loss: 10.7658176CurrentTrain: epoch  0, batch    15 | loss: 10.3615494CurrentTrain: epoch  0, batch    16 | loss: 10.3035555CurrentTrain: epoch  0, batch    17 | loss: 10.1106558CurrentTrain: epoch  0, batch    18 | loss: 10.7182112CurrentTrain: epoch  0, batch    19 | loss: 9.6667042CurrentTrain: epoch  0, batch    20 | loss: 10.2518864CurrentTrain: epoch  0, batch    21 | loss: 9.7331753CurrentTrain: epoch  0, batch    22 | loss: 10.6861439CurrentTrain: epoch  0, batch    23 | loss: 9.8792610CurrentTrain: epoch  0, batch    24 | loss: 10.8179436CurrentTrain: epoch  0, batch    25 | loss: 11.5640221CurrentTrain: epoch  0, batch    26 | loss: 10.7134571CurrentTrain: epoch  0, batch    27 | loss: 10.6837177CurrentTrain: epoch  0, batch    28 | loss: 9.3518066CurrentTrain: epoch  0, batch    29 | loss: 9.9948711CurrentTrain: epoch  0, batch    30 | loss: 9.9478245CurrentTrain: epoch  0, batch    31 | loss: 10.1619425CurrentTrain: epoch  0, batch    32 | loss: 9.7000504CurrentTrain: epoch  0, batch    33 | loss: 9.6447287CurrentTrain: epoch  0, batch    34 | loss: 10.7425289CurrentTrain: epoch  0, batch    35 | loss: 9.7948847CurrentTrain: epoch  0, batch    36 | loss: 9.2492085CurrentTrain: epoch  0, batch    37 | loss: 9.3026276CurrentTrain: epoch  1, batch     0 | loss: 9.5663080CurrentTrain: epoch  1, batch     1 | loss: 9.5871611CurrentTrain: epoch  1, batch     2 | loss: 9.9005070CurrentTrain: epoch  1, batch     3 | loss: 9.2229910CurrentTrain: epoch  1, batch     4 | loss: 9.2252159CurrentTrain: epoch  1, batch     5 | loss: 8.9243259CurrentTrain: epoch  1, batch     6 | loss: 9.7689514CurrentTrain: epoch  1, batch     7 | loss: 9.0011845CurrentTrain: epoch  1, batch     8 | loss: 9.4780025CurrentTrain: epoch  1, batch     9 | loss: 9.7024422CurrentTrain: epoch  1, batch    10 | loss: 9.3921900CurrentTrain: epoch  1, batch    11 | loss: 8.6413784CurrentTrain: epoch  1, batch    12 | loss: 9.5185490CurrentTrain: epoch  1, batch    13 | loss: 8.9300442CurrentTrain: epoch  1, batch    14 | loss: 8.6783543CurrentTrain: epoch  1, batch    15 | loss: 8.2205715CurrentTrain: epoch  1, batch    16 | loss: 8.9082623CurrentTrain: epoch  1, batch    17 | loss: 9.2133713CurrentTrain: epoch  1, batch    18 | loss: 9.4490070CurrentTrain: epoch  1, batch    19 | loss: 9.1847372CurrentTrain: epoch  1, batch    20 | loss: 8.6000519CurrentTrain: epoch  1, batch    21 | loss: 8.8166924CurrentTrain: epoch  1, batch    22 | loss: 8.2471504CurrentTrain: epoch  1, batch    23 | loss: 9.1752682CurrentTrain: epoch  1, batch    24 | loss: 9.8275108CurrentTrain: epoch  1, batch    25 | loss: 9.4409180CurrentTrain: epoch  1, batch    26 | loss: 8.3519344CurrentTrain: epoch  1, batch    27 | loss: 8.7478647CurrentTrain: epoch  1, batch    28 | loss: 8.4379835CurrentTrain: epoch  1, batch    29 | loss: 7.9573488CurrentTrain: epoch  1, batch    30 | loss: 8.1854134CurrentTrain: epoch  1, batch    31 | loss: 8.2743721CurrentTrain: epoch  1, batch    32 | loss: 8.3680534CurrentTrain: epoch  1, batch    33 | loss: 8.1743135CurrentTrain: epoch  1, batch    34 | loss: 8.1293726CurrentTrain: epoch  1, batch    35 | loss: 8.6553345CurrentTrain: epoch  1, batch    36 | loss: 6.6446667CurrentTrain: epoch  1, batch    37 | loss: 8.5239735CurrentTrain: epoch  2, batch     0 | loss: 8.6418219CurrentTrain: epoch  2, batch     1 | loss: 8.5288544CurrentTrain: epoch  2, batch     2 | loss: 8.5434828CurrentTrain: epoch  2, batch     3 | loss: 7.6401129CurrentTrain: epoch  2, batch     4 | loss: 8.1322889CurrentTrain: epoch  2, batch     5 | loss: 8.4838715CurrentTrain: epoch  2, batch     6 | loss: 7.2681999CurrentTrain: epoch  2, batch     7 | loss: 8.8652420CurrentTrain: epoch  2, batch     8 | loss: 9.0236025CurrentTrain: epoch  2, batch     9 | loss: 8.0297508CurrentTrain: epoch  2, batch    10 | loss: 8.5988731CurrentTrain: epoch  2, batch    11 | loss: 8.0089378CurrentTrain: epoch  2, batch    12 | loss: 8.2127523CurrentTrain: epoch  2, batch    13 | loss: 7.4162140CurrentTrain: epoch  2, batch    14 | loss: 8.0555706CurrentTrain: epoch  2, batch    15 | loss: 8.8997393CurrentTrain: epoch  2, batch    16 | loss: 7.9635892CurrentTrain: epoch  2, batch    17 | loss: 8.2252798CurrentTrain: epoch  2, batch    18 | loss: 7.4898324CurrentTrain: epoch  2, batch    19 | loss: 7.1995196CurrentTrain: epoch  2, batch    20 | loss: 7.5344925CurrentTrain: epoch  2, batch    21 | loss: 6.7465911CurrentTrain: epoch  2, batch    22 | loss: 7.2857418CurrentTrain: epoch  2, batch    23 | loss: 7.1610880CurrentTrain: epoch  2, batch    24 | loss: 8.1104984CurrentTrain: epoch  2, batch    25 | loss: 7.1133165CurrentTrain: epoch  2, batch    26 | loss: 8.2817297CurrentTrain: epoch  2, batch    27 | loss: 7.3768797CurrentTrain: epoch  2, batch    28 | loss: 7.6859946CurrentTrain: epoch  2, batch    29 | loss: 7.4639368CurrentTrain: epoch  2, batch    30 | loss: 7.0119128CurrentTrain: epoch  2, batch    31 | loss: 7.1889853CurrentTrain: epoch  2, batch    32 | loss: 6.2050524CurrentTrain: epoch  2, batch    33 | loss: 7.9729528CurrentTrain: epoch  2, batch    34 | loss: 6.9446855CurrentTrain: epoch  2, batch    35 | loss: 8.4130459CurrentTrain: epoch  2, batch    36 | loss: 7.1561933CurrentTrain: epoch  2, batch    37 | loss: 6.8447828CurrentTrain: epoch  3, batch     0 | loss: 6.7495227CurrentTrain: epoch  3, batch     1 | loss: 6.9528170CurrentTrain: epoch  3, batch     2 | loss: 7.0266762CurrentTrain: epoch  3, batch     3 | loss: 7.4576664CurrentTrain: epoch  3, batch     4 | loss: 7.7823663CurrentTrain: epoch  3, batch     5 | loss: 7.3614683CurrentTrain: epoch  3, batch     6 | loss: 7.6086850CurrentTrain: epoch  3, batch     7 | loss: 7.1865511CurrentTrain: epoch  3, batch     8 | loss: 7.2221293CurrentTrain: epoch  3, batch     9 | loss: 7.5208106CurrentTrain: epoch  3, batch    10 | loss: 6.9016519CurrentTrain: epoch  3, batch    11 | loss: 6.3317561CurrentTrain: epoch  3, batch    12 | loss: 7.7344618CurrentTrain: epoch  3, batch    13 | loss: 6.3138847CurrentTrain: epoch  3, batch    14 | loss: 7.1450872CurrentTrain: epoch  3, batch    15 | loss: 6.4472275CurrentTrain: epoch  3, batch    16 | loss: 6.9890342CurrentTrain: epoch  3, batch    17 | loss: 7.4970107CurrentTrain: epoch  3, batch    18 | loss: 8.1890793CurrentTrain: epoch  3, batch    19 | loss: 7.8152542CurrentTrain: epoch  3, batch    20 | loss: 7.4739895CurrentTrain: epoch  3, batch    21 | loss: 6.6493039CurrentTrain: epoch  3, batch    22 | loss: 7.1213384CurrentTrain: epoch  3, batch    23 | loss: 6.7685652CurrentTrain: epoch  3, batch    24 | loss: 7.3915896CurrentTrain: epoch  3, batch    25 | loss: 6.2554574CurrentTrain: epoch  3, batch    26 | loss: 7.2128763CurrentTrain: epoch  3, batch    27 | loss: 6.4449058CurrentTrain: epoch  3, batch    28 | loss: 7.5262570CurrentTrain: epoch  3, batch    29 | loss: 5.9755230CurrentTrain: epoch  3, batch    30 | loss: 6.0571299CurrentTrain: epoch  3, batch    31 | loss: 7.2888994CurrentTrain: epoch  3, batch    32 | loss: 6.3508625CurrentTrain: epoch  3, batch    33 | loss: 7.6665173CurrentTrain: epoch  3, batch    34 | loss: 7.0020676CurrentTrain: epoch  3, batch    35 | loss: 7.5473609CurrentTrain: epoch  3, batch    36 | loss: 7.3324122CurrentTrain: epoch  3, batch    37 | loss: 6.7194386CurrentTrain: epoch  4, batch     0 | loss: 6.0571728CurrentTrain: epoch  4, batch     1 | loss: 6.1627150CurrentTrain: epoch  4, batch     2 | loss: 6.6914129CurrentTrain: epoch  4, batch     3 | loss: 6.8920460CurrentTrain: epoch  4, batch     4 | loss: 6.9788218CurrentTrain: epoch  4, batch     5 | loss: 7.2339997CurrentTrain: epoch  4, batch     6 | loss: 6.4948444CurrentTrain: epoch  4, batch     7 | loss: 6.4131460CurrentTrain: epoch  4, batch     8 | loss: 6.7899566CurrentTrain: epoch  4, batch     9 | loss: 7.0256414CurrentTrain: epoch  4, batch    10 | loss: 6.7346134CurrentTrain: epoch  4, batch    11 | loss: 6.5827975CurrentTrain: epoch  4, batch    12 | loss: 6.4463873CurrentTrain: epoch  4, batch    13 | loss: 6.3268151CurrentTrain: epoch  4, batch    14 | loss: 6.5156827CurrentTrain: epoch  4, batch    15 | loss: 6.3504243CurrentTrain: epoch  4, batch    16 | loss: 6.5187144CurrentTrain: epoch  4, batch    17 | loss: 5.8663487CurrentTrain: epoch  4, batch    18 | loss: 6.1711483CurrentTrain: epoch  4, batch    19 | loss: 5.9027481CurrentTrain: epoch  4, batch    20 | loss: 6.2850847CurrentTrain: epoch  4, batch    21 | loss: 6.4187317CurrentTrain: epoch  4, batch    22 | loss: 6.0069075CurrentTrain: epoch  4, batch    23 | loss: 5.5508299CurrentTrain: epoch  4, batch    24 | loss: 6.9908743CurrentTrain: epoch  4, batch    25 | loss: 6.6414485CurrentTrain: epoch  4, batch    26 | loss: 6.4339542CurrentTrain: epoch  4, batch    27 | loss: 6.6451874CurrentTrain: epoch  4, batch    28 | loss: 5.6742845CurrentTrain: epoch  4, batch    29 | loss: 6.3257389CurrentTrain: epoch  4, batch    30 | loss: 5.5072227CurrentTrain: epoch  4, batch    31 | loss: 6.4055357CurrentTrain: epoch  4, batch    32 | loss: 6.1860771CurrentTrain: epoch  4, batch    33 | loss: 6.6413870CurrentTrain: epoch  4, batch    34 | loss: 6.5381842CurrentTrain: epoch  4, batch    35 | loss: 6.7196550CurrentTrain: epoch  4, batch    36 | loss: 7.5713263CurrentTrain: epoch  4, batch    37 | loss: 6.6564274CurrentTrain: epoch  5, batch     0 | loss: 6.5840187CurrentTrain: epoch  5, batch     1 | loss: 6.4031744CurrentTrain: epoch  5, batch     2 | loss: 6.2873006CurrentTrain: epoch  5, batch     3 | loss: 5.8160934CurrentTrain: epoch  5, batch     4 | loss: 6.9405022CurrentTrain: epoch  5, batch     5 | loss: 5.9566231CurrentTrain: epoch  5, batch     6 | loss: 6.1983652CurrentTrain: epoch  5, batch     7 | loss: 6.1707544CurrentTrain: epoch  5, batch     8 | loss: 5.6008940CurrentTrain: epoch  5, batch     9 | loss: 5.7568002CurrentTrain: epoch  5, batch    10 | loss: 5.7476816CurrentTrain: epoch  5, batch    11 | loss: 5.6207447CurrentTrain: epoch  5, batch    12 | loss: 5.3938837CurrentTrain: epoch  5, batch    13 | loss: 6.6529388CurrentTrain: epoch  5, batch    14 | loss: 5.7307138CurrentTrain: epoch  5, batch    15 | loss: 6.5193539CurrentTrain: epoch  5, batch    16 | loss: 5.5883303CurrentTrain: epoch  5, batch    17 | loss: 5.4248271CurrentTrain: epoch  5, batch    18 | loss: 5.5615034CurrentTrain: epoch  5, batch    19 | loss: 5.8241124CurrentTrain: epoch  5, batch    20 | loss: 6.1206055CurrentTrain: epoch  5, batch    21 | loss: 6.2259789CurrentTrain: epoch  5, batch    22 | loss: 5.6477871CurrentTrain: epoch  5, batch    23 | loss: 5.4727840CurrentTrain: epoch  5, batch    24 | loss: 5.4866171CurrentTrain: epoch  5, batch    25 | loss: 5.5415888CurrentTrain: epoch  5, batch    26 | loss: 5.7948484CurrentTrain: epoch  5, batch    27 | loss: 5.7870722CurrentTrain: epoch  5, batch    28 | loss: 6.2736969CurrentTrain: epoch  5, batch    29 | loss: 6.0339255CurrentTrain: epoch  5, batch    30 | loss: 6.2272387CurrentTrain: epoch  5, batch    31 | loss: 5.3462749CurrentTrain: epoch  5, batch    32 | loss: 5.7553940CurrentTrain: epoch  5, batch    33 | loss: 5.8332000CurrentTrain: epoch  5, batch    34 | loss: 6.1867008CurrentTrain: epoch  5, batch    35 | loss: 5.6188583CurrentTrain: epoch  5, batch    36 | loss: 6.2444763CurrentTrain: epoch  5, batch    37 | loss: 5.8725929CurrentTrain: epoch  6, batch     0 | loss: 5.3010335CurrentTrain: epoch  6, batch     1 | loss: 5.4931574CurrentTrain: epoch  6, batch     2 | loss: 5.6910830CurrentTrain: epoch  6, batch     3 | loss: 5.3188133CurrentTrain: epoch  6, batch     4 | loss: 5.4453125CurrentTrain: epoch  6, batch     5 | loss: 6.4954033CurrentTrain: epoch  6, batch     6 | loss: 5.9821987CurrentTrain: epoch  6, batch     7 | loss: 5.6164637CurrentTrain: epoch  6, batch     8 | loss: 5.4422541CurrentTrain: epoch  6, batch     9 | loss: 5.6210084CurrentTrain: epoch  6, batch    10 | loss: 5.3405476CurrentTrain: epoch  6, batch    11 | loss: 5.4095764CurrentTrain: epoch  6, batch    12 | loss: 6.1398926CurrentTrain: epoch  6, batch    13 | loss: 5.3313117CurrentTrain: epoch  6, batch    14 | loss: 5.4866314CurrentTrain: epoch  6, batch    15 | loss: 5.4870987CurrentTrain: epoch  6, batch    16 | loss: 5.6315546CurrentTrain: epoch  6, batch    17 | loss: 5.4794703CurrentTrain: epoch  6, batch    18 | loss: 5.8820772CurrentTrain: epoch  6, batch    19 | loss: 5.2790232CurrentTrain: epoch  6, batch    20 | loss: 5.5286484CurrentTrain: epoch  6, batch    21 | loss: 5.8117561CurrentTrain: epoch  6, batch    22 | loss: 5.3503380CurrentTrain: epoch  6, batch    23 | loss: 5.5888100CurrentTrain: epoch  6, batch    24 | loss: 5.1943645CurrentTrain: epoch  6, batch    25 | loss: 5.3826480CurrentTrain: epoch  6, batch    26 | loss: 5.8224969CurrentTrain: epoch  6, batch    27 | loss: 5.2258439CurrentTrain: epoch  6, batch    28 | loss: 5.9251251CurrentTrain: epoch  6, batch    29 | loss: 5.5664501CurrentTrain: epoch  6, batch    30 | loss: 5.1986237CurrentTrain: epoch  6, batch    31 | loss: 5.5570021CurrentTrain: epoch  6, batch    32 | loss: 5.6298800CurrentTrain: epoch  6, batch    33 | loss: 5.3771567CurrentTrain: epoch  6, batch    34 | loss: 5.1547303CurrentTrain: epoch  6, batch    35 | loss: 6.8778944CurrentTrain: epoch  6, batch    36 | loss: 5.4354906CurrentTrain: epoch  6, batch    37 | loss: 5.1339173CurrentTrain: epoch  7, batch     0 | loss: 5.9270163CurrentTrain: epoch  7, batch     1 | loss: 5.2945518CurrentTrain: epoch  7, batch     2 | loss: 5.4929323CurrentTrain: epoch  7, batch     3 | loss: 5.6739607CurrentTrain: epoch  7, batch     4 | loss: 5.5321198CurrentTrain: epoch  7, batch     5 | loss: 5.0773592CurrentTrain: epoch  7, batch     6 | loss: 5.2525492CurrentTrain: epoch  7, batch     7 | loss: 5.5019832CurrentTrain: epoch  7, batch     8 | loss: 5.2937627CurrentTrain: epoch  7, batch     9 | loss: 5.3627739CurrentTrain: epoch  7, batch    10 | loss: 5.2142000CurrentTrain: epoch  7, batch    11 | loss: 5.6258545CurrentTrain: epoch  7, batch    12 | loss: 5.2338476CurrentTrain: epoch  7, batch    13 | loss: 5.1276741CurrentTrain: epoch  7, batch    14 | loss: 5.1862192CurrentTrain: epoch  7, batch    15 | loss: 5.1541343CurrentTrain: epoch  7, batch    16 | loss: 5.0780206CurrentTrain: epoch  7, batch    17 | loss: 5.1797934CurrentTrain: epoch  7, batch    18 | loss: 5.0497112CurrentTrain: epoch  7, batch    19 | loss: 5.5578184CurrentTrain: epoch  7, batch    20 | loss: 5.2192492CurrentTrain: epoch  7, batch    21 | loss: 5.0138302CurrentTrain: epoch  7, batch    22 | loss: 5.0398245CurrentTrain: epoch  7, batch    23 | loss: 5.3075180CurrentTrain: epoch  7, batch    24 | loss: 5.5747881CurrentTrain: epoch  7, batch    25 | loss: 5.7899647CurrentTrain: epoch  7, batch    26 | loss: 6.2777462CurrentTrain: epoch  7, batch    27 | loss: 5.2148914CurrentTrain: epoch  7, batch    28 | loss: 5.6571684CurrentTrain: epoch  7, batch    29 | loss: 5.1465120CurrentTrain: epoch  7, batch    30 | loss: 5.2829056CurrentTrain: epoch  7, batch    31 | loss: 5.6718292CurrentTrain: epoch  7, batch    32 | loss: 5.1619697CurrentTrain: epoch  7, batch    33 | loss: 5.4023733CurrentTrain: epoch  7, batch    34 | loss: 4.9272323CurrentTrain: epoch  7, batch    35 | loss: 4.9698181CurrentTrain: epoch  7, batch    36 | loss: 5.3510857CurrentTrain: epoch  7, batch    37 | loss: 4.9231505CurrentTrain: epoch  8, batch     0 | loss: 5.0168490CurrentTrain: epoch  8, batch     1 | loss: 5.7203670CurrentTrain: epoch  8, batch     2 | loss: 5.1069555CurrentTrain: epoch  8, batch     3 | loss: 5.0367193CurrentTrain: epoch  8, batch     4 | loss: 5.1187487CurrentTrain: epoch  8, batch     5 | loss: 5.2751055CurrentTrain: epoch  8, batch     6 | loss: 5.2564802CurrentTrain: epoch  8, batch     7 | loss: 5.1886358CurrentTrain: epoch  8, batch     8 | loss: 5.1485648CurrentTrain: epoch  8, batch     9 | loss: 5.0792675CurrentTrain: epoch  8, batch    10 | loss: 5.1419654CurrentTrain: epoch  8, batch    11 | loss: 5.0674562CurrentTrain: epoch  8, batch    12 | loss: 5.5903296CurrentTrain: epoch  8, batch    13 | loss: 5.8417959CurrentTrain: epoch  8, batch    14 | loss: 5.4350700CurrentTrain: epoch  8, batch    15 | loss: 5.3679256CurrentTrain: epoch  8, batch    16 | loss: 5.0566044CurrentTrain: epoch  8, batch    17 | loss: 5.3173237CurrentTrain: epoch  8, batch    18 | loss: 5.5487547CurrentTrain: epoch  8, batch    19 | loss: 5.2379770CurrentTrain: epoch  8, batch    20 | loss: 4.9534917CurrentTrain: epoch  8, batch    21 | loss: 4.8841858CurrentTrain: epoch  8, batch    22 | loss: 5.1473827CurrentTrain: epoch  8, batch    23 | loss: 5.3952498CurrentTrain: epoch  8, batch    24 | loss: 5.1771555CurrentTrain: epoch  8, batch    25 | loss: 5.0638285CurrentTrain: epoch  8, batch    26 | loss: 5.1669555CurrentTrain: epoch  8, batch    27 | loss: 5.3729167CurrentTrain: epoch  8, batch    28 | loss: 4.9587555CurrentTrain: epoch  8, batch    29 | loss: 5.0554094CurrentTrain: epoch  8, batch    30 | loss: 5.2200031CurrentTrain: epoch  8, batch    31 | loss: 5.0288730CurrentTrain: epoch  8, batch    32 | loss: 4.9527378CurrentTrain: epoch  8, batch    33 | loss: 5.1584873CurrentTrain: epoch  8, batch    34 | loss: 5.2792559CurrentTrain: epoch  8, batch    35 | loss: 4.8034377CurrentTrain: epoch  8, batch    36 | loss: 4.9449039CurrentTrain: epoch  8, batch    37 | loss: 5.7673888CurrentTrain: epoch  9, batch     0 | loss: 5.1609888CurrentTrain: epoch  9, batch     1 | loss: 5.1186104CurrentTrain: epoch  9, batch     2 | loss: 5.0379229CurrentTrain: epoch  9, batch     3 | loss: 5.0181837CurrentTrain: epoch  9, batch     4 | loss: 5.2383504CurrentTrain: epoch  9, batch     5 | loss: 5.0184493CurrentTrain: epoch  9, batch     6 | loss: 5.0556164CurrentTrain: epoch  9, batch     7 | loss: 5.1890631CurrentTrain: epoch  9, batch     8 | loss: 4.8221893CurrentTrain: epoch  9, batch     9 | loss: 5.0642529CurrentTrain: epoch  9, batch    10 | loss: 5.0238991CurrentTrain: epoch  9, batch    11 | loss: 5.1607494CurrentTrain: epoch  9, batch    12 | loss: 4.9301300CurrentTrain: epoch  9, batch    13 | loss: 4.7900143CurrentTrain: epoch  9, batch    14 | loss: 4.9786668CurrentTrain: epoch  9, batch    15 | loss: 4.9626470CurrentTrain: epoch  9, batch    16 | loss: 4.8003244CurrentTrain: epoch  9, batch    17 | loss: 5.2744021CurrentTrain: epoch  9, batch    18 | loss: 5.0633698CurrentTrain: epoch  9, batch    19 | loss: 5.4749088CurrentTrain: epoch  9, batch    20 | loss: 5.0396085CurrentTrain: epoch  9, batch    21 | loss: 5.0676537CurrentTrain: epoch  9, batch    22 | loss: 4.8501654CurrentTrain: epoch  9, batch    23 | loss: 4.9025450CurrentTrain: epoch  9, batch    24 | loss: 5.0321131CurrentTrain: epoch  9, batch    25 | loss: 4.9086208CurrentTrain: epoch  9, batch    26 | loss: 4.8878736CurrentTrain: epoch  9, batch    27 | loss: 4.9245768CurrentTrain: epoch  9, batch    28 | loss: 5.0031362CurrentTrain: epoch  9, batch    29 | loss: 5.0245047CurrentTrain: epoch  9, batch    30 | loss: 4.8237190CurrentTrain: epoch  9, batch    31 | loss: 4.8577032CurrentTrain: epoch  9, batch    32 | loss: 4.8946056CurrentTrain: epoch  9, batch    33 | loss: 5.0990329CurrentTrain: epoch  9, batch    34 | loss: 4.8800640CurrentTrain: epoch  9, batch    35 | loss: 5.0227580CurrentTrain: epoch  9, batch    36 | loss: 4.9584923CurrentTrain: epoch  9, batch    37 | loss: 5.0068731
#### person countries of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person countries of residence" means a person is living in a country.
Here is an example:
Relation: person countries of residence
Context: embattled us attorney general alberto gonzales formally announced his resignation on monday , after months at the center of a raging political storm .
Head Entity: alberto gonzales
Tail Entity: us
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person countries of residence":
Relation: person countries of residence  
Context: After years of living in Paris, the renowned artist decided to return to his hometown in Italy.  
Head Entity: the renowned artist  
Tail Entity: Italy  

Relation: person countries of residence  
Context: Following her studies in London, she moved to Canada to start her career in technology.  
Head Entity: she  
Tail Entity: Canada  

Relation: person countries of residence  
Context: The famous actor has been residing in Australia for the past few years while filming his latest movie.  
Head Entity: The famous actor  
Tail Entity: Australia  

Relation: person countries of residence  
Context: After spending a decade in Japan, the scientist relocated to Germany for a new research opportunity.  
Head Entity: the scientist  
Tail Entity: Germany  

Relation: person countries of residence  
Context: He has lived in Brazil for most of his life, enjoying the vibrant culture and beautiful landscapes.  
Head Entity: He  
Tail Entity: Brazil  
#### organization top members employees ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization top members employees" means an organization 's employer is a person.
Here is an example:
Relation: organization top members employees
Context: whether this means the country 's tense political situation will dissolve back into civil war is yet to be seen , said rinaldo depagne , a west africa analyst at the international crisis group .
Head Entity: international crisis group
Tail Entity: rinaldo depagne
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization top members employees":
Relation: organization top members employees  
Context: The CEO of the tech giant announced a new initiative to improve employee satisfaction during the annual company meeting.  
Head Entity: tech giant  
Tail Entity: CEO  

Relation: organization top members employees  
Context: During the charity event, the founder of the non-profit organization expressed gratitude towards the volunteers who dedicated their time to the cause.  
Head Entity: non-profit organization  
Tail Entity: founder  

Relation: organization top members employees  
Context: The board of directors met to discuss the future of the company and the role of the new marketing director in shaping its strategy.  
Head Entity: company  
Tail Entity: marketing director  

Relation: organization top members employees  
Context: At the annual conference, the president of the university highlighted the achievements of the faculty members in advancing research and education.  
Head Entity: university  
Tail Entity: president  

Relation: organization top members employees  
Context: The manager of the restaurant praised the head chef for creating a unique menu that has attracted many new customers.  
Head Entity: restaurant  
Tail Entity: head chef  
#### organization member of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization member of" means an organization is the member of an organization.
Here is an example:
Relation: organization member of
Context: rong lan , a teacher in tianjin , a city of more than 10 million people about 150 kilometers -lrb- 90 miles -rrb- southeast of beijing and home to the cbl 's tianjin lions , said the chinese just do n't get baseball .
Head Entity: tianjin lions
Tail Entity: cbl
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization member of":
Relation: organization member of  
Context: The New York Yankees, a professional baseball team based in the Bronx, are part of Major League Baseball and have a long-standing rivalry with the Boston Red Sox.  
Head Entity: New York Yankees  
Tail Entity: Major League Baseball  

Relation: organization member of  
Context: The United Nations, an international organization founded in 1945, includes various member states, including France, which plays a significant role in global diplomacy.  
Head Entity: United Nations  
Tail Entity: France  

Relation: organization member of  
Context: The National Football League, known for its thrilling games and passionate fan base, includes teams like the Green Bay Packers, which have a storied history in American football.  
Head Entity: Green Bay Packers  
Tail Entity: National Football League  

Relation: organization member of  
Context: The World Health Organization, a specialized agency of the United Nations, works with countries like Canada to improve global health standards and responses to health emergencies.  
Head Entity: World Health Organization  
Tail Entity: Canada  

Relation: organization member of  
Context: The European Union, a political and economic union of member states located primarily in Europe, includes Germany, which is one of its largest economies.  
Head Entity: European Union  
Tail Entity: Germany  
#### person origin ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person origin" means a person 's nationality is a country.
Here is an example:
Relation: person origin
Context: urgent chadian pm dies in paris hospital chad 's prime minister pascal yoadimnadji has died from a cerebral hemorrhage in a paris hospital , the chadian ambassador said friday .
Head Entity: pascal yoadimnadji
Tail Entity: chadian
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person origin":
Relation: person origin  
Context: the renowned scientist albert einstein was born in ulm, in the kingdom of wurttemberg in the german empire.  
Head Entity: albert einstein  
Tail Entity: german  

Relation: person origin  
Context: the famous author chimamanda ngozi adichie hails from enugu, nigeria, where she spent her early years before moving to the united states.  
Head Entity: chimamanda ngozi adichie  
Tail Entity: nigerian  

Relation: person origin  
Context: the legendary musician bob marley was born in nine mile, jamaica, and became a global icon of reggae music.  
Head Entity: bob marley  
Tail Entity: jamaican  

Relation: person origin  
Context: the celebrated filmmaker akira kurosawa was born in tokyo, japan, and is known for his influential works in cinema.  
Head Entity: akira kurosawa  
Tail Entity: japanese  

Relation: person origin  
Context: the prominent civil rights leader nelson mandela was born in mvezo, a small village in south africa, and became a symbol of the struggle against apartheid.  
Head Entity: nelson mandela  
Tail Entity: south african  
#### person title ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person title" means a person 's title is a title.
Here is an example:
Relation: person title
Context: `` making the amendment retroactive will ... help repair the image of the sentencing guidelines in communities of color , '' naacp chairman julian bond wrote to the commission .
Head Entity: julian bond
Tail Entity: chairman
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person title":
Relation: person title  
Context: `` After years of dedicated service, the board appointed Dr. Emily Carter as the new president of the university. ''  
Head Entity: Dr. Emily Carter  
Tail Entity: president  

Relation: person title  
Context: `` In her acceptance speech, the newly elected mayor, Sarah Thompson, promised to focus on community development. ''  
Head Entity: Sarah Thompson  
Tail Entity: mayor  

Relation: person title  
Context: `` The renowned scientist, Dr. Alan Smith, received the prestigious award for his groundbreaking research in genetics. ''  
Head Entity: Dr. Alan Smith  
Tail Entity: scientist  

Relation: person title  
Context: `` As the chief executive officer of the company, Mark Johnson has led numerous successful initiatives over the past decade. ''  
Head Entity: Mark Johnson  
Tail Entity: chief executive officer  

Relation: person title  
Context: `` The famous author, Lisa Chen, captivated audiences with her latest novel during the book launch event. ''  
Head Entity: Lisa Chen  
Tail Entity: author  
#### organization country of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization country of headquarters" means an organization is located in a country.
Here is an example:
Relation: organization country of headquarters
Context: `` japan 's growth has yet to be sustained by domestic demand alone , '' said yoshimasa maruyama , a senior economist at itochu corp. in tokyo .
Head Entity: itochu corp.
Tail Entity: japan
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization country of headquarters":
Relation: organization country of headquarters  
Context: "The headquarters of Samsung Electronics is located in Suwon, South Korea, where it has been a major player in the global technology market."  
Head Entity: Samsung Electronics  
Tail Entity: South Korea  

Relation: organization country of headquarters  
Context: "Nestlé, the world's largest food and beverage company, has its headquarters in Vevey, Switzerland, overseeing operations in numerous countries."  
Head Entity: Nestlé  
Tail Entity: Switzerland  

Relation: organization country of headquarters  
Context: "Volkswagen AG, a leading automobile manufacturer, is headquartered in Wolfsburg, Germany, where it designs and produces a wide range of vehicles."  
Head Entity: Volkswagen AG  
Tail Entity: Germany  

Relation: organization country of headquarters  
Context: "The multinational corporation Unilever has its headquarters in London, England, and operates in over 190 countries worldwide."  
Head Entity: Unilever  
Tail Entity: England  

Relation: organization country of headquarters  
Context: "Sony Corporation, known for its electronics and entertainment products, is headquartered in Tokyo, Japan, contributing significantly to the country's economy."  
Head Entity: Sony Corporation  
Tail Entity: Japan  
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    1 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    2 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    3 | acc: 62.50%,  total acc: 76.56%   [EVAL] batch:    4 | acc: 68.75%,  total acc: 75.00%   [EVAL] batch:    5 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 78.57%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 81.25%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 83.33%   [EVAL] batch:    9 | acc: 93.75%,  total acc: 84.38%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 85.80%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 86.46%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 87.02%   [EVAL] batch:   13 | acc: 68.75%,  total acc: 85.71%   [EVAL] batch:   14 | acc: 81.25%,  total acc: 85.42%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 83.59%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 83.09%   [EVAL] batch:   17 | acc: 68.75%,  total acc: 82.29%   [EVAL] batch:   18 | acc: 75.00%,  total acc: 81.91%   [EVAL] batch:   19 | acc: 75.00%,  total acc: 81.56%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 82.44%   [EVAL] batch:   21 | acc: 100.00%,  total acc: 83.24%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 83.97%   [EVAL] batch:   23 | acc: 100.00%,  total acc: 84.64%   [EVAL] batch:   24 | acc: 100.00%,  total acc: 85.25%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 85.82%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 86.11%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 86.61%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 87.07%   [EVAL] batch:   29 | acc: 87.50%,  total acc: 87.08%   [EVAL] batch:   30 | acc: 87.50%,  total acc: 87.10%   [EVAL] batch:   31 | acc: 93.75%,  total acc: 87.30%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 85.80%   
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    1 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    2 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    3 | acc: 62.50%,  total acc: 76.56%   [EVAL] batch:    4 | acc: 68.75%,  total acc: 75.00%   [EVAL] batch:    5 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 78.57%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 81.25%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 83.33%   [EVAL] batch:    9 | acc: 93.75%,  total acc: 84.38%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 85.80%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 86.46%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 87.02%   [EVAL] batch:   13 | acc: 68.75%,  total acc: 85.71%   [EVAL] batch:   14 | acc: 81.25%,  total acc: 85.42%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 83.59%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 83.09%   [EVAL] batch:   17 | acc: 68.75%,  total acc: 82.29%   [EVAL] batch:   18 | acc: 75.00%,  total acc: 81.91%   [EVAL] batch:   19 | acc: 75.00%,  total acc: 81.56%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 82.44%   [EVAL] batch:   21 | acc: 100.00%,  total acc: 83.24%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 83.97%   [EVAL] batch:   23 | acc: 100.00%,  total acc: 84.64%   [EVAL] batch:   24 | acc: 100.00%,  total acc: 85.25%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 85.82%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 86.11%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 86.61%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 87.07%   [EVAL] batch:   29 | acc: 87.50%,  total acc: 87.08%   [EVAL] batch:   30 | acc: 87.50%,  total acc: 87.10%   [EVAL] batch:   31 | acc: 93.75%,  total acc: 87.30%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 85.80%   
cur_acc:  ['0.8580']
his_acc:  ['0.8580']
CurrentTrain: epoch  0, batch     0 | loss: 6.2867098CurrentTrain: epoch  0, batch     1 | loss: 7.0269647CurrentTrain: epoch  1, batch     0 | loss: 5.8915138CurrentTrain: epoch  1, batch     1 | loss: 5.8177638CurrentTrain: epoch  2, batch     0 | loss: 5.5289679CurrentTrain: epoch  2, batch     1 | loss: 5.0860114CurrentTrain: epoch  3, batch     0 | loss: 4.8239474CurrentTrain: epoch  3, batch     1 | loss: 5.5519061CurrentTrain: epoch  4, batch     0 | loss: 4.8133054CurrentTrain: epoch  4, batch     1 | loss: 4.4697552CurrentTrain: epoch  5, batch     0 | loss: 4.4706869CurrentTrain: epoch  5, batch     1 | loss: 4.4696045CurrentTrain: epoch  6, batch     0 | loss: 4.1162949CurrentTrain: epoch  6, batch     1 | loss: 4.6657844CurrentTrain: epoch  7, batch     0 | loss: 4.0687127CurrentTrain: epoch  7, batch     1 | loss: 4.2619200CurrentTrain: epoch  8, batch     0 | loss: 3.9350581CurrentTrain: epoch  8, batch     1 | loss: 3.8058641CurrentTrain: epoch  9, batch     0 | loss: 3.5855842CurrentTrain: epoch  9, batch     1 | loss: 3.6470973
#### person stateorprovinces of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovinces of residence" means a person is living in a state or province.
Here is an example:
Relation: person stateorprovinces of residence
Context: ny-schools-chief -lrb- new york -rrb- -- cathleen p. black , mayor michael r. bloomberg 's choice to be the next chancellor of new york city 's public-school system , has during more than 40 years in the media business broken numerous glass ceilings -- and amassed a fortune -- with quick and cold-blooded decision making , crystal-clear goal setting , and an all-surpassing attention to the bottom line .
Head Entity: cathleen p. black
Tail Entity: new york
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovinces of residence":
Relation: person stateorprovinces of residence  
Context: After years of living in the bustling city, actor Tom Hanks has decided to settle down in a quieter area, choosing to make his home in the picturesque state of California.  
Head Entity: Tom Hanks  
Tail Entity: California  

Relation: person stateorprovinces of residence  
Context: The renowned author J.K. Rowling has spent much of her life in Edinburgh, where she found inspiration for her famous Harry Potter series.  
Head Entity: J.K. Rowling  
Tail Entity: Edinburgh  

Relation: person stateorprovinces of residence  
Context: Following his successful career in the tech industry, entrepreneur Elon Musk has moved to Texas, where he plans to expand his business ventures.  
Head Entity: Elon Musk  
Tail Entity: Texas  

Relation: person stateorprovinces of residence  
Context: After retiring from professional basketball, Michael Jordan chose to reside in North Carolina, where he continues to be involved in the local community.  
Head Entity: Michael Jordan  
Tail Entity: North Carolina  

Relation: person stateorprovinces of residence  
Context: The famous singer Taylor Swift has made her home in Nashville, Tennessee, where she began her music career and still finds creative inspiration.  
Head Entity: Taylor Swift  
Tail Entity: Nashville
#### person date of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person date of death" means a person was died on a date.
Here is an example:
Relation: person date of death
Context: he passed away on saturday .
Head Entity: he
Tail Entity: saturday
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person date of death":
Relation: person date of death  
Context: John Smith died on March 15, 2020.  
Head Entity: John Smith  
Tail Entity: March 15, 2020  

Relation: person date of death  
Context: The famous author passed away in 1995.  
Head Entity: The famous author  
Tail Entity: 1995  

Relation: person date of death  
Context: She left this world on New Year's Day.  
Head Entity: She  
Tail Entity: New Year's Day  

Relation: person date of death  
Context: The scientist's life ended on July 4th, 2018.  
Head Entity: The scientist  
Tail Entity: July 4th, 2018  

Relation: person date of death  
Context: He was reported dead on the evening of December 31.  
Head Entity: He  
Tail Entity: December 31  
#### organization number of employees members ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization number of employees members" means the number of an organization 's employees is a number.
Here is an example:
Relation: organization number of employees members
Context: covidien , which posted revenue of more than $ 10 billion last year , has about 42,000 employees worldwide .
Head Entity: covidien
Tail Entity: 42,000
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization number of employees members":
Relation: organization number of employees members  
Context: TechCorp, a leading software development company, employs approximately 5,500 people across its global offices.  
Head Entity: TechCorp  
Tail Entity: 5,500  

Relation: organization number of employees members  
Context: The nonprofit organization Helping Hands has grown significantly and now boasts a workforce of over 1,200 dedicated volunteers.  
Head Entity: Helping Hands  
Tail Entity: 1,200  

Relation: organization number of employees members  
Context: With a workforce of around 3,000, Green Energy Solutions is making strides in renewable energy initiatives.  
Head Entity: Green Energy Solutions  
Tail Entity: 3,000  

Relation: organization number of employees members  
Context: Last year, Global Finance reported that it has expanded its team to include 10,000 employees to meet increasing client demands.  
Head Entity: Global Finance  
Tail Entity: 10,000  

Relation: organization number of employees members  
Context: The educational institution Bright Future Academy has a total of 800 staff members dedicated to providing quality education.  
Head Entity: Bright Future Academy  
Tail Entity: 800  
#### person alternate names ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person alternate names" means a person 's alias is a person.
Here is an example:
Relation: person alternate names
Context: a judge in new york city said remy ma , whose real name is remy smith , said thursday that the hip-hopper could not leave the united states for a five-country european concert tour .
Head Entity: remy smith
Tail Entity: remy ma
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person alternate names":
Relation: person alternate names  
Context: The famous author Samuel Langhorne Clemens, better known by his pen name Mark Twain, is celebrated for his novels like "The Adventures of Tom Sawyer."  
Head Entity: Samuel Langhorne Clemens  
Tail Entity: Mark Twain  

Relation: person alternate names  
Context: The musician Stefani Joanne Angelina Germanotta, who is widely recognized as Lady Gaga, has made a significant impact on the pop music scene.  
Head Entity: Stefani Joanne Angelina Germanotta  
Tail Entity: Lady Gaga  

Relation: person alternate names  
Context: The actor and filmmaker known as Orson Welles was born George Orson Welles and is famous for his groundbreaking work in cinema.  
Head Entity: George Orson Welles  
Tail Entity: Orson Welles  

Relation: person alternate names  
Context: The renowned physicist Albert Einstein, who is often referred to simply as Einstein, developed the theory of relativity.  
Head Entity: Albert Einstein  
Tail Entity: Einstein  

Relation: person alternate names  
Context: The legendary basketball player Michael Jordan, often called MJ, is considered one of the greatest athletes of all time.  
Head Entity: Michael Jordan  
Tail Entity: MJ  
#### person spouse ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person spouse" means a person 's spouse is a person.
Here is an example:
Relation: person spouse
Context: beverly hills , california 2008-08-17 21:15:39 utc ------ there was much dancing : ellen degeneres and portia de rossi are married , according to reports .
Head Entity: ellen degeneres
Tail Entity: portia de rossi
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person spouse":
Relation: person spouse  
Context: in a beautiful ceremony held in new york city, 2015-06-20 15:30:00 utc ------ the couple exchanged vows: john legend and chrissy teigen are now officially husband and wife.  
Head Entity: john legend  
Tail Entity: chrissy teigen  

Relation: person spouse  
Context: during a lavish wedding in italy, 2017-09-30 18:45:00 utc ------ the stars tied the knot: justin timberlake and jessica biel celebrated their love with family and friends.  
Head Entity: justin timberlake  
Tail Entity: jessica biel  

Relation: person spouse  
Context: on a sunny day in los angeles, 2019-05-12 12:00:00 utc ------ they said 'i do': blake lively and ryan reynolds have been married for several years now.  
Head Entity: blake lively  
Tail Entity: ryan reynolds  

Relation: person spouse  
Context: at a private ceremony in london, 2021-07-15 14:00:00 utc ------ the couple exchanged rings: prince harry and meghan markle are happily married.  
Head Entity: prince harry  
Tail Entity: meghan markle  

Relation: person spouse  
Context: in a quaint chapel in nashville, 2018-10-06 16:30:00 utc ------ they celebrated their love: carrie underwood and mike fisher have been partners for life.  
Head Entity: carrie underwood  
Tail Entity: mike fisher  
Mixup data size:  3730
MixupTrain:  epoch  0, batch     0 | loss: 5.5154543MixupTrain:  epoch  0, batch     1 | loss: 5.5660071MixupTrain:  epoch  0, batch     2 | loss: 6.0944777MixupTrain:  epoch  0, batch     3 | loss: 5.9539280MixupTrain:  epoch  0, batch     4 | loss: 5.4402308MixupTrain:  epoch  0, batch     5 | loss: 5.1468511MixupTrain:  epoch  0, batch     6 | loss: 5.4160485MixupTrain:  epoch  0, batch     7 | loss: 5.1513867MixupTrain:  epoch  0, batch     8 | loss: 5.3852911MixupTrain:  epoch  0, batch     9 | loss: 5.0869856MixupTrain:  epoch  0, batch    10 | loss: 5.1401467MixupTrain:  epoch  0, batch    11 | loss: 4.4070892MixupTrain:  epoch  0, batch    12 | loss: 5.1225634MixupTrain:  epoch  0, batch    13 | loss: 4.6929283MixupTrain:  epoch  0, batch    14 | loss: 4.7473698MixupTrain:  epoch  0, batch    15 | loss: 4.5449004MixupTrain:  epoch  0, batch    16 | loss: 5.0819149MixupTrain:  epoch  0, batch    17 | loss: 4.3224773MixupTrain:  epoch  0, batch    18 | loss: 5.1306281MixupTrain:  epoch  0, batch    19 | loss: 4.2275467MixupTrain:  epoch  0, batch    20 | loss: 4.7988892MixupTrain:  epoch  0, batch    21 | loss: 4.4360523MixupTrain:  epoch  0, batch    22 | loss: 4.2884789MixupTrain:  epoch  0, batch    23 | loss: 4.4822702MixupTrain:  epoch  0, batch    24 | loss: 3.7825525MixupTrain:  epoch  0, batch    25 | loss: 4.3516831MixupTrain:  epoch  0, batch    26 | loss: 4.0152011MixupTrain:  epoch  0, batch    27 | loss: 4.1535721MixupTrain:  epoch  0, batch    28 | loss: 4.7543526MixupTrain:  epoch  0, batch    29 | loss: 3.9970415MixupTrain:  epoch  0, batch    30 | loss: 4.1942496MixupTrain:  epoch  0, batch    31 | loss: 4.3452816MixupTrain:  epoch  0, batch    32 | loss: 4.1089058MixupTrain:  epoch  0, batch    33 | loss: 3.9217126MixupTrain:  epoch  0, batch    34 | loss: 4.1977816MixupTrain:  epoch  0, batch    35 | loss: 3.9890544MixupTrain:  epoch  0, batch    36 | loss: 3.7724380MixupTrain:  epoch  0, batch    37 | loss: 3.9171975MixupTrain:  epoch  0, batch    38 | loss: 4.2757702MixupTrain:  epoch  0, batch    39 | loss: 3.9675488MixupTrain:  epoch  0, batch    40 | loss: 3.4734395MixupTrain:  epoch  0, batch    41 | loss: 3.8111949MixupTrain:  epoch  0, batch    42 | loss: 3.8116202MixupTrain:  epoch  0, batch    43 | loss: 4.1324615MixupTrain:  epoch  0, batch    44 | loss: 3.4127195MixupTrain:  epoch  0, batch    45 | loss: 3.5746427MixupTrain:  epoch  0, batch    46 | loss: 4.0244484MixupTrain:  epoch  0, batch    47 | loss: 3.6049376MixupTrain:  epoch  0, batch    48 | loss: 3.9002535MixupTrain:  epoch  0, batch    49 | loss: 3.8003705MixupTrain:  epoch  0, batch    50 | loss: 3.3939703MixupTrain:  epoch  0, batch    51 | loss: 3.5078065MixupTrain:  epoch  0, batch    52 | loss: 3.0541220MixupTrain:  epoch  0, batch    53 | loss: 3.6975603MixupTrain:  epoch  0, batch    54 | loss: 3.3546054MixupTrain:  epoch  0, batch    55 | loss: 3.4524374MixupTrain:  epoch  0, batch    56 | loss: 3.1697071MixupTrain:  epoch  0, batch    57 | loss: 3.4293978MixupTrain:  epoch  0, batch    58 | loss: 3.5298305MixupTrain:  epoch  0, batch    59 | loss: 3.0731802MixupTrain:  epoch  0, batch    60 | loss: 3.2572284MixupTrain:  epoch  0, batch    61 | loss: 3.3387020MixupTrain:  epoch  0, batch    62 | loss: 2.9262958MixupTrain:  epoch  0, batch    63 | loss: 2.9263439MixupTrain:  epoch  0, batch    64 | loss: 2.9966781MixupTrain:  epoch  0, batch    65 | loss: 2.8878984MixupTrain:  epoch  0, batch    66 | loss: 3.0601368MixupTrain:  epoch  0, batch    67 | loss: 2.9263539MixupTrain:  epoch  0, batch    68 | loss: 2.9601264MixupTrain:  epoch  0, batch    69 | loss: 2.9845672MixupTrain:  epoch  0, batch    70 | loss: 3.3834157MixupTrain:  epoch  0, batch    71 | loss: 2.9661522MixupTrain:  epoch  0, batch    72 | loss: 3.0160909MixupTrain:  epoch  0, batch    73 | loss: 3.3015113MixupTrain:  epoch  0, batch    74 | loss: 2.8418987MixupTrain:  epoch  0, batch    75 | loss: 2.9940691MixupTrain:  epoch  0, batch    76 | loss: 2.8246603MixupTrain:  epoch  0, batch    77 | loss: 3.0651646MixupTrain:  epoch  0, batch    78 | loss: 3.1471119MixupTrain:  epoch  0, batch    79 | loss: 3.1537578MixupTrain:  epoch  0, batch    80 | loss: 2.5652537MixupTrain:  epoch  0, batch    81 | loss: 2.8915110MixupTrain:  epoch  0, batch    82 | loss: 2.9768665MixupTrain:  epoch  0, batch    83 | loss: 2.8204265MixupTrain:  epoch  0, batch    84 | loss: 2.8351321MixupTrain:  epoch  0, batch    85 | loss: 2.9930480MixupTrain:  epoch  0, batch    86 | loss: 2.7560484MixupTrain:  epoch  0, batch    87 | loss: 2.9877038MixupTrain:  epoch  0, batch    88 | loss: 2.6612864MixupTrain:  epoch  0, batch    89 | loss: 2.6376872MixupTrain:  epoch  0, batch    90 | loss: 2.9019895MixupTrain:  epoch  0, batch    91 | loss: 2.7446377MixupTrain:  epoch  0, batch    92 | loss: 2.8235786MixupTrain:  epoch  0, batch    93 | loss: 2.6017280MixupTrain:  epoch  0, batch    94 | loss: 2.7225137MixupTrain:  epoch  0, batch    95 | loss: 2.7572112MixupTrain:  epoch  0, batch    96 | loss: 2.6994591MixupTrain:  epoch  0, batch    97 | loss: 2.5501547MixupTrain:  epoch  0, batch    98 | loss: 2.6207473MixupTrain:  epoch  0, batch    99 | loss: 2.6482697MixupTrain:  epoch  0, batch   100 | loss: 2.7388253MixupTrain:  epoch  0, batch   101 | loss: 2.4641478MixupTrain:  epoch  0, batch   102 | loss: 2.4526675MixupTrain:  epoch  0, batch   103 | loss: 2.4144044MixupTrain:  epoch  0, batch   104 | loss: 2.5283980MixupTrain:  epoch  0, batch   105 | loss: 2.5688303MixupTrain:  epoch  0, batch   106 | loss: 2.6422400MixupTrain:  epoch  0, batch   107 | loss: 2.4684107MixupTrain:  epoch  0, batch   108 | loss: 2.6602185MixupTrain:  epoch  0, batch   109 | loss: 2.4189701MixupTrain:  epoch  0, batch   110 | loss: 2.5737824MixupTrain:  epoch  0, batch   111 | loss: 2.4469352MixupTrain:  epoch  0, batch   112 | loss: 2.3165002MixupTrain:  epoch  0, batch   113 | loss: 2.3184404MixupTrain:  epoch  0, batch   114 | loss: 2.5260687MixupTrain:  epoch  0, batch   115 | loss: 2.4232314MixupTrain:  epoch  0, batch   116 | loss: 2.4108090MixupTrain:  epoch  0, batch   117 | loss: 2.5605421MixupTrain:  epoch  0, batch   118 | loss: 2.4147129MixupTrain:  epoch  0, batch   119 | loss: 2.2227836MixupTrain:  epoch  0, batch   120 | loss: 2.4188585MixupTrain:  epoch  0, batch   121 | loss: 2.3804946MixupTrain:  epoch  0, batch   122 | loss: 2.4268730MixupTrain:  epoch  0, batch   123 | loss: 2.5691500MixupTrain:  epoch  0, batch   124 | loss: 2.3370831MixupTrain:  epoch  0, batch   125 | loss: 2.3008389MixupTrain:  epoch  0, batch   126 | loss: 2.3943806MixupTrain:  epoch  0, batch   127 | loss: 2.3745978MixupTrain:  epoch  0, batch   128 | loss: 2.5037956MixupTrain:  epoch  0, batch   129 | loss: 2.4499302MixupTrain:  epoch  0, batch   130 | loss: 2.5279779MixupTrain:  epoch  0, batch   131 | loss: 2.6315269MixupTrain:  epoch  0, batch   132 | loss: 2.3587101MixupTrain:  epoch  0, batch   133 | loss: 2.4059324MixupTrain:  epoch  0, batch   134 | loss: 2.3135142MixupTrain:  epoch  0, batch   135 | loss: 2.2910357MixupTrain:  epoch  0, batch   136 | loss: 2.4334130MixupTrain:  epoch  0, batch   137 | loss: 2.3009899MixupTrain:  epoch  0, batch   138 | loss: 2.3496313MixupTrain:  epoch  0, batch   139 | loss: 2.2797120MixupTrain:  epoch  0, batch   140 | loss: 2.3370245MixupTrain:  epoch  0, batch   141 | loss: 2.4203997MixupTrain:  epoch  0, batch   142 | loss: 2.3682694MixupTrain:  epoch  0, batch   143 | loss: 2.2284505MixupTrain:  epoch  0, batch   144 | loss: 2.3277879MixupTrain:  epoch  0, batch   145 | loss: 2.3658366MixupTrain:  epoch  0, batch   146 | loss: 2.3549013MixupTrain:  epoch  0, batch   147 | loss: 2.2632422MixupTrain:  epoch  0, batch   148 | loss: 2.3077583MixupTrain:  epoch  0, batch   149 | loss: 2.4496477MixupTrain:  epoch  0, batch   150 | loss: 2.2867768MixupTrain:  epoch  0, batch   151 | loss: 2.1766043MixupTrain:  epoch  0, batch   152 | loss: 2.4181848MixupTrain:  epoch  0, batch   153 | loss: 2.3731096MixupTrain:  epoch  0, batch   154 | loss: 2.2316658MixupTrain:  epoch  0, batch   155 | loss: 2.2650733MixupTrain:  epoch  0, batch   156 | loss: 2.3462231MixupTrain:  epoch  0, batch   157 | loss: 2.2860377MixupTrain:  epoch  0, batch   158 | loss: 2.2765698MixupTrain:  epoch  0, batch   159 | loss: 2.2300544MixupTrain:  epoch  0, batch   160 | loss: 2.1872568MixupTrain:  epoch  0, batch   161 | loss: 2.3752515MixupTrain:  epoch  0, batch   162 | loss: 2.2189226MixupTrain:  epoch  0, batch   163 | loss: 2.2366521MixupTrain:  epoch  0, batch   164 | loss: 2.1870165MixupTrain:  epoch  0, batch   165 | loss: 2.2931731MixupTrain:  epoch  0, batch   166 | loss: 2.3677816MixupTrain:  epoch  0, batch   167 | loss: 2.3822699MixupTrain:  epoch  0, batch   168 | loss: 2.3602786MixupTrain:  epoch  0, batch   169 | loss: 2.2710967MixupTrain:  epoch  0, batch   170 | loss: 2.2273626MixupTrain:  epoch  0, batch   171 | loss: 2.2731969MixupTrain:  epoch  0, batch   172 | loss: 2.2430329MixupTrain:  epoch  0, batch   173 | loss: 2.3772345MixupTrain:  epoch  0, batch   174 | loss: 2.3067279MixupTrain:  epoch  0, batch   175 | loss: 2.2071834MixupTrain:  epoch  0, batch   176 | loss: 2.2489712MixupTrain:  epoch  0, batch   177 | loss: 2.3066463MixupTrain:  epoch  0, batch   178 | loss: 2.2796288MixupTrain:  epoch  0, batch   179 | loss: 2.2154694MixupTrain:  epoch  0, batch   180 | loss: 2.1838369MixupTrain:  epoch  0, batch   181 | loss: 2.2258084MixupTrain:  epoch  0, batch   182 | loss: 2.1312804MixupTrain:  epoch  0, batch   183 | loss: 2.1290665MixupTrain:  epoch  0, batch   184 | loss: 2.2169695MixupTrain:  epoch  0, batch   185 | loss: 2.2287145MixupTrain:  epoch  0, batch   186 | loss: 2.1915851MixupTrain:  epoch  0, batch   187 | loss: 2.2570982MixupTrain:  epoch  0, batch   188 | loss: 2.2556586MixupTrain:  epoch  0, batch   189 | loss: 2.1451597MixupTrain:  epoch  0, batch   190 | loss: 2.2498522MixupTrain:  epoch  0, batch   191 | loss: 2.1433017MixupTrain:  epoch  0, batch   192 | loss: 2.1938214MixupTrain:  epoch  0, batch   193 | loss: 2.2492504MixupTrain:  epoch  0, batch   194 | loss: 2.2465062MixupTrain:  epoch  0, batch   195 | loss: 2.1480751MixupTrain:  epoch  0, batch   196 | loss: 2.2078209MixupTrain:  epoch  0, batch   197 | loss: 2.1127448MixupTrain:  epoch  0, batch   198 | loss: 2.2052286MixupTrain:  epoch  0, batch   199 | loss: 2.3268926MixupTrain:  epoch  0, batch   200 | loss: 2.2516861MixupTrain:  epoch  0, batch   201 | loss: 2.2542505MixupTrain:  epoch  0, batch   202 | loss: 2.1968520MixupTrain:  epoch  0, batch   203 | loss: 2.2382042MixupTrain:  epoch  0, batch   204 | loss: 2.2569883MixupTrain:  epoch  0, batch   205 | loss: 2.1479268MixupTrain:  epoch  0, batch   206 | loss: 2.1994154MixupTrain:  epoch  0, batch   207 | loss: 2.2134185MixupTrain:  epoch  0, batch   208 | loss: 2.2041731MixupTrain:  epoch  0, batch   209 | loss: 2.1643252MixupTrain:  epoch  0, batch   210 | loss: 2.3106117MixupTrain:  epoch  0, batch   211 | loss: 2.1863956MixupTrain:  epoch  0, batch   212 | loss: 2.2383268MixupTrain:  epoch  0, batch   213 | loss: 2.2368026MixupTrain:  epoch  0, batch   214 | loss: 2.1561744MixupTrain:  epoch  0, batch   215 | loss: 2.1867337MixupTrain:  epoch  0, batch   216 | loss: 2.1484609MixupTrain:  epoch  0, batch   217 | loss: 2.1336322MixupTrain:  epoch  0, batch   218 | loss: 2.1911852MixupTrain:  epoch  0, batch   219 | loss: 2.2121618MixupTrain:  epoch  0, batch   220 | loss: 2.1225986MixupTrain:  epoch  0, batch   221 | loss: 2.1568923MixupTrain:  epoch  0, batch   222 | loss: 2.1627374MixupTrain:  epoch  0, batch   223 | loss: 2.1473670MixupTrain:  epoch  0, batch   224 | loss: 2.2711735MixupTrain:  epoch  0, batch   225 | loss: 2.1760774MixupTrain:  epoch  0, batch   226 | loss: 2.1889124MixupTrain:  epoch  0, batch   227 | loss: 2.1462469MixupTrain:  epoch  0, batch   228 | loss: 2.1508007MixupTrain:  epoch  0, batch   229 | loss: 2.0875041MixupTrain:  epoch  0, batch   230 | loss: 2.2141869MixupTrain:  epoch  0, batch   231 | loss: 2.2400608MixupTrain:  epoch  0, batch   232 | loss: 2.1123552MixupTrain:  epoch  0, batch   233 | loss: 1.9735312
MemoryTrain:  epoch  0, batch     0 | loss: 2.0779676MemoryTrain:  epoch  0, batch     1 | loss: 3.9116015MemoryTrain:  epoch  0, batch     2 | loss: 2.8442683MemoryTrain:  epoch  0, batch     3 | loss: 3.3739438MemoryTrain:  epoch  0, batch     4 | loss: 2.3761210MemoryTrain:  epoch  1, batch     0 | loss: 1.8835528MemoryTrain:  epoch  1, batch     1 | loss: 1.8711354MemoryTrain:  epoch  1, batch     2 | loss: 1.8660495MemoryTrain:  epoch  1, batch     3 | loss: 1.8888264MemoryTrain:  epoch  1, batch     4 | loss: 1.8206203MemoryTrain:  epoch  2, batch     0 | loss: 1.8596634MemoryTrain:  epoch  2, batch     1 | loss: 1.8625772MemoryTrain:  epoch  2, batch     2 | loss: 1.8702953MemoryTrain:  epoch  2, batch     3 | loss: 1.8615885MemoryTrain:  epoch  2, batch     4 | loss: 1.8496261MemoryTrain:  epoch  3, batch     0 | loss: 1.8699479MemoryTrain:  epoch  3, batch     1 | loss: 1.8590794MemoryTrain:  epoch  3, batch     2 | loss: 1.8750722MemoryTrain:  epoch  3, batch     3 | loss: 1.8347449MemoryTrain:  epoch  3, batch     4 | loss: 1.8334486MemoryTrain:  epoch  4, batch     0 | loss: 1.8871568MemoryTrain:  epoch  4, batch     1 | loss: 1.8640711MemoryTrain:  epoch  4, batch     2 | loss: 1.8573796MemoryTrain:  epoch  4, batch     3 | loss: 1.8616667MemoryTrain:  epoch  4, batch     4 | loss: 1.8389590MemoryTrain:  epoch  5, batch     0 | loss: 1.8608402MemoryTrain:  epoch  5, batch     1 | loss: 1.9058082MemoryTrain:  epoch  5, batch     2 | loss: 1.8657070MemoryTrain:  epoch  5, batch     3 | loss: 1.8711541MemoryTrain:  epoch  5, batch     4 | loss: 1.8318005MemoryTrain:  epoch  6, batch     0 | loss: 1.8989747MemoryTrain:  epoch  6, batch     1 | loss: 1.8677858MemoryTrain:  epoch  6, batch     2 | loss: 1.8384691MemoryTrain:  epoch  6, batch     3 | loss: 1.8516238MemoryTrain:  epoch  6, batch     4 | loss: 1.8159940MemoryTrain:  epoch  7, batch     0 | loss: 1.8581703MemoryTrain:  epoch  7, batch     1 | loss: 1.8484223MemoryTrain:  epoch  7, batch     2 | loss: 1.8372697MemoryTrain:  epoch  7, batch     3 | loss: 1.8357747MemoryTrain:  epoch  7, batch     4 | loss: 1.8681182MemoryTrain:  epoch  8, batch     0 | loss: 1.8530737MemoryTrain:  epoch  8, batch     1 | loss: 1.8574953MemoryTrain:  epoch  8, batch     2 | loss: 1.8521783MemoryTrain:  epoch  8, batch     3 | loss: 1.8493798MemoryTrain:  epoch  8, batch     4 | loss: 1.8229764MemoryTrain:  epoch  9, batch     0 | loss: 1.8330905MemoryTrain:  epoch  9, batch     1 | loss: 1.8559880MemoryTrain:  epoch  9, batch     2 | loss: 1.8462100MemoryTrain:  epoch  9, batch     3 | loss: 1.8588978MemoryTrain:  epoch  9, batch     4 | loss: 1.9160633
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 87.50%   [EVAL] batch:    2 | acc: 81.25%,  total acc: 85.42%   [EVAL] batch:    3 | acc: 93.75%,  total acc: 87.50%   [EVAL] batch:    4 | acc: 100.00%,  total acc: 90.00%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 91.67%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 92.86%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 92.97%   [EVAL] batch:    8 | acc: 93.75%,  total acc: 93.06%   [EVAL] batch:    9 | acc: 75.00%,  total acc: 91.25%   [EVAL] batch:   10 | acc: 75.00%,  total acc: 89.77%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 90.10%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 90.38%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 90.62%   [EVAL] batch:   14 | acc: 43.75%,  total acc: 87.50%   
[EVAL] batch:    0 | acc: 43.75%,  total acc: 43.75%   [EVAL] batch:    1 | acc: 62.50%,  total acc: 53.12%   [EVAL] batch:    2 | acc: 56.25%,  total acc: 54.17%   [EVAL] batch:    3 | acc: 43.75%,  total acc: 51.56%   [EVAL] batch:    4 | acc: 43.75%,  total acc: 50.00%   [EVAL] batch:    5 | acc: 43.75%,  total acc: 48.96%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 55.36%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 60.16%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 64.58%   [EVAL] batch:    9 | acc: 100.00%,  total acc: 68.12%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 71.02%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 72.92%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 74.52%   [EVAL] batch:   13 | acc: 62.50%,  total acc: 73.66%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 73.75%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 72.66%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 72.79%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 72.22%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 71.71%   [EVAL] batch:   19 | acc: 87.50%,  total acc: 72.50%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 73.81%   [EVAL] batch:   21 | acc: 100.00%,  total acc: 75.00%   [EVAL] batch:   22 | acc: 93.75%,  total acc: 75.82%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 76.56%   [EVAL] batch:   24 | acc: 100.00%,  total acc: 77.50%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 78.37%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 78.94%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 79.69%   [EVAL] batch:   28 | acc: 68.75%,  total acc: 79.31%   [EVAL] batch:   29 | acc: 62.50%,  total acc: 78.75%   [EVAL] batch:   30 | acc: 62.50%,  total acc: 78.23%   [EVAL] batch:   31 | acc: 87.50%,  total acc: 78.52%   [EVAL] batch:   32 | acc: 81.25%,  total acc: 78.60%   [EVAL] batch:   33 | acc: 81.25%,  total acc: 78.68%   [EVAL] batch:   34 | acc: 93.75%,  total acc: 79.11%   [EVAL] batch:   35 | acc: 81.25%,  total acc: 79.17%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 79.73%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 80.26%   [EVAL] batch:   38 | acc: 100.00%,  total acc: 80.77%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 81.25%   [EVAL] batch:   40 | acc: 87.50%,  total acc: 81.40%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 81.85%   [EVAL] batch:   42 | acc: 56.25%,  total acc: 81.25%   [EVAL] batch:   43 | acc: 87.50%,  total acc: 81.39%   [EVAL] batch:   44 | acc: 93.75%,  total acc: 81.67%   [EVAL] batch:   45 | acc: 93.75%,  total acc: 81.93%   [EVAL] batch:   46 | acc: 81.25%,  total acc: 81.91%   
cur_acc:  ['0.8580', '0.8750']
his_acc:  ['0.8580', '0.8191']
CurrentTrain: epoch  0, batch     0 | loss: 5.9588814CurrentTrain: epoch  0, batch     1 | loss: 6.6597629CurrentTrain: epoch  1, batch     0 | loss: 6.7194796CurrentTrain: epoch  1, batch     1 | loss: 5.0824833CurrentTrain: epoch  2, batch     0 | loss: 5.1743035CurrentTrain: epoch  2, batch     1 | loss: 5.1371450CurrentTrain: epoch  3, batch     0 | loss: 5.0684166CurrentTrain: epoch  3, batch     1 | loss: 4.4360232CurrentTrain: epoch  4, batch     0 | loss: 4.4426832CurrentTrain: epoch  4, batch     1 | loss: 4.8852730CurrentTrain: epoch  5, batch     0 | loss: 5.2634521CurrentTrain: epoch  5, batch     1 | loss: 3.0273602CurrentTrain: epoch  6, batch     0 | loss: 4.3404069CurrentTrain: epoch  6, batch     1 | loss: 4.6110501CurrentTrain: epoch  7, batch     0 | loss: 3.9195240CurrentTrain: epoch  7, batch     1 | loss: 3.5749469CurrentTrain: epoch  8, batch     0 | loss: 3.5755129CurrentTrain: epoch  8, batch     1 | loss: 3.3557611CurrentTrain: epoch  9, batch     0 | loss: 2.9143634CurrentTrain: epoch  9, batch     1 | loss: 2.2989995
#### person date of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person date of birth" means a person was born in a date.
Here is an example:
Relation: person date of birth
Context: born of schoolteacher parents in the western town of sabaneta on july 28 , 1954 , chavez studied at the military academy of venezuela in caracas .
Head Entity: chavez
Tail Entity: july 28 , 1954
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person date of birth":
Relation: person date of birth  
Context: the famous physicist albert einstein was born in ulm, in the kingdom of wurttemberg in the german empire on march 14, 1879.  
Head Entity: albert einstein  
Tail Entity: march 14, 1879  

Relation: person date of birth  
Context: the renowned author jane austen was born on december 16, 1775, in steventon, hampshire, england.  
Head Entity: jane austen  
Tail Entity: december 16, 1775  

Relation: person date of birth  
Context: the legendary musician freddie mercury was born farrokh bulsara on september 5, 1946, in zanzibar, tanzania.  
Head Entity: freddie mercury  
Tail Entity: september 5, 1946  

Relation: person date of birth  
Context: the influential civil rights leader martin luther king jr. was born on january 15, 1929, in atlanta, georgia.  
Head Entity: martin luther king jr.  
Tail Entity: january 15, 1929  

Relation: person date of birth  
Context: the famous painter pablo picasso was born on october 25, 1881, in malaga, spain.  
Head Entity: pablo picasso  
Tail Entity: october 25, 1881  
#### person stateorprovince of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of birth" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of birth
Context: jane matilda bolin was born on april 11 , 1908 , in poughkeepsie , ny .
Head Entity: jane matilda bolin
Tail Entity: ny
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of birth":
Relation: person stateorprovince of birth  
Context: albert einstein was born on march 14, 1879, in ulm, württemberg, germany.  
Head Entity: albert einstein  
Tail Entity: württemberg  

Relation: person stateorprovince of birth  
Context: marilyn monroe was born on june 1, 1926, in los angeles, california.  
Head Entity: marilyn monroe  
Tail Entity: california  

Relation: person stateorprovince of birth  
Context: barack obama was born on august 4, 1961, in honolulu, hawaii.  
Head Entity: barack obama  
Tail Entity: hawaii  

Relation: person stateorprovince of birth  
Context: agatha christie was born on september 15, 1890, in torquay, devon.  
Head Entity: agatha christie  
Tail Entity: devon  

Relation: person stateorprovince of birth  
Context: nelson mandela was born on july 18, 1918, in mvezo, eastern cape.  
Head Entity: nelson mandela  
Tail Entity: eastern cape  
#### person parents ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person parents" means a person 's parent is a person.
Here is an example:
Relation: person parents
Context: lynne spears told the court that lutfi had treated her daughter like a hostage in her own home , drugged her and took over her finances .
Head Entity: her
Tail Entity: lynne spears
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person parents":
1. Relation: person parents  
   Context: After years of hard work, Sarah finally made her parents proud by graduating at the top of her class.  
   Head Entity: her  
   Tail Entity: parents  

2. Relation: person parents  
   Context: During the family reunion, Michael shared stories about how his father taught him valuable life lessons.  
   Head Entity: his  
   Tail Entity: father  

3. Relation: person parents  
   Context: Emily often reminisces about the summer vacations she spent with her mother at the beach.  
   Head Entity: her  
   Tail Entity: mother  

4. Relation: person parents  
   Context: The documentary highlighted how the struggles of his parents shaped his career as an artist.  
   Head Entity: his  
   Tail Entity: parents  

5. Relation: person parents  
   Context: Jessica credits her success to the unwavering support she received from her father throughout her life.  
   Head Entity: her  
   Tail Entity: father  
#### person employee of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person employee of" means a person is an employee of an organization.
Here is an example:
Relation: person employee of
Context: seeking revenge , axel reunites with old pal sgt. billy rosewood -lrb- judge reinhold -rrb- and jon flint -lrb- hector elizondo -rrb- of the beverly hills police department .
Head Entity: hector elizondo
Tail Entity: beverly hills police department
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person employee of":
Relation: person employee of  
Context: After years of hard work, Maria finally secured a position at the prestigious tech firm, Innovatech Solutions, where she could showcase her skills.  
Head Entity: Maria  
Tail Entity: Innovatech Solutions  

Relation: person employee of  
Context: John has been with the company for over a decade, contributing significantly to its growth and success as a lead engineer.  
Head Entity: John  
Tail Entity: the company  

Relation: person employee of  
Context: As a talented graphic designer, Sarah was thrilled to join Creative Minds Agency, where she could work on exciting projects.  
Head Entity: Sarah  
Tail Entity: Creative Minds Agency  

Relation: person employee of  
Context: After completing his internship, David was offered a full-time role at Green Energy Corp, where he would work on sustainable projects.  
Head Entity: David  
Tail Entity: Green Energy Corp  

Relation: person employee of  
Context: Emily's dedication and innovative ideas led her to become a senior analyst at Global Finance Group, a leader in financial consulting.  
Head Entity: Emily  
Tail Entity: Global Finance Group  
#### person stateorprovince of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of death" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of death
Context: irene morgan kirkaldy , whose defiance of bus segregation laws more than a decade before rosa parks ' landmark case helped lay the foundation for later civil rights victories , died friday at her home in hayes , va. .
Head Entity: irene morgan kirkaldy
Tail Entity: va.
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of death":
Relation: person stateorprovince of death  
Context: john doe, a renowned author known for his thrilling novels, passed away unexpectedly in his sleep at his residence in los angeles, ca.  
Head Entity: john doe  
Tail Entity: ca.  

Relation: person stateorprovince of death  
Context: after a long battle with illness, elizabeth taylor, the iconic actress, died peacefully in her home located in bel air, ca.  
Head Entity: elizabeth taylor  
Tail Entity: ca.  

Relation: person stateorprovince of death  
Context: the famous physicist, albert einstein, took his last breath in a hospital in princeton, nj, where he had been receiving treatment.  
Head Entity: albert einstein  
Tail Entity: nj.  

Relation: person stateorprovince of death  
Context: the beloved musician, prince, was found unresponsive in his home in minneapolis, mn, leading to an outpouring of grief from fans worldwide.  
Head Entity: prince  
Tail Entity: mn.  

Relation: person stateorprovince of death  
Context: the legendary civil rights leader, martin luther king jr., was assassinated in memphis, tn, a tragic event that shook the nation.  
Head Entity: martin luther king jr.  
Tail Entity: tn.  
Mixup data size:  6820
MixupTrain:  epoch  0, batch     0 | loss: 4.5421162MixupTrain:  epoch  0, batch     1 | loss: 5.3487244MixupTrain:  epoch  0, batch     2 | loss: 5.0118704MixupTrain:  epoch  0, batch     3 | loss: 4.9918065MixupTrain:  epoch  0, batch     4 | loss: 4.5061417MixupTrain:  epoch  0, batch     5 | loss: 3.7011693MixupTrain:  epoch  0, batch     6 | loss: 4.8315077MixupTrain:  epoch  0, batch     7 | loss: 4.1030455MixupTrain:  epoch  0, batch     8 | loss: 4.1068068MixupTrain:  epoch  0, batch     9 | loss: 4.2396588MixupTrain:  epoch  0, batch    10 | loss: 3.9931431MixupTrain:  epoch  0, batch    11 | loss: 3.9480448MixupTrain:  epoch  0, batch    12 | loss: 3.7491148MixupTrain:  epoch  0, batch    13 | loss: 3.5774777MixupTrain:  epoch  0, batch    14 | loss: 3.6054063MixupTrain:  epoch  0, batch    15 | loss: 3.6569242MixupTrain:  epoch  0, batch    16 | loss: 3.6056685MixupTrain:  epoch  0, batch    17 | loss: 3.9280858MixupTrain:  epoch  0, batch    18 | loss: 4.2821417MixupTrain:  epoch  0, batch    19 | loss: 3.4621572MixupTrain:  epoch  0, batch    20 | loss: 3.4397840MixupTrain:  epoch  0, batch    21 | loss: 2.9275019MixupTrain:  epoch  0, batch    22 | loss: 3.1200771MixupTrain:  epoch  0, batch    23 | loss: 3.4936380MixupTrain:  epoch  0, batch    24 | loss: 3.1823733MixupTrain:  epoch  0, batch    25 | loss: 3.0471325MixupTrain:  epoch  0, batch    26 | loss: 2.9314678MixupTrain:  epoch  0, batch    27 | loss: 3.7478266MixupTrain:  epoch  0, batch    28 | loss: 2.9104028MixupTrain:  epoch  0, batch    29 | loss: 3.5511150MixupTrain:  epoch  0, batch    30 | loss: 3.2494659MixupTrain:  epoch  0, batch    31 | loss: 3.1098595MixupTrain:  epoch  0, batch    32 | loss: 3.0619292MixupTrain:  epoch  0, batch    33 | loss: 2.8416314MixupTrain:  epoch  0, batch    34 | loss: 2.7199578MixupTrain:  epoch  0, batch    35 | loss: 2.8606529MixupTrain:  epoch  0, batch    36 | loss: 3.0653231MixupTrain:  epoch  0, batch    37 | loss: 2.9077659MixupTrain:  epoch  0, batch    38 | loss: 2.6567070MixupTrain:  epoch  0, batch    39 | loss: 2.8757615MixupTrain:  epoch  0, batch    40 | loss: 3.2411995MixupTrain:  epoch  0, batch    41 | loss: 2.8382726MixupTrain:  epoch  0, batch    42 | loss: 3.4424675MixupTrain:  epoch  0, batch    43 | loss: 3.0830100MixupTrain:  epoch  0, batch    44 | loss: 2.7436345MixupTrain:  epoch  0, batch    45 | loss: 3.0361004MixupTrain:  epoch  0, batch    46 | loss: 3.2766440MixupTrain:  epoch  0, batch    47 | loss: 2.8739643MixupTrain:  epoch  0, batch    48 | loss: 2.9978766MixupTrain:  epoch  0, batch    49 | loss: 2.8575482MixupTrain:  epoch  0, batch    50 | loss: 2.3067698MixupTrain:  epoch  0, batch    51 | loss: 2.8741083MixupTrain:  epoch  0, batch    52 | loss: 2.5314279MixupTrain:  epoch  0, batch    53 | loss: 2.6316671MixupTrain:  epoch  0, batch    54 | loss: 3.0665917MixupTrain:  epoch  0, batch    55 | loss: 2.8466139MixupTrain:  epoch  0, batch    56 | loss: 2.1505272MixupTrain:  epoch  0, batch    57 | loss: 2.6274271MixupTrain:  epoch  0, batch    58 | loss: 2.7051311MixupTrain:  epoch  0, batch    59 | loss: 2.9414248MixupTrain:  epoch  0, batch    60 | loss: 2.6913691MixupTrain:  epoch  0, batch    61 | loss: 2.4731193MixupTrain:  epoch  0, batch    62 | loss: 2.7118001MixupTrain:  epoch  0, batch    63 | loss: 2.6375394MixupTrain:  epoch  0, batch    64 | loss: 2.5499845MixupTrain:  epoch  0, batch    65 | loss: 2.4925666MixupTrain:  epoch  0, batch    66 | loss: 2.5954380MixupTrain:  epoch  0, batch    67 | loss: 2.3580370MixupTrain:  epoch  0, batch    68 | loss: 2.6747184MixupTrain:  epoch  0, batch    69 | loss: 2.4359651MixupTrain:  epoch  0, batch    70 | loss: 2.1362917MixupTrain:  epoch  0, batch    71 | loss: 2.2612469MixupTrain:  epoch  0, batch    72 | loss: 2.4714315MixupTrain:  epoch  0, batch    73 | loss: 2.2709188MixupTrain:  epoch  0, batch    74 | loss: 2.5484285MixupTrain:  epoch  0, batch    75 | loss: 2.2843595MixupTrain:  epoch  0, batch    76 | loss: 2.4051156MixupTrain:  epoch  0, batch    77 | loss: 2.2740607MixupTrain:  epoch  0, batch    78 | loss: 2.3269525MixupTrain:  epoch  0, batch    79 | loss: 2.4632144MixupTrain:  epoch  0, batch    80 | loss: 2.4229729MixupTrain:  epoch  0, batch    81 | loss: 2.3380585MixupTrain:  epoch  0, batch    82 | loss: 2.3061240MixupTrain:  epoch  0, batch    83 | loss: 2.3937674MixupTrain:  epoch  0, batch    84 | loss: 2.6297469MixupTrain:  epoch  0, batch    85 | loss: 2.3857675MixupTrain:  epoch  0, batch    86 | loss: 2.3470104MixupTrain:  epoch  0, batch    87 | loss: 2.2032287MixupTrain:  epoch  0, batch    88 | loss: 2.4532545MixupTrain:  epoch  0, batch    89 | loss: 2.4691656MixupTrain:  epoch  0, batch    90 | loss: 2.4203069MixupTrain:  epoch  0, batch    91 | loss: 2.2961540MixupTrain:  epoch  0, batch    92 | loss: 2.2803450MixupTrain:  epoch  0, batch    93 | loss: 2.3694317MixupTrain:  epoch  0, batch    94 | loss: 2.3268907MixupTrain:  epoch  0, batch    95 | loss: 2.3321989MixupTrain:  epoch  0, batch    96 | loss: 2.5284367MixupTrain:  epoch  0, batch    97 | loss: 2.2338858MixupTrain:  epoch  0, batch    98 | loss: 2.2561402MixupTrain:  epoch  0, batch    99 | loss: 2.2911057MixupTrain:  epoch  0, batch   100 | loss: 2.1862452MixupTrain:  epoch  0, batch   101 | loss: 2.4124169MixupTrain:  epoch  0, batch   102 | loss: 2.3092189MixupTrain:  epoch  0, batch   103 | loss: 2.3276272MixupTrain:  epoch  0, batch   104 | loss: 2.0757279MixupTrain:  epoch  0, batch   105 | loss: 2.1602321MixupTrain:  epoch  0, batch   106 | loss: 2.1309633MixupTrain:  epoch  0, batch   107 | loss: 2.4203777MixupTrain:  epoch  0, batch   108 | loss: 2.3305795MixupTrain:  epoch  0, batch   109 | loss: 2.2427559MixupTrain:  epoch  0, batch   110 | loss: 2.0390501MixupTrain:  epoch  0, batch   111 | loss: 2.2220592MixupTrain:  epoch  0, batch   112 | loss: 2.3856006MixupTrain:  epoch  0, batch   113 | loss: 2.1653841MixupTrain:  epoch  0, batch   114 | loss: 2.1404109MixupTrain:  epoch  0, batch   115 | loss: 2.3414841MixupTrain:  epoch  0, batch   116 | loss: 2.2704494MixupTrain:  epoch  0, batch   117 | loss: 2.2427876MixupTrain:  epoch  0, batch   118 | loss: 2.3210042MixupTrain:  epoch  0, batch   119 | loss: 2.0593762MixupTrain:  epoch  0, batch   120 | loss: 2.2871838MixupTrain:  epoch  0, batch   121 | loss: 2.2401996MixupTrain:  epoch  0, batch   122 | loss: 2.2921095MixupTrain:  epoch  0, batch   123 | loss: 2.2906408MixupTrain:  epoch  0, batch   124 | loss: 2.1757917MixupTrain:  epoch  0, batch   125 | loss: 2.1854987MixupTrain:  epoch  0, batch   126 | loss: 2.1640186MixupTrain:  epoch  0, batch   127 | loss: 2.1726575MixupTrain:  epoch  0, batch   128 | loss: 2.3012486MixupTrain:  epoch  0, batch   129 | loss: 2.1894546MixupTrain:  epoch  0, batch   130 | loss: 2.2177339MixupTrain:  epoch  0, batch   131 | loss: 2.1787748MixupTrain:  epoch  0, batch   132 | loss: 2.2398601MixupTrain:  epoch  0, batch   133 | loss: 2.1085303MixupTrain:  epoch  0, batch   134 | loss: 2.2472754MixupTrain:  epoch  0, batch   135 | loss: 2.1030474MixupTrain:  epoch  0, batch   136 | loss: 2.1411862MixupTrain:  epoch  0, batch   137 | loss: 2.2777872MixupTrain:  epoch  0, batch   138 | loss: 2.0874949MixupTrain:  epoch  0, batch   139 | loss: 2.1928411MixupTrain:  epoch  0, batch   140 | loss: 2.0253227MixupTrain:  epoch  0, batch   141 | loss: 2.0905190MixupTrain:  epoch  0, batch   142 | loss: 2.1680789MixupTrain:  epoch  0, batch   143 | loss: 2.0379915MixupTrain:  epoch  0, batch   144 | loss: 2.1779616MixupTrain:  epoch  0, batch   145 | loss: 2.2740068MixupTrain:  epoch  0, batch   146 | loss: 2.1968184MixupTrain:  epoch  0, batch   147 | loss: 2.2485745MixupTrain:  epoch  0, batch   148 | loss: 2.1976769MixupTrain:  epoch  0, batch   149 | loss: 2.1033921MixupTrain:  epoch  0, batch   150 | loss: 2.1635408MixupTrain:  epoch  0, batch   151 | loss: 2.1225791MixupTrain:  epoch  0, batch   152 | loss: 2.1541643MixupTrain:  epoch  0, batch   153 | loss: 2.0621912MixupTrain:  epoch  0, batch   154 | loss: 2.0204339MixupTrain:  epoch  0, batch   155 | loss: 2.1361632MixupTrain:  epoch  0, batch   156 | loss: 2.1043267MixupTrain:  epoch  0, batch   157 | loss: 2.0549273MixupTrain:  epoch  0, batch   158 | loss: 2.1279764MixupTrain:  epoch  0, batch   159 | loss: 2.0897062MixupTrain:  epoch  0, batch   160 | loss: 2.1419590MixupTrain:  epoch  0, batch   161 | loss: 2.0918500MixupTrain:  epoch  0, batch   162 | loss: 2.0627098MixupTrain:  epoch  0, batch   163 | loss: 2.1168609MixupTrain:  epoch  0, batch   164 | loss: 2.2236753MixupTrain:  epoch  0, batch   165 | loss: 2.1171670MixupTrain:  epoch  0, batch   166 | loss: 2.0833552MixupTrain:  epoch  0, batch   167 | loss: 2.2038326MixupTrain:  epoch  0, batch   168 | loss: 2.0549097MixupTrain:  epoch  0, batch   169 | loss: 2.0160711MixupTrain:  epoch  0, batch   170 | loss: 2.0769386MixupTrain:  epoch  0, batch   171 | loss: 2.1244826MixupTrain:  epoch  0, batch   172 | loss: 2.1076124MixupTrain:  epoch  0, batch   173 | loss: 2.1533647MixupTrain:  epoch  0, batch   174 | loss: 2.1114094MixupTrain:  epoch  0, batch   175 | loss: 2.0575817MixupTrain:  epoch  0, batch   176 | loss: 2.1993954MixupTrain:  epoch  0, batch   177 | loss: 2.1909008MixupTrain:  epoch  0, batch   178 | loss: 2.0445428MixupTrain:  epoch  0, batch   179 | loss: 2.1893981MixupTrain:  epoch  0, batch   180 | loss: 2.1261044MixupTrain:  epoch  0, batch   181 | loss: 2.1798766MixupTrain:  epoch  0, batch   182 | loss: 2.0175605MixupTrain:  epoch  0, batch   183 | loss: 2.1605678MixupTrain:  epoch  0, batch   184 | loss: 2.0604062MixupTrain:  epoch  0, batch   185 | loss: 2.0780234MixupTrain:  epoch  0, batch   186 | loss: 2.1282401MixupTrain:  epoch  0, batch   187 | loss: 2.0742140MixupTrain:  epoch  0, batch   188 | loss: 2.0911324MixupTrain:  epoch  0, batch   189 | loss: 2.1563418MixupTrain:  epoch  0, batch   190 | loss: 2.1393189MixupTrain:  epoch  0, batch   191 | loss: 2.2070062MixupTrain:  epoch  0, batch   192 | loss: 1.9700296MixupTrain:  epoch  0, batch   193 | loss: 2.2293806MixupTrain:  epoch  0, batch   194 | loss: 2.1099665MixupTrain:  epoch  0, batch   195 | loss: 2.0116405MixupTrain:  epoch  0, batch   196 | loss: 2.0558491MixupTrain:  epoch  0, batch   197 | loss: 2.1570594MixupTrain:  epoch  0, batch   198 | loss: 2.0661955MixupTrain:  epoch  0, batch   199 | loss: 2.0504689MixupTrain:  epoch  0, batch   200 | loss: 2.1096673MixupTrain:  epoch  0, batch   201 | loss: 2.1143999MixupTrain:  epoch  0, batch   202 | loss: 2.0504856MixupTrain:  epoch  0, batch   203 | loss: 2.0479989MixupTrain:  epoch  0, batch   204 | loss: 2.0505137MixupTrain:  epoch  0, batch   205 | loss: 2.1653137MixupTrain:  epoch  0, batch   206 | loss: 1.9867166MixupTrain:  epoch  0, batch   207 | loss: 2.0505819MixupTrain:  epoch  0, batch   208 | loss: 2.0419440MixupTrain:  epoch  0, batch   209 | loss: 2.0094266MixupTrain:  epoch  0, batch   210 | loss: 1.9939162MixupTrain:  epoch  0, batch   211 | loss: 2.0999527MixupTrain:  epoch  0, batch   212 | loss: 2.1282659MixupTrain:  epoch  0, batch   213 | loss: 2.2171872MixupTrain:  epoch  0, batch   214 | loss: 2.0920806MixupTrain:  epoch  0, batch   215 | loss: 2.0648398MixupTrain:  epoch  0, batch   216 | loss: 2.0656788MixupTrain:  epoch  0, batch   217 | loss: 2.0606184MixupTrain:  epoch  0, batch   218 | loss: 2.0296898MixupTrain:  epoch  0, batch   219 | loss: 2.1015344MixupTrain:  epoch  0, batch   220 | loss: 2.1370139MixupTrain:  epoch  0, batch   221 | loss: 2.1697536MixupTrain:  epoch  0, batch   222 | loss: 2.0777230MixupTrain:  epoch  0, batch   223 | loss: 1.9563715MixupTrain:  epoch  0, batch   224 | loss: 2.0454054MixupTrain:  epoch  0, batch   225 | loss: 2.0097878MixupTrain:  epoch  0, batch   226 | loss: 2.0250180MixupTrain:  epoch  0, batch   227 | loss: 2.1695118MixupTrain:  epoch  0, batch   228 | loss: 2.1614203MixupTrain:  epoch  0, batch   229 | loss: 2.0418601MixupTrain:  epoch  0, batch   230 | loss: 2.1385603MixupTrain:  epoch  0, batch   231 | loss: 2.0481184MixupTrain:  epoch  0, batch   232 | loss: 2.0647123MixupTrain:  epoch  0, batch   233 | loss: 2.0785017MixupTrain:  epoch  0, batch   234 | loss: 2.0910041MixupTrain:  epoch  0, batch   235 | loss: 2.0918045MixupTrain:  epoch  0, batch   236 | loss: 1.9658551MixupTrain:  epoch  0, batch   237 | loss: 2.1006293MixupTrain:  epoch  0, batch   238 | loss: 2.1320739MixupTrain:  epoch  0, batch   239 | loss: 2.0602083MixupTrain:  epoch  0, batch   240 | loss: 1.9818407MixupTrain:  epoch  0, batch   241 | loss: 2.1002324MixupTrain:  epoch  0, batch   242 | loss: 2.0733688MixupTrain:  epoch  0, batch   243 | loss: 2.0697849MixupTrain:  epoch  0, batch   244 | loss: 2.0976238MixupTrain:  epoch  0, batch   245 | loss: 2.0112352MixupTrain:  epoch  0, batch   246 | loss: 2.0321147MixupTrain:  epoch  0, batch   247 | loss: 2.0325327MixupTrain:  epoch  0, batch   248 | loss: 2.0235071MixupTrain:  epoch  0, batch   249 | loss: 2.0244145MixupTrain:  epoch  0, batch   250 | loss: 2.0715833MixupTrain:  epoch  0, batch   251 | loss: 2.0957441MixupTrain:  epoch  0, batch   252 | loss: 2.0457234MixupTrain:  epoch  0, batch   253 | loss: 2.0280666MixupTrain:  epoch  0, batch   254 | loss: 2.0152206MixupTrain:  epoch  0, batch   255 | loss: 1.9668428MixupTrain:  epoch  0, batch   256 | loss: 1.9927502MixupTrain:  epoch  0, batch   257 | loss: 2.1014795MixupTrain:  epoch  0, batch   258 | loss: 2.0078068MixupTrain:  epoch  0, batch   259 | loss: 2.1084609MixupTrain:  epoch  0, batch   260 | loss: 2.0253656MixupTrain:  epoch  0, batch   261 | loss: 2.1142352MixupTrain:  epoch  0, batch   262 | loss: 2.0308847MixupTrain:  epoch  0, batch   263 | loss: 1.9969176MixupTrain:  epoch  0, batch   264 | loss: 2.0579193MixupTrain:  epoch  0, batch   265 | loss: 2.0559368MixupTrain:  epoch  0, batch   266 | loss: 1.9685506MixupTrain:  epoch  0, batch   267 | loss: 2.1377711MixupTrain:  epoch  0, batch   268 | loss: 2.0470004MixupTrain:  epoch  0, batch   269 | loss: 2.0282989MixupTrain:  epoch  0, batch   270 | loss: 2.0833373MixupTrain:  epoch  0, batch   271 | loss: 2.0051730MixupTrain:  epoch  0, batch   272 | loss: 1.9386158MixupTrain:  epoch  0, batch   273 | loss: 2.0989587MixupTrain:  epoch  0, batch   274 | loss: 2.0095425MixupTrain:  epoch  0, batch   275 | loss: 2.1082129MixupTrain:  epoch  0, batch   276 | loss: 2.0249977MixupTrain:  epoch  0, batch   277 | loss: 2.0528445MixupTrain:  epoch  0, batch   278 | loss: 2.1090770MixupTrain:  epoch  0, batch   279 | loss: 1.9915626MixupTrain:  epoch  0, batch   280 | loss: 2.0828075MixupTrain:  epoch  0, batch   281 | loss: 2.0184178MixupTrain:  epoch  0, batch   282 | loss: 2.0122802MixupTrain:  epoch  0, batch   283 | loss: 2.0151055MixupTrain:  epoch  0, batch   284 | loss: 2.0622001MixupTrain:  epoch  0, batch   285 | loss: 2.0730529MixupTrain:  epoch  0, batch   286 | loss: 2.0609567MixupTrain:  epoch  0, batch   287 | loss: 2.0434146MixupTrain:  epoch  0, batch   288 | loss: 2.0553493MixupTrain:  epoch  0, batch   289 | loss: 2.0840173MixupTrain:  epoch  0, batch   290 | loss: 2.0574110MixupTrain:  epoch  0, batch   291 | loss: 2.0101173MixupTrain:  epoch  0, batch   292 | loss: 2.0377648MixupTrain:  epoch  0, batch   293 | loss: 2.0071335MixupTrain:  epoch  0, batch   294 | loss: 2.0933623MixupTrain:  epoch  0, batch   295 | loss: 2.0867331MixupTrain:  epoch  0, batch   296 | loss: 1.9985224MixupTrain:  epoch  0, batch   297 | loss: 2.0945187MixupTrain:  epoch  0, batch   298 | loss: 2.0315804MixupTrain:  epoch  0, batch   299 | loss: 2.0528750MixupTrain:  epoch  0, batch   300 | loss: 1.9522461MixupTrain:  epoch  0, batch   301 | loss: 2.0039625MixupTrain:  epoch  0, batch   302 | loss: 1.9965863MixupTrain:  epoch  0, batch   303 | loss: 2.0257220MixupTrain:  epoch  0, batch   304 | loss: 2.0000980MixupTrain:  epoch  0, batch   305 | loss: 2.0695064MixupTrain:  epoch  0, batch   306 | loss: 1.9961164MixupTrain:  epoch  0, batch   307 | loss: 2.0553060MixupTrain:  epoch  0, batch   308 | loss: 2.0624571MixupTrain:  epoch  0, batch   309 | loss: 2.0200181MixupTrain:  epoch  0, batch   310 | loss: 2.0210218MixupTrain:  epoch  0, batch   311 | loss: 2.0786717MixupTrain:  epoch  0, batch   312 | loss: 1.9454454MixupTrain:  epoch  0, batch   313 | loss: 2.1259809MixupTrain:  epoch  0, batch   314 | loss: 1.9249213MixupTrain:  epoch  0, batch   315 | loss: 2.0131447MixupTrain:  epoch  0, batch   316 | loss: 1.9975944MixupTrain:  epoch  0, batch   317 | loss: 2.1122770MixupTrain:  epoch  0, batch   318 | loss: 2.0117488MixupTrain:  epoch  0, batch   319 | loss: 2.0436664MixupTrain:  epoch  0, batch   320 | loss: 2.0975296MixupTrain:  epoch  0, batch   321 | loss: 2.0560515MixupTrain:  epoch  0, batch   322 | loss: 2.0204511MixupTrain:  epoch  0, batch   323 | loss: 2.0427225MixupTrain:  epoch  0, batch   324 | loss: 2.0391123MixupTrain:  epoch  0, batch   325 | loss: 2.0503345MixupTrain:  epoch  0, batch   326 | loss: 1.9735758MixupTrain:  epoch  0, batch   327 | loss: 2.0790684MixupTrain:  epoch  0, batch   328 | loss: 2.0542715MixupTrain:  epoch  0, batch   329 | loss: 2.0609465MixupTrain:  epoch  0, batch   330 | loss: 2.0200100MixupTrain:  epoch  0, batch   331 | loss: 2.0483837MixupTrain:  epoch  0, batch   332 | loss: 2.0967190MixupTrain:  epoch  0, batch   333 | loss: 2.0600681MixupTrain:  epoch  0, batch   334 | loss: 2.0071578MixupTrain:  epoch  0, batch   335 | loss: 2.0127716MixupTrain:  epoch  0, batch   336 | loss: 1.9911776MixupTrain:  epoch  0, batch   337 | loss: 2.0164177MixupTrain:  epoch  0, batch   338 | loss: 2.0730751MixupTrain:  epoch  0, batch   339 | loss: 2.0354586MixupTrain:  epoch  0, batch   340 | loss: 2.0728059MixupTrain:  epoch  0, batch   341 | loss: 2.0248652MixupTrain:  epoch  0, batch   342 | loss: 1.9448239MixupTrain:  epoch  0, batch   343 | loss: 1.9848812MixupTrain:  epoch  0, batch   344 | loss: 1.9770417MixupTrain:  epoch  0, batch   345 | loss: 2.0713909MixupTrain:  epoch  0, batch   346 | loss: 2.0087383MixupTrain:  epoch  0, batch   347 | loss: 1.9938684MixupTrain:  epoch  0, batch   348 | loss: 1.9356201MixupTrain:  epoch  0, batch   349 | loss: 2.0104632MixupTrain:  epoch  0, batch   350 | loss: 2.0240552MixupTrain:  epoch  0, batch   351 | loss: 1.9727530MixupTrain:  epoch  0, batch   352 | loss: 2.0178676MixupTrain:  epoch  0, batch   353 | loss: 1.9914393MixupTrain:  epoch  0, batch   354 | loss: 2.0052745MixupTrain:  epoch  0, batch   355 | loss: 2.0291328MixupTrain:  epoch  0, batch   356 | loss: 1.9856586MixupTrain:  epoch  0, batch   357 | loss: 1.9694090MixupTrain:  epoch  0, batch   358 | loss: 2.0346682MixupTrain:  epoch  0, batch   359 | loss: 2.0653362MixupTrain:  epoch  0, batch   360 | loss: 2.0467229MixupTrain:  epoch  0, batch   361 | loss: 2.0262804MixupTrain:  epoch  0, batch   362 | loss: 2.0668001MixupTrain:  epoch  0, batch   363 | loss: 1.9807097MixupTrain:  epoch  0, batch   364 | loss: 2.0272131MixupTrain:  epoch  0, batch   365 | loss: 2.0611675MixupTrain:  epoch  0, batch   366 | loss: 2.0542002MixupTrain:  epoch  0, batch   367 | loss: 2.0467324MixupTrain:  epoch  0, batch   368 | loss: 2.0625725MixupTrain:  epoch  0, batch   369 | loss: 1.9669279MixupTrain:  epoch  0, batch   370 | loss: 1.9806225MixupTrain:  epoch  0, batch   371 | loss: 2.0131679MixupTrain:  epoch  0, batch   372 | loss: 1.9966073MixupTrain:  epoch  0, batch   373 | loss: 2.0654554MixupTrain:  epoch  0, batch   374 | loss: 2.0884757MixupTrain:  epoch  0, batch   375 | loss: 1.9999382MixupTrain:  epoch  0, batch   376 | loss: 2.0386996MixupTrain:  epoch  0, batch   377 | loss: 1.9915836MixupTrain:  epoch  0, batch   378 | loss: 2.0583112MixupTrain:  epoch  0, batch   379 | loss: 2.0197999MixupTrain:  epoch  0, batch   380 | loss: 1.9350314MixupTrain:  epoch  0, batch   381 | loss: 2.0143344MixupTrain:  epoch  0, batch   382 | loss: 1.9804516MixupTrain:  epoch  0, batch   383 | loss: 1.9448702MixupTrain:  epoch  0, batch   384 | loss: 1.9880334MixupTrain:  epoch  0, batch   385 | loss: 1.9824347MixupTrain:  epoch  0, batch   386 | loss: 1.9949281MixupTrain:  epoch  0, batch   387 | loss: 1.9647206MixupTrain:  epoch  0, batch   388 | loss: 1.9867828MixupTrain:  epoch  0, batch   389 | loss: 2.0497384MixupTrain:  epoch  0, batch   390 | loss: 1.9032574MixupTrain:  epoch  0, batch   391 | loss: 1.9066153MixupTrain:  epoch  0, batch   392 | loss: 1.9577338MixupTrain:  epoch  0, batch   393 | loss: 1.9403616MixupTrain:  epoch  0, batch   394 | loss: 2.0342960MixupTrain:  epoch  0, batch   395 | loss: 2.0023994MixupTrain:  epoch  0, batch   396 | loss: 1.9777036MixupTrain:  epoch  0, batch   397 | loss: 2.0407660MixupTrain:  epoch  0, batch   398 | loss: 1.9816582MixupTrain:  epoch  0, batch   399 | loss: 1.9348115MixupTrain:  epoch  0, batch   400 | loss: 1.9667799MixupTrain:  epoch  0, batch   401 | loss: 1.9789615MixupTrain:  epoch  0, batch   402 | loss: 1.9735646MixupTrain:  epoch  0, batch   403 | loss: 2.0260730MixupTrain:  epoch  0, batch   404 | loss: 2.0720959MixupTrain:  epoch  0, batch   405 | loss: 1.9737701MixupTrain:  epoch  0, batch   406 | loss: 1.9918889MixupTrain:  epoch  0, batch   407 | loss: 2.0525599MixupTrain:  epoch  0, batch   408 | loss: 1.9975934MixupTrain:  epoch  0, batch   409 | loss: 1.9920805MixupTrain:  epoch  0, batch   410 | loss: 1.9617741MixupTrain:  epoch  0, batch   411 | loss: 2.0576560MixupTrain:  epoch  0, batch   412 | loss: 1.9170203MixupTrain:  epoch  0, batch   413 | loss: 2.0025547MixupTrain:  epoch  0, batch   414 | loss: 2.0939770MixupTrain:  epoch  0, batch   415 | loss: 2.0397580MixupTrain:  epoch  0, batch   416 | loss: 1.9460602MixupTrain:  epoch  0, batch   417 | loss: 2.0034389MixupTrain:  epoch  0, batch   418 | loss: 1.9554362MixupTrain:  epoch  0, batch   419 | loss: 2.0047567MixupTrain:  epoch  0, batch   420 | loss: 2.0232399MixupTrain:  epoch  0, batch   421 | loss: 1.9751842MixupTrain:  epoch  0, batch   422 | loss: 1.9008789MixupTrain:  epoch  0, batch   423 | loss: 1.9663918MixupTrain:  epoch  0, batch   424 | loss: 2.0220809MixupTrain:  epoch  0, batch   425 | loss: 2.0610569MixupTrain:  epoch  0, batch   426 | loss: 1.9052063
MemoryTrain:  epoch  0, batch     0 | loss: 1.9289387MemoryTrain:  epoch  0, batch     1 | loss: 2.8362343MemoryTrain:  epoch  0, batch     2 | loss: 2.8216515MemoryTrain:  epoch  0, batch     3 | loss: 2.5341845MemoryTrain:  epoch  0, batch     4 | loss: 2.3468275MemoryTrain:  epoch  0, batch     5 | loss: 2.2898364MemoryTrain:  epoch  1, batch     0 | loss: 1.8238003MemoryTrain:  epoch  1, batch     1 | loss: 1.8316636MemoryTrain:  epoch  1, batch     2 | loss: 1.8507904MemoryTrain:  epoch  1, batch     3 | loss: 1.9925196MemoryTrain:  epoch  1, batch     4 | loss: 1.8681381MemoryTrain:  epoch  1, batch     5 | loss: 1.8502191MemoryTrain:  epoch  2, batch     0 | loss: 1.8397639MemoryTrain:  epoch  2, batch     1 | loss: 1.8983265MemoryTrain:  epoch  2, batch     2 | loss: 1.8473155MemoryTrain:  epoch  2, batch     3 | loss: 1.8466957MemoryTrain:  epoch  2, batch     4 | loss: 1.9446309MemoryTrain:  epoch  2, batch     5 | loss: 1.8346791MemoryTrain:  epoch  3, batch     0 | loss: 1.8328304MemoryTrain:  epoch  3, batch     1 | loss: 1.8407921MemoryTrain:  epoch  3, batch     2 | loss: 1.8517497MemoryTrain:  epoch  3, batch     3 | loss: 1.8266726MemoryTrain:  epoch  3, batch     4 | loss: 1.8373055MemoryTrain:  epoch  3, batch     5 | loss: 1.8374833MemoryTrain:  epoch  4, batch     0 | loss: 1.8337575MemoryTrain:  epoch  4, batch     1 | loss: 1.8410614MemoryTrain:  epoch  4, batch     2 | loss: 1.8265579MemoryTrain:  epoch  4, batch     3 | loss: 1.8331952MemoryTrain:  epoch  4, batch     4 | loss: 1.8297101MemoryTrain:  epoch  4, batch     5 | loss: 1.8310554MemoryTrain:  epoch  5, batch     0 | loss: 1.8355894MemoryTrain:  epoch  5, batch     1 | loss: 1.8341303MemoryTrain:  epoch  5, batch     2 | loss: 1.8302444MemoryTrain:  epoch  5, batch     3 | loss: 1.8451675MemoryTrain:  epoch  5, batch     4 | loss: 1.8326828MemoryTrain:  epoch  5, batch     5 | loss: 1.8256207MemoryTrain:  epoch  6, batch     0 | loss: 1.8346075MemoryTrain:  epoch  6, batch     1 | loss: 1.8601543MemoryTrain:  epoch  6, batch     2 | loss: 1.8641524MemoryTrain:  epoch  6, batch     3 | loss: 1.8382472MemoryTrain:  epoch  6, batch     4 | loss: 1.8348560MemoryTrain:  epoch  6, batch     5 | loss: 1.8465450MemoryTrain:  epoch  7, batch     0 | loss: 1.8332822MemoryTrain:  epoch  7, batch     1 | loss: 1.8395431MemoryTrain:  epoch  7, batch     2 | loss: 1.8420608MemoryTrain:  epoch  7, batch     3 | loss: 1.8451911MemoryTrain:  epoch  7, batch     4 | loss: 1.8205388MemoryTrain:  epoch  7, batch     5 | loss: 1.8395929MemoryTrain:  epoch  8, batch     0 | loss: 1.8480147MemoryTrain:  epoch  8, batch     1 | loss: 1.8384306MemoryTrain:  epoch  8, batch     2 | loss: 1.8339940MemoryTrain:  epoch  8, batch     3 | loss: 1.8363382MemoryTrain:  epoch  8, batch     4 | loss: 1.8287141MemoryTrain:  epoch  8, batch     5 | loss: 1.8441870MemoryTrain:  epoch  9, batch     0 | loss: 1.8504653MemoryTrain:  epoch  9, batch     1 | loss: 1.8464741MemoryTrain:  epoch  9, batch     2 | loss: 1.8397244MemoryTrain:  epoch  9, batch     3 | loss: 1.8248371MemoryTrain:  epoch  9, batch     4 | loss: 1.8352156MemoryTrain:  epoch  9, batch     5 | loss: 1.8403866
[EVAL] batch:    0 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    1 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    2 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    4 | acc: 100.00%,  total acc: 90.00%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 91.67%   [EVAL] batch:    6 | acc: 75.00%,  total acc: 89.29%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 89.84%   [EVAL] batch:    8 | acc: 93.75%,  total acc: 90.28%   [EVAL] batch:    9 | acc: 93.75%,  total acc: 90.62%   [EVAL] batch:   10 | acc: 81.25%,  total acc: 89.77%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 90.10%   [EVAL] batch:   12 | acc: 87.50%,  total acc: 89.90%   [EVAL] batch:   13 | acc: 12.50%,  total acc: 84.38%   
[EVAL] batch:    0 | acc: 62.50%,  total acc: 62.50%   [EVAL] batch:    1 | acc: 68.75%,  total acc: 65.62%   [EVAL] batch:    2 | acc: 62.50%,  total acc: 64.58%   [EVAL] batch:    3 | acc: 50.00%,  total acc: 60.94%   [EVAL] batch:    4 | acc: 62.50%,  total acc: 61.25%   [EVAL] batch:    5 | acc: 43.75%,  total acc: 58.33%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 63.39%   [EVAL] batch:    7 | acc: 87.50%,  total acc: 66.41%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 70.14%   [EVAL] batch:    9 | acc: 100.00%,  total acc: 73.12%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 75.57%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 77.08%   [EVAL] batch:   12 | acc: 81.25%,  total acc: 77.40%   [EVAL] batch:   13 | acc: 62.50%,  total acc: 76.34%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 76.25%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 75.00%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 74.31%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 73.68%   [EVAL] batch:   19 | acc: 81.25%,  total acc: 74.06%   [EVAL] batch:   20 | acc: 93.75%,  total acc: 75.00%   [EVAL] batch:   21 | acc: 100.00%,  total acc: 76.14%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 76.36%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 77.08%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 77.75%   [EVAL] batch:   25 | acc: 93.75%,  total acc: 78.37%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 78.70%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 79.24%   [EVAL] batch:   28 | acc: 75.00%,  total acc: 79.09%   [EVAL] batch:   29 | acc: 62.50%,  total acc: 78.54%   [EVAL] batch:   30 | acc: 62.50%,  total acc: 78.02%   [EVAL] batch:   31 | acc: 87.50%,  total acc: 78.32%   [EVAL] batch:   32 | acc: 56.25%,  total acc: 77.65%   [EVAL] batch:   33 | acc: 43.75%,  total acc: 76.65%   [EVAL] batch:   34 | acc: 50.00%,  total acc: 75.89%   [EVAL] batch:   35 | acc: 25.00%,  total acc: 74.48%   [EVAL] batch:   36 | acc: 62.50%,  total acc: 74.16%   [EVAL] batch:   37 | acc: 81.25%,  total acc: 74.34%   [EVAL] batch:   38 | acc: 56.25%,  total acc: 73.88%   [EVAL] batch:   39 | acc: 93.75%,  total acc: 74.38%   [EVAL] batch:   40 | acc: 56.25%,  total acc: 73.93%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 74.55%   [EVAL] batch:   42 | acc: 25.00%,  total acc: 73.40%   [EVAL] batch:   43 | acc: 6.25%,  total acc: 71.88%   [EVAL] batch:   44 | acc: 0.00%,  total acc: 70.28%   [EVAL] batch:   45 | acc: 0.00%,  total acc: 68.75%   [EVAL] batch:   46 | acc: 18.75%,  total acc: 67.69%   [EVAL] batch:   47 | acc: 81.25%,  total acc: 67.97%   [EVAL] batch:   48 | acc: 93.75%,  total acc: 68.49%   [EVAL] batch:   49 | acc: 87.50%,  total acc: 68.88%   [EVAL] batch:   50 | acc: 87.50%,  total acc: 69.24%   [EVAL] batch:   51 | acc: 100.00%,  total acc: 69.83%   [EVAL] batch:   52 | acc: 100.00%,  total acc: 70.40%   [EVAL] batch:   53 | acc: 75.00%,  total acc: 70.49%   [EVAL] batch:   54 | acc: 93.75%,  total acc: 70.91%   [EVAL] batch:   55 | acc: 93.75%,  total acc: 71.32%   [EVAL] batch:   56 | acc: 93.75%,  total acc: 71.71%   [EVAL] batch:   57 | acc: 75.00%,  total acc: 71.77%   [EVAL] batch:   58 | acc: 100.00%,  total acc: 72.25%   [EVAL] batch:   59 | acc: 75.00%,  total acc: 72.29%   [EVAL] batch:   60 | acc: 6.25%,  total acc: 71.21%   
cur_acc:  ['0.8580', '0.8750', '0.8438']
his_acc:  ['0.8580', '0.8191', '0.7121']
CurrentTrain: epoch  0, batch     0 | loss: 5.1470251CurrentTrain: epoch  0, batch     1 | loss: 4.6573987CurrentTrain: epoch  1, batch     0 | loss: 4.2327185CurrentTrain: epoch  1, batch     1 | loss: 3.5854180CurrentTrain: epoch  2, batch     0 | loss: 3.4022121CurrentTrain: epoch  2, batch     1 | loss: 2.4390836CurrentTrain: epoch  3, batch     0 | loss: 2.8635578CurrentTrain: epoch  3, batch     1 | loss: 2.2834761CurrentTrain: epoch  4, batch     0 | loss: 2.3214941CurrentTrain: epoch  4, batch     1 | loss: 2.8063145CurrentTrain: epoch  5, batch     0 | loss: 2.2568660CurrentTrain: epoch  5, batch     1 | loss: 2.0902498CurrentTrain: epoch  6, batch     0 | loss: 2.0824940CurrentTrain: epoch  6, batch     1 | loss: 2.2233279CurrentTrain: epoch  7, batch     0 | loss: 2.0110393CurrentTrain: epoch  7, batch     1 | loss: 2.0065618CurrentTrain: epoch  8, batch     0 | loss: 1.9773719CurrentTrain: epoch  8, batch     1 | loss: 2.1550267CurrentTrain: epoch  9, batch     0 | loss: 2.0516992CurrentTrain: epoch  9, batch     1 | loss: 1.8535472
#### person cities of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person cities of residence" means a person is living in a city.
Here is an example:
Relation: person cities of residence
Context: tv-idol-johns -- atlanta -- `` american idol '' finalist michael johns moved to los angeles several years ago , but his heart is still in atlanta .
Head Entity: his
Tail Entity: atlanta
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person cities of residence":
Relation: person cities of residence  
Context: after years of living in new york city, the famous author decided to return to her hometown of boston, where she feels most at home.  
Head Entity: she  
Tail Entity: boston  

Relation: person cities of residence  
Context: despite being a global superstar, the singer often reminisces about her childhood in nashville, where she first discovered her love for music.  
Head Entity: she  
Tail Entity: nashville  

Relation: person cities of residence  
Context: after completing his studies in san francisco, the tech entrepreneur moved back to his roots in seattle to start his new venture.  
Head Entity: he  
Tail Entity: seattle  

Relation: person cities of residence  
Context: the renowned chef, who gained fame in chicago, now runs a successful restaurant in miami, but he still considers chicago his true home.  
Head Entity: he  
Tail Entity: chicago  

Relation: person cities of residence  
Context: although she has traveled the world, the actress always returns to her beloved los angeles, where she feels most inspired.  
Head Entity: she  
Tail Entity: los angeles  
#### person schools attended ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person schools attended" means a person 's school is an organization.
Here is an example:
Relation: person schools attended
Context: her political involvement began early : at cornell , she helped organize local farmers ' cooperatives .
Head Entity: she
Tail Entity: cornell
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person schools attended":
Relation: person schools attended  
Context: After graduating from high school, he enrolled at Stanford University to pursue his degree in computer science.  
Head Entity: he  
Tail Entity: Stanford University  

Relation: person schools attended  
Context: She often reminisces about her time at Harvard, where she developed a passion for literature and writing.  
Head Entity: She  
Tail Entity: Harvard  

Relation: person schools attended  
Context: During his college years, John was an active member of the student council at the University of California, Berkeley.  
Head Entity: John  
Tail Entity: University of California, Berkeley  

Relation: person schools attended  
Context: Maria completed her undergraduate studies at the University of Texas, where she majored in biology.  
Head Entity: Maria  
Tail Entity: University of Texas  

Relation: person schools attended  
Context: After moving to New York, he decided to attend Columbia University to further his education in economics.  
Head Entity: he  
Tail Entity: Columbia University  
#### person country of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person country of death" means a person was died in a country.
Here is an example:
Relation: person country of death
Context: u.s. rep. parren mitchell , founding member of congressional black caucus , dies at 85
Head Entity: parren mitchell
Tail Entity: u.s.
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person country of death":
Relation: person country of death  
Context: renowned physicist stephen hawking passed away in cambridge, england at the age of 76  
Head Entity: stephen hawking  
Tail Entity: england  

Relation: person country of death  
Context: the famous author gabriel garcia marquez died in mexico city, mexico, leaving behind a legacy of magical realism  
Head Entity: gabriel garcia marquez  
Tail Entity: mexico  

Relation: person country of death  
Context: legendary musician freddie mercury succumbed to aids in london, united kingdom, at the age of 45  
Head Entity: freddie mercury  
Tail Entity: united kingdom  

Relation: person country of death  
Context: former south african president nelson mandela passed away peacefully in johannesburg, south africa  
Head Entity: nelson mandela  
Tail Entity: south africa  

Relation: person country of death  
Context: iconic actress audrey hepburn died in tolochenaz, switzerland, at the age of 63  
Head Entity: audrey hepburn  
Tail Entity: switzerland  
#### person children ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person children" means a person 's children is a person.
Here is an example:
Relation: person children
Context: he is survived by two stepdaughters , barbara a. hammond and brenda l. stevenson ; a stepson , michael a. taylor ; two grandchildren and one great-grandchild .
Head Entity: he
Tail Entity: brenda l. stevenson
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person children":
Relation: person children  
Context: she has three children, including her son, john, and her daughters, emily and sarah, who are both very talented.  
Head Entity: she  
Tail Entity: emily  

Relation: person children  
Context: after the divorce, he took custody of his two daughters, lily and rose, who are now thriving in school.  
Head Entity: he  
Tail Entity: rose  

Relation: person children  
Context: the famous author often mentioned his son, alex, in interviews, highlighting their close relationship.  
Head Entity: the famous author  
Tail Entity: alex  

Relation: person children  
Context: during the family reunion, she proudly introduced her children, including her youngest, max, who just graduated from high school.  
Head Entity: she  
Tail Entity: max  

Relation: person children  
Context: he often shares stories about his daughter, mia, who is an aspiring artist and has already held her first exhibition.  
Head Entity: he  
Tail Entity: mia  
#### person charges ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person charges" means a person was charged with an event.
Here is an example:
Relation: person charges
Context: ferrara said he was innocent of limoli 's slaying , but he pleaded guilty in 1992 to murder , along with racketeering charges , under a deal that sent him to prison for 22 years , rather than go to trial and risk a conviction that could lead to life in prison .
Head Entity: ferrara
Tail Entity: racketeering
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person charges":
Relation: person charges  
Context: After a lengthy investigation, the authorities announced that Johnson was charged with embezzlement, which shocked his colleagues at the firm.  
Head Entity: Johnson  
Tail Entity: embezzlement  

Relation: person charges  
Context: The district attorney confirmed that Smith was charged with assault following the altercation at the downtown bar last weekend.  
Head Entity: Smith  
Tail Entity: assault  

Relation: person charges  
Context: In a surprising turn of events, the police revealed that Martinez was charged with fraud after an extensive audit of his business practices.  
Head Entity: Martinez  
Tail Entity: fraud  

Relation: person charges  
Context: Following the protests, the city council announced that Thompson was charged with inciting violence during the demonstration.  
Head Entity: Thompson  
Tail Entity: inciting violence  

Relation: person charges  
Context: The court documents indicated that Lee was charged with theft after being caught on surveillance cameras stealing merchandise from the store.  
Head Entity: Lee  
Tail Entity: theft  
Mixup data size:  10810
MixupTrain:  epoch  0, batch     0 | loss: 4.3308258MixupTrain:  epoch  0, batch     1 | loss: 4.2333889MixupTrain:  epoch  0, batch     2 | loss: 5.1013298MixupTrain:  epoch  0, batch     3 | loss: 4.7692919MixupTrain:  epoch  0, batch     4 | loss: 4.0979147MixupTrain:  epoch  0, batch     5 | loss: 4.1210694MixupTrain:  epoch  0, batch     6 | loss: 4.7293544MixupTrain:  epoch  0, batch     7 | loss: 4.0293183MixupTrain:  epoch  0, batch     8 | loss: 3.7620397MixupTrain:  epoch  0, batch     9 | loss: 3.6292462MixupTrain:  epoch  0, batch    10 | loss: 3.6727734MixupTrain:  epoch  0, batch    11 | loss: 3.9524977MixupTrain:  epoch  0, batch    12 | loss: 3.9274530MixupTrain:  epoch  0, batch    13 | loss: 4.4304676MixupTrain:  epoch  0, batch    14 | loss: 3.7567055MixupTrain:  epoch  0, batch    15 | loss: 3.5131161MixupTrain:  epoch  0, batch    16 | loss: 2.9450336MixupTrain:  epoch  0, batch    17 | loss: 3.7762048MixupTrain:  epoch  0, batch    18 | loss: 4.0328903MixupTrain:  epoch  0, batch    19 | loss: 3.4050641MixupTrain:  epoch  0, batch    20 | loss: 3.2264905MixupTrain:  epoch  0, batch    21 | loss: 3.3998523MixupTrain:  epoch  0, batch    22 | loss: 3.3492222MixupTrain:  epoch  0, batch    23 | loss: 3.2508073MixupTrain:  epoch  0, batch    24 | loss: 3.5122466MixupTrain:  epoch  0, batch    25 | loss: 4.0665722MixupTrain:  epoch  0, batch    26 | loss: 3.4839439MixupTrain:  epoch  0, batch    27 | loss: 3.4536076MixupTrain:  epoch  0, batch    28 | loss: 3.7273417MixupTrain:  epoch  0, batch    29 | loss: 3.4443367MixupTrain:  epoch  0, batch    30 | loss: 3.5191033MixupTrain:  epoch  0, batch    31 | loss: 3.6936073MixupTrain:  epoch  0, batch    32 | loss: 3.2466040MixupTrain:  epoch  0, batch    33 | loss: 3.8286259MixupTrain:  epoch  0, batch    34 | loss: 3.0567682MixupTrain:  epoch  0, batch    35 | loss: 3.2152386MixupTrain:  epoch  0, batch    36 | loss: 3.4454546MixupTrain:  epoch  0, batch    37 | loss: 2.8037086MixupTrain:  epoch  0, batch    38 | loss: 3.0281987MixupTrain:  epoch  0, batch    39 | loss: 2.9406893MixupTrain:  epoch  0, batch    40 | loss: 3.2136555MixupTrain:  epoch  0, batch    41 | loss: 3.0637145MixupTrain:  epoch  0, batch    42 | loss: 3.5257242MixupTrain:  epoch  0, batch    43 | loss: 3.4615245MixupTrain:  epoch  0, batch    44 | loss: 3.0361929MixupTrain:  epoch  0, batch    45 | loss: 3.3859534MixupTrain:  epoch  0, batch    46 | loss: 2.9736362MixupTrain:  epoch  0, batch    47 | loss: 3.5817890MixupTrain:  epoch  0, batch    48 | loss: 3.0871201MixupTrain:  epoch  0, batch    49 | loss: 3.1417041MixupTrain:  epoch  0, batch    50 | loss: 3.2027171MixupTrain:  epoch  0, batch    51 | loss: 3.2732997MixupTrain:  epoch  0, batch    52 | loss: 2.8906565MixupTrain:  epoch  0, batch    53 | loss: 2.8051414MixupTrain:  epoch  0, batch    54 | loss: 3.4258244MixupTrain:  epoch  0, batch    55 | loss: 3.1225002MixupTrain:  epoch  0, batch    56 | loss: 3.2414346MixupTrain:  epoch  0, batch    57 | loss: 3.2595003MixupTrain:  epoch  0, batch    58 | loss: 2.7785406MixupTrain:  epoch  0, batch    59 | loss: 2.6336601MixupTrain:  epoch  0, batch    60 | loss: 2.5921221MixupTrain:  epoch  0, batch    61 | loss: 3.0283113MixupTrain:  epoch  0, batch    62 | loss: 2.7387109MixupTrain:  epoch  0, batch    63 | loss: 2.8880439MixupTrain:  epoch  0, batch    64 | loss: 2.7467642MixupTrain:  epoch  0, batch    65 | loss: 2.7126241MixupTrain:  epoch  0, batch    66 | loss: 3.1115770MixupTrain:  epoch  0, batch    67 | loss: 2.8328989MixupTrain:  epoch  0, batch    68 | loss: 2.9428310MixupTrain:  epoch  0, batch    69 | loss: 2.8265595MixupTrain:  epoch  0, batch    70 | loss: 2.8653841MixupTrain:  epoch  0, batch    71 | loss: 2.7290030MixupTrain:  epoch  0, batch    72 | loss: 2.5018089MixupTrain:  epoch  0, batch    73 | loss: 3.0382018MixupTrain:  epoch  0, batch    74 | loss: 3.0009456MixupTrain:  epoch  0, batch    75 | loss: 2.5642190MixupTrain:  epoch  0, batch    76 | loss: 3.1035609MixupTrain:  epoch  0, batch    77 | loss: 2.7602494MixupTrain:  epoch  0, batch    78 | loss: 2.7779465MixupTrain:  epoch  0, batch    79 | loss: 2.3047657MixupTrain:  epoch  0, batch    80 | loss: 2.9363167MixupTrain:  epoch  0, batch    81 | loss: 2.8456459MixupTrain:  epoch  0, batch    82 | loss: 2.6998596MixupTrain:  epoch  0, batch    83 | loss: 2.9494791MixupTrain:  epoch  0, batch    84 | loss: 2.8987067MixupTrain:  epoch  0, batch    85 | loss: 3.0062711MixupTrain:  epoch  0, batch    86 | loss: 2.7954388MixupTrain:  epoch  0, batch    87 | loss: 2.6542201MixupTrain:  epoch  0, batch    88 | loss: 2.7848656MixupTrain:  epoch  0, batch    89 | loss: 2.5775919MixupTrain:  epoch  0, batch    90 | loss: 2.6316948MixupTrain:  epoch  0, batch    91 | loss: 2.9499731MixupTrain:  epoch  0, batch    92 | loss: 2.4566669MixupTrain:  epoch  0, batch    93 | loss: 2.6951811MixupTrain:  epoch  0, batch    94 | loss: 2.7589879MixupTrain:  epoch  0, batch    95 | loss: 2.6653857MixupTrain:  epoch  0, batch    96 | loss: 3.0102582MixupTrain:  epoch  0, batch    97 | loss: 2.4973326MixupTrain:  epoch  0, batch    98 | loss: 2.4058058MixupTrain:  epoch  0, batch    99 | loss: 2.6186464MixupTrain:  epoch  0, batch   100 | loss: 2.4553919MixupTrain:  epoch  0, batch   101 | loss: 2.8554740MixupTrain:  epoch  0, batch   102 | loss: 2.5671315MixupTrain:  epoch  0, batch   103 | loss: 2.1973515MixupTrain:  epoch  0, batch   104 | loss: 2.4616971MixupTrain:  epoch  0, batch   105 | loss: 2.7725916MixupTrain:  epoch  0, batch   106 | loss: 2.7330296MixupTrain:  epoch  0, batch   107 | loss: 2.6461272MixupTrain:  epoch  0, batch   108 | loss: 2.4515157MixupTrain:  epoch  0, batch   109 | loss: 2.5963702MixupTrain:  epoch  0, batch   110 | loss: 2.6394029MixupTrain:  epoch  0, batch   111 | loss: 2.4055657MixupTrain:  epoch  0, batch   112 | loss: 2.6342373MixupTrain:  epoch  0, batch   113 | loss: 2.5897779MixupTrain:  epoch  0, batch   114 | loss: 2.1431024MixupTrain:  epoch  0, batch   115 | loss: 2.2969775MixupTrain:  epoch  0, batch   116 | loss: 2.5936489MixupTrain:  epoch  0, batch   117 | loss: 2.5847235MixupTrain:  epoch  0, batch   118 | loss: 2.2127190MixupTrain:  epoch  0, batch   119 | loss: 2.4976091MixupTrain:  epoch  0, batch   120 | loss: 2.5499415MixupTrain:  epoch  0, batch   121 | loss: 2.4598687MixupTrain:  epoch  0, batch   122 | loss: 2.6958890MixupTrain:  epoch  0, batch   123 | loss: 2.6279831MixupTrain:  epoch  0, batch   124 | loss: 2.7398925MixupTrain:  epoch  0, batch   125 | loss: 2.2706549MixupTrain:  epoch  0, batch   126 | loss: 2.4891198MixupTrain:  epoch  0, batch   127 | loss: 2.3612022MixupTrain:  epoch  0, batch   128 | loss: 2.2041569MixupTrain:  epoch  0, batch   129 | loss: 2.3998809MixupTrain:  epoch  0, batch   130 | loss: 2.3720107MixupTrain:  epoch  0, batch   131 | loss: 2.3991299MixupTrain:  epoch  0, batch   132 | loss: 2.6206861MixupTrain:  epoch  0, batch   133 | loss: 2.5165911MixupTrain:  epoch  0, batch   134 | loss: 2.6761596MixupTrain:  epoch  0, batch   135 | loss: 2.4324632MixupTrain:  epoch  0, batch   136 | loss: 2.4049368MixupTrain:  epoch  0, batch   137 | loss: 2.3831463MixupTrain:  epoch  0, batch   138 | loss: 2.5660591MixupTrain:  epoch  0, batch   139 | loss: 2.4391255MixupTrain:  epoch  0, batch   140 | loss: 2.2227535MixupTrain:  epoch  0, batch   141 | loss: 2.4401107MixupTrain:  epoch  0, batch   142 | loss: 2.3696923MixupTrain:  epoch  0, batch   143 | loss: 2.3873150MixupTrain:  epoch  0, batch   144 | loss: 2.3988123MixupTrain:  epoch  0, batch   145 | loss: 2.3684173MixupTrain:  epoch  0, batch   146 | loss: 2.6188998MixupTrain:  epoch  0, batch   147 | loss: 2.2739277MixupTrain:  epoch  0, batch   148 | loss: 2.3897331MixupTrain:  epoch  0, batch   149 | loss: 2.3781660MixupTrain:  epoch  0, batch   150 | loss: 2.5903544MixupTrain:  epoch  0, batch   151 | loss: 2.3217349MixupTrain:  epoch  0, batch   152 | loss: 2.3688917MixupTrain:  epoch  0, batch   153 | loss: 2.5926442MixupTrain:  epoch  0, batch   154 | loss: 2.6817255MixupTrain:  epoch  0, batch   155 | loss: 2.6148052MixupTrain:  epoch  0, batch   156 | loss: 2.2397292MixupTrain:  epoch  0, batch   157 | loss: 2.4970946MixupTrain:  epoch  0, batch   158 | loss: 2.4422836MixupTrain:  epoch  0, batch   159 | loss: 2.5107841MixupTrain:  epoch  0, batch   160 | loss: 2.4611619MixupTrain:  epoch  0, batch   161 | loss: 2.6246600MixupTrain:  epoch  0, batch   162 | loss: 2.4354291MixupTrain:  epoch  0, batch   163 | loss: 2.3653693MixupTrain:  epoch  0, batch   164 | loss: 2.5076830MixupTrain:  epoch  0, batch   165 | loss: 2.2414756MixupTrain:  epoch  0, batch   166 | loss: 2.2745681MixupTrain:  epoch  0, batch   167 | loss: 2.5005002MixupTrain:  epoch  0, batch   168 | loss: 2.4546952MixupTrain:  epoch  0, batch   169 | loss: 2.3720183MixupTrain:  epoch  0, batch   170 | loss: 2.3580008MixupTrain:  epoch  0, batch   171 | loss: 2.3799105MixupTrain:  epoch  0, batch   172 | loss: 2.6271353MixupTrain:  epoch  0, batch   173 | loss: 2.3243368MixupTrain:  epoch  0, batch   174 | loss: 2.7592359MixupTrain:  epoch  0, batch   175 | loss: 2.6683018MixupTrain:  epoch  0, batch   176 | loss: 2.5131829MixupTrain:  epoch  0, batch   177 | loss: 2.5308473MixupTrain:  epoch  0, batch   178 | loss: 2.4546833MixupTrain:  epoch  0, batch   179 | loss: 2.4907768MixupTrain:  epoch  0, batch   180 | loss: 2.3490987MixupTrain:  epoch  0, batch   181 | loss: 2.4781160MixupTrain:  epoch  0, batch   182 | loss: 2.5409718MixupTrain:  epoch  0, batch   183 | loss: 2.3224134MixupTrain:  epoch  0, batch   184 | loss: 2.5083222MixupTrain:  epoch  0, batch   185 | loss: 2.5530879MixupTrain:  epoch  0, batch   186 | loss: 2.4241343MixupTrain:  epoch  0, batch   187 | loss: 2.4058781MixupTrain:  epoch  0, batch   188 | loss: 2.4912610MixupTrain:  epoch  0, batch   189 | loss: 2.1965635MixupTrain:  epoch  0, batch   190 | loss: 2.5289526MixupTrain:  epoch  0, batch   191 | loss: 2.3602154MixupTrain:  epoch  0, batch   192 | loss: 2.1819744MixupTrain:  epoch  0, batch   193 | loss: 2.1758840MixupTrain:  epoch  0, batch   194 | loss: 2.3656969MixupTrain:  epoch  0, batch   195 | loss: 2.4266703MixupTrain:  epoch  0, batch   196 | loss: 2.3234906MixupTrain:  epoch  0, batch   197 | loss: 2.3965907MixupTrain:  epoch  0, batch   198 | loss: 2.2738976MixupTrain:  epoch  0, batch   199 | loss: 2.5379515MixupTrain:  epoch  0, batch   200 | loss: 2.3647556MixupTrain:  epoch  0, batch   201 | loss: 2.5501852MixupTrain:  epoch  0, batch   202 | loss: 2.4959953MixupTrain:  epoch  0, batch   203 | loss: 2.3437061MixupTrain:  epoch  0, batch   204 | loss: 2.4174669MixupTrain:  epoch  0, batch   205 | loss: 2.3815446MixupTrain:  epoch  0, batch   206 | loss: 2.5582032MixupTrain:  epoch  0, batch   207 | loss: 2.4371433MixupTrain:  epoch  0, batch   208 | loss: 2.3783450MixupTrain:  epoch  0, batch   209 | loss: 2.3751047MixupTrain:  epoch  0, batch   210 | loss: 2.2009883MixupTrain:  epoch  0, batch   211 | loss: 2.2454174MixupTrain:  epoch  0, batch   212 | loss: 2.3274927MixupTrain:  epoch  0, batch   213 | loss: 2.3503895MixupTrain:  epoch  0, batch   214 | loss: 2.2561913MixupTrain:  epoch  0, batch   215 | loss: 2.3398936MixupTrain:  epoch  0, batch   216 | loss: 2.3505020MixupTrain:  epoch  0, batch   217 | loss: 2.2186463MixupTrain:  epoch  0, batch   218 | loss: 2.1336977MixupTrain:  epoch  0, batch   219 | loss: 2.3020892MixupTrain:  epoch  0, batch   220 | loss: 2.2268906MixupTrain:  epoch  0, batch   221 | loss: 2.2219620MixupTrain:  epoch  0, batch   222 | loss: 2.3607030MixupTrain:  epoch  0, batch   223 | loss: 2.3189692MixupTrain:  epoch  0, batch   224 | loss: 2.4427781MixupTrain:  epoch  0, batch   225 | loss: 2.1160288MixupTrain:  epoch  0, batch   226 | loss: 2.3126192MixupTrain:  epoch  0, batch   227 | loss: 2.3157177MixupTrain:  epoch  0, batch   228 | loss: 2.3237438MixupTrain:  epoch  0, batch   229 | loss: 2.4627903MixupTrain:  epoch  0, batch   230 | loss: 2.3023577MixupTrain:  epoch  0, batch   231 | loss: 2.4289565MixupTrain:  epoch  0, batch   232 | loss: 2.2511632MixupTrain:  epoch  0, batch   233 | loss: 2.3724508MixupTrain:  epoch  0, batch   234 | loss: 2.3794394MixupTrain:  epoch  0, batch   235 | loss: 2.3142991MixupTrain:  epoch  0, batch   236 | loss: 2.3253574MixupTrain:  epoch  0, batch   237 | loss: 2.6275988MixupTrain:  epoch  0, batch   238 | loss: 2.4692943MixupTrain:  epoch  0, batch   239 | loss: 2.3463879MixupTrain:  epoch  0, batch   240 | loss: 2.4435363MixupTrain:  epoch  0, batch   241 | loss: 2.2863922MixupTrain:  epoch  0, batch   242 | loss: 2.2167487MixupTrain:  epoch  0, batch   243 | loss: 2.6063430MixupTrain:  epoch  0, batch   244 | loss: 2.1030705MixupTrain:  epoch  0, batch   245 | loss: 2.1017575MixupTrain:  epoch  0, batch   246 | loss: 2.3174691MixupTrain:  epoch  0, batch   247 | loss: 2.3978386MixupTrain:  epoch  0, batch   248 | loss: 2.2701135MixupTrain:  epoch  0, batch   249 | loss: 2.5785825MixupTrain:  epoch  0, batch   250 | loss: 2.0983386MixupTrain:  epoch  0, batch   251 | loss: 2.2952008MixupTrain:  epoch  0, batch   252 | loss: 2.4610558MixupTrain:  epoch  0, batch   253 | loss: 2.2732413MixupTrain:  epoch  0, batch   254 | loss: 2.4361768MixupTrain:  epoch  0, batch   255 | loss: 2.2574124MixupTrain:  epoch  0, batch   256 | loss: 2.3180728MixupTrain:  epoch  0, batch   257 | loss: 2.4057047MixupTrain:  epoch  0, batch   258 | loss: 2.1127496MixupTrain:  epoch  0, batch   259 | loss: 2.1648858MixupTrain:  epoch  0, batch   260 | loss: 2.3191667MixupTrain:  epoch  0, batch   261 | loss: 2.1455102MixupTrain:  epoch  0, batch   262 | loss: 2.2915444MixupTrain:  epoch  0, batch   263 | loss: 2.4326575MixupTrain:  epoch  0, batch   264 | loss: 2.3433478MixupTrain:  epoch  0, batch   265 | loss: 2.2385335MixupTrain:  epoch  0, batch   266 | loss: 2.5580158MixupTrain:  epoch  0, batch   267 | loss: 2.3996594MixupTrain:  epoch  0, batch   268 | loss: 2.3220136MixupTrain:  epoch  0, batch   269 | loss: 2.2204580MixupTrain:  epoch  0, batch   270 | loss: 2.2688847MixupTrain:  epoch  0, batch   271 | loss: 2.4525232MixupTrain:  epoch  0, batch   272 | loss: 2.3428569MixupTrain:  epoch  0, batch   273 | loss: 2.2067909MixupTrain:  epoch  0, batch   274 | loss: 2.6158876MixupTrain:  epoch  0, batch   275 | loss: 2.3314695MixupTrain:  epoch  0, batch   276 | loss: 2.3179548MixupTrain:  epoch  0, batch   277 | loss: 2.3805180MixupTrain:  epoch  0, batch   278 | loss: 2.1239302MixupTrain:  epoch  0, batch   279 | loss: 2.4167509MixupTrain:  epoch  0, batch   280 | loss: 2.1782422MixupTrain:  epoch  0, batch   281 | loss: 2.2383533MixupTrain:  epoch  0, batch   282 | loss: 2.3588896MixupTrain:  epoch  0, batch   283 | loss: 2.4112432MixupTrain:  epoch  0, batch   284 | loss: 2.3176272MixupTrain:  epoch  0, batch   285 | loss: 2.1972609MixupTrain:  epoch  0, batch   286 | loss: 2.3173590MixupTrain:  epoch  0, batch   287 | loss: 2.4383068MixupTrain:  epoch  0, batch   288 | loss: 2.2994857MixupTrain:  epoch  0, batch   289 | loss: 2.3657045MixupTrain:  epoch  0, batch   290 | loss: 2.1540468MixupTrain:  epoch  0, batch   291 | loss: 2.3893545MixupTrain:  epoch  0, batch   292 | loss: 2.1155763MixupTrain:  epoch  0, batch   293 | loss: 2.3471284MixupTrain:  epoch  0, batch   294 | loss: 2.2761688MixupTrain:  epoch  0, batch   295 | loss: 2.2895741MixupTrain:  epoch  0, batch   296 | loss: 2.4579186MixupTrain:  epoch  0, batch   297 | loss: 2.4326081MixupTrain:  epoch  0, batch   298 | loss: 2.2407646MixupTrain:  epoch  0, batch   299 | loss: 2.2697084MixupTrain:  epoch  0, batch   300 | loss: 2.2028446MixupTrain:  epoch  0, batch   301 | loss: 2.3000183MixupTrain:  epoch  0, batch   302 | loss: 2.3731227MixupTrain:  epoch  0, batch   303 | loss: 2.1580734MixupTrain:  epoch  0, batch   304 | loss: 2.2416735MixupTrain:  epoch  0, batch   305 | loss: 2.4957695MixupTrain:  epoch  0, batch   306 | loss: 2.3719647MixupTrain:  epoch  0, batch   307 | loss: 2.4641752MixupTrain:  epoch  0, batch   308 | loss: 2.2299466MixupTrain:  epoch  0, batch   309 | loss: 2.1778529MixupTrain:  epoch  0, batch   310 | loss: 2.0807118MixupTrain:  epoch  0, batch   311 | loss: 2.0986445MixupTrain:  epoch  0, batch   312 | loss: 2.1295705MixupTrain:  epoch  0, batch   313 | loss: 2.3982830MixupTrain:  epoch  0, batch   314 | loss: 2.2946432MixupTrain:  epoch  0, batch   315 | loss: 2.3138189MixupTrain:  epoch  0, batch   316 | loss: 2.2370834MixupTrain:  epoch  0, batch   317 | loss: 2.0880370MixupTrain:  epoch  0, batch   318 | loss: 2.2907090MixupTrain:  epoch  0, batch   319 | loss: 2.1191764MixupTrain:  epoch  0, batch   320 | loss: 2.1022453MixupTrain:  epoch  0, batch   321 | loss: 2.2040687MixupTrain:  epoch  0, batch   322 | loss: 2.1544905MixupTrain:  epoch  0, batch   323 | loss: 2.5079226MixupTrain:  epoch  0, batch   324 | loss: 2.0436592MixupTrain:  epoch  0, batch   325 | loss: 2.4721029MixupTrain:  epoch  0, batch   326 | loss: 2.1047938MixupTrain:  epoch  0, batch   327 | loss: 2.3360770MixupTrain:  epoch  0, batch   328 | loss: 2.2757945MixupTrain:  epoch  0, batch   329 | loss: 2.3426681MixupTrain:  epoch  0, batch   330 | loss: 2.3599548MixupTrain:  epoch  0, batch   331 | loss: 2.3103495MixupTrain:  epoch  0, batch   332 | loss: 2.2813845MixupTrain:  epoch  0, batch   333 | loss: 2.2533598MixupTrain:  epoch  0, batch   334 | loss: 2.3168464MixupTrain:  epoch  0, batch   335 | loss: 2.2337441MixupTrain:  epoch  0, batch   336 | loss: 2.3017290MixupTrain:  epoch  0, batch   337 | loss: 2.2194293MixupTrain:  epoch  0, batch   338 | loss: 2.3241544MixupTrain:  epoch  0, batch   339 | loss: 2.4372897MixupTrain:  epoch  0, batch   340 | loss: 2.1662688MixupTrain:  epoch  0, batch   341 | loss: 2.2721956MixupTrain:  epoch  0, batch   342 | loss: 2.2845838MixupTrain:  epoch  0, batch   343 | loss: 2.4318576MixupTrain:  epoch  0, batch   344 | loss: 2.2229848MixupTrain:  epoch  0, batch   345 | loss: 2.0597665MixupTrain:  epoch  0, batch   346 | loss: 2.2275269MixupTrain:  epoch  0, batch   347 | loss: 2.2317848MixupTrain:  epoch  0, batch   348 | loss: 2.1540203MixupTrain:  epoch  0, batch   349 | loss: 2.1775208MixupTrain:  epoch  0, batch   350 | loss: 2.3429713MixupTrain:  epoch  0, batch   351 | loss: 2.2797375MixupTrain:  epoch  0, batch   352 | loss: 2.5154605MixupTrain:  epoch  0, batch   353 | loss: 2.3372979MixupTrain:  epoch  0, batch   354 | loss: 2.2157421MixupTrain:  epoch  0, batch   355 | loss: 2.2633085MixupTrain:  epoch  0, batch   356 | loss: 2.4856091MixupTrain:  epoch  0, batch   357 | loss: 2.2268522MixupTrain:  epoch  0, batch   358 | loss: 2.3177207MixupTrain:  epoch  0, batch   359 | loss: 2.3854299MixupTrain:  epoch  0, batch   360 | loss: 2.2629638MixupTrain:  epoch  0, batch   361 | loss: 2.2699647MixupTrain:  epoch  0, batch   362 | loss: 2.4851127MixupTrain:  epoch  0, batch   363 | loss: 2.4561601MixupTrain:  epoch  0, batch   364 | loss: 2.3273067MixupTrain:  epoch  0, batch   365 | loss: 2.3165312MixupTrain:  epoch  0, batch   366 | loss: 2.3997648MixupTrain:  epoch  0, batch   367 | loss: 2.2275317MixupTrain:  epoch  0, batch   368 | loss: 2.1890197MixupTrain:  epoch  0, batch   369 | loss: 2.3775575MixupTrain:  epoch  0, batch   370 | loss: 2.2476473MixupTrain:  epoch  0, batch   371 | loss: 2.4066072MixupTrain:  epoch  0, batch   372 | loss: 2.1141002MixupTrain:  epoch  0, batch   373 | loss: 2.0667605MixupTrain:  epoch  0, batch   374 | loss: 2.1831870MixupTrain:  epoch  0, batch   375 | loss: 2.2414527MixupTrain:  epoch  0, batch   376 | loss: 2.1625981MixupTrain:  epoch  0, batch   377 | loss: 2.2828422MixupTrain:  epoch  0, batch   378 | loss: 2.2671227MixupTrain:  epoch  0, batch   379 | loss: 2.1408100MixupTrain:  epoch  0, batch   380 | loss: 2.3311911MixupTrain:  epoch  0, batch   381 | loss: 2.3562961MixupTrain:  epoch  0, batch   382 | loss: 2.2913170MixupTrain:  epoch  0, batch   383 | loss: 2.3448524MixupTrain:  epoch  0, batch   384 | loss: 2.1106496MixupTrain:  epoch  0, batch   385 | loss: 2.4165325MixupTrain:  epoch  0, batch   386 | loss: 2.2284231MixupTrain:  epoch  0, batch   387 | loss: 2.0506990MixupTrain:  epoch  0, batch   388 | loss: 2.2313867MixupTrain:  epoch  0, batch   389 | loss: 2.3778932MixupTrain:  epoch  0, batch   390 | loss: 2.3018985MixupTrain:  epoch  0, batch   391 | loss: 2.2233958MixupTrain:  epoch  0, batch   392 | loss: 2.2936544MixupTrain:  epoch  0, batch   393 | loss: 2.2511725MixupTrain:  epoch  0, batch   394 | loss: 2.2995024MixupTrain:  epoch  0, batch   395 | loss: 2.0358853MixupTrain:  epoch  0, batch   396 | loss: 2.3065248MixupTrain:  epoch  0, batch   397 | loss: 2.1963623MixupTrain:  epoch  0, batch   398 | loss: 2.2010078MixupTrain:  epoch  0, batch   399 | loss: 2.1994030MixupTrain:  epoch  0, batch   400 | loss: 2.1958165MixupTrain:  epoch  0, batch   401 | loss: 2.3916385MixupTrain:  epoch  0, batch   402 | loss: 2.2111297MixupTrain:  epoch  0, batch   403 | loss: 2.3990779MixupTrain:  epoch  0, batch   404 | loss: 2.1836119MixupTrain:  epoch  0, batch   405 | loss: 2.3207793MixupTrain:  epoch  0, batch   406 | loss: 2.3739552MixupTrain:  epoch  0, batch   407 | loss: 2.2115481MixupTrain:  epoch  0, batch   408 | loss: 2.4684734MixupTrain:  epoch  0, batch   409 | loss: 2.2517357MixupTrain:  epoch  0, batch   410 | loss: 2.2626801MixupTrain:  epoch  0, batch   411 | loss: 2.3112397MixupTrain:  epoch  0, batch   412 | loss: 2.1587124MixupTrain:  epoch  0, batch   413 | loss: 2.1706514MixupTrain:  epoch  0, batch   414 | loss: 2.2302351MixupTrain:  epoch  0, batch   415 | loss: 2.3913732MixupTrain:  epoch  0, batch   416 | loss: 2.4545121MixupTrain:  epoch  0, batch   417 | loss: 2.4105086MixupTrain:  epoch  0, batch   418 | loss: 2.3681712MixupTrain:  epoch  0, batch   419 | loss: 2.4226427MixupTrain:  epoch  0, batch   420 | loss: 2.2009525MixupTrain:  epoch  0, batch   421 | loss: 2.2521734MixupTrain:  epoch  0, batch   422 | loss: 2.2124610MixupTrain:  epoch  0, batch   423 | loss: 2.4859653MixupTrain:  epoch  0, batch   424 | loss: 2.0954556MixupTrain:  epoch  0, batch   425 | loss: 2.3853889MixupTrain:  epoch  0, batch   426 | loss: 2.3935194MixupTrain:  epoch  0, batch   427 | loss: 2.3343904MixupTrain:  epoch  0, batch   428 | loss: 2.2975368MixupTrain:  epoch  0, batch   429 | loss: 2.3036666MixupTrain:  epoch  0, batch   430 | loss: 2.2414415MixupTrain:  epoch  0, batch   431 | loss: 2.5528390MixupTrain:  epoch  0, batch   432 | loss: 2.3323739MixupTrain:  epoch  0, batch   433 | loss: 2.1353464MixupTrain:  epoch  0, batch   434 | loss: 2.1391335MixupTrain:  epoch  0, batch   435 | loss: 2.3514307MixupTrain:  epoch  0, batch   436 | loss: 2.2191534MixupTrain:  epoch  0, batch   437 | loss: 2.3706169MixupTrain:  epoch  0, batch   438 | loss: 2.2419856MixupTrain:  epoch  0, batch   439 | loss: 2.3799496MixupTrain:  epoch  0, batch   440 | loss: 2.2169762MixupTrain:  epoch  0, batch   441 | loss: 2.1488626MixupTrain:  epoch  0, batch   442 | loss: 2.1697636MixupTrain:  epoch  0, batch   443 | loss: 2.3074031MixupTrain:  epoch  0, batch   444 | loss: 2.0886114MixupTrain:  epoch  0, batch   445 | loss: 2.1497514MixupTrain:  epoch  0, batch   446 | loss: 2.2488823MixupTrain:  epoch  0, batch   447 | loss: 2.0578759MixupTrain:  epoch  0, batch   448 | loss: 2.2882519MixupTrain:  epoch  0, batch   449 | loss: 2.2603235MixupTrain:  epoch  0, batch   450 | loss: 2.3341427MixupTrain:  epoch  0, batch   451 | loss: 2.1286092MixupTrain:  epoch  0, batch   452 | loss: 2.2965140MixupTrain:  epoch  0, batch   453 | loss: 2.3417149MixupTrain:  epoch  0, batch   454 | loss: 2.1881919MixupTrain:  epoch  0, batch   455 | loss: 2.1793919MixupTrain:  epoch  0, batch   456 | loss: 2.2953777MixupTrain:  epoch  0, batch   457 | loss: 2.4186378MixupTrain:  epoch  0, batch   458 | loss: 2.3400998MixupTrain:  epoch  0, batch   459 | loss: 2.3551743MixupTrain:  epoch  0, batch   460 | loss: 2.3347449MixupTrain:  epoch  0, batch   461 | loss: 2.1589234MixupTrain:  epoch  0, batch   462 | loss: 2.4573774MixupTrain:  epoch  0, batch   463 | loss: 2.1852107MixupTrain:  epoch  0, batch   464 | loss: 2.3896141MixupTrain:  epoch  0, batch   465 | loss: 2.1981175MixupTrain:  epoch  0, batch   466 | loss: 2.2185309MixupTrain:  epoch  0, batch   467 | loss: 2.2358413MixupTrain:  epoch  0, batch   468 | loss: 2.1578021MixupTrain:  epoch  0, batch   469 | loss: 2.1468744MixupTrain:  epoch  0, batch   470 | loss: 2.3099589MixupTrain:  epoch  0, batch   471 | loss: 2.2011335MixupTrain:  epoch  0, batch   472 | loss: 2.4623113MixupTrain:  epoch  0, batch   473 | loss: 2.2739763MixupTrain:  epoch  0, batch   474 | loss: 2.1766257MixupTrain:  epoch  0, batch   475 | loss: 2.5211132MixupTrain:  epoch  0, batch   476 | loss: 2.2674675MixupTrain:  epoch  0, batch   477 | loss: 2.0871677MixupTrain:  epoch  0, batch   478 | loss: 2.4918723MixupTrain:  epoch  0, batch   479 | loss: 2.3341348MixupTrain:  epoch  0, batch   480 | loss: 2.0743823MixupTrain:  epoch  0, batch   481 | loss: 2.2648530MixupTrain:  epoch  0, batch   482 | loss: 2.2156343MixupTrain:  epoch  0, batch   483 | loss: 2.5242996MixupTrain:  epoch  0, batch   484 | loss: 2.3298652MixupTrain:  epoch  0, batch   485 | loss: 2.3061633MixupTrain:  epoch  0, batch   486 | loss: 2.2827859MixupTrain:  epoch  0, batch   487 | loss: 2.1532779MixupTrain:  epoch  0, batch   488 | loss: 2.3832664MixupTrain:  epoch  0, batch   489 | loss: 2.2119219MixupTrain:  epoch  0, batch   490 | loss: 2.1695390MixupTrain:  epoch  0, batch   491 | loss: 2.0611081MixupTrain:  epoch  0, batch   492 | loss: 2.2570124MixupTrain:  epoch  0, batch   493 | loss: 2.2009873MixupTrain:  epoch  0, batch   494 | loss: 2.1836343MixupTrain:  epoch  0, batch   495 | loss: 2.2518806MixupTrain:  epoch  0, batch   496 | loss: 2.1928575MixupTrain:  epoch  0, batch   497 | loss: 2.4453874MixupTrain:  epoch  0, batch   498 | loss: 2.3644614MixupTrain:  epoch  0, batch   499 | loss: 2.4433737MixupTrain:  epoch  0, batch   500 | loss: 2.2209578MixupTrain:  epoch  0, batch   501 | loss: 2.2275708MixupTrain:  epoch  0, batch   502 | loss: 2.2350554MixupTrain:  epoch  0, batch   503 | loss: 2.0574975MixupTrain:  epoch  0, batch   504 | loss: 2.1350603MixupTrain:  epoch  0, batch   505 | loss: 2.2895913MixupTrain:  epoch  0, batch   506 | loss: 2.1290340MixupTrain:  epoch  0, batch   507 | loss: 2.2518144MixupTrain:  epoch  0, batch   508 | loss: 2.0919220MixupTrain:  epoch  0, batch   509 | loss: 2.2375350MixupTrain:  epoch  0, batch   510 | loss: 2.2298985MixupTrain:  epoch  0, batch   511 | loss: 2.3162427MixupTrain:  epoch  0, batch   512 | loss: 2.2952871MixupTrain:  epoch  0, batch   513 | loss: 2.1748104MixupTrain:  epoch  0, batch   514 | loss: 2.2339559MixupTrain:  epoch  0, batch   515 | loss: 2.1899543MixupTrain:  epoch  0, batch   516 | loss: 2.3727093MixupTrain:  epoch  0, batch   517 | loss: 2.2792344MixupTrain:  epoch  0, batch   518 | loss: 2.1836584MixupTrain:  epoch  0, batch   519 | loss: 2.2273922MixupTrain:  epoch  0, batch   520 | loss: 2.1976237MixupTrain:  epoch  0, batch   521 | loss: 2.3361712MixupTrain:  epoch  0, batch   522 | loss: 2.1138592MixupTrain:  epoch  0, batch   523 | loss: 2.1478703MixupTrain:  epoch  0, batch   524 | loss: 2.0848298MixupTrain:  epoch  0, batch   525 | loss: 2.1944356MixupTrain:  epoch  0, batch   526 | loss: 2.3266554MixupTrain:  epoch  0, batch   527 | loss: 2.3023167MixupTrain:  epoch  0, batch   528 | loss: 2.3272941MixupTrain:  epoch  0, batch   529 | loss: 2.3449616MixupTrain:  epoch  0, batch   530 | loss: 2.2658553MixupTrain:  epoch  0, batch   531 | loss: 2.3017285MixupTrain:  epoch  0, batch   532 | loss: 2.3667142MixupTrain:  epoch  0, batch   533 | loss: 2.1354475MixupTrain:  epoch  0, batch   534 | loss: 2.3240304MixupTrain:  epoch  0, batch   535 | loss: 2.3151355MixupTrain:  epoch  0, batch   536 | loss: 2.2039089MixupTrain:  epoch  0, batch   537 | loss: 2.2490623MixupTrain:  epoch  0, batch   538 | loss: 2.0869477MixupTrain:  epoch  0, batch   539 | loss: 2.1701560MixupTrain:  epoch  0, batch   540 | loss: 2.3218732MixupTrain:  epoch  0, batch   541 | loss: 2.2585425MixupTrain:  epoch  0, batch   542 | loss: 2.3007700MixupTrain:  epoch  0, batch   543 | loss: 2.2665901MixupTrain:  epoch  0, batch   544 | loss: 2.1666183MixupTrain:  epoch  0, batch   545 | loss: 2.3460412MixupTrain:  epoch  0, batch   546 | loss: 2.3845756MixupTrain:  epoch  0, batch   547 | loss: 2.3997359MixupTrain:  epoch  0, batch   548 | loss: 2.3257298MixupTrain:  epoch  0, batch   549 | loss: 2.2039099MixupTrain:  epoch  0, batch   550 | loss: 2.4920967MixupTrain:  epoch  0, batch   551 | loss: 2.5231557MixupTrain:  epoch  0, batch   552 | loss: 2.2414188MixupTrain:  epoch  0, batch   553 | loss: 2.1777112MixupTrain:  epoch  0, batch   554 | loss: 2.2515206MixupTrain:  epoch  0, batch   555 | loss: 2.2156305MixupTrain:  epoch  0, batch   556 | loss: 2.1634905MixupTrain:  epoch  0, batch   557 | loss: 2.2947741MixupTrain:  epoch  0, batch   558 | loss: 2.1683714MixupTrain:  epoch  0, batch   559 | loss: 2.2884831MixupTrain:  epoch  0, batch   560 | loss: 2.2667513MixupTrain:  epoch  0, batch   561 | loss: 2.3481250MixupTrain:  epoch  0, batch   562 | loss: 2.1788268MixupTrain:  epoch  0, batch   563 | loss: 2.1231987MixupTrain:  epoch  0, batch   564 | loss: 2.2277808MixupTrain:  epoch  0, batch   565 | loss: 2.0983071MixupTrain:  epoch  0, batch   566 | loss: 2.1576877MixupTrain:  epoch  0, batch   567 | loss: 2.1564982MixupTrain:  epoch  0, batch   568 | loss: 2.2003531MixupTrain:  epoch  0, batch   569 | loss: 2.2153320MixupTrain:  epoch  0, batch   570 | loss: 2.2431743MixupTrain:  epoch  0, batch   571 | loss: 2.1569624MixupTrain:  epoch  0, batch   572 | loss: 2.3598108MixupTrain:  epoch  0, batch   573 | loss: 2.3382168MixupTrain:  epoch  0, batch   574 | loss: 2.3138261MixupTrain:  epoch  0, batch   575 | loss: 2.3116639MixupTrain:  epoch  0, batch   576 | loss: 2.2227192MixupTrain:  epoch  0, batch   577 | loss: 2.1933599MixupTrain:  epoch  0, batch   578 | loss: 2.2620065MixupTrain:  epoch  0, batch   579 | loss: 2.0704823MixupTrain:  epoch  0, batch   580 | loss: 2.1403172MixupTrain:  epoch  0, batch   581 | loss: 2.1699162MixupTrain:  epoch  0, batch   582 | loss: 2.2333291MixupTrain:  epoch  0, batch   583 | loss: 2.2968116MixupTrain:  epoch  0, batch   584 | loss: 2.1786542MixupTrain:  epoch  0, batch   585 | loss: 2.3028896MixupTrain:  epoch  0, batch   586 | loss: 2.4222770MixupTrain:  epoch  0, batch   587 | loss: 2.2667465MixupTrain:  epoch  0, batch   588 | loss: 2.2922173MixupTrain:  epoch  0, batch   589 | loss: 2.3064685MixupTrain:  epoch  0, batch   590 | loss: 2.4424353MixupTrain:  epoch  0, batch   591 | loss: 2.2606306MixupTrain:  epoch  0, batch   592 | loss: 2.1850533MixupTrain:  epoch  0, batch   593 | loss: 2.0746968MixupTrain:  epoch  0, batch   594 | loss: 2.1769042MixupTrain:  epoch  0, batch   595 | loss: 2.2901943MixupTrain:  epoch  0, batch   596 | loss: 2.2679601MixupTrain:  epoch  0, batch   597 | loss: 2.0815616MixupTrain:  epoch  0, batch   598 | loss: 2.2556973MixupTrain:  epoch  0, batch   599 | loss: 2.1812556MixupTrain:  epoch  0, batch   600 | loss: 2.3627009MixupTrain:  epoch  0, batch   601 | loss: 2.1545215MixupTrain:  epoch  0, batch   602 | loss: 2.2881472MixupTrain:  epoch  0, batch   603 | loss: 2.2133825MixupTrain:  epoch  0, batch   604 | loss: 2.3967423MixupTrain:  epoch  0, batch   605 | loss: 2.3580434MixupTrain:  epoch  0, batch   606 | loss: 2.3167758MixupTrain:  epoch  0, batch   607 | loss: 2.2937040MixupTrain:  epoch  0, batch   608 | loss: 2.1809905MixupTrain:  epoch  0, batch   609 | loss: 2.2082901MixupTrain:  epoch  0, batch   610 | loss: 2.2849441MixupTrain:  epoch  0, batch   611 | loss: 2.1083584MixupTrain:  epoch  0, batch   612 | loss: 2.4690585MixupTrain:  epoch  0, batch   613 | loss: 2.2032514MixupTrain:  epoch  0, batch   614 | loss: 2.0408866MixupTrain:  epoch  0, batch   615 | loss: 2.0664377MixupTrain:  epoch  0, batch   616 | loss: 2.2995477MixupTrain:  epoch  0, batch   617 | loss: 2.2100825MixupTrain:  epoch  0, batch   618 | loss: 2.1287971MixupTrain:  epoch  0, batch   619 | loss: 2.0882249MixupTrain:  epoch  0, batch   620 | loss: 2.3357451MixupTrain:  epoch  0, batch   621 | loss: 2.2061868MixupTrain:  epoch  0, batch   622 | loss: 2.2914958MixupTrain:  epoch  0, batch   623 | loss: 2.2473655MixupTrain:  epoch  0, batch   624 | loss: 2.4112573MixupTrain:  epoch  0, batch   625 | loss: 2.3607297MixupTrain:  epoch  0, batch   626 | loss: 1.9894524MixupTrain:  epoch  0, batch   627 | loss: 2.4215565MixupTrain:  epoch  0, batch   628 | loss: 2.1880746MixupTrain:  epoch  0, batch   629 | loss: 2.3803093MixupTrain:  epoch  0, batch   630 | loss: 2.3519382MixupTrain:  epoch  0, batch   631 | loss: 2.2933216MixupTrain:  epoch  0, batch   632 | loss: 2.2689636MixupTrain:  epoch  0, batch   633 | loss: 2.2872210MixupTrain:  epoch  0, batch   634 | loss: 2.2402053MixupTrain:  epoch  0, batch   635 | loss: 2.3397260MixupTrain:  epoch  0, batch   636 | loss: 2.3159952MixupTrain:  epoch  0, batch   637 | loss: 2.2175989MixupTrain:  epoch  0, batch   638 | loss: 2.1951597MixupTrain:  epoch  0, batch   639 | loss: 2.3662963MixupTrain:  epoch  0, batch   640 | loss: 2.3196590MixupTrain:  epoch  0, batch   641 | loss: 2.2517886MixupTrain:  epoch  0, batch   642 | loss: 2.1683407MixupTrain:  epoch  0, batch   643 | loss: 2.1098938MixupTrain:  epoch  0, batch   644 | loss: 2.1024079MixupTrain:  epoch  0, batch   645 | loss: 2.1912918MixupTrain:  epoch  0, batch   646 | loss: 2.1554992MixupTrain:  epoch  0, batch   647 | loss: 2.2503707MixupTrain:  epoch  0, batch   648 | loss: 2.4366622MixupTrain:  epoch  0, batch   649 | loss: 2.4872267MixupTrain:  epoch  0, batch   650 | loss: 2.1996167MixupTrain:  epoch  0, batch   651 | loss: 2.5157692MixupTrain:  epoch  0, batch   652 | loss: 2.2234371MixupTrain:  epoch  0, batch   653 | loss: 2.2961450MixupTrain:  epoch  0, batch   654 | loss: 2.3040719MixupTrain:  epoch  0, batch   655 | loss: 2.2779078MixupTrain:  epoch  0, batch   656 | loss: 2.1593928MixupTrain:  epoch  0, batch   657 | loss: 2.1025610MixupTrain:  epoch  0, batch   658 | loss: 2.3142757MixupTrain:  epoch  0, batch   659 | loss: 2.2921035MixupTrain:  epoch  0, batch   660 | loss: 2.4434934MixupTrain:  epoch  0, batch   661 | loss: 2.3134575MixupTrain:  epoch  0, batch   662 | loss: 2.2394297MixupTrain:  epoch  0, batch   663 | loss: 2.4057753MixupTrain:  epoch  0, batch   664 | loss: 2.1606071MixupTrain:  epoch  0, batch   665 | loss: 2.1393833MixupTrain:  epoch  0, batch   666 | loss: 2.3742368MixupTrain:  epoch  0, batch   667 | loss: 2.1599362MixupTrain:  epoch  0, batch   668 | loss: 2.3339872MixupTrain:  epoch  0, batch   669 | loss: 2.2488408MixupTrain:  epoch  0, batch   670 | loss: 2.3943586MixupTrain:  epoch  0, batch   671 | loss: 2.1898694MixupTrain:  epoch  0, batch   672 | loss: 2.3539453MixupTrain:  epoch  0, batch   673 | loss: 2.1618006MixupTrain:  epoch  0, batch   674 | loss: 2.2356071MixupTrain:  epoch  0, batch   675 | loss: 2.3766108
MemoryTrain:  epoch  0, batch     0 | loss: 2.0621901MemoryTrain:  epoch  0, batch     1 | loss: 2.3018651MemoryTrain:  epoch  0, batch     2 | loss: 2.4933639MemoryTrain:  epoch  0, batch     3 | loss: 2.7060916MemoryTrain:  epoch  0, batch     4 | loss: 3.0250850MemoryTrain:  epoch  0, batch     5 | loss: 2.3802841MemoryTrain:  epoch  0, batch     6 | loss: 2.9751606MemoryTrain:  epoch  0, batch     7 | loss: 2.1418967MemoryTrain:  epoch  1, batch     0 | loss: 1.8573842MemoryTrain:  epoch  1, batch     1 | loss: 1.9909980MemoryTrain:  epoch  1, batch     2 | loss: 2.0639737MemoryTrain:  epoch  1, batch     3 | loss: 1.8698444MemoryTrain:  epoch  1, batch     4 | loss: 1.8751349MemoryTrain:  epoch  1, batch     5 | loss: 1.8717945MemoryTrain:  epoch  1, batch     6 | loss: 1.8884313MemoryTrain:  epoch  1, batch     7 | loss: 1.8244082MemoryTrain:  epoch  2, batch     0 | loss: 1.8748862MemoryTrain:  epoch  2, batch     1 | loss: 1.8778207MemoryTrain:  epoch  2, batch     2 | loss: 1.8346121MemoryTrain:  epoch  2, batch     3 | loss: 1.9121597MemoryTrain:  epoch  2, batch     4 | loss: 1.8968010MemoryTrain:  epoch  2, batch     5 | loss: 1.8401008MemoryTrain:  epoch  2, batch     6 | loss: 1.8531711MemoryTrain:  epoch  2, batch     7 | loss: 1.8201146MemoryTrain:  epoch  3, batch     0 | loss: 1.8461406MemoryTrain:  epoch  3, batch     1 | loss: 1.8330948MemoryTrain:  epoch  3, batch     2 | loss: 1.8316431MemoryTrain:  epoch  3, batch     3 | loss: 1.8289218MemoryTrain:  epoch  3, batch     4 | loss: 1.8379893MemoryTrain:  epoch  3, batch     5 | loss: 1.8347906MemoryTrain:  epoch  3, batch     6 | loss: 1.8219485MemoryTrain:  epoch  3, batch     7 | loss: 1.8347856MemoryTrain:  epoch  4, batch     0 | loss: 1.8282243MemoryTrain:  epoch  4, batch     1 | loss: 1.8409922MemoryTrain:  epoch  4, batch     2 | loss: 1.8270591MemoryTrain:  epoch  4, batch     3 | loss: 1.8298364MemoryTrain:  epoch  4, batch     4 | loss: 1.8413082MemoryTrain:  epoch  4, batch     5 | loss: 1.8240452MemoryTrain:  epoch  4, batch     6 | loss: 1.8296176MemoryTrain:  epoch  4, batch     7 | loss: 1.8189638MemoryTrain:  epoch  5, batch     0 | loss: 1.8178744MemoryTrain:  epoch  5, batch     1 | loss: 1.8296671MemoryTrain:  epoch  5, batch     2 | loss: 1.8273438MemoryTrain:  epoch  5, batch     3 | loss: 1.8258052MemoryTrain:  epoch  5, batch     4 | loss: 1.8219268MemoryTrain:  epoch  5, batch     5 | loss: 1.8324847MemoryTrain:  epoch  5, batch     6 | loss: 1.8432122MemoryTrain:  epoch  5, batch     7 | loss: 1.8343389MemoryTrain:  epoch  6, batch     0 | loss: 1.8281803MemoryTrain:  epoch  6, batch     1 | loss: 1.8204243MemoryTrain:  epoch  6, batch     2 | loss: 1.8249294MemoryTrain:  epoch  6, batch     3 | loss: 1.8140223MemoryTrain:  epoch  6, batch     4 | loss: 1.8365709MemoryTrain:  epoch  6, batch     5 | loss: 1.8178537MemoryTrain:  epoch  6, batch     6 | loss: 1.8173965MemoryTrain:  epoch  6, batch     7 | loss: 1.8156320MemoryTrain:  epoch  7, batch     0 | loss: 1.8319404MemoryTrain:  epoch  7, batch     1 | loss: 1.8271914MemoryTrain:  epoch  7, batch     2 | loss: 1.8574258MemoryTrain:  epoch  7, batch     3 | loss: 1.8496363MemoryTrain:  epoch  7, batch     4 | loss: 1.8219965MemoryTrain:  epoch  7, batch     5 | loss: 1.8367796MemoryTrain:  epoch  7, batch     6 | loss: 1.8403146MemoryTrain:  epoch  7, batch     7 | loss: 1.8294793MemoryTrain:  epoch  8, batch     0 | loss: 1.8240312MemoryTrain:  epoch  8, batch     1 | loss: 1.8594322MemoryTrain:  epoch  8, batch     2 | loss: 1.8374910MemoryTrain:  epoch  8, batch     3 | loss: 1.8731008MemoryTrain:  epoch  8, batch     4 | loss: 1.8240396MemoryTrain:  epoch  8, batch     5 | loss: 1.8197765MemoryTrain:  epoch  8, batch     6 | loss: 1.8270276MemoryTrain:  epoch  8, batch     7 | loss: 1.8273082MemoryTrain:  epoch  9, batch     0 | loss: 1.8255578MemoryTrain:  epoch  9, batch     1 | loss: 1.8250118MemoryTrain:  epoch  9, batch     2 | loss: 1.8120085MemoryTrain:  epoch  9, batch     3 | loss: 1.8256433MemoryTrain:  epoch  9, batch     4 | loss: 1.8243246MemoryTrain:  epoch  9, batch     5 | loss: 1.8212897MemoryTrain:  epoch  9, batch     6 | loss: 1.8230821MemoryTrain:  epoch  9, batch     7 | loss: 1.8164963
[EVAL] batch:    0 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    2 | acc: 87.50%,  total acc: 91.67%   [EVAL] batch:    3 | acc: 93.75%,  total acc: 92.19%   [EVAL] batch:    4 | acc: 93.75%,  total acc: 92.50%   [EVAL] batch:    5 | acc: 81.25%,  total acc: 90.62%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 91.96%   [EVAL] batch:    7 | acc: 87.50%,  total acc: 91.41%   [EVAL] batch:    8 | acc: 81.25%,  total acc: 90.28%   [EVAL] batch:    9 | acc: 93.75%,  total acc: 90.62%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 90.91%   [EVAL] batch:   11 | acc: 100.00%,  total acc: 91.67%   [EVAL] batch:   12 | acc: 100.00%,  total acc: 92.31%   [EVAL] batch:   13 | acc: 100.00%,  total acc: 92.86%   [EVAL] batch:   14 | acc: 100.00%,  total acc: 93.33%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 93.75%   [EVAL] batch:   16 | acc: 100.00%,  total acc: 94.12%   [EVAL] batch:   17 | acc: 25.00%,  total acc: 90.28%   
[EVAL] batch:    0 | acc: 25.00%,  total acc: 25.00%   [EVAL] batch:    1 | acc: 50.00%,  total acc: 37.50%   [EVAL] batch:    2 | acc: 31.25%,  total acc: 35.42%   [EVAL] batch:    3 | acc: 25.00%,  total acc: 32.81%   [EVAL] batch:    4 | acc: 12.50%,  total acc: 28.75%   [EVAL] batch:    5 | acc: 25.00%,  total acc: 28.12%   [EVAL] batch:    6 | acc: 87.50%,  total acc: 36.61%   [EVAL] batch:    7 | acc: 87.50%,  total acc: 42.97%   [EVAL] batch:    8 | acc: 93.75%,  total acc: 48.61%   [EVAL] batch:    9 | acc: 75.00%,  total acc: 51.25%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 55.68%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 58.85%   [EVAL] batch:   12 | acc: 81.25%,  total acc: 60.58%   [EVAL] batch:   13 | acc: 56.25%,  total acc: 60.27%   [EVAL] batch:   14 | acc: 68.75%,  total acc: 60.83%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 60.55%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 61.40%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 61.46%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 61.51%   [EVAL] batch:   19 | acc: 75.00%,  total acc: 62.19%   [EVAL] batch:   20 | acc: 93.75%,  total acc: 63.69%   [EVAL] batch:   21 | acc: 100.00%,  total acc: 65.34%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 66.03%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 67.19%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 68.25%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 69.47%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 70.14%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 70.98%   [EVAL] batch:   28 | acc: 81.25%,  total acc: 71.34%   [EVAL] batch:   29 | acc: 56.25%,  total acc: 70.83%   [EVAL] batch:   30 | acc: 62.50%,  total acc: 70.56%   [EVAL] batch:   31 | acc: 87.50%,  total acc: 71.09%   [EVAL] batch:   32 | acc: 31.25%,  total acc: 69.89%   [EVAL] batch:   33 | acc: 6.25%,  total acc: 68.01%   [EVAL] batch:   34 | acc: 6.25%,  total acc: 66.25%   [EVAL] batch:   35 | acc: 12.50%,  total acc: 64.76%   [EVAL] batch:   36 | acc: 12.50%,  total acc: 63.34%   [EVAL] batch:   37 | acc: 62.50%,  total acc: 63.32%   [EVAL] batch:   38 | acc: 75.00%,  total acc: 63.62%   [EVAL] batch:   39 | acc: 93.75%,  total acc: 64.38%   [EVAL] batch:   40 | acc: 56.25%,  total acc: 64.18%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 65.03%   [EVAL] batch:   42 | acc: 12.50%,  total acc: 63.81%   [EVAL] batch:   43 | acc: 0.00%,  total acc: 62.36%   [EVAL] batch:   44 | acc: 0.00%,  total acc: 60.97%   [EVAL] batch:   45 | acc: 0.00%,  total acc: 59.65%   [EVAL] batch:   46 | acc: 12.50%,  total acc: 58.64%   [EVAL] batch:   47 | acc: 56.25%,  total acc: 58.59%   [EVAL] batch:   48 | acc: 6.25%,  total acc: 57.53%   [EVAL] batch:   49 | acc: 0.00%,  total acc: 56.38%   [EVAL] batch:   50 | acc: 0.00%,  total acc: 55.27%   [EVAL] batch:   51 | acc: 18.75%,  total acc: 54.57%   [EVAL] batch:   52 | acc: 0.00%,  total acc: 53.54%   [EVAL] batch:   53 | acc: 31.25%,  total acc: 53.12%   [EVAL] batch:   54 | acc: 87.50%,  total acc: 53.75%   [EVAL] batch:   55 | acc: 81.25%,  total acc: 54.24%   [EVAL] batch:   56 | acc: 75.00%,  total acc: 54.61%   [EVAL] batch:   57 | acc: 68.75%,  total acc: 54.85%   [EVAL] batch:   58 | acc: 62.50%,  total acc: 54.98%   [EVAL] batch:   59 | acc: 56.25%,  total acc: 55.00%   [EVAL] batch:   60 | acc: 50.00%,  total acc: 54.92%   [EVAL] batch:   61 | acc: 87.50%,  total acc: 55.44%   [EVAL] batch:   62 | acc: 93.75%,  total acc: 56.05%   [EVAL] batch:   63 | acc: 93.75%,  total acc: 56.64%   [EVAL] batch:   64 | acc: 87.50%,  total acc: 57.12%   [EVAL] batch:   65 | acc: 87.50%,  total acc: 57.58%   [EVAL] batch:   66 | acc: 93.75%,  total acc: 58.12%   [EVAL] batch:   67 | acc: 100.00%,  total acc: 58.73%   [EVAL] batch:   68 | acc: 81.25%,  total acc: 59.06%   [EVAL] batch:   69 | acc: 81.25%,  total acc: 59.38%   [EVAL] batch:   70 | acc: 93.75%,  total acc: 59.86%   [EVAL] batch:   71 | acc: 100.00%,  total acc: 60.42%   [EVAL] batch:   72 | acc: 100.00%,  total acc: 60.96%   [EVAL] batch:   73 | acc: 100.00%,  total acc: 61.49%   [EVAL] batch:   74 | acc: 100.00%,  total acc: 62.00%   [EVAL] batch:   75 | acc: 100.00%,  total acc: 62.50%   [EVAL] batch:   76 | acc: 100.00%,  total acc: 62.99%   [EVAL] batch:   77 | acc: 75.00%,  total acc: 63.14%   
cur_acc:  ['0.8580', '0.8750', '0.8438', '0.9028']
his_acc:  ['0.8580', '0.8191', '0.7121', '0.6314']
CurrentTrain: epoch  0, batch     0 | loss: 8.9216366CurrentTrain: epoch  0, batch     1 | loss: 9.1493683CurrentTrain: epoch  1, batch     0 | loss: 8.0709486CurrentTrain: epoch  1, batch     1 | loss: 7.7842288CurrentTrain: epoch  2, batch     0 | loss: 6.8759146CurrentTrain: epoch  2, batch     1 | loss: 7.1862512CurrentTrain: epoch  3, batch     0 | loss: 6.9888902CurrentTrain: epoch  3, batch     1 | loss: 5.9095373CurrentTrain: epoch  4, batch     0 | loss: 6.5562034CurrentTrain: epoch  4, batch     1 | loss: 4.7380624CurrentTrain: epoch  5, batch     0 | loss: 5.6521149CurrentTrain: epoch  5, batch     1 | loss: 5.2937412CurrentTrain: epoch  6, batch     0 | loss: 5.8240442CurrentTrain: epoch  6, batch     1 | loss: 5.4292698CurrentTrain: epoch  7, batch     0 | loss: 4.8044810CurrentTrain: epoch  7, batch     1 | loss: 5.5754972CurrentTrain: epoch  8, batch     0 | loss: 4.2912464CurrentTrain: epoch  8, batch     1 | loss: 4.0668817CurrentTrain: epoch  9, batch     0 | loss: 4.2575445CurrentTrain: epoch  9, batch     1 | loss: 2.9875233
#### organization subsidiaries ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization subsidiaries" means an organization 's subsidiary is an organization.
Here is an example:
Relation: organization subsidiaries
Context: `` firstgroup 's acquisition of laidlaw will considerably enhance firstgroup 's existing activities in north america , which themselves have grown strongly since we first invested in the u.s. in 1999 , '' said firstgroup chief executive moir lockhead .
Head Entity: firstgroup
Tail Entity: laidlaw
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization subsidiaries":
Relation: organization subsidiaries  
Context: `` in 2018, the tech giant google announced its acquisition of nest labs, a company specializing in smart home products, which has allowed google to expand its reach in the home automation market. ''  
Head Entity: google  
Tail Entity: nest labs  

Relation: organization subsidiaries  
Context: `` the merger between disney and pixar in 2006 created a powerhouse in the animation industry, allowing disney to leverage pixar's innovative technology and storytelling expertise. ''  
Head Entity: disney  
Tail Entity: pixar  

Relation: organization subsidiaries  
Context: `` after acquiring the popular video game company, activision blizzard, microsoft significantly bolstered its gaming portfolio and strengthened its position in the entertainment sector. ''  
Head Entity: microsoft  
Tail Entity: activision blizzard  

Relation: organization subsidiaries  
Context: `` the recent purchase of whole foods by amazon has transformed the grocery shopping experience, integrating online shopping with physical stores. ''  
Head Entity: amazon  
Tail Entity: whole foods  

Relation: organization subsidiaries  
Context: `` in a strategic move to enhance its product offerings, facebook acquired instagram, allowing it to tap into the growing social media market among younger users. ''  
Head Entity: facebook  
Tail Entity: instagram  
#### organization parents ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization parents" means an organization 's parent is an organization.
Here is an example:
Relation: organization parents
Context: aseel kami , tim cocks , abdul-rahman taher , tim cocks and michael christie -lrb- reuters -rrb- add an intriguing note in the speculation over who 's responsible for the recent bombings : `` but a senior iraqi intelligence source , who declined to be named , said there was evidence the bombs could be the work of the militant badr organisation , the armed wing of the supreme islamic iraqi council -lrb- isci -rrb- .
Head Entity: badr organisation
Tail Entity: supreme islamic iraqi council
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization parents":
Relation: organization parents  
Context: The tech giant Alphabet Inc. has been making headlines with its innovative projects, but many are unaware that it is a subsidiary of the much larger Google LLC, which has been a leader in the tech industry for over two decades.  
Head Entity: Alphabet Inc.  
Tail Entity: Google LLC  

Relation: organization parents  
Context: In the world of finance, JPMorgan Chase & Co. has a long history, but it is important to note that it operates under the umbrella of the larger holding company, JPMorgan Chase & Co., which was formed through the merger of several financial institutions.  
Head Entity: JPMorgan Chase & Co.  
Tail Entity: JPMorgan Chase & Co.  

Relation: organization parents  
Context: The popular social media platform Instagram was acquired by Facebook Inc. in 2012, and since then, it has grown significantly under the guidance of its parent company, which has expanded its reach across various digital platforms.  
Head Entity: Instagram  
Tail Entity: Facebook Inc.  

Relation: organization parents  
Context: The renowned car manufacturer Tesla, Inc. has been making waves in the automotive industry, but it is a subsidiary of the larger conglomerate, Tesla, Inc., which has diversified into various sectors including energy and technology.  
Head Entity: Tesla, Inc.  
Tail Entity: Tesla, Inc.  

Relation: organization parents  
Context: The fast-food chain Burger King is known for its flame-grilled burgers, but it operates as a subsidiary of Restaurant Brands International, which also owns other popular food brands like Tim Hortons and Popeyes.  
Head Entity: Burger King  
Tail Entity: Restaurant Brands International  
#### organization alternate names ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization alternate names" means a person 's alias is a person.
Here is an example:
Relation: organization alternate names
Context: the national security council -lrb- nsc -rrb- made the demand at talks chaired by president hamid karzai , who has been vocal in condemning international forces he believes are responsible for the incident last saturday in the eastern flashpoint of kunar .
Head Entity: national security council
Tail Entity: nsc
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization alternate names":
Relation: organization alternate names  
Context: the world health organization -lrb- who -rrb- has been instrumental in coordinating global health responses during pandemics.  
Head Entity: world health organization  
Tail Entity: who  

Relation: organization alternate names  
Context: the federal bureau of investigation -lrb- fbi -rrb- is known for its role in investigating federal crimes in the United States.  
Head Entity: federal bureau of investigation  
Tail Entity: fbi  

Relation: organization alternate names  
Context: the international monetary fund -lrb- imf -rrb- provides financial assistance and advice to member countries.  
Head Entity: international monetary fund  
Tail Entity: imf  

Relation: organization alternate names  
Context: the national aeronautics and space administration -lrb- nasa -rrb- is responsible for the nation's civilian space program and for aeronautics and aerospace research.  
Head Entity: national aeronautics and space administration  
Tail Entity: nasa  

Relation: organization alternate names  
Context: the united nations educational, scientific and cultural organization -lrb- unesco -rrb- aims to promote world peace and security through international cooperation in education, the sciences, and culture.  
Head Entity: united nations educational, scientific and cultural organization  
Tail Entity: unesco  
#### organization city of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization city of headquarters" means an organization is located in a city.
Here is an example:
Relation: organization city of headquarters
Context: guy-sheftall entered spelman college in atlanta at age 16 and later earned a master 's in english with a thesis titled `` faulkner 's treatment of women in his major novels . ''
Head Entity: spelman college
Tail Entity: atlanta
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization city of headquarters":
Relation: organization city of headquarters  
Context: the headquarters of the tech giant apple inc. is located in cupertino, california, where it has been since 1993.  
Head Entity: apple inc.  
Tail Entity: cupertino  

Relation: organization city of headquarters  
Context: the united nations has its main headquarters in new york city, which serves as a hub for international diplomacy.  
Head Entity: united nations  
Tail Entity: new york city  

Relation: organization city of headquarters  
Context: the famous car manufacturer ford motor company is headquartered in dearborn, michigan, a city known for its automotive history.  
Head Entity: ford motor company  
Tail Entity: dearborn  

Relation: organization city of headquarters  
Context: google's parent company, alphabet inc., has its headquarters in mountain view, california, in the heart of silicon valley.  
Head Entity: alphabet inc.  
Tail Entity: mountain view  

Relation: organization city of headquarters  
Context: the multinational corporation samsung electronics is headquartered in suwon, south korea, where it was founded in 1969.  
Head Entity: samsung electronics  
Tail Entity: suwon  
#### person siblings ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person siblings" means a person 's sibling is a person.
Here is an example:
Relation: person siblings
Context: forsberg , a political science professor at city college of new york , died oct. 19 in a bronx hospital of cancer , said her sister , celia seupel .
Head Entity: forsberg
Tail Entity: celia seupel
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person siblings":
Relation: person siblings  
Context: During the family reunion, John introduced his sister, Emily, who had just returned from studying abroad.  
Head Entity: John  
Tail Entity: Emily  

Relation: person siblings  
Context: After the game, Sarah celebrated her victory with her brother, Michael, who had been her biggest supporter throughout the season.  
Head Entity: Sarah  
Tail Entity: Michael  

Relation: person siblings  
Context: In her memoir, Lisa writes fondly about her childhood adventures with her brother, Tom, who always had a knack for getting into trouble.  
Head Entity: Lisa  
Tail Entity: Tom  

Relation: person siblings  
Context: At the wedding, Anna was thrilled to see her brother, David, who had flown in from another state to be her best man.  
Head Entity: Anna  
Tail Entity: David  

Relation: person siblings  
Context: The documentary featured interviews with various family members, including Rachel's sister, Jessica, who shared their experiences growing up together.  
Head Entity: Rachel  
Tail Entity: Jessica  
Mixup data size:  15700
MixupTrain:  epoch  0, batch     0 | loss: 5.0084553MixupTrain:  epoch  0, batch     1 | loss: 3.7908497MixupTrain:  epoch  0, batch     2 | loss: 3.5584497MixupTrain:  epoch  0, batch     3 | loss: 3.8162708MixupTrain:  epoch  0, batch     4 | loss: 3.7760644MixupTrain:  epoch  0, batch     5 | loss: 2.9991455MixupTrain:  epoch  0, batch     6 | loss: 3.5342913MixupTrain:  epoch  0, batch     7 | loss: 4.4058280MixupTrain:  epoch  0, batch     8 | loss: 3.4069979MixupTrain:  epoch  0, batch     9 | loss: 4.2771215MixupTrain:  epoch  0, batch    10 | loss: 3.4405618MixupTrain:  epoch  0, batch    11 | loss: 4.2831545MixupTrain:  epoch  0, batch    12 | loss: 3.8602698MixupTrain:  epoch  0, batch    13 | loss: 4.3724360MixupTrain:  epoch  0, batch    14 | loss: 3.4207239MixupTrain:  epoch  0, batch    15 | loss: 4.5840330MixupTrain:  epoch  0, batch    16 | loss: 3.8433340MixupTrain:  epoch  0, batch    17 | loss: 3.1314507MixupTrain:  epoch  0, batch    18 | loss: 3.0509703MixupTrain:  epoch  0, batch    19 | loss: 3.6043503MixupTrain:  epoch  0, batch    20 | loss: 3.9575529MixupTrain:  epoch  0, batch    21 | loss: 3.2099972MixupTrain:  epoch  0, batch    22 | loss: 2.5417109MixupTrain:  epoch  0, batch    23 | loss: 2.6869187MixupTrain:  epoch  0, batch    24 | loss: 3.2433851MixupTrain:  epoch  0, batch    25 | loss: 3.0872407MixupTrain:  epoch  0, batch    26 | loss: 2.6281452MixupTrain:  epoch  0, batch    27 | loss: 3.9516962MixupTrain:  epoch  0, batch    28 | loss: 3.0486495MixupTrain:  epoch  0, batch    29 | loss: 3.5742946MixupTrain:  epoch  0, batch    30 | loss: 2.8882837MixupTrain:  epoch  0, batch    31 | loss: 2.5259495MixupTrain:  epoch  0, batch    32 | loss: 3.7306256MixupTrain:  epoch  0, batch    33 | loss: 2.7753835MixupTrain:  epoch  0, batch    34 | loss: 3.7715249MixupTrain:  epoch  0, batch    35 | loss: 3.3379774MixupTrain:  epoch  0, batch    36 | loss: 3.4600332MixupTrain:  epoch  0, batch    37 | loss: 3.2317777MixupTrain:  epoch  0, batch    38 | loss: 2.9846392MixupTrain:  epoch  0, batch    39 | loss: 2.7105532MixupTrain:  epoch  0, batch    40 | loss: 3.2679212MixupTrain:  epoch  0, batch    41 | loss: 3.7535114MixupTrain:  epoch  0, batch    42 | loss: 2.6827769MixupTrain:  epoch  0, batch    43 | loss: 3.5498905MixupTrain:  epoch  0, batch    44 | loss: 3.5430098MixupTrain:  epoch  0, batch    45 | loss: 3.8387272MixupTrain:  epoch  0, batch    46 | loss: 3.9961183MixupTrain:  epoch  0, batch    47 | loss: 3.2163944MixupTrain:  epoch  0, batch    48 | loss: 2.9952703MixupTrain:  epoch  0, batch    49 | loss: 3.5993738MixupTrain:  epoch  0, batch    50 | loss: 3.8573861MixupTrain:  epoch  0, batch    51 | loss: 3.8157723MixupTrain:  epoch  0, batch    52 | loss: 3.7413344MixupTrain:  epoch  0, batch    53 | loss: 3.6062679MixupTrain:  epoch  0, batch    54 | loss: 2.6098914MixupTrain:  epoch  0, batch    55 | loss: 4.0741377MixupTrain:  epoch  0, batch    56 | loss: 2.7748804MixupTrain:  epoch  0, batch    57 | loss: 3.2969680MixupTrain:  epoch  0, batch    58 | loss: 2.9397209MixupTrain:  epoch  0, batch    59 | loss: 3.4780290MixupTrain:  epoch  0, batch    60 | loss: 3.5848336MixupTrain:  epoch  0, batch    61 | loss: 3.1758382MixupTrain:  epoch  0, batch    62 | loss: 2.8210688MixupTrain:  epoch  0, batch    63 | loss: 3.0972714MixupTrain:  epoch  0, batch    64 | loss: 3.2777460MixupTrain:  epoch  0, batch    65 | loss: 2.4926274MixupTrain:  epoch  0, batch    66 | loss: 3.5801134MixupTrain:  epoch  0, batch    67 | loss: 3.3921285MixupTrain:  epoch  0, batch    68 | loss: 3.2110136MixupTrain:  epoch  0, batch    69 | loss: 3.5023677MixupTrain:  epoch  0, batch    70 | loss: 3.6526880MixupTrain:  epoch  0, batch    71 | loss: 3.5024240MixupTrain:  epoch  0, batch    72 | loss: 2.7920322MixupTrain:  epoch  0, batch    73 | loss: 3.4583535MixupTrain:  epoch  0, batch    74 | loss: 3.0250037MixupTrain:  epoch  0, batch    75 | loss: 3.8254306MixupTrain:  epoch  0, batch    76 | loss: 2.2472658MixupTrain:  epoch  0, batch    77 | loss: 3.0823879MixupTrain:  epoch  0, batch    78 | loss: 3.5204883MixupTrain:  epoch  0, batch    79 | loss: 2.7797322MixupTrain:  epoch  0, batch    80 | loss: 3.5840054MixupTrain:  epoch  0, batch    81 | loss: 2.8977461MixupTrain:  epoch  0, batch    82 | loss: 2.5039811MixupTrain:  epoch  0, batch    83 | loss: 3.0465345MixupTrain:  epoch  0, batch    84 | loss: 2.8500090MixupTrain:  epoch  0, batch    85 | loss: 2.8613641MixupTrain:  epoch  0, batch    86 | loss: 3.2674251MixupTrain:  epoch  0, batch    87 | loss: 2.8676667MixupTrain:  epoch  0, batch    88 | loss: 2.4943185MixupTrain:  epoch  0, batch    89 | loss: 2.7334614MixupTrain:  epoch  0, batch    90 | loss: 2.6158743MixupTrain:  epoch  0, batch    91 | loss: 3.2713761MixupTrain:  epoch  0, batch    92 | loss: 3.2969232MixupTrain:  epoch  0, batch    93 | loss: 2.7576284MixupTrain:  epoch  0, batch    94 | loss: 2.5637424MixupTrain:  epoch  0, batch    95 | loss: 2.9270182MixupTrain:  epoch  0, batch    96 | loss: 2.6769595MixupTrain:  epoch  0, batch    97 | loss: 3.5025928MixupTrain:  epoch  0, batch    98 | loss: 3.3551216MixupTrain:  epoch  0, batch    99 | loss: 2.5268579MixupTrain:  epoch  0, batch   100 | loss: 2.6162825MixupTrain:  epoch  0, batch   101 | loss: 2.8902307MixupTrain:  epoch  0, batch   102 | loss: 3.3309340MixupTrain:  epoch  0, batch   103 | loss: 2.8301835MixupTrain:  epoch  0, batch   104 | loss: 4.0048952MixupTrain:  epoch  0, batch   105 | loss: 3.0567985MixupTrain:  epoch  0, batch   106 | loss: 3.4825561MixupTrain:  epoch  0, batch   107 | loss: 3.1396863MixupTrain:  epoch  0, batch   108 | loss: 2.9042950MixupTrain:  epoch  0, batch   109 | loss: 2.9400554MixupTrain:  epoch  0, batch   110 | loss: 3.1909170MixupTrain:  epoch  0, batch   111 | loss: 2.7513723MixupTrain:  epoch  0, batch   112 | loss: 3.3577905MixupTrain:  epoch  0, batch   113 | loss: 2.5013423MixupTrain:  epoch  0, batch   114 | loss: 2.6853244MixupTrain:  epoch  0, batch   115 | loss: 3.1854835MixupTrain:  epoch  0, batch   116 | loss: 2.6770830MixupTrain:  epoch  0, batch   117 | loss: 2.8801386MixupTrain:  epoch  0, batch   118 | loss: 2.9199605MixupTrain:  epoch  0, batch   119 | loss: 3.0824282MixupTrain:  epoch  0, batch   120 | loss: 2.6406128MixupTrain:  epoch  0, batch   121 | loss: 2.8577721MixupTrain:  epoch  0, batch   122 | loss: 2.8555951MixupTrain:  epoch  0, batch   123 | loss: 2.9099526MixupTrain:  epoch  0, batch   124 | loss: 3.1139336MixupTrain:  epoch  0, batch   125 | loss: 3.0804648MixupTrain:  epoch  0, batch   126 | loss: 2.6517453MixupTrain:  epoch  0, batch   127 | loss: 2.2168460MixupTrain:  epoch  0, batch   128 | loss: 3.1664984MixupTrain:  epoch  0, batch   129 | loss: 3.6581354MixupTrain:  epoch  0, batch   130 | loss: 2.4505095MixupTrain:  epoch  0, batch   131 | loss: 3.4125433MixupTrain:  epoch  0, batch   132 | loss: 2.8326783MixupTrain:  epoch  0, batch   133 | loss: 3.1141286MixupTrain:  epoch  0, batch   134 | loss: 2.9763188MixupTrain:  epoch  0, batch   135 | loss: 2.6782777MixupTrain:  epoch  0, batch   136 | loss: 2.5561805MixupTrain:  epoch  0, batch   137 | loss: 2.2971990MixupTrain:  epoch  0, batch   138 | loss: 2.5041480MixupTrain:  epoch  0, batch   139 | loss: 2.7160275MixupTrain:  epoch  0, batch   140 | loss: 3.1127386MixupTrain:  epoch  0, batch   141 | loss: 2.9017315MixupTrain:  epoch  0, batch   142 | loss: 2.2729244MixupTrain:  epoch  0, batch   143 | loss: 2.4293656MixupTrain:  epoch  0, batch   144 | loss: 2.6768179MixupTrain:  epoch  0, batch   145 | loss: 2.5431840MixupTrain:  epoch  0, batch   146 | loss: 3.1070275MixupTrain:  epoch  0, batch   147 | loss: 2.7497156MixupTrain:  epoch  0, batch   148 | loss: 3.1451926MixupTrain:  epoch  0, batch   149 | loss: 2.7215285MixupTrain:  epoch  0, batch   150 | loss: 2.5929327MixupTrain:  epoch  0, batch   151 | loss: 2.6123874MixupTrain:  epoch  0, batch   152 | loss: 2.7395086MixupTrain:  epoch  0, batch   153 | loss: 2.8016832MixupTrain:  epoch  0, batch   154 | loss: 3.5454698MixupTrain:  epoch  0, batch   155 | loss: 2.9273524MixupTrain:  epoch  0, batch   156 | loss: 2.7645910MixupTrain:  epoch  0, batch   157 | loss: 3.1181788MixupTrain:  epoch  0, batch   158 | loss: 2.7809114MixupTrain:  epoch  0, batch   159 | loss: 2.9835386MixupTrain:  epoch  0, batch   160 | loss: 2.6139083MixupTrain:  epoch  0, batch   161 | loss: 2.2898207MixupTrain:  epoch  0, batch   162 | loss: 2.8316329MixupTrain:  epoch  0, batch   163 | loss: 2.4328051MixupTrain:  epoch  0, batch   164 | loss: 2.8348749MixupTrain:  epoch  0, batch   165 | loss: 3.0263214MixupTrain:  epoch  0, batch   166 | loss: 3.3028626MixupTrain:  epoch  0, batch   167 | loss: 3.1082449MixupTrain:  epoch  0, batch   168 | loss: 2.4043140MixupTrain:  epoch  0, batch   169 | loss: 2.5995364MixupTrain:  epoch  0, batch   170 | loss: 2.6149671MixupTrain:  epoch  0, batch   171 | loss: 2.5658135MixupTrain:  epoch  0, batch   172 | loss: 2.4933496MixupTrain:  epoch  0, batch   173 | loss: 3.0590651MixupTrain:  epoch  0, batch   174 | loss: 2.8502765MixupTrain:  epoch  0, batch   175 | loss: 2.9941907MixupTrain:  epoch  0, batch   176 | loss: 2.6413798MixupTrain:  epoch  0, batch   177 | loss: 2.1226015MixupTrain:  epoch  0, batch   178 | loss: 2.6804199MixupTrain:  epoch  0, batch   179 | loss: 2.7185807MixupTrain:  epoch  0, batch   180 | loss: 2.6980276MixupTrain:  epoch  0, batch   181 | loss: 2.5435410MixupTrain:  epoch  0, batch   182 | loss: 2.5789382MixupTrain:  epoch  0, batch   183 | loss: 2.3103504MixupTrain:  epoch  0, batch   184 | loss: 2.6807702MixupTrain:  epoch  0, batch   185 | loss: 2.4170485MixupTrain:  epoch  0, batch   186 | loss: 2.5432081MixupTrain:  epoch  0, batch   187 | loss: 2.6968722MixupTrain:  epoch  0, batch   188 | loss: 2.7702680MixupTrain:  epoch  0, batch   189 | loss: 2.6352665MixupTrain:  epoch  0, batch   190 | loss: 2.5310044MixupTrain:  epoch  0, batch   191 | loss: 2.6637712MixupTrain:  epoch  0, batch   192 | loss: 2.3456192MixupTrain:  epoch  0, batch   193 | loss: 2.3612173MixupTrain:  epoch  0, batch   194 | loss: 2.4624305MixupTrain:  epoch  0, batch   195 | loss: 2.5960574MixupTrain:  epoch  0, batch   196 | loss: 2.4244378MixupTrain:  epoch  0, batch   197 | loss: 2.4471755MixupTrain:  epoch  0, batch   198 | loss: 2.3722680MixupTrain:  epoch  0, batch   199 | loss: 2.7724967MixupTrain:  epoch  0, batch   200 | loss: 2.6556716MixupTrain:  epoch  0, batch   201 | loss: 2.5687494MixupTrain:  epoch  0, batch   202 | loss: 2.3227427MixupTrain:  epoch  0, batch   203 | loss: 2.7226663MixupTrain:  epoch  0, batch   204 | loss: 2.6087193MixupTrain:  epoch  0, batch   205 | loss: 2.6374886MixupTrain:  epoch  0, batch   206 | loss: 3.1931899MixupTrain:  epoch  0, batch   207 | loss: 2.5629046MixupTrain:  epoch  0, batch   208 | loss: 2.3597162MixupTrain:  epoch  0, batch   209 | loss: 2.3299284MixupTrain:  epoch  0, batch   210 | loss: 2.8152690MixupTrain:  epoch  0, batch   211 | loss: 2.9162226MixupTrain:  epoch  0, batch   212 | loss: 2.3296175MixupTrain:  epoch  0, batch   213 | loss: 2.1766200MixupTrain:  epoch  0, batch   214 | loss: 3.0055847MixupTrain:  epoch  0, batch   215 | loss: 2.4123716MixupTrain:  epoch  0, batch   216 | loss: 2.5375016MixupTrain:  epoch  0, batch   217 | loss: 2.5444658MixupTrain:  epoch  0, batch   218 | loss: 2.3955824MixupTrain:  epoch  0, batch   219 | loss: 2.8449361MixupTrain:  epoch  0, batch   220 | loss: 2.5459847MixupTrain:  epoch  0, batch   221 | loss: 2.5722520MixupTrain:  epoch  0, batch   222 | loss: 2.3956995MixupTrain:  epoch  0, batch   223 | loss: 3.0526996MixupTrain:  epoch  0, batch   224 | loss: 2.7040987MixupTrain:  epoch  0, batch   225 | loss: 2.7502027MixupTrain:  epoch  0, batch   226 | loss: 2.3851845MixupTrain:  epoch  0, batch   227 | loss: 2.5894423MixupTrain:  epoch  0, batch   228 | loss: 2.0396008MixupTrain:  epoch  0, batch   229 | loss: 2.7945459MixupTrain:  epoch  0, batch   230 | loss: 3.2704072MixupTrain:  epoch  0, batch   231 | loss: 2.9037962MixupTrain:  epoch  0, batch   232 | loss: 2.6089876MixupTrain:  epoch  0, batch   233 | loss: 2.6212368MixupTrain:  epoch  0, batch   234 | loss: 2.5191033MixupTrain:  epoch  0, batch   235 | loss: 2.6814597MixupTrain:  epoch  0, batch   236 | loss: 2.5208406MixupTrain:  epoch  0, batch   237 | loss: 2.2577736MixupTrain:  epoch  0, batch   238 | loss: 2.8473420MixupTrain:  epoch  0, batch   239 | loss: 2.6122003MixupTrain:  epoch  0, batch   240 | loss: 2.2169766MixupTrain:  epoch  0, batch   241 | loss: 2.6547005MixupTrain:  epoch  0, batch   242 | loss: 2.4285290MixupTrain:  epoch  0, batch   243 | loss: 2.4890814MixupTrain:  epoch  0, batch   244 | loss: 2.2989879MixupTrain:  epoch  0, batch   245 | loss: 2.3020658MixupTrain:  epoch  0, batch   246 | loss: 2.6804318MixupTrain:  epoch  0, batch   247 | loss: 2.4985664MixupTrain:  epoch  0, batch   248 | loss: 2.4968734MixupTrain:  epoch  0, batch   249 | loss: 2.8274474MixupTrain:  epoch  0, batch   250 | loss: 2.4551907MixupTrain:  epoch  0, batch   251 | loss: 2.5426552MixupTrain:  epoch  0, batch   252 | loss: 2.2578449MixupTrain:  epoch  0, batch   253 | loss: 2.6976490MixupTrain:  epoch  0, batch   254 | loss: 2.7173750MixupTrain:  epoch  0, batch   255 | loss: 2.3649065MixupTrain:  epoch  0, batch   256 | loss: 2.2942686MixupTrain:  epoch  0, batch   257 | loss: 2.5685921MixupTrain:  epoch  0, batch   258 | loss: 2.4344857MixupTrain:  epoch  0, batch   259 | loss: 3.1946936MixupTrain:  epoch  0, batch   260 | loss: 2.6204424MixupTrain:  epoch  0, batch   261 | loss: 2.4414687MixupTrain:  epoch  0, batch   262 | loss: 2.6941562MixupTrain:  epoch  0, batch   263 | loss: 2.5634787MixupTrain:  epoch  0, batch   264 | loss: 2.2256784MixupTrain:  epoch  0, batch   265 | loss: 2.6807532MixupTrain:  epoch  0, batch   266 | loss: 2.5423408MixupTrain:  epoch  0, batch   267 | loss: 2.2258787MixupTrain:  epoch  0, batch   268 | loss: 2.8057432MixupTrain:  epoch  0, batch   269 | loss: 2.8766599MixupTrain:  epoch  0, batch   270 | loss: 2.9728804MixupTrain:  epoch  0, batch   271 | loss: 2.9415226MixupTrain:  epoch  0, batch   272 | loss: 2.5693984MixupTrain:  epoch  0, batch   273 | loss: 2.2059665MixupTrain:  epoch  0, batch   274 | loss: 3.1665854MixupTrain:  epoch  0, batch   275 | loss: 2.8432279MixupTrain:  epoch  0, batch   276 | loss: 2.2511063MixupTrain:  epoch  0, batch   277 | loss: 2.4175992MixupTrain:  epoch  0, batch   278 | loss: 2.3188066MixupTrain:  epoch  0, batch   279 | loss: 2.4046021MixupTrain:  epoch  0, batch   280 | loss: 2.4562807MixupTrain:  epoch  0, batch   281 | loss: 2.6789699MixupTrain:  epoch  0, batch   282 | loss: 2.3354883MixupTrain:  epoch  0, batch   283 | loss: 2.7268398MixupTrain:  epoch  0, batch   284 | loss: 2.3884785MixupTrain:  epoch  0, batch   285 | loss: 2.5886345MixupTrain:  epoch  0, batch   286 | loss: 2.7242546MixupTrain:  epoch  0, batch   287 | loss: 3.2370610MixupTrain:  epoch  0, batch   288 | loss: 2.4870014MixupTrain:  epoch  0, batch   289 | loss: 2.9627697MixupTrain:  epoch  0, batch   290 | loss: 2.7996187MixupTrain:  epoch  0, batch   291 | loss: 2.4883120MixupTrain:  epoch  0, batch   292 | loss: 2.8244004MixupTrain:  epoch  0, batch   293 | loss: 2.7018819MixupTrain:  epoch  0, batch   294 | loss: 2.2694879MixupTrain:  epoch  0, batch   295 | loss: 2.6867104MixupTrain:  epoch  0, batch   296 | loss: 2.7900386MixupTrain:  epoch  0, batch   297 | loss: 2.3488040MixupTrain:  epoch  0, batch   298 | loss: 2.5941949MixupTrain:  epoch  0, batch   299 | loss: 2.6849804MixupTrain:  epoch  0, batch   300 | loss: 2.5589263MixupTrain:  epoch  0, batch   301 | loss: 2.7321622MixupTrain:  epoch  0, batch   302 | loss: 2.2768538MixupTrain:  epoch  0, batch   303 | loss: 2.0951498MixupTrain:  epoch  0, batch   304 | loss: 2.3379207MixupTrain:  epoch  0, batch   305 | loss: 2.6063375MixupTrain:  epoch  0, batch   306 | loss: 2.3838725MixupTrain:  epoch  0, batch   307 | loss: 2.5878096MixupTrain:  epoch  0, batch   308 | loss: 2.6972051MixupTrain:  epoch  0, batch   309 | loss: 2.4764872MixupTrain:  epoch  0, batch   310 | loss: 2.5889921MixupTrain:  epoch  0, batch   311 | loss: 2.5738006MixupTrain:  epoch  0, batch   312 | loss: 2.5394816MixupTrain:  epoch  0, batch   313 | loss: 2.5592966MixupTrain:  epoch  0, batch   314 | loss: 2.9168715MixupTrain:  epoch  0, batch   315 | loss: 2.5507424MixupTrain:  epoch  0, batch   316 | loss: 2.3210840MixupTrain:  epoch  0, batch   317 | loss: 2.6640100MixupTrain:  epoch  0, batch   318 | loss: 2.6656671MixupTrain:  epoch  0, batch   319 | loss: 2.3198509MixupTrain:  epoch  0, batch   320 | loss: 2.4670548MixupTrain:  epoch  0, batch   321 | loss: 2.8249779MixupTrain:  epoch  0, batch   322 | loss: 2.4966955MixupTrain:  epoch  0, batch   323 | loss: 2.1209433MixupTrain:  epoch  0, batch   324 | loss: 2.3729026MixupTrain:  epoch  0, batch   325 | loss: 2.2823071MixupTrain:  epoch  0, batch   326 | loss: 2.8353324MixupTrain:  epoch  0, batch   327 | loss: 2.8275442MixupTrain:  epoch  0, batch   328 | loss: 2.6264133MixupTrain:  epoch  0, batch   329 | loss: 2.7201078MixupTrain:  epoch  0, batch   330 | loss: 2.5639458MixupTrain:  epoch  0, batch   331 | loss: 2.7374835MixupTrain:  epoch  0, batch   332 | loss: 2.7899389MixupTrain:  epoch  0, batch   333 | loss: 2.6799746MixupTrain:  epoch  0, batch   334 | loss: 2.5936103MixupTrain:  epoch  0, batch   335 | loss: 2.3489642MixupTrain:  epoch  0, batch   336 | loss: 2.7167110MixupTrain:  epoch  0, batch   337 | loss: 2.6121731MixupTrain:  epoch  0, batch   338 | loss: 2.3377407MixupTrain:  epoch  0, batch   339 | loss: 2.9124129MixupTrain:  epoch  0, batch   340 | loss: 2.6428339MixupTrain:  epoch  0, batch   341 | loss: 2.4836316MixupTrain:  epoch  0, batch   342 | loss: 2.6295409MixupTrain:  epoch  0, batch   343 | loss: 2.3531322MixupTrain:  epoch  0, batch   344 | loss: 2.6907187MixupTrain:  epoch  0, batch   345 | loss: 2.9291797MixupTrain:  epoch  0, batch   346 | loss: 2.2821879MixupTrain:  epoch  0, batch   347 | loss: 2.3680527MixupTrain:  epoch  0, batch   348 | loss: 2.3462296MixupTrain:  epoch  0, batch   349 | loss: 2.6605606MixupTrain:  epoch  0, batch   350 | loss: 2.7140484MixupTrain:  epoch  0, batch   351 | loss: 2.6697130MixupTrain:  epoch  0, batch   352 | loss: 2.3863683MixupTrain:  epoch  0, batch   353 | loss: 2.4572897MixupTrain:  epoch  0, batch   354 | loss: 2.6596918MixupTrain:  epoch  0, batch   355 | loss: 2.5825615MixupTrain:  epoch  0, batch   356 | loss: 2.3199832MixupTrain:  epoch  0, batch   357 | loss: 2.4614749MixupTrain:  epoch  0, batch   358 | loss: 2.5919375MixupTrain:  epoch  0, batch   359 | loss: 2.3628640MixupTrain:  epoch  0, batch   360 | loss: 2.9445977MixupTrain:  epoch  0, batch   361 | loss: 2.9701138MixupTrain:  epoch  0, batch   362 | loss: 1.9018327MixupTrain:  epoch  0, batch   363 | loss: 2.4847231MixupTrain:  epoch  0, batch   364 | loss: 2.8447657MixupTrain:  epoch  0, batch   365 | loss: 2.7453046MixupTrain:  epoch  0, batch   366 | loss: 2.4318492MixupTrain:  epoch  0, batch   367 | loss: 2.5220914MixupTrain:  epoch  0, batch   368 | loss: 2.6590865MixupTrain:  epoch  0, batch   369 | loss: 2.6781311MixupTrain:  epoch  0, batch   370 | loss: 2.7222581MixupTrain:  epoch  0, batch   371 | loss: 2.5198507MixupTrain:  epoch  0, batch   372 | loss: 2.4156020MixupTrain:  epoch  0, batch   373 | loss: 2.4493194MixupTrain:  epoch  0, batch   374 | loss: 2.7052593MixupTrain:  epoch  0, batch   375 | loss: 2.5148807MixupTrain:  epoch  0, batch   376 | loss: 2.7655597MixupTrain:  epoch  0, batch   377 | loss: 2.5329022MixupTrain:  epoch  0, batch   378 | loss: 2.7088928MixupTrain:  epoch  0, batch   379 | loss: 2.4037895MixupTrain:  epoch  0, batch   380 | loss: 2.3938167MixupTrain:  epoch  0, batch   381 | loss: 2.5253854MixupTrain:  epoch  0, batch   382 | loss: 2.6317887MixupTrain:  epoch  0, batch   383 | loss: 2.4799271MixupTrain:  epoch  0, batch   384 | loss: 2.7895265MixupTrain:  epoch  0, batch   385 | loss: 2.5327220MixupTrain:  epoch  0, batch   386 | loss: 2.6561551MixupTrain:  epoch  0, batch   387 | loss: 2.7716641MixupTrain:  epoch  0, batch   388 | loss: 2.4052658MixupTrain:  epoch  0, batch   389 | loss: 2.0589948MixupTrain:  epoch  0, batch   390 | loss: 2.7993994MixupTrain:  epoch  0, batch   391 | loss: 2.3061569MixupTrain:  epoch  0, batch   392 | loss: 2.9166584MixupTrain:  epoch  0, batch   393 | loss: 2.2613993MixupTrain:  epoch  0, batch   394 | loss: 2.3897467MixupTrain:  epoch  0, batch   395 | loss: 2.6086082MixupTrain:  epoch  0, batch   396 | loss: 2.3528547MixupTrain:  epoch  0, batch   397 | loss: 2.1668959MixupTrain:  epoch  0, batch   398 | loss: 2.9352303MixupTrain:  epoch  0, batch   399 | loss: 2.1720543MixupTrain:  epoch  0, batch   400 | loss: 2.1574035MixupTrain:  epoch  0, batch   401 | loss: 2.4782324MixupTrain:  epoch  0, batch   402 | loss: 2.5603037MixupTrain:  epoch  0, batch   403 | loss: 2.0908675MixupTrain:  epoch  0, batch   404 | loss: 2.4553895MixupTrain:  epoch  0, batch   405 | loss: 2.8085928MixupTrain:  epoch  0, batch   406 | loss: 2.4317176MixupTrain:  epoch  0, batch   407 | loss: 2.8081355MixupTrain:  epoch  0, batch   408 | loss: 2.1752906MixupTrain:  epoch  0, batch   409 | loss: 2.6191046MixupTrain:  epoch  0, batch   410 | loss: 2.4712408MixupTrain:  epoch  0, batch   411 | loss: 2.4346569MixupTrain:  epoch  0, batch   412 | loss: 2.1346521MixupTrain:  epoch  0, batch   413 | loss: 2.1519444MixupTrain:  epoch  0, batch   414 | loss: 2.8615797MixupTrain:  epoch  0, batch   415 | loss: 2.5980496MixupTrain:  epoch  0, batch   416 | loss: 2.4153221MixupTrain:  epoch  0, batch   417 | loss: 2.4202704MixupTrain:  epoch  0, batch   418 | loss: 2.6506045MixupTrain:  epoch  0, batch   419 | loss: 2.5620255MixupTrain:  epoch  0, batch   420 | loss: 2.3360441MixupTrain:  epoch  0, batch   421 | loss: 2.6196916MixupTrain:  epoch  0, batch   422 | loss: 2.8577509MixupTrain:  epoch  0, batch   423 | loss: 2.5972672MixupTrain:  epoch  0, batch   424 | loss: 2.2786202MixupTrain:  epoch  0, batch   425 | loss: 2.4142728MixupTrain:  epoch  0, batch   426 | loss: 2.7248611MixupTrain:  epoch  0, batch   427 | loss: 2.5890419MixupTrain:  epoch  0, batch   428 | loss: 2.0331931MixupTrain:  epoch  0, batch   429 | loss: 2.4694254MixupTrain:  epoch  0, batch   430 | loss: 2.3123920MixupTrain:  epoch  0, batch   431 | loss: 2.2277145MixupTrain:  epoch  0, batch   432 | loss: 2.2308674MixupTrain:  epoch  0, batch   433 | loss: 2.9709888MixupTrain:  epoch  0, batch   434 | loss: 2.4441118MixupTrain:  epoch  0, batch   435 | loss: 2.3038511MixupTrain:  epoch  0, batch   436 | loss: 2.5695639MixupTrain:  epoch  0, batch   437 | loss: 2.2235630MixupTrain:  epoch  0, batch   438 | loss: 2.4315591MixupTrain:  epoch  0, batch   439 | loss: 2.3720088MixupTrain:  epoch  0, batch   440 | loss: 2.4627392MixupTrain:  epoch  0, batch   441 | loss: 2.3611956MixupTrain:  epoch  0, batch   442 | loss: 2.3324804MixupTrain:  epoch  0, batch   443 | loss: 2.7664709MixupTrain:  epoch  0, batch   444 | loss: 3.0157180MixupTrain:  epoch  0, batch   445 | loss: 2.1471982MixupTrain:  epoch  0, batch   446 | loss: 2.4520960MixupTrain:  epoch  0, batch   447 | loss: 2.0645485MixupTrain:  epoch  0, batch   448 | loss: 2.2559748MixupTrain:  epoch  0, batch   449 | loss: 2.5793986MixupTrain:  epoch  0, batch   450 | loss: 2.8630409MixupTrain:  epoch  0, batch   451 | loss: 2.1838980MixupTrain:  epoch  0, batch   452 | loss: 2.2119422MixupTrain:  epoch  0, batch   453 | loss: 2.4820037MixupTrain:  epoch  0, batch   454 | loss: 2.4180377MixupTrain:  epoch  0, batch   455 | loss: 2.6136761MixupTrain:  epoch  0, batch   456 | loss: 2.7715082MixupTrain:  epoch  0, batch   457 | loss: 2.3980207MixupTrain:  epoch  0, batch   458 | loss: 2.7767768MixupTrain:  epoch  0, batch   459 | loss: 2.5239537MixupTrain:  epoch  0, batch   460 | loss: 3.1121111MixupTrain:  epoch  0, batch   461 | loss: 2.5212114MixupTrain:  epoch  0, batch   462 | loss: 2.3797755MixupTrain:  epoch  0, batch   463 | loss: 2.2786288MixupTrain:  epoch  0, batch   464 | loss: 2.6426969MixupTrain:  epoch  0, batch   465 | loss: 2.8059194MixupTrain:  epoch  0, batch   466 | loss: 2.2346303MixupTrain:  epoch  0, batch   467 | loss: 2.3195105MixupTrain:  epoch  0, batch   468 | loss: 2.1273904MixupTrain:  epoch  0, batch   469 | loss: 2.6080458MixupTrain:  epoch  0, batch   470 | loss: 2.3819308MixupTrain:  epoch  0, batch   471 | loss: 2.5558696MixupTrain:  epoch  0, batch   472 | loss: 2.4152825MixupTrain:  epoch  0, batch   473 | loss: 2.3007784MixupTrain:  epoch  0, batch   474 | loss: 2.6384523MixupTrain:  epoch  0, batch   475 | loss: 2.1451256MixupTrain:  epoch  0, batch   476 | loss: 2.7183168MixupTrain:  epoch  0, batch   477 | loss: 2.1093729MixupTrain:  epoch  0, batch   478 | loss: 2.1294165MixupTrain:  epoch  0, batch   479 | loss: 2.4687514MixupTrain:  epoch  0, batch   480 | loss: 2.4222479MixupTrain:  epoch  0, batch   481 | loss: 2.4462566MixupTrain:  epoch  0, batch   482 | loss: 2.6270404MixupTrain:  epoch  0, batch   483 | loss: 2.6268678MixupTrain:  epoch  0, batch   484 | loss: 2.5399179MixupTrain:  epoch  0, batch   485 | loss: 2.3660076MixupTrain:  epoch  0, batch   486 | loss: 2.4831617MixupTrain:  epoch  0, batch   487 | loss: 2.5320137MixupTrain:  epoch  0, batch   488 | loss: 1.9796181MixupTrain:  epoch  0, batch   489 | loss: 2.3576465MixupTrain:  epoch  0, batch   490 | loss: 2.9227960MixupTrain:  epoch  0, batch   491 | loss: 2.5671539MixupTrain:  epoch  0, batch   492 | loss: 2.7809739MixupTrain:  epoch  0, batch   493 | loss: 2.4987383MixupTrain:  epoch  0, batch   494 | loss: 2.5106647MixupTrain:  epoch  0, batch   495 | loss: 2.4730661MixupTrain:  epoch  0, batch   496 | loss: 2.5165265MixupTrain:  epoch  0, batch   497 | loss: 2.4590702MixupTrain:  epoch  0, batch   498 | loss: 2.4667964MixupTrain:  epoch  0, batch   499 | loss: 2.2252345MixupTrain:  epoch  0, batch   500 | loss: 2.8084002MixupTrain:  epoch  0, batch   501 | loss: 2.4052291MixupTrain:  epoch  0, batch   502 | loss: 2.4208798MixupTrain:  epoch  0, batch   503 | loss: 2.7662067MixupTrain:  epoch  0, batch   504 | loss: 2.2237077MixupTrain:  epoch  0, batch   505 | loss: 2.5856953MixupTrain:  epoch  0, batch   506 | loss: 2.2923658MixupTrain:  epoch  0, batch   507 | loss: 2.2581129MixupTrain:  epoch  0, batch   508 | loss: 2.5349984MixupTrain:  epoch  0, batch   509 | loss: 2.4548588MixupTrain:  epoch  0, batch   510 | loss: 2.5077758MixupTrain:  epoch  0, batch   511 | loss: 2.1567736MixupTrain:  epoch  0, batch   512 | loss: 2.1427846MixupTrain:  epoch  0, batch   513 | loss: 2.5508115MixupTrain:  epoch  0, batch   514 | loss: 2.5607665MixupTrain:  epoch  0, batch   515 | loss: 2.1982775MixupTrain:  epoch  0, batch   516 | loss: 3.0590103MixupTrain:  epoch  0, batch   517 | loss: 2.1497312MixupTrain:  epoch  0, batch   518 | loss: 2.1848605MixupTrain:  epoch  0, batch   519 | loss: 2.6867423MixupTrain:  epoch  0, batch   520 | loss: 2.1546946MixupTrain:  epoch  0, batch   521 | loss: 2.0675571MixupTrain:  epoch  0, batch   522 | loss: 2.4508834MixupTrain:  epoch  0, batch   523 | loss: 2.4860353MixupTrain:  epoch  0, batch   524 | loss: 2.3298712MixupTrain:  epoch  0, batch   525 | loss: 2.4534769MixupTrain:  epoch  0, batch   526 | loss: 2.1797230MixupTrain:  epoch  0, batch   527 | loss: 2.5061979MixupTrain:  epoch  0, batch   528 | loss: 2.4192882MixupTrain:  epoch  0, batch   529 | loss: 2.6123061MixupTrain:  epoch  0, batch   530 | loss: 2.4615293MixupTrain:  epoch  0, batch   531 | loss: 2.5893917MixupTrain:  epoch  0, batch   532 | loss: 2.6109858MixupTrain:  epoch  0, batch   533 | loss: 2.4961205MixupTrain:  epoch  0, batch   534 | loss: 2.5404468MixupTrain:  epoch  0, batch   535 | loss: 2.6047900MixupTrain:  epoch  0, batch   536 | loss: 2.2963865MixupTrain:  epoch  0, batch   537 | loss: 2.8009839MixupTrain:  epoch  0, batch   538 | loss: 2.2082520MixupTrain:  epoch  0, batch   539 | loss: 2.6081438MixupTrain:  epoch  0, batch   540 | loss: 2.5363626MixupTrain:  epoch  0, batch   541 | loss: 2.4531317MixupTrain:  epoch  0, batch   542 | loss: 2.2661562MixupTrain:  epoch  0, batch   543 | loss: 2.9306965MixupTrain:  epoch  0, batch   544 | loss: 2.1252446MixupTrain:  epoch  0, batch   545 | loss: 2.4172750MixupTrain:  epoch  0, batch   546 | loss: 2.4370074MixupTrain:  epoch  0, batch   547 | loss: 2.6124396MixupTrain:  epoch  0, batch   548 | loss: 2.1592727MixupTrain:  epoch  0, batch   549 | loss: 2.3654428MixupTrain:  epoch  0, batch   550 | loss: 2.7921696MixupTrain:  epoch  0, batch   551 | loss: 2.4926224MixupTrain:  epoch  0, batch   552 | loss: 2.6088529MixupTrain:  epoch  0, batch   553 | loss: 2.6317480MixupTrain:  epoch  0, batch   554 | loss: 2.5635831MixupTrain:  epoch  0, batch   555 | loss: 2.3515568MixupTrain:  epoch  0, batch   556 | loss: 2.8105564MixupTrain:  epoch  0, batch   557 | loss: 2.5017529MixupTrain:  epoch  0, batch   558 | loss: 2.7339039MixupTrain:  epoch  0, batch   559 | loss: 2.5923529MixupTrain:  epoch  0, batch   560 | loss: 2.4393816MixupTrain:  epoch  0, batch   561 | loss: 2.6577973MixupTrain:  epoch  0, batch   562 | loss: 2.3907194MixupTrain:  epoch  0, batch   563 | loss: 2.6738615MixupTrain:  epoch  0, batch   564 | loss: 2.7842946MixupTrain:  epoch  0, batch   565 | loss: 2.4051943MixupTrain:  epoch  0, batch   566 | loss: 2.3988428MixupTrain:  epoch  0, batch   567 | loss: 2.4673047MixupTrain:  epoch  0, batch   568 | loss: 2.5327463MixupTrain:  epoch  0, batch   569 | loss: 2.4067986MixupTrain:  epoch  0, batch   570 | loss: 2.4322438MixupTrain:  epoch  0, batch   571 | loss: 2.3840389MixupTrain:  epoch  0, batch   572 | loss: 2.2994747MixupTrain:  epoch  0, batch   573 | loss: 2.2212341MixupTrain:  epoch  0, batch   574 | loss: 2.5080478MixupTrain:  epoch  0, batch   575 | loss: 2.1950433MixupTrain:  epoch  0, batch   576 | loss: 2.4519963MixupTrain:  epoch  0, batch   577 | loss: 2.5112305MixupTrain:  epoch  0, batch   578 | loss: 2.4537940MixupTrain:  epoch  0, batch   579 | loss: 2.1993902MixupTrain:  epoch  0, batch   580 | loss: 2.3612542MixupTrain:  epoch  0, batch   581 | loss: 2.5039818MixupTrain:  epoch  0, batch   582 | loss: 2.8066802MixupTrain:  epoch  0, batch   583 | loss: 2.3669019MixupTrain:  epoch  0, batch   584 | loss: 2.5492561MixupTrain:  epoch  0, batch   585 | loss: 2.2230816MixupTrain:  epoch  0, batch   586 | loss: 2.7770770MixupTrain:  epoch  0, batch   587 | loss: 2.1841722MixupTrain:  epoch  0, batch   588 | loss: 2.5050812MixupTrain:  epoch  0, batch   589 | loss: 2.1201334MixupTrain:  epoch  0, batch   590 | loss: 2.6586144MixupTrain:  epoch  0, batch   591 | loss: 2.4612048MixupTrain:  epoch  0, batch   592 | loss: 2.4842465MixupTrain:  epoch  0, batch   593 | loss: 2.3078485MixupTrain:  epoch  0, batch   594 | loss: 2.5247650MixupTrain:  epoch  0, batch   595 | loss: 2.4509783MixupTrain:  epoch  0, batch   596 | loss: 2.4169233MixupTrain:  epoch  0, batch   597 | loss: 2.1829028MixupTrain:  epoch  0, batch   598 | loss: 2.4504955MixupTrain:  epoch  0, batch   599 | loss: 2.7522035MixupTrain:  epoch  0, batch   600 | loss: 2.3496251MixupTrain:  epoch  0, batch   601 | loss: 2.8981380MixupTrain:  epoch  0, batch   602 | loss: 2.6902952MixupTrain:  epoch  0, batch   603 | loss: 2.2778950MixupTrain:  epoch  0, batch   604 | loss: 2.4638205MixupTrain:  epoch  0, batch   605 | loss: 2.6056294MixupTrain:  epoch  0, batch   606 | loss: 2.3962631MixupTrain:  epoch  0, batch   607 | loss: 2.3106704MixupTrain:  epoch  0, batch   608 | loss: 2.2569218MixupTrain:  epoch  0, batch   609 | loss: 2.4557717MixupTrain:  epoch  0, batch   610 | loss: 2.5106635MixupTrain:  epoch  0, batch   611 | loss: 2.2490473MixupTrain:  epoch  0, batch   612 | loss: 2.5957246MixupTrain:  epoch  0, batch   613 | loss: 2.3489223MixupTrain:  epoch  0, batch   614 | loss: 2.9048715MixupTrain:  epoch  0, batch   615 | loss: 2.3524137MixupTrain:  epoch  0, batch   616 | loss: 2.6137500MixupTrain:  epoch  0, batch   617 | loss: 2.3824725MixupTrain:  epoch  0, batch   618 | loss: 2.6668010MixupTrain:  epoch  0, batch   619 | loss: 2.5254750MixupTrain:  epoch  0, batch   620 | loss: 2.7607472MixupTrain:  epoch  0, batch   621 | loss: 2.1449702MixupTrain:  epoch  0, batch   622 | loss: 2.5341496MixupTrain:  epoch  0, batch   623 | loss: 2.3123865MixupTrain:  epoch  0, batch   624 | loss: 2.3517685MixupTrain:  epoch  0, batch   625 | loss: 2.5491886MixupTrain:  epoch  0, batch   626 | loss: 2.6829865MixupTrain:  epoch  0, batch   627 | loss: 2.3253579MixupTrain:  epoch  0, batch   628 | loss: 2.4742584MixupTrain:  epoch  0, batch   629 | loss: 2.6964486MixupTrain:  epoch  0, batch   630 | loss: 2.2891874MixupTrain:  epoch  0, batch   631 | loss: 2.0679219MixupTrain:  epoch  0, batch   632 | loss: 2.5823758MixupTrain:  epoch  0, batch   633 | loss: 2.4812171MixupTrain:  epoch  0, batch   634 | loss: 2.7336571MixupTrain:  epoch  0, batch   635 | loss: 2.7910562MixupTrain:  epoch  0, batch   636 | loss: 2.2052550MixupTrain:  epoch  0, batch   637 | loss: 2.0508404MixupTrain:  epoch  0, batch   638 | loss: 2.6785955MixupTrain:  epoch  0, batch   639 | loss: 2.2873249MixupTrain:  epoch  0, batch   640 | loss: 3.0072570MixupTrain:  epoch  0, batch   641 | loss: 2.3745477MixupTrain:  epoch  0, batch   642 | loss: 2.5573087MixupTrain:  epoch  0, batch   643 | loss: 2.4224319MixupTrain:  epoch  0, batch   644 | loss: 2.6784267MixupTrain:  epoch  0, batch   645 | loss: 2.1908045MixupTrain:  epoch  0, batch   646 | loss: 2.7173269MixupTrain:  epoch  0, batch   647 | loss: 2.3718448MixupTrain:  epoch  0, batch   648 | loss: 2.0778947MixupTrain:  epoch  0, batch   649 | loss: 2.6038661MixupTrain:  epoch  0, batch   650 | loss: 2.1674895MixupTrain:  epoch  0, batch   651 | loss: 2.3518248MixupTrain:  epoch  0, batch   652 | loss: 2.7555940MixupTrain:  epoch  0, batch   653 | loss: 2.4166632MixupTrain:  epoch  0, batch   654 | loss: 2.6457248MixupTrain:  epoch  0, batch   655 | loss: 2.3288798MixupTrain:  epoch  0, batch   656 | loss: 2.6551721MixupTrain:  epoch  0, batch   657 | loss: 2.3207121MixupTrain:  epoch  0, batch   658 | loss: 2.3796122MixupTrain:  epoch  0, batch   659 | loss: 2.5809937MixupTrain:  epoch  0, batch   660 | loss: 2.4301057MixupTrain:  epoch  0, batch   661 | loss: 2.3769119MixupTrain:  epoch  0, batch   662 | loss: 2.4602969MixupTrain:  epoch  0, batch   663 | loss: 2.3250461MixupTrain:  epoch  0, batch   664 | loss: 2.5495305MixupTrain:  epoch  0, batch   665 | loss: 2.1945479MixupTrain:  epoch  0, batch   666 | loss: 2.5246215MixupTrain:  epoch  0, batch   667 | loss: 2.3773236MixupTrain:  epoch  0, batch   668 | loss: 2.5715446MixupTrain:  epoch  0, batch   669 | loss: 2.5118904MixupTrain:  epoch  0, batch   670 | loss: 2.2365046MixupTrain:  epoch  0, batch   671 | loss: 2.6647818MixupTrain:  epoch  0, batch   672 | loss: 2.5856917MixupTrain:  epoch  0, batch   673 | loss: 2.6684699MixupTrain:  epoch  0, batch   674 | loss: 2.2555447MixupTrain:  epoch  0, batch   675 | loss: 2.4924593MixupTrain:  epoch  0, batch   676 | loss: 2.7351353MixupTrain:  epoch  0, batch   677 | loss: 2.3566155MixupTrain:  epoch  0, batch   678 | loss: 2.9273336MixupTrain:  epoch  0, batch   679 | loss: 2.2667737MixupTrain:  epoch  0, batch   680 | loss: 2.3375337MixupTrain:  epoch  0, batch   681 | loss: 2.3673978MixupTrain:  epoch  0, batch   682 | loss: 2.6653805MixupTrain:  epoch  0, batch   683 | loss: 2.1964335MixupTrain:  epoch  0, batch   684 | loss: 2.4756346MixupTrain:  epoch  0, batch   685 | loss: 2.5902479MixupTrain:  epoch  0, batch   686 | loss: 2.5243230MixupTrain:  epoch  0, batch   687 | loss: 2.0516136MixupTrain:  epoch  0, batch   688 | loss: 2.4095416MixupTrain:  epoch  0, batch   689 | loss: 2.7781882MixupTrain:  epoch  0, batch   690 | loss: 2.4381881MixupTrain:  epoch  0, batch   691 | loss: 2.4548302MixupTrain:  epoch  0, batch   692 | loss: 2.1557789MixupTrain:  epoch  0, batch   693 | loss: 2.7444479MixupTrain:  epoch  0, batch   694 | loss: 2.6067724MixupTrain:  epoch  0, batch   695 | loss: 3.0707021MixupTrain:  epoch  0, batch   696 | loss: 2.5023782MixupTrain:  epoch  0, batch   697 | loss: 2.2399912MixupTrain:  epoch  0, batch   698 | loss: 2.6445160MixupTrain:  epoch  0, batch   699 | loss: 2.4074111MixupTrain:  epoch  0, batch   700 | loss: 2.4901576MixupTrain:  epoch  0, batch   701 | loss: 2.4723363MixupTrain:  epoch  0, batch   702 | loss: 2.3205767MixupTrain:  epoch  0, batch   703 | loss: 2.3997996MixupTrain:  epoch  0, batch   704 | loss: 2.7464085MixupTrain:  epoch  0, batch   705 | loss: 2.9333084MixupTrain:  epoch  0, batch   706 | loss: 2.5940111MixupTrain:  epoch  0, batch   707 | loss: 2.4794796MixupTrain:  epoch  0, batch   708 | loss: 2.1856246MixupTrain:  epoch  0, batch   709 | loss: 2.3243127MixupTrain:  epoch  0, batch   710 | loss: 2.4633622MixupTrain:  epoch  0, batch   711 | loss: 2.0496783MixupTrain:  epoch  0, batch   712 | loss: 2.4503329MixupTrain:  epoch  0, batch   713 | loss: 2.8493948MixupTrain:  epoch  0, batch   714 | loss: 2.8657124MixupTrain:  epoch  0, batch   715 | loss: 2.4548140MixupTrain:  epoch  0, batch   716 | loss: 2.2897682MixupTrain:  epoch  0, batch   717 | loss: 2.2552028MixupTrain:  epoch  0, batch   718 | loss: 2.4111054MixupTrain:  epoch  0, batch   719 | loss: 2.3438876MixupTrain:  epoch  0, batch   720 | loss: 2.4721041MixupTrain:  epoch  0, batch   721 | loss: 2.4380257MixupTrain:  epoch  0, batch   722 | loss: 2.4692731MixupTrain:  epoch  0, batch   723 | loss: 2.3442850MixupTrain:  epoch  0, batch   724 | loss: 2.7349944MixupTrain:  epoch  0, batch   725 | loss: 2.4713151MixupTrain:  epoch  0, batch   726 | loss: 2.6121294MixupTrain:  epoch  0, batch   727 | loss: 2.4603336MixupTrain:  epoch  0, batch   728 | loss: 2.4488809MixupTrain:  epoch  0, batch   729 | loss: 2.4653661MixupTrain:  epoch  0, batch   730 | loss: 2.3497925MixupTrain:  epoch  0, batch   731 | loss: 2.4818437MixupTrain:  epoch  0, batch   732 | loss: 2.4743805MixupTrain:  epoch  0, batch   733 | loss: 2.9686720MixupTrain:  epoch  0, batch   734 | loss: 2.5176806MixupTrain:  epoch  0, batch   735 | loss: 2.4835377MixupTrain:  epoch  0, batch   736 | loss: 2.3777041MixupTrain:  epoch  0, batch   737 | loss: 2.2811680MixupTrain:  epoch  0, batch   738 | loss: 2.1847572MixupTrain:  epoch  0, batch   739 | loss: 2.4885211MixupTrain:  epoch  0, batch   740 | loss: 2.0406365MixupTrain:  epoch  0, batch   741 | loss: 2.5918808MixupTrain:  epoch  0, batch   742 | loss: 2.3783350MixupTrain:  epoch  0, batch   743 | loss: 2.1902289MixupTrain:  epoch  0, batch   744 | loss: 2.4047511MixupTrain:  epoch  0, batch   745 | loss: 2.2241211MixupTrain:  epoch  0, batch   746 | loss: 2.7054207MixupTrain:  epoch  0, batch   747 | loss: 2.2611146MixupTrain:  epoch  0, batch   748 | loss: 2.3615360MixupTrain:  epoch  0, batch   749 | loss: 2.1671083MixupTrain:  epoch  0, batch   750 | loss: 2.5245898MixupTrain:  epoch  0, batch   751 | loss: 2.7349715MixupTrain:  epoch  0, batch   752 | loss: 2.3990505MixupTrain:  epoch  0, batch   753 | loss: 2.6551354MixupTrain:  epoch  0, batch   754 | loss: 2.2407560MixupTrain:  epoch  0, batch   755 | loss: 2.7249429MixupTrain:  epoch  0, batch   756 | loss: 2.5837433MixupTrain:  epoch  0, batch   757 | loss: 2.3888865MixupTrain:  epoch  0, batch   758 | loss: 2.5573545MixupTrain:  epoch  0, batch   759 | loss: 2.3067641MixupTrain:  epoch  0, batch   760 | loss: 2.3314381MixupTrain:  epoch  0, batch   761 | loss: 2.5802426MixupTrain:  epoch  0, batch   762 | loss: 2.3070374MixupTrain:  epoch  0, batch   763 | loss: 2.3575683MixupTrain:  epoch  0, batch   764 | loss: 2.5452805MixupTrain:  epoch  0, batch   765 | loss: 2.4454389MixupTrain:  epoch  0, batch   766 | loss: 2.2208447MixupTrain:  epoch  0, batch   767 | loss: 2.1407726MixupTrain:  epoch  0, batch   768 | loss: 2.6250257MixupTrain:  epoch  0, batch   769 | loss: 2.0874887MixupTrain:  epoch  0, batch   770 | loss: 2.1206272MixupTrain:  epoch  0, batch   771 | loss: 2.1198797MixupTrain:  epoch  0, batch   772 | loss: 2.3680890MixupTrain:  epoch  0, batch   773 | loss: 2.2756801MixupTrain:  epoch  0, batch   774 | loss: 2.0907233MixupTrain:  epoch  0, batch   775 | loss: 2.4839976MixupTrain:  epoch  0, batch   776 | loss: 2.5232627MixupTrain:  epoch  0, batch   777 | loss: 2.8211110MixupTrain:  epoch  0, batch   778 | loss: 2.3443630MixupTrain:  epoch  0, batch   779 | loss: 2.1345794MixupTrain:  epoch  0, batch   780 | loss: 2.3844049MixupTrain:  epoch  0, batch   781 | loss: 2.5964403MixupTrain:  epoch  0, batch   782 | loss: 2.5015039MixupTrain:  epoch  0, batch   783 | loss: 2.4182296MixupTrain:  epoch  0, batch   784 | loss: 2.4320426MixupTrain:  epoch  0, batch   785 | loss: 2.4119275MixupTrain:  epoch  0, batch   786 | loss: 2.7035835MixupTrain:  epoch  0, batch   787 | loss: 2.1931815MixupTrain:  epoch  0, batch   788 | loss: 2.7557724MixupTrain:  epoch  0, batch   789 | loss: 2.3019168MixupTrain:  epoch  0, batch   790 | loss: 2.4831445MixupTrain:  epoch  0, batch   791 | loss: 2.7185264MixupTrain:  epoch  0, batch   792 | loss: 2.6823072MixupTrain:  epoch  0, batch   793 | loss: 2.8157754MixupTrain:  epoch  0, batch   794 | loss: 2.3670852MixupTrain:  epoch  0, batch   795 | loss: 2.5868382MixupTrain:  epoch  0, batch   796 | loss: 2.4672959MixupTrain:  epoch  0, batch   797 | loss: 2.9415812MixupTrain:  epoch  0, batch   798 | loss: 2.3214736MixupTrain:  epoch  0, batch   799 | loss: 2.2848494MixupTrain:  epoch  0, batch   800 | loss: 2.4762406MixupTrain:  epoch  0, batch   801 | loss: 2.2139339MixupTrain:  epoch  0, batch   802 | loss: 2.4908559MixupTrain:  epoch  0, batch   803 | loss: 2.7094674MixupTrain:  epoch  0, batch   804 | loss: 2.4778709MixupTrain:  epoch  0, batch   805 | loss: 2.2928076MixupTrain:  epoch  0, batch   806 | loss: 2.5710635MixupTrain:  epoch  0, batch   807 | loss: 2.3458533MixupTrain:  epoch  0, batch   808 | loss: 2.2838449MixupTrain:  epoch  0, batch   809 | loss: 2.3448606MixupTrain:  epoch  0, batch   810 | loss: 2.4091709MixupTrain:  epoch  0, batch   811 | loss: 2.1910167MixupTrain:  epoch  0, batch   812 | loss: 2.3416770MixupTrain:  epoch  0, batch   813 | loss: 2.4369051MixupTrain:  epoch  0, batch   814 | loss: 2.4400644MixupTrain:  epoch  0, batch   815 | loss: 2.1567426MixupTrain:  epoch  0, batch   816 | loss: 2.1950536MixupTrain:  epoch  0, batch   817 | loss: 2.5907307MixupTrain:  epoch  0, batch   818 | loss: 2.2522418MixupTrain:  epoch  0, batch   819 | loss: 2.6933615MixupTrain:  epoch  0, batch   820 | loss: 2.3532844MixupTrain:  epoch  0, batch   821 | loss: 2.3507981MixupTrain:  epoch  0, batch   822 | loss: 2.7593393MixupTrain:  epoch  0, batch   823 | loss: 2.6689367MixupTrain:  epoch  0, batch   824 | loss: 2.1535201MixupTrain:  epoch  0, batch   825 | loss: 2.6821489MixupTrain:  epoch  0, batch   826 | loss: 2.7351189MixupTrain:  epoch  0, batch   827 | loss: 2.3978851MixupTrain:  epoch  0, batch   828 | loss: 2.1288352MixupTrain:  epoch  0, batch   829 | loss: 2.3603101MixupTrain:  epoch  0, batch   830 | loss: 2.3158977MixupTrain:  epoch  0, batch   831 | loss: 2.2275078MixupTrain:  epoch  0, batch   832 | loss: 2.6069803MixupTrain:  epoch  0, batch   833 | loss: 2.6071382MixupTrain:  epoch  0, batch   834 | loss: 2.5125036MixupTrain:  epoch  0, batch   835 | loss: 2.5056691MixupTrain:  epoch  0, batch   836 | loss: 2.6299851MixupTrain:  epoch  0, batch   837 | loss: 2.6982996MixupTrain:  epoch  0, batch   838 | loss: 2.5708895MixupTrain:  epoch  0, batch   839 | loss: 2.2864552MixupTrain:  epoch  0, batch   840 | loss: 2.7754302MixupTrain:  epoch  0, batch   841 | loss: 2.2663207MixupTrain:  epoch  0, batch   842 | loss: 2.2941179MixupTrain:  epoch  0, batch   843 | loss: 2.3818107MixupTrain:  epoch  0, batch   844 | loss: 2.4485798MixupTrain:  epoch  0, batch   845 | loss: 2.6173837MixupTrain:  epoch  0, batch   846 | loss: 2.5849814MixupTrain:  epoch  0, batch   847 | loss: 2.3561149MixupTrain:  epoch  0, batch   848 | loss: 2.2423003MixupTrain:  epoch  0, batch   849 | loss: 2.3693042MixupTrain:  epoch  0, batch   850 | loss: 2.6145272MixupTrain:  epoch  0, batch   851 | loss: 2.4539437MixupTrain:  epoch  0, batch   852 | loss: 2.6193714MixupTrain:  epoch  0, batch   853 | loss: 2.4476314MixupTrain:  epoch  0, batch   854 | loss: 2.2587481MixupTrain:  epoch  0, batch   855 | loss: 2.4659085MixupTrain:  epoch  0, batch   856 | loss: 2.3607771MixupTrain:  epoch  0, batch   857 | loss: 2.6534882MixupTrain:  epoch  0, batch   858 | loss: 2.1970491MixupTrain:  epoch  0, batch   859 | loss: 2.2687528MixupTrain:  epoch  0, batch   860 | loss: 2.9002247MixupTrain:  epoch  0, batch   861 | loss: 2.3013077MixupTrain:  epoch  0, batch   862 | loss: 2.1113327MixupTrain:  epoch  0, batch   863 | loss: 2.5709157MixupTrain:  epoch  0, batch   864 | loss: 2.2062795MixupTrain:  epoch  0, batch   865 | loss: 2.6446619MixupTrain:  epoch  0, batch   866 | loss: 2.5570610MixupTrain:  epoch  0, batch   867 | loss: 2.1647391MixupTrain:  epoch  0, batch   868 | loss: 2.3537960MixupTrain:  epoch  0, batch   869 | loss: 2.2651587MixupTrain:  epoch  0, batch   870 | loss: 2.5796719MixupTrain:  epoch  0, batch   871 | loss: 2.8187840MixupTrain:  epoch  0, batch   872 | loss: 2.1218703MixupTrain:  epoch  0, batch   873 | loss: 3.0057225MixupTrain:  epoch  0, batch   874 | loss: 2.5674548MixupTrain:  epoch  0, batch   875 | loss: 2.1803222MixupTrain:  epoch  0, batch   876 | loss: 2.5383689MixupTrain:  epoch  0, batch   877 | loss: 2.4860723MixupTrain:  epoch  0, batch   878 | loss: 2.6647406MixupTrain:  epoch  0, batch   879 | loss: 2.5745168MixupTrain:  epoch  0, batch   880 | loss: 2.4776402MixupTrain:  epoch  0, batch   881 | loss: 2.4373517MixupTrain:  epoch  0, batch   882 | loss: 2.4699390MixupTrain:  epoch  0, batch   883 | loss: 2.4502902MixupTrain:  epoch  0, batch   884 | loss: 2.3224649MixupTrain:  epoch  0, batch   885 | loss: 2.5978467MixupTrain:  epoch  0, batch   886 | loss: 2.7107072MixupTrain:  epoch  0, batch   887 | loss: 2.6607194MixupTrain:  epoch  0, batch   888 | loss: 2.5782363MixupTrain:  epoch  0, batch   889 | loss: 2.4984694MixupTrain:  epoch  0, batch   890 | loss: 2.1581070MixupTrain:  epoch  0, batch   891 | loss: 2.1434071MixupTrain:  epoch  0, batch   892 | loss: 2.1508203MixupTrain:  epoch  0, batch   893 | loss: 2.4688215MixupTrain:  epoch  0, batch   894 | loss: 2.1332648MixupTrain:  epoch  0, batch   895 | loss: 2.1422417MixupTrain:  epoch  0, batch   896 | loss: 2.5925789MixupTrain:  epoch  0, batch   897 | loss: 2.7926900MixupTrain:  epoch  0, batch   898 | loss: 2.5733526MixupTrain:  epoch  0, batch   899 | loss: 2.7386994MixupTrain:  epoch  0, batch   900 | loss: 2.0991650MixupTrain:  epoch  0, batch   901 | loss: 2.8678360MixupTrain:  epoch  0, batch   902 | loss: 2.4078012MixupTrain:  epoch  0, batch   903 | loss: 2.7540269MixupTrain:  epoch  0, batch   904 | loss: 2.4573863MixupTrain:  epoch  0, batch   905 | loss: 2.1494260MixupTrain:  epoch  0, batch   906 | loss: 2.4236526MixupTrain:  epoch  0, batch   907 | loss: 2.7087684MixupTrain:  epoch  0, batch   908 | loss: 2.0300095MixupTrain:  epoch  0, batch   909 | loss: 2.2121234MixupTrain:  epoch  0, batch   910 | loss: 2.3134594MixupTrain:  epoch  0, batch   911 | loss: 2.3056540MixupTrain:  epoch  0, batch   912 | loss: 2.3310747MixupTrain:  epoch  0, batch   913 | loss: 2.4228311MixupTrain:  epoch  0, batch   914 | loss: 2.7302928MixupTrain:  epoch  0, batch   915 | loss: 2.6054027MixupTrain:  epoch  0, batch   916 | loss: 2.3561194MixupTrain:  epoch  0, batch   917 | loss: 2.0324373MixupTrain:  epoch  0, batch   918 | loss: 2.2356749MixupTrain:  epoch  0, batch   919 | loss: 2.5190146MixupTrain:  epoch  0, batch   920 | loss: 2.4842107MixupTrain:  epoch  0, batch   921 | loss: 2.5260403MixupTrain:  epoch  0, batch   922 | loss: 2.3179808MixupTrain:  epoch  0, batch   923 | loss: 2.2953794MixupTrain:  epoch  0, batch   924 | loss: 2.5386906MixupTrain:  epoch  0, batch   925 | loss: 2.3645926MixupTrain:  epoch  0, batch   926 | loss: 2.7058039MixupTrain:  epoch  0, batch   927 | loss: 2.2773504MixupTrain:  epoch  0, batch   928 | loss: 2.3499627MixupTrain:  epoch  0, batch   929 | loss: 2.4005849MixupTrain:  epoch  0, batch   930 | loss: 2.2490652MixupTrain:  epoch  0, batch   931 | loss: 2.7899988MixupTrain:  epoch  0, batch   932 | loss: 2.4686339MixupTrain:  epoch  0, batch   933 | loss: 2.6759040MixupTrain:  epoch  0, batch   934 | loss: 2.8892219MixupTrain:  epoch  0, batch   935 | loss: 2.2856832MixupTrain:  epoch  0, batch   936 | loss: 2.4041066MixupTrain:  epoch  0, batch   937 | loss: 2.0948842MixupTrain:  epoch  0, batch   938 | loss: 2.4107361MixupTrain:  epoch  0, batch   939 | loss: 2.4569836MixupTrain:  epoch  0, batch   940 | loss: 2.6178219MixupTrain:  epoch  0, batch   941 | loss: 2.9805455MixupTrain:  epoch  0, batch   942 | loss: 2.2891009MixupTrain:  epoch  0, batch   943 | loss: 2.5369303MixupTrain:  epoch  0, batch   944 | loss: 2.7001021MixupTrain:  epoch  0, batch   945 | loss: 2.5410187MixupTrain:  epoch  0, batch   946 | loss: 2.5547564MixupTrain:  epoch  0, batch   947 | loss: 2.3395090MixupTrain:  epoch  0, batch   948 | loss: 2.6624537MixupTrain:  epoch  0, batch   949 | loss: 2.6369629MixupTrain:  epoch  0, batch   950 | loss: 2.1303773MixupTrain:  epoch  0, batch   951 | loss: 2.3634746MixupTrain:  epoch  0, batch   952 | loss: 2.5829873MixupTrain:  epoch  0, batch   953 | loss: 2.3479044MixupTrain:  epoch  0, batch   954 | loss: 2.3936529MixupTrain:  epoch  0, batch   955 | loss: 2.2546332MixupTrain:  epoch  0, batch   956 | loss: 2.3093905MixupTrain:  epoch  0, batch   957 | loss: 2.5565629MixupTrain:  epoch  0, batch   958 | loss: 2.3991637MixupTrain:  epoch  0, batch   959 | loss: 2.2092450MixupTrain:  epoch  0, batch   960 | loss: 2.5400229MixupTrain:  epoch  0, batch   961 | loss: 2.1912141MixupTrain:  epoch  0, batch   962 | loss: 2.2759192MixupTrain:  epoch  0, batch   963 | loss: 2.4407101MixupTrain:  epoch  0, batch   964 | loss: 2.0747347MixupTrain:  epoch  0, batch   965 | loss: 2.4632740MixupTrain:  epoch  0, batch   966 | loss: 2.2852182MixupTrain:  epoch  0, batch   967 | loss: 2.5125685MixupTrain:  epoch  0, batch   968 | loss: 2.4294367MixupTrain:  epoch  0, batch   969 | loss: 2.1211419MixupTrain:  epoch  0, batch   970 | loss: 2.0354614MixupTrain:  epoch  0, batch   971 | loss: 2.3359618MixupTrain:  epoch  0, batch   972 | loss: 2.3337970MixupTrain:  epoch  0, batch   973 | loss: 2.1349344MixupTrain:  epoch  0, batch   974 | loss: 3.0490239MixupTrain:  epoch  0, batch   975 | loss: 2.2178659MixupTrain:  epoch  0, batch   976 | loss: 2.2408667MixupTrain:  epoch  0, batch   977 | loss: 2.3972507MixupTrain:  epoch  0, batch   978 | loss: 2.6209571MixupTrain:  epoch  0, batch   979 | loss: 2.3895552MixupTrain:  epoch  0, batch   980 | loss: 2.6160207MixupTrain:  epoch  0, batch   981 | loss: 2.5301290
MemoryTrain:  epoch  0, batch     0 | loss: 2.0950885MemoryTrain:  epoch  0, batch     1 | loss: 3.3093915MemoryTrain:  epoch  0, batch     2 | loss: 2.5084262MemoryTrain:  epoch  0, batch     3 | loss: 2.2706475MemoryTrain:  epoch  0, batch     4 | loss: 3.2322738MemoryTrain:  epoch  0, batch     5 | loss: 2.0981650MemoryTrain:  epoch  0, batch     6 | loss: 2.4973764MemoryTrain:  epoch  0, batch     7 | loss: 2.1698456MemoryTrain:  epoch  0, batch     8 | loss: 2.5107844MemoryTrain:  epoch  0, batch     9 | loss: 2.3378241MemoryTrain:  epoch  1, batch     0 | loss: 1.8442935MemoryTrain:  epoch  1, batch     1 | loss: 2.2550623MemoryTrain:  epoch  1, batch     2 | loss: 1.8345345MemoryTrain:  epoch  1, batch     3 | loss: 1.8640752MemoryTrain:  epoch  1, batch     4 | loss: 1.8360933MemoryTrain:  epoch  1, batch     5 | loss: 1.8590151MemoryTrain:  epoch  1, batch     6 | loss: 1.8805728MemoryTrain:  epoch  1, batch     7 | loss: 1.8771234MemoryTrain:  epoch  1, batch     8 | loss: 1.9244404MemoryTrain:  epoch  1, batch     9 | loss: 1.8764129MemoryTrain:  epoch  2, batch     0 | loss: 1.8267246MemoryTrain:  epoch  2, batch     1 | loss: 1.8597447MemoryTrain:  epoch  2, batch     2 | loss: 1.8410145MemoryTrain:  epoch  2, batch     3 | loss: 1.8299894MemoryTrain:  epoch  2, batch     4 | loss: 1.8511291MemoryTrain:  epoch  2, batch     5 | loss: 1.8865292MemoryTrain:  epoch  2, batch     6 | loss: 1.8191494MemoryTrain:  epoch  2, batch     7 | loss: 1.8192062MemoryTrain:  epoch  2, batch     8 | loss: 1.8275473MemoryTrain:  epoch  2, batch     9 | loss: 1.8294876MemoryTrain:  epoch  3, batch     0 | loss: 1.8228879MemoryTrain:  epoch  3, batch     1 | loss: 1.8234099MemoryTrain:  epoch  3, batch     2 | loss: 1.8699203MemoryTrain:  epoch  3, batch     3 | loss: 1.8222119MemoryTrain:  epoch  3, batch     4 | loss: 1.8162042MemoryTrain:  epoch  3, batch     5 | loss: 1.8206365MemoryTrain:  epoch  3, batch     6 | loss: 1.8394288MemoryTrain:  epoch  3, batch     7 | loss: 1.8291852MemoryTrain:  epoch  3, batch     8 | loss: 1.8460279MemoryTrain:  epoch  3, batch     9 | loss: 1.8434021MemoryTrain:  epoch  4, batch     0 | loss: 1.8671604MemoryTrain:  epoch  4, batch     1 | loss: 1.8135223MemoryTrain:  epoch  4, batch     2 | loss: 1.8140426MemoryTrain:  epoch  4, batch     3 | loss: 1.8426862MemoryTrain:  epoch  4, batch     4 | loss: 1.8242644MemoryTrain:  epoch  4, batch     5 | loss: 1.8177929MemoryTrain:  epoch  4, batch     6 | loss: 1.8124804MemoryTrain:  epoch  4, batch     7 | loss: 1.8228531MemoryTrain:  epoch  4, batch     8 | loss: 1.8259315MemoryTrain:  epoch  4, batch     9 | loss: 1.8211756MemoryTrain:  epoch  5, batch     0 | loss: 1.8243732MemoryTrain:  epoch  5, batch     1 | loss: 1.8175822MemoryTrain:  epoch  5, batch     2 | loss: 1.8174462MemoryTrain:  epoch  5, batch     3 | loss: 1.8158290MemoryTrain:  epoch  5, batch     4 | loss: 1.8169942MemoryTrain:  epoch  5, batch     5 | loss: 1.8176171MemoryTrain:  epoch  5, batch     6 | loss: 1.8291181MemoryTrain:  epoch  5, batch     7 | loss: 1.8169783MemoryTrain:  epoch  5, batch     8 | loss: 1.8324544MemoryTrain:  epoch  5, batch     9 | loss: 1.8221344MemoryTrain:  epoch  6, batch     0 | loss: 1.8169291MemoryTrain:  epoch  6, batch     1 | loss: 1.8217361MemoryTrain:  epoch  6, batch     2 | loss: 1.8240275MemoryTrain:  epoch  6, batch     3 | loss: 1.8127108MemoryTrain:  epoch  6, batch     4 | loss: 1.8301716MemoryTrain:  epoch  6, batch     5 | loss: 1.8228205MemoryTrain:  epoch  6, batch     6 | loss: 1.8185592MemoryTrain:  epoch  6, batch     7 | loss: 1.8164762MemoryTrain:  epoch  6, batch     8 | loss: 1.8193134MemoryTrain:  epoch  6, batch     9 | loss: 1.8144373MemoryTrain:  epoch  7, batch     0 | loss: 1.8231698MemoryTrain:  epoch  7, batch     1 | loss: 1.8147707MemoryTrain:  epoch  7, batch     2 | loss: 1.8172705MemoryTrain:  epoch  7, batch     3 | loss: 1.8137515MemoryTrain:  epoch  7, batch     4 | loss: 1.8259363MemoryTrain:  epoch  7, batch     5 | loss: 1.8154271MemoryTrain:  epoch  7, batch     6 | loss: 1.8178010MemoryTrain:  epoch  7, batch     7 | loss: 1.8189741MemoryTrain:  epoch  7, batch     8 | loss: 1.8118336MemoryTrain:  epoch  7, batch     9 | loss: 1.8114669MemoryTrain:  epoch  8, batch     0 | loss: 1.8067636MemoryTrain:  epoch  8, batch     1 | loss: 1.8212655MemoryTrain:  epoch  8, batch     2 | loss: 1.8186551MemoryTrain:  epoch  8, batch     3 | loss: 1.8175039MemoryTrain:  epoch  8, batch     4 | loss: 1.8145335MemoryTrain:  epoch  8, batch     5 | loss: 1.8146217MemoryTrain:  epoch  8, batch     6 | loss: 1.8266913MemoryTrain:  epoch  8, batch     7 | loss: 1.8190939MemoryTrain:  epoch  8, batch     8 | loss: 1.8192097MemoryTrain:  epoch  8, batch     9 | loss: 1.8139461MemoryTrain:  epoch  9, batch     0 | loss: 1.8131930MemoryTrain:  epoch  9, batch     1 | loss: 1.8167026MemoryTrain:  epoch  9, batch     2 | loss: 1.8170466MemoryTrain:  epoch  9, batch     3 | loss: 1.8187444MemoryTrain:  epoch  9, batch     4 | loss: 1.8125741MemoryTrain:  epoch  9, batch     5 | loss: 1.8206365MemoryTrain:  epoch  9, batch     6 | loss: 1.8135810MemoryTrain:  epoch  9, batch     7 | loss: 1.8214430MemoryTrain:  epoch  9, batch     8 | loss: 1.8094268MemoryTrain:  epoch  9, batch     9 | loss: 1.8202856
[EVAL] batch:    0 | acc: 37.50%,  total acc: 37.50%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 37.50%   [EVAL] batch:    2 | acc: 31.25%,  total acc: 35.42%   [EVAL] batch:    3 | acc: 43.75%,  total acc: 37.50%   [EVAL] batch:    4 | acc: 25.00%,  total acc: 35.00%   [EVAL] batch:    5 | acc: 68.75%,  total acc: 40.62%   [EVAL] batch:    6 | acc: 62.50%,  total acc: 43.75%   [EVAL] batch:    7 | acc: 62.50%,  total acc: 46.09%   [EVAL] batch:    8 | acc: 43.75%,  total acc: 45.83%   [EVAL] batch:    9 | acc: 56.25%,  total acc: 46.88%   [EVAL] batch:   10 | acc: 68.75%,  total acc: 48.86%   [EVAL] batch:   11 | acc: 68.75%,  total acc: 50.52%   [EVAL] batch:   12 | acc: 56.25%,  total acc: 50.96%   [EVAL] batch:   13 | acc: 100.00%,  total acc: 54.46%   [EVAL] batch:   14 | acc: 100.00%,  total acc: 57.50%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 60.16%   [EVAL] batch:   16 | acc: 100.00%,  total acc: 62.50%   [EVAL] batch:   17 | acc: 87.50%,  total acc: 63.89%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 63.82%   [EVAL] batch:   19 | acc: 87.50%,  total acc: 65.00%   [EVAL] batch:   20 | acc: 75.00%,  total acc: 65.48%   [EVAL] batch:   21 | acc: 43.75%,  total acc: 64.49%   
[EVAL] batch:    0 | acc: 25.00%,  total acc: 25.00%   [EVAL] batch:    1 | acc: 56.25%,  total acc: 40.62%   [EVAL] batch:    2 | acc: 31.25%,  total acc: 37.50%   [EVAL] batch:    3 | acc: 25.00%,  total acc: 34.38%   [EVAL] batch:    4 | acc: 25.00%,  total acc: 32.50%   [EVAL] batch:    5 | acc: 31.25%,  total acc: 32.29%   [EVAL] batch:    6 | acc: 68.75%,  total acc: 37.50%   [EVAL] batch:    7 | acc: 75.00%,  total acc: 42.19%   [EVAL] batch:    8 | acc: 87.50%,  total acc: 47.22%   [EVAL] batch:    9 | acc: 68.75%,  total acc: 49.38%   [EVAL] batch:   10 | acc: 68.75%,  total acc: 51.14%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 54.17%   [EVAL] batch:   12 | acc: 43.75%,  total acc: 53.37%   [EVAL] batch:   13 | acc: 37.50%,  total acc: 52.23%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 53.75%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 53.91%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 55.15%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 55.56%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 55.92%   [EVAL] batch:   19 | acc: 75.00%,  total acc: 56.88%   [EVAL] batch:   20 | acc: 93.75%,  total acc: 58.63%   [EVAL] batch:   21 | acc: 100.00%,  total acc: 60.51%   [EVAL] batch:   22 | acc: 87.50%,  total acc: 61.68%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 63.02%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 64.25%   [EVAL] batch:   25 | acc: 87.50%,  total acc: 65.14%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 65.97%   [EVAL] batch:   27 | acc: 81.25%,  total acc: 66.52%   [EVAL] batch:   28 | acc: 62.50%,  total acc: 66.38%   [EVAL] batch:   29 | acc: 56.25%,  total acc: 66.04%   [EVAL] batch:   30 | acc: 56.25%,  total acc: 65.73%   [EVAL] batch:   31 | acc: 81.25%,  total acc: 66.21%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 65.34%   [EVAL] batch:   33 | acc: 12.50%,  total acc: 63.79%   [EVAL] batch:   34 | acc: 18.75%,  total acc: 62.50%   [EVAL] batch:   35 | acc: 18.75%,  total acc: 61.28%   [EVAL] batch:   36 | acc: 25.00%,  total acc: 60.30%   [EVAL] batch:   37 | acc: 62.50%,  total acc: 60.36%   [EVAL] batch:   38 | acc: 62.50%,  total acc: 60.42%   [EVAL] batch:   39 | acc: 93.75%,  total acc: 61.25%   [EVAL] batch:   40 | acc: 62.50%,  total acc: 61.28%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 62.20%   [EVAL] batch:   42 | acc: 6.25%,  total acc: 60.90%   [EVAL] batch:   43 | acc: 0.00%,  total acc: 59.52%   [EVAL] batch:   44 | acc: 0.00%,  total acc: 58.19%   [EVAL] batch:   45 | acc: 0.00%,  total acc: 56.93%   [EVAL] batch:   46 | acc: 12.50%,  total acc: 55.98%   [EVAL] batch:   47 | acc: 50.00%,  total acc: 55.86%   [EVAL] batch:   48 | acc: 12.50%,  total acc: 54.97%   [EVAL] batch:   49 | acc: 0.00%,  total acc: 53.87%   [EVAL] batch:   50 | acc: 6.25%,  total acc: 52.94%   [EVAL] batch:   51 | acc: 0.00%,  total acc: 51.92%   [EVAL] batch:   52 | acc: 0.00%,  total acc: 50.94%   [EVAL] batch:   53 | acc: 31.25%,  total acc: 50.58%   [EVAL] batch:   54 | acc: 87.50%,  total acc: 51.25%   [EVAL] batch:   55 | acc: 87.50%,  total acc: 51.90%   [EVAL] batch:   56 | acc: 75.00%,  total acc: 52.30%   [EVAL] batch:   57 | acc: 62.50%,  total acc: 52.48%   [EVAL] batch:   58 | acc: 68.75%,  total acc: 52.75%   [EVAL] batch:   59 | acc: 56.25%,  total acc: 52.81%   [EVAL] batch:   60 | acc: 43.75%,  total acc: 52.66%   [EVAL] batch:   61 | acc: 87.50%,  total acc: 53.23%   [EVAL] batch:   62 | acc: 93.75%,  total acc: 53.87%   [EVAL] batch:   63 | acc: 87.50%,  total acc: 54.39%   [EVAL] batch:   64 | acc: 93.75%,  total acc: 55.00%   [EVAL] batch:   65 | acc: 87.50%,  total acc: 55.49%   [EVAL] batch:   66 | acc: 100.00%,  total acc: 56.16%   [EVAL] batch:   67 | acc: 93.75%,  total acc: 56.71%   [EVAL] batch:   68 | acc: 87.50%,  total acc: 57.16%   [EVAL] batch:   69 | acc: 62.50%,  total acc: 57.23%   [EVAL] batch:   70 | acc: 81.25%,  total acc: 57.57%   [EVAL] batch:   71 | acc: 68.75%,  total acc: 57.73%   [EVAL] batch:   72 | acc: 100.00%,  total acc: 58.30%   [EVAL] batch:   73 | acc: 93.75%,  total acc: 58.78%   [EVAL] batch:   74 | acc: 100.00%,  total acc: 59.33%   [EVAL] batch:   75 | acc: 100.00%,  total acc: 59.87%   [EVAL] batch:   76 | acc: 100.00%,  total acc: 60.39%   [EVAL] batch:   77 | acc: 75.00%,  total acc: 60.58%   [EVAL] batch:   78 | acc: 43.75%,  total acc: 60.36%   [EVAL] batch:   79 | acc: 25.00%,  total acc: 59.92%   [EVAL] batch:   80 | acc: 50.00%,  total acc: 59.80%   [EVAL] batch:   81 | acc: 25.00%,  total acc: 59.38%   [EVAL] batch:   82 | acc: 37.50%,  total acc: 59.11%   [EVAL] batch:   83 | acc: 68.75%,  total acc: 59.23%   [EVAL] batch:   84 | acc: 62.50%,  total acc: 59.26%   [EVAL] batch:   85 | acc: 56.25%,  total acc: 59.23%   [EVAL] batch:   86 | acc: 50.00%,  total acc: 59.12%   [EVAL] batch:   87 | acc: 62.50%,  total acc: 59.16%   [EVAL] batch:   88 | acc: 62.50%,  total acc: 59.20%   [EVAL] batch:   89 | acc: 68.75%,  total acc: 59.31%   [EVAL] batch:   90 | acc: 68.75%,  total acc: 59.41%   [EVAL] batch:   91 | acc: 100.00%,  total acc: 59.85%   [EVAL] batch:   92 | acc: 100.00%,  total acc: 60.28%   [EVAL] batch:   93 | acc: 100.00%,  total acc: 60.70%   [EVAL] batch:   94 | acc: 93.75%,  total acc: 61.05%   [EVAL] batch:   95 | acc: 87.50%,  total acc: 61.33%   [EVAL] batch:   96 | acc: 68.75%,  total acc: 61.40%   [EVAL] batch:   97 | acc: 81.25%,  total acc: 61.61%   [EVAL] batch:   98 | acc: 81.25%,  total acc: 61.81%   [EVAL] batch:   99 | acc: 18.75%,  total acc: 61.38%   
cur_acc:  ['0.8580', '0.8750', '0.8438', '0.9028', '0.6449']
his_acc:  ['0.8580', '0.8191', '0.7121', '0.6314', '0.6138']
CurrentTrain: epoch  0, batch     0 | loss: 5.7462139CurrentTrain: epoch  0, batch     1 | loss: 9.0128345CurrentTrain: epoch  1, batch     0 | loss: 5.4498205CurrentTrain: epoch  1, batch     1 | loss: 6.6718001CurrentTrain: epoch  2, batch     0 | loss: 4.9546766CurrentTrain: epoch  2, batch     1 | loss: 5.0761967CurrentTrain: epoch  3, batch     0 | loss: 4.7592249CurrentTrain: epoch  3, batch     1 | loss: 1.9963523CurrentTrain: epoch  4, batch     0 | loss: 2.8999205CurrentTrain: epoch  4, batch     1 | loss: 3.7213020CurrentTrain: epoch  5, batch     0 | loss: 3.5809908CurrentTrain: epoch  5, batch     1 | loss: 2.5070488CurrentTrain: epoch  6, batch     0 | loss: 2.5227742CurrentTrain: epoch  6, batch     1 | loss: 3.3671353CurrentTrain: epoch  7, batch     0 | loss: 2.6652133CurrentTrain: epoch  7, batch     1 | loss: 2.7675607CurrentTrain: epoch  8, batch     0 | loss: 2.3302169CurrentTrain: epoch  8, batch     1 | loss: 1.9167731CurrentTrain: epoch  9, batch     0 | loss: 2.0799618CurrentTrain: epoch  9, batch     1 | loss: 2.0758591
#### person country of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person country of birth" means a person was born in a country.
Here is an example:
Relation: person country of birth
Context: de maiziere noted that germany took in another former inmate from guantanamo in 2006 -- murat kurnaz , a turkish national who was born and grew up in germany .
Head Entity: murat kurnaz
Tail Entity: germany
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person country of birth":
Relation: person country of birth  
Context: The famous physicist Albert Einstein was born in the Kingdom of Württemberg in the German Empire in 1879.  
Head Entity: Albert Einstein  
Tail Entity: Germany  

Relation: person country of birth  
Context: Born in the bustling city of Toronto, Justin Bieber rose to fame as a pop sensation in Canada.  
Head Entity: Justin Bieber  
Tail Entity: Canada  

Relation: person country of birth  
Context: The renowned author Gabriel García Márquez was born in Aracataca, Colombia, where he spent his early years.  
Head Entity: Gabriel García Márquez  
Tail Entity: Colombia  

Relation: person country of birth  
Context: The legendary soccer player Pelé was born in Três Corações, Brazil, and became a global icon of the sport.  
Head Entity: Pelé  
Tail Entity: Brazil  

Relation: person country of birth  
Context: The acclaimed actress Lupita Nyong'o was born in Mexico City, Mexico, before moving to Kenya as a child.  
Head Entity: Lupita Nyong'o  
Tail Entity: Mexico  
#### organization website ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization website" means an organization 's website is an url.
Here is an example:
Relation: organization website
Context: 11.30.08 2008 cma awards red carpet special http://www.cmt.com/shows/dyn/2008-cma-awards-red-carpet/1/episode.jhtml
Head Entity: cma
Tail Entity: http://www.cmt.com/shows/dyn/2008-cma-awards-red-carpet/1/episode.jhtml
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization website":
Relation: organization website  
Context: The official website for the American Red Cross can be found at https://www.redcross.org.  
Head Entity: American Red Cross  
Tail Entity: https://www.redcross.org  

Relation: organization website  
Context: For more information about the World Wildlife Fund, visit their site at https://www.worldwildlife.org.  
Head Entity: World Wildlife Fund  
Tail Entity: https://www.worldwildlife.org  

Relation: organization website  
Context: You can explore the latest research and initiatives at the National Institutes of Health by going to https://www.nih.gov.  
Head Entity: National Institutes of Health  
Tail Entity: https://www.nih.gov  

Relation: organization website  
Context: The website for the United Nations is accessible at https://www.un.org.  
Head Entity: United Nations  
Tail Entity: https://www.un.org  

Relation: organization website  
Context: Check out the latest updates from NASA on their official website at https://www.nasa.gov.  
Head Entity: NASA  
Tail Entity: https://www.nasa.gov  
#### organization shareholders ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization shareholders" means an organization was invested by a person.
Here is an example:
Relation: organization shareholders
Context: marsans already owns the madrid-based air comet and 95 percent of aerolineas argentinas .
Head Entity: aerolineas argentinas
Tail Entity: marsans
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization shareholders":
Relation: organization shareholders  
Context: tech giant apple has seen significant investments from warren buffett's berkshire hathaway.  
Head Entity: apple  
Tail Entity: berkshire hathaway  

Relation: organization shareholders  
Context: the famous investor george soros has acquired a substantial stake in the online retail company alibaba.  
Head Entity: alibaba  
Tail Entity: george soros  

Relation: organization shareholders  
Context: the pharmaceutical company pfizer has received funding from the investment firm blackrock.  
Head Entity: pfizer  
Tail Entity: blackrock  

Relation: organization shareholders  
Context: the renewable energy firm nextera energy has attracted investments from the investment group vanguard.  
Head Entity: nextera energy  
Tail Entity: vanguard  

Relation: organization shareholders  
Context: the automotive manufacturer tesla has been backed by significant shares from the investment company fidelity.  
Head Entity: tesla  
Tail Entity: fidelity  
#### organization dissolved ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization dissolved" means an organization was dissolved in a date.
Here is an example:
Relation: organization dissolved
Context: the tse suffered its worst-ever system crash in november 2005 which paralyzed the world 's second largest bourse and forced it to shelve plan for a listing of its own .
Head Entity: tse
Tail Entity: november 2005
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization dissolved":
Relation: organization dissolved  
Context: The once-prominent tech startup, Innovatech, officially ceased operations in March 2020 after struggling to secure funding.  
Head Entity: Innovatech  
Tail Entity: March 2020  

Relation: organization dissolved  
Context: After years of financial difficulties, the local arts council announced its dissolution in January 2019, leaving many artists without support.  
Head Entity: local arts council  
Tail Entity: January 2019  

Relation: organization dissolved  
Context: The historic bookstore, Pages & Co., closed its doors for good in July 2021, marking the end of an era for the community.  
Head Entity: Pages & Co.  
Tail Entity: July 2021  

Relation: organization dissolved  
Context: Following a series of scandals, the charity organization, Helping Hands, was officially dissolved in February 2022.  
Head Entity: Helping Hands  
Tail Entity: February 2022  

Relation: organization dissolved  
Context: The environmental group, Green Future, announced its dissolution in October 2018 due to a lack of funding and support.  
Head Entity: Green Future  
Tail Entity: October 2018  
#### organization founded by ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization founded by" means an organization was found by a person.
Here is an example:
Relation: organization founded by
Context: `` i have no greater obligation than to ensure the safely of airline travelers in this country , '' transportation secretary ray lahood said in a joint statement with j. randolph babbitt , administrator of the federal aviation administration , that was issued on the eve of a senate hearing on aviation safety .
Head Entity: federal aviation administration
Tail Entity: j. randolph babbitt
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization founded by":
Relation: organization founded by  
Context: In 1975, the renowned physicist and entrepreneur, Dr. John Smith, established Quantum Innovations, a company dedicated to advancing quantum computing technologies.  
Head Entity: Quantum Innovations  
Tail Entity: Dr. John Smith  

Relation: organization founded by  
Context: The charity organization, Hope for Tomorrow, was created in 2010 by the well-known philanthropist, Sarah Johnson, to support underprivileged children.  
Head Entity: Hope for Tomorrow  
Tail Entity: Sarah Johnson  

Relation: organization founded by  
Context: After years of research and development, the tech startup, GreenTech Solutions, was founded by environmental scientist Dr. Emily Carter to promote sustainable energy solutions.  
Head Entity: GreenTech Solutions  
Tail Entity: Dr. Emily Carter  

Relation: organization founded by  
Context: The prestigious art gallery, Modern Visions, was established in 2018 by acclaimed artist and curator, Michael Lee, to showcase contemporary art.  
Head Entity: Modern Visions  
Tail Entity: Michael Lee  

Relation: organization founded by  
Context: In 1999, the innovative software company, CodeCrafters, was founded by a group of talented engineers led by Alex Turner, who aimed to revolutionize app development.  
Head Entity: CodeCrafters  
Tail Entity: Alex Turner  
Mixup data size:  21490
MixupTrain:  epoch  0, batch     0 | loss: 3.8398509MixupTrain:  epoch  0, batch     1 | loss: 3.9731035MixupTrain:  epoch  0, batch     2 | loss: 4.0701628MixupTrain:  epoch  0, batch     3 | loss: 2.5340929MixupTrain:  epoch  0, batch     4 | loss: 3.8176155MixupTrain:  epoch  0, batch     5 | loss: 3.8573937MixupTrain:  epoch  0, batch     6 | loss: 3.2997718MixupTrain:  epoch  0, batch     7 | loss: 3.2824392MixupTrain:  epoch  0, batch     8 | loss: 3.6564169MixupTrain:  epoch  0, batch     9 | loss: 4.0871511MixupTrain:  epoch  0, batch    10 | loss: 4.3140836MixupTrain:  epoch  0, batch    11 | loss: 3.2544005MixupTrain:  epoch  0, batch    12 | loss: 3.2209353MixupTrain:  epoch  0, batch    13 | loss: 4.0146317MixupTrain:  epoch  0, batch    14 | loss: 3.1114781MixupTrain:  epoch  0, batch    15 | loss: 3.2532969MixupTrain:  epoch  0, batch    16 | loss: 3.7789619MixupTrain:  epoch  0, batch    17 | loss: 3.2118936MixupTrain:  epoch  0, batch    18 | loss: 4.3792367MixupTrain:  epoch  0, batch    19 | loss: 3.6106527MixupTrain:  epoch  0, batch    21 | loss: 2.9381976MixupTrain:  epoch  0, batch    22 | loss: 3.9656124MixupTrain:  epoch  0, batch    23 | loss: 3.2639937MixupTrain:  epoch  0, batch    24 | loss: 3.5647116MixupTrain:  epoch  0, batch    25 | loss: 3.1813087MixupTrain:  epoch  0, batch    26 | loss: 2.9349251MixupTrain:  epoch  0, batch    27 | loss: 3.1842024MixupTrain:  epoch  0, batch    29 | loss: 2.9966297MixupTrain:  epoch  0, batch    30 | loss: 2.9810266MixupTrain:  epoch  0, batch    31 | loss: 3.1432116MixupTrain:  epoch  0, batch    32 | loss: 3.3872998MixupTrain:  epoch  0, batch    33 | loss: 2.9063458MixupTrain:  epoch  0, batch    34 | loss: 3.2746887MixupTrain:  epoch  0, batch    35 | loss: 2.8799386MixupTrain:  epoch  0, batch    36 | loss: 3.1253328MixupTrain:  epoch  0, batch    37 | loss: 2.9104989MixupTrain:  epoch  0, batch    38 | loss: 3.0385947MixupTrain:  epoch  0, batch    39 | loss: 3.2166853MixupTrain:  epoch  0, batch    40 | loss: 2.5098717MixupTrain:  epoch  0, batch    41 | loss: 3.2284184MixupTrain:  epoch  0, batch    42 | loss: 3.4127548MixupTrain:  epoch  0, batch    43 | loss: 3.3932712MixupTrain:  epoch  0, batch    44 | loss: 2.5751960MixupTrain:  epoch  0, batch    45 | loss: 3.4268429MixupTrain:  epoch  0, batch    46 | loss: 3.8397744MixupTrain:  epoch  0, batch    47 | loss: 3.8447795MixupTrain:  epoch  0, batch    48 | loss: 4.1474657MixupTrain:  epoch  0, batch    50 | loss: 3.6824331MixupTrain:  epoch  0, batch    51 | loss: 3.0004768MixupTrain:  epoch  0, batch    53 | loss: 2.5605073MixupTrain:  epoch  0, batch    54 | loss: 3.7224092MixupTrain:  epoch  0, batch    55 | loss: 3.4870872MixupTrain:  epoch  0, batch    56 | loss: 2.3561080MixupTrain:  epoch  0, batch    57 | loss: 2.3790715MixupTrain:  epoch  0, batch    58 | loss: 2.7049098MixupTrain:  epoch  0, batch    59 | loss: 3.6325836MixupTrain:  epoch  0, batch    60 | loss: 3.4770691MixupTrain:  epoch  0, batch    61 | loss: 2.7386913MixupTrain:  epoch  0, batch    64 | loss: 2.8456647MixupTrain:  epoch  0, batch    66 | loss: 3.0868044MixupTrain:  epoch  0, batch    67 | loss: 2.8328226MixupTrain:  epoch  0, batch    68 | loss: 2.4108117MixupTrain:  epoch  0, batch    69 | loss: 3.2463903MixupTrain:  epoch  0, batch    70 | loss: 2.5440948MixupTrain:  epoch  0, batch    72 | loss: 2.4133484MixupTrain:  epoch  0, batch    73 | loss: 2.8293626MixupTrain:  epoch  0, batch    75 | loss: 3.7215602MixupTrain:  epoch  0, batch    77 | loss: 2.3927014MixupTrain:  epoch  0, batch    78 | loss: 2.6793656MixupTrain:  epoch  0, batch    80 | loss: 2.8745823MixupTrain:  epoch  0, batch    81 | loss: 2.4660242MixupTrain:  epoch  0, batch    83 | loss: 2.4459329MixupTrain:  epoch  0, batch    84 | loss: 2.6142693MixupTrain:  epoch  0, batch    85 | loss: 2.5778904MixupTrain:  epoch  0, batch    86 | loss: 3.4111228MixupTrain:  epoch  0, batch    87 | loss: 2.6192682MixupTrain:  epoch  0, batch    88 | loss: 2.6218703MixupTrain:  epoch  0, batch    89 | loss: 3.1325450MixupTrain:  epoch  0, batch    90 | loss: 2.6479959MixupTrain:  epoch  0, batch    91 | loss: 2.9364448MixupTrain:  epoch  0, batch    92 | loss: 3.7382812MixupTrain:  epoch  0, batch    93 | loss: 3.4613156MixupTrain:  epoch  0, batch    94 | loss: 2.5455506MixupTrain:  epoch  0, batch    96 | loss: 2.4856164MixupTrain:  epoch  0, batch    97 | loss: 2.6339390MixupTrain:  epoch  0, batch    98 | loss: 2.0871322MixupTrain:  epoch  0, batch    99 | loss: 2.6361382MixupTrain:  epoch  0, batch   100 | loss: 2.9884729MixupTrain:  epoch  0, batch   101 | loss: 2.3072696MixupTrain:  epoch  0, batch   102 | loss: 2.3520813MixupTrain:  epoch  0, batch   103 | loss: 2.7712336MixupTrain:  epoch  0, batch   104 | loss: 2.6419702MixupTrain:  epoch  0, batch   105 | loss: 3.1535521MixupTrain:  epoch  0, batch   107 | loss: 3.2739034MixupTrain:  epoch  0, batch   108 | loss: 3.3886495MixupTrain:  epoch  0, batch   109 | loss: 2.8446174MixupTrain:  epoch  0, batch   110 | loss: 3.2007732MixupTrain:  epoch  0, batch   111 | loss: 2.9815893MixupTrain:  epoch  0, batch   112 | loss: 2.4602177MixupTrain:  epoch  0, batch   113 | loss: 3.2670784MixupTrain:  epoch  0, batch   114 | loss: 3.0922408MixupTrain:  epoch  0, batch   116 | loss: 2.7479036MixupTrain:  epoch  0, batch   117 | loss: 2.9559522MixupTrain:  epoch  0, batch   119 | loss: 2.2891128MixupTrain:  epoch  0, batch   121 | loss: 2.3042040MixupTrain:  epoch  0, batch   122 | loss: 2.5559974MixupTrain:  epoch  0, batch   123 | loss: 3.6237073MixupTrain:  epoch  0, batch   124 | loss: 2.7284913MixupTrain:  epoch  0, batch   125 | loss: 2.2619472MixupTrain:  epoch  0, batch   126 | loss: 2.1535671MixupTrain:  epoch  0, batch   127 | loss: 2.8793504MixupTrain:  epoch  0, batch   128 | loss: 2.9572005MixupTrain:  epoch  0, batch   129 | loss: 2.8016887MixupTrain:  epoch  0, batch   130 | loss: 2.4780798MixupTrain:  epoch  0, batch   131 | loss: 2.7933383MixupTrain:  epoch  0, batch   133 | loss: 2.6854398MixupTrain:  epoch  0, batch   134 | loss: 3.0425804MixupTrain:  epoch  0, batch   135 | loss: 2.6958456MixupTrain:  epoch  0, batch   136 | loss: 3.5324781MixupTrain:  epoch  0, batch   137 | loss: 3.1779160MixupTrain:  epoch  0, batch   138 | loss: 2.5218163MixupTrain:  epoch  0, batch   139 | loss: 2.7507930MixupTrain:  epoch  0, batch   141 | loss: 2.1662707MixupTrain:  epoch  0, batch   142 | loss: 2.8636789MixupTrain:  epoch  0, batch   143 | loss: 3.0705512MixupTrain:  epoch  0, batch   144 | loss: 3.2235160MixupTrain:  epoch  0, batch   145 | loss: 2.2847431MixupTrain:  epoch  0, batch   146 | loss: 2.4038374MixupTrain:  epoch  0, batch   147 | loss: 2.6859641MixupTrain:  epoch  0, batch   148 | loss: 2.6824818MixupTrain:  epoch  0, batch   149 | loss: 3.3641121MixupTrain:  epoch  0, batch   151 | loss: 2.4713967MixupTrain:  epoch  0, batch   152 | loss: 2.2673559MixupTrain:  epoch  0, batch   153 | loss: 2.9616010MixupTrain:  epoch  0, batch   154 | loss: 2.5040388MixupTrain:  epoch  0, batch   155 | loss: 3.0314400MixupTrain:  epoch  0, batch   156 | loss: 2.2146306MixupTrain:  epoch  0, batch   157 | loss: 2.4587383MixupTrain:  epoch  0, batch   158 | loss: 2.4391475MixupTrain:  epoch  0, batch   159 | loss: 2.9115748MixupTrain:  epoch  0, batch   160 | loss: 2.6078753MixupTrain:  epoch  0, batch   162 | loss: 2.2532103MixupTrain:  epoch  0, batch   163 | loss: 2.6546547MixupTrain:  epoch  0, batch   164 | loss: 2.6513209MixupTrain:  epoch  0, batch   165 | loss: 2.3913906MixupTrain:  epoch  0, batch   166 | loss: 2.3225808MixupTrain:  epoch  0, batch   167 | loss: 2.7356243MixupTrain:  epoch  0, batch   168 | loss: 2.6183889MixupTrain:  epoch  0, batch   169 | loss: 2.5916505MixupTrain:  epoch  0, batch   170 | loss: 2.6952095MixupTrain:  epoch  0, batch   172 | loss: 2.4402575MixupTrain:  epoch  0, batch   173 | loss: 2.9481397MixupTrain:  epoch  0, batch   175 | loss: 2.3585873MixupTrain:  epoch  0, batch   176 | loss: 2.7386937MixupTrain:  epoch  0, batch   177 | loss: 2.3969021MixupTrain:  epoch  0, batch   178 | loss: 3.0785136MixupTrain:  epoch  0, batch   180 | loss: 2.4709096MixupTrain:  epoch  0, batch   181 | loss: 2.3624637MixupTrain:  epoch  0, batch   182 | loss: 2.2978394MixupTrain:  epoch  0, batch   183 | loss: 2.0487618MixupTrain:  epoch  0, batch   184 | loss: 2.2396078MixupTrain:  epoch  0, batch   185 | loss: 2.4201279MixupTrain:  epoch  0, batch   186 | loss: 2.7609744MixupTrain:  epoch  0, batch   187 | loss: 2.7633822MixupTrain:  epoch  0, batch   188 | loss: 2.3180120MixupTrain:  epoch  0, batch   189 | loss: 2.6820219MixupTrain:  epoch  0, batch   190 | loss: 2.1580610MixupTrain:  epoch  0, batch   192 | loss: 2.4771495MixupTrain:  epoch  0, batch   194 | loss: 2.6517911MixupTrain:  epoch  0, batch   195 | loss: 2.4838190MixupTrain:  epoch  0, batch   196 | loss: 2.4714458MixupTrain:  epoch  0, batch   197 | loss: 2.2863040MixupTrain:  epoch  0, batch   198 | loss: 2.4004128MixupTrain:  epoch  0, batch   199 | loss: 2.7227206MixupTrain:  epoch  0, batch   200 | loss: 2.3657806MixupTrain:  epoch  0, batch   202 | loss: 2.3233449MixupTrain:  epoch  0, batch   203 | loss: 2.2776203MixupTrain:  epoch  0, batch   204 | loss: 2.5099132MixupTrain:  epoch  0, batch   205 | loss: 2.5169802MixupTrain:  epoch  0, batch   206 | loss: 2.4132376MixupTrain:  epoch  0, batch   207 | loss: 2.4264617MixupTrain:  epoch  0, batch   208 | loss: 2.4889994MixupTrain:  epoch  0, batch   209 | loss: 2.5404568MixupTrain:  epoch  0, batch   211 | loss: 2.8407016MixupTrain:  epoch  0, batch   212 | loss: 2.8211520MixupTrain:  epoch  0, batch   214 | loss: 3.2147737MixupTrain:  epoch  0, batch   215 | loss: 1.8647321MixupTrain:  epoch  0, batch   216 | loss: 2.3190811MixupTrain:  epoch  0, batch   217 | loss: 2.5328903MixupTrain:  epoch  0, batch   218 | loss: 2.6588278MixupTrain:  epoch  0, batch   220 | loss: 2.5849931MixupTrain:  epoch  0, batch   222 | loss: 2.0556538MixupTrain:  epoch  0, batch   223 | loss: 2.3764894MixupTrain:  epoch  0, batch   224 | loss: 2.6689491MixupTrain:  epoch  0, batch   225 | loss: 2.4069657MixupTrain:  epoch  0, batch   226 | loss: 2.3755302MixupTrain:  epoch  0, batch   227 | loss: 2.7460942MixupTrain:  epoch  0, batch   228 | loss: 2.5320852MixupTrain:  epoch  0, batch   229 | loss: 2.7277288MixupTrain:  epoch  0, batch   230 | loss: 2.0096805MixupTrain:  epoch  0, batch   231 | loss: 2.6641059MixupTrain:  epoch  0, batch   232 | loss: 2.8193662MixupTrain:  epoch  0, batch   233 | loss: 2.2551999MixupTrain:  epoch  0, batch   234 | loss: 2.3939590MixupTrain:  epoch  0, batch   235 | loss: 2.4407449MixupTrain:  epoch  0, batch   236 | loss: 2.0875466MixupTrain:  epoch  0, batch   237 | loss: 2.8328295MixupTrain:  epoch  0, batch   240 | loss: 2.9675705MixupTrain:  epoch  0, batch   241 | loss: 2.1338997MixupTrain:  epoch  0, batch   242 | loss: 2.2760947MixupTrain:  epoch  0, batch   243 | loss: 2.7043309MixupTrain:  epoch  0, batch   244 | loss: 2.7345080MixupTrain:  epoch  0, batch   245 | loss: 2.5913310MixupTrain:  epoch  0, batch   246 | loss: 2.3222227MixupTrain:  epoch  0, batch   247 | loss: 2.2952986MixupTrain:  epoch  0, batch   248 | loss: 2.7683070MixupTrain:  epoch  0, batch   249 | loss: 2.2856789MixupTrain:  epoch  0, batch   250 | loss: 2.3636739MixupTrain:  epoch  0, batch   251 | loss: 2.5328918MixupTrain:  epoch  0, batch   252 | loss: 2.2985742MixupTrain:  epoch  0, batch   253 | loss: 2.2462339MixupTrain:  epoch  0, batch   254 | loss: 2.6353512MixupTrain:  epoch  0, batch   255 | loss: 2.2823863MixupTrain:  epoch  0, batch   256 | loss: 2.6835623MixupTrain:  epoch  0, batch   257 | loss: 2.4023685MixupTrain:  epoch  0, batch   258 | loss: 2.6206784MixupTrain:  epoch  0, batch   259 | loss: 2.2243905MixupTrain:  epoch  0, batch   260 | loss: 2.4723768MixupTrain:  epoch  0, batch   261 | loss: 2.5847483MixupTrain:  epoch  0, batch   262 | loss: 2.7556181MixupTrain:  epoch  0, batch   263 | loss: 2.7116480MixupTrain:  epoch  0, batch   265 | loss: 2.8687897MixupTrain:  epoch  0, batch   266 | loss: 2.5868187MixupTrain:  epoch  0, batch   267 | loss: 2.2409542MixupTrain:  epoch  0, batch   270 | loss: 2.6079988MixupTrain:  epoch  0, batch   271 | loss: 2.0291755MixupTrain:  epoch  0, batch   272 | loss: 2.3467412MixupTrain:  epoch  0, batch   273 | loss: 2.2877178MixupTrain:  epoch  0, batch   276 | loss: 2.2702456MixupTrain:  epoch  0, batch   277 | loss: 2.4258142MixupTrain:  epoch  0, batch   278 | loss: 2.6905577MixupTrain:  epoch  0, batch   279 | loss: 2.3512144MixupTrain:  epoch  0, batch   280 | loss: 2.6542068MixupTrain:  epoch  0, batch   283 | loss: 2.1022608MixupTrain:  epoch  0, batch   284 | loss: 2.1745672MixupTrain:  epoch  0, batch   285 | loss: 2.3130143MixupTrain:  epoch  0, batch   286 | loss: 2.7649119MixupTrain:  epoch  0, batch   288 | loss: 2.2980046MixupTrain:  epoch  0, batch   289 | loss: 2.3710039MixupTrain:  epoch  0, batch   291 | loss: 2.4339416MixupTrain:  epoch  0, batch   292 | loss: 2.7876058MixupTrain:  epoch  0, batch   293 | loss: 2.5063856MixupTrain:  epoch  0, batch   294 | loss: 2.5038126MixupTrain:  epoch  0, batch   295 | loss: 2.3339033MixupTrain:  epoch  0, batch   296 | loss: 2.1744070MixupTrain:  epoch  0, batch   297 | loss: 2.5253434MixupTrain:  epoch  0, batch   299 | loss: 2.5550804MixupTrain:  epoch  0, batch   300 | loss: 2.3629060MixupTrain:  epoch  0, batch   301 | loss: 2.4866836MixupTrain:  epoch  0, batch   303 | loss: 2.3525410MixupTrain:  epoch  0, batch   304 | loss: 2.6664066MixupTrain:  epoch  0, batch   305 | loss: 2.7295647MixupTrain:  epoch  0, batch   306 | loss: 2.2148886MixupTrain:  epoch  0, batch   307 | loss: 2.8107581MixupTrain:  epoch  0, batch   308 | loss: 2.3803716MixupTrain:  epoch  0, batch   309 | loss: 2.2923584MixupTrain:  epoch  0, batch   310 | loss: 2.3875360MixupTrain:  epoch  0, batch   311 | loss: 2.6904902MixupTrain:  epoch  0, batch   312 | loss: 2.4366732MixupTrain:  epoch  0, batch   313 | loss: 2.7571905MixupTrain:  epoch  0, batch   314 | loss: 2.5518532MixupTrain:  epoch  0, batch   315 | loss: 2.2284329MixupTrain:  epoch  0, batch   316 | loss: 1.9916720MixupTrain:  epoch  0, batch   317 | loss: 2.0312269MixupTrain:  epoch  0, batch   318 | loss: 2.7336693MixupTrain:  epoch  0, batch   319 | loss: 2.2927661MixupTrain:  epoch  0, batch   320 | loss: 2.3522611MixupTrain:  epoch  0, batch   321 | loss: 2.0992594MixupTrain:  epoch  0, batch   322 | loss: 2.6666627MixupTrain:  epoch  0, batch   324 | loss: 2.2068102MixupTrain:  epoch  0, batch   325 | loss: 2.3712239MixupTrain:  epoch  0, batch   326 | loss: 2.4840329MixupTrain:  epoch  0, batch   328 | loss: 2.4634469MixupTrain:  epoch  0, batch   330 | loss: 2.3367040MixupTrain:  epoch  0, batch   331 | loss: 2.7606666MixupTrain:  epoch  0, batch   332 | loss: 2.5528605MixupTrain:  epoch  0, batch   333 | loss: 2.2834840MixupTrain:  epoch  0, batch   334 | loss: 2.3634703MixupTrain:  epoch  0, batch   335 | loss: 2.6571927MixupTrain:  epoch  0, batch   336 | loss: 2.7099223MixupTrain:  epoch  0, batch   337 | loss: 2.4465446MixupTrain:  epoch  0, batch   338 | loss: 2.4340286MixupTrain:  epoch  0, batch   339 | loss: 2.2172663MixupTrain:  epoch  0, batch   340 | loss: 2.7364657MixupTrain:  epoch  0, batch   342 | loss: 2.1249692MixupTrain:  epoch  0, batch   343 | loss: 2.2284286MixupTrain:  epoch  0, batch   344 | loss: 2.4952717MixupTrain:  epoch  0, batch   345 | loss: 2.4691343MixupTrain:  epoch  0, batch   347 | loss: 2.3432612MixupTrain:  epoch  0, batch   348 | loss: 2.4392540MixupTrain:  epoch  0, batch   349 | loss: 2.3174553MixupTrain:  epoch  0, batch   350 | loss: 2.5712786MixupTrain:  epoch  0, batch   351 | loss: 2.3074424MixupTrain:  epoch  0, batch   352 | loss: 2.3051662MixupTrain:  epoch  0, batch   353 | loss: 2.2210689MixupTrain:  epoch  0, batch   354 | loss: 2.5735016MixupTrain:  epoch  0, batch   355 | loss: 2.5226607MixupTrain:  epoch  0, batch   356 | loss: 2.3925662MixupTrain:  epoch  0, batch   357 | loss: 2.2453942MixupTrain:  epoch  0, batch   358 | loss: 2.0929646MixupTrain:  epoch  0, batch   361 | loss: 2.3678253MixupTrain:  epoch  0, batch   362 | loss: 2.4519675MixupTrain:  epoch  0, batch   363 | loss: 2.5394564MixupTrain:  epoch  0, batch   364 | loss: 2.3131967MixupTrain:  epoch  0, batch   365 | loss: 2.6224160MixupTrain:  epoch  0, batch   366 | loss: 2.1553164MixupTrain:  epoch  0, batch   367 | loss: 2.3732178MixupTrain:  epoch  0, batch   368 | loss: 2.3187847MixupTrain:  epoch  0, batch   370 | loss: 2.4891376MixupTrain:  epoch  0, batch   371 | loss: 2.3246195MixupTrain:  epoch  0, batch   372 | loss: 2.5258336MixupTrain:  epoch  0, batch   374 | loss: 2.1662693MixupTrain:  epoch  0, batch   375 | loss: 2.1917434MixupTrain:  epoch  0, batch   377 | loss: 2.3337407MixupTrain:  epoch  0, batch   378 | loss: 2.2376702MixupTrain:  epoch  0, batch   379 | loss: 2.9546480MixupTrain:  epoch  0, batch   380 | loss: 2.0529408MixupTrain:  epoch  0, batch   381 | loss: 2.7956524MixupTrain:  epoch  0, batch   382 | loss: 2.5873432MixupTrain:  epoch  0, batch   383 | loss: 2.4609871MixupTrain:  epoch  0, batch   384 | loss: 2.4912548MixupTrain:  epoch  0, batch   385 | loss: 2.4084578MixupTrain:  epoch  0, batch   386 | loss: 2.3331394MixupTrain:  epoch  0, batch   387 | loss: 2.4832373MixupTrain:  epoch  0, batch   389 | loss: 2.5557709MixupTrain:  epoch  0, batch   390 | loss: 2.2886267MixupTrain:  epoch  0, batch   391 | loss: 2.4033751MixupTrain:  epoch  0, batch   392 | loss: 2.4754119MixupTrain:  epoch  0, batch   394 | loss: 2.1293695MixupTrain:  epoch  0, batch   395 | loss: 2.5612202MixupTrain:  epoch  0, batch   396 | loss: 2.3313408MixupTrain:  epoch  0, batch   397 | loss: 2.2342560MixupTrain:  epoch  0, batch   398 | loss: 2.4410033MixupTrain:  epoch  0, batch   399 | loss: 2.3233495MixupTrain:  epoch  0, batch   400 | loss: 2.1452484MixupTrain:  epoch  0, batch   401 | loss: 2.3104773MixupTrain:  epoch  0, batch   402 | loss: 2.6868987MixupTrain:  epoch  0, batch   403 | loss: 2.4081745MixupTrain:  epoch  0, batch   406 | loss: 2.5459490MixupTrain:  epoch  0, batch   407 | loss: 2.2432346MixupTrain:  epoch  0, batch   408 | loss: 2.3164854MixupTrain:  epoch  0, batch   409 | loss: 2.5594330MixupTrain:  epoch  0, batch   410 | loss: 2.4943264MixupTrain:  epoch  0, batch   411 | loss: 2.5589366MixupTrain:  epoch  0, batch   412 | loss: 2.0740728MixupTrain:  epoch  0, batch   414 | loss: 2.1448078MixupTrain:  epoch  0, batch   415 | loss: 2.5230269MixupTrain:  epoch  0, batch   417 | loss: 2.5304282MixupTrain:  epoch  0, batch   419 | loss: 2.5861926MixupTrain:  epoch  0, batch   420 | loss: 2.4458892MixupTrain:  epoch  0, batch   422 | loss: 2.2950802MixupTrain:  epoch  0, batch   423 | loss: 2.4970751MixupTrain:  epoch  0, batch   424 | loss: 2.2108669MixupTrain:  epoch  0, batch   425 | loss: 2.4769132MixupTrain:  epoch  0, batch   426 | loss: 2.1781492MixupTrain:  epoch  0, batch   427 | loss: 2.9173493MixupTrain:  epoch  0, batch   428 | loss: 2.3614900MixupTrain:  epoch  0, batch   431 | loss: 2.4001224MixupTrain:  epoch  0, batch   432 | loss: 2.6711898MixupTrain:  epoch  0, batch   433 | loss: 2.5098276MixupTrain:  epoch  0, batch   434 | loss: 2.1412916MixupTrain:  epoch  0, batch   435 | loss: 2.4227605MixupTrain:  epoch  0, batch   437 | loss: 2.3135085MixupTrain:  epoch  0, batch   438 | loss: 2.1940794MixupTrain:  epoch  0, batch   439 | loss: 2.3159075MixupTrain:  epoch  0, batch   440 | loss: 2.5308056MixupTrain:  epoch  0, batch   441 | loss: 2.5701532MixupTrain:  epoch  0, batch   442 | loss: 2.4931409MixupTrain:  epoch  0, batch   443 | loss: 2.3577223MixupTrain:  epoch  0, batch   444 | loss: 2.3368506MixupTrain:  epoch  0, batch   445 | loss: 2.2509930MixupTrain:  epoch  0, batch   446 | loss: 2.0583801MixupTrain:  epoch  0, batch   447 | loss: 2.2655408MixupTrain:  epoch  0, batch   448 | loss: 2.2916064MixupTrain:  epoch  0, batch   449 | loss: 2.4931295MixupTrain:  epoch  0, batch   450 | loss: 2.2528181MixupTrain:  epoch  0, batch   451 | loss: 2.3112507MixupTrain:  epoch  0, batch   453 | loss: 2.2828734MixupTrain:  epoch  0, batch   455 | loss: 2.2475696MixupTrain:  epoch  0, batch   456 | loss: 2.6535807MixupTrain:  epoch  0, batch   457 | loss: 2.3392572MixupTrain:  epoch  0, batch   458 | loss: 2.3681335MixupTrain:  epoch  0, batch   459 | loss: 2.3557708MixupTrain:  epoch  0, batch   460 | loss: 2.3363233MixupTrain:  epoch  0, batch   461 | loss: 2.2323952MixupTrain:  epoch  0, batch   463 | loss: 2.4147961MixupTrain:  epoch  0, batch   464 | loss: 2.0386143MixupTrain:  epoch  0, batch   465 | loss: 2.1820292MixupTrain:  epoch  0, batch   466 | loss: 2.5054626MixupTrain:  epoch  0, batch   467 | loss: 2.7048526MixupTrain:  epoch  0, batch   468 | loss: 2.2284157MixupTrain:  epoch  0, batch   469 | loss: 2.5732837MixupTrain:  epoch  0, batch   470 | loss: 2.5941129MixupTrain:  epoch  0, batch   471 | loss: 2.2955170MixupTrain:  epoch  0, batch   472 | loss: 2.5560751MixupTrain:  epoch  0, batch   473 | loss: 2.5423436MixupTrain:  epoch  0, batch   474 | loss: 2.8610849MixupTrain:  epoch  0, batch   475 | loss: 2.5193596MixupTrain:  epoch  0, batch   476 | loss: 2.2517080MixupTrain:  epoch  0, batch   477 | loss: 2.4529886MixupTrain:  epoch  0, batch   478 | loss: 2.2666674MixupTrain:  epoch  0, batch   479 | loss: 2.2277174MixupTrain:  epoch  0, batch   480 | loss: 2.0530384MixupTrain:  epoch  0, batch   481 | loss: 2.2145739MixupTrain:  epoch  0, batch   482 | loss: 2.4766555MixupTrain:  epoch  0, batch   483 | loss: 2.2532482MixupTrain:  epoch  0, batch   484 | loss: 2.3317533MixupTrain:  epoch  0, batch   485 | loss: 2.1642349MixupTrain:  epoch  0, batch   487 | loss: 2.4000850MixupTrain:  epoch  0, batch   488 | loss: 2.0160992MixupTrain:  epoch  0, batch   489 | loss: 2.7859578MixupTrain:  epoch  0, batch   490 | loss: 2.6993523MixupTrain:  epoch  0, batch   491 | loss: 2.2337255MixupTrain:  epoch  0, batch   492 | loss: 2.3067069MixupTrain:  epoch  0, batch   493 | loss: 2.1928058MixupTrain:  epoch  0, batch   494 | loss: 2.2996387MixupTrain:  epoch  0, batch   496 | loss: 2.0352449MixupTrain:  epoch  0, batch   497 | loss: 2.6092572MixupTrain:  epoch  0, batch   498 | loss: 2.6377618MixupTrain:  epoch  0, batch   499 | loss: 2.1534221MixupTrain:  epoch  0, batch   500 | loss: 2.7323604MixupTrain:  epoch  0, batch   502 | loss: 2.6039133MixupTrain:  epoch  0, batch   504 | loss: 2.1855798MixupTrain:  epoch  0, batch   505 | loss: 2.0530534MixupTrain:  epoch  0, batch   506 | loss: 2.3168678MixupTrain:  epoch  0, batch   507 | loss: 2.2061973MixupTrain:  epoch  0, batch   508 | loss: 1.9475083MixupTrain:  epoch  0, batch   509 | loss: 2.5181859MixupTrain:  epoch  0, batch   510 | loss: 2.1380246MixupTrain:  epoch  0, batch   511 | loss: 2.2129288MixupTrain:  epoch  0, batch   512 | loss: 2.3893628MixupTrain:  epoch  0, batch   513 | loss: 2.4511266MixupTrain:  epoch  0, batch   514 | loss: 2.3228364MixupTrain:  epoch  0, batch   515 | loss: 2.2327185MixupTrain:  epoch  0, batch   516 | loss: 2.4733570MixupTrain:  epoch  0, batch   517 | loss: 2.4650273MixupTrain:  epoch  0, batch   518 | loss: 2.4985127MixupTrain:  epoch  0, batch   519 | loss: 2.5623653MixupTrain:  epoch  0, batch   520 | loss: 2.4032099MixupTrain:  epoch  0, batch   521 | loss: 2.5140922MixupTrain:  epoch  0, batch   522 | loss: 2.1936517MixupTrain:  epoch  0, batch   523 | loss: 2.3868191MixupTrain:  epoch  0, batch   525 | loss: 2.2622342MixupTrain:  epoch  0, batch   526 | loss: 2.4042344MixupTrain:  epoch  0, batch   527 | loss: 2.2441432MixupTrain:  epoch  0, batch   528 | loss: 2.2940984MixupTrain:  epoch  0, batch   529 | loss: 2.2639444MixupTrain:  epoch  0, batch   531 | loss: 2.3201828MixupTrain:  epoch  0, batch   532 | loss: 2.4256516MixupTrain:  epoch  0, batch   533 | loss: 2.4913480MixupTrain:  epoch  0, batch   534 | loss: 2.4944715MixupTrain:  epoch  0, batch   535 | loss: 2.4858565MixupTrain:  epoch  0, batch   537 | loss: 2.4953499MixupTrain:  epoch  0, batch   538 | loss: 2.2850151MixupTrain:  epoch  0, batch   539 | loss: 2.2465563MixupTrain:  epoch  0, batch   540 | loss: 2.0480766MixupTrain:  epoch  0, batch   541 | loss: 2.2758272MixupTrain:  epoch  0, batch   542 | loss: 2.3127518MixupTrain:  epoch  0, batch   543 | loss: 2.5965405MixupTrain:  epoch  0, batch   544 | loss: 2.6359713MixupTrain:  epoch  0, batch   545 | loss: 2.0909510MixupTrain:  epoch  0, batch   546 | loss: 2.2935402MixupTrain:  epoch  0, batch   547 | loss: 2.4129586MixupTrain:  epoch  0, batch   548 | loss: 2.1740053MixupTrain:  epoch  0, batch   549 | loss: 2.2898350MixupTrain:  epoch  0, batch   550 | loss: 2.4006159MixupTrain:  epoch  0, batch   551 | loss: 2.4364700MixupTrain:  epoch  0, batch   552 | loss: 2.4453037MixupTrain:  epoch  0, batch   553 | loss: 2.1622577MixupTrain:  epoch  0, batch   554 | loss: 2.2107954MixupTrain:  epoch  0, batch   555 | loss: 2.1284108MixupTrain:  epoch  0, batch   556 | loss: 2.5257740MixupTrain:  epoch  0, batch   558 | loss: 2.3489501MixupTrain:  epoch  0, batch   559 | loss: 2.3570461MixupTrain:  epoch  0, batch   560 | loss: 2.4065373MixupTrain:  epoch  0, batch   561 | loss: 1.9816407MixupTrain:  epoch  0, batch   562 | loss: 2.6446807MixupTrain:  epoch  0, batch   563 | loss: 2.3150792MixupTrain:  epoch  0, batch   564 | loss: 2.0205622MixupTrain:  epoch  0, batch   565 | loss: 2.3889623MixupTrain:  epoch  0, batch   566 | loss: 2.4876709MixupTrain:  epoch  0, batch   567 | loss: 2.1192369MixupTrain:  epoch  0, batch   568 | loss: 2.0467896MixupTrain:  epoch  0, batch   570 | loss: 2.4221704MixupTrain:  epoch  0, batch   571 | loss: 2.2384868MixupTrain:  epoch  0, batch   573 | loss: 2.4521689MixupTrain:  epoch  0, batch   574 | loss: 2.1413164MixupTrain:  epoch  0, batch   575 | loss: 2.2655678MixupTrain:  epoch  0, batch   576 | loss: 2.3685210MixupTrain:  epoch  0, batch   577 | loss: 2.9380972MixupTrain:  epoch  0, batch   578 | loss: 2.1645770MixupTrain:  epoch  0, batch   579 | loss: 2.2259345MixupTrain:  epoch  0, batch   580 | loss: 2.4696364MixupTrain:  epoch  0, batch   581 | loss: 2.4460835MixupTrain:  epoch  0, batch   582 | loss: 2.2151914MixupTrain:  epoch  0, batch   583 | loss: 2.2951391MixupTrain:  epoch  0, batch   586 | loss: 2.1718793MixupTrain:  epoch  0, batch   589 | loss: 2.2309613MixupTrain:  epoch  0, batch   590 | loss: 2.2995784MixupTrain:  epoch  0, batch   591 | loss: 2.1656125MixupTrain:  epoch  0, batch   592 | loss: 2.3394396MixupTrain:  epoch  0, batch   593 | loss: 2.4255230MixupTrain:  epoch  0, batch   594 | loss: 2.2610998MixupTrain:  epoch  0, batch   595 | loss: 2.3477206MixupTrain:  epoch  0, batch   596 | loss: 2.3826485MixupTrain:  epoch  0, batch   598 | loss: 2.3989887MixupTrain:  epoch  0, batch   599 | loss: 2.4378452MixupTrain:  epoch  0, batch   600 | loss: 2.3292882MixupTrain:  epoch  0, batch   601 | loss: 2.3065267MixupTrain:  epoch  0, batch   602 | loss: 2.8438354MixupTrain:  epoch  0, batch   603 | loss: 2.5300283MixupTrain:  epoch  0, batch   606 | loss: 2.3531375MixupTrain:  epoch  0, batch   608 | loss: 2.2391095MixupTrain:  epoch  0, batch   609 | loss: 2.7139196MixupTrain:  epoch  0, batch   610 | loss: 2.8466558MixupTrain:  epoch  0, batch   611 | loss: 2.6385570MixupTrain:  epoch  0, batch   612 | loss: 2.0640275MixupTrain:  epoch  0, batch   613 | loss: 2.0186982MixupTrain:  epoch  0, batch   614 | loss: 2.3419244MixupTrain:  epoch  0, batch   615 | loss: 2.2592337MixupTrain:  epoch  0, batch   616 | loss: 2.0021067MixupTrain:  epoch  0, batch   617 | loss: 2.4236164MixupTrain:  epoch  0, batch   618 | loss: 2.2455907MixupTrain:  epoch  0, batch   619 | loss: 2.1725235MixupTrain:  epoch  0, batch   620 | loss: 2.2960744MixupTrain:  epoch  0, batch   621 | loss: 2.2773118MixupTrain:  epoch  0, batch   622 | loss: 2.3987722MixupTrain:  epoch  0, batch   623 | loss: 2.4982677MixupTrain:  epoch  0, batch   624 | loss: 2.3107059MixupTrain:  epoch  0, batch   625 | loss: 2.2793896MixupTrain:  epoch  0, batch   626 | loss: 2.1429625MixupTrain:  epoch  0, batch   627 | loss: 2.0246506MixupTrain:  epoch  0, batch   628 | loss: 2.6879759MixupTrain:  epoch  0, batch   629 | loss: 2.3580439MixupTrain:  epoch  0, batch   631 | loss: 2.4555483MixupTrain:  epoch  0, batch   632 | loss: 2.3830490MixupTrain:  epoch  0, batch   633 | loss: 2.2948561MixupTrain:  epoch  0, batch   634 | loss: 2.4228442MixupTrain:  epoch  0, batch   635 | loss: 2.2135208MixupTrain:  epoch  0, batch   636 | loss: 2.3182533MixupTrain:  epoch  0, batch   637 | loss: 2.4777932MixupTrain:  epoch  0, batch   638 | loss: 2.5222399MixupTrain:  epoch  0, batch   639 | loss: 2.6153731MixupTrain:  epoch  0, batch   640 | loss: 2.2217422MixupTrain:  epoch  0, batch   641 | loss: 2.2312648MixupTrain:  epoch  0, batch   642 | loss: 2.2004676MixupTrain:  epoch  0, batch   644 | loss: 2.2617512MixupTrain:  epoch  0, batch   645 | loss: 2.3417630MixupTrain:  epoch  0, batch   647 | loss: 2.6254864MixupTrain:  epoch  0, batch   648 | loss: 2.0850444MixupTrain:  epoch  0, batch   650 | loss: 2.1833558MixupTrain:  epoch  0, batch   651 | loss: 2.5557485MixupTrain:  epoch  0, batch   653 | loss: 2.7025511MixupTrain:  epoch  0, batch   654 | loss: 2.6178637MixupTrain:  epoch  0, batch   656 | loss: 2.1449447MixupTrain:  epoch  0, batch   657 | loss: 2.2511117MixupTrain:  epoch  0, batch   658 | loss: 2.2800844MixupTrain:  epoch  0, batch   659 | loss: 2.3825517MixupTrain:  epoch  0, batch   661 | loss: 2.2628484MixupTrain:  epoch  0, batch   662 | loss: 2.4799089MixupTrain:  epoch  0, batch   663 | loss: 2.2768834MixupTrain:  epoch  0, batch   664 | loss: 2.4066973MixupTrain:  epoch  0, batch   665 | loss: 2.5935993MixupTrain:  epoch  0, batch   666 | loss: 2.3103528MixupTrain:  epoch  0, batch   667 | loss: 2.4065242MixupTrain:  epoch  0, batch   668 | loss: 2.3665941MixupTrain:  epoch  0, batch   669 | loss: 2.1707869MixupTrain:  epoch  0, batch   670 | loss: 2.5962622MixupTrain:  epoch  0, batch   671 | loss: 2.3866816MixupTrain:  epoch  0, batch   672 | loss: 2.1728978MixupTrain:  epoch  0, batch   673 | loss: 2.3889933MixupTrain:  epoch  0, batch   675 | loss: 2.2058730MixupTrain:  epoch  0, batch   677 | loss: 1.9775774MixupTrain:  epoch  0, batch   678 | loss: 2.3954508MixupTrain:  epoch  0, batch   679 | loss: 2.6354699MixupTrain:  epoch  0, batch   680 | loss: 2.3486686MixupTrain:  epoch  0, batch   681 | loss: 2.0981765MixupTrain:  epoch  0, batch   682 | loss: 2.2915134MixupTrain:  epoch  0, batch   684 | loss: 2.1965930MixupTrain:  epoch  0, batch   685 | loss: 2.3651385MixupTrain:  epoch  0, batch   686 | loss: 2.5257666MixupTrain:  epoch  0, batch   687 | loss: 2.5456018MixupTrain:  epoch  0, batch   688 | loss: 2.2519166MixupTrain:  epoch  0, batch   689 | loss: 2.2037325MixupTrain:  epoch  0, batch   690 | loss: 2.3501680MixupTrain:  epoch  0, batch   691 | loss: 2.0911198MixupTrain:  epoch  0, batch   692 | loss: 2.2345476MixupTrain:  epoch  0, batch   693 | loss: 2.3763072MixupTrain:  epoch  0, batch   694 | loss: 2.0409675MixupTrain:  epoch  0, batch   695 | loss: 2.1860297MixupTrain:  epoch  0, batch   696 | loss: 2.1961164MixupTrain:  epoch  0, batch   697 | loss: 2.3163538MixupTrain:  epoch  0, batch   698 | loss: 2.5275748MixupTrain:  epoch  0, batch   699 | loss: 2.2969632MixupTrain:  epoch  0, batch   700 | loss: 2.1781998MixupTrain:  epoch  0, batch   701 | loss: 2.1085603MixupTrain:  epoch  0, batch   702 | loss: 2.2695856MixupTrain:  epoch  0, batch   703 | loss: 2.2235854MixupTrain:  epoch  0, batch   704 | loss: 2.0914514MixupTrain:  epoch  0, batch   705 | loss: 2.2829885MixupTrain:  epoch  0, batch   708 | loss: 2.3794339MixupTrain:  epoch  0, batch   710 | loss: 2.2511160MixupTrain:  epoch  0, batch   711 | loss: 2.5336299MixupTrain:  epoch  0, batch   712 | loss: 2.2860479MixupTrain:  epoch  0, batch   713 | loss: 2.4312444MixupTrain:  epoch  0, batch   714 | loss: 2.5168958MixupTrain:  epoch  0, batch   715 | loss: 2.5287611MixupTrain:  epoch  0, batch   716 | loss: 2.5977120MixupTrain:  epoch  0, batch   717 | loss: 2.3814008MixupTrain:  epoch  0, batch   718 | loss: 2.2674401MixupTrain:  epoch  0, batch   719 | loss: 2.3508158MixupTrain:  epoch  0, batch   720 | loss: 2.4095521MixupTrain:  epoch  0, batch   721 | loss: 2.6981156MixupTrain:  epoch  0, batch   722 | loss: 2.7219071MixupTrain:  epoch  0, batch   724 | loss: 2.3266425MixupTrain:  epoch  0, batch   725 | loss: 2.2428579MixupTrain:  epoch  0, batch   726 | loss: 2.5658615MixupTrain:  epoch  0, batch   728 | loss: 2.6205869MixupTrain:  epoch  0, batch   729 | loss: 2.1649971MixupTrain:  epoch  0, batch   730 | loss: 2.5296268MixupTrain:  epoch  0, batch   731 | loss: 2.4218273MixupTrain:  epoch  0, batch   732 | loss: 2.2944541MixupTrain:  epoch  0, batch   733 | loss: 2.1347370MixupTrain:  epoch  0, batch   735 | loss: 2.1411841MixupTrain:  epoch  0, batch   736 | loss: 2.3478324MixupTrain:  epoch  0, batch   737 | loss: 2.2233043MixupTrain:  epoch  0, batch   738 | loss: 2.3544824MixupTrain:  epoch  0, batch   739 | loss: 2.2866168MixupTrain:  epoch  0, batch   740 | loss: 2.2371151MixupTrain:  epoch  0, batch   741 | loss: 2.1331854MixupTrain:  epoch  0, batch   742 | loss: 2.0238299MixupTrain:  epoch  0, batch   743 | loss: 2.2433777MixupTrain:  epoch  0, batch   744 | loss: 2.1760163MixupTrain:  epoch  0, batch   745 | loss: 2.2249341MixupTrain:  epoch  0, batch   746 | loss: 2.1531224MixupTrain:  epoch  0, batch   747 | loss: 2.3589129MixupTrain:  epoch  0, batch   748 | loss: 2.5440989MixupTrain:  epoch  0, batch   749 | loss: 2.2849731MixupTrain:  epoch  0, batch   751 | loss: 2.4038339MixupTrain:  epoch  0, batch   753 | loss: 2.4098494MixupTrain:  epoch  0, batch   755 | loss: 2.2787209MixupTrain:  epoch  0, batch   757 | loss: 2.4321408MixupTrain:  epoch  0, batch   758 | loss: 2.3440094MixupTrain:  epoch  0, batch   759 | loss: 1.9287285MixupTrain:  epoch  0, batch   760 | loss: 2.5143631MixupTrain:  epoch  0, batch   761 | loss: 2.3439584MixupTrain:  epoch  0, batch   762 | loss: 2.5629385MixupTrain:  epoch  0, batch   764 | loss: 2.1935999MixupTrain:  epoch  0, batch   765 | loss: 2.2095706MixupTrain:  epoch  0, batch   766 | loss: 2.2667561MixupTrain:  epoch  0, batch   767 | loss: 2.3558724MixupTrain:  epoch  0, batch   768 | loss: 2.1836493MixupTrain:  epoch  0, batch   769 | loss: 2.4391537MixupTrain:  epoch  0, batch   771 | loss: 2.3142247MixupTrain:  epoch  0, batch   772 | loss: 2.4529533MixupTrain:  epoch  0, batch   773 | loss: 2.0442796MixupTrain:  epoch  0, batch   774 | loss: 2.5244794MixupTrain:  epoch  0, batch   775 | loss: 2.1571124MixupTrain:  epoch  0, batch   776 | loss: 2.4314218MixupTrain:  epoch  0, batch   777 | loss: 2.4936113MixupTrain:  epoch  0, batch   779 | loss: 2.4325457MixupTrain:  epoch  0, batch   780 | loss: 2.3937557MixupTrain:  epoch  0, batch   781 | loss: 2.2511706MixupTrain:  epoch  0, batch   782 | loss: 2.5193753MixupTrain:  epoch  0, batch   783 | loss: 2.4443154MixupTrain:  epoch  0, batch   784 | loss: 2.2011127MixupTrain:  epoch  0, batch   785 | loss: 2.3372738MixupTrain:  epoch  0, batch   786 | loss: 2.2859097MixupTrain:  epoch  0, batch   787 | loss: 2.1757412MixupTrain:  epoch  0, batch   788 | loss: 2.4389255MixupTrain:  epoch  0, batch   789 | loss: 2.5796890MixupTrain:  epoch  0, batch   790 | loss: 2.0402083MixupTrain:  epoch  0, batch   791 | loss: 2.6077018MixupTrain:  epoch  0, batch   792 | loss: 2.3914351MixupTrain:  epoch  0, batch   793 | loss: 2.3841610MixupTrain:  epoch  0, batch   794 | loss: 2.1163952MixupTrain:  epoch  0, batch   795 | loss: 2.3159394MixupTrain:  epoch  0, batch   796 | loss: 2.5112848MixupTrain:  epoch  0, batch   797 | loss: 2.4211030MixupTrain:  epoch  0, batch   798 | loss: 2.2368231MixupTrain:  epoch  0, batch   799 | loss: 2.2880650MixupTrain:  epoch  0, batch   800 | loss: 2.0747781MixupTrain:  epoch  0, batch   801 | loss: 2.2527063MixupTrain:  epoch  0, batch   802 | loss: 2.3464680MixupTrain:  epoch  0, batch   803 | loss: 2.0385389MixupTrain:  epoch  0, batch   805 | loss: 2.1312704MixupTrain:  epoch  0, batch   806 | loss: 2.3680027MixupTrain:  epoch  0, batch   808 | loss: 2.4825404MixupTrain:  epoch  0, batch   809 | loss: 2.2795463MixupTrain:  epoch  0, batch   810 | loss: 2.0004513MixupTrain:  epoch  0, batch   811 | loss: 2.3045974MixupTrain:  epoch  0, batch   812 | loss: 2.4321787MixupTrain:  epoch  0, batch   813 | loss: 2.4187193MixupTrain:  epoch  0, batch   814 | loss: 2.4868186MixupTrain:  epoch  0, batch   815 | loss: 2.5887375MixupTrain:  epoch  0, batch   816 | loss: 2.3792403MixupTrain:  epoch  0, batch   817 | loss: 2.6074643MixupTrain:  epoch  0, batch   818 | loss: 1.9910856MixupTrain:  epoch  0, batch   819 | loss: 2.3266582MixupTrain:  epoch  0, batch   820 | loss: 2.4063199MixupTrain:  epoch  0, batch   821 | loss: 2.4322217MixupTrain:  epoch  0, batch   822 | loss: 2.0752516MixupTrain:  epoch  0, batch   823 | loss: 2.4868500MixupTrain:  epoch  0, batch   824 | loss: 2.4311707MixupTrain:  epoch  0, batch   827 | loss: 2.3256183MixupTrain:  epoch  0, batch   828 | loss: 2.2260122MixupTrain:  epoch  0, batch   829 | loss: 2.3183942MixupTrain:  epoch  0, batch   830 | loss: 2.1818488MixupTrain:  epoch  0, batch   831 | loss: 2.2420919MixupTrain:  epoch  0, batch   832 | loss: 2.8397570MixupTrain:  epoch  0, batch   833 | loss: 2.2815168MixupTrain:  epoch  0, batch   834 | loss: 1.9956512MixupTrain:  epoch  0, batch   835 | loss: 2.4496751MixupTrain:  epoch  0, batch   836 | loss: 2.2883358MixupTrain:  epoch  0, batch   837 | loss: 2.1046534MixupTrain:  epoch  0, batch   840 | loss: 2.3071022MixupTrain:  epoch  0, batch   841 | loss: 2.3046956MixupTrain:  epoch  0, batch   842 | loss: 2.5628450MixupTrain:  epoch  0, batch   843 | loss: 2.7147105MixupTrain:  epoch  0, batch   844 | loss: 2.4982862MixupTrain:  epoch  0, batch   845 | loss: 2.0509119MixupTrain:  epoch  0, batch   846 | loss: 2.1898754MixupTrain:  epoch  0, batch   848 | loss: 2.2442064MixupTrain:  epoch  0, batch   849 | loss: 2.3768015MixupTrain:  epoch  0, batch   851 | loss: 2.1662135MixupTrain:  epoch  0, batch   853 | loss: 2.2235162MixupTrain:  epoch  0, batch   855 | loss: 2.3427043MixupTrain:  epoch  0, batch   856 | loss: 2.1900439MixupTrain:  epoch  0, batch   857 | loss: 2.2254887MixupTrain:  epoch  0, batch   858 | loss: 2.3566577MixupTrain:  epoch  0, batch   859 | loss: 2.4038424MixupTrain:  epoch  0, batch   860 | loss: 2.3230157MixupTrain:  epoch  0, batch   861 | loss: 2.0699244MixupTrain:  epoch  0, batch   862 | loss: 2.2047753MixupTrain:  epoch  0, batch   863 | loss: 2.2995293MixupTrain:  epoch  0, batch   864 | loss: 2.4065034MixupTrain:  epoch  0, batch   865 | loss: 2.2965350MixupTrain:  epoch  0, batch   866 | loss: 2.1715205MixupTrain:  epoch  0, batch   867 | loss: 2.1541324MixupTrain:  epoch  0, batch   869 | loss: 2.1250420MixupTrain:  epoch  0, batch   870 | loss: 2.5937557MixupTrain:  epoch  0, batch   871 | loss: 2.1569977MixupTrain:  epoch  0, batch   872 | loss: 2.2485013MixupTrain:  epoch  0, batch   873 | loss: 2.1655138MixupTrain:  epoch  0, batch   874 | loss: 2.7449191MixupTrain:  epoch  0, batch   875 | loss: 2.5007100MixupTrain:  epoch  0, batch   876 | loss: 2.3236845MixupTrain:  epoch  0, batch   877 | loss: 2.2419374MixupTrain:  epoch  0, batch   878 | loss: 2.2258673MixupTrain:  epoch  0, batch   879 | loss: 2.6405902MixupTrain:  epoch  0, batch   880 | loss: 2.1150870MixupTrain:  epoch  0, batch   881 | loss: 2.2478261MixupTrain:  epoch  0, batch   882 | loss: 2.0584171MixupTrain:  epoch  0, batch   884 | loss: 2.2189486MixupTrain:  epoch  0, batch   885 | loss: 2.3141611MixupTrain:  epoch  0, batch   887 | loss: 2.1379104MixupTrain:  epoch  0, batch   888 | loss: 2.1979337MixupTrain:  epoch  0, batch   889 | loss: 2.6461945MixupTrain:  epoch  0, batch   890 | loss: 2.4916551MixupTrain:  epoch  0, batch   891 | loss: 2.2323675MixupTrain:  epoch  0, batch   892 | loss: 2.2972765MixupTrain:  epoch  0, batch   893 | loss: 2.2923417MixupTrain:  epoch  0, batch   894 | loss: 2.1131203MixupTrain:  epoch  0, batch   895 | loss: 2.2742746MixupTrain:  epoch  0, batch   898 | loss: 2.3221653MixupTrain:  epoch  0, batch   900 | loss: 2.5120254MixupTrain:  epoch  0, batch   901 | loss: 2.5757642MixupTrain:  epoch  0, batch   902 | loss: 2.4924560MixupTrain:  epoch  0, batch   903 | loss: 2.4018440MixupTrain:  epoch  0, batch   904 | loss: 2.1580677MixupTrain:  epoch  0, batch   905 | loss: 2.3226566MixupTrain:  epoch  0, batch   906 | loss: 2.0774164MixupTrain:  epoch  0, batch   907 | loss: 2.3269796MixupTrain:  epoch  0, batch   908 | loss: 2.2626493MixupTrain:  epoch  0, batch   909 | loss: 2.3436656MixupTrain:  epoch  0, batch   910 | loss: 2.2411337MixupTrain:  epoch  0, batch   911 | loss: 2.3608208MixupTrain:  epoch  0, batch   912 | loss: 2.3235233MixupTrain:  epoch  0, batch   913 | loss: 2.1628060MixupTrain:  epoch  0, batch   914 | loss: 2.1980996MixupTrain:  epoch  0, batch   915 | loss: 2.2471743MixupTrain:  epoch  0, batch   916 | loss: 2.6179569MixupTrain:  epoch  0, batch   917 | loss: 2.2340252MixupTrain:  epoch  0, batch   919 | loss: 2.5515952MixupTrain:  epoch  0, batch   920 | loss: 2.2385013MixupTrain:  epoch  0, batch   921 | loss: 2.6368670MixupTrain:  epoch  0, batch   922 | loss: 2.4176798MixupTrain:  epoch  0, batch   923 | loss: 1.9446058MixupTrain:  epoch  0, batch   924 | loss: 2.0512216MixupTrain:  epoch  0, batch   926 | loss: 2.2642086MixupTrain:  epoch  0, batch   927 | loss: 2.3791981MixupTrain:  epoch  0, batch   928 | loss: 2.4315405MixupTrain:  epoch  0, batch   929 | loss: 2.5422480MixupTrain:  epoch  0, batch   930 | loss: 2.4810085MixupTrain:  epoch  0, batch   931 | loss: 2.1156018MixupTrain:  epoch  0, batch   933 | loss: 2.7324357MixupTrain:  epoch  0, batch   934 | loss: 2.3447299MixupTrain:  epoch  0, batch   935 | loss: 2.3112736MixupTrain:  epoch  0, batch   936 | loss: 2.3534057MixupTrain:  epoch  0, batch   937 | loss: 2.1333809MixupTrain:  epoch  0, batch   938 | loss: 2.2765441MixupTrain:  epoch  0, batch   939 | loss: 1.9486331MixupTrain:  epoch  0, batch   940 | loss: 2.4144664MixupTrain:  epoch  0, batch   941 | loss: 2.5604532MixupTrain:  epoch  0, batch   943 | loss: 2.2487063MixupTrain:  epoch  0, batch   945 | loss: 2.4117038MixupTrain:  epoch  0, batch   946 | loss: 2.3492677MixupTrain:  epoch  0, batch   947 | loss: 2.3938704MixupTrain:  epoch  0, batch   948 | loss: 2.0602825MixupTrain:  epoch  0, batch   949 | loss: 2.1669438MixupTrain:  epoch  0, batch   950 | loss: 2.0189688MixupTrain:  epoch  0, batch   951 | loss: 2.6581635MixupTrain:  epoch  0, batch   952 | loss: 2.4140077MixupTrain:  epoch  0, batch   953 | loss: 2.2224822MixupTrain:  epoch  0, batch   954 | loss: 2.6207609MixupTrain:  epoch  0, batch   955 | loss: 2.4059782MixupTrain:  epoch  0, batch   956 | loss: 2.1653593MixupTrain:  epoch  0, batch   957 | loss: 2.5404396MixupTrain:  epoch  0, batch   958 | loss: 2.1839080MixupTrain:  epoch  0, batch   959 | loss: 2.5518849MixupTrain:  epoch  0, batch   960 | loss: 2.6654155MixupTrain:  epoch  0, batch   962 | loss: 2.3380258MixupTrain:  epoch  0, batch   963 | loss: 2.3974962MixupTrain:  epoch  0, batch   964 | loss: 2.2089057MixupTrain:  epoch  0, batch   966 | loss: 2.4349885MixupTrain:  epoch  0, batch   967 | loss: 2.3394918MixupTrain:  epoch  0, batch   968 | loss: 2.6128950MixupTrain:  epoch  0, batch   969 | loss: 2.1803508MixupTrain:  epoch  0, batch   970 | loss: 2.2836680MixupTrain:  epoch  0, batch   971 | loss: 2.1493471MixupTrain:  epoch  0, batch   973 | loss: 1.9127495MixupTrain:  epoch  0, batch   974 | loss: 2.3077579MixupTrain:  epoch  0, batch   975 | loss: 2.1923409MixupTrain:  epoch  0, batch   976 | loss: 2.6699228MixupTrain:  epoch  0, batch   977 | loss: 2.4004092MixupTrain:  epoch  0, batch   978 | loss: 2.4025180MixupTrain:  epoch  0, batch   979 | loss: 2.1555882MixupTrain:  epoch  0, batch   980 | loss: 2.4330821MixupTrain:  epoch  0, batch   981 | loss: 2.5135710MixupTrain:  epoch  0, batch   982 | loss: 2.2591047MixupTrain:  epoch  0, batch   983 | loss: 2.3147869MixupTrain:  epoch  0, batch   984 | loss: 2.2719488MixupTrain:  epoch  0, batch   985 | loss: 2.5416512MixupTrain:  epoch  0, batch   986 | loss: 2.3695250MixupTrain:  epoch  0, batch   987 | loss: 2.1588998MixupTrain:  epoch  0, batch   988 | loss: 2.5363131MixupTrain:  epoch  0, batch   989 | loss: 2.1072021MixupTrain:  epoch  0, batch   990 | loss: 2.3150978MixupTrain:  epoch  0, batch   991 | loss: 2.3675900MixupTrain:  epoch  0, batch   992 | loss: 2.0761769MixupTrain:  epoch  0, batch   993 | loss: 2.6018443MixupTrain:  epoch  0, batch   994 | loss: 2.4473014MixupTrain:  epoch  0, batch   995 | loss: 2.3868356MixupTrain:  epoch  0, batch   997 | loss: 2.3924243MixupTrain:  epoch  0, batch   998 | loss: 2.5765488MixupTrain:  epoch  0, batch   999 | loss: 1.9406297MixupTrain:  epoch  0, batch  1000 | loss: 2.2394257MixupTrain:  epoch  0, batch  1001 | loss: 2.2966852MixupTrain:  epoch  0, batch  1003 | loss: 2.1933665MixupTrain:  epoch  0, batch  1004 | loss: 2.2454214MixupTrain:  epoch  0, batch  1005 | loss: 2.2593513MixupTrain:  epoch  0, batch  1006 | loss: 2.0321341MixupTrain:  epoch  0, batch  1007 | loss: 2.0134339MixupTrain:  epoch  0, batch  1008 | loss: 2.3930593MixupTrain:  epoch  0, batch  1009 | loss: 2.3313088MixupTrain:  epoch  0, batch  1010 | loss: 2.5615659MixupTrain:  epoch  0, batch  1011 | loss: 2.2240222MixupTrain:  epoch  0, batch  1012 | loss: 2.1669936MixupTrain:  epoch  0, batch  1013 | loss: 2.3766379MixupTrain:  epoch  0, batch  1014 | loss: 2.2323568MixupTrain:  epoch  0, batch  1016 | loss: 2.0712466MixupTrain:  epoch  0, batch  1017 | loss: 2.4332020MixupTrain:  epoch  0, batch  1018 | loss: 2.1493394MixupTrain:  epoch  0, batch  1019 | loss: 2.3014281MixupTrain:  epoch  0, batch  1021 | loss: 2.5766163MixupTrain:  epoch  0, batch  1022 | loss: 2.2811031MixupTrain:  epoch  0, batch  1024 | loss: 2.2767150MixupTrain:  epoch  0, batch  1025 | loss: 2.4612880MixupTrain:  epoch  0, batch  1026 | loss: 2.5263815MixupTrain:  epoch  0, batch  1027 | loss: 2.5377605MixupTrain:  epoch  0, batch  1028 | loss: 2.2698009MixupTrain:  epoch  0, batch  1029 | loss: 1.9767390MixupTrain:  epoch  0, batch  1030 | loss: 2.4412796MixupTrain:  epoch  0, batch  1031 | loss: 2.2860107MixupTrain:  epoch  0, batch  1032 | loss: 2.3378718MixupTrain:  epoch  0, batch  1033 | loss: 2.1669822MixupTrain:  epoch  0, batch  1035 | loss: 2.3997962MixupTrain:  epoch  0, batch  1036 | loss: 2.1937432MixupTrain:  epoch  0, batch  1037 | loss: 2.4889038MixupTrain:  epoch  0, batch  1038 | loss: 1.9187675MixupTrain:  epoch  0, batch  1039 | loss: 2.4580362MixupTrain:  epoch  0, batch  1040 | loss: 2.5239315MixupTrain:  epoch  0, batch  1042 | loss: 2.1465089MixupTrain:  epoch  0, batch  1043 | loss: 2.3953185MixupTrain:  epoch  0, batch  1045 | loss: 2.1740901MixupTrain:  epoch  0, batch  1046 | loss: 2.1385019MixupTrain:  epoch  0, batch  1048 | loss: 2.2207148MixupTrain:  epoch  0, batch  1050 | loss: 2.5943043MixupTrain:  epoch  0, batch  1051 | loss: 2.4843631MixupTrain:  epoch  0, batch  1053 | loss: 2.3728602MixupTrain:  epoch  0, batch  1054 | loss: 2.1770239MixupTrain:  epoch  0, batch  1055 | loss: 2.7347522MixupTrain:  epoch  0, batch  1056 | loss: 2.0448096MixupTrain:  epoch  0, batch  1057 | loss: 2.5667672MixupTrain:  epoch  0, batch  1058 | loss: 2.3657434MixupTrain:  epoch  0, batch  1059 | loss: 2.3784022MixupTrain:  epoch  0, batch  1060 | loss: 2.1448312MixupTrain:  epoch  0, batch  1061 | loss: 2.2438085MixupTrain:  epoch  0, batch  1063 | loss: 2.2258697MixupTrain:  epoch  0, batch  1065 | loss: 2.1477730MixupTrain:  epoch  0, batch  1066 | loss: 2.3085945MixupTrain:  epoch  0, batch  1067 | loss: 2.4583430MixupTrain:  epoch  0, batch  1069 | loss: 2.1714907MixupTrain:  epoch  0, batch  1070 | loss: 2.0819836MixupTrain:  epoch  0, batch  1071 | loss: 2.1738398MixupTrain:  epoch  0, batch  1072 | loss: 2.4939160MixupTrain:  epoch  0, batch  1073 | loss: 2.1115019MixupTrain:  epoch  0, batch  1074 | loss: 2.4152870MixupTrain:  epoch  0, batch  1075 | loss: 2.2767656MixupTrain:  epoch  0, batch  1076 | loss: 2.1907432MixupTrain:  epoch  0, batch  1077 | loss: 2.3537121MixupTrain:  epoch  0, batch  1078 | loss: 2.0375578MixupTrain:  epoch  0, batch  1082 | loss: 2.3068032MixupTrain:  epoch  0, batch  1083 | loss: 2.1397030MixupTrain:  epoch  0, batch  1084 | loss: 2.3676298MixupTrain:  epoch  0, batch  1085 | loss: 2.2792482MixupTrain:  epoch  0, batch  1088 | loss: 2.5521097MixupTrain:  epoch  0, batch  1089 | loss: 2.2506909MixupTrain:  epoch  0, batch  1090 | loss: 2.5698881MixupTrain:  epoch  0, batch  1091 | loss: 2.3779376MixupTrain:  epoch  0, batch  1092 | loss: 2.1890445MixupTrain:  epoch  0, batch  1093 | loss: 2.4868999MixupTrain:  epoch  0, batch  1094 | loss: 2.4789400MixupTrain:  epoch  0, batch  1095 | loss: 2.2310328MixupTrain:  epoch  0, batch  1096 | loss: 2.1922145MixupTrain:  epoch  0, batch  1097 | loss: 2.1915665MixupTrain:  epoch  0, batch  1098 | loss: 2.4187174MixupTrain:  epoch  0, batch  1099 | loss: 2.1813757MixupTrain:  epoch  0, batch  1100 | loss: 2.7017524MixupTrain:  epoch  0, batch  1101 | loss: 2.2894106MixupTrain:  epoch  0, batch  1102 | loss: 2.7063637MixupTrain:  epoch  0, batch  1104 | loss: 2.2823834MixupTrain:  epoch  0, batch  1105 | loss: 2.2760763MixupTrain:  epoch  0, batch  1106 | loss: 2.1547742MixupTrain:  epoch  0, batch  1108 | loss: 2.1675792MixupTrain:  epoch  0, batch  1109 | loss: 2.3340609MixupTrain:  epoch  0, batch  1110 | loss: 2.4705682MixupTrain:  epoch  0, batch  1111 | loss: 2.1036730MixupTrain:  epoch  0, batch  1112 | loss: 2.5747490MixupTrain:  epoch  0, batch  1113 | loss: 2.5214901MixupTrain:  epoch  0, batch  1114 | loss: 2.2339888MixupTrain:  epoch  0, batch  1115 | loss: 2.2270355MixupTrain:  epoch  0, batch  1116 | loss: 2.0860934MixupTrain:  epoch  0, batch  1117 | loss: 2.6404741MixupTrain:  epoch  0, batch  1118 | loss: 2.3663340MixupTrain:  epoch  0, batch  1119 | loss: 2.6817541MixupTrain:  epoch  0, batch  1121 | loss: 2.1059978MixupTrain:  epoch  0, batch  1122 | loss: 2.6333818MixupTrain:  epoch  0, batch  1123 | loss: 2.4617250MixupTrain:  epoch  0, batch  1125 | loss: 2.2274251MixupTrain:  epoch  0, batch  1126 | loss: 2.3869448MixupTrain:  epoch  0, batch  1127 | loss: 2.1531725MixupTrain:  epoch  0, batch  1129 | loss: 2.4903889MixupTrain:  epoch  0, batch  1130 | loss: 2.2953687MixupTrain:  epoch  0, batch  1131 | loss: 2.3832574MixupTrain:  epoch  0, batch  1132 | loss: 2.2701764MixupTrain:  epoch  0, batch  1133 | loss: 2.7078304MixupTrain:  epoch  0, batch  1134 | loss: 2.1895037MixupTrain:  epoch  0, batch  1135 | loss: 2.1076045MixupTrain:  epoch  0, batch  1136 | loss: 2.4095302MixupTrain:  epoch  0, batch  1137 | loss: 2.5669937MixupTrain:  epoch  0, batch  1138 | loss: 2.4079187MixupTrain:  epoch  0, batch  1140 | loss: 2.1464972MixupTrain:  epoch  0, batch  1141 | loss: 2.2356143MixupTrain:  epoch  0, batch  1142 | loss: 2.3566048MixupTrain:  epoch  0, batch  1144 | loss: 2.2918010MixupTrain:  epoch  0, batch  1145 | loss: 2.2828126MixupTrain:  epoch  0, batch  1146 | loss: 2.2405789MixupTrain:  epoch  0, batch  1147 | loss: 2.1840339MixupTrain:  epoch  0, batch  1149 | loss: 2.3529904MixupTrain:  epoch  0, batch  1150 | loss: 2.0670974MixupTrain:  epoch  0, batch  1151 | loss: 2.2557669MixupTrain:  epoch  0, batch  1152 | loss: 2.3611093MixupTrain:  epoch  0, batch  1153 | loss: 2.1811011MixupTrain:  epoch  0, batch  1154 | loss: 2.4169478MixupTrain:  epoch  0, batch  1155 | loss: 2.2830448MixupTrain:  epoch  0, batch  1156 | loss: 2.3049653MixupTrain:  epoch  0, batch  1157 | loss: 2.6358857MixupTrain:  epoch  0, batch  1158 | loss: 2.6126444MixupTrain:  epoch  0, batch  1159 | loss: 2.3634772MixupTrain:  epoch  0, batch  1160 | loss: 2.3520281MixupTrain:  epoch  0, batch  1161 | loss: 2.3996987MixupTrain:  epoch  0, batch  1162 | loss: 2.4312434MixupTrain:  epoch  0, batch  1163 | loss: 2.0282762MixupTrain:  epoch  0, batch  1164 | loss: 2.3647585MixupTrain:  epoch  0, batch  1165 | loss: 2.3343675MixupTrain:  epoch  0, batch  1166 | loss: 2.3071470MixupTrain:  epoch  0, batch  1167 | loss: 2.3471484MixupTrain:  epoch  0, batch  1169 | loss: 2.3702273MixupTrain:  epoch  0, batch  1170 | loss: 2.1186349MixupTrain:  epoch  0, batch  1171 | loss: 2.4667974MixupTrain:  epoch  0, batch  1172 | loss: 2.3933737MixupTrain:  epoch  0, batch  1173 | loss: 2.2985437MixupTrain:  epoch  0, batch  1174 | loss: 2.2869372MixupTrain:  epoch  0, batch  1175 | loss: 2.1891530MixupTrain:  epoch  0, batch  1176 | loss: 1.9950423MixupTrain:  epoch  0, batch  1177 | loss: 2.1646972MixupTrain:  epoch  0, batch  1178 | loss: 2.1287792MixupTrain:  epoch  0, batch  1179 | loss: 2.3093731MixupTrain:  epoch  0, batch  1180 | loss: 2.5196614MixupTrain:  epoch  0, batch  1181 | loss: 2.4872801MixupTrain:  epoch  0, batch  1182 | loss: 2.3388526MixupTrain:  epoch  0, batch  1183 | loss: 2.2320251MixupTrain:  epoch  0, batch  1184 | loss: 2.6238534MixupTrain:  epoch  0, batch  1185 | loss: 2.3187897MixupTrain:  epoch  0, batch  1186 | loss: 2.4735613MixupTrain:  epoch  0, batch  1187 | loss: 2.2308779MixupTrain:  epoch  0, batch  1188 | loss: 2.5156913MixupTrain:  epoch  0, batch  1190 | loss: 2.1072650MixupTrain:  epoch  0, batch  1191 | loss: 2.1650717MixupTrain:  epoch  0, batch  1192 | loss: 2.0495832MixupTrain:  epoch  0, batch  1193 | loss: 2.4011512MixupTrain:  epoch  0, batch  1194 | loss: 1.9862194MixupTrain:  epoch  0, batch  1196 | loss: 2.1364961MixupTrain:  epoch  0, batch  1197 | loss: 2.4068410MixupTrain:  epoch  0, batch  1198 | loss: 2.2677031MixupTrain:  epoch  0, batch  1199 | loss: 2.3071008MixupTrain:  epoch  0, batch  1200 | loss: 2.6966581MixupTrain:  epoch  0, batch  1201 | loss: 2.1634159MixupTrain:  epoch  0, batch  1204 | loss: 2.2281084MixupTrain:  epoch  0, batch  1206 | loss: 2.0897322MixupTrain:  epoch  0, batch  1207 | loss: 2.0128832MixupTrain:  epoch  0, batch  1208 | loss: 2.2159739MixupTrain:  epoch  0, batch  1209 | loss: 2.2882233MixupTrain:  epoch  0, batch  1210 | loss: 2.6117849MixupTrain:  epoch  0, batch  1211 | loss: 2.2764144MixupTrain:  epoch  0, batch  1212 | loss: 2.2375956MixupTrain:  epoch  0, batch  1213 | loss: 2.1962111MixupTrain:  epoch  0, batch  1214 | loss: 2.5793452MixupTrain:  epoch  0, batch  1215 | loss: 2.3356643MixupTrain:  epoch  0, batch  1216 | loss: 2.1806283MixupTrain:  epoch  0, batch  1217 | loss: 1.9961351MixupTrain:  epoch  0, batch  1218 | loss: 2.4278886MixupTrain:  epoch  0, batch  1219 | loss: 2.3216760MixupTrain:  epoch  0, batch  1220 | loss: 2.3531585MixupTrain:  epoch  0, batch  1222 | loss: 2.3349934MixupTrain:  epoch  0, batch  1223 | loss: 2.6065636MixupTrain:  epoch  0, batch  1224 | loss: 2.4347367MixupTrain:  epoch  0, batch  1226 | loss: 2.2598577MixupTrain:  epoch  0, batch  1227 | loss: 1.8744869MixupTrain:  epoch  0, batch  1228 | loss: 2.2333918MixupTrain:  epoch  0, batch  1229 | loss: 2.3577547MixupTrain:  epoch  0, batch  1230 | loss: 2.5238390MixupTrain:  epoch  0, batch  1232 | loss: 2.2858224MixupTrain:  epoch  0, batch  1233 | loss: 2.3540382MixupTrain:  epoch  0, batch  1234 | loss: 2.3723359MixupTrain:  epoch  0, batch  1235 | loss: 2.0399337MixupTrain:  epoch  0, batch  1237 | loss: 2.1677260MixupTrain:  epoch  0, batch  1238 | loss: 2.3409457MixupTrain:  epoch  0, batch  1239 | loss: 2.3254371MixupTrain:  epoch  0, batch  1240 | loss: 2.2799184MixupTrain:  epoch  0, batch  1241 | loss: 2.2341819MixupTrain:  epoch  0, batch  1242 | loss: 2.3001063MixupTrain:  epoch  0, batch  1244 | loss: 2.4420044MixupTrain:  epoch  0, batch  1245 | loss: 2.3041854MixupTrain:  epoch  0, batch  1246 | loss: 2.6166735MixupTrain:  epoch  0, batch  1247 | loss: 2.0530314MixupTrain:  epoch  0, batch  1249 | loss: 2.2175994MixupTrain:  epoch  0, batch  1250 | loss: 2.1821706MixupTrain:  epoch  0, batch  1251 | loss: 2.3964248MixupTrain:  epoch  0, batch  1252 | loss: 2.8273354MixupTrain:  epoch  0, batch  1253 | loss: 2.2767782MixupTrain:  epoch  0, batch  1254 | loss: 2.3512344MixupTrain:  epoch  0, batch  1255 | loss: 2.1302342MixupTrain:  epoch  0, batch  1256 | loss: 2.4020946MixupTrain:  epoch  0, batch  1257 | loss: 2.2525964MixupTrain:  epoch  0, batch  1258 | loss: 2.1428366MixupTrain:  epoch  0, batch  1261 | loss: 2.2544005MixupTrain:  epoch  0, batch  1262 | loss: 2.2430487MixupTrain:  epoch  0, batch  1263 | loss: 2.1581364MixupTrain:  epoch  0, batch  1264 | loss: 2.2226107MixupTrain:  epoch  0, batch  1265 | loss: 2.6460519MixupTrain:  epoch  0, batch  1267 | loss: 2.2199333MixupTrain:  epoch  0, batch  1269 | loss: 2.4638498MixupTrain:  epoch  0, batch  1270 | loss: 2.0802643MixupTrain:  epoch  0, batch  1271 | loss: 2.2501724MixupTrain:  epoch  0, batch  1272 | loss: 2.3146503MixupTrain:  epoch  0, batch  1273 | loss: 2.2766023MixupTrain:  epoch  0, batch  1274 | loss: 2.2665377MixupTrain:  epoch  0, batch  1276 | loss: 2.3436813MixupTrain:  epoch  0, batch  1277 | loss: 2.3053703MixupTrain:  epoch  0, batch  1278 | loss: 2.2538891MixupTrain:  epoch  0, batch  1279 | loss: 2.3043904MixupTrain:  epoch  0, batch  1280 | loss: 2.3586950MixupTrain:  epoch  0, batch  1281 | loss: 2.3483748MixupTrain:  epoch  0, batch  1282 | loss: 2.2679281MixupTrain:  epoch  0, batch  1284 | loss: 2.7170768MixupTrain:  epoch  0, batch  1285 | loss: 2.2650294MixupTrain:  epoch  0, batch  1286 | loss: 2.2439082MixupTrain:  epoch  0, batch  1287 | loss: 2.4746208MixupTrain:  epoch  0, batch  1288 | loss: 2.4009085MixupTrain:  epoch  0, batch  1289 | loss: 2.3136022MixupTrain:  epoch  0, batch  1290 | loss: 2.3427882MixupTrain:  epoch  0, batch  1291 | loss: 2.2534132MixupTrain:  epoch  0, batch  1292 | loss: 2.3307874MixupTrain:  epoch  0, batch  1293 | loss: 2.1769321MixupTrain:  epoch  0, batch  1294 | loss: 1.9246955MixupTrain:  epoch  0, batch  1295 | loss: 2.2582998MixupTrain:  epoch  0, batch  1296 | loss: 2.4565277MixupTrain:  epoch  0, batch  1297 | loss: 2.3306749MixupTrain:  epoch  0, batch  1298 | loss: 2.4274979MixupTrain:  epoch  0, batch  1299 | loss: 2.4012609MixupTrain:  epoch  0, batch  1301 | loss: 2.1178916MixupTrain:  epoch  0, batch  1302 | loss: 2.3902135MixupTrain:  epoch  0, batch  1303 | loss: 2.1602399MixupTrain:  epoch  0, batch  1306 | loss: 2.4996300MixupTrain:  epoch  0, batch  1307 | loss: 2.2340093MixupTrain:  epoch  0, batch  1308 | loss: 2.2451761MixupTrain:  epoch  0, batch  1310 | loss: 1.9937418MixupTrain:  epoch  0, batch  1311 | loss: 2.0305603MixupTrain:  epoch  0, batch  1312 | loss: 2.4356756MixupTrain:  epoch  0, batch  1313 | loss: 2.4541702MixupTrain:  epoch  0, batch  1314 | loss: 2.4870598MixupTrain:  epoch  0, batch  1315 | loss: 2.2942033MixupTrain:  epoch  0, batch  1318 | loss: 2.3828635MixupTrain:  epoch  0, batch  1319 | loss: 2.2653410MixupTrain:  epoch  0, batch  1320 | loss: 2.4010439MixupTrain:  epoch  0, batch  1321 | loss: 2.1445198MixupTrain:  epoch  0, batch  1322 | loss: 2.4029756MixupTrain:  epoch  0, batch  1323 | loss: 2.1923018MixupTrain:  epoch  0, batch  1324 | loss: 2.1360972MixupTrain:  epoch  0, batch  1326 | loss: 2.4513860MixupTrain:  epoch  0, batch  1328 | loss: 2.3520021MixupTrain:  epoch  0, batch  1330 | loss: 2.4706626MixupTrain:  epoch  0, batch  1331 | loss: 2.7199838MixupTrain:  epoch  0, batch  1332 | loss: 2.3164093MixupTrain:  epoch  0, batch  1333 | loss: 2.5388551MixupTrain:  epoch  0, batch  1334 | loss: 2.2973328MixupTrain:  epoch  0, batch  1336 | loss: 2.5265660MixupTrain:  epoch  0, batch  1337 | loss: 2.4266825MixupTrain:  epoch  0, batch  1338 | loss: 2.2654777MixupTrain:  epoch  0, batch  1339 | loss: 2.4104066MixupTrain:  epoch  0, batch  1340 | loss: 2.3219740MixupTrain:  epoch  0, batch  1341 | loss: 2.4448557MixupTrain:  epoch  0, batch  1342 | loss: 2.3106446MixupTrain:  epoch  0, batch  1343 | loss: 1.8122251
MemoryTrain:  epoch  0, batch     0 | loss: 2.1322198MemoryTrain:  epoch  0, batch     1 | loss: 2.1600432MemoryTrain:  epoch  0, batch     2 | loss: 2.5686483MemoryTrain:  epoch  0, batch     3 | loss: 2.2739439MemoryTrain:  epoch  0, batch     4 | loss: 2.2296667MemoryTrain:  epoch  0, batch     5 | loss: 3.2732763MemoryTrain:  epoch  0, batch     6 | loss: 2.7420926MemoryTrain:  epoch  0, batch     7 | loss: 2.0098407MemoryTrain:  epoch  0, batch     8 | loss: 2.3177474MemoryTrain:  epoch  0, batch     9 | loss: 2.2765651MemoryTrain:  epoch  0, batch    10 | loss: 1.9747593MemoryTrain:  epoch  0, batch    11 | loss: 2.0717406MemoryTrain:  epoch  1, batch     0 | loss: 1.8134993MemoryTrain:  epoch  1, batch     1 | loss: 1.8240764MemoryTrain:  epoch  1, batch     2 | loss: 1.8390143MemoryTrain:  epoch  1, batch     3 | loss: 1.8317195MemoryTrain:  epoch  1, batch     4 | loss: 1.8265746MemoryTrain:  epoch  1, batch     5 | loss: 1.8380055MemoryTrain:  epoch  1, batch     6 | loss: 1.8200871MemoryTrain:  epoch  1, batch     7 | loss: 1.8388876MemoryTrain:  epoch  1, batch     8 | loss: 1.8257706MemoryTrain:  epoch  1, batch     9 | loss: 1.8757972MemoryTrain:  epoch  1, batch    10 | loss: 1.8368098MemoryTrain:  epoch  1, batch    11 | loss: 1.8250970MemoryTrain:  epoch  2, batch     0 | loss: 1.8157282MemoryTrain:  epoch  2, batch     1 | loss: 1.8260030MemoryTrain:  epoch  2, batch     2 | loss: 1.8315771MemoryTrain:  epoch  2, batch     3 | loss: 1.8265976MemoryTrain:  epoch  2, batch     4 | loss: 1.8152301MemoryTrain:  epoch  2, batch     5 | loss: 1.8251692MemoryTrain:  epoch  2, batch     6 | loss: 1.8271288MemoryTrain:  epoch  2, batch     7 | loss: 1.8354161MemoryTrain:  epoch  2, batch     8 | loss: 1.8313612MemoryTrain:  epoch  2, batch     9 | loss: 1.8174950MemoryTrain:  epoch  2, batch    10 | loss: 1.8180096MemoryTrain:  epoch  2, batch    11 | loss: 1.8129148MemoryTrain:  epoch  3, batch     0 | loss: 1.8137870MemoryTrain:  epoch  3, batch     1 | loss: 1.8172945MemoryTrain:  epoch  3, batch     2 | loss: 1.8162892MemoryTrain:  epoch  3, batch     3 | loss: 1.8196585MemoryTrain:  epoch  3, batch     4 | loss: 1.8217520MemoryTrain:  epoch  3, batch     5 | loss: 1.8143320MemoryTrain:  epoch  3, batch     6 | loss: 1.8174293MemoryTrain:  epoch  3, batch     7 | loss: 1.8150413MemoryTrain:  epoch  3, batch     8 | loss: 1.8132005MemoryTrain:  epoch  3, batch     9 | loss: 1.8200705MemoryTrain:  epoch  3, batch    10 | loss: 1.8152144MemoryTrain:  epoch  3, batch    11 | loss: 1.8104500MemoryTrain:  epoch  4, batch     0 | loss: 1.8199039MemoryTrain:  epoch  4, batch     1 | loss: 1.8121808MemoryTrain:  epoch  4, batch     2 | loss: 1.8121846MemoryTrain:  epoch  4, batch     3 | loss: 1.8149130MemoryTrain:  epoch  4, batch     4 | loss: 1.8112280MemoryTrain:  epoch  4, batch     5 | loss: 1.8100479MemoryTrain:  epoch  4, batch     6 | loss: 1.8165865MemoryTrain:  epoch  4, batch     7 | loss: 1.8068997MemoryTrain:  epoch  4, batch     8 | loss: 1.8190448MemoryTrain:  epoch  4, batch     9 | loss: 1.8151116MemoryTrain:  epoch  4, batch    10 | loss: 1.8138442MemoryTrain:  epoch  4, batch    11 | loss: 1.8166888MemoryTrain:  epoch  5, batch     0 | loss: 1.8117417MemoryTrain:  epoch  5, batch     1 | loss: 1.8223019MemoryTrain:  epoch  5, batch     2 | loss: 1.8117069MemoryTrain:  epoch  5, batch     3 | loss: 1.8120880MemoryTrain:  epoch  5, batch     4 | loss: 1.8161309MemoryTrain:  epoch  5, batch     5 | loss: 1.8274158MemoryTrain:  epoch  5, batch     6 | loss: 1.8248360MemoryTrain:  epoch  5, batch     7 | loss: 1.8188145MemoryTrain:  epoch  5, batch     8 | loss: 1.8212006MemoryTrain:  epoch  5, batch     9 | loss: 1.8181971MemoryTrain:  epoch  5, batch    10 | loss: 1.8151641MemoryTrain:  epoch  5, batch    11 | loss: 1.8221680MemoryTrain:  epoch  6, batch     0 | loss: 1.8218123MemoryTrain:  epoch  6, batch     1 | loss: 1.8379018MemoryTrain:  epoch  6, batch     2 | loss: 1.8158211MemoryTrain:  epoch  6, batch     3 | loss: 1.8134621MemoryTrain:  epoch  6, batch     4 | loss: 1.8136123MemoryTrain:  epoch  6, batch     5 | loss: 1.8199918MemoryTrain:  epoch  6, batch     6 | loss: 1.8139538MemoryTrain:  epoch  6, batch     7 | loss: 1.8149476MemoryTrain:  epoch  6, batch     8 | loss: 1.8148443MemoryTrain:  epoch  6, batch     9 | loss: 1.8159580MemoryTrain:  epoch  6, batch    10 | loss: 1.8308160MemoryTrain:  epoch  6, batch    11 | loss: 1.8124665MemoryTrain:  epoch  7, batch     0 | loss: 1.8210884MemoryTrain:  epoch  7, batch     1 | loss: 1.8338912MemoryTrain:  epoch  7, batch     2 | loss: 1.8132083MemoryTrain:  epoch  7, batch     3 | loss: 1.8069205MemoryTrain:  epoch  7, batch     4 | loss: 1.8196363MemoryTrain:  epoch  7, batch     5 | loss: 1.8066677MemoryTrain:  epoch  7, batch     6 | loss: 1.8095160MemoryTrain:  epoch  7, batch     7 | loss: 1.8127310MemoryTrain:  epoch  7, batch     8 | loss: 1.8130960MemoryTrain:  epoch  7, batch     9 | loss: 1.8122482MemoryTrain:  epoch  7, batch    10 | loss: 1.8138976MemoryTrain:  epoch  7, batch    11 | loss: 1.8158848MemoryTrain:  epoch  8, batch     0 | loss: 1.8178844MemoryTrain:  epoch  8, batch     1 | loss: 1.8136778MemoryTrain:  epoch  8, batch     2 | loss: 1.8217647MemoryTrain:  epoch  8, batch     3 | loss: 1.8158334MemoryTrain:  epoch  8, batch     4 | loss: 1.8166760MemoryTrain:  epoch  8, batch     5 | loss: 1.8174133MemoryTrain:  epoch  8, batch     6 | loss: 1.8116913MemoryTrain:  epoch  8, batch     7 | loss: 1.8148429MemoryTrain:  epoch  8, batch     8 | loss: 1.8143015MemoryTrain:  epoch  8, batch     9 | loss: 1.8124107MemoryTrain:  epoch  8, batch    10 | loss: 1.8093238MemoryTrain:  epoch  8, batch    11 | loss: 1.8264859MemoryTrain:  epoch  9, batch     0 | loss: 1.8158661MemoryTrain:  epoch  9, batch     1 | loss: 1.8149570MemoryTrain:  epoch  9, batch     2 | loss: 1.8133146MemoryTrain:  epoch  9, batch     3 | loss: 1.8131249MemoryTrain:  epoch  9, batch     4 | loss: 1.8166640MemoryTrain:  epoch  9, batch     5 | loss: 1.8134129MemoryTrain:  epoch  9, batch     6 | loss: 1.8231189MemoryTrain:  epoch  9, batch     7 | loss: 1.8096792MemoryTrain:  epoch  9, batch     8 | loss: 1.8118515MemoryTrain:  epoch  9, batch     9 | loss: 1.8111504MemoryTrain:  epoch  9, batch    10 | loss: 1.8225062MemoryTrain:  epoch  9, batch    11 | loss: 1.8075558
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    1 | acc: 87.50%,  total acc: 81.25%   [EVAL] batch:    2 | acc: 68.75%,  total acc: 77.08%   [EVAL] batch:    3 | acc: 93.75%,  total acc: 81.25%   [EVAL] batch:    4 | acc: 87.50%,  total acc: 82.50%   [EVAL] batch:    5 | acc: 87.50%,  total acc: 83.33%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 85.71%   [EVAL] batch:    7 | acc: 12.50%,  total acc: 76.56%   
[EVAL] batch:    0 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:    1 | acc: 43.75%,  total acc: 25.00%   [EVAL] batch:    2 | acc: 6.25%,  total acc: 18.75%   [EVAL] batch:    3 | acc: 12.50%,  total acc: 17.19%   [EVAL] batch:    4 | acc: 12.50%,  total acc: 16.25%   [EVAL] batch:    5 | acc: 18.75%,  total acc: 16.67%   [EVAL] batch:    6 | acc: 25.00%,  total acc: 17.86%   [EVAL] batch:    7 | acc: 6.25%,  total acc: 16.41%   [EVAL] batch:    8 | acc: 0.00%,  total acc: 14.58%   [EVAL] batch:    9 | acc: 6.25%,  total acc: 13.75%   [EVAL] batch:   10 | acc: 6.25%,  total acc: 13.07%   [EVAL] batch:   11 | acc: 6.25%,  total acc: 12.50%   [EVAL] batch:   12 | acc: 6.25%,  total acc: 12.02%   [EVAL] batch:   13 | acc: 31.25%,  total acc: 13.39%   [EVAL] batch:   14 | acc: 68.75%,  total acc: 17.08%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 19.53%   [EVAL] batch:   16 | acc: 68.75%,  total acc: 22.43%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 24.65%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 26.64%   [EVAL] batch:   19 | acc: 75.00%,  total acc: 29.06%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 31.85%   [EVAL] batch:   21 | acc: 93.75%,  total acc: 34.66%   [EVAL] batch:   22 | acc: 75.00%,  total acc: 36.41%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 38.80%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 41.00%   [EVAL] batch:   25 | acc: 93.75%,  total acc: 43.03%   [EVAL] batch:   26 | acc: 81.25%,  total acc: 44.44%   [EVAL] batch:   27 | acc: 81.25%,  total acc: 45.76%   [EVAL] batch:   28 | acc: 81.25%,  total acc: 46.98%   [EVAL] batch:   29 | acc: 37.50%,  total acc: 46.67%   [EVAL] batch:   30 | acc: 50.00%,  total acc: 46.77%   [EVAL] batch:   31 | acc: 68.75%,  total acc: 47.46%   [EVAL] batch:   32 | acc: 43.75%,  total acc: 47.35%   [EVAL] batch:   33 | acc: 18.75%,  total acc: 46.51%   [EVAL] batch:   34 | acc: 25.00%,  total acc: 45.89%   [EVAL] batch:   35 | acc: 25.00%,  total acc: 45.31%   [EVAL] batch:   36 | acc: 25.00%,  total acc: 44.76%   [EVAL] batch:   37 | acc: 62.50%,  total acc: 45.23%   [EVAL] batch:   38 | acc: 75.00%,  total acc: 45.99%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 47.34%   [EVAL] batch:   40 | acc: 62.50%,  total acc: 47.71%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 48.96%   [EVAL] batch:   42 | acc: 6.25%,  total acc: 47.97%   [EVAL] batch:   43 | acc: 0.00%,  total acc: 46.88%   [EVAL] batch:   44 | acc: 0.00%,  total acc: 45.83%   [EVAL] batch:   45 | acc: 0.00%,  total acc: 44.84%   [EVAL] batch:   46 | acc: 12.50%,  total acc: 44.15%   [EVAL] batch:   47 | acc: 50.00%,  total acc: 44.27%   [EVAL] batch:   48 | acc: 25.00%,  total acc: 43.88%   [EVAL] batch:   49 | acc: 12.50%,  total acc: 43.25%   [EVAL] batch:   50 | acc: 0.00%,  total acc: 42.40%   [EVAL] batch:   51 | acc: 18.75%,  total acc: 41.95%   [EVAL] batch:   52 | acc: 0.00%,  total acc: 41.16%   [EVAL] batch:   53 | acc: 31.25%,  total acc: 40.97%   [EVAL] batch:   54 | acc: 93.75%,  total acc: 41.93%   [EVAL] batch:   55 | acc: 87.50%,  total acc: 42.75%   [EVAL] batch:   56 | acc: 81.25%,  total acc: 43.42%   [EVAL] batch:   57 | acc: 68.75%,  total acc: 43.86%   [EVAL] batch:   58 | acc: 68.75%,  total acc: 44.28%   [EVAL] batch:   59 | acc: 56.25%,  total acc: 44.48%   [EVAL] batch:   60 | acc: 37.50%,  total acc: 44.36%   [EVAL] batch:   61 | acc: 56.25%,  total acc: 44.56%   [EVAL] batch:   62 | acc: 56.25%,  total acc: 44.74%   [EVAL] batch:   63 | acc: 81.25%,  total acc: 45.31%   [EVAL] batch:   64 | acc: 75.00%,  total acc: 45.77%   [EVAL] batch:   65 | acc: 75.00%,  total acc: 46.21%   [EVAL] batch:   66 | acc: 68.75%,  total acc: 46.55%   [EVAL] batch:   67 | acc: 93.75%,  total acc: 47.24%   [EVAL] batch:   68 | acc: 43.75%,  total acc: 47.19%   [EVAL] batch:   69 | acc: 37.50%,  total acc: 47.05%   [EVAL] batch:   70 | acc: 68.75%,  total acc: 47.36%   [EVAL] batch:   71 | acc: 68.75%,  total acc: 47.66%   [EVAL] batch:   72 | acc: 100.00%,  total acc: 48.37%   [EVAL] batch:   73 | acc: 93.75%,  total acc: 48.99%   [EVAL] batch:   74 | acc: 100.00%,  total acc: 49.67%   [EVAL] batch:   75 | acc: 100.00%,  total acc: 50.33%   [EVAL] batch:   76 | acc: 100.00%,  total acc: 50.97%   [EVAL] batch:   77 | acc: 68.75%,  total acc: 51.20%   [EVAL] batch:   78 | acc: 0.00%,  total acc: 50.55%   [EVAL] batch:   79 | acc: 0.00%,  total acc: 49.92%   [EVAL] batch:   80 | acc: 12.50%,  total acc: 49.46%   [EVAL] batch:   81 | acc: 25.00%,  total acc: 49.16%   [EVAL] batch:   82 | acc: 12.50%,  total acc: 48.72%   [EVAL] batch:   83 | acc: 50.00%,  total acc: 48.74%   [EVAL] batch:   84 | acc: 37.50%,  total acc: 48.60%   [EVAL] batch:   85 | acc: 25.00%,  total acc: 48.33%   [EVAL] batch:   86 | acc: 25.00%,  total acc: 48.06%   [EVAL] batch:   87 | acc: 56.25%,  total acc: 48.15%   [EVAL] batch:   88 | acc: 25.00%,  total acc: 47.89%   [EVAL] batch:   89 | acc: 37.50%,  total acc: 47.78%   [EVAL] batch:   90 | acc: 56.25%,  total acc: 47.87%   [EVAL] batch:   91 | acc: 100.00%,  total acc: 48.44%   [EVAL] batch:   92 | acc: 100.00%,  total acc: 48.99%   [EVAL] batch:   93 | acc: 100.00%,  total acc: 49.53%   [EVAL] batch:   94 | acc: 93.75%,  total acc: 50.00%   [EVAL] batch:   95 | acc: 87.50%,  total acc: 50.39%   [EVAL] batch:   96 | acc: 62.50%,  total acc: 50.52%   [EVAL] batch:   97 | acc: 62.50%,  total acc: 50.64%   [EVAL] batch:   98 | acc: 75.00%,  total acc: 50.88%   [EVAL] batch:   99 | acc: 81.25%,  total acc: 51.19%   [EVAL] batch:  100 | acc: 87.50%,  total acc: 51.55%   [EVAL] batch:  101 | acc: 62.50%,  total acc: 51.65%   [EVAL] batch:  102 | acc: 93.75%,  total acc: 52.06%   [EVAL] batch:  103 | acc: 87.50%,  total acc: 52.40%   [EVAL] batch:  104 | acc: 87.50%,  total acc: 52.74%   [EVAL] batch:  105 | acc: 100.00%,  total acc: 53.18%   [EVAL] batch:  106 | acc: 31.25%,  total acc: 52.98%   
cur_acc:  ['0.8580', '0.8750', '0.8438', '0.9028', '0.6449', '0.7656']
his_acc:  ['0.8580', '0.8191', '0.7121', '0.6314', '0.6138', '0.5298']
CurrentTrain: epoch  0, batch     0 | loss: 3.9549406CurrentTrain: epoch  0, batch     1 | loss: 5.2051325CurrentTrain: epoch  1, batch     0 | loss: 3.7965920CurrentTrain: epoch  1, batch     1 | loss: 3.0126617CurrentTrain: epoch  2, batch     0 | loss: 2.6930227CurrentTrain: epoch  2, batch     1 | loss: 3.5428133CurrentTrain: epoch  3, batch     0 | loss: 2.8651066CurrentTrain: epoch  3, batch     1 | loss: 2.5929520CurrentTrain: epoch  4, batch     0 | loss: 2.9499145CurrentTrain: epoch  4, batch     1 | loss: 1.9241045CurrentTrain: epoch  5, batch     0 | loss: 2.9552865CurrentTrain: epoch  5, batch     1 | loss: 2.1840384CurrentTrain: epoch  6, batch     0 | loss: 2.3851457CurrentTrain: epoch  6, batch     1 | loss: 2.3517253CurrentTrain: epoch  7, batch     0 | loss: 2.4744849CurrentTrain: epoch  7, batch     1 | loss: 2.2957683CurrentTrain: epoch  8, batch     0 | loss: 2.2516232CurrentTrain: epoch  8, batch     1 | loss: 1.9907949CurrentTrain: epoch  9, batch     0 | loss: 1.9125774CurrentTrain: epoch  9, batch     1 | loss: 2.5867777
#### person cause of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person cause of death" means a person was died of an event.
Here is an example:
Relation: person cause of death
Context: mr scheider had suffered from multiple myeloma for several years , and died of complications from a staph infection , his wife , brenda siemer , said .
Head Entity: mr scheider
Tail Entity: complications from a staph infection
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person cause of death":
Relation: person cause of death  
Context: after battling lung cancer for over a year, john doe passed away peacefully in his sleep, surrounded by family.  
Head Entity: john doe  
Tail Entity: lung cancer  

Relation: person cause of death  
Context: the renowned author, jane smith, tragically lost her life due to a car accident while returning from a book signing event.  
Head Entity: jane smith  
Tail Entity: car accident  

Relation: person cause of death  
Context: following a long struggle with heart disease, mr. thompson succumbed to his illness last night at the hospital.  
Head Entity: mr. thompson  
Tail Entity: heart disease  

Relation: person cause of death  
Context: the community mourned the loss of their beloved mayor, who died from a sudden stroke during a city council meeting.  
Head Entity: the mayor  
Tail Entity: stroke  

Relation: person cause of death  
Context: after a courageous fight against pancreatic cancer, elizabeth jones passed away, leaving behind a legacy of kindness and compassion.  
Head Entity: elizabeth jones  
Tail Entity: pancreatic cancer  
#### organization political religious affiliation ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization political religious affiliation" means an organization is the member of a religion.
Here is an example:
Relation: organization political religious affiliation
Context: the head of the organisation of the islamic conference -lrb- oic -rrb- said us president barack obama 's speech on thursday would help win hearts in the muslim world .
Head Entity: oic
Tail Entity: muslim
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization political religious affiliation":
1. Relation: organization political religious affiliation  
   Context: The Catholic Church has been a significant player in global politics, influencing various governments and policies.  
   Head Entity: Catholic Church  
   Tail Entity: Christianity  

2. Relation: organization political religious affiliation  
   Context: The World Council of Churches aims to promote unity among Christian denominations and engage in social justice issues worldwide.  
   Head Entity: World Council of Churches  
   Tail Entity: Christianity  

3. Relation: organization political religious affiliation  
   Context: The Islamic Society of North America has been actively involved in advocating for Muslim rights and representation in the political arena.  
   Head Entity: Islamic Society of North America  
   Tail Entity: Islam  

4. Relation: organization political religious affiliation  
   Context: The Jewish Federation works to support Jewish communities and promote their interests in political discussions.  
   Head Entity: Jewish Federation  
   Tail Entity: Judaism  

5. Relation: organization political religious affiliation  
   Context: The National Council of Churches has been a vocal advocate for various social issues, representing a wide array of Christian denominations.  
   Head Entity: National Council of Churches  
   Tail Entity: Christianity  
#### organization stateorprovince of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization stateorprovince of headquarters" means an organization is located in a state or province.
Here is an example:
Relation: organization stateorprovince of headquarters
Context: based in armonk , new york , mbia insures $ 670 billion -lrb- euro452 .18 billion -rrb- in debt .
Head Entity: mbia
Tail Entity: new york
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization stateorprovince of headquarters":
Relation: organization stateorprovince of headquarters  
Context: the tech giant apple inc. has its headquarters in cupertino, california, where it develops innovative products.  
Head Entity: apple inc.  
Tail Entity: california  

Relation: organization stateorprovince of headquarters  
Context: headquartered in seattle, washington, amazon.com, inc. is a leading e-commerce and cloud computing company.  
Head Entity: amazon.com, inc.  
Tail Entity: washington  

Relation: organization stateorprovince of headquarters  
Context: the multinational corporation samsung electronics is based in suwon, gyeonggi-do, south korea, and is known for its electronics and technology.  
Head Entity: samsung electronics  
Tail Entity: gyeonggi-do  

Relation: organization stateorprovince of headquarters  
Context: based in redmond, washington, microsoft corporation is a major player in software development and technology solutions.  
Head Entity: microsoft corporation  
Tail Entity: washington  

Relation: organization stateorprovince of headquarters  
Context: the global automotive manufacturer toyota motor corporation has its headquarters in toyota city, aichi prefecture, japan.  
Head Entity: toyota motor corporation  
Tail Entity: aichi prefecture  
#### person other family ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person other family" means a person 's relative is a person.
Here is an example:
Relation: person other family
Context: parren mitchell 's sister-in-law , juanita jackson mitchell , was the long - time head and legal counsel of the maryland naacp .
Head Entity: parren mitchell
Tail Entity: juanita jackson mitchell
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person other family":
Relation: person other family  
Context: barack obama's half-sister, maya soetoro-ng, is a prominent educator and author.  
Head Entity: barack obama  
Tail Entity: maya soetoro-ng  

Relation: person other family  
Context: the famous actor, tom hanks, has a brother named jim hanks who is also involved in the film industry.  
Head Entity: tom hanks  
Tail Entity: jim hanks  

Relation: person other family  
Context: queen elizabeth ii's cousin, prince michael of kent, often attends royal events and ceremonies.  
Head Entity: queen elizabeth ii  
Tail Entity: prince michael of kent  

Relation: person other family  
Context: serena williams often credits her older sister, venus williams, for inspiring her tennis career.  
Head Entity: serena williams  
Tail Entity: venus williams  

Relation: person other family  
Context: the renowned scientist, albert einstein, had a sister named maria einstein who was a talented musician.  
Head Entity: albert einstein  
Tail Entity: maria einstein  
#### person city of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person city of death" means a person was died in a city.
Here is an example:
Relation: person city of death
Context: irene morgan kirkaldy , 90 , who died of alzheimer 's disease aug. 10 at her home in gloucester , va. , quietly changed history in 1944 when she refused to give up her seat on a crowded greyhound bus to a white couple .
Head Entity: her
Tail Entity: gloucester
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person city of death":
Relation: person city of death  
Context: john smith, a renowned author, passed away on march 5 in the vibrant city of new orleans, where he spent his final years writing his last novel.  
Head Entity: john smith  
Tail Entity: new orleans  

Relation: person city of death  
Context: after a long battle with cancer, elizabeth taylor died on march 23 in the luxurious city of los angeles, surrounded by her family and friends.  
Head Entity: elizabeth taylor  
Tail Entity: los angeles  

Relation: person city of death  
Context: the famous scientist, albert einstein, took his last breath on april 18 in the serene city of princeton, where he had lived for many years.  
Head Entity: albert einstein  
Tail Entity: princeton  

Relation: person city of death  
Context: on january 1, the beloved musician, prince, was found dead in his home located in the bustling city of minneapolis, leaving fans in shock.  
Head Entity: prince  
Tail Entity: minneapolis  

Relation: person city of death  
Context: the legendary actor, robin williams, tragically died on august 11 in the picturesque city of paradise cay, leaving behind a legacy of laughter.  
Head Entity: robin williams  
Tail Entity: paradise cay  
Mixup data size:  28180
MixupTrain:  epoch  0, batch     0 | loss: 3.3738351MixupTrain:  epoch  0, batch     1 | loss: 4.3050618MixupTrain:  epoch  0, batch     2 | loss: 4.3039665MixupTrain:  epoch  0, batch     3 | loss: 4.1085644MixupTrain:  epoch  0, batch     4 | loss: 3.3866405MixupTrain:  epoch  0, batch     5 | loss: 4.3103552MixupTrain:  epoch  0, batch     6 | loss: 4.4029036MixupTrain:  epoch  0, batch     7 | loss: 4.1868429MixupTrain:  epoch  0, batch     8 | loss: 3.7904110MixupTrain:  epoch  0, batch     9 | loss: 3.7506192MixupTrain:  epoch  0, batch    10 | loss: 3.9619591MixupTrain:  epoch  0, batch    11 | loss: 3.4106274MixupTrain:  epoch  0, batch    12 | loss: 4.0324025MixupTrain:  epoch  0, batch    13 | loss: 4.0450535MixupTrain:  epoch  0, batch    14 | loss: 3.2614160MixupTrain:  epoch  0, batch    15 | loss: 4.0363164MixupTrain:  epoch  0, batch    16 | loss: 3.6743364MixupTrain:  epoch  0, batch    17 | loss: 3.1237125MixupTrain:  epoch  0, batch    18 | loss: 3.2082748MixupTrain:  epoch  0, batch    19 | loss: 3.9655123MixupTrain:  epoch  0, batch    20 | loss: 3.1027377MixupTrain:  epoch  0, batch    21 | loss: 2.5433407MixupTrain:  epoch  0, batch    22 | loss: 3.0610147MixupTrain:  epoch  0, batch    23 | loss: 3.4442639MixupTrain:  epoch  0, batch    24 | loss: 3.6828656MixupTrain:  epoch  0, batch    25 | loss: 2.9633911MixupTrain:  epoch  0, batch    26 | loss: 3.0390196MixupTrain:  epoch  0, batch    27 | loss: 4.2272415MixupTrain:  epoch  0, batch    28 | loss: 3.6093910MixupTrain:  epoch  0, batch    29 | loss: 3.4594283MixupTrain:  epoch  0, batch    30 | loss: 3.1027613MixupTrain:  epoch  0, batch    31 | loss: 2.7171421MixupTrain:  epoch  0, batch    32 | loss: 4.8024511MixupTrain:  epoch  0, batch    33 | loss: 3.8345366MixupTrain:  epoch  0, batch    34 | loss: 3.3713291MixupTrain:  epoch  0, batch    35 | loss: 3.4311509MixupTrain:  epoch  0, batch    36 | loss: 2.8227043MixupTrain:  epoch  0, batch    37 | loss: 2.9627790MixupTrain:  epoch  0, batch    38 | loss: 3.6432662MixupTrain:  epoch  0, batch    39 | loss: 3.1830039MixupTrain:  epoch  0, batch    40 | loss: 3.7326870MixupTrain:  epoch  0, batch    41 | loss: 3.4495347MixupTrain:  epoch  0, batch    42 | loss: 3.5839846MixupTrain:  epoch  0, batch    43 | loss: 3.4794834MixupTrain:  epoch  0, batch    44 | loss: 2.8624496MixupTrain:  epoch  0, batch    45 | loss: 2.8949714MixupTrain:  epoch  0, batch    46 | loss: 3.3955317MixupTrain:  epoch  0, batch    47 | loss: 3.5984244MixupTrain:  epoch  0, batch    48 | loss: 3.0153594MixupTrain:  epoch  0, batch    49 | loss: 3.2505713MixupTrain:  epoch  0, batch    50 | loss: 3.1148877MixupTrain:  epoch  0, batch    51 | loss: 2.6243467MixupTrain:  epoch  0, batch    52 | loss: 2.8977163MixupTrain:  epoch  0, batch    53 | loss: 2.6302390MixupTrain:  epoch  0, batch    54 | loss: 3.4164009MixupTrain:  epoch  0, batch    55 | loss: 2.8606505MixupTrain:  epoch  0, batch    56 | loss: 3.0808482MixupTrain:  epoch  0, batch    57 | loss: 3.9887516MixupTrain:  epoch  0, batch    58 | loss: 3.0464716MixupTrain:  epoch  0, batch    59 | loss: 3.2239151MixupTrain:  epoch  0, batch    60 | loss: 3.1515384MixupTrain:  epoch  0, batch    61 | loss: 3.6721435MixupTrain:  epoch  0, batch    62 | loss: 3.6952949MixupTrain:  epoch  0, batch    63 | loss: 2.8745999MixupTrain:  epoch  0, batch    64 | loss: 2.9503107MixupTrain:  epoch  0, batch    65 | loss: 2.8353508MixupTrain:  epoch  0, batch    66 | loss: 2.9038229MixupTrain:  epoch  0, batch    67 | loss: 3.2482181MixupTrain:  epoch  0, batch    68 | loss: 3.2438540MixupTrain:  epoch  0, batch    69 | loss: 2.9813347MixupTrain:  epoch  0, batch    70 | loss: 3.2511213MixupTrain:  epoch  0, batch    71 | loss: 2.6681287MixupTrain:  epoch  0, batch    72 | loss: 2.8804641MixupTrain:  epoch  0, batch    73 | loss: 3.5340962MixupTrain:  epoch  0, batch    74 | loss: 2.6204753MixupTrain:  epoch  0, batch    75 | loss: 3.3808823MixupTrain:  epoch  0, batch    76 | loss: 3.0317950MixupTrain:  epoch  0, batch    77 | loss: 2.9352574MixupTrain:  epoch  0, batch    78 | loss: 2.2032518MixupTrain:  epoch  0, batch    79 | loss: 3.3927636MixupTrain:  epoch  0, batch    80 | loss: 3.0140309MixupTrain:  epoch  0, batch    81 | loss: 3.0982871MixupTrain:  epoch  0, batch    82 | loss: 2.5003672MixupTrain:  epoch  0, batch    83 | loss: 3.1669014MixupTrain:  epoch  0, batch    84 | loss: 2.5243552MixupTrain:  epoch  0, batch    85 | loss: 2.4809408MixupTrain:  epoch  0, batch    86 | loss: 2.8839591MixupTrain:  epoch  0, batch    87 | loss: 2.8149457MixupTrain:  epoch  0, batch    88 | loss: 2.8998556MixupTrain:  epoch  0, batch    89 | loss: 3.3051333MixupTrain:  epoch  0, batch    90 | loss: 2.6276836MixupTrain:  epoch  0, batch    91 | loss: 2.8215342MixupTrain:  epoch  0, batch    92 | loss: 2.6933780MixupTrain:  epoch  0, batch    93 | loss: 2.6322014MixupTrain:  epoch  0, batch    94 | loss: 2.4182076MixupTrain:  epoch  0, batch    95 | loss: 2.8718367MixupTrain:  epoch  0, batch    96 | loss: 2.7876606MixupTrain:  epoch  0, batch    97 | loss: 2.6565919MixupTrain:  epoch  0, batch    98 | loss: 3.0501924MixupTrain:  epoch  0, batch    99 | loss: 2.4843628MixupTrain:  epoch  0, batch   100 | loss: 2.8718886MixupTrain:  epoch  0, batch   101 | loss: 2.6713421MixupTrain:  epoch  0, batch   102 | loss: 2.8209929MixupTrain:  epoch  0, batch   103 | loss: 2.9779332MixupTrain:  epoch  0, batch   104 | loss: 2.7532938MixupTrain:  epoch  0, batch   105 | loss: 2.6837220MixupTrain:  epoch  0, batch   106 | loss: 2.9618194MixupTrain:  epoch  0, batch   107 | loss: 2.7328806MixupTrain:  epoch  0, batch   108 | loss: 2.6007762MixupTrain:  epoch  0, batch   109 | loss: 2.9603686MixupTrain:  epoch  0, batch   110 | loss: 2.5459845MixupTrain:  epoch  0, batch   111 | loss: 3.0875139MixupTrain:  epoch  0, batch   112 | loss: 2.2999654MixupTrain:  epoch  0, batch   113 | loss: 2.4913833MixupTrain:  epoch  0, batch   114 | loss: 2.6508179MixupTrain:  epoch  0, batch   115 | loss: 3.0203676MixupTrain:  epoch  0, batch   116 | loss: 3.1341875MixupTrain:  epoch  0, batch   117 | loss: 3.2474234MixupTrain:  epoch  0, batch   118 | loss: 3.1139903MixupTrain:  epoch  0, batch   119 | loss: 2.7594686MixupTrain:  epoch  0, batch   120 | loss: 2.4274621MixupTrain:  epoch  0, batch   121 | loss: 2.7333214MixupTrain:  epoch  0, batch   122 | loss: 2.4404781MixupTrain:  epoch  0, batch   123 | loss: 2.5822234MixupTrain:  epoch  0, batch   124 | loss: 2.0251248MixupTrain:  epoch  0, batch   125 | loss: 2.6955361MixupTrain:  epoch  0, batch   126 | loss: 2.6947412MixupTrain:  epoch  0, batch   127 | loss: 2.7370155MixupTrain:  epoch  0, batch   128 | loss: 2.5455160MixupTrain:  epoch  0, batch   129 | loss: 2.9680960MixupTrain:  epoch  0, batch   130 | loss: 3.0275874MixupTrain:  epoch  0, batch   131 | loss: 2.8118310MixupTrain:  epoch  0, batch   132 | loss: 2.6413388MixupTrain:  epoch  0, batch   133 | loss: 2.6873465MixupTrain:  epoch  0, batch   134 | loss: 2.7698774MixupTrain:  epoch  0, batch   135 | loss: 2.5472641MixupTrain:  epoch  0, batch   136 | loss: 2.7836714MixupTrain:  epoch  0, batch   137 | loss: 3.0682111MixupTrain:  epoch  0, batch   138 | loss: 2.7337332MixupTrain:  epoch  0, batch   139 | loss: 2.5468302MixupTrain:  epoch  0, batch   140 | loss: 2.7801914MixupTrain:  epoch  0, batch   141 | loss: 2.6440306MixupTrain:  epoch  0, batch   142 | loss: 2.6279535MixupTrain:  epoch  0, batch   143 | loss: 2.7605817MixupTrain:  epoch  0, batch   144 | loss: 2.5647526MixupTrain:  epoch  0, batch   145 | loss: 2.1308537MixupTrain:  epoch  0, batch   146 | loss: 2.5852680MixupTrain:  epoch  0, batch   147 | loss: 2.3658180MixupTrain:  epoch  0, batch   148 | loss: 2.5314102MixupTrain:  epoch  0, batch   149 | loss: 2.5203834MixupTrain:  epoch  0, batch   150 | loss: 2.7552891MixupTrain:  epoch  0, batch   151 | loss: 2.6350825MixupTrain:  epoch  0, batch   152 | loss: 2.7010989MixupTrain:  epoch  0, batch   153 | loss: 2.0971775MixupTrain:  epoch  0, batch   154 | loss: 2.9125514MixupTrain:  epoch  0, batch   155 | loss: 2.7591126MixupTrain:  epoch  0, batch   156 | loss: 2.7114544MixupTrain:  epoch  0, batch   157 | loss: 2.9466014MixupTrain:  epoch  0, batch   158 | loss: 3.4052210MixupTrain:  epoch  0, batch   159 | loss: 2.5624108MixupTrain:  epoch  0, batch   160 | loss: 2.6870513MixupTrain:  epoch  0, batch   161 | loss: 2.6996460MixupTrain:  epoch  0, batch   162 | loss: 2.9134202MixupTrain:  epoch  0, batch   163 | loss: 2.5155230MixupTrain:  epoch  0, batch   164 | loss: 2.4396815MixupTrain:  epoch  0, batch   165 | loss: 2.7314181MixupTrain:  epoch  0, batch   166 | loss: 3.2264309MixupTrain:  epoch  0, batch   167 | loss: 2.3545625MixupTrain:  epoch  0, batch   168 | loss: 2.9361205MixupTrain:  epoch  0, batch   169 | loss: 2.4674754MixupTrain:  epoch  0, batch   170 | loss: 2.7726550MixupTrain:  epoch  0, batch   171 | loss: 2.6097856MixupTrain:  epoch  0, batch   172 | loss: 2.4782059MixupTrain:  epoch  0, batch   173 | loss: 2.2605858MixupTrain:  epoch  0, batch   174 | loss: 2.6160212MixupTrain:  epoch  0, batch   175 | loss: 2.3827267MixupTrain:  epoch  0, batch   176 | loss: 2.8726487MixupTrain:  epoch  0, batch   177 | loss: 2.1566739MixupTrain:  epoch  0, batch   178 | loss: 2.3085370MixupTrain:  epoch  0, batch   179 | loss: 2.6956515MixupTrain:  epoch  0, batch   180 | loss: 2.4152999MixupTrain:  epoch  0, batch   181 | loss: 2.3543711MixupTrain:  epoch  0, batch   182 | loss: 2.5997279MixupTrain:  epoch  0, batch   183 | loss: 2.7754111MixupTrain:  epoch  0, batch   184 | loss: 2.8497980MixupTrain:  epoch  0, batch   185 | loss: 2.5786920MixupTrain:  epoch  0, batch   186 | loss: 2.6266699MixupTrain:  epoch  0, batch   187 | loss: 2.4673657MixupTrain:  epoch  0, batch   188 | loss: 2.6108456MixupTrain:  epoch  0, batch   189 | loss: 2.3356152MixupTrain:  epoch  0, batch   190 | loss: 2.4799652MixupTrain:  epoch  0, batch   191 | loss: 2.4900136MixupTrain:  epoch  0, batch   192 | loss: 2.2882326MixupTrain:  epoch  0, batch   193 | loss: 2.7265992MixupTrain:  epoch  0, batch   194 | loss: 2.2042317MixupTrain:  epoch  0, batch   195 | loss: 2.4742508MixupTrain:  epoch  0, batch   196 | loss: 2.7337456MixupTrain:  epoch  0, batch   197 | loss: 2.7239485MixupTrain:  epoch  0, batch   198 | loss: 2.3467770MixupTrain:  epoch  0, batch   199 | loss: 2.5578232MixupTrain:  epoch  0, batch   200 | loss: 2.5342820MixupTrain:  epoch  0, batch   201 | loss: 3.0839622MixupTrain:  epoch  0, batch   202 | loss: 2.8097830MixupTrain:  epoch  0, batch   203 | loss: 2.5472169MixupTrain:  epoch  0, batch   204 | loss: 2.4468460MixupTrain:  epoch  0, batch   205 | loss: 2.7557163MixupTrain:  epoch  0, batch   206 | loss: 2.3177872MixupTrain:  epoch  0, batch   207 | loss: 2.5997708MixupTrain:  epoch  0, batch   208 | loss: 2.5096235MixupTrain:  epoch  0, batch   209 | loss: 2.5494771MixupTrain:  epoch  0, batch   210 | loss: 2.4320614MixupTrain:  epoch  0, batch   211 | loss: 2.4652467MixupTrain:  epoch  0, batch   212 | loss: 2.3404541MixupTrain:  epoch  0, batch   213 | loss: 2.5087481MixupTrain:  epoch  0, batch   214 | loss: 2.5334053MixupTrain:  epoch  0, batch   215 | loss: 2.5587325MixupTrain:  epoch  0, batch   216 | loss: 2.4792576MixupTrain:  epoch  0, batch   217 | loss: 2.5552707MixupTrain:  epoch  0, batch   218 | loss: 2.5792093MixupTrain:  epoch  0, batch   219 | loss: 2.3204122MixupTrain:  epoch  0, batch   220 | loss: 2.2460089MixupTrain:  epoch  0, batch   221 | loss: 2.2924447MixupTrain:  epoch  0, batch   222 | loss: 2.7813399MixupTrain:  epoch  0, batch   223 | loss: 2.6927400MixupTrain:  epoch  0, batch   224 | loss: 2.7707829MixupTrain:  epoch  0, batch   225 | loss: 2.3040171MixupTrain:  epoch  0, batch   226 | loss: 2.6388519MixupTrain:  epoch  0, batch   227 | loss: 2.5512428MixupTrain:  epoch  0, batch   228 | loss: 2.3877389MixupTrain:  epoch  0, batch   229 | loss: 2.3282356MixupTrain:  epoch  0, batch   230 | loss: 2.6176338MixupTrain:  epoch  0, batch   231 | loss: 2.2937129MixupTrain:  epoch  0, batch   232 | loss: 2.2464638MixupTrain:  epoch  0, batch   233 | loss: 2.6147230MixupTrain:  epoch  0, batch   234 | loss: 2.8135614MixupTrain:  epoch  0, batch   235 | loss: 2.6088748MixupTrain:  epoch  0, batch   236 | loss: 2.9683304MixupTrain:  epoch  0, batch   237 | loss: 2.5755138MixupTrain:  epoch  0, batch   238 | loss: 2.9872031MixupTrain:  epoch  0, batch   239 | loss: 2.7424426MixupTrain:  epoch  0, batch   240 | loss: 2.5131519MixupTrain:  epoch  0, batch   241 | loss: 2.2286863MixupTrain:  epoch  0, batch   242 | loss: 2.3310802MixupTrain:  epoch  0, batch   243 | loss: 2.6944656MixupTrain:  epoch  0, batch   244 | loss: 2.5478332MixupTrain:  epoch  0, batch   245 | loss: 2.5727649MixupTrain:  epoch  0, batch   246 | loss: 2.5241294MixupTrain:  epoch  0, batch   247 | loss: 2.5691829MixupTrain:  epoch  0, batch   248 | loss: 2.5808265MixupTrain:  epoch  0, batch   249 | loss: 2.4713202MixupTrain:  epoch  0, batch   250 | loss: 2.0186894MixupTrain:  epoch  0, batch   251 | loss: 3.1363649MixupTrain:  epoch  0, batch   252 | loss: 2.4370966MixupTrain:  epoch  0, batch   253 | loss: 2.6191993MixupTrain:  epoch  0, batch   254 | loss: 2.9551592MixupTrain:  epoch  0, batch   255 | loss: 2.3137681MixupTrain:  epoch  0, batch   256 | loss: 2.3664048MixupTrain:  epoch  0, batch   257 | loss: 2.4225068MixupTrain:  epoch  0, batch   258 | loss: 2.7703669MixupTrain:  epoch  0, batch   259 | loss: 2.8377414MixupTrain:  epoch  0, batch   260 | loss: 2.3769653MixupTrain:  epoch  0, batch   261 | loss: 2.6476769MixupTrain:  epoch  0, batch   262 | loss: 2.6942589MixupTrain:  epoch  0, batch   263 | loss: 2.3829007MixupTrain:  epoch  0, batch   264 | loss: 2.6296282MixupTrain:  epoch  0, batch   265 | loss: 2.4146748MixupTrain:  epoch  0, batch   266 | loss: 2.1217577MixupTrain:  epoch  0, batch   267 | loss: 2.4768395MixupTrain:  epoch  0, batch   268 | loss: 2.3722882MixupTrain:  epoch  0, batch   269 | loss: 2.2391305MixupTrain:  epoch  0, batch   270 | loss: 2.2446730MixupTrain:  epoch  0, batch   271 | loss: 2.4848228MixupTrain:  epoch  0, batch   272 | loss: 2.5295796MixupTrain:  epoch  0, batch   273 | loss: 2.3996749MixupTrain:  epoch  0, batch   274 | loss: 2.5744429MixupTrain:  epoch  0, batch   275 | loss: 2.4439669MixupTrain:  epoch  0, batch   276 | loss: 2.3164325MixupTrain:  epoch  0, batch   277 | loss: 2.3725815MixupTrain:  epoch  0, batch   278 | loss: 2.5676711MixupTrain:  epoch  0, batch   279 | loss: 2.3289912MixupTrain:  epoch  0, batch   280 | loss: 2.3343306MixupTrain:  epoch  0, batch   281 | loss: 2.5096450MixupTrain:  epoch  0, batch   282 | loss: 2.4891481MixupTrain:  epoch  0, batch   283 | loss: 2.4969139MixupTrain:  epoch  0, batch   284 | loss: 2.9079068MixupTrain:  epoch  0, batch   285 | loss: 2.5578423MixupTrain:  epoch  0, batch   286 | loss: 2.4325624MixupTrain:  epoch  0, batch   287 | loss: 2.5721524MixupTrain:  epoch  0, batch   288 | loss: 2.3073440MixupTrain:  epoch  0, batch   289 | loss: 2.2970018MixupTrain:  epoch  0, batch   290 | loss: 2.2009358MixupTrain:  epoch  0, batch   291 | loss: 2.5805097MixupTrain:  epoch  0, batch   292 | loss: 2.7059979MixupTrain:  epoch  0, batch   293 | loss: 1.8842088MixupTrain:  epoch  0, batch   294 | loss: 2.4216995MixupTrain:  epoch  0, batch   295 | loss: 2.1584196MixupTrain:  epoch  0, batch   296 | loss: 2.3251610MixupTrain:  epoch  0, batch   297 | loss: 2.0819888MixupTrain:  epoch  0, batch   298 | loss: 2.4396181MixupTrain:  epoch  0, batch   299 | loss: 2.7634506MixupTrain:  epoch  0, batch   300 | loss: 2.2958646MixupTrain:  epoch  0, batch   301 | loss: 2.4105530MixupTrain:  epoch  0, batch   302 | loss: 2.6206269MixupTrain:  epoch  0, batch   303 | loss: 2.2733798MixupTrain:  epoch  0, batch   304 | loss: 2.1000199MixupTrain:  epoch  0, batch   305 | loss: 2.3719897MixupTrain:  epoch  0, batch   306 | loss: 2.4360499MixupTrain:  epoch  0, batch   307 | loss: 2.7341521MixupTrain:  epoch  0, batch   308 | loss: 2.1134984MixupTrain:  epoch  0, batch   309 | loss: 2.2117963MixupTrain:  epoch  0, batch   310 | loss: 2.1742198MixupTrain:  epoch  0, batch   311 | loss: 2.3991780MixupTrain:  epoch  0, batch   312 | loss: 2.4277506MixupTrain:  epoch  0, batch   313 | loss: 2.8098285MixupTrain:  epoch  0, batch   314 | loss: 2.3677945MixupTrain:  epoch  0, batch   315 | loss: 2.4286387MixupTrain:  epoch  0, batch   316 | loss: 2.3865998MixupTrain:  epoch  0, batch   317 | loss: 2.5080061MixupTrain:  epoch  0, batch   318 | loss: 2.4438875MixupTrain:  epoch  0, batch   319 | loss: 2.5373492MixupTrain:  epoch  0, batch   320 | loss: 2.8242781MixupTrain:  epoch  0, batch   321 | loss: 2.5636573MixupTrain:  epoch  0, batch   322 | loss: 2.3880730MixupTrain:  epoch  0, batch   323 | loss: 2.7032032MixupTrain:  epoch  0, batch   324 | loss: 2.3058929MixupTrain:  epoch  0, batch   325 | loss: 2.4344049MixupTrain:  epoch  0, batch   326 | loss: 2.4773755MixupTrain:  epoch  0, batch   327 | loss: 2.6235824MixupTrain:  epoch  0, batch   328 | loss: 2.7641239MixupTrain:  epoch  0, batch   329 | loss: 2.5854604MixupTrain:  epoch  0, batch   330 | loss: 2.5425050MixupTrain:  epoch  0, batch   331 | loss: 2.7319026MixupTrain:  epoch  0, batch   332 | loss: 2.5044920MixupTrain:  epoch  0, batch   333 | loss: 2.6194973MixupTrain:  epoch  0, batch   334 | loss: 2.0966277MixupTrain:  epoch  0, batch   335 | loss: 2.2612000MixupTrain:  epoch  0, batch   336 | loss: 2.6339409MixupTrain:  epoch  0, batch   337 | loss: 2.2749844MixupTrain:  epoch  0, batch   338 | loss: 2.7192762MixupTrain:  epoch  0, batch   339 | loss: 2.4404702MixupTrain:  epoch  0, batch   340 | loss: 2.4706407MixupTrain:  epoch  0, batch   341 | loss: 2.1335917MixupTrain:  epoch  0, batch   342 | loss: 2.4525464MixupTrain:  epoch  0, batch   343 | loss: 2.4337587MixupTrain:  epoch  0, batch   344 | loss: 2.4530575MixupTrain:  epoch  0, batch   345 | loss: 2.6156263MixupTrain:  epoch  0, batch   346 | loss: 2.2972245MixupTrain:  epoch  0, batch   347 | loss: 2.1481788MixupTrain:  epoch  0, batch   348 | loss: 2.4875994MixupTrain:  epoch  0, batch   349 | loss: 2.0955234MixupTrain:  epoch  0, batch   350 | loss: 2.5221624MixupTrain:  epoch  0, batch   351 | loss: 2.0298753MixupTrain:  epoch  0, batch   352 | loss: 2.4821057MixupTrain:  epoch  0, batch   353 | loss: 2.7032719MixupTrain:  epoch  0, batch   354 | loss: 2.5818489MixupTrain:  epoch  0, batch   355 | loss: 2.4831231MixupTrain:  epoch  0, batch   356 | loss: 2.2389541MixupTrain:  epoch  0, batch   357 | loss: 1.9504354MixupTrain:  epoch  0, batch   358 | loss: 2.1611352MixupTrain:  epoch  0, batch   359 | loss: 2.6484499MixupTrain:  epoch  0, batch   360 | loss: 2.5052266MixupTrain:  epoch  0, batch   361 | loss: 2.3225806MixupTrain:  epoch  0, batch   362 | loss: 2.6607375MixupTrain:  epoch  0, batch   363 | loss: 2.6656222MixupTrain:  epoch  0, batch   364 | loss: 2.4603658MixupTrain:  epoch  0, batch   365 | loss: 2.0376663MixupTrain:  epoch  0, batch   366 | loss: 2.3798761MixupTrain:  epoch  0, batch   367 | loss: 2.5192020MixupTrain:  epoch  0, batch   368 | loss: 2.5637517MixupTrain:  epoch  0, batch   369 | loss: 2.3957376MixupTrain:  epoch  0, batch   370 | loss: 2.3503926MixupTrain:  epoch  0, batch   371 | loss: 2.2740841MixupTrain:  epoch  0, batch   372 | loss: 2.2392011MixupTrain:  epoch  0, batch   373 | loss: 2.8394237MixupTrain:  epoch  0, batch   374 | loss: 2.5364017MixupTrain:  epoch  0, batch   375 | loss: 2.2308989MixupTrain:  epoch  0, batch   376 | loss: 2.2487946MixupTrain:  epoch  0, batch   377 | loss: 2.3702354MixupTrain:  epoch  0, batch   378 | loss: 2.3338525MixupTrain:  epoch  0, batch   379 | loss: 2.1780205MixupTrain:  epoch  0, batch   380 | loss: 2.3914962MixupTrain:  epoch  0, batch   381 | loss: 2.4990168MixupTrain:  epoch  0, batch   382 | loss: 2.5126534MixupTrain:  epoch  0, batch   383 | loss: 2.2120581MixupTrain:  epoch  0, batch   384 | loss: 2.2936602MixupTrain:  epoch  0, batch   385 | loss: 2.1853943MixupTrain:  epoch  0, batch   386 | loss: 2.5709591MixupTrain:  epoch  0, batch   387 | loss: 2.3055096MixupTrain:  epoch  0, batch   388 | loss: 2.6590605MixupTrain:  epoch  0, batch   389 | loss: 2.4273665MixupTrain:  epoch  0, batch   390 | loss: 2.4925337MixupTrain:  epoch  0, batch   391 | loss: 2.8247213MixupTrain:  epoch  0, batch   392 | loss: 2.1854639MixupTrain:  epoch  0, batch   393 | loss: 2.5530899MixupTrain:  epoch  0, batch   394 | loss: 2.1873946MixupTrain:  epoch  0, batch   395 | loss: 2.1877275MixupTrain:  epoch  0, batch   396 | loss: 2.5743876MixupTrain:  epoch  0, batch   397 | loss: 2.8404891MixupTrain:  epoch  0, batch   398 | loss: 2.4093575MixupTrain:  epoch  0, batch   399 | loss: 2.4392910MixupTrain:  epoch  0, batch   400 | loss: 2.2836421MixupTrain:  epoch  0, batch   401 | loss: 2.4591212MixupTrain:  epoch  0, batch   402 | loss: 2.2321219MixupTrain:  epoch  0, batch   403 | loss: 2.5669339MixupTrain:  epoch  0, batch   404 | loss: 2.0706697MixupTrain:  epoch  0, batch   405 | loss: 2.0493951MixupTrain:  epoch  0, batch   406 | loss: 2.1991634MixupTrain:  epoch  0, batch   407 | loss: 2.6398048MixupTrain:  epoch  0, batch   408 | loss: 2.2131929MixupTrain:  epoch  0, batch   409 | loss: 2.1177695MixupTrain:  epoch  0, batch   410 | loss: 2.2251194MixupTrain:  epoch  0, batch   411 | loss: 2.5825262MixupTrain:  epoch  0, batch   412 | loss: 2.4485388MixupTrain:  epoch  0, batch   413 | loss: 2.3669276MixupTrain:  epoch  0, batch   414 | loss: 2.8095691MixupTrain:  epoch  0, batch   415 | loss: 2.7177372MixupTrain:  epoch  0, batch   416 | loss: 2.3276577MixupTrain:  epoch  0, batch   417 | loss: 2.2764573MixupTrain:  epoch  0, batch   418 | loss: 2.3300869MixupTrain:  epoch  0, batch   419 | loss: 2.0570827MixupTrain:  epoch  0, batch   420 | loss: 2.2194312MixupTrain:  epoch  0, batch   421 | loss: 2.6670434MixupTrain:  epoch  0, batch   422 | loss: 2.5627635MixupTrain:  epoch  0, batch   423 | loss: 2.3934016MixupTrain:  epoch  0, batch   424 | loss: 2.2590876MixupTrain:  epoch  0, batch   425 | loss: 2.1366472MixupTrain:  epoch  0, batch   426 | loss: 2.2698092MixupTrain:  epoch  0, batch   427 | loss: 2.5990603MixupTrain:  epoch  0, batch   428 | loss: 2.4641337MixupTrain:  epoch  0, batch   429 | loss: 2.2711906MixupTrain:  epoch  0, batch   430 | loss: 2.6424079MixupTrain:  epoch  0, batch   431 | loss: 2.4713182MixupTrain:  epoch  0, batch   432 | loss: 2.5278902MixupTrain:  epoch  0, batch   433 | loss: 2.4164424MixupTrain:  epoch  0, batch   434 | loss: 2.4299254MixupTrain:  epoch  0, batch   435 | loss: 2.4690921MixupTrain:  epoch  0, batch   436 | loss: 2.2418771MixupTrain:  epoch  0, batch   437 | loss: 2.4183409MixupTrain:  epoch  0, batch   438 | loss: 2.6823771MixupTrain:  epoch  0, batch   439 | loss: 2.3029647MixupTrain:  epoch  0, batch   440 | loss: 2.2389846MixupTrain:  epoch  0, batch   441 | loss: 2.3168342MixupTrain:  epoch  0, batch   442 | loss: 2.7678018MixupTrain:  epoch  0, batch   443 | loss: 2.3980577MixupTrain:  epoch  0, batch   444 | loss: 2.2936273MixupTrain:  epoch  0, batch   445 | loss: 2.3125761MixupTrain:  epoch  0, batch   446 | loss: 2.6865656MixupTrain:  epoch  0, batch   447 | loss: 2.2997067MixupTrain:  epoch  0, batch   448 | loss: 1.8861548MixupTrain:  epoch  0, batch   449 | loss: 2.4932873MixupTrain:  epoch  0, batch   450 | loss: 2.4326651MixupTrain:  epoch  0, batch   451 | loss: 2.0577624MixupTrain:  epoch  0, batch   452 | loss: 2.4503593MixupTrain:  epoch  0, batch   453 | loss: 2.4689140MixupTrain:  epoch  0, batch   454 | loss: 2.4732294MixupTrain:  epoch  0, batch   455 | loss: 2.3675635MixupTrain:  epoch  0, batch   456 | loss: 2.2023478MixupTrain:  epoch  0, batch   457 | loss: 2.5925872MixupTrain:  epoch  0, batch   458 | loss: 2.4811220MixupTrain:  epoch  0, batch   459 | loss: 2.6183107MixupTrain:  epoch  0, batch   460 | loss: 2.9679751MixupTrain:  epoch  0, batch   461 | loss: 2.4808571MixupTrain:  epoch  0, batch   462 | loss: 2.4351673MixupTrain:  epoch  0, batch   463 | loss: 2.2642832MixupTrain:  epoch  0, batch   464 | loss: 2.8375199MixupTrain:  epoch  0, batch   465 | loss: 2.5250821MixupTrain:  epoch  0, batch   466 | loss: 2.1341276MixupTrain:  epoch  0, batch   467 | loss: 2.1453502MixupTrain:  epoch  0, batch   468 | loss: 2.3709247MixupTrain:  epoch  0, batch   469 | loss: 2.2489805MixupTrain:  epoch  0, batch   470 | loss: 2.2869844MixupTrain:  epoch  0, batch   471 | loss: 2.4074826MixupTrain:  epoch  0, batch   472 | loss: 2.6902149MixupTrain:  epoch  0, batch   473 | loss: 2.2148383MixupTrain:  epoch  0, batch   474 | loss: 2.1252167MixupTrain:  epoch  0, batch   475 | loss: 2.4452133MixupTrain:  epoch  0, batch   476 | loss: 2.2003436MixupTrain:  epoch  0, batch   477 | loss: 2.2309921MixupTrain:  epoch  0, batch   478 | loss: 2.2157845MixupTrain:  epoch  0, batch   479 | loss: 2.8698077MixupTrain:  epoch  0, batch   480 | loss: 2.1713843MixupTrain:  epoch  0, batch   481 | loss: 2.7787817MixupTrain:  epoch  0, batch   482 | loss: 2.7250328MixupTrain:  epoch  0, batch   483 | loss: 2.3866773MixupTrain:  epoch  0, batch   484 | loss: 2.1773043MixupTrain:  epoch  0, batch   485 | loss: 2.2442608MixupTrain:  epoch  0, batch   486 | loss: 2.5768933MixupTrain:  epoch  0, batch   487 | loss: 2.1574271MixupTrain:  epoch  0, batch   488 | loss: 2.5733199MixupTrain:  epoch  0, batch   489 | loss: 2.1653659MixupTrain:  epoch  0, batch   490 | loss: 2.2913876MixupTrain:  epoch  0, batch   491 | loss: 2.3743262MixupTrain:  epoch  0, batch   492 | loss: 2.3274953MixupTrain:  epoch  0, batch   493 | loss: 2.1107941MixupTrain:  epoch  0, batch   494 | loss: 2.2869208MixupTrain:  epoch  0, batch   495 | loss: 2.0068088MixupTrain:  epoch  0, batch   496 | loss: 2.2308018MixupTrain:  epoch  0, batch   497 | loss: 2.1685119MixupTrain:  epoch  0, batch   498 | loss: 2.5516181MixupTrain:  epoch  0, batch   499 | loss: 2.7696795MixupTrain:  epoch  0, batch   500 | loss: 2.8407755MixupTrain:  epoch  0, batch   501 | loss: 1.8396126MixupTrain:  epoch  0, batch   502 | loss: 2.6014776MixupTrain:  epoch  0, batch   503 | loss: 2.5780184MixupTrain:  epoch  0, batch   504 | loss: 2.6752758MixupTrain:  epoch  0, batch   505 | loss: 2.2848253MixupTrain:  epoch  0, batch   506 | loss: 2.1259799MixupTrain:  epoch  0, batch   507 | loss: 2.2503350MixupTrain:  epoch  0, batch   508 | loss: 2.5890613MixupTrain:  epoch  0, batch   509 | loss: 2.3433256MixupTrain:  epoch  0, batch   510 | loss: 2.5482206MixupTrain:  epoch  0, batch   511 | loss: 2.5103307MixupTrain:  epoch  0, batch   512 | loss: 2.3558645MixupTrain:  epoch  0, batch   513 | loss: 2.5423982MixupTrain:  epoch  0, batch   514 | loss: 2.2274547MixupTrain:  epoch  0, batch   515 | loss: 2.3082392MixupTrain:  epoch  0, batch   516 | loss: 2.7502499MixupTrain:  epoch  0, batch   517 | loss: 2.1552422MixupTrain:  epoch  0, batch   518 | loss: 2.4664631MixupTrain:  epoch  0, batch   519 | loss: 2.4997394MixupTrain:  epoch  0, batch   520 | loss: 2.5925205MixupTrain:  epoch  0, batch   521 | loss: 2.5674427MixupTrain:  epoch  0, batch   522 | loss: 2.3650048MixupTrain:  epoch  0, batch   523 | loss: 2.3588641MixupTrain:  epoch  0, batch   524 | loss: 2.3970399MixupTrain:  epoch  0, batch   525 | loss: 2.4323738MixupTrain:  epoch  0, batch   526 | loss: 2.5299964MixupTrain:  epoch  0, batch   527 | loss: 2.3445523MixupTrain:  epoch  0, batch   528 | loss: 2.4103253MixupTrain:  epoch  0, batch   529 | loss: 2.5910110MixupTrain:  epoch  0, batch   530 | loss: 2.3034892MixupTrain:  epoch  0, batch   531 | loss: 2.8373713MixupTrain:  epoch  0, batch   532 | loss: 2.4317656MixupTrain:  epoch  0, batch   533 | loss: 2.5064232MixupTrain:  epoch  0, batch   534 | loss: 2.3356121MixupTrain:  epoch  0, batch   535 | loss: 2.5483520MixupTrain:  epoch  0, batch   536 | loss: 2.1579633MixupTrain:  epoch  0, batch   537 | loss: 2.4197145MixupTrain:  epoch  0, batch   538 | loss: 2.3297884MixupTrain:  epoch  0, batch   539 | loss: 2.2656715MixupTrain:  epoch  0, batch   540 | loss: 2.4039493MixupTrain:  epoch  0, batch   541 | loss: 2.4155235MixupTrain:  epoch  0, batch   542 | loss: 2.3527064MixupTrain:  epoch  0, batch   543 | loss: 2.1707482MixupTrain:  epoch  0, batch   544 | loss: 2.4849038MixupTrain:  epoch  0, batch   545 | loss: 2.0727615MixupTrain:  epoch  0, batch   546 | loss: 2.4822583MixupTrain:  epoch  0, batch   547 | loss: 2.2803349MixupTrain:  epoch  0, batch   548 | loss: 2.3886709MixupTrain:  epoch  0, batch   549 | loss: 2.2957921MixupTrain:  epoch  0, batch   550 | loss: 2.2952294MixupTrain:  epoch  0, batch   551 | loss: 2.5855942MixupTrain:  epoch  0, batch   552 | loss: 2.6084805MixupTrain:  epoch  0, batch   553 | loss: 2.3432155MixupTrain:  epoch  0, batch   554 | loss: 2.4009547MixupTrain:  epoch  0, batch   555 | loss: 2.2742629MixupTrain:  epoch  0, batch   556 | loss: 2.2999079MixupTrain:  epoch  0, batch   557 | loss: 2.3466141MixupTrain:  epoch  0, batch   558 | loss: 2.0781784MixupTrain:  epoch  0, batch   559 | loss: 2.4975202MixupTrain:  epoch  0, batch   560 | loss: 2.6204216MixupTrain:  epoch  0, batch   561 | loss: 2.3501232MixupTrain:  epoch  0, batch   562 | loss: 2.2166147MixupTrain:  epoch  0, batch   563 | loss: 2.6173496MixupTrain:  epoch  0, batch   564 | loss: 2.4272742MixupTrain:  epoch  0, batch   565 | loss: 2.3018308MixupTrain:  epoch  0, batch   566 | loss: 2.2604320MixupTrain:  epoch  0, batch   567 | loss: 2.1422243MixupTrain:  epoch  0, batch   568 | loss: 2.1082053MixupTrain:  epoch  0, batch   569 | loss: 2.6400819MixupTrain:  epoch  0, batch   570 | loss: 2.5068312MixupTrain:  epoch  0, batch   571 | loss: 2.1994092MixupTrain:  epoch  0, batch   572 | loss: 2.0854878MixupTrain:  epoch  0, batch   573 | loss: 2.2563529MixupTrain:  epoch  0, batch   574 | loss: 2.9447789MixupTrain:  epoch  0, batch   575 | loss: 2.4532976MixupTrain:  epoch  0, batch   576 | loss: 2.4627151MixupTrain:  epoch  0, batch   577 | loss: 2.2416072MixupTrain:  epoch  0, batch   578 | loss: 2.4328642MixupTrain:  epoch  0, batch   579 | loss: 2.3348038MixupTrain:  epoch  0, batch   580 | loss: 2.2959654MixupTrain:  epoch  0, batch   581 | loss: 2.4057355MixupTrain:  epoch  0, batch   582 | loss: 2.2946157MixupTrain:  epoch  0, batch   583 | loss: 2.6082294MixupTrain:  epoch  0, batch   584 | loss: 2.6580353MixupTrain:  epoch  0, batch   585 | loss: 2.1141760MixupTrain:  epoch  0, batch   586 | loss: 2.1098404MixupTrain:  epoch  0, batch   587 | loss: 2.8111937MixupTrain:  epoch  0, batch   588 | loss: 2.3494864MixupTrain:  epoch  0, batch   589 | loss: 2.2346454MixupTrain:  epoch  0, batch   590 | loss: 2.4470620MixupTrain:  epoch  0, batch   591 | loss: 2.5007873MixupTrain:  epoch  0, batch   592 | loss: 2.5662708MixupTrain:  epoch  0, batch   593 | loss: 2.3278952MixupTrain:  epoch  0, batch   594 | loss: 2.1783216MixupTrain:  epoch  0, batch   595 | loss: 2.3957810MixupTrain:  epoch  0, batch   596 | loss: 2.2374835MixupTrain:  epoch  0, batch   597 | loss: 2.3752246MixupTrain:  epoch  0, batch   598 | loss: 2.3993311MixupTrain:  epoch  0, batch   599 | loss: 2.4047372MixupTrain:  epoch  0, batch   600 | loss: 2.5720515MixupTrain:  epoch  0, batch   601 | loss: 2.2791467MixupTrain:  epoch  0, batch   602 | loss: 2.4800506MixupTrain:  epoch  0, batch   603 | loss: 2.2226210MixupTrain:  epoch  0, batch   604 | loss: 2.3206577MixupTrain:  epoch  0, batch   605 | loss: 2.2379439MixupTrain:  epoch  0, batch   606 | loss: 2.1844287MixupTrain:  epoch  0, batch   607 | loss: 2.3985269MixupTrain:  epoch  0, batch   608 | loss: 2.4202244MixupTrain:  epoch  0, batch   609 | loss: 2.4985726MixupTrain:  epoch  0, batch   610 | loss: 2.6093850MixupTrain:  epoch  0, batch   611 | loss: 2.1556540MixupTrain:  epoch  0, batch   612 | loss: 2.6231093MixupTrain:  epoch  0, batch   613 | loss: 2.3136191MixupTrain:  epoch  0, batch   614 | loss: 2.9038424MixupTrain:  epoch  0, batch   615 | loss: 2.5665994MixupTrain:  epoch  0, batch   616 | loss: 2.5550334MixupTrain:  epoch  0, batch   617 | loss: 2.0493238MixupTrain:  epoch  0, batch   618 | loss: 2.3784714MixupTrain:  epoch  0, batch   619 | loss: 2.2241764MixupTrain:  epoch  0, batch   620 | loss: 1.9379411MixupTrain:  epoch  0, batch   621 | loss: 2.6039329MixupTrain:  epoch  0, batch   622 | loss: 2.1844673MixupTrain:  epoch  0, batch   623 | loss: 2.4583530MixupTrain:  epoch  0, batch   624 | loss: 2.1252391MixupTrain:  epoch  0, batch   625 | loss: 2.1622968MixupTrain:  epoch  0, batch   626 | loss: 2.4677804MixupTrain:  epoch  0, batch   627 | loss: 2.4444768MixupTrain:  epoch  0, batch   628 | loss: 2.5519953MixupTrain:  epoch  0, batch   629 | loss: 2.1698623MixupTrain:  epoch  0, batch   630 | loss: 2.5525880MixupTrain:  epoch  0, batch   631 | loss: 2.1628101MixupTrain:  epoch  0, batch   632 | loss: 2.6035810MixupTrain:  epoch  0, batch   633 | loss: 2.1341913MixupTrain:  epoch  0, batch   634 | loss: 2.2538185MixupTrain:  epoch  0, batch   635 | loss: 2.5872686MixupTrain:  epoch  0, batch   636 | loss: 2.1684542MixupTrain:  epoch  0, batch   637 | loss: 2.4293165MixupTrain:  epoch  0, batch   638 | loss: 2.4714804MixupTrain:  epoch  0, batch   639 | loss: 2.2214477MixupTrain:  epoch  0, batch   640 | loss: 2.4572291MixupTrain:  epoch  0, batch   641 | loss: 2.4918349MixupTrain:  epoch  0, batch   642 | loss: 2.3596239MixupTrain:  epoch  0, batch   643 | loss: 2.3176763MixupTrain:  epoch  0, batch   644 | loss: 2.1180608MixupTrain:  epoch  0, batch   645 | loss: 2.4181170MixupTrain:  epoch  0, batch   646 | loss: 2.4239593MixupTrain:  epoch  0, batch   647 | loss: 2.3514352MixupTrain:  epoch  0, batch   648 | loss: 2.3990157MixupTrain:  epoch  0, batch   649 | loss: 2.1152635MixupTrain:  epoch  0, batch   650 | loss: 2.4388175MixupTrain:  epoch  0, batch   651 | loss: 2.4079678MixupTrain:  epoch  0, batch   652 | loss: 2.5536981MixupTrain:  epoch  0, batch   653 | loss: 2.3389454MixupTrain:  epoch  0, batch   654 | loss: 2.2635121MixupTrain:  epoch  0, batch   655 | loss: 2.5177550MixupTrain:  epoch  0, batch   656 | loss: 2.4589210MixupTrain:  epoch  0, batch   657 | loss: 2.4114335MixupTrain:  epoch  0, batch   658 | loss: 2.7192416MixupTrain:  epoch  0, batch   659 | loss: 2.5092692MixupTrain:  epoch  0, batch   660 | loss: 2.3783631MixupTrain:  epoch  0, batch   661 | loss: 2.2306709MixupTrain:  epoch  0, batch   662 | loss: 2.3279910MixupTrain:  epoch  0, batch   663 | loss: 2.3266573MixupTrain:  epoch  0, batch   664 | loss: 2.4414005MixupTrain:  epoch  0, batch   665 | loss: 2.4035337MixupTrain:  epoch  0, batch   666 | loss: 2.0633974MixupTrain:  epoch  0, batch   667 | loss: 2.3056436MixupTrain:  epoch  0, batch   668 | loss: 2.2410078MixupTrain:  epoch  0, batch   669 | loss: 2.2384462MixupTrain:  epoch  0, batch   670 | loss: 2.3758974MixupTrain:  epoch  0, batch   671 | loss: 2.4459810MixupTrain:  epoch  0, batch   672 | loss: 2.6275902MixupTrain:  epoch  0, batch   673 | loss: 2.3249021MixupTrain:  epoch  0, batch   674 | loss: 2.4641280MixupTrain:  epoch  0, batch   675 | loss: 2.4123700MixupTrain:  epoch  0, batch   676 | loss: 2.4055018MixupTrain:  epoch  0, batch   677 | loss: 2.2945385MixupTrain:  epoch  0, batch   678 | loss: 2.4821770MixupTrain:  epoch  0, batch   679 | loss: 2.3178949MixupTrain:  epoch  0, batch   680 | loss: 2.4412076MixupTrain:  epoch  0, batch   681 | loss: 2.3157043MixupTrain:  epoch  0, batch   682 | loss: 2.4493122MixupTrain:  epoch  0, batch   683 | loss: 2.3078461MixupTrain:  epoch  0, batch   684 | loss: 2.2082758MixupTrain:  epoch  0, batch   685 | loss: 2.5613298MixupTrain:  epoch  0, batch   686 | loss: 2.2665672MixupTrain:  epoch  0, batch   687 | loss: 2.1587994MixupTrain:  epoch  0, batch   688 | loss: 2.1560416MixupTrain:  epoch  0, batch   689 | loss: 2.2631068MixupTrain:  epoch  0, batch   690 | loss: 2.5320251MixupTrain:  epoch  0, batch   691 | loss: 2.4465246MixupTrain:  epoch  0, batch   692 | loss: 2.3595510MixupTrain:  epoch  0, batch   693 | loss: 2.1759965MixupTrain:  epoch  0, batch   694 | loss: 2.6357598MixupTrain:  epoch  0, batch   695 | loss: 2.2343302MixupTrain:  epoch  0, batch   696 | loss: 2.2208190MixupTrain:  epoch  0, batch   697 | loss: 2.4796748MixupTrain:  epoch  0, batch   698 | loss: 2.5094786MixupTrain:  epoch  0, batch   699 | loss: 2.2903411MixupTrain:  epoch  0, batch   700 | loss: 2.2593870MixupTrain:  epoch  0, batch   701 | loss: 2.1602061MixupTrain:  epoch  0, batch   702 | loss: 2.4678121MixupTrain:  epoch  0, batch   703 | loss: 2.5693841MixupTrain:  epoch  0, batch   704 | loss: 2.4047208MixupTrain:  epoch  0, batch   705 | loss: 2.2950253MixupTrain:  epoch  0, batch   706 | loss: 2.2532616MixupTrain:  epoch  0, batch   707 | loss: 2.1959348MixupTrain:  epoch  0, batch   708 | loss: 2.5589118MixupTrain:  epoch  0, batch   709 | loss: 2.5618048MixupTrain:  epoch  0, batch   710 | loss: 2.5208280MixupTrain:  epoch  0, batch   711 | loss: 2.4132342MixupTrain:  epoch  0, batch   712 | loss: 2.3667140MixupTrain:  epoch  0, batch   713 | loss: 2.2925458MixupTrain:  epoch  0, batch   714 | loss: 2.1708484MixupTrain:  epoch  0, batch   715 | loss: 2.2589290MixupTrain:  epoch  0, batch   716 | loss: 2.4898820MixupTrain:  epoch  0, batch   717 | loss: 2.8397193MixupTrain:  epoch  0, batch   718 | loss: 2.2727461MixupTrain:  epoch  0, batch   719 | loss: 2.2761207MixupTrain:  epoch  0, batch   720 | loss: 2.7548959MixupTrain:  epoch  0, batch   721 | loss: 2.4401422MixupTrain:  epoch  0, batch   722 | loss: 2.4351802MixupTrain:  epoch  0, batch   723 | loss: 2.7383876MixupTrain:  epoch  0, batch   724 | loss: 2.3534136MixupTrain:  epoch  0, batch   725 | loss: 2.4858739MixupTrain:  epoch  0, batch   726 | loss: 2.3513751MixupTrain:  epoch  0, batch   727 | loss: 2.3883896MixupTrain:  epoch  0, batch   728 | loss: 2.0398784MixupTrain:  epoch  0, batch   729 | loss: 2.7888947MixupTrain:  epoch  0, batch   730 | loss: 2.3682108MixupTrain:  epoch  0, batch   731 | loss: 2.4093931MixupTrain:  epoch  0, batch   732 | loss: 2.1358538MixupTrain:  epoch  0, batch   733 | loss: 2.3735795MixupTrain:  epoch  0, batch   734 | loss: 2.1968615MixupTrain:  epoch  0, batch   735 | loss: 2.3859980MixupTrain:  epoch  0, batch   736 | loss: 2.6720700MixupTrain:  epoch  0, batch   737 | loss: 2.3331921MixupTrain:  epoch  0, batch   738 | loss: 2.2135181MixupTrain:  epoch  0, batch   739 | loss: 2.2240336MixupTrain:  epoch  0, batch   740 | loss: 2.3952532MixupTrain:  epoch  0, batch   741 | loss: 2.4169009MixupTrain:  epoch  0, batch   742 | loss: 2.4457150MixupTrain:  epoch  0, batch   743 | loss: 2.6885972MixupTrain:  epoch  0, batch   744 | loss: 2.3763082MixupTrain:  epoch  0, batch   745 | loss: 2.4600773MixupTrain:  epoch  0, batch   746 | loss: 2.0899510MixupTrain:  epoch  0, batch   747 | loss: 2.1661031MixupTrain:  epoch  0, batch   748 | loss: 2.4773417MixupTrain:  epoch  0, batch   749 | loss: 2.4886746MixupTrain:  epoch  0, batch   750 | loss: 2.4052558MixupTrain:  epoch  0, batch   751 | loss: 2.4584360MixupTrain:  epoch  0, batch   752 | loss: 2.2975535MixupTrain:  epoch  0, batch   753 | loss: 2.2759418MixupTrain:  epoch  0, batch   754 | loss: 2.5120835MixupTrain:  epoch  0, batch   755 | loss: 2.4278395MixupTrain:  epoch  0, batch   756 | loss: 2.2386308MixupTrain:  epoch  0, batch   757 | loss: 2.4660635MixupTrain:  epoch  0, batch   758 | loss: 2.2667449MixupTrain:  epoch  0, batch   759 | loss: 2.3554571MixupTrain:  epoch  0, batch   760 | loss: 2.5595794MixupTrain:  epoch  0, batch   761 | loss: 2.3417366MixupTrain:  epoch  0, batch   762 | loss: 2.4677594MixupTrain:  epoch  0, batch   763 | loss: 2.2725515MixupTrain:  epoch  0, batch   764 | loss: 2.4622397MixupTrain:  epoch  0, batch   765 | loss: 2.5458283MixupTrain:  epoch  0, batch   766 | loss: 2.1439543MixupTrain:  epoch  0, batch   767 | loss: 2.3818603MixupTrain:  epoch  0, batch   768 | loss: 2.1985536MixupTrain:  epoch  0, batch   769 | loss: 2.1535485MixupTrain:  epoch  0, batch   770 | loss: 2.2274685MixupTrain:  epoch  0, batch   771 | loss: 2.4627185MixupTrain:  epoch  0, batch   772 | loss: 2.1954501MixupTrain:  epoch  0, batch   773 | loss: 2.5996354MixupTrain:  epoch  0, batch   774 | loss: 2.3703351MixupTrain:  epoch  0, batch   775 | loss: 2.4498875MixupTrain:  epoch  0, batch   776 | loss: 2.5799246MixupTrain:  epoch  0, batch   777 | loss: 2.2640908MixupTrain:  epoch  0, batch   778 | loss: 2.6511319MixupTrain:  epoch  0, batch   779 | loss: 2.3552074MixupTrain:  epoch  0, batch   780 | loss: 2.2122111MixupTrain:  epoch  0, batch   781 | loss: 2.5753655MixupTrain:  epoch  0, batch   782 | loss: 2.0447283MixupTrain:  epoch  0, batch   783 | loss: 2.3851557MixupTrain:  epoch  0, batch   784 | loss: 2.3493738MixupTrain:  epoch  0, batch   785 | loss: 2.4015808MixupTrain:  epoch  0, batch   786 | loss: 2.4119339MixupTrain:  epoch  0, batch   787 | loss: 2.7046814MixupTrain:  epoch  0, batch   788 | loss: 2.4703732MixupTrain:  epoch  0, batch   789 | loss: 2.4435353MixupTrain:  epoch  0, batch   790 | loss: 2.3731992MixupTrain:  epoch  0, batch   791 | loss: 2.2990365MixupTrain:  epoch  0, batch   792 | loss: 2.3494465MixupTrain:  epoch  0, batch   793 | loss: 2.3462486MixupTrain:  epoch  0, batch   794 | loss: 2.6564584MixupTrain:  epoch  0, batch   795 | loss: 2.3157589MixupTrain:  epoch  0, batch   796 | loss: 2.0034320MixupTrain:  epoch  0, batch   797 | loss: 2.2857223MixupTrain:  epoch  0, batch   798 | loss: 2.4748502MixupTrain:  epoch  0, batch   799 | loss: 2.4351344MixupTrain:  epoch  0, batch   800 | loss: 2.4060740MixupTrain:  epoch  0, batch   801 | loss: 2.1177349MixupTrain:  epoch  0, batch   802 | loss: 2.6862788MixupTrain:  epoch  0, batch   803 | loss: 2.4733949MixupTrain:  epoch  0, batch   804 | loss: 2.4073410MixupTrain:  epoch  0, batch   805 | loss: 2.4680088MixupTrain:  epoch  0, batch   806 | loss: 2.4638252MixupTrain:  epoch  0, batch   807 | loss: 2.7671504MixupTrain:  epoch  0, batch   808 | loss: 2.1597342MixupTrain:  epoch  0, batch   809 | loss: 2.4317241MixupTrain:  epoch  0, batch   810 | loss: 2.1964087MixupTrain:  epoch  0, batch   811 | loss: 2.4807391MixupTrain:  epoch  0, batch   812 | loss: 2.2393878MixupTrain:  epoch  0, batch   813 | loss: 3.0196538MixupTrain:  epoch  0, batch   814 | loss: 2.7191167MixupTrain:  epoch  0, batch   815 | loss: 2.3013549MixupTrain:  epoch  0, batch   816 | loss: 2.5912662MixupTrain:  epoch  0, batch   817 | loss: 2.4212778MixupTrain:  epoch  0, batch   818 | loss: 2.3948383MixupTrain:  epoch  0, batch   819 | loss: 2.4453499MixupTrain:  epoch  0, batch   820 | loss: 2.1784914MixupTrain:  epoch  0, batch   821 | loss: 2.0476468MixupTrain:  epoch  0, batch   822 | loss: 2.1429281MixupTrain:  epoch  0, batch   823 | loss: 2.5042949MixupTrain:  epoch  0, batch   824 | loss: 2.3803427MixupTrain:  epoch  0, batch   825 | loss: 2.0938220MixupTrain:  epoch  0, batch   826 | loss: 2.3019910MixupTrain:  epoch  0, batch   827 | loss: 2.2654154MixupTrain:  epoch  0, batch   828 | loss: 2.5074949MixupTrain:  epoch  0, batch   829 | loss: 2.2226083MixupTrain:  epoch  0, batch   830 | loss: 2.3041339MixupTrain:  epoch  0, batch   831 | loss: 2.4583120MixupTrain:  epoch  0, batch   832 | loss: 2.3084276MixupTrain:  epoch  0, batch   833 | loss: 2.3381536MixupTrain:  epoch  0, batch   834 | loss: 2.3026352MixupTrain:  epoch  0, batch   835 | loss: 2.0788407MixupTrain:  epoch  0, batch   836 | loss: 2.5672500MixupTrain:  epoch  0, batch   837 | loss: 2.5044253MixupTrain:  epoch  0, batch   838 | loss: 2.0137372MixupTrain:  epoch  0, batch   839 | loss: 2.3881123MixupTrain:  epoch  0, batch   840 | loss: 2.4457986MixupTrain:  epoch  0, batch   841 | loss: 2.3682592MixupTrain:  epoch  0, batch   842 | loss: 2.2512755MixupTrain:  epoch  0, batch   843 | loss: 2.5776894MixupTrain:  epoch  0, batch   844 | loss: 2.1632128MixupTrain:  epoch  0, batch   845 | loss: 2.3470953MixupTrain:  epoch  0, batch   846 | loss: 2.1522660MixupTrain:  epoch  0, batch   847 | loss: 2.4159846MixupTrain:  epoch  0, batch   848 | loss: 2.2051830MixupTrain:  epoch  0, batch   849 | loss: 2.1231301MixupTrain:  epoch  0, batch   850 | loss: 2.3366640MixupTrain:  epoch  0, batch   851 | loss: 2.4027896MixupTrain:  epoch  0, batch   852 | loss: 2.4016702MixupTrain:  epoch  0, batch   853 | loss: 2.5111835MixupTrain:  epoch  0, batch   854 | loss: 2.1312659MixupTrain:  epoch  0, batch   855 | loss: 2.1989493MixupTrain:  epoch  0, batch   856 | loss: 2.3843422MixupTrain:  epoch  0, batch   857 | loss: 2.2457533MixupTrain:  epoch  0, batch   858 | loss: 2.2977898MixupTrain:  epoch  0, batch   859 | loss: 2.2255249MixupTrain:  epoch  0, batch   860 | loss: 2.3690729MixupTrain:  epoch  0, batch   861 | loss: 2.4228122MixupTrain:  epoch  0, batch   862 | loss: 2.2757096MixupTrain:  epoch  0, batch   863 | loss: 2.6818430MixupTrain:  epoch  0, batch   864 | loss: 2.7472539MixupTrain:  epoch  0, batch   865 | loss: 2.2297883MixupTrain:  epoch  0, batch   866 | loss: 2.1730847MixupTrain:  epoch  0, batch   867 | loss: 2.2146006MixupTrain:  epoch  0, batch   868 | loss: 2.2886510MixupTrain:  epoch  0, batch   869 | loss: 2.1553507MixupTrain:  epoch  0, batch   870 | loss: 2.1529276MixupTrain:  epoch  0, batch   871 | loss: 2.3143270MixupTrain:  epoch  0, batch   872 | loss: 2.2674773MixupTrain:  epoch  0, batch   873 | loss: 2.3807859MixupTrain:  epoch  0, batch   874 | loss: 2.4171813MixupTrain:  epoch  0, batch   875 | loss: 2.4583220MixupTrain:  epoch  0, batch   876 | loss: 2.2187061MixupTrain:  epoch  0, batch   877 | loss: 2.4499061MixupTrain:  epoch  0, batch   878 | loss: 2.3390191MixupTrain:  epoch  0, batch   879 | loss: 2.3035948MixupTrain:  epoch  0, batch   880 | loss: 2.5681295MixupTrain:  epoch  0, batch   881 | loss: 2.4113357MixupTrain:  epoch  0, batch   882 | loss: 2.2850204MixupTrain:  epoch  0, batch   883 | loss: 2.2633822MixupTrain:  epoch  0, batch   884 | loss: 2.4200532MixupTrain:  epoch  0, batch   885 | loss: 2.0397344MixupTrain:  epoch  0, batch   886 | loss: 2.2006636MixupTrain:  epoch  0, batch   887 | loss: 2.3049233MixupTrain:  epoch  0, batch   888 | loss: 2.4519753MixupTrain:  epoch  0, batch   889 | loss: 2.0028396MixupTrain:  epoch  0, batch   890 | loss: 2.4436157MixupTrain:  epoch  0, batch   891 | loss: 2.4475541MixupTrain:  epoch  0, batch   892 | loss: 2.2740359MixupTrain:  epoch  0, batch   893 | loss: 2.3474011MixupTrain:  epoch  0, batch   894 | loss: 2.5055346MixupTrain:  epoch  0, batch   895 | loss: 2.4149313MixupTrain:  epoch  0, batch   896 | loss: 2.3086796MixupTrain:  epoch  0, batch   897 | loss: 2.2844748MixupTrain:  epoch  0, batch   898 | loss: 2.2507718MixupTrain:  epoch  0, batch   899 | loss: 2.3635774MixupTrain:  epoch  0, batch   900 | loss: 2.3968387MixupTrain:  epoch  0, batch   901 | loss: 2.2887232MixupTrain:  epoch  0, batch   902 | loss: 2.6598229MixupTrain:  epoch  0, batch   903 | loss: 2.5203245MixupTrain:  epoch  0, batch   904 | loss: 2.3422990MixupTrain:  epoch  0, batch   905 | loss: 2.3405294MixupTrain:  epoch  0, batch   906 | loss: 2.1970091MixupTrain:  epoch  0, batch   907 | loss: 2.4650402MixupTrain:  epoch  0, batch   908 | loss: 2.3932817MixupTrain:  epoch  0, batch   909 | loss: 2.2758615MixupTrain:  epoch  0, batch   910 | loss: 2.2766616MixupTrain:  epoch  0, batch   911 | loss: 2.1529028MixupTrain:  epoch  0, batch   912 | loss: 2.2340689MixupTrain:  epoch  0, batch   913 | loss: 2.4722195MixupTrain:  epoch  0, batch   914 | loss: 2.2376761MixupTrain:  epoch  0, batch   915 | loss: 2.5366497MixupTrain:  epoch  0, batch   916 | loss: 2.2695770MixupTrain:  epoch  0, batch   917 | loss: 2.4932873MixupTrain:  epoch  0, batch   918 | loss: 2.1990719MixupTrain:  epoch  0, batch   919 | loss: 2.3916562MixupTrain:  epoch  0, batch   920 | loss: 2.4867907MixupTrain:  epoch  0, batch   921 | loss: 2.5048304MixupTrain:  epoch  0, batch   922 | loss: 2.5998683MixupTrain:  epoch  0, batch   923 | loss: 2.3177648MixupTrain:  epoch  0, batch   924 | loss: 2.5117898MixupTrain:  epoch  0, batch   925 | loss: 2.4177625MixupTrain:  epoch  0, batch   926 | loss: 2.6540751MixupTrain:  epoch  0, batch   927 | loss: 2.3007407MixupTrain:  epoch  0, batch   928 | loss: 2.2391319MixupTrain:  epoch  0, batch   929 | loss: 2.4627974MixupTrain:  epoch  0, batch   930 | loss: 2.0140717MixupTrain:  epoch  0, batch   931 | loss: 2.4345288MixupTrain:  epoch  0, batch   932 | loss: 2.2939460MixupTrain:  epoch  0, batch   933 | loss: 2.1533146MixupTrain:  epoch  0, batch   934 | loss: 2.5412781MixupTrain:  epoch  0, batch   935 | loss: 2.6059258MixupTrain:  epoch  0, batch   936 | loss: 2.7733405MixupTrain:  epoch  0, batch   937 | loss: 2.4074664MixupTrain:  epoch  0, batch   938 | loss: 2.5430515MixupTrain:  epoch  0, batch   939 | loss: 2.2786393MixupTrain:  epoch  0, batch   940 | loss: 2.3752966MixupTrain:  epoch  0, batch   941 | loss: 2.4559507MixupTrain:  epoch  0, batch   942 | loss: 2.1297996MixupTrain:  epoch  0, batch   943 | loss: 2.4379034MixupTrain:  epoch  0, batch   944 | loss: 2.1824198MixupTrain:  epoch  0, batch   945 | loss: 2.5359859MixupTrain:  epoch  0, batch   946 | loss: 2.1972556MixupTrain:  epoch  0, batch   947 | loss: 2.2960086MixupTrain:  epoch  0, batch   948 | loss: 2.2730885MixupTrain:  epoch  0, batch   949 | loss: 2.2666097MixupTrain:  epoch  0, batch   950 | loss: 2.6196575MixupTrain:  epoch  0, batch   951 | loss: 2.6824458MixupTrain:  epoch  0, batch   952 | loss: 2.3367634MixupTrain:  epoch  0, batch   953 | loss: 2.2738395MixupTrain:  epoch  0, batch   954 | loss: 2.3233991MixupTrain:  epoch  0, batch   955 | loss: 2.5673814MixupTrain:  epoch  0, batch   956 | loss: 2.4986339MixupTrain:  epoch  0, batch   957 | loss: 1.9391505MixupTrain:  epoch  0, batch   958 | loss: 2.1896734MixupTrain:  epoch  0, batch   959 | loss: 2.2812595MixupTrain:  epoch  0, batch   960 | loss: 2.6155844MixupTrain:  epoch  0, batch   961 | loss: 2.1088991MixupTrain:  epoch  0, batch   962 | loss: 2.1510010MixupTrain:  epoch  0, batch   963 | loss: 2.4751277MixupTrain:  epoch  0, batch   964 | loss: 2.3635368MixupTrain:  epoch  0, batch   965 | loss: 2.6358767MixupTrain:  epoch  0, batch   966 | loss: 2.4513013MixupTrain:  epoch  0, batch   967 | loss: 2.3599448MixupTrain:  epoch  0, batch   968 | loss: 2.4792986MixupTrain:  epoch  0, batch   969 | loss: 2.2906344MixupTrain:  epoch  0, batch   970 | loss: 2.3059201MixupTrain:  epoch  0, batch   971 | loss: 2.2749453MixupTrain:  epoch  0, batch   972 | loss: 2.0470152MixupTrain:  epoch  0, batch   973 | loss: 2.5100682MixupTrain:  epoch  0, batch   974 | loss: 2.5329142MixupTrain:  epoch  0, batch   975 | loss: 2.3782282MixupTrain:  epoch  0, batch   976 | loss: 2.4004426MixupTrain:  epoch  0, batch   977 | loss: 2.4507196MixupTrain:  epoch  0, batch   978 | loss: 2.3647072MixupTrain:  epoch  0, batch   979 | loss: 2.5208058MixupTrain:  epoch  0, batch   980 | loss: 2.1882873MixupTrain:  epoch  0, batch   981 | loss: 2.4071474MixupTrain:  epoch  0, batch   982 | loss: 2.0976944MixupTrain:  epoch  0, batch   983 | loss: 2.3638258MixupTrain:  epoch  0, batch   984 | loss: 2.1035666MixupTrain:  epoch  0, batch   985 | loss: 2.2243543MixupTrain:  epoch  0, batch   986 | loss: 2.2838895MixupTrain:  epoch  0, batch   987 | loss: 2.4789894MixupTrain:  epoch  0, batch   988 | loss: 2.2700362MixupTrain:  epoch  0, batch   989 | loss: 2.4461503MixupTrain:  epoch  0, batch   990 | loss: 2.0218787MixupTrain:  epoch  0, batch   991 | loss: 2.4874725MixupTrain:  epoch  0, batch   992 | loss: 2.5752778MixupTrain:  epoch  0, batch   993 | loss: 2.1409557MixupTrain:  epoch  0, batch   994 | loss: 2.2715721MixupTrain:  epoch  0, batch   995 | loss: 2.4050174MixupTrain:  epoch  0, batch   996 | loss: 2.5785568MixupTrain:  epoch  0, batch   997 | loss: 2.2959976MixupTrain:  epoch  0, batch   998 | loss: 2.2997141MixupTrain:  epoch  0, batch   999 | loss: 2.3331087MixupTrain:  epoch  0, batch  1000 | loss: 2.1489730MixupTrain:  epoch  0, batch  1001 | loss: 2.4404278MixupTrain:  epoch  0, batch  1002 | loss: 2.1520715MixupTrain:  epoch  0, batch  1003 | loss: 2.4709854MixupTrain:  epoch  0, batch  1004 | loss: 2.2704799MixupTrain:  epoch  0, batch  1005 | loss: 2.3381445MixupTrain:  epoch  0, batch  1006 | loss: 2.3207893MixupTrain:  epoch  0, batch  1007 | loss: 2.5325587MixupTrain:  epoch  0, batch  1008 | loss: 2.3044510MixupTrain:  epoch  0, batch  1009 | loss: 2.3413215MixupTrain:  epoch  0, batch  1010 | loss: 2.5140667MixupTrain:  epoch  0, batch  1011 | loss: 2.3972034MixupTrain:  epoch  0, batch  1012 | loss: 2.3119655MixupTrain:  epoch  0, batch  1013 | loss: 2.4407859MixupTrain:  epoch  0, batch  1014 | loss: 2.3888083MixupTrain:  epoch  0, batch  1015 | loss: 2.6731882MixupTrain:  epoch  0, batch  1016 | loss: 2.8437686MixupTrain:  epoch  0, batch  1017 | loss: 2.3123732MixupTrain:  epoch  0, batch  1018 | loss: 2.2364230MixupTrain:  epoch  0, batch  1019 | loss: 2.4055574MixupTrain:  epoch  0, batch  1020 | loss: 2.4220796MixupTrain:  epoch  0, batch  1021 | loss: 2.4038129MixupTrain:  epoch  0, batch  1022 | loss: 2.2575243MixupTrain:  epoch  0, batch  1023 | loss: 2.5649619MixupTrain:  epoch  0, batch  1024 | loss: 2.5757520MixupTrain:  epoch  0, batch  1025 | loss: 2.3944712MixupTrain:  epoch  0, batch  1026 | loss: 1.9744437MixupTrain:  epoch  0, batch  1027 | loss: 2.3669009MixupTrain:  epoch  0, batch  1028 | loss: 2.3268549MixupTrain:  epoch  0, batch  1029 | loss: 2.7287571MixupTrain:  epoch  0, batch  1030 | loss: 2.5143111MixupTrain:  epoch  0, batch  1031 | loss: 2.5869379MixupTrain:  epoch  0, batch  1032 | loss: 2.2304358MixupTrain:  epoch  0, batch  1033 | loss: 2.0795624MixupTrain:  epoch  0, batch  1034 | loss: 2.2983670MixupTrain:  epoch  0, batch  1035 | loss: 2.1641927MixupTrain:  epoch  0, batch  1036 | loss: 2.1846559MixupTrain:  epoch  0, batch  1037 | loss: 2.4764228MixupTrain:  epoch  0, batch  1038 | loss: 2.3937204MixupTrain:  epoch  0, batch  1039 | loss: 2.4810786MixupTrain:  epoch  0, batch  1040 | loss: 2.2994881MixupTrain:  epoch  0, batch  1041 | loss: 2.4807425MixupTrain:  epoch  0, batch  1042 | loss: 2.4681463MixupTrain:  epoch  0, batch  1043 | loss: 2.2229829MixupTrain:  epoch  0, batch  1044 | loss: 2.5007057MixupTrain:  epoch  0, batch  1045 | loss: 2.6332264MixupTrain:  epoch  0, batch  1046 | loss: 2.5011327MixupTrain:  epoch  0, batch  1047 | loss: 2.6166153MixupTrain:  epoch  0, batch  1048 | loss: 2.2941804MixupTrain:  epoch  0, batch  1049 | loss: 2.0795326MixupTrain:  epoch  0, batch  1050 | loss: 2.3295338MixupTrain:  epoch  0, batch  1051 | loss: 2.6857686MixupTrain:  epoch  0, batch  1052 | loss: 2.1643672MixupTrain:  epoch  0, batch  1053 | loss: 2.6087036MixupTrain:  epoch  0, batch  1054 | loss: 2.3808460MixupTrain:  epoch  0, batch  1055 | loss: 2.3074760MixupTrain:  epoch  0, batch  1056 | loss: 2.4676769MixupTrain:  epoch  0, batch  1057 | loss: 2.0060029MixupTrain:  epoch  0, batch  1058 | loss: 2.1346765MixupTrain:  epoch  0, batch  1059 | loss: 2.0338457MixupTrain:  epoch  0, batch  1060 | loss: 2.3574126MixupTrain:  epoch  0, batch  1061 | loss: 2.2035429MixupTrain:  epoch  0, batch  1062 | loss: 2.0790589MixupTrain:  epoch  0, batch  1063 | loss: 2.4927371MixupTrain:  epoch  0, batch  1064 | loss: 2.2565668MixupTrain:  epoch  0, batch  1065 | loss: 2.1150105MixupTrain:  epoch  0, batch  1066 | loss: 2.2612486MixupTrain:  epoch  0, batch  1067 | loss: 2.5169697MixupTrain:  epoch  0, batch  1068 | loss: 2.4708955MixupTrain:  epoch  0, batch  1069 | loss: 2.1694288MixupTrain:  epoch  0, batch  1070 | loss: 2.2866197MixupTrain:  epoch  0, batch  1071 | loss: 2.5387225MixupTrain:  epoch  0, batch  1072 | loss: 2.4107494MixupTrain:  epoch  0, batch  1073 | loss: 2.2475193MixupTrain:  epoch  0, batch  1074 | loss: 2.4838648MixupTrain:  epoch  0, batch  1075 | loss: 2.0168862MixupTrain:  epoch  0, batch  1076 | loss: 2.0570045MixupTrain:  epoch  0, batch  1077 | loss: 2.3748646MixupTrain:  epoch  0, batch  1078 | loss: 2.3092015MixupTrain:  epoch  0, batch  1079 | loss: 2.3762445MixupTrain:  epoch  0, batch  1080 | loss: 2.2581563MixupTrain:  epoch  0, batch  1081 | loss: 2.2892482MixupTrain:  epoch  0, batch  1082 | loss: 2.3068845MixupTrain:  epoch  0, batch  1083 | loss: 2.4320030MixupTrain:  epoch  0, batch  1084 | loss: 2.3212790MixupTrain:  epoch  0, batch  1085 | loss: 2.2462959MixupTrain:  epoch  0, batch  1086 | loss: 2.4416842MixupTrain:  epoch  0, batch  1087 | loss: 2.5748901MixupTrain:  epoch  0, batch  1088 | loss: 2.6018190MixupTrain:  epoch  0, batch  1089 | loss: 2.4751248MixupTrain:  epoch  0, batch  1090 | loss: 2.5899885MixupTrain:  epoch  0, batch  1091 | loss: 2.1395779MixupTrain:  epoch  0, batch  1092 | loss: 2.1972485MixupTrain:  epoch  0, batch  1093 | loss: 2.4114637MixupTrain:  epoch  0, batch  1094 | loss: 2.3020003MixupTrain:  epoch  0, batch  1095 | loss: 2.5102363MixupTrain:  epoch  0, batch  1096 | loss: 2.3982332MixupTrain:  epoch  0, batch  1097 | loss: 2.3317487MixupTrain:  epoch  0, batch  1098 | loss: 2.4049978MixupTrain:  epoch  0, batch  1099 | loss: 2.1044276MixupTrain:  epoch  0, batch  1100 | loss: 1.9993597MixupTrain:  epoch  0, batch  1101 | loss: 2.5076256MixupTrain:  epoch  0, batch  1102 | loss: 2.6931129MixupTrain:  epoch  0, batch  1103 | loss: 2.1540956MixupTrain:  epoch  0, batch  1104 | loss: 2.4218154MixupTrain:  epoch  0, batch  1105 | loss: 2.3677616MixupTrain:  epoch  0, batch  1106 | loss: 2.5846307MixupTrain:  epoch  0, batch  1107 | loss: 2.3476503MixupTrain:  epoch  0, batch  1108 | loss: 2.2216482MixupTrain:  epoch  0, batch  1109 | loss: 2.3797116MixupTrain:  epoch  0, batch  1110 | loss: 2.3698483MixupTrain:  epoch  0, batch  1111 | loss: 2.5246792MixupTrain:  epoch  0, batch  1112 | loss: 2.1825848MixupTrain:  epoch  0, batch  1113 | loss: 2.3983154MixupTrain:  epoch  0, batch  1114 | loss: 2.3978472MixupTrain:  epoch  0, batch  1115 | loss: 2.2356763MixupTrain:  epoch  0, batch  1116 | loss: 2.2163541MixupTrain:  epoch  0, batch  1117 | loss: 2.2403798MixupTrain:  epoch  0, batch  1118 | loss: 2.1838427MixupTrain:  epoch  0, batch  1119 | loss: 2.0833769MixupTrain:  epoch  0, batch  1120 | loss: 2.4562187MixupTrain:  epoch  0, batch  1121 | loss: 2.3818438MixupTrain:  epoch  0, batch  1122 | loss: 2.2744977MixupTrain:  epoch  0, batch  1123 | loss: 2.5617695MixupTrain:  epoch  0, batch  1124 | loss: 2.0998056MixupTrain:  epoch  0, batch  1125 | loss: 2.2841759MixupTrain:  epoch  0, batch  1126 | loss: 2.2618246MixupTrain:  epoch  0, batch  1127 | loss: 2.6798539MixupTrain:  epoch  0, batch  1128 | loss: 2.0584383MixupTrain:  epoch  0, batch  1129 | loss: 2.1978555MixupTrain:  epoch  0, batch  1130 | loss: 2.4993374MixupTrain:  epoch  0, batch  1131 | loss: 2.7642839MixupTrain:  epoch  0, batch  1132 | loss: 2.5768845MixupTrain:  epoch  0, batch  1133 | loss: 2.4908392MixupTrain:  epoch  0, batch  1134 | loss: 2.2442479MixupTrain:  epoch  0, batch  1135 | loss: 2.2485704MixupTrain:  epoch  0, batch  1136 | loss: 2.5265601MixupTrain:  epoch  0, batch  1137 | loss: 2.4978251MixupTrain:  epoch  0, batch  1138 | loss: 2.2083786MixupTrain:  epoch  0, batch  1139 | loss: 2.3796291MixupTrain:  epoch  0, batch  1140 | loss: 2.2454476MixupTrain:  epoch  0, batch  1141 | loss: 2.4434257MixupTrain:  epoch  0, batch  1142 | loss: 2.5597954MixupTrain:  epoch  0, batch  1143 | loss: 2.2395210MixupTrain:  epoch  0, batch  1144 | loss: 2.1682773MixupTrain:  epoch  0, batch  1145 | loss: 2.5394473MixupTrain:  epoch  0, batch  1146 | loss: 2.2796431MixupTrain:  epoch  0, batch  1147 | loss: 2.2092628MixupTrain:  epoch  0, batch  1148 | loss: 2.3398743MixupTrain:  epoch  0, batch  1149 | loss: 2.3065176MixupTrain:  epoch  0, batch  1150 | loss: 2.1507435MixupTrain:  epoch  0, batch  1151 | loss: 2.0568662MixupTrain:  epoch  0, batch  1152 | loss: 2.4680681MixupTrain:  epoch  0, batch  1153 | loss: 2.4305353MixupTrain:  epoch  0, batch  1154 | loss: 2.5041890MixupTrain:  epoch  0, batch  1155 | loss: 2.2788808MixupTrain:  epoch  0, batch  1156 | loss: 2.3815215MixupTrain:  epoch  0, batch  1157 | loss: 2.3219824MixupTrain:  epoch  0, batch  1158 | loss: 2.2245493MixupTrain:  epoch  0, batch  1159 | loss: 2.4518838MixupTrain:  epoch  0, batch  1160 | loss: 2.5737619MixupTrain:  epoch  0, batch  1161 | loss: 2.5568161MixupTrain:  epoch  0, batch  1162 | loss: 2.2002513MixupTrain:  epoch  0, batch  1163 | loss: 2.0446801MixupTrain:  epoch  0, batch  1164 | loss: 2.3008373MixupTrain:  epoch  0, batch  1165 | loss: 1.8896345MixupTrain:  epoch  0, batch  1166 | loss: 2.4977236MixupTrain:  epoch  0, batch  1167 | loss: 2.2093911MixupTrain:  epoch  0, batch  1168 | loss: 2.3767962MixupTrain:  epoch  0, batch  1169 | loss: 2.5208733MixupTrain:  epoch  0, batch  1170 | loss: 2.2477727MixupTrain:  epoch  0, batch  1171 | loss: 2.6321082MixupTrain:  epoch  0, batch  1172 | loss: 2.4759030MixupTrain:  epoch  0, batch  1173 | loss: 2.5622785MixupTrain:  epoch  0, batch  1174 | loss: 2.2706251MixupTrain:  epoch  0, batch  1175 | loss: 2.2207029MixupTrain:  epoch  0, batch  1176 | loss: 2.5203919MixupTrain:  epoch  0, batch  1177 | loss: 2.5668230MixupTrain:  epoch  0, batch  1178 | loss: 2.3378727MixupTrain:  epoch  0, batch  1179 | loss: 2.4718103MixupTrain:  epoch  0, batch  1180 | loss: 2.2305732MixupTrain:  epoch  0, batch  1181 | loss: 2.3904488MixupTrain:  epoch  0, batch  1182 | loss: 2.1666965MixupTrain:  epoch  0, batch  1183 | loss: 2.5123489MixupTrain:  epoch  0, batch  1184 | loss: 2.4577723MixupTrain:  epoch  0, batch  1185 | loss: 2.8837957MixupTrain:  epoch  0, batch  1186 | loss: 2.6359520MixupTrain:  epoch  0, batch  1187 | loss: 2.3266110MixupTrain:  epoch  0, batch  1188 | loss: 2.4320891MixupTrain:  epoch  0, batch  1189 | loss: 2.2263978MixupTrain:  epoch  0, batch  1190 | loss: 2.1737659MixupTrain:  epoch  0, batch  1191 | loss: 2.7564273MixupTrain:  epoch  0, batch  1192 | loss: 2.5125833MixupTrain:  epoch  0, batch  1193 | loss: 2.4511969MixupTrain:  epoch  0, batch  1194 | loss: 2.5124662MixupTrain:  epoch  0, batch  1195 | loss: 2.1186733MixupTrain:  epoch  0, batch  1196 | loss: 2.5378838MixupTrain:  epoch  0, batch  1197 | loss: 2.1741979MixupTrain:  epoch  0, batch  1198 | loss: 2.4143076MixupTrain:  epoch  0, batch  1199 | loss: 2.2727547MixupTrain:  epoch  0, batch  1200 | loss: 2.4824226MixupTrain:  epoch  0, batch  1201 | loss: 2.3877993MixupTrain:  epoch  0, batch  1202 | loss: 2.6265931MixupTrain:  epoch  0, batch  1203 | loss: 2.2666404MixupTrain:  epoch  0, batch  1204 | loss: 2.4029648MixupTrain:  epoch  0, batch  1205 | loss: 2.4110703MixupTrain:  epoch  0, batch  1206 | loss: 2.1519656MixupTrain:  epoch  0, batch  1207 | loss: 2.5441940MixupTrain:  epoch  0, batch  1208 | loss: 2.3103867MixupTrain:  epoch  0, batch  1209 | loss: 2.3320787MixupTrain:  epoch  0, batch  1210 | loss: 2.6451998MixupTrain:  epoch  0, batch  1211 | loss: 2.2952399MixupTrain:  epoch  0, batch  1212 | loss: 2.3676820MixupTrain:  epoch  0, batch  1213 | loss: 2.3031309MixupTrain:  epoch  0, batch  1214 | loss: 2.5396430MixupTrain:  epoch  0, batch  1215 | loss: 2.1206989MixupTrain:  epoch  0, batch  1216 | loss: 2.6825860MixupTrain:  epoch  0, batch  1217 | loss: 2.1728225MixupTrain:  epoch  0, batch  1218 | loss: 2.8137183MixupTrain:  epoch  0, batch  1219 | loss: 2.5177956MixupTrain:  epoch  0, batch  1220 | loss: 2.2787969MixupTrain:  epoch  0, batch  1221 | loss: 2.2725730MixupTrain:  epoch  0, batch  1222 | loss: 2.0553594MixupTrain:  epoch  0, batch  1223 | loss: 2.3005569MixupTrain:  epoch  0, batch  1224 | loss: 2.3191223MixupTrain:  epoch  0, batch  1225 | loss: 2.2679811MixupTrain:  epoch  0, batch  1226 | loss: 2.4717622MixupTrain:  epoch  0, batch  1227 | loss: 2.3980439MixupTrain:  epoch  0, batch  1228 | loss: 2.1493866MixupTrain:  epoch  0, batch  1229 | loss: 2.2243772MixupTrain:  epoch  0, batch  1230 | loss: 2.3012278MixupTrain:  epoch  0, batch  1231 | loss: 2.2871859MixupTrain:  epoch  0, batch  1232 | loss: 2.3161402MixupTrain:  epoch  0, batch  1233 | loss: 2.3922460MixupTrain:  epoch  0, batch  1234 | loss: 2.3390408MixupTrain:  epoch  0, batch  1235 | loss: 2.3175578MixupTrain:  epoch  0, batch  1236 | loss: 2.3853922MixupTrain:  epoch  0, batch  1237 | loss: 2.4819155MixupTrain:  epoch  0, batch  1238 | loss: 2.3398881MixupTrain:  epoch  0, batch  1239 | loss: 2.4869313MixupTrain:  epoch  0, batch  1240 | loss: 2.2597218MixupTrain:  epoch  0, batch  1241 | loss: 2.2689090MixupTrain:  epoch  0, batch  1242 | loss: 2.4812322MixupTrain:  epoch  0, batch  1243 | loss: 2.1427059MixupTrain:  epoch  0, batch  1244 | loss: 2.7575955MixupTrain:  epoch  0, batch  1245 | loss: 2.4417775MixupTrain:  epoch  0, batch  1246 | loss: 2.2765915MixupTrain:  epoch  0, batch  1247 | loss: 2.3763416MixupTrain:  epoch  0, batch  1248 | loss: 2.1974068MixupTrain:  epoch  0, batch  1249 | loss: 2.4265723MixupTrain:  epoch  0, batch  1250 | loss: 2.5208969MixupTrain:  epoch  0, batch  1251 | loss: 2.2711816MixupTrain:  epoch  0, batch  1252 | loss: 2.4288278MixupTrain:  epoch  0, batch  1253 | loss: 2.4720254MixupTrain:  epoch  0, batch  1254 | loss: 2.6754770MixupTrain:  epoch  0, batch  1255 | loss: 2.2967267MixupTrain:  epoch  0, batch  1256 | loss: 2.9144468MixupTrain:  epoch  0, batch  1257 | loss: 2.5964417MixupTrain:  epoch  0, batch  1258 | loss: 2.2473822MixupTrain:  epoch  0, batch  1259 | loss: 2.2983212MixupTrain:  epoch  0, batch  1260 | loss: 2.5629897MixupTrain:  epoch  0, batch  1261 | loss: 2.2810330MixupTrain:  epoch  0, batch  1262 | loss: 2.5322442MixupTrain:  epoch  0, batch  1263 | loss: 2.2839091MixupTrain:  epoch  0, batch  1264 | loss: 2.1702585MixupTrain:  epoch  0, batch  1265 | loss: 2.6430271MixupTrain:  epoch  0, batch  1266 | loss: 2.3577764MixupTrain:  epoch  0, batch  1267 | loss: 2.4342744MixupTrain:  epoch  0, batch  1268 | loss: 2.4237728MixupTrain:  epoch  0, batch  1269 | loss: 2.3547800MixupTrain:  epoch  0, batch  1270 | loss: 2.4008803MixupTrain:  epoch  0, batch  1271 | loss: 2.1009376MixupTrain:  epoch  0, batch  1272 | loss: 2.4200187MixupTrain:  epoch  0, batch  1273 | loss: 2.3783131MixupTrain:  epoch  0, batch  1274 | loss: 2.3958421MixupTrain:  epoch  0, batch  1275 | loss: 2.4656899MixupTrain:  epoch  0, batch  1276 | loss: 2.4278862MixupTrain:  epoch  0, batch  1277 | loss: 2.0975542MixupTrain:  epoch  0, batch  1278 | loss: 2.6047683MixupTrain:  epoch  0, batch  1279 | loss: 2.5809875MixupTrain:  epoch  0, batch  1280 | loss: 2.3396046MixupTrain:  epoch  0, batch  1281 | loss: 2.0853558MixupTrain:  epoch  0, batch  1282 | loss: 2.5389385MixupTrain:  epoch  0, batch  1283 | loss: 2.2840414MixupTrain:  epoch  0, batch  1284 | loss: 2.1992183MixupTrain:  epoch  0, batch  1285 | loss: 1.9963624MixupTrain:  epoch  0, batch  1286 | loss: 2.4125805MixupTrain:  epoch  0, batch  1287 | loss: 2.0623651MixupTrain:  epoch  0, batch  1288 | loss: 2.5883780MixupTrain:  epoch  0, batch  1289 | loss: 2.2885356MixupTrain:  epoch  0, batch  1290 | loss: 2.3339338MixupTrain:  epoch  0, batch  1291 | loss: 2.4767091MixupTrain:  epoch  0, batch  1292 | loss: 2.2211838MixupTrain:  epoch  0, batch  1293 | loss: 2.2692847MixupTrain:  epoch  0, batch  1294 | loss: 2.2036743MixupTrain:  epoch  0, batch  1295 | loss: 2.4148786MixupTrain:  epoch  0, batch  1296 | loss: 2.3562453MixupTrain:  epoch  0, batch  1297 | loss: 2.2679322MixupTrain:  epoch  0, batch  1298 | loss: 2.1896873MixupTrain:  epoch  0, batch  1299 | loss: 2.1188080MixupTrain:  epoch  0, batch  1300 | loss: 2.4155412MixupTrain:  epoch  0, batch  1301 | loss: 2.2849023MixupTrain:  epoch  0, batch  1302 | loss: 2.5531294MixupTrain:  epoch  0, batch  1303 | loss: 2.1603885MixupTrain:  epoch  0, batch  1304 | loss: 2.4509082MixupTrain:  epoch  0, batch  1305 | loss: 2.6532311MixupTrain:  epoch  0, batch  1306 | loss: 2.3963394MixupTrain:  epoch  0, batch  1307 | loss: 2.5944490MixupTrain:  epoch  0, batch  1308 | loss: 2.4231071MixupTrain:  epoch  0, batch  1309 | loss: 2.4682941MixupTrain:  epoch  0, batch  1310 | loss: 2.2602327MixupTrain:  epoch  0, batch  1311 | loss: 2.3871555MixupTrain:  epoch  0, batch  1312 | loss: 2.7165117MixupTrain:  epoch  0, batch  1313 | loss: 2.5045795MixupTrain:  epoch  0, batch  1314 | loss: 2.2469306MixupTrain:  epoch  0, batch  1315 | loss: 2.1700420MixupTrain:  epoch  0, batch  1316 | loss: 2.6505520MixupTrain:  epoch  0, batch  1317 | loss: 2.2620108MixupTrain:  epoch  0, batch  1318 | loss: 2.5376172MixupTrain:  epoch  0, batch  1319 | loss: 2.3562322MixupTrain:  epoch  0, batch  1320 | loss: 2.1560755MixupTrain:  epoch  0, batch  1321 | loss: 2.2511568MixupTrain:  epoch  0, batch  1322 | loss: 2.0669131MixupTrain:  epoch  0, batch  1323 | loss: 2.4063997MixupTrain:  epoch  0, batch  1324 | loss: 2.4916148MixupTrain:  epoch  0, batch  1325 | loss: 2.5220942MixupTrain:  epoch  0, batch  1326 | loss: 2.3443394MixupTrain:  epoch  0, batch  1327 | loss: 2.4219503MixupTrain:  epoch  0, batch  1328 | loss: 2.3976381MixupTrain:  epoch  0, batch  1329 | loss: 2.6582918MixupTrain:  epoch  0, batch  1330 | loss: 2.7285767MixupTrain:  epoch  0, batch  1331 | loss: 2.4755182MixupTrain:  epoch  0, batch  1332 | loss: 2.1957335MixupTrain:  epoch  0, batch  1333 | loss: 2.3568718MixupTrain:  epoch  0, batch  1334 | loss: 2.4384170MixupTrain:  epoch  0, batch  1335 | loss: 2.1955023MixupTrain:  epoch  0, batch  1336 | loss: 2.3566246MixupTrain:  epoch  0, batch  1337 | loss: 2.4049563MixupTrain:  epoch  0, batch  1338 | loss: 2.3966932MixupTrain:  epoch  0, batch  1339 | loss: 2.7247505MixupTrain:  epoch  0, batch  1340 | loss: 2.0398815MixupTrain:  epoch  0, batch  1341 | loss: 2.4136066MixupTrain:  epoch  0, batch  1342 | loss: 2.3314810MixupTrain:  epoch  0, batch  1343 | loss: 1.9934976MixupTrain:  epoch  0, batch  1344 | loss: 2.3494349MixupTrain:  epoch  0, batch  1345 | loss: 2.6211724MixupTrain:  epoch  0, batch  1346 | loss: 2.1511989MixupTrain:  epoch  0, batch  1347 | loss: 2.1749635MixupTrain:  epoch  0, batch  1348 | loss: 2.6877298MixupTrain:  epoch  0, batch  1349 | loss: 2.2666018MixupTrain:  epoch  0, batch  1350 | loss: 1.9729501MixupTrain:  epoch  0, batch  1351 | loss: 2.3406610MixupTrain:  epoch  0, batch  1352 | loss: 2.2755070MixupTrain:  epoch  0, batch  1353 | loss: 2.0350871MixupTrain:  epoch  0, batch  1354 | loss: 2.0355895MixupTrain:  epoch  0, batch  1355 | loss: 2.4420300MixupTrain:  epoch  0, batch  1356 | loss: 2.5121369MixupTrain:  epoch  0, batch  1357 | loss: 2.1312566MixupTrain:  epoch  0, batch  1358 | loss: 2.6040232MixupTrain:  epoch  0, batch  1359 | loss: 2.2169132MixupTrain:  epoch  0, batch  1360 | loss: 2.6321640MixupTrain:  epoch  0, batch  1361 | loss: 2.1862788MixupTrain:  epoch  0, batch  1362 | loss: 2.4411669MixupTrain:  epoch  0, batch  1363 | loss: 2.3984022MixupTrain:  epoch  0, batch  1364 | loss: 2.3374436MixupTrain:  epoch  0, batch  1365 | loss: 2.1029491MixupTrain:  epoch  0, batch  1366 | loss: 2.5255141MixupTrain:  epoch  0, batch  1367 | loss: 2.5530617MixupTrain:  epoch  0, batch  1368 | loss: 2.4219732MixupTrain:  epoch  0, batch  1369 | loss: 2.0798802MixupTrain:  epoch  0, batch  1370 | loss: 2.5735543MixupTrain:  epoch  0, batch  1371 | loss: 2.1284096MixupTrain:  epoch  0, batch  1372 | loss: 2.7471652MixupTrain:  epoch  0, batch  1373 | loss: 2.4995008MixupTrain:  epoch  0, batch  1374 | loss: 2.5399389MixupTrain:  epoch  0, batch  1375 | loss: 2.5060222MixupTrain:  epoch  0, batch  1376 | loss: 2.4214282MixupTrain:  epoch  0, batch  1377 | loss: 2.2163136MixupTrain:  epoch  0, batch  1378 | loss: 2.5992794MixupTrain:  epoch  0, batch  1379 | loss: 2.3978634MixupTrain:  epoch  0, batch  1380 | loss: 2.4164875MixupTrain:  epoch  0, batch  1381 | loss: 2.6391525MixupTrain:  epoch  0, batch  1382 | loss: 2.3892617MixupTrain:  epoch  0, batch  1383 | loss: 2.2497063MixupTrain:  epoch  0, batch  1384 | loss: 2.2480488MixupTrain:  epoch  0, batch  1385 | loss: 2.4237967MixupTrain:  epoch  0, batch  1386 | loss: 2.1806638MixupTrain:  epoch  0, batch  1387 | loss: 2.4804971MixupTrain:  epoch  0, batch  1388 | loss: 2.2803211MixupTrain:  epoch  0, batch  1389 | loss: 2.4666586MixupTrain:  epoch  0, batch  1390 | loss: 2.1081767MixupTrain:  epoch  0, batch  1391 | loss: 2.1984615MixupTrain:  epoch  0, batch  1392 | loss: 2.2226672MixupTrain:  epoch  0, batch  1393 | loss: 2.3470607MixupTrain:  epoch  0, batch  1394 | loss: 2.3759055MixupTrain:  epoch  0, batch  1395 | loss: 2.2755916MixupTrain:  epoch  0, batch  1396 | loss: 2.7253587MixupTrain:  epoch  0, batch  1397 | loss: 2.0441887MixupTrain:  epoch  0, batch  1398 | loss: 2.5224640MixupTrain:  epoch  0, batch  1399 | loss: 2.4037938MixupTrain:  epoch  0, batch  1400 | loss: 2.3599102MixupTrain:  epoch  0, batch  1401 | loss: 2.1905417MixupTrain:  epoch  0, batch  1402 | loss: 2.4472625MixupTrain:  epoch  0, batch  1403 | loss: 2.3633616MixupTrain:  epoch  0, batch  1404 | loss: 2.2302966MixupTrain:  epoch  0, batch  1405 | loss: 2.2660379MixupTrain:  epoch  0, batch  1406 | loss: 2.5331309MixupTrain:  epoch  0, batch  1407 | loss: 2.3708434MixupTrain:  epoch  0, batch  1408 | loss: 2.6015882MixupTrain:  epoch  0, batch  1409 | loss: 2.4197693MixupTrain:  epoch  0, batch  1410 | loss: 2.3790903MixupTrain:  epoch  0, batch  1411 | loss: 2.2233772MixupTrain:  epoch  0, batch  1412 | loss: 2.4126773MixupTrain:  epoch  0, batch  1413 | loss: 2.2989073MixupTrain:  epoch  0, batch  1414 | loss: 2.0320306MixupTrain:  epoch  0, batch  1415 | loss: 2.1258061MixupTrain:  epoch  0, batch  1416 | loss: 2.1280141MixupTrain:  epoch  0, batch  1417 | loss: 2.0601261MixupTrain:  epoch  0, batch  1418 | loss: 2.6040826MixupTrain:  epoch  0, batch  1419 | loss: 2.3246751MixupTrain:  epoch  0, batch  1420 | loss: 2.6175094MixupTrain:  epoch  0, batch  1421 | loss: 2.4109530MixupTrain:  epoch  0, batch  1422 | loss: 2.1810825MixupTrain:  epoch  0, batch  1423 | loss: 2.1913600MixupTrain:  epoch  0, batch  1424 | loss: 2.3407981MixupTrain:  epoch  0, batch  1425 | loss: 2.3700800MixupTrain:  epoch  0, batch  1426 | loss: 2.2658703MixupTrain:  epoch  0, batch  1427 | loss: 2.3202779MixupTrain:  epoch  0, batch  1428 | loss: 2.4163418MixupTrain:  epoch  0, batch  1429 | loss: 2.1661804MixupTrain:  epoch  0, batch  1430 | loss: 2.2461028MixupTrain:  epoch  0, batch  1431 | loss: 2.5717266MixupTrain:  epoch  0, batch  1432 | loss: 2.0958359MixupTrain:  epoch  0, batch  1433 | loss: 2.2442913MixupTrain:  epoch  0, batch  1434 | loss: 2.1019607MixupTrain:  epoch  0, batch  1435 | loss: 2.5570443MixupTrain:  epoch  0, batch  1436 | loss: 2.4933009MixupTrain:  epoch  0, batch  1437 | loss: 2.2316248MixupTrain:  epoch  0, batch  1438 | loss: 2.3169396MixupTrain:  epoch  0, batch  1439 | loss: 2.4026849MixupTrain:  epoch  0, batch  1440 | loss: 2.3653522MixupTrain:  epoch  0, batch  1441 | loss: 2.1722589MixupTrain:  epoch  0, batch  1442 | loss: 2.3101139MixupTrain:  epoch  0, batch  1443 | loss: 2.5011194MixupTrain:  epoch  0, batch  1444 | loss: 2.1671019MixupTrain:  epoch  0, batch  1445 | loss: 2.3453867MixupTrain:  epoch  0, batch  1446 | loss: 2.5296044MixupTrain:  epoch  0, batch  1447 | loss: 2.3782959MixupTrain:  epoch  0, batch  1448 | loss: 2.2546628MixupTrain:  epoch  0, batch  1449 | loss: 2.3251109MixupTrain:  epoch  0, batch  1450 | loss: 2.4431338MixupTrain:  epoch  0, batch  1451 | loss: 2.3369927MixupTrain:  epoch  0, batch  1452 | loss: 2.1528103MixupTrain:  epoch  0, batch  1453 | loss: 2.3479233MixupTrain:  epoch  0, batch  1454 | loss: 2.2944827MixupTrain:  epoch  0, batch  1455 | loss: 2.0847244MixupTrain:  epoch  0, batch  1456 | loss: 2.2839253MixupTrain:  epoch  0, batch  1457 | loss: 2.2253952MixupTrain:  epoch  0, batch  1458 | loss: 2.4265974MixupTrain:  epoch  0, batch  1459 | loss: 2.4110794MixupTrain:  epoch  0, batch  1460 | loss: 2.3046072MixupTrain:  epoch  0, batch  1461 | loss: 2.4815090MixupTrain:  epoch  0, batch  1462 | loss: 2.4302206MixupTrain:  epoch  0, batch  1463 | loss: 2.1163464MixupTrain:  epoch  0, batch  1464 | loss: 2.4977479MixupTrain:  epoch  0, batch  1465 | loss: 2.3213429MixupTrain:  epoch  0, batch  1466 | loss: 2.1153736MixupTrain:  epoch  0, batch  1467 | loss: 2.1799445MixupTrain:  epoch  0, batch  1468 | loss: 2.4233258MixupTrain:  epoch  0, batch  1469 | loss: 2.4189727MixupTrain:  epoch  0, batch  1470 | loss: 2.5023303MixupTrain:  epoch  0, batch  1471 | loss: 2.2652895MixupTrain:  epoch  0, batch  1472 | loss: 2.1689630MixupTrain:  epoch  0, batch  1473 | loss: 2.4363279MixupTrain:  epoch  0, batch  1474 | loss: 2.3815188MixupTrain:  epoch  0, batch  1475 | loss: 2.4849968MixupTrain:  epoch  0, batch  1476 | loss: 2.2819705MixupTrain:  epoch  0, batch  1477 | loss: 2.6162724MixupTrain:  epoch  0, batch  1478 | loss: 2.3569398MixupTrain:  epoch  0, batch  1479 | loss: 2.1891460MixupTrain:  epoch  0, batch  1480 | loss: 2.3922822MixupTrain:  epoch  0, batch  1481 | loss: 2.2688231MixupTrain:  epoch  0, batch  1482 | loss: 2.3745561MixupTrain:  epoch  0, batch  1483 | loss: 2.4142551MixupTrain:  epoch  0, batch  1484 | loss: 2.2101455MixupTrain:  epoch  0, batch  1485 | loss: 2.4878635MixupTrain:  epoch  0, batch  1486 | loss: 2.0495760MixupTrain:  epoch  0, batch  1487 | loss: 2.3616529MixupTrain:  epoch  0, batch  1488 | loss: 2.5201960MixupTrain:  epoch  0, batch  1489 | loss: 2.4048514MixupTrain:  epoch  0, batch  1490 | loss: 2.7095079MixupTrain:  epoch  0, batch  1491 | loss: 2.2507010MixupTrain:  epoch  0, batch  1492 | loss: 2.6375532MixupTrain:  epoch  0, batch  1493 | loss: 2.8170819MixupTrain:  epoch  0, batch  1494 | loss: 2.4172649MixupTrain:  epoch  0, batch  1495 | loss: 2.6972077MixupTrain:  epoch  0, batch  1496 | loss: 2.2620223MixupTrain:  epoch  0, batch  1497 | loss: 2.3952179MixupTrain:  epoch  0, batch  1498 | loss: 2.2924399MixupTrain:  epoch  0, batch  1499 | loss: 2.2439215MixupTrain:  epoch  0, batch  1500 | loss: 2.3595839MixupTrain:  epoch  0, batch  1501 | loss: 2.2902935MixupTrain:  epoch  0, batch  1502 | loss: 2.4698937MixupTrain:  epoch  0, batch  1503 | loss: 2.3407092MixupTrain:  epoch  0, batch  1504 | loss: 1.9636439MixupTrain:  epoch  0, batch  1505 | loss: 2.2047014MixupTrain:  epoch  0, batch  1506 | loss: 2.4043229MixupTrain:  epoch  0, batch  1507 | loss: 2.5520546MixupTrain:  epoch  0, batch  1508 | loss: 2.3261385MixupTrain:  epoch  0, batch  1509 | loss: 2.5171027MixupTrain:  epoch  0, batch  1510 | loss: 2.4200876MixupTrain:  epoch  0, batch  1511 | loss: 2.5512209MixupTrain:  epoch  0, batch  1512 | loss: 2.2281199MixupTrain:  epoch  0, batch  1513 | loss: 2.2643144MixupTrain:  epoch  0, batch  1514 | loss: 2.2944438MixupTrain:  epoch  0, batch  1515 | loss: 2.4538450MixupTrain:  epoch  0, batch  1516 | loss: 2.3313713MixupTrain:  epoch  0, batch  1517 | loss: 2.6703932MixupTrain:  epoch  0, batch  1518 | loss: 2.0444856MixupTrain:  epoch  0, batch  1519 | loss: 2.1489844MixupTrain:  epoch  0, batch  1520 | loss: 2.0267682MixupTrain:  epoch  0, batch  1521 | loss: 2.4718947MixupTrain:  epoch  0, batch  1522 | loss: 2.0931628MixupTrain:  epoch  0, batch  1523 | loss: 2.1711440MixupTrain:  epoch  0, batch  1524 | loss: 2.1406140MixupTrain:  epoch  0, batch  1525 | loss: 2.3854957MixupTrain:  epoch  0, batch  1526 | loss: 2.4676006MixupTrain:  epoch  0, batch  1527 | loss: 2.5587943MixupTrain:  epoch  0, batch  1528 | loss: 2.0552483MixupTrain:  epoch  0, batch  1529 | loss: 2.2819154MixupTrain:  epoch  0, batch  1530 | loss: 2.5666170MixupTrain:  epoch  0, batch  1531 | loss: 2.5837154MixupTrain:  epoch  0, batch  1532 | loss: 2.1791339MixupTrain:  epoch  0, batch  1533 | loss: 2.7707653MixupTrain:  epoch  0, batch  1534 | loss: 2.3926528MixupTrain:  epoch  0, batch  1535 | loss: 2.2667069MixupTrain:  epoch  0, batch  1536 | loss: 2.2952380MixupTrain:  epoch  0, batch  1537 | loss: 2.4622581MixupTrain:  epoch  0, batch  1538 | loss: 2.2848253MixupTrain:  epoch  0, batch  1539 | loss: 2.3709774MixupTrain:  epoch  0, batch  1540 | loss: 2.3535283MixupTrain:  epoch  0, batch  1541 | loss: 2.3256915MixupTrain:  epoch  0, batch  1542 | loss: 2.2925146MixupTrain:  epoch  0, batch  1543 | loss: 2.3625910MixupTrain:  epoch  0, batch  1544 | loss: 2.3149552MixupTrain:  epoch  0, batch  1545 | loss: 2.3373387MixupTrain:  epoch  0, batch  1546 | loss: 2.3529732MixupTrain:  epoch  0, batch  1547 | loss: 2.2840738MixupTrain:  epoch  0, batch  1548 | loss: 2.3897700MixupTrain:  epoch  0, batch  1549 | loss: 2.2281919MixupTrain:  epoch  0, batch  1550 | loss: 2.5262041MixupTrain:  epoch  0, batch  1551 | loss: 2.4660325MixupTrain:  epoch  0, batch  1552 | loss: 2.6268845MixupTrain:  epoch  0, batch  1553 | loss: 2.2834291MixupTrain:  epoch  0, batch  1554 | loss: 2.3831210MixupTrain:  epoch  0, batch  1555 | loss: 2.2002637MixupTrain:  epoch  0, batch  1556 | loss: 2.1237431MixupTrain:  epoch  0, batch  1557 | loss: 2.4884167MixupTrain:  epoch  0, batch  1558 | loss: 2.2228687MixupTrain:  epoch  0, batch  1559 | loss: 2.3274155MixupTrain:  epoch  0, batch  1560 | loss: 2.3090148MixupTrain:  epoch  0, batch  1561 | loss: 2.3984022MixupTrain:  epoch  0, batch  1562 | loss: 2.0235381MixupTrain:  epoch  0, batch  1563 | loss: 2.0596702MixupTrain:  epoch  0, batch  1564 | loss: 2.3661342MixupTrain:  epoch  0, batch  1565 | loss: 2.3479970MixupTrain:  epoch  0, batch  1566 | loss: 2.4404845MixupTrain:  epoch  0, batch  1567 | loss: 2.2291193MixupTrain:  epoch  0, batch  1568 | loss: 2.2454181MixupTrain:  epoch  0, batch  1569 | loss: 2.4725261MixupTrain:  epoch  0, batch  1570 | loss: 2.1955049MixupTrain:  epoch  0, batch  1571 | loss: 2.6081955MixupTrain:  epoch  0, batch  1572 | loss: 2.3761578MixupTrain:  epoch  0, batch  1573 | loss: 2.4190903MixupTrain:  epoch  0, batch  1574 | loss: 2.5339265MixupTrain:  epoch  0, batch  1575 | loss: 2.3883195MixupTrain:  epoch  0, batch  1576 | loss: 2.4131608MixupTrain:  epoch  0, batch  1577 | loss: 2.1663983MixupTrain:  epoch  0, batch  1578 | loss: 2.2372618MixupTrain:  epoch  0, batch  1579 | loss: 2.1594486MixupTrain:  epoch  0, batch  1580 | loss: 2.8785629MixupTrain:  epoch  0, batch  1581 | loss: 2.2800837MixupTrain:  epoch  0, batch  1582 | loss: 2.1864185MixupTrain:  epoch  0, batch  1583 | loss: 2.1154709MixupTrain:  epoch  0, batch  1584 | loss: 2.1197729MixupTrain:  epoch  0, batch  1585 | loss: 2.3585734MixupTrain:  epoch  0, batch  1586 | loss: 2.7104943MixupTrain:  epoch  0, batch  1587 | loss: 2.4789438MixupTrain:  epoch  0, batch  1588 | loss: 2.4531212MixupTrain:  epoch  0, batch  1589 | loss: 2.1727805MixupTrain:  epoch  0, batch  1590 | loss: 2.0608463MixupTrain:  epoch  0, batch  1591 | loss: 2.3152556MixupTrain:  epoch  0, batch  1592 | loss: 2.1027565MixupTrain:  epoch  0, batch  1593 | loss: 2.3037963MixupTrain:  epoch  0, batch  1594 | loss: 2.5225945MixupTrain:  epoch  0, batch  1595 | loss: 2.3149440MixupTrain:  epoch  0, batch  1596 | loss: 2.6171718MixupTrain:  epoch  0, batch  1597 | loss: 2.1513216MixupTrain:  epoch  0, batch  1598 | loss: 2.3640854MixupTrain:  epoch  0, batch  1599 | loss: 2.3504362MixupTrain:  epoch  0, batch  1600 | loss: 2.3133512MixupTrain:  epoch  0, batch  1601 | loss: 2.5001006MixupTrain:  epoch  0, batch  1602 | loss: 2.4125493MixupTrain:  epoch  0, batch  1603 | loss: 2.1621113MixupTrain:  epoch  0, batch  1604 | loss: 2.4196918MixupTrain:  epoch  0, batch  1605 | loss: 2.5122859MixupTrain:  epoch  0, batch  1606 | loss: 2.5629568MixupTrain:  epoch  0, batch  1607 | loss: 2.1721079MixupTrain:  epoch  0, batch  1608 | loss: 2.2700715MixupTrain:  epoch  0, batch  1609 | loss: 2.4254553MixupTrain:  epoch  0, batch  1610 | loss: 2.1993008MixupTrain:  epoch  0, batch  1611 | loss: 2.5859334MixupTrain:  epoch  0, batch  1612 | loss: 2.2328811MixupTrain:  epoch  0, batch  1613 | loss: 2.3750412MixupTrain:  epoch  0, batch  1614 | loss: 2.4561367MixupTrain:  epoch  0, batch  1615 | loss: 2.5487933MixupTrain:  epoch  0, batch  1616 | loss: 2.6043043MixupTrain:  epoch  0, batch  1617 | loss: 2.1919093MixupTrain:  epoch  0, batch  1618 | loss: 2.4443965MixupTrain:  epoch  0, batch  1619 | loss: 1.9192805MixupTrain:  epoch  0, batch  1620 | loss: 2.0034907MixupTrain:  epoch  0, batch  1621 | loss: 2.1680140MixupTrain:  epoch  0, batch  1622 | loss: 2.5041718MixupTrain:  epoch  0, batch  1623 | loss: 2.2499256MixupTrain:  epoch  0, batch  1624 | loss: 2.3286123MixupTrain:  epoch  0, batch  1625 | loss: 2.3722456MixupTrain:  epoch  0, batch  1626 | loss: 2.4785125MixupTrain:  epoch  0, batch  1627 | loss: 2.4190772MixupTrain:  epoch  0, batch  1628 | loss: 2.5144141MixupTrain:  epoch  0, batch  1629 | loss: 2.4225044MixupTrain:  epoch  0, batch  1630 | loss: 2.4993055MixupTrain:  epoch  0, batch  1631 | loss: 2.4249351MixupTrain:  epoch  0, batch  1632 | loss: 2.1968172MixupTrain:  epoch  0, batch  1633 | loss: 2.4444699MixupTrain:  epoch  0, batch  1634 | loss: 2.6349502MixupTrain:  epoch  0, batch  1635 | loss: 2.1940999MixupTrain:  epoch  0, batch  1636 | loss: 2.5062366MixupTrain:  epoch  0, batch  1637 | loss: 2.3677330MixupTrain:  epoch  0, batch  1638 | loss: 2.6833887MixupTrain:  epoch  0, batch  1639 | loss: 2.0642858MixupTrain:  epoch  0, batch  1640 | loss: 2.4253879MixupTrain:  epoch  0, batch  1641 | loss: 2.3291662MixupTrain:  epoch  0, batch  1642 | loss: 2.2843378MixupTrain:  epoch  0, batch  1643 | loss: 2.3312182MixupTrain:  epoch  0, batch  1644 | loss: 2.3379011MixupTrain:  epoch  0, batch  1645 | loss: 2.0705264MixupTrain:  epoch  0, batch  1646 | loss: 2.2141783MixupTrain:  epoch  0, batch  1647 | loss: 2.1679492MixupTrain:  epoch  0, batch  1648 | loss: 2.4385340MixupTrain:  epoch  0, batch  1649 | loss: 2.4269981MixupTrain:  epoch  0, batch  1650 | loss: 2.1430593MixupTrain:  epoch  0, batch  1651 | loss: 2.4066401MixupTrain:  epoch  0, batch  1652 | loss: 2.7410276MixupTrain:  epoch  0, batch  1653 | loss: 2.2894492MixupTrain:  epoch  0, batch  1654 | loss: 2.4740858MixupTrain:  epoch  0, batch  1655 | loss: 2.2733400MixupTrain:  epoch  0, batch  1656 | loss: 2.5426831MixupTrain:  epoch  0, batch  1657 | loss: 2.4129529MixupTrain:  epoch  0, batch  1658 | loss: 2.7284956MixupTrain:  epoch  0, batch  1659 | loss: 2.3404675MixupTrain:  epoch  0, batch  1660 | loss: 2.4519429MixupTrain:  epoch  0, batch  1661 | loss: 2.4138794MixupTrain:  epoch  0, batch  1662 | loss: 2.3887010MixupTrain:  epoch  0, batch  1663 | loss: 2.4332066MixupTrain:  epoch  0, batch  1664 | loss: 2.1521044MixupTrain:  epoch  0, batch  1665 | loss: 2.0686822MixupTrain:  epoch  0, batch  1666 | loss: 2.2505746MixupTrain:  epoch  0, batch  1667 | loss: 2.1367218MixupTrain:  epoch  0, batch  1668 | loss: 2.2238545MixupTrain:  epoch  0, batch  1669 | loss: 2.4015880MixupTrain:  epoch  0, batch  1670 | loss: 2.5436275MixupTrain:  epoch  0, batch  1671 | loss: 2.5470648MixupTrain:  epoch  0, batch  1672 | loss: 2.3414640MixupTrain:  epoch  0, batch  1673 | loss: 2.0769477MixupTrain:  epoch  0, batch  1674 | loss: 2.4638135MixupTrain:  epoch  0, batch  1675 | loss: 2.4201899MixupTrain:  epoch  0, batch  1676 | loss: 2.3485832MixupTrain:  epoch  0, batch  1677 | loss: 2.3318696MixupTrain:  epoch  0, batch  1678 | loss: 2.6188118MixupTrain:  epoch  0, batch  1679 | loss: 2.4879804MixupTrain:  epoch  0, batch  1680 | loss: 2.2805614MixupTrain:  epoch  0, batch  1681 | loss: 2.0784585MixupTrain:  epoch  0, batch  1682 | loss: 2.2143707MixupTrain:  epoch  0, batch  1683 | loss: 2.6490445MixupTrain:  epoch  0, batch  1684 | loss: 2.5589204MixupTrain:  epoch  0, batch  1685 | loss: 2.3508763MixupTrain:  epoch  0, batch  1686 | loss: 2.4250281MixupTrain:  epoch  0, batch  1687 | loss: 2.3763225MixupTrain:  epoch  0, batch  1688 | loss: 2.3639412MixupTrain:  epoch  0, batch  1689 | loss: 2.3276587MixupTrain:  epoch  0, batch  1690 | loss: 2.5788515MixupTrain:  epoch  0, batch  1691 | loss: 2.3099043MixupTrain:  epoch  0, batch  1692 | loss: 2.4066410MixupTrain:  epoch  0, batch  1693 | loss: 2.1852806MixupTrain:  epoch  0, batch  1694 | loss: 2.0781710MixupTrain:  epoch  0, batch  1695 | loss: 2.1769407MixupTrain:  epoch  0, batch  1696 | loss: 2.3604031MixupTrain:  epoch  0, batch  1697 | loss: 2.4353013MixupTrain:  epoch  0, batch  1698 | loss: 2.6868329MixupTrain:  epoch  0, batch  1699 | loss: 2.0128589MixupTrain:  epoch  0, batch  1700 | loss: 2.3789563MixupTrain:  epoch  0, batch  1701 | loss: 2.3940740MixupTrain:  epoch  0, batch  1702 | loss: 2.4030578MixupTrain:  epoch  0, batch  1703 | loss: 2.1555738MixupTrain:  epoch  0, batch  1704 | loss: 2.6884933MixupTrain:  epoch  0, batch  1705 | loss: 2.3556111MixupTrain:  epoch  0, batch  1706 | loss: 2.1733768MixupTrain:  epoch  0, batch  1707 | loss: 2.5286956MixupTrain:  epoch  0, batch  1708 | loss: 2.5190775MixupTrain:  epoch  0, batch  1709 | loss: 2.1467161MixupTrain:  epoch  0, batch  1710 | loss: 2.5237656MixupTrain:  epoch  0, batch  1711 | loss: 2.2070770MixupTrain:  epoch  0, batch  1712 | loss: 2.4553776MixupTrain:  epoch  0, batch  1713 | loss: 2.5080140MixupTrain:  epoch  0, batch  1714 | loss: 2.3305311MixupTrain:  epoch  0, batch  1715 | loss: 2.2962258MixupTrain:  epoch  0, batch  1716 | loss: 2.4330606MixupTrain:  epoch  0, batch  1717 | loss: 2.3001232MixupTrain:  epoch  0, batch  1718 | loss: 2.3466482MixupTrain:  epoch  0, batch  1719 | loss: 2.3114913MixupTrain:  epoch  0, batch  1720 | loss: 2.3272264MixupTrain:  epoch  0, batch  1721 | loss: 2.4459538MixupTrain:  epoch  0, batch  1722 | loss: 2.3576572MixupTrain:  epoch  0, batch  1723 | loss: 2.1462088MixupTrain:  epoch  0, batch  1724 | loss: 2.2292271MixupTrain:  epoch  0, batch  1725 | loss: 2.3491354MixupTrain:  epoch  0, batch  1726 | loss: 2.1765790MixupTrain:  epoch  0, batch  1727 | loss: 2.4200859MixupTrain:  epoch  0, batch  1728 | loss: 2.2833312MixupTrain:  epoch  0, batch  1729 | loss: 2.0777683MixupTrain:  epoch  0, batch  1730 | loss: 2.3672476MixupTrain:  epoch  0, batch  1731 | loss: 2.5253119MixupTrain:  epoch  0, batch  1732 | loss: 2.5841451MixupTrain:  epoch  0, batch  1733 | loss: 2.7117832MixupTrain:  epoch  0, batch  1734 | loss: 2.4818270MixupTrain:  epoch  0, batch  1735 | loss: 2.1017034MixupTrain:  epoch  0, batch  1736 | loss: 2.3529058MixupTrain:  epoch  0, batch  1737 | loss: 2.2553411MixupTrain:  epoch  0, batch  1738 | loss: 2.4061246MixupTrain:  epoch  0, batch  1739 | loss: 1.9671025MixupTrain:  epoch  0, batch  1740 | loss: 2.2148497MixupTrain:  epoch  0, batch  1741 | loss: 2.4003568MixupTrain:  epoch  0, batch  1742 | loss: 2.0820889MixupTrain:  epoch  0, batch  1743 | loss: 2.4877529MixupTrain:  epoch  0, batch  1744 | loss: 2.8139577MixupTrain:  epoch  0, batch  1745 | loss: 2.5392370MixupTrain:  epoch  0, batch  1746 | loss: 2.3825707MixupTrain:  epoch  0, batch  1747 | loss: 2.1408310MixupTrain:  epoch  0, batch  1748 | loss: 2.4275494MixupTrain:  epoch  0, batch  1749 | loss: 2.3287868MixupTrain:  epoch  0, batch  1750 | loss: 2.5956838MixupTrain:  epoch  0, batch  1751 | loss: 2.2935910MixupTrain:  epoch  0, batch  1752 | loss: 2.2838464MixupTrain:  epoch  0, batch  1753 | loss: 2.1086597MixupTrain:  epoch  0, batch  1754 | loss: 2.6640117MixupTrain:  epoch  0, batch  1755 | loss: 2.4669824MixupTrain:  epoch  0, batch  1756 | loss: 2.1875355MixupTrain:  epoch  0, batch  1757 | loss: 2.3661149MixupTrain:  epoch  0, batch  1758 | loss: 2.3385644MixupTrain:  epoch  0, batch  1759 | loss: 2.3530936MixupTrain:  epoch  0, batch  1760 | loss: 2.2391987MixupTrain:  epoch  0, batch  1761 | loss: 1.9294413
MemoryTrain:  epoch  0, batch     0 | loss: 2.4596181MemoryTrain:  epoch  0, batch     1 | loss: 2.6813223MemoryTrain:  epoch  0, batch     2 | loss: 2.6556273MemoryTrain:  epoch  0, batch     3 | loss: 2.6820080MemoryTrain:  epoch  0, batch     4 | loss: 2.7107410MemoryTrain:  epoch  0, batch     5 | loss: 2.2658896MemoryTrain:  epoch  0, batch     6 | loss: 2.2840080MemoryTrain:  epoch  0, batch     7 | loss: 2.9444747MemoryTrain:  epoch  0, batch     8 | loss: 2.2455328MemoryTrain:  epoch  0, batch     9 | loss: 2.1423888MemoryTrain:  epoch  0, batch    10 | loss: 1.8903310MemoryTrain:  epoch  0, batch    11 | loss: 1.9937029MemoryTrain:  epoch  0, batch    12 | loss: 2.3852034MemoryTrain:  epoch  0, batch    13 | loss: 2.2271180MemoryTrain:  epoch  1, batch     0 | loss: 1.8208191MemoryTrain:  epoch  1, batch     1 | loss: 1.8455560MemoryTrain:  epoch  1, batch     2 | loss: 1.8250809MemoryTrain:  epoch  1, batch     3 | loss: 1.8323705MemoryTrain:  epoch  1, batch     4 | loss: 1.8454142MemoryTrain:  epoch  1, batch     5 | loss: 1.8116560MemoryTrain:  epoch  1, batch     6 | loss: 1.8214537MemoryTrain:  epoch  1, batch     7 | loss: 2.4356649MemoryTrain:  epoch  1, batch     8 | loss: 2.0261254MemoryTrain:  epoch  1, batch     9 | loss: 1.9547803MemoryTrain:  epoch  1, batch    10 | loss: 1.8179545MemoryTrain:  epoch  1, batch    11 | loss: 1.9483733MemoryTrain:  epoch  1, batch    12 | loss: 1.9390386MemoryTrain:  epoch  1, batch    13 | loss: 1.9166108MemoryTrain:  epoch  2, batch     0 | loss: 1.8932747MemoryTrain:  epoch  2, batch     1 | loss: 1.8187757MemoryTrain:  epoch  2, batch     2 | loss: 1.9619470MemoryTrain:  epoch  2, batch     3 | loss: 1.9470538MemoryTrain:  epoch  2, batch     4 | loss: 1.8836830MemoryTrain:  epoch  2, batch     5 | loss: 1.8180878MemoryTrain:  epoch  2, batch     6 | loss: 1.9328501MemoryTrain:  epoch  2, batch     7 | loss: 1.8677619MemoryTrain:  epoch  2, batch     8 | loss: 1.9805723MemoryTrain:  epoch  2, batch     9 | loss: 1.8308706MemoryTrain:  epoch  2, batch    10 | loss: 1.8095448MemoryTrain:  epoch  2, batch    11 | loss: 1.8090836MemoryTrain:  epoch  2, batch    12 | loss: 1.8206513MemoryTrain:  epoch  2, batch    13 | loss: 1.8163173MemoryTrain:  epoch  3, batch     0 | loss: 1.8207611MemoryTrain:  epoch  3, batch     1 | loss: 1.8191448MemoryTrain:  epoch  3, batch     2 | loss: 1.9360220MemoryTrain:  epoch  3, batch     3 | loss: 1.8143711MemoryTrain:  epoch  3, batch     4 | loss: 1.8140990MemoryTrain:  epoch  3, batch     5 | loss: 1.8373384MemoryTrain:  epoch  3, batch     6 | loss: 1.8245648MemoryTrain:  epoch  3, batch     7 | loss: 1.8136005MemoryTrain:  epoch  3, batch     8 | loss: 1.8146122MemoryTrain:  epoch  3, batch     9 | loss: 1.8106751MemoryTrain:  epoch  3, batch    10 | loss: 1.8113129MemoryTrain:  epoch  3, batch    11 | loss: 1.8118215MemoryTrain:  epoch  3, batch    12 | loss: 1.8411192MemoryTrain:  epoch  3, batch    13 | loss: 1.8633492MemoryTrain:  epoch  4, batch     0 | loss: 1.8379309MemoryTrain:  epoch  4, batch     1 | loss: 1.8175623MemoryTrain:  epoch  4, batch     2 | loss: 1.8095170MemoryTrain:  epoch  4, batch     3 | loss: 1.8102806MemoryTrain:  epoch  4, batch     4 | loss: 1.8085124MemoryTrain:  epoch  4, batch     5 | loss: 1.8106310MemoryTrain:  epoch  4, batch     6 | loss: 1.8105897MemoryTrain:  epoch  4, batch     7 | loss: 1.8122123MemoryTrain:  epoch  4, batch     8 | loss: 1.8072753MemoryTrain:  epoch  4, batch     9 | loss: 1.8104823MemoryTrain:  epoch  4, batch    10 | loss: 1.8087282MemoryTrain:  epoch  4, batch    11 | loss: 1.8141305MemoryTrain:  epoch  4, batch    12 | loss: 1.8124139MemoryTrain:  epoch  4, batch    13 | loss: 1.8201290MemoryTrain:  epoch  5, batch     0 | loss: 1.8114686MemoryTrain:  epoch  5, batch     1 | loss: 1.8091471MemoryTrain:  epoch  5, batch     2 | loss: 1.8157773MemoryTrain:  epoch  5, batch     3 | loss: 1.8108697MemoryTrain:  epoch  5, batch     4 | loss: 1.8105440MemoryTrain:  epoch  5, batch     5 | loss: 1.8073717MemoryTrain:  epoch  5, batch     6 | loss: 1.8123921MemoryTrain:  epoch  5, batch     7 | loss: 1.8083425MemoryTrain:  epoch  5, batch     8 | loss: 1.8084015MemoryTrain:  epoch  5, batch     9 | loss: 1.8079937MemoryTrain:  epoch  5, batch    10 | loss: 1.8125479MemoryTrain:  epoch  5, batch    11 | loss: 1.8124059MemoryTrain:  epoch  5, batch    12 | loss: 1.8171670MemoryTrain:  epoch  5, batch    13 | loss: 1.8097020MemoryTrain:  epoch  6, batch     0 | loss: 1.8108077MemoryTrain:  epoch  6, batch     1 | loss: 1.8068185MemoryTrain:  epoch  6, batch     2 | loss: 1.8168948MemoryTrain:  epoch  6, batch     3 | loss: 1.8120197MemoryTrain:  epoch  6, batch     4 | loss: 1.8155001MemoryTrain:  epoch  6, batch     5 | loss: 1.8135359MemoryTrain:  epoch  6, batch     6 | loss: 1.8122258MemoryTrain:  epoch  6, batch     7 | loss: 1.8182101MemoryTrain:  epoch  6, batch     8 | loss: 1.8163874MemoryTrain:  epoch  6, batch     9 | loss: 1.8110180MemoryTrain:  epoch  6, batch    10 | loss: 1.8074543MemoryTrain:  epoch  6, batch    11 | loss: 1.8157027MemoryTrain:  epoch  6, batch    12 | loss: 1.8152053MemoryTrain:  epoch  6, batch    13 | loss: 1.8131723MemoryTrain:  epoch  7, batch     0 | loss: 1.8160264MemoryTrain:  epoch  7, batch     1 | loss: 1.8125519MemoryTrain:  epoch  7, batch     2 | loss: 1.8107452MemoryTrain:  epoch  7, batch     3 | loss: 1.8100803MemoryTrain:  epoch  7, batch     4 | loss: 1.8099737MemoryTrain:  epoch  7, batch     5 | loss: 1.8127567MemoryTrain:  epoch  7, batch     6 | loss: 1.8134317MemoryTrain:  epoch  7, batch     7 | loss: 1.8117954MemoryTrain:  epoch  7, batch     8 | loss: 1.8157498MemoryTrain:  epoch  7, batch     9 | loss: 1.8115976MemoryTrain:  epoch  7, batch    10 | loss: 1.8087134MemoryTrain:  epoch  7, batch    11 | loss: 1.8171840MemoryTrain:  epoch  7, batch    12 | loss: 1.8056427MemoryTrain:  epoch  7, batch    13 | loss: 1.8170966MemoryTrain:  epoch  8, batch     0 | loss: 1.8097571MemoryTrain:  epoch  8, batch     1 | loss: 1.8081187MemoryTrain:  epoch  8, batch     2 | loss: 1.8122281MemoryTrain:  epoch  8, batch     3 | loss: 1.8077754MemoryTrain:  epoch  8, batch     4 | loss: 1.8062054MemoryTrain:  epoch  8, batch     5 | loss: 1.8162363MemoryTrain:  epoch  8, batch     6 | loss: 1.8140662MemoryTrain:  epoch  8, batch     7 | loss: 1.8141346MemoryTrain:  epoch  8, batch     8 | loss: 1.8088766MemoryTrain:  epoch  8, batch     9 | loss: 1.8140793MemoryTrain:  epoch  8, batch    10 | loss: 1.8089854MemoryTrain:  epoch  8, batch    11 | loss: 1.8147154MemoryTrain:  epoch  8, batch    12 | loss: 1.8104446MemoryTrain:  epoch  8, batch    13 | loss: 1.8091038MemoryTrain:  epoch  9, batch     0 | loss: 1.8110796MemoryTrain:  epoch  9, batch     1 | loss: 1.8129156MemoryTrain:  epoch  9, batch     2 | loss: 1.8096020MemoryTrain:  epoch  9, batch     3 | loss: 1.8156235MemoryTrain:  epoch  9, batch     4 | loss: 1.8083326MemoryTrain:  epoch  9, batch     5 | loss: 1.8172735MemoryTrain:  epoch  9, batch     6 | loss: 1.8097792MemoryTrain:  epoch  9, batch     7 | loss: 1.8112130MemoryTrain:  epoch  9, batch     8 | loss: 1.8114154MemoryTrain:  epoch  9, batch     9 | loss: 1.8117704MemoryTrain:  epoch  9, batch    10 | loss: 1.8259894MemoryTrain:  epoch  9, batch    11 | loss: 1.8178127MemoryTrain:  epoch  9, batch    12 | loss: 1.8090008MemoryTrain:  epoch  9, batch    13 | loss: 1.8114583
[EVAL] batch:    0 | acc: 56.25%,  total acc: 56.25%   [EVAL] batch:    1 | acc: 75.00%,  total acc: 65.62%   [EVAL] batch:    2 | acc: 81.25%,  total acc: 70.83%   [EVAL] batch:    3 | acc: 81.25%,  total acc: 73.44%   [EVAL] batch:    4 | acc: 100.00%,  total acc: 78.75%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 82.29%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 83.93%   [EVAL] batch:    7 | acc: 87.50%,  total acc: 84.38%   [EVAL] batch:    8 | acc: 81.25%,  total acc: 84.03%   [EVAL] batch:    9 | acc: 75.00%,  total acc: 83.12%   [EVAL] batch:   10 | acc: 87.50%,  total acc: 83.52%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 84.38%   [EVAL] batch:   12 | acc: 56.25%,  total acc: 82.21%   
[EVAL] batch:    0 | acc: 0.00%,  total acc: 0.00%   [EVAL] batch:    1 | acc: 25.00%,  total acc: 12.50%   [EVAL] batch:    2 | acc: 6.25%,  total acc: 10.42%   [EVAL] batch:    3 | acc: 6.25%,  total acc: 9.38%   [EVAL] batch:    4 | acc: 6.25%,  total acc: 8.75%   [EVAL] batch:    5 | acc: 6.25%,  total acc: 8.33%   [EVAL] batch:    6 | acc: 6.25%,  total acc: 8.04%   [EVAL] batch:    7 | acc: 0.00%,  total acc: 7.03%   [EVAL] batch:    8 | acc: 0.00%,  total acc: 6.25%   [EVAL] batch:    9 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:   10 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:   11 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:   12 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:   13 | acc: 25.00%,  total acc: 7.59%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 12.08%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 14.84%   [EVAL] batch:   16 | acc: 68.75%,  total acc: 18.01%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 20.49%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 22.70%   [EVAL] batch:   19 | acc: 81.25%,  total acc: 25.62%   [EVAL] batch:   20 | acc: 93.75%,  total acc: 28.87%   [EVAL] batch:   21 | acc: 100.00%,  total acc: 32.10%   [EVAL] batch:   22 | acc: 93.75%,  total acc: 34.78%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 37.24%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 39.50%   [EVAL] batch:   25 | acc: 93.75%,  total acc: 41.59%   [EVAL] batch:   26 | acc: 62.50%,  total acc: 42.36%   [EVAL] batch:   27 | acc: 43.75%,  total acc: 42.41%   [EVAL] batch:   28 | acc: 62.50%,  total acc: 43.10%   [EVAL] batch:   29 | acc: 31.25%,  total acc: 42.71%   [EVAL] batch:   30 | acc: 56.25%,  total acc: 43.15%   [EVAL] batch:   31 | acc: 50.00%,  total acc: 43.36%   [EVAL] batch:   32 | acc: 31.25%,  total acc: 42.99%   [EVAL] batch:   33 | acc: 6.25%,  total acc: 41.91%   [EVAL] batch:   34 | acc: 6.25%,  total acc: 40.89%   [EVAL] batch:   35 | acc: 12.50%,  total acc: 40.10%   [EVAL] batch:   36 | acc: 0.00%,  total acc: 39.02%   [EVAL] batch:   37 | acc: 56.25%,  total acc: 39.47%   [EVAL] batch:   38 | acc: 75.00%,  total acc: 40.38%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 41.88%   [EVAL] batch:   40 | acc: 62.50%,  total acc: 42.38%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 43.75%   [EVAL] batch:   42 | acc: 6.25%,  total acc: 42.88%   [EVAL] batch:   43 | acc: 0.00%,  total acc: 41.90%   [EVAL] batch:   44 | acc: 0.00%,  total acc: 40.97%   [EVAL] batch:   45 | acc: 0.00%,  total acc: 40.08%   [EVAL] batch:   46 | acc: 12.50%,  total acc: 39.49%   [EVAL] batch:   47 | acc: 43.75%,  total acc: 39.58%   [EVAL] batch:   48 | acc: 0.00%,  total acc: 38.78%   [EVAL] batch:   49 | acc: 0.00%,  total acc: 38.00%   [EVAL] batch:   50 | acc: 0.00%,  total acc: 37.25%   [EVAL] batch:   51 | acc: 0.00%,  total acc: 36.54%   [EVAL] batch:   52 | acc: 0.00%,  total acc: 35.85%   [EVAL] batch:   53 | acc: 31.25%,  total acc: 35.76%   [EVAL] batch:   54 | acc: 93.75%,  total acc: 36.82%   [EVAL] batch:   55 | acc: 81.25%,  total acc: 37.61%   [EVAL] batch:   56 | acc: 75.00%,  total acc: 38.27%   [EVAL] batch:   57 | acc: 62.50%,  total acc: 38.69%   [EVAL] batch:   58 | acc: 62.50%,  total acc: 39.09%   [EVAL] batch:   59 | acc: 50.00%,  total acc: 39.27%   [EVAL] batch:   60 | acc: 6.25%,  total acc: 38.73%   [EVAL] batch:   61 | acc: 18.75%,  total acc: 38.41%   [EVAL] batch:   62 | acc: 12.50%,  total acc: 38.00%   [EVAL] batch:   63 | acc: 31.25%,  total acc: 37.89%   [EVAL] batch:   64 | acc: 12.50%,  total acc: 37.50%   [EVAL] batch:   65 | acc: 6.25%,  total acc: 37.03%   [EVAL] batch:   66 | acc: 18.75%,  total acc: 36.75%   [EVAL] batch:   67 | acc: 93.75%,  total acc: 37.59%   [EVAL] batch:   68 | acc: 50.00%,  total acc: 37.77%   [EVAL] batch:   69 | acc: 12.50%,  total acc: 37.41%   [EVAL] batch:   70 | acc: 37.50%,  total acc: 37.41%   [EVAL] batch:   71 | acc: 68.75%,  total acc: 37.85%   [EVAL] batch:   72 | acc: 100.00%,  total acc: 38.70%   [EVAL] batch:   73 | acc: 100.00%,  total acc: 39.53%   [EVAL] batch:   74 | acc: 100.00%,  total acc: 40.33%   [EVAL] batch:   75 | acc: 100.00%,  total acc: 41.12%   [EVAL] batch:   76 | acc: 100.00%,  total acc: 41.88%   [EVAL] batch:   77 | acc: 75.00%,  total acc: 42.31%   [EVAL] batch:   78 | acc: 0.00%,  total acc: 41.77%   [EVAL] batch:   79 | acc: 0.00%,  total acc: 41.25%   [EVAL] batch:   80 | acc: 6.25%,  total acc: 40.82%   [EVAL] batch:   81 | acc: 12.50%,  total acc: 40.47%   [EVAL] batch:   82 | acc: 6.25%,  total acc: 40.06%   [EVAL] batch:   83 | acc: 25.00%,  total acc: 39.88%   [EVAL] batch:   84 | acc: 50.00%,  total acc: 40.00%   [EVAL] batch:   85 | acc: 50.00%,  total acc: 40.12%   [EVAL] batch:   86 | acc: 37.50%,  total acc: 40.09%   [EVAL] batch:   87 | acc: 62.50%,  total acc: 40.34%   [EVAL] batch:   88 | acc: 56.25%,  total acc: 40.52%   [EVAL] batch:   89 | acc: 50.00%,  total acc: 40.62%   [EVAL] batch:   90 | acc: 56.25%,  total acc: 40.80%   [EVAL] batch:   91 | acc: 62.50%,  total acc: 41.03%   [EVAL] batch:   92 | acc: 50.00%,  total acc: 41.13%   [EVAL] batch:   93 | acc: 43.75%,  total acc: 41.16%   [EVAL] batch:   94 | acc: 43.75%,  total acc: 41.18%   [EVAL] batch:   95 | acc: 43.75%,  total acc: 41.21%   [EVAL] batch:   96 | acc: 43.75%,  total acc: 41.24%   [EVAL] batch:   97 | acc: 62.50%,  total acc: 41.45%   [EVAL] batch:   98 | acc: 37.50%,  total acc: 41.41%   [EVAL] batch:   99 | acc: 81.25%,  total acc: 41.81%   [EVAL] batch:  100 | acc: 87.50%,  total acc: 42.26%   [EVAL] batch:  101 | acc: 62.50%,  total acc: 42.46%   [EVAL] batch:  102 | acc: 93.75%,  total acc: 42.96%   [EVAL] batch:  103 | acc: 93.75%,  total acc: 43.45%   [EVAL] batch:  104 | acc: 93.75%,  total acc: 43.93%   [EVAL] batch:  105 | acc: 100.00%,  total acc: 44.46%   [EVAL] batch:  106 | acc: 68.75%,  total acc: 44.68%   [EVAL] batch:  107 | acc: 68.75%,  total acc: 44.91%   [EVAL] batch:  108 | acc: 81.25%,  total acc: 45.24%   [EVAL] batch:  109 | acc: 75.00%,  total acc: 45.51%   [EVAL] batch:  110 | acc: 100.00%,  total acc: 46.00%   [EVAL] batch:  111 | acc: 100.00%,  total acc: 46.48%   [EVAL] batch:  112 | acc: 93.75%,  total acc: 46.90%   [EVAL] batch:  113 | acc: 100.00%,  total acc: 47.37%   [EVAL] batch:  114 | acc: 87.50%,  total acc: 47.72%   [EVAL] batch:  115 | acc: 68.75%,  total acc: 47.90%   [EVAL] batch:  116 | acc: 75.00%,  total acc: 48.13%   [EVAL] batch:  117 | acc: 100.00%,  total acc: 48.57%   [EVAL] batch:  118 | acc: 81.25%,  total acc: 48.84%   
cur_acc:  ['0.8580', '0.8750', '0.8438', '0.9028', '0.6449', '0.7656', '0.8221']
his_acc:  ['0.8580', '0.8191', '0.7121', '0.6314', '0.6138', '0.5298', '0.4884']
CurrentTrain: epoch  0, batch     0 | loss: 4.8102908CurrentTrain: epoch  0, batch     1 | loss: 4.0923209CurrentTrain: epoch  1, batch     0 | loss: 3.5775170CurrentTrain: epoch  1, batch     1 | loss: 2.4117656CurrentTrain: epoch  2, batch     0 | loss: 2.7440088CurrentTrain: epoch  2, batch     1 | loss: 2.4633472CurrentTrain: epoch  3, batch     0 | loss: 2.3585801CurrentTrain: epoch  3, batch     1 | loss: 2.0445054CurrentTrain: epoch  4, batch     0 | loss: 2.2584200CurrentTrain: epoch  4, batch     1 | loss: 1.7999331CurrentTrain: epoch  5, batch     0 | loss: 2.0196893CurrentTrain: epoch  5, batch     1 | loss: 1.7595071CurrentTrain: epoch  6, batch     0 | loss: 1.7748940CurrentTrain: epoch  6, batch     1 | loss: 1.8982111CurrentTrain: epoch  7, batch     0 | loss: 1.7804523CurrentTrain: epoch  7, batch     1 | loss: 1.6857836CurrentTrain: epoch  8, batch     0 | loss: 1.6958177CurrentTrain: epoch  8, batch     1 | loss: 1.7474030CurrentTrain: epoch  9, batch     0 | loss: 1.7068646CurrentTrain: epoch  9, batch     1 | loss: 1.6791707
#### organization founded ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization founded" means an organization was found in a date.
Here is an example:
Relation: organization founded
Context: pandit worked at the brokerage morgan stanley for about 11 years until 2005 , when he and some morgan stanley colleagues quit and later founded the hedge fund old lane partners .
Head Entity: old lane partners
Tail Entity: 2005
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization founded":
Relation: organization founded  
Context: In 1998, a group of engineers and entrepreneurs came together to establish the tech startup, Innovatech Solutions, which has since become a leader in software development.  
Head Entity: Innovatech Solutions  
Tail Entity: 1998  

Relation: organization founded  
Context: The non-profit organization Green Earth Initiative was established in 2010 to promote environmental awareness and sustainability practices across communities.  
Head Entity: Green Earth Initiative  
Tail Entity: 2010  

Relation: organization founded  
Context: After years of research and development, the pharmaceutical company HealthPlus was founded in 2015 to focus on innovative healthcare solutions.  
Head Entity: HealthPlus  
Tail Entity: 2015  

Relation: organization founded  
Context: In 2001, the educational institution Future Leaders Academy was founded to provide quality education and leadership training to underprivileged youth.  
Head Entity: Future Leaders Academy  
Tail Entity: 2001  

Relation: organization founded  
Context: The fashion brand EcoWear was founded in 2020 with a mission to create sustainable clothing using recycled materials.  
Head Entity: EcoWear  
Tail Entity: 2020  
#### person age ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person age" means a person 's age is a number.
Here is an example:
Relation: person age
Context: paris , feb 23 -lrb- xinhua -rrb- yoadimnadji , 56 , died of a cardiovascular problem at midnight .
Head Entity: yoadimnadji
Tail Entity: 56
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person age":
Relation: person age  
Context: In a recent interview, the famous actor Robert Downey Jr. revealed that he is currently 58 years old.  
Head Entity: Robert Downey Jr.  
Tail Entity: 58  

Relation: person age  
Context: The renowned scientist, Dr. Jane Goodall, celebrated her 89th birthday last week, marking decades of groundbreaking research.  
Head Entity: Dr. Jane Goodall  
Tail Entity: 89  

Relation: person age  
Context: During the family reunion, my grandmother proudly announced that she has reached the age of 92, still full of energy and stories.  
Head Entity: my grandmother  
Tail Entity: 92  

Relation: person age  
Context: The young prodigy, Alex, has already made headlines at the age of 12 for his exceptional talent in mathematics.  
Head Entity: Alex  
Tail Entity: 12  

Relation: person age  
Context: At the annual conference, it was noted that the keynote speaker, Dr. Emily Carter, is 45 years old and has published numerous influential papers.  
Head Entity: Dr. Emily Carter  
Tail Entity: 45  
#### person city of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person city of birth" means a person was born in a city.
Here is an example:
Relation: person city of birth
Context: forsberg was born in 1943 in huntsville , ala. , and grew up on long island in new york .
Head Entity: forsberg
Tail Entity: huntsville
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person city of birth":
Relation: person city of birth  
Context: elena was born in 1990 in barcelona, spain, where she spent her childhood.  
Head Entity: elena  
Tail Entity: barcelona  

Relation: person city of birth  
Context: during a press conference, it was revealed that john was born in 1985 in san francisco, california.  
Head Entity: john  
Tail Entity: san francisco  

Relation: person city of birth  
Context: the famous author was born in 1975 in dublin, ireland, and later moved to london.  
Head Entity: the famous author  
Tail Entity: dublin  

Relation: person city of birth  
Context: after years of research, it was discovered that maria was born in 1968 in mexico city, mexico.  
Head Entity: maria  
Tail Entity: mexico city  

Relation: person city of birth  
Context: the documentary highlighted that samuel was born in 2000 in sydney, australia, before relocating to melbourne.  
Head Entity: samuel  
Tail Entity: sydney  
#### organization members ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization members" means an organization 's member is an organization.
Here is an example:
Relation: organization members
Context: sun plays for the grand rapids flight of the international basketball league after toiling for the maryland nighthawks of the american basketball association , both development leagues for those who dream of an nba career .
Head Entity: american basketball association
Tail Entity: maryland nighthawks
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization members":
Relation: organization members  
Context: The New York Philharmonic is one of the oldest orchestras in the United States, and it has had many notable musicians, including members from the Boston Symphony Orchestra.  
Head Entity: Boston Symphony Orchestra  
Tail Entity: New York Philharmonic  

Relation: organization members  
Context: The National Football League has various teams, and the Dallas Cowboys are one of its most famous members, often competing against the New England Patriots.  
Head Entity: New England Patriots  
Tail Entity: Dallas Cowboys  

Relation: organization members  
Context: The United Nations consists of various specialized agencies, including the World Health Organization, which plays a crucial role in global health initiatives.  
Head Entity: World Health Organization  
Tail Entity: United Nations  

Relation: organization members  
Context: The International Olympic Committee oversees the Olympic Games and includes various national committees, such as the United States Olympic and Paralympic Committee.  
Head Entity: United States Olympic and Paralympic Committee  
Tail Entity: International Olympic Committee  

Relation: organization members  
Context: The European Union is made up of several member states, including Germany, which plays a significant role in the EU's economic policies.  
Head Entity: Germany  
Tail Entity: European Union  
#### person religion ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person religion" means an person is the member of a religion.
Here is an example:
Relation: person religion
Context: the pope defended his action on the grounds that he could not refuse an audience to a head of state from a country with a strong catholic tradition unless he had clear-cut proof of the allegations against him .
Head Entity: he
Tail Entity: catholic
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person religion":
Relation: person religion  
Context: During the ceremony, the rabbi spoke about the importance of faith and community in Judaism, emphasizing how every member plays a vital role.  
Head Entity: rabbi  
Tail Entity: Judaism  

Relation: person religion  
Context: The famous author often drew inspiration from his Hindu upbringing, which influenced many themes in his novels.  
Head Entity: author  
Tail Entity: Hindu  

Relation: person religion  
Context: She often participates in community service organized by her church, reflecting her deep commitment to Christianity.  
Head Entity: She  
Tail Entity: Christianity  

Relation: person religion  
Context: The imam led the prayers at the mosque, guiding the congregation in their devotion to Islam.  
Head Entity: imam  
Tail Entity: Islam  

Relation: person religion  
Context: As a prominent figure in the Buddhist community, he frequently shares teachings that promote peace and mindfulness.  
Head Entity: figure  
Tail Entity: Buddhist  
Mixup data size:  35770
MixupTrain:  epoch  0, batch     0 | loss: 3.9681888MixupTrain:  epoch  0, batch     1 | loss: 3.2668681MixupTrain:  epoch  0, batch     2 | loss: 3.8095307MixupTrain:  epoch  0, batch     3 | loss: 4.2378273MixupTrain:  epoch  0, batch     4 | loss: 4.3210034MixupTrain:  epoch  0, batch     5 | loss: 3.8446035MixupTrain:  epoch  0, batch     6 | loss: 3.4271443MixupTrain:  epoch  0, batch     7 | loss: 3.5861740MixupTrain:  epoch  0, batch     8 | loss: 3.3607287MixupTrain:  epoch  0, batch     9 | loss: 3.0295289MixupTrain:  epoch  0, batch    10 | loss: 3.4566154MixupTrain:  epoch  0, batch    11 | loss: 3.9831700MixupTrain:  epoch  0, batch    12 | loss: 3.1309881MixupTrain:  epoch  0, batch    13 | loss: 4.1142406MixupTrain:  epoch  0, batch    14 | loss: 3.5916429MixupTrain:  epoch  0, batch    15 | loss: 2.8408704MixupTrain:  epoch  0, batch    16 | loss: 3.7363834MixupTrain:  epoch  0, batch    17 | loss: 2.5234368MixupTrain:  epoch  0, batch    18 | loss: 3.2982998MixupTrain:  epoch  0, batch    19 | loss: 2.8637538MixupTrain:  epoch  0, batch    20 | loss: 2.6064334MixupTrain:  epoch  0, batch    21 | loss: 2.9531226MixupTrain:  epoch  0, batch    22 | loss: 3.4710014MixupTrain:  epoch  0, batch    23 | loss: 3.6951163MixupTrain:  epoch  0, batch    24 | loss: 2.8269825MixupTrain:  epoch  0, batch    25 | loss: 4.1464005MixupTrain:  epoch  0, batch    26 | loss: 2.7242601MixupTrain:  epoch  0, batch    27 | loss: 3.1391747MixupTrain:  epoch  0, batch    28 | loss: 3.8730597MixupTrain:  epoch  0, batch    29 | loss: 3.5376558MixupTrain:  epoch  0, batch    30 | loss: 3.0313482MixupTrain:  epoch  0, batch    31 | loss: 3.5530393MixupTrain:  epoch  0, batch    32 | loss: 2.7616427MixupTrain:  epoch  0, batch    33 | loss: 4.2687221MixupTrain:  epoch  0, batch    34 | loss: 3.3048100MixupTrain:  epoch  0, batch    35 | loss: 3.3032670MixupTrain:  epoch  0, batch    36 | loss: 2.6122713MixupTrain:  epoch  0, batch    37 | loss: 3.0441871MixupTrain:  epoch  0, batch    38 | loss: 3.2865396MixupTrain:  epoch  0, batch    39 | loss: 3.1478965MixupTrain:  epoch  0, batch    40 | loss: 3.0065794MixupTrain:  epoch  0, batch    41 | loss: 3.7310767MixupTrain:  epoch  0, batch    42 | loss: 3.0985146MixupTrain:  epoch  0, batch    43 | loss: 3.0612974MixupTrain:  epoch  0, batch    44 | loss: 3.5486193MixupTrain:  epoch  0, batch    45 | loss: 2.9817557MixupTrain:  epoch  0, batch    46 | loss: 3.5301232MixupTrain:  epoch  0, batch    47 | loss: 3.0855532MixupTrain:  epoch  0, batch    48 | loss: 3.4658566MixupTrain:  epoch  0, batch    49 | loss: 3.0449209MixupTrain:  epoch  0, batch    50 | loss: 2.8238692MixupTrain:  epoch  0, batch    51 | loss: 3.1191623MixupTrain:  epoch  0, batch    52 | loss: 3.1283922MixupTrain:  epoch  0, batch    53 | loss: 4.3489046MixupTrain:  epoch  0, batch    54 | loss: 3.7115493MixupTrain:  epoch  0, batch    55 | loss: 2.7275310MixupTrain:  epoch  0, batch    56 | loss: 3.0929484MixupTrain:  epoch  0, batch    57 | loss: 3.0261576MixupTrain:  epoch  0, batch    58 | loss: 3.5695024MixupTrain:  epoch  0, batch    59 | loss: 3.0350251MixupTrain:  epoch  0, batch    60 | loss: 3.0601211MixupTrain:  epoch  0, batch    61 | loss: 2.7769065MixupTrain:  epoch  0, batch    62 | loss: 3.7353783MixupTrain:  epoch  0, batch    63 | loss: 3.5022552MixupTrain:  epoch  0, batch    64 | loss: 2.7145121MixupTrain:  epoch  0, batch    65 | loss: 2.7700343MixupTrain:  epoch  0, batch    66 | loss: 2.8442891MixupTrain:  epoch  0, batch    67 | loss: 2.8520443MixupTrain:  epoch  0, batch    68 | loss: 2.4372482MixupTrain:  epoch  0, batch    69 | loss: 3.2322392MixupTrain:  epoch  0, batch    70 | loss: 3.4455616MixupTrain:  epoch  0, batch    71 | loss: 3.7113879MixupTrain:  epoch  0, batch    72 | loss: 2.7419069MixupTrain:  epoch  0, batch    73 | loss: 2.5488448MixupTrain:  epoch  0, batch    74 | loss: 2.3029289MixupTrain:  epoch  0, batch    75 | loss: 2.8564739MixupTrain:  epoch  0, batch    76 | loss: 3.7818556MixupTrain:  epoch  0, batch    77 | loss: 2.6480491MixupTrain:  epoch  0, batch    78 | loss: 2.4075079MixupTrain:  epoch  0, batch    79 | loss: 3.2210429MixupTrain:  epoch  0, batch    80 | loss: 2.8073406MixupTrain:  epoch  0, batch    81 | loss: 2.8734386MixupTrain:  epoch  0, batch    82 | loss: 2.9183350MixupTrain:  epoch  0, batch    83 | loss: 2.7680178MixupTrain:  epoch  0, batch    84 | loss: 3.3576365MixupTrain:  epoch  0, batch    85 | loss: 3.0082290MixupTrain:  epoch  0, batch    86 | loss: 2.8349862MixupTrain:  epoch  0, batch    87 | loss: 2.9961939MixupTrain:  epoch  0, batch    88 | loss: 2.4649069MixupTrain:  epoch  0, batch    89 | loss: 2.6919398MixupTrain:  epoch  0, batch    90 | loss: 2.9756982MixupTrain:  epoch  0, batch    91 | loss: 2.4141245MixupTrain:  epoch  0, batch    92 | loss: 2.3556938MixupTrain:  epoch  0, batch    93 | loss: 3.3702726MixupTrain:  epoch  0, batch    94 | loss: 2.5758648MixupTrain:  epoch  0, batch    95 | loss: 2.7979376MixupTrain:  epoch  0, batch    96 | loss: 2.4408846MixupTrain:  epoch  0, batch    97 | loss: 2.9899466MixupTrain:  epoch  0, batch    98 | loss: 3.5826550MixupTrain:  epoch  0, batch    99 | loss: 2.6332901MixupTrain:  epoch  0, batch   100 | loss: 1.8647193MixupTrain:  epoch  0, batch   101 | loss: 2.9641492MixupTrain:  epoch  0, batch   102 | loss: 2.6179280MixupTrain:  epoch  0, batch   103 | loss: 2.6522079MixupTrain:  epoch  0, batch   104 | loss: 2.5693636MixupTrain:  epoch  0, batch   105 | loss: 3.7675800MixupTrain:  epoch  0, batch   106 | loss: 3.0747337MixupTrain:  epoch  0, batch   107 | loss: 2.4910300MixupTrain:  epoch  0, batch   108 | loss: 2.7940321MixupTrain:  epoch  0, batch   109 | loss: 2.4433942MixupTrain:  epoch  0, batch   110 | loss: 2.2024803MixupTrain:  epoch  0, batch   111 | loss: 2.6779613MixupTrain:  epoch  0, batch   112 | loss: 2.4707780MixupTrain:  epoch  0, batch   113 | loss: 2.9196434MixupTrain:  epoch  0, batch   114 | loss: 2.9245389MixupTrain:  epoch  0, batch   115 | loss: 2.8957591MixupTrain:  epoch  0, batch   116 | loss: 2.6276851MixupTrain:  epoch  0, batch   117 | loss: 3.2681894MixupTrain:  epoch  0, batch   118 | loss: 2.3905463MixupTrain:  epoch  0, batch   119 | loss: 3.1661878MixupTrain:  epoch  0, batch   120 | loss: 2.7134638MixupTrain:  epoch  0, batch   121 | loss: 3.1225781MixupTrain:  epoch  0, batch   122 | loss: 2.6156671MixupTrain:  epoch  0, batch   123 | loss: 2.9336095MixupTrain:  epoch  0, batch   124 | loss: 2.5150940MixupTrain:  epoch  0, batch   125 | loss: 2.4695044MixupTrain:  epoch  0, batch   126 | loss: 3.1137221MixupTrain:  epoch  0, batch   127 | loss: 2.5423856MixupTrain:  epoch  0, batch   128 | loss: 2.4988334MixupTrain:  epoch  0, batch   129 | loss: 3.3184178MixupTrain:  epoch  0, batch   130 | loss: 2.8103271MixupTrain:  epoch  0, batch   131 | loss: 2.5985360MixupTrain:  epoch  0, batch   132 | loss: 2.9383409MixupTrain:  epoch  0, batch   133 | loss: 3.0011578MixupTrain:  epoch  0, batch   134 | loss: 2.4726577MixupTrain:  epoch  0, batch   135 | loss: 2.4422183MixupTrain:  epoch  0, batch   136 | loss: 2.3040469MixupTrain:  epoch  0, batch   137 | loss: 2.9084804MixupTrain:  epoch  0, batch   138 | loss: 2.9984250MixupTrain:  epoch  0, batch   139 | loss: 3.1107774MixupTrain:  epoch  0, batch   140 | loss: 3.4803891MixupTrain:  epoch  0, batch   141 | loss: 2.8732243MixupTrain:  epoch  0, batch   142 | loss: 2.7527699MixupTrain:  epoch  0, batch   143 | loss: 2.8676734MixupTrain:  epoch  0, batch   144 | loss: 3.0154219MixupTrain:  epoch  0, batch   145 | loss: 2.6995926MixupTrain:  epoch  0, batch   146 | loss: 2.9866593MixupTrain:  epoch  0, batch   147 | loss: 2.8423593MixupTrain:  epoch  0, batch   148 | loss: 3.0830507MixupTrain:  epoch  0, batch   149 | loss: 2.7643681MixupTrain:  epoch  0, batch   150 | loss: 2.5193257MixupTrain:  epoch  0, batch   151 | loss: 2.7414217MixupTrain:  epoch  0, batch   152 | loss: 2.8808835MixupTrain:  epoch  0, batch   153 | loss: 2.4622033MixupTrain:  epoch  0, batch   154 | loss: 3.0140591MixupTrain:  epoch  0, batch   155 | loss: 2.3847196MixupTrain:  epoch  0, batch   156 | loss: 2.4185443MixupTrain:  epoch  0, batch   157 | loss: 2.5287266MixupTrain:  epoch  0, batch   158 | loss: 2.4783964MixupTrain:  epoch  0, batch   159 | loss: 3.4059682MixupTrain:  epoch  0, batch   160 | loss: 2.5319772MixupTrain:  epoch  0, batch   161 | loss: 2.5156083MixupTrain:  epoch  0, batch   162 | loss: 3.1121738MixupTrain:  epoch  0, batch   163 | loss: 3.3147159MixupTrain:  epoch  0, batch   164 | loss: 2.9271441MixupTrain:  epoch  0, batch   165 | loss: 2.3971214MixupTrain:  epoch  0, batch   166 | loss: 2.5021768MixupTrain:  epoch  0, batch   167 | loss: 2.0677686MixupTrain:  epoch  0, batch   168 | loss: 3.1485333MixupTrain:  epoch  0, batch   169 | loss: 2.6397641MixupTrain:  epoch  0, batch   170 | loss: 2.5508885MixupTrain:  epoch  0, batch   171 | loss: 2.8151355MixupTrain:  epoch  0, batch   172 | loss: 2.1641421MixupTrain:  epoch  0, batch   173 | loss: 2.2791371MixupTrain:  epoch  0, batch   174 | loss: 2.4490678MixupTrain:  epoch  0, batch   175 | loss: 2.0345602MixupTrain:  epoch  0, batch   176 | loss: 3.0922766MixupTrain:  epoch  0, batch   177 | loss: 2.5739686MixupTrain:  epoch  0, batch   178 | loss: 2.2771928MixupTrain:  epoch  0, batch   179 | loss: 2.1972151MixupTrain:  epoch  0, batch   180 | loss: 2.4379075MixupTrain:  epoch  0, batch   181 | loss: 3.5160151MixupTrain:  epoch  0, batch   182 | loss: 2.5637484MixupTrain:  epoch  0, batch   183 | loss: 2.7514396MixupTrain:  epoch  0, batch   184 | loss: 2.5119710MixupTrain:  epoch  0, batch   185 | loss: 2.5231001MixupTrain:  epoch  0, batch   186 | loss: 2.7363222MixupTrain:  epoch  0, batch   187 | loss: 3.0748718MixupTrain:  epoch  0, batch   188 | loss: 2.5234601MixupTrain:  epoch  0, batch   189 | loss: 2.5124888MixupTrain:  epoch  0, batch   190 | loss: 3.0002489MixupTrain:  epoch  0, batch   191 | loss: 2.4608300MixupTrain:  epoch  0, batch   192 | loss: 2.8682854MixupTrain:  epoch  0, batch   193 | loss: 2.1609766MixupTrain:  epoch  0, batch   194 | loss: 2.6696987MixupTrain:  epoch  0, batch   195 | loss: 2.9954224MixupTrain:  epoch  0, batch   196 | loss: 2.3740218MixupTrain:  epoch  0, batch   197 | loss: 2.6437192MixupTrain:  epoch  0, batch   198 | loss: 2.9366479MixupTrain:  epoch  0, batch   199 | loss: 2.6437676MixupTrain:  epoch  0, batch   200 | loss: 2.5178108MixupTrain:  epoch  0, batch   201 | loss: 2.4971774MixupTrain:  epoch  0, batch   202 | loss: 2.3383379MixupTrain:  epoch  0, batch   203 | loss: 2.6580124MixupTrain:  epoch  0, batch   204 | loss: 2.4855056MixupTrain:  epoch  0, batch   205 | loss: 2.4351635MixupTrain:  epoch  0, batch   206 | loss: 2.8371944MixupTrain:  epoch  0, batch   207 | loss: 3.0854702MixupTrain:  epoch  0, batch   208 | loss: 2.8297198MixupTrain:  epoch  0, batch   209 | loss: 2.7425175MixupTrain:  epoch  0, batch   210 | loss: 3.5748184MixupTrain:  epoch  0, batch   211 | loss: 2.2081957MixupTrain:  epoch  0, batch   212 | loss: 2.6877406MixupTrain:  epoch  0, batch   213 | loss: 2.3849030MixupTrain:  epoch  0, batch   214 | loss: 2.1467612MixupTrain:  epoch  0, batch   215 | loss: 2.4800987MixupTrain:  epoch  0, batch   216 | loss: 2.5101576MixupTrain:  epoch  0, batch   217 | loss: 2.8847542MixupTrain:  epoch  0, batch   218 | loss: 2.6350870MixupTrain:  epoch  0, batch   219 | loss: 2.4596345MixupTrain:  epoch  0, batch   220 | loss: 2.6226528MixupTrain:  epoch  0, batch   221 | loss: 2.9572878MixupTrain:  epoch  0, batch   222 | loss: 2.3272595MixupTrain:  epoch  0, batch   223 | loss: 2.9126420MixupTrain:  epoch  0, batch   224 | loss: 2.4727879MixupTrain:  epoch  0, batch   225 | loss: 2.4569767MixupTrain:  epoch  0, batch   226 | loss: 2.5040853MixupTrain:  epoch  0, batch   227 | loss: 2.4978514MixupTrain:  epoch  0, batch   228 | loss: 2.2281570MixupTrain:  epoch  0, batch   229 | loss: 2.9417052MixupTrain:  epoch  0, batch   230 | loss: 2.2325912MixupTrain:  epoch  0, batch   231 | loss: 2.7963343MixupTrain:  epoch  0, batch   232 | loss: 2.7274170MixupTrain:  epoch  0, batch   233 | loss: 2.7901716MixupTrain:  epoch  0, batch   234 | loss: 3.2512317MixupTrain:  epoch  0, batch   235 | loss: 2.0621572MixupTrain:  epoch  0, batch   236 | loss: 2.2311635MixupTrain:  epoch  0, batch   237 | loss: 2.7276027MixupTrain:  epoch  0, batch   238 | loss: 2.4833984MixupTrain:  epoch  0, batch   239 | loss: 2.7461858MixupTrain:  epoch  0, batch   240 | loss: 2.4600008MixupTrain:  epoch  0, batch   241 | loss: 2.2116194MixupTrain:  epoch  0, batch   242 | loss: 2.7347591MixupTrain:  epoch  0, batch   243 | loss: 2.5011125MixupTrain:  epoch  0, batch   244 | loss: 2.8022013MixupTrain:  epoch  0, batch   245 | loss: 2.3438811MixupTrain:  epoch  0, batch   246 | loss: 2.2694120MixupTrain:  epoch  0, batch   247 | loss: 3.0153298MixupTrain:  epoch  0, batch   248 | loss: 3.2265437MixupTrain:  epoch  0, batch   249 | loss: 2.8365312MixupTrain:  epoch  0, batch   250 | loss: 2.7939868MixupTrain:  epoch  0, batch   251 | loss: 2.3520637MixupTrain:  epoch  0, batch   252 | loss: 2.4754786MixupTrain:  epoch  0, batch   253 | loss: 2.5197449MixupTrain:  epoch  0, batch   254 | loss: 2.3476300MixupTrain:  epoch  0, batch   255 | loss: 2.4618473MixupTrain:  epoch  0, batch   256 | loss: 2.1366332MixupTrain:  epoch  0, batch   257 | loss: 2.4629817MixupTrain:  epoch  0, batch   258 | loss: 2.4619236MixupTrain:  epoch  0, batch   259 | loss: 2.6928589MixupTrain:  epoch  0, batch   260 | loss: 2.2704332MixupTrain:  epoch  0, batch   261 | loss: 2.6470304MixupTrain:  epoch  0, batch   262 | loss: 2.6944304MixupTrain:  epoch  0, batch   263 | loss: 2.4609201MixupTrain:  epoch  0, batch   264 | loss: 2.9788654MixupTrain:  epoch  0, batch   265 | loss: 2.1387296MixupTrain:  epoch  0, batch   266 | loss: 2.7066877MixupTrain:  epoch  0, batch   267 | loss: 2.4262910MixupTrain:  epoch  0, batch   268 | loss: 2.4061315MixupTrain:  epoch  0, batch   269 | loss: 2.7168179MixupTrain:  epoch  0, batch   270 | loss: 2.3353133MixupTrain:  epoch  0, batch   271 | loss: 2.0936234MixupTrain:  epoch  0, batch   272 | loss: 2.3644168MixupTrain:  epoch  0, batch   273 | loss: 2.4379945MixupTrain:  epoch  0, batch   274 | loss: 2.6273940MixupTrain:  epoch  0, batch   275 | loss: 2.3750777MixupTrain:  epoch  0, batch   276 | loss: 2.8489051MixupTrain:  epoch  0, batch   277 | loss: 3.2801447MixupTrain:  epoch  0, batch   278 | loss: 2.2822704MixupTrain:  epoch  0, batch   279 | loss: 2.2932889MixupTrain:  epoch  0, batch   280 | loss: 2.8313060MixupTrain:  epoch  0, batch   281 | loss: 2.3594203MixupTrain:  epoch  0, batch   282 | loss: 2.8217664MixupTrain:  epoch  0, batch   283 | loss: 3.0196271MixupTrain:  epoch  0, batch   284 | loss: 2.5118175MixupTrain:  epoch  0, batch   285 | loss: 2.3964458MixupTrain:  epoch  0, batch   286 | loss: 2.5086350MixupTrain:  epoch  0, batch   287 | loss: 2.6677198MixupTrain:  epoch  0, batch   288 | loss: 3.0404835MixupTrain:  epoch  0, batch   289 | loss: 2.7766633MixupTrain:  epoch  0, batch   290 | loss: 2.4946780MixupTrain:  epoch  0, batch   291 | loss: 2.4242883MixupTrain:  epoch  0, batch   292 | loss: 2.1600852MixupTrain:  epoch  0, batch   293 | loss: 2.3356736MixupTrain:  epoch  0, batch   294 | loss: 2.7260823MixupTrain:  epoch  0, batch   295 | loss: 2.7553644MixupTrain:  epoch  0, batch   296 | loss: 2.6177440MixupTrain:  epoch  0, batch   297 | loss: 2.3569794MixupTrain:  epoch  0, batch   298 | loss: 2.7644148MixupTrain:  epoch  0, batch   299 | loss: 2.7267649MixupTrain:  epoch  0, batch   300 | loss: 2.6236594MixupTrain:  epoch  0, batch   301 | loss: 2.6591496MixupTrain:  epoch  0, batch   302 | loss: 2.2173424MixupTrain:  epoch  0, batch   303 | loss: 2.2703373MixupTrain:  epoch  0, batch   304 | loss: 2.2614717MixupTrain:  epoch  0, batch   305 | loss: 2.4889398MixupTrain:  epoch  0, batch   306 | loss: 2.7090409MixupTrain:  epoch  0, batch   307 | loss: 2.2471187MixupTrain:  epoch  0, batch   308 | loss: 2.9055495MixupTrain:  epoch  0, batch   309 | loss: 3.2800388MixupTrain:  epoch  0, batch   310 | loss: 2.3234639MixupTrain:  epoch  0, batch   311 | loss: 2.3816509MixupTrain:  epoch  0, batch   312 | loss: 3.2687299MixupTrain:  epoch  0, batch   313 | loss: 2.4354877MixupTrain:  epoch  0, batch   314 | loss: 2.4017358MixupTrain:  epoch  0, batch   315 | loss: 2.5982866MixupTrain:  epoch  0, batch   316 | loss: 2.2626252MixupTrain:  epoch  0, batch   317 | loss: 2.7938564MixupTrain:  epoch  0, batch   318 | loss: 2.7797854MixupTrain:  epoch  0, batch   319 | loss: 2.6164765MixupTrain:  epoch  0, batch   320 | loss: 2.3868365MixupTrain:  epoch  0, batch   321 | loss: 2.3093753MixupTrain:  epoch  0, batch   322 | loss: 2.4608800MixupTrain:  epoch  0, batch   323 | loss: 2.2643330MixupTrain:  epoch  0, batch   324 | loss: 2.5324421MixupTrain:  epoch  0, batch   325 | loss: 2.4256485MixupTrain:  epoch  0, batch   326 | loss: 2.1129017MixupTrain:  epoch  0, batch   327 | loss: 2.3119526MixupTrain:  epoch  0, batch   328 | loss: 2.8638051MixupTrain:  epoch  0, batch   329 | loss: 2.8000908MixupTrain:  epoch  0, batch   330 | loss: 2.7534423MixupTrain:  epoch  0, batch   331 | loss: 2.4051178MixupTrain:  epoch  0, batch   332 | loss: 2.4251375MixupTrain:  epoch  0, batch   333 | loss: 2.5163655MixupTrain:  epoch  0, batch   334 | loss: 2.8820658MixupTrain:  epoch  0, batch   335 | loss: 2.9844136MixupTrain:  epoch  0, batch   336 | loss: 2.7360780MixupTrain:  epoch  0, batch   337 | loss: 2.6295092MixupTrain:  epoch  0, batch   338 | loss: 2.3806009MixupTrain:  epoch  0, batch   339 | loss: 2.5596380MixupTrain:  epoch  0, batch   340 | loss: 2.5649295MixupTrain:  epoch  0, batch   341 | loss: 2.8747692MixupTrain:  epoch  0, batch   342 | loss: 3.0028062MixupTrain:  epoch  0, batch   343 | loss: 2.1931357MixupTrain:  epoch  0, batch   344 | loss: 2.4331441MixupTrain:  epoch  0, batch   345 | loss: 2.9510093MixupTrain:  epoch  0, batch   346 | loss: 2.4755940MixupTrain:  epoch  0, batch   347 | loss: 2.4255548MixupTrain:  epoch  0, batch   348 | loss: 2.4942486MixupTrain:  epoch  0, batch   349 | loss: 2.4301972MixupTrain:  epoch  0, batch   350 | loss: 2.6339145MixupTrain:  epoch  0, batch   351 | loss: 2.6472414MixupTrain:  epoch  0, batch   352 | loss: 2.4363427MixupTrain:  epoch  0, batch   353 | loss: 2.1966691MixupTrain:  epoch  0, batch   354 | loss: 2.5832698MixupTrain:  epoch  0, batch   355 | loss: 2.4904480MixupTrain:  epoch  0, batch   356 | loss: 3.0881238MixupTrain:  epoch  0, batch   357 | loss: 2.2378514MixupTrain:  epoch  0, batch   358 | loss: 2.7301049MixupTrain:  epoch  0, batch   359 | loss: 2.6481190MixupTrain:  epoch  0, batch   360 | loss: 2.6305265MixupTrain:  epoch  0, batch   361 | loss: 3.2546401MixupTrain:  epoch  0, batch   362 | loss: 2.3798919MixupTrain:  epoch  0, batch   363 | loss: 2.2618375MixupTrain:  epoch  0, batch   364 | loss: 2.2518196MixupTrain:  epoch  0, batch   365 | loss: 2.4382842MixupTrain:  epoch  0, batch   366 | loss: 2.8887987MixupTrain:  epoch  0, batch   367 | loss: 2.3891747MixupTrain:  epoch  0, batch   368 | loss: 2.6103296MixupTrain:  epoch  0, batch   369 | loss: 2.7678640MixupTrain:  epoch  0, batch   370 | loss: 2.3745179MixupTrain:  epoch  0, batch   371 | loss: 2.5590184MixupTrain:  epoch  0, batch   372 | loss: 2.2631190MixupTrain:  epoch  0, batch   373 | loss: 2.5487502MixupTrain:  epoch  0, batch   374 | loss: 2.5858836MixupTrain:  epoch  0, batch   375 | loss: 2.6287932MixupTrain:  epoch  0, batch   376 | loss: 2.5547705MixupTrain:  epoch  0, batch   377 | loss: 2.6933825MixupTrain:  epoch  0, batch   378 | loss: 2.6220410MixupTrain:  epoch  0, batch   379 | loss: 2.3402531MixupTrain:  epoch  0, batch   380 | loss: 2.6013587MixupTrain:  epoch  0, batch   381 | loss: 2.1705437MixupTrain:  epoch  0, batch   382 | loss: 2.2240086MixupTrain:  epoch  0, batch   383 | loss: 2.5591023MixupTrain:  epoch  0, batch   384 | loss: 2.6109064MixupTrain:  epoch  0, batch   385 | loss: 2.9819508MixupTrain:  epoch  0, batch   386 | loss: 2.3030019MixupTrain:  epoch  0, batch   387 | loss: 2.4307189MixupTrain:  epoch  0, batch   388 | loss: 2.2501116MixupTrain:  epoch  0, batch   389 | loss: 2.3573709MixupTrain:  epoch  0, batch   390 | loss: 2.6584203MixupTrain:  epoch  0, batch   391 | loss: 2.3663192MixupTrain:  epoch  0, batch   392 | loss: 2.3878806MixupTrain:  epoch  0, batch   393 | loss: 2.3682060MixupTrain:  epoch  0, batch   394 | loss: 2.2794456MixupTrain:  epoch  0, batch   395 | loss: 3.0653539MixupTrain:  epoch  0, batch   396 | loss: 2.6424260MixupTrain:  epoch  0, batch   397 | loss: 2.3525646MixupTrain:  epoch  0, batch   398 | loss: 2.5561290MixupTrain:  epoch  0, batch   399 | loss: 2.3744102MixupTrain:  epoch  0, batch   400 | loss: 2.3678484MixupTrain:  epoch  0, batch   401 | loss: 2.6856184MixupTrain:  epoch  0, batch   402 | loss: 2.1889818MixupTrain:  epoch  0, batch   403 | loss: 2.8066673MixupTrain:  epoch  0, batch   404 | loss: 2.5668168MixupTrain:  epoch  0, batch   405 | loss: 2.6915064MixupTrain:  epoch  0, batch   406 | loss: 2.8376539MixupTrain:  epoch  0, batch   407 | loss: 2.4397717MixupTrain:  epoch  0, batch   408 | loss: 2.3381815MixupTrain:  epoch  0, batch   409 | loss: 2.6579595MixupTrain:  epoch  0, batch   410 | loss: 2.4831257MixupTrain:  epoch  0, batch   411 | loss: 2.4346437MixupTrain:  epoch  0, batch   412 | loss: 2.7052326MixupTrain:  epoch  0, batch   413 | loss: 2.5664911MixupTrain:  epoch  0, batch   414 | loss: 2.1000457MixupTrain:  epoch  0, batch   415 | loss: 2.4686778MixupTrain:  epoch  0, batch   416 | loss: 2.4148793MixupTrain:  epoch  0, batch   417 | loss: 2.8240247MixupTrain:  epoch  0, batch   418 | loss: 1.9620640MixupTrain:  epoch  0, batch   419 | loss: 2.4821634MixupTrain:  epoch  0, batch   420 | loss: 2.8589044MixupTrain:  epoch  0, batch   421 | loss: 2.2121854MixupTrain:  epoch  0, batch   422 | loss: 2.7066453MixupTrain:  epoch  0, batch   423 | loss: 2.6928871MixupTrain:  epoch  0, batch   424 | loss: 2.6470704MixupTrain:  epoch  0, batch   425 | loss: 2.5182548MixupTrain:  epoch  0, batch   426 | loss: 2.1683159MixupTrain:  epoch  0, batch   427 | loss: 2.4996266MixupTrain:  epoch  0, batch   428 | loss: 2.1647766MixupTrain:  epoch  0, batch   429 | loss: 2.2573886MixupTrain:  epoch  0, batch   430 | loss: 2.4660931MixupTrain:  epoch  0, batch   431 | loss: 3.1162269MixupTrain:  epoch  0, batch   432 | loss: 2.0375917MixupTrain:  epoch  0, batch   433 | loss: 2.8092117MixupTrain:  epoch  0, batch   434 | loss: 2.6436095MixupTrain:  epoch  0, batch   435 | loss: 3.0365324MixupTrain:  epoch  0, batch   436 | loss: 2.6232262MixupTrain:  epoch  0, batch   437 | loss: 2.5687051MixupTrain:  epoch  0, batch   438 | loss: 2.6396961MixupTrain:  epoch  0, batch   439 | loss: 2.0439689MixupTrain:  epoch  0, batch   440 | loss: 2.7482243MixupTrain:  epoch  0, batch   441 | loss: 2.0392041MixupTrain:  epoch  0, batch   442 | loss: 2.2460070MixupTrain:  epoch  0, batch   443 | loss: 2.4734545MixupTrain:  epoch  0, batch   444 | loss: 2.2989001MixupTrain:  epoch  0, batch   445 | loss: 2.5142772MixupTrain:  epoch  0, batch   446 | loss: 2.6892638MixupTrain:  epoch  0, batch   447 | loss: 2.8266933MixupTrain:  epoch  0, batch   448 | loss: 2.6466036MixupTrain:  epoch  0, batch   449 | loss: 2.5015407MixupTrain:  epoch  0, batch   450 | loss: 2.6533275MixupTrain:  epoch  0, batch   451 | loss: 2.5722499MixupTrain:  epoch  0, batch   452 | loss: 2.6607742MixupTrain:  epoch  0, batch   453 | loss: 2.6731868MixupTrain:  epoch  0, batch   454 | loss: 2.6189060MixupTrain:  epoch  0, batch   455 | loss: 2.4333014MixupTrain:  epoch  0, batch   456 | loss: 2.6741061MixupTrain:  epoch  0, batch   457 | loss: 3.0864699MixupTrain:  epoch  0, batch   458 | loss: 2.3054914MixupTrain:  epoch  0, batch   459 | loss: 2.5555983MixupTrain:  epoch  0, batch   460 | loss: 2.5117819MixupTrain:  epoch  0, batch   461 | loss: 2.4488378MixupTrain:  epoch  0, batch   462 | loss: 2.7090654MixupTrain:  epoch  0, batch   463 | loss: 2.3111410MixupTrain:  epoch  0, batch   464 | loss: 2.4773800MixupTrain:  epoch  0, batch   465 | loss: 2.3571582MixupTrain:  epoch  0, batch   466 | loss: 2.5265441MixupTrain:  epoch  0, batch   467 | loss: 2.2171276MixupTrain:  epoch  0, batch   468 | loss: 2.2722344MixupTrain:  epoch  0, batch   469 | loss: 2.5406845MixupTrain:  epoch  0, batch   470 | loss: 2.4396675MixupTrain:  epoch  0, batch   471 | loss: 2.2369661MixupTrain:  epoch  0, batch   472 | loss: 2.4046922MixupTrain:  epoch  0, batch   473 | loss: 2.5264990MixupTrain:  epoch  0, batch   474 | loss: 2.7752612MixupTrain:  epoch  0, batch   475 | loss: 2.3735566MixupTrain:  epoch  0, batch   476 | loss: 2.2406850MixupTrain:  epoch  0, batch   477 | loss: 2.0952363MixupTrain:  epoch  0, batch   478 | loss: 2.5903459MixupTrain:  epoch  0, batch   479 | loss: 2.3511987MixupTrain:  epoch  0, batch   480 | loss: 2.3363655MixupTrain:  epoch  0, batch   481 | loss: 2.3860805MixupTrain:  epoch  0, batch   482 | loss: 2.5759165MixupTrain:  epoch  0, batch   483 | loss: 2.2130218MixupTrain:  epoch  0, batch   484 | loss: 2.7585459MixupTrain:  epoch  0, batch   485 | loss: 2.3581443MixupTrain:  epoch  0, batch   486 | loss: 2.2585258MixupTrain:  epoch  0, batch   487 | loss: 2.5243735MixupTrain:  epoch  0, batch   488 | loss: 2.5074041MixupTrain:  epoch  0, batch   489 | loss: 2.1492348MixupTrain:  epoch  0, batch   490 | loss: 2.0508986MixupTrain:  epoch  0, batch   491 | loss: 2.3857164MixupTrain:  epoch  0, batch   492 | loss: 2.5089531MixupTrain:  epoch  0, batch   493 | loss: 2.6289349MixupTrain:  epoch  0, batch   494 | loss: 2.5718484MixupTrain:  epoch  0, batch   495 | loss: 2.5795712MixupTrain:  epoch  0, batch   496 | loss: 2.2051797MixupTrain:  epoch  0, batch   497 | loss: 2.5213962MixupTrain:  epoch  0, batch   498 | loss: 2.0472612MixupTrain:  epoch  0, batch   499 | loss: 3.0305390MixupTrain:  epoch  0, batch   500 | loss: 2.4169686MixupTrain:  epoch  0, batch   501 | loss: 2.5714767MixupTrain:  epoch  0, batch   502 | loss: 2.1584821MixupTrain:  epoch  0, batch   503 | loss: 2.4744611MixupTrain:  epoch  0, batch   504 | loss: 2.4047298MixupTrain:  epoch  0, batch   505 | loss: 2.7707813MixupTrain:  epoch  0, batch   506 | loss: 2.5108252MixupTrain:  epoch  0, batch   507 | loss: 2.4113083MixupTrain:  epoch  0, batch   508 | loss: 1.9653246MixupTrain:  epoch  0, batch   509 | loss: 2.5923216MixupTrain:  epoch  0, batch   510 | loss: 2.7252045MixupTrain:  epoch  0, batch   511 | loss: 2.4557357MixupTrain:  epoch  0, batch   512 | loss: 2.5926037MixupTrain:  epoch  0, batch   513 | loss: 2.2055092MixupTrain:  epoch  0, batch   514 | loss: 2.1185071MixupTrain:  epoch  0, batch   515 | loss: 2.4781451MixupTrain:  epoch  0, batch   516 | loss: 2.4394727MixupTrain:  epoch  0, batch   517 | loss: 2.6305723MixupTrain:  epoch  0, batch   518 | loss: 2.7109308MixupTrain:  epoch  0, batch   519 | loss: 2.2545276MixupTrain:  epoch  0, batch   520 | loss: 2.6606865MixupTrain:  epoch  0, batch   521 | loss: 2.4261644MixupTrain:  epoch  0, batch   522 | loss: 2.9272470MixupTrain:  epoch  0, batch   523 | loss: 2.3995032MixupTrain:  epoch  0, batch   524 | loss: 2.2908332MixupTrain:  epoch  0, batch   525 | loss: 2.8290949MixupTrain:  epoch  0, batch   526 | loss: 2.3622808MixupTrain:  epoch  0, batch   527 | loss: 2.3714828MixupTrain:  epoch  0, batch   528 | loss: 2.0860467MixupTrain:  epoch  0, batch   529 | loss: 2.3222361MixupTrain:  epoch  0, batch   530 | loss: 2.6675515MixupTrain:  epoch  0, batch   531 | loss: 2.4195881MixupTrain:  epoch  0, batch   532 | loss: 2.4059591MixupTrain:  epoch  0, batch   533 | loss: 2.2436428MixupTrain:  epoch  0, batch   534 | loss: 2.4391212MixupTrain:  epoch  0, batch   535 | loss: 2.5497775MixupTrain:  epoch  0, batch   536 | loss: 2.1276178MixupTrain:  epoch  0, batch   537 | loss: 2.8869753MixupTrain:  epoch  0, batch   538 | loss: 2.5119557MixupTrain:  epoch  0, batch   539 | loss: 2.2605982MixupTrain:  epoch  0, batch   540 | loss: 2.5134647MixupTrain:  epoch  0, batch   541 | loss: 2.7720585MixupTrain:  epoch  0, batch   542 | loss: 2.7378745MixupTrain:  epoch  0, batch   543 | loss: 2.4372687MixupTrain:  epoch  0, batch   544 | loss: 2.3409567MixupTrain:  epoch  0, batch   545 | loss: 2.3255000MixupTrain:  epoch  0, batch   546 | loss: 2.3563173MixupTrain:  epoch  0, batch   547 | loss: 2.0642786MixupTrain:  epoch  0, batch   548 | loss: 2.5837092MixupTrain:  epoch  0, batch   549 | loss: 2.3464243MixupTrain:  epoch  0, batch   550 | loss: 2.3936677MixupTrain:  epoch  0, batch   551 | loss: 2.1264687MixupTrain:  epoch  0, batch   552 | loss: 2.5453188MixupTrain:  epoch  0, batch   553 | loss: 2.4136696MixupTrain:  epoch  0, batch   554 | loss: 2.9598842MixupTrain:  epoch  0, batch   555 | loss: 2.5276217MixupTrain:  epoch  0, batch   556 | loss: 1.9834766MixupTrain:  epoch  0, batch   557 | loss: 2.3923080MixupTrain:  epoch  0, batch   558 | loss: 2.4773889MixupTrain:  epoch  0, batch   559 | loss: 2.8642766MixupTrain:  epoch  0, batch   560 | loss: 2.6790640MixupTrain:  epoch  0, batch   561 | loss: 2.5059817MixupTrain:  epoch  0, batch   562 | loss: 2.1522894MixupTrain:  epoch  0, batch   563 | loss: 2.3012233MixupTrain:  epoch  0, batch   564 | loss: 2.4971473MixupTrain:  epoch  0, batch   565 | loss: 2.9128966MixupTrain:  epoch  0, batch   566 | loss: 2.5477028MixupTrain:  epoch  0, batch   567 | loss: 2.4308009MixupTrain:  epoch  0, batch   568 | loss: 2.7568483MixupTrain:  epoch  0, batch   569 | loss: 2.7988758MixupTrain:  epoch  0, batch   570 | loss: 2.6462126MixupTrain:  epoch  0, batch   571 | loss: 2.4268095MixupTrain:  epoch  0, batch   572 | loss: 2.2063627MixupTrain:  epoch  0, batch   573 | loss: 2.3994532MixupTrain:  epoch  0, batch   574 | loss: 2.3313413MixupTrain:  epoch  0, batch   575 | loss: 2.8497987MixupTrain:  epoch  0, batch   576 | loss: 1.9836574MixupTrain:  epoch  0, batch   577 | loss: 2.5043688MixupTrain:  epoch  0, batch   578 | loss: 2.2543299MixupTrain:  epoch  0, batch   579 | loss: 2.6090879MixupTrain:  epoch  0, batch   580 | loss: 2.2121041MixupTrain:  epoch  0, batch   581 | loss: 2.2037327MixupTrain:  epoch  0, batch   582 | loss: 2.6040809MixupTrain:  epoch  0, batch   583 | loss: 2.3190160MixupTrain:  epoch  0, batch   584 | loss: 2.1789370MixupTrain:  epoch  0, batch   585 | loss: 2.1691618MixupTrain:  epoch  0, batch   586 | loss: 2.3648829MixupTrain:  epoch  0, batch   587 | loss: 2.4094019MixupTrain:  epoch  0, batch   588 | loss: 2.4134636MixupTrain:  epoch  0, batch   589 | loss: 2.4860096MixupTrain:  epoch  0, batch   590 | loss: 2.5898876MixupTrain:  epoch  0, batch   591 | loss: 2.6139925MixupTrain:  epoch  0, batch   592 | loss: 2.7087429MixupTrain:  epoch  0, batch   593 | loss: 2.3643541MixupTrain:  epoch  0, batch   594 | loss: 2.6257272MixupTrain:  epoch  0, batch   595 | loss: 2.3242548MixupTrain:  epoch  0, batch   596 | loss: 2.2510276MixupTrain:  epoch  0, batch   597 | loss: 2.2373405MixupTrain:  epoch  0, batch   598 | loss: 2.2961831MixupTrain:  epoch  0, batch   599 | loss: 2.6364784MixupTrain:  epoch  0, batch   600 | loss: 2.7895770MixupTrain:  epoch  0, batch   601 | loss: 2.6599221MixupTrain:  epoch  0, batch   602 | loss: 2.5562077MixupTrain:  epoch  0, batch   603 | loss: 2.3302872MixupTrain:  epoch  0, batch   604 | loss: 2.3580453MixupTrain:  epoch  0, batch   605 | loss: 2.5691090MixupTrain:  epoch  0, batch   606 | loss: 2.2222509MixupTrain:  epoch  0, batch   607 | loss: 2.1068316MixupTrain:  epoch  0, batch   608 | loss: 2.7136002MixupTrain:  epoch  0, batch   609 | loss: 2.3333306MixupTrain:  epoch  0, batch   610 | loss: 2.2624812MixupTrain:  epoch  0, batch   611 | loss: 2.3692386MixupTrain:  epoch  0, batch   612 | loss: 2.1350760MixupTrain:  epoch  0, batch   613 | loss: 2.2706714MixupTrain:  epoch  0, batch   614 | loss: 2.8839345MixupTrain:  epoch  0, batch   615 | loss: 2.3942308MixupTrain:  epoch  0, batch   616 | loss: 2.4780140MixupTrain:  epoch  0, batch   617 | loss: 2.7191484MixupTrain:  epoch  0, batch   618 | loss: 2.7367055MixupTrain:  epoch  0, batch   619 | loss: 2.3954451MixupTrain:  epoch  0, batch   620 | loss: 2.4929025MixupTrain:  epoch  0, batch   621 | loss: 2.9520538MixupTrain:  epoch  0, batch   622 | loss: 2.4796875MixupTrain:  epoch  0, batch   623 | loss: 2.4214394MixupTrain:  epoch  0, batch   624 | loss: 2.5710831MixupTrain:  epoch  0, batch   625 | loss: 2.4425192MixupTrain:  epoch  0, batch   626 | loss: 2.1368084MixupTrain:  epoch  0, batch   627 | loss: 2.5706732MixupTrain:  epoch  0, batch   628 | loss: 1.9498441MixupTrain:  epoch  0, batch   629 | loss: 2.5304947MixupTrain:  epoch  0, batch   630 | loss: 2.2877102MixupTrain:  epoch  0, batch   631 | loss: 2.7676425MixupTrain:  epoch  0, batch   632 | loss: 2.3634939MixupTrain:  epoch  0, batch   633 | loss: 2.3486500MixupTrain:  epoch  0, batch   634 | loss: 2.4062924MixupTrain:  epoch  0, batch   635 | loss: 2.4671330MixupTrain:  epoch  0, batch   636 | loss: 2.1830220MixupTrain:  epoch  0, batch   637 | loss: 2.3490739MixupTrain:  epoch  0, batch   638 | loss: 2.1876006MixupTrain:  epoch  0, batch   639 | loss: 2.2297025MixupTrain:  epoch  0, batch   640 | loss: 2.4512315MixupTrain:  epoch  0, batch   641 | loss: 2.4480550MixupTrain:  epoch  0, batch   642 | loss: 2.5232682MixupTrain:  epoch  0, batch   643 | loss: 2.2326610MixupTrain:  epoch  0, batch   644 | loss: 2.3100019MixupTrain:  epoch  0, batch   645 | loss: 2.6868000MixupTrain:  epoch  0, batch   646 | loss: 2.9291697MixupTrain:  epoch  0, batch   647 | loss: 2.1073296MixupTrain:  epoch  0, batch   648 | loss: 2.6367965MixupTrain:  epoch  0, batch   649 | loss: 2.7794895MixupTrain:  epoch  0, batch   650 | loss: 2.6058209MixupTrain:  epoch  0, batch   651 | loss: 2.4230566MixupTrain:  epoch  0, batch   652 | loss: 2.2388368MixupTrain:  epoch  0, batch   653 | loss: 2.2569895MixupTrain:  epoch  0, batch   654 | loss: 2.7607641MixupTrain:  epoch  0, batch   655 | loss: 2.3505507MixupTrain:  epoch  0, batch   656 | loss: 2.6116254MixupTrain:  epoch  0, batch   657 | loss: 2.5254173MixupTrain:  epoch  0, batch   658 | loss: 1.9854698MixupTrain:  epoch  0, batch   659 | loss: 2.5742927MixupTrain:  epoch  0, batch   660 | loss: 2.4533248MixupTrain:  epoch  0, batch   661 | loss: 2.3425179MixupTrain:  epoch  0, batch   662 | loss: 2.5161266MixupTrain:  epoch  0, batch   663 | loss: 2.3461561MixupTrain:  epoch  0, batch   664 | loss: 2.1820421MixupTrain:  epoch  0, batch   665 | loss: 2.3633270MixupTrain:  epoch  0, batch   666 | loss: 2.4837465MixupTrain:  epoch  0, batch   667 | loss: 2.4857645MixupTrain:  epoch  0, batch   668 | loss: 2.8232391MixupTrain:  epoch  0, batch   669 | loss: 2.4982991MixupTrain:  epoch  0, batch   670 | loss: 2.3623197MixupTrain:  epoch  0, batch   671 | loss: 2.6320729MixupTrain:  epoch  0, batch   672 | loss: 2.9423714MixupTrain:  epoch  0, batch   673 | loss: 2.1151390MixupTrain:  epoch  0, batch   674 | loss: 2.8454001MixupTrain:  epoch  0, batch   675 | loss: 2.4596825MixupTrain:  epoch  0, batch   676 | loss: 2.2580481MixupTrain:  epoch  0, batch   677 | loss: 2.5373070MixupTrain:  epoch  0, batch   678 | loss: 2.3373523MixupTrain:  epoch  0, batch   679 | loss: 2.4058919MixupTrain:  epoch  0, batch   680 | loss: 2.4438210MixupTrain:  epoch  0, batch   681 | loss: 2.1954448MixupTrain:  epoch  0, batch   682 | loss: 2.6200428MixupTrain:  epoch  0, batch   683 | loss: 2.5143661MixupTrain:  epoch  0, batch   684 | loss: 2.2627511MixupTrain:  epoch  0, batch   685 | loss: 2.2034674MixupTrain:  epoch  0, batch   686 | loss: 1.9622483MixupTrain:  epoch  0, batch   687 | loss: 2.4049842MixupTrain:  epoch  0, batch   688 | loss: 2.3377817MixupTrain:  epoch  0, batch   689 | loss: 2.2196660MixupTrain:  epoch  0, batch   690 | loss: 2.4097781MixupTrain:  epoch  0, batch   691 | loss: 2.6372814MixupTrain:  epoch  0, batch   692 | loss: 2.3483753MixupTrain:  epoch  0, batch   693 | loss: 2.6278813MixupTrain:  epoch  0, batch   694 | loss: 2.1959050MixupTrain:  epoch  0, batch   695 | loss: 2.9487619MixupTrain:  epoch  0, batch   696 | loss: 2.2104931MixupTrain:  epoch  0, batch   697 | loss: 2.2929769MixupTrain:  epoch  0, batch   698 | loss: 2.5798602MixupTrain:  epoch  0, batch   699 | loss: 2.6153824MixupTrain:  epoch  0, batch   700 | loss: 2.3267937MixupTrain:  epoch  0, batch   701 | loss: 2.2583213MixupTrain:  epoch  0, batch   702 | loss: 2.2451432MixupTrain:  epoch  0, batch   703 | loss: 3.1055255MixupTrain:  epoch  0, batch   704 | loss: 2.3052664MixupTrain:  epoch  0, batch   705 | loss: 2.9050040MixupTrain:  epoch  0, batch   706 | loss: 2.3956254MixupTrain:  epoch  0, batch   707 | loss: 2.0479825MixupTrain:  epoch  0, batch   708 | loss: 2.0381212MixupTrain:  epoch  0, batch   709 | loss: 2.6811905MixupTrain:  epoch  0, batch   710 | loss: 2.7000856MixupTrain:  epoch  0, batch   711 | loss: 2.4315333MixupTrain:  epoch  0, batch   712 | loss: 2.2890902MixupTrain:  epoch  0, batch   713 | loss: 2.4482689MixupTrain:  epoch  0, batch   714 | loss: 2.4866302MixupTrain:  epoch  0, batch   715 | loss: 2.4686320MixupTrain:  epoch  0, batch   716 | loss: 2.6774421MixupTrain:  epoch  0, batch   717 | loss: 2.4999423MixupTrain:  epoch  0, batch   718 | loss: 2.3058021MixupTrain:  epoch  0, batch   719 | loss: 2.2987118MixupTrain:  epoch  0, batch   720 | loss: 2.3219230MixupTrain:  epoch  0, batch   721 | loss: 2.8795569MixupTrain:  epoch  0, batch   722 | loss: 2.5672178MixupTrain:  epoch  0, batch   723 | loss: 2.1936903MixupTrain:  epoch  0, batch   724 | loss: 2.4013846MixupTrain:  epoch  0, batch   725 | loss: 2.7974029MixupTrain:  epoch  0, batch   726 | loss: 2.1096358MixupTrain:  epoch  0, batch   727 | loss: 2.1456017MixupTrain:  epoch  0, batch   728 | loss: 2.9391870MixupTrain:  epoch  0, batch   729 | loss: 2.5174515MixupTrain:  epoch  0, batch   730 | loss: 2.3944585MixupTrain:  epoch  0, batch   731 | loss: 2.4721501MixupTrain:  epoch  0, batch   732 | loss: 2.6416354MixupTrain:  epoch  0, batch   733 | loss: 2.8387127MixupTrain:  epoch  0, batch   734 | loss: 2.4681475MixupTrain:  epoch  0, batch   735 | loss: 2.7894835MixupTrain:  epoch  0, batch   736 | loss: 2.7882545MixupTrain:  epoch  0, batch   737 | loss: 2.2601008MixupTrain:  epoch  0, batch   738 | loss: 1.9974884MixupTrain:  epoch  0, batch   739 | loss: 2.3337591MixupTrain:  epoch  0, batch   740 | loss: 2.4893305MixupTrain:  epoch  0, batch   741 | loss: 2.3992238MixupTrain:  epoch  0, batch   742 | loss: 2.3081186MixupTrain:  epoch  0, batch   743 | loss: 2.6881943MixupTrain:  epoch  0, batch   744 | loss: 2.4855561MixupTrain:  epoch  0, batch   745 | loss: 2.5158978MixupTrain:  epoch  0, batch   746 | loss: 2.4576254MixupTrain:  epoch  0, batch   747 | loss: 2.6016655MixupTrain:  epoch  0, batch   748 | loss: 2.6983860MixupTrain:  epoch  0, batch   749 | loss: 2.1582317MixupTrain:  epoch  0, batch   750 | loss: 2.5450342MixupTrain:  epoch  0, batch   751 | loss: 2.4034996MixupTrain:  epoch  0, batch   752 | loss: 2.7516212MixupTrain:  epoch  0, batch   753 | loss: 2.1555295MixupTrain:  epoch  0, batch   754 | loss: 2.6213312MixupTrain:  epoch  0, batch   755 | loss: 2.1483417MixupTrain:  epoch  0, batch   756 | loss: 2.6476901MixupTrain:  epoch  0, batch   757 | loss: 3.1412797MixupTrain:  epoch  0, batch   758 | loss: 2.3752236MixupTrain:  epoch  0, batch   759 | loss: 2.2495353MixupTrain:  epoch  0, batch   760 | loss: 2.5699496MixupTrain:  epoch  0, batch   761 | loss: 2.4290402MixupTrain:  epoch  0, batch   762 | loss: 2.4361300MixupTrain:  epoch  0, batch   763 | loss: 1.9490588MixupTrain:  epoch  0, batch   764 | loss: 2.7381883MixupTrain:  epoch  0, batch   765 | loss: 2.3270941MixupTrain:  epoch  0, batch   766 | loss: 2.6541107MixupTrain:  epoch  0, batch   767 | loss: 2.4242780MixupTrain:  epoch  0, batch   768 | loss: 2.5023985MixupTrain:  epoch  0, batch   769 | loss: 2.7168379MixupTrain:  epoch  0, batch   770 | loss: 2.3199100MixupTrain:  epoch  0, batch   771 | loss: 2.5663292MixupTrain:  epoch  0, batch   772 | loss: 2.5822480MixupTrain:  epoch  0, batch   773 | loss: 2.3005915MixupTrain:  epoch  0, batch   774 | loss: 2.2666984MixupTrain:  epoch  0, batch   775 | loss: 2.1170776MixupTrain:  epoch  0, batch   776 | loss: 2.2969608MixupTrain:  epoch  0, batch   777 | loss: 2.4706459MixupTrain:  epoch  0, batch   778 | loss: 2.3367257MixupTrain:  epoch  0, batch   779 | loss: 1.9966090MixupTrain:  epoch  0, batch   780 | loss: 2.6927958MixupTrain:  epoch  0, batch   781 | loss: 2.7339678MixupTrain:  epoch  0, batch   782 | loss: 2.5203075MixupTrain:  epoch  0, batch   783 | loss: 2.3094473MixupTrain:  epoch  0, batch   784 | loss: 2.7960911MixupTrain:  epoch  0, batch   785 | loss: 2.4162083MixupTrain:  epoch  0, batch   786 | loss: 2.1491952MixupTrain:  epoch  0, batch   787 | loss: 2.0966935MixupTrain:  epoch  0, batch   788 | loss: 2.6826868MixupTrain:  epoch  0, batch   789 | loss: 2.6857657MixupTrain:  epoch  0, batch   790 | loss: 2.2294362MixupTrain:  epoch  0, batch   791 | loss: 2.9360650MixupTrain:  epoch  0, batch   792 | loss: 2.4059365MixupTrain:  epoch  0, batch   793 | loss: 2.4861107MixupTrain:  epoch  0, batch   794 | loss: 2.2247834MixupTrain:  epoch  0, batch   795 | loss: 2.5707593MixupTrain:  epoch  0, batch   796 | loss: 2.4294853MixupTrain:  epoch  0, batch   797 | loss: 2.6883173MixupTrain:  epoch  0, batch   798 | loss: 2.4464703MixupTrain:  epoch  0, batch   799 | loss: 2.6202295MixupTrain:  epoch  0, batch   800 | loss: 2.3027930MixupTrain:  epoch  0, batch   801 | loss: 2.4833891MixupTrain:  epoch  0, batch   802 | loss: 2.2785504MixupTrain:  epoch  0, batch   803 | loss: 2.4543414MixupTrain:  epoch  0, batch   804 | loss: 2.3118982MixupTrain:  epoch  0, batch   805 | loss: 2.6076746MixupTrain:  epoch  0, batch   806 | loss: 2.7912719MixupTrain:  epoch  0, batch   807 | loss: 2.3487725MixupTrain:  epoch  0, batch   808 | loss: 2.5378132MixupTrain:  epoch  0, batch   809 | loss: 2.2165062MixupTrain:  epoch  0, batch   810 | loss: 2.1431417MixupTrain:  epoch  0, batch   811 | loss: 2.3721342MixupTrain:  epoch  0, batch   812 | loss: 2.2841358MixupTrain:  epoch  0, batch   813 | loss: 2.4618173MixupTrain:  epoch  0, batch   814 | loss: 2.1826925MixupTrain:  epoch  0, batch   815 | loss: 2.5245008MixupTrain:  epoch  0, batch   816 | loss: 2.6613913MixupTrain:  epoch  0, batch   817 | loss: 2.2796717MixupTrain:  epoch  0, batch   818 | loss: 2.2285933MixupTrain:  epoch  0, batch   819 | loss: 2.2471228MixupTrain:  epoch  0, batch   820 | loss: 2.3072038MixupTrain:  epoch  0, batch   821 | loss: 2.3355694MixupTrain:  epoch  0, batch   822 | loss: 2.4388528MixupTrain:  epoch  0, batch   823 | loss: 2.2438972MixupTrain:  epoch  0, batch   824 | loss: 2.3150425MixupTrain:  epoch  0, batch   825 | loss: 2.3441770MixupTrain:  epoch  0, batch   826 | loss: 2.7606583MixupTrain:  epoch  0, batch   827 | loss: 2.2914572MixupTrain:  epoch  0, batch   828 | loss: 2.7805221MixupTrain:  epoch  0, batch   829 | loss: 2.0901415MixupTrain:  epoch  0, batch   830 | loss: 2.1295257MixupTrain:  epoch  0, batch   831 | loss: 2.4470313MixupTrain:  epoch  0, batch   832 | loss: 2.4881673MixupTrain:  epoch  0, batch   833 | loss: 2.6640558MixupTrain:  epoch  0, batch   834 | loss: 2.0164142MixupTrain:  epoch  0, batch   835 | loss: 2.2440131MixupTrain:  epoch  0, batch   836 | loss: 2.5777047MixupTrain:  epoch  0, batch   837 | loss: 2.4827628MixupTrain:  epoch  0, batch   838 | loss: 1.9651608MixupTrain:  epoch  0, batch   839 | loss: 2.6016550MixupTrain:  epoch  0, batch   840 | loss: 2.3807063MixupTrain:  epoch  0, batch   841 | loss: 2.1395440MixupTrain:  epoch  0, batch   842 | loss: 2.7287388MixupTrain:  epoch  0, batch   843 | loss: 2.7105756MixupTrain:  epoch  0, batch   844 | loss: 2.1798365MixupTrain:  epoch  0, batch   845 | loss: 2.6061003MixupTrain:  epoch  0, batch   846 | loss: 2.2663422MixupTrain:  epoch  0, batch   847 | loss: 2.3007774MixupTrain:  epoch  0, batch   848 | loss: 2.6375120MixupTrain:  epoch  0, batch   849 | loss: 2.4547806MixupTrain:  epoch  0, batch   850 | loss: 2.3593450MixupTrain:  epoch  0, batch   851 | loss: 2.2955256MixupTrain:  epoch  0, batch   852 | loss: 2.4609642MixupTrain:  epoch  0, batch   853 | loss: 2.1887817MixupTrain:  epoch  0, batch   854 | loss: 2.6631603MixupTrain:  epoch  0, batch   855 | loss: 2.3883078MixupTrain:  epoch  0, batch   856 | loss: 2.1415603MixupTrain:  epoch  0, batch   857 | loss: 2.4811053MixupTrain:  epoch  0, batch   858 | loss: 2.0877357MixupTrain:  epoch  0, batch   859 | loss: 2.2891395MixupTrain:  epoch  0, batch   860 | loss: 2.7681913MixupTrain:  epoch  0, batch   861 | loss: 2.3832479MixupTrain:  epoch  0, batch   862 | loss: 2.4886031MixupTrain:  epoch  0, batch   863 | loss: 2.5225086MixupTrain:  epoch  0, batch   864 | loss: 2.5277193MixupTrain:  epoch  0, batch   865 | loss: 2.4235559MixupTrain:  epoch  0, batch   866 | loss: 2.3891482MixupTrain:  epoch  0, batch   867 | loss: 2.8009236MixupTrain:  epoch  0, batch   868 | loss: 2.4277699MixupTrain:  epoch  0, batch   869 | loss: 2.1632805MixupTrain:  epoch  0, batch   870 | loss: 2.8225164MixupTrain:  epoch  0, batch   871 | loss: 2.3219256MixupTrain:  epoch  0, batch   872 | loss: 2.7259049MixupTrain:  epoch  0, batch   873 | loss: 2.7436812MixupTrain:  epoch  0, batch   874 | loss: 2.4406652MixupTrain:  epoch  0, batch   875 | loss: 2.4717398MixupTrain:  epoch  0, batch   876 | loss: 2.2674975MixupTrain:  epoch  0, batch   877 | loss: 2.4558318MixupTrain:  epoch  0, batch   878 | loss: 2.4672375MixupTrain:  epoch  0, batch   879 | loss: 2.4031525MixupTrain:  epoch  0, batch   880 | loss: 2.3511755MixupTrain:  epoch  0, batch   881 | loss: 2.4633117MixupTrain:  epoch  0, batch   882 | loss: 2.2464948MixupTrain:  epoch  0, batch   883 | loss: 2.3032629MixupTrain:  epoch  0, batch   884 | loss: 2.6734996MixupTrain:  epoch  0, batch   885 | loss: 2.6289194MixupTrain:  epoch  0, batch   886 | loss: 2.1248219MixupTrain:  epoch  0, batch   887 | loss: 2.0987687MixupTrain:  epoch  0, batch   888 | loss: 2.4077444MixupTrain:  epoch  0, batch   889 | loss: 2.4843183MixupTrain:  epoch  0, batch   890 | loss: 2.2927647MixupTrain:  epoch  0, batch   891 | loss: 2.5697830MixupTrain:  epoch  0, batch   892 | loss: 2.7208393MixupTrain:  epoch  0, batch   893 | loss: 2.6132450MixupTrain:  epoch  0, batch   894 | loss: 2.1285615MixupTrain:  epoch  0, batch   895 | loss: 2.3573761MixupTrain:  epoch  0, batch   896 | loss: 2.7172604MixupTrain:  epoch  0, batch   897 | loss: 2.2685163MixupTrain:  epoch  0, batch   898 | loss: 2.5050688MixupTrain:  epoch  0, batch   899 | loss: 2.5275295MixupTrain:  epoch  0, batch   900 | loss: 2.4681492MixupTrain:  epoch  0, batch   901 | loss: 2.7032280MixupTrain:  epoch  0, batch   902 | loss: 2.6558769MixupTrain:  epoch  0, batch   903 | loss: 2.6712251MixupTrain:  epoch  0, batch   904 | loss: 2.1683013MixupTrain:  epoch  0, batch   905 | loss: 2.6770248MixupTrain:  epoch  0, batch   906 | loss: 2.6348996MixupTrain:  epoch  0, batch   907 | loss: 2.3783092MixupTrain:  epoch  0, batch   908 | loss: 2.4344702MixupTrain:  epoch  0, batch   909 | loss: 2.4495833MixupTrain:  epoch  0, batch   910 | loss: 2.1857231MixupTrain:  epoch  0, batch   911 | loss: 2.4521871MixupTrain:  epoch  0, batch   912 | loss: 2.4740791MixupTrain:  epoch  0, batch   913 | loss: 2.5101633MixupTrain:  epoch  0, batch   914 | loss: 2.4127154MixupTrain:  epoch  0, batch   915 | loss: 2.4022546MixupTrain:  epoch  0, batch   916 | loss: 2.2534394MixupTrain:  epoch  0, batch   917 | loss: 2.7582624MixupTrain:  epoch  0, batch   918 | loss: 2.2198567MixupTrain:  epoch  0, batch   919 | loss: 2.2026212MixupTrain:  epoch  0, batch   920 | loss: 2.1999459MixupTrain:  epoch  0, batch   921 | loss: 2.5398059MixupTrain:  epoch  0, batch   922 | loss: 2.2683120MixupTrain:  epoch  0, batch   923 | loss: 2.4353709MixupTrain:  epoch  0, batch   924 | loss: 2.2815113MixupTrain:  epoch  0, batch   925 | loss: 2.4449091MixupTrain:  epoch  0, batch   926 | loss: 2.8722005MixupTrain:  epoch  0, batch   927 | loss: 2.2759943MixupTrain:  epoch  0, batch   928 | loss: 2.4812846MixupTrain:  epoch  0, batch   929 | loss: 2.5573688MixupTrain:  epoch  0, batch   930 | loss: 2.0375030MixupTrain:  epoch  0, batch   931 | loss: 2.4876127MixupTrain:  epoch  0, batch   932 | loss: 2.3830962MixupTrain:  epoch  0, batch   933 | loss: 2.1801839MixupTrain:  epoch  0, batch   934 | loss: 2.5814202MixupTrain:  epoch  0, batch   935 | loss: 2.6618783MixupTrain:  epoch  0, batch   936 | loss: 2.3742220MixupTrain:  epoch  0, batch   937 | loss: 2.4478941MixupTrain:  epoch  0, batch   938 | loss: 2.1657648MixupTrain:  epoch  0, batch   939 | loss: 2.3465853MixupTrain:  epoch  0, batch   940 | loss: 2.4529338MixupTrain:  epoch  0, batch   941 | loss: 2.2720852MixupTrain:  epoch  0, batch   942 | loss: 2.3273640MixupTrain:  epoch  0, batch   943 | loss: 2.3420720MixupTrain:  epoch  0, batch   944 | loss: 2.5246153MixupTrain:  epoch  0, batch   945 | loss: 2.8420362MixupTrain:  epoch  0, batch   946 | loss: 2.5156569MixupTrain:  epoch  0, batch   947 | loss: 2.5503621MixupTrain:  epoch  0, batch   948 | loss: 2.7632999MixupTrain:  epoch  0, batch   949 | loss: 2.5717411MixupTrain:  epoch  0, batch   950 | loss: 2.4118018MixupTrain:  epoch  0, batch   951 | loss: 2.1291914MixupTrain:  epoch  0, batch   952 | loss: 2.2662196MixupTrain:  epoch  0, batch   953 | loss: 2.2770839MixupTrain:  epoch  0, batch   954 | loss: 2.3581605MixupTrain:  epoch  0, batch   955 | loss: 2.6993680MixupTrain:  epoch  0, batch   956 | loss: 2.5090585MixupTrain:  epoch  0, batch   957 | loss: 2.7374716MixupTrain:  epoch  0, batch   958 | loss: 2.7910657MixupTrain:  epoch  0, batch   959 | loss: 2.3047194MixupTrain:  epoch  0, batch   960 | loss: 2.2726901MixupTrain:  epoch  0, batch   961 | loss: 2.3589153MixupTrain:  epoch  0, batch   962 | loss: 2.5451584MixupTrain:  epoch  0, batch   963 | loss: 2.6122205MixupTrain:  epoch  0, batch   964 | loss: 2.5103576MixupTrain:  epoch  0, batch   965 | loss: 2.1926084MixupTrain:  epoch  0, batch   966 | loss: 2.4116182MixupTrain:  epoch  0, batch   967 | loss: 2.3963842MixupTrain:  epoch  0, batch   968 | loss: 2.6500688MixupTrain:  epoch  0, batch   969 | loss: 2.6190696MixupTrain:  epoch  0, batch   970 | loss: 2.2466702MixupTrain:  epoch  0, batch   971 | loss: 2.2234249MixupTrain:  epoch  0, batch   972 | loss: 2.4673719MixupTrain:  epoch  0, batch   973 | loss: 2.2572479MixupTrain:  epoch  0, batch   974 | loss: 2.1437678MixupTrain:  epoch  0, batch   975 | loss: 2.6421556MixupTrain:  epoch  0, batch   976 | loss: 3.0175235MixupTrain:  epoch  0, batch   977 | loss: 2.6469996MixupTrain:  epoch  0, batch   978 | loss: 2.6448240MixupTrain:  epoch  0, batch   979 | loss: 3.0054235MixupTrain:  epoch  0, batch   980 | loss: 2.5841224MixupTrain:  epoch  0, batch   981 | loss: 2.4742694MixupTrain:  epoch  0, batch   982 | loss: 2.7129693MixupTrain:  epoch  0, batch   983 | loss: 2.4032078MixupTrain:  epoch  0, batch   984 | loss: 2.9381571MixupTrain:  epoch  0, batch   985 | loss: 2.6116467MixupTrain:  epoch  0, batch   986 | loss: 2.5849197MixupTrain:  epoch  0, batch   987 | loss: 2.9212329MixupTrain:  epoch  0, batch   988 | loss: 2.2342796MixupTrain:  epoch  0, batch   989 | loss: 2.4239287MixupTrain:  epoch  0, batch   990 | loss: 2.5165055MixupTrain:  epoch  0, batch   991 | loss: 2.3157077MixupTrain:  epoch  0, batch   992 | loss: 2.6285396MixupTrain:  epoch  0, batch   993 | loss: 2.4756525MixupTrain:  epoch  0, batch   994 | loss: 2.7682493MixupTrain:  epoch  0, batch   995 | loss: 2.2543399MixupTrain:  epoch  0, batch   996 | loss: 2.6933689MixupTrain:  epoch  0, batch   997 | loss: 2.2482858MixupTrain:  epoch  0, batch   998 | loss: 2.4811153MixupTrain:  epoch  0, batch   999 | loss: 2.2121797MixupTrain:  epoch  0, batch  1000 | loss: 2.4400277MixupTrain:  epoch  0, batch  1001 | loss: 2.5448380MixupTrain:  epoch  0, batch  1002 | loss: 2.7562652MixupTrain:  epoch  0, batch  1003 | loss: 2.4872327MixupTrain:  epoch  0, batch  1004 | loss: 2.7507505MixupTrain:  epoch  0, batch  1005 | loss: 2.5441077MixupTrain:  epoch  0, batch  1006 | loss: 2.9699578MixupTrain:  epoch  0, batch  1007 | loss: 2.5156195MixupTrain:  epoch  0, batch  1008 | loss: 2.2547727MixupTrain:  epoch  0, batch  1009 | loss: 2.1449578MixupTrain:  epoch  0, batch  1010 | loss: 2.7667170MixupTrain:  epoch  0, batch  1011 | loss: 2.8740466MixupTrain:  epoch  0, batch  1012 | loss: 2.4003844MixupTrain:  epoch  0, batch  1013 | loss: 2.4592533MixupTrain:  epoch  0, batch  1014 | loss: 2.2342401MixupTrain:  epoch  0, batch  1015 | loss: 2.0764327MixupTrain:  epoch  0, batch  1016 | loss: 2.5544465MixupTrain:  epoch  0, batch  1017 | loss: 2.3207092MixupTrain:  epoch  0, batch  1018 | loss: 1.9703995MixupTrain:  epoch  0, batch  1019 | loss: 2.5506110MixupTrain:  epoch  0, batch  1020 | loss: 2.5236497MixupTrain:  epoch  0, batch  1021 | loss: 2.0955503MixupTrain:  epoch  0, batch  1022 | loss: 2.7030740MixupTrain:  epoch  0, batch  1023 | loss: 2.3791964MixupTrain:  epoch  0, batch  1024 | loss: 2.5741611MixupTrain:  epoch  0, batch  1025 | loss: 2.1919498MixupTrain:  epoch  0, batch  1026 | loss: 2.4849224MixupTrain:  epoch  0, batch  1027 | loss: 2.3492460MixupTrain:  epoch  0, batch  1028 | loss: 2.5609324MixupTrain:  epoch  0, batch  1029 | loss: 2.3978500MixupTrain:  epoch  0, batch  1030 | loss: 2.7533693MixupTrain:  epoch  0, batch  1031 | loss: 2.5826802MixupTrain:  epoch  0, batch  1032 | loss: 2.3388386MixupTrain:  epoch  0, batch  1033 | loss: 2.0908818MixupTrain:  epoch  0, batch  1034 | loss: 2.4957495MixupTrain:  epoch  0, batch  1035 | loss: 2.4963381MixupTrain:  epoch  0, batch  1036 | loss: 2.4891138MixupTrain:  epoch  0, batch  1037 | loss: 2.6813052MixupTrain:  epoch  0, batch  1038 | loss: 2.7834330MixupTrain:  epoch  0, batch  1039 | loss: 2.5479493MixupTrain:  epoch  0, batch  1040 | loss: 2.2538519MixupTrain:  epoch  0, batch  1041 | loss: 2.5823238MixupTrain:  epoch  0, batch  1042 | loss: 2.1462617MixupTrain:  epoch  0, batch  1043 | loss: 2.4015844MixupTrain:  epoch  0, batch  1044 | loss: 2.9232781MixupTrain:  epoch  0, batch  1045 | loss: 2.7573385MixupTrain:  epoch  0, batch  1046 | loss: 2.6766014MixupTrain:  epoch  0, batch  1047 | loss: 2.2117820MixupTrain:  epoch  0, batch  1048 | loss: 2.2479565MixupTrain:  epoch  0, batch  1049 | loss: 2.5918934MixupTrain:  epoch  0, batch  1050 | loss: 2.0112348MixupTrain:  epoch  0, batch  1051 | loss: 2.3481836MixupTrain:  epoch  0, batch  1052 | loss: 2.3180830MixupTrain:  epoch  0, batch  1053 | loss: 2.2429018MixupTrain:  epoch  0, batch  1054 | loss: 2.4668634MixupTrain:  epoch  0, batch  1055 | loss: 2.4901853MixupTrain:  epoch  0, batch  1056 | loss: 2.7790859MixupTrain:  epoch  0, batch  1057 | loss: 1.9367051MixupTrain:  epoch  0, batch  1058 | loss: 2.1680965MixupTrain:  epoch  0, batch  1059 | loss: 2.6679931MixupTrain:  epoch  0, batch  1060 | loss: 2.6243331MixupTrain:  epoch  0, batch  1061 | loss: 2.6954222MixupTrain:  epoch  0, batch  1062 | loss: 1.9805329MixupTrain:  epoch  0, batch  1063 | loss: 2.2416234MixupTrain:  epoch  0, batch  1064 | loss: 2.4398506MixupTrain:  epoch  0, batch  1065 | loss: 2.6309509MixupTrain:  epoch  0, batch  1066 | loss: 2.1015944MixupTrain:  epoch  0, batch  1067 | loss: 2.5185630MixupTrain:  epoch  0, batch  1068 | loss: 2.2025936MixupTrain:  epoch  0, batch  1069 | loss: 2.3320813MixupTrain:  epoch  0, batch  1070 | loss: 2.0338106MixupTrain:  epoch  0, batch  1071 | loss: 2.6352186MixupTrain:  epoch  0, batch  1072 | loss: 2.5898013MixupTrain:  epoch  0, batch  1073 | loss: 2.3405633MixupTrain:  epoch  0, batch  1074 | loss: 2.3178940MixupTrain:  epoch  0, batch  1075 | loss: 2.3170972MixupTrain:  epoch  0, batch  1076 | loss: 2.1204777MixupTrain:  epoch  0, batch  1077 | loss: 2.2178476MixupTrain:  epoch  0, batch  1078 | loss: 2.7063756MixupTrain:  epoch  0, batch  1079 | loss: 2.3847086MixupTrain:  epoch  0, batch  1080 | loss: 2.7529736MixupTrain:  epoch  0, batch  1081 | loss: 2.4646273MixupTrain:  epoch  0, batch  1082 | loss: 2.8660488MixupTrain:  epoch  0, batch  1083 | loss: 2.0593431MixupTrain:  epoch  0, batch  1084 | loss: 2.1926479MixupTrain:  epoch  0, batch  1085 | loss: 2.2624340MixupTrain:  epoch  0, batch  1086 | loss: 2.2498603MixupTrain:  epoch  0, batch  1087 | loss: 2.7022095MixupTrain:  epoch  0, batch  1088 | loss: 2.4971519MixupTrain:  epoch  0, batch  1089 | loss: 2.6217175MixupTrain:  epoch  0, batch  1090 | loss: 1.9018416MixupTrain:  epoch  0, batch  1091 | loss: 2.8019664MixupTrain:  epoch  0, batch  1092 | loss: 2.5833278MixupTrain:  epoch  0, batch  1093 | loss: 2.5562677MixupTrain:  epoch  0, batch  1094 | loss: 2.6500630MixupTrain:  epoch  0, batch  1095 | loss: 2.3074381MixupTrain:  epoch  0, batch  1096 | loss: 2.1932321MixupTrain:  epoch  0, batch  1097 | loss: 2.3654432MixupTrain:  epoch  0, batch  1098 | loss: 2.2359354MixupTrain:  epoch  0, batch  1099 | loss: 2.2398663MixupTrain:  epoch  0, batch  1100 | loss: 2.2986441MixupTrain:  epoch  0, batch  1101 | loss: 2.6551838MixupTrain:  epoch  0, batch  1102 | loss: 2.4683638MixupTrain:  epoch  0, batch  1103 | loss: 2.4808960MixupTrain:  epoch  0, batch  1104 | loss: 2.7264359MixupTrain:  epoch  0, batch  1105 | loss: 2.4424539MixupTrain:  epoch  0, batch  1106 | loss: 2.5459232MixupTrain:  epoch  0, batch  1107 | loss: 2.1857314MixupTrain:  epoch  0, batch  1108 | loss: 2.1840336MixupTrain:  epoch  0, batch  1109 | loss: 2.3870330MixupTrain:  epoch  0, batch  1110 | loss: 2.1698420MixupTrain:  epoch  0, batch  1111 | loss: 2.5930028MixupTrain:  epoch  0, batch  1112 | loss: 2.3523564MixupTrain:  epoch  0, batch  1113 | loss: 2.0399790MixupTrain:  epoch  0, batch  1114 | loss: 2.2844944MixupTrain:  epoch  0, batch  1115 | loss: 2.1366181MixupTrain:  epoch  0, batch  1116 | loss: 2.6640525MixupTrain:  epoch  0, batch  1117 | loss: 2.2948678MixupTrain:  epoch  0, batch  1118 | loss: 2.6414914MixupTrain:  epoch  0, batch  1119 | loss: 2.8892765MixupTrain:  epoch  0, batch  1120 | loss: 2.4186358MixupTrain:  epoch  0, batch  1121 | loss: 2.2210903MixupTrain:  epoch  0, batch  1122 | loss: 2.5573020MixupTrain:  epoch  0, batch  1123 | loss: 2.8364911MixupTrain:  epoch  0, batch  1124 | loss: 2.7282572MixupTrain:  epoch  0, batch  1125 | loss: 2.5927320MixupTrain:  epoch  0, batch  1126 | loss: 2.8660917MixupTrain:  epoch  0, batch  1127 | loss: 2.0459199MixupTrain:  epoch  0, batch  1128 | loss: 2.8544683MixupTrain:  epoch  0, batch  1129 | loss: 2.8605199MixupTrain:  epoch  0, batch  1130 | loss: 2.2096043MixupTrain:  epoch  0, batch  1131 | loss: 3.1049161MixupTrain:  epoch  0, batch  1132 | loss: 2.4721184MixupTrain:  epoch  0, batch  1133 | loss: 2.2687168MixupTrain:  epoch  0, batch  1134 | loss: 2.2483158MixupTrain:  epoch  0, batch  1135 | loss: 2.3968582MixupTrain:  epoch  0, batch  1136 | loss: 2.5058737MixupTrain:  epoch  0, batch  1137 | loss: 2.3081193MixupTrain:  epoch  0, batch  1138 | loss: 2.0763717MixupTrain:  epoch  0, batch  1139 | loss: 2.4630775MixupTrain:  epoch  0, batch  1140 | loss: 2.3694692MixupTrain:  epoch  0, batch  1141 | loss: 1.8544650MixupTrain:  epoch  0, batch  1142 | loss: 2.4920611MixupTrain:  epoch  0, batch  1143 | loss: 2.2906389MixupTrain:  epoch  0, batch  1144 | loss: 2.6470613MixupTrain:  epoch  0, batch  1145 | loss: 2.0379400MixupTrain:  epoch  0, batch  1146 | loss: 2.2901015MixupTrain:  epoch  0, batch  1147 | loss: 2.3579588MixupTrain:  epoch  0, batch  1148 | loss: 2.1141496MixupTrain:  epoch  0, batch  1149 | loss: 2.6425834MixupTrain:  epoch  0, batch  1150 | loss: 2.2041183MixupTrain:  epoch  0, batch  1151 | loss: 2.2463255MixupTrain:  epoch  0, batch  1152 | loss: 2.4558666MixupTrain:  epoch  0, batch  1153 | loss: 2.1135738MixupTrain:  epoch  0, batch  1154 | loss: 2.9288130MixupTrain:  epoch  0, batch  1155 | loss: 2.4291599MixupTrain:  epoch  0, batch  1156 | loss: 2.2109289MixupTrain:  epoch  0, batch  1157 | loss: 2.6498728MixupTrain:  epoch  0, batch  1158 | loss: 2.8905125MixupTrain:  epoch  0, batch  1159 | loss: 2.1774735MixupTrain:  epoch  0, batch  1160 | loss: 2.6445012MixupTrain:  epoch  0, batch  1161 | loss: 2.7610211MixupTrain:  epoch  0, batch  1162 | loss: 2.1269336MixupTrain:  epoch  0, batch  1163 | loss: 2.2369070MixupTrain:  epoch  0, batch  1164 | loss: 2.2480669MixupTrain:  epoch  0, batch  1165 | loss: 2.8375642MixupTrain:  epoch  0, batch  1166 | loss: 2.1457510MixupTrain:  epoch  0, batch  1167 | loss: 2.6294861MixupTrain:  epoch  0, batch  1168 | loss: 2.7765865MixupTrain:  epoch  0, batch  1169 | loss: 2.2147164MixupTrain:  epoch  0, batch  1170 | loss: 2.4728134MixupTrain:  epoch  0, batch  1171 | loss: 2.6436579MixupTrain:  epoch  0, batch  1172 | loss: 2.5890985MixupTrain:  epoch  0, batch  1173 | loss: 2.2918746MixupTrain:  epoch  0, batch  1174 | loss: 2.6361668MixupTrain:  epoch  0, batch  1175 | loss: 2.4436932MixupTrain:  epoch  0, batch  1176 | loss: 2.2604847MixupTrain:  epoch  0, batch  1177 | loss: 2.7228823MixupTrain:  epoch  0, batch  1178 | loss: 2.3388813MixupTrain:  epoch  0, batch  1179 | loss: 2.5207291MixupTrain:  epoch  0, batch  1180 | loss: 2.2092953MixupTrain:  epoch  0, batch  1181 | loss: 2.4818928MixupTrain:  epoch  0, batch  1182 | loss: 2.6122096MixupTrain:  epoch  0, batch  1183 | loss: 2.6775577MixupTrain:  epoch  0, batch  1184 | loss: 2.6501160MixupTrain:  epoch  0, batch  1185 | loss: 2.4064171MixupTrain:  epoch  0, batch  1186 | loss: 2.5745749MixupTrain:  epoch  0, batch  1187 | loss: 2.7468948MixupTrain:  epoch  0, batch  1188 | loss: 2.1542935MixupTrain:  epoch  0, batch  1189 | loss: 2.6410794MixupTrain:  epoch  0, batch  1190 | loss: 2.0416362MixupTrain:  epoch  0, batch  1191 | loss: 2.5552821MixupTrain:  epoch  0, batch  1192 | loss: 2.5716918MixupTrain:  epoch  0, batch  1193 | loss: 2.6499619MixupTrain:  epoch  0, batch  1194 | loss: 2.0734992MixupTrain:  epoch  0, batch  1195 | loss: 2.1405618MixupTrain:  epoch  0, batch  1196 | loss: 2.2146199MixupTrain:  epoch  0, batch  1197 | loss: 2.1862381MixupTrain:  epoch  0, batch  1198 | loss: 2.3505936MixupTrain:  epoch  0, batch  1199 | loss: 2.3394146MixupTrain:  epoch  0, batch  1200 | loss: 2.0580142MixupTrain:  epoch  0, batch  1201 | loss: 2.3200831MixupTrain:  epoch  0, batch  1202 | loss: 2.7118819MixupTrain:  epoch  0, batch  1203 | loss: 2.4736123MixupTrain:  epoch  0, batch  1204 | loss: 2.5734909MixupTrain:  epoch  0, batch  1205 | loss: 2.8975556MixupTrain:  epoch  0, batch  1206 | loss: 2.5159662MixupTrain:  epoch  0, batch  1207 | loss: 2.5711854MixupTrain:  epoch  0, batch  1208 | loss: 2.5119975MixupTrain:  epoch  0, batch  1209 | loss: 2.2851677MixupTrain:  epoch  0, batch  1210 | loss: 2.5837200MixupTrain:  epoch  0, batch  1211 | loss: 2.5763371MixupTrain:  epoch  0, batch  1212 | loss: 2.5545795MixupTrain:  epoch  0, batch  1213 | loss: 2.5989373MixupTrain:  epoch  0, batch  1214 | loss: 2.4188864MixupTrain:  epoch  0, batch  1215 | loss: 2.4127324MixupTrain:  epoch  0, batch  1216 | loss: 2.7406023MixupTrain:  epoch  0, batch  1217 | loss: 2.4227915MixupTrain:  epoch  0, batch  1218 | loss: 2.4534974MixupTrain:  epoch  0, batch  1219 | loss: 2.3639379MixupTrain:  epoch  0, batch  1220 | loss: 2.3202477MixupTrain:  epoch  0, batch  1221 | loss: 2.7033758MixupTrain:  epoch  0, batch  1222 | loss: 2.6008959MixupTrain:  epoch  0, batch  1223 | loss: 2.2640209MixupTrain:  epoch  0, batch  1224 | loss: 2.6189110MixupTrain:  epoch  0, batch  1225 | loss: 2.3065920MixupTrain:  epoch  0, batch  1226 | loss: 2.1627040MixupTrain:  epoch  0, batch  1227 | loss: 2.7607617MixupTrain:  epoch  0, batch  1228 | loss: 1.9467176MixupTrain:  epoch  0, batch  1229 | loss: 2.0394855MixupTrain:  epoch  0, batch  1230 | loss: 2.4013939MixupTrain:  epoch  0, batch  1231 | loss: 2.2610781MixupTrain:  epoch  0, batch  1232 | loss: 2.6642723MixupTrain:  epoch  0, batch  1233 | loss: 2.2258015MixupTrain:  epoch  0, batch  1234 | loss: 2.1858354MixupTrain:  epoch  0, batch  1235 | loss: 2.6445522MixupTrain:  epoch  0, batch  1236 | loss: 2.5723410MixupTrain:  epoch  0, batch  1237 | loss: 2.3645964MixupTrain:  epoch  0, batch  1238 | loss: 2.3082681MixupTrain:  epoch  0, batch  1239 | loss: 2.2551594MixupTrain:  epoch  0, batch  1240 | loss: 2.3644209MixupTrain:  epoch  0, batch  1241 | loss: 2.2917709MixupTrain:  epoch  0, batch  1242 | loss: 2.4697418MixupTrain:  epoch  0, batch  1243 | loss: 2.1450768MixupTrain:  epoch  0, batch  1244 | loss: 2.1671920MixupTrain:  epoch  0, batch  1245 | loss: 2.3534174MixupTrain:  epoch  0, batch  1246 | loss: 2.7275937MixupTrain:  epoch  0, batch  1247 | loss: 2.3468909MixupTrain:  epoch  0, batch  1248 | loss: 2.3510201MixupTrain:  epoch  0, batch  1249 | loss: 2.2519922MixupTrain:  epoch  0, batch  1250 | loss: 2.6857615MixupTrain:  epoch  0, batch  1251 | loss: 2.3159506MixupTrain:  epoch  0, batch  1252 | loss: 2.2736044MixupTrain:  epoch  0, batch  1253 | loss: 2.4761600MixupTrain:  epoch  0, batch  1254 | loss: 2.2188835MixupTrain:  epoch  0, batch  1255 | loss: 2.0993738MixupTrain:  epoch  0, batch  1256 | loss: 2.3481684MixupTrain:  epoch  0, batch  1257 | loss: 2.3447087MixupTrain:  epoch  0, batch  1258 | loss: 2.3772612MixupTrain:  epoch  0, batch  1259 | loss: 2.5723104MixupTrain:  epoch  0, batch  1260 | loss: 3.1019459MixupTrain:  epoch  0, batch  1261 | loss: 2.3924108MixupTrain:  epoch  0, batch  1262 | loss: 2.2824273MixupTrain:  epoch  0, batch  1263 | loss: 2.8362229MixupTrain:  epoch  0, batch  1264 | loss: 2.1309476MixupTrain:  epoch  0, batch  1265 | loss: 2.5264370MixupTrain:  epoch  0, batch  1266 | loss: 2.1715498MixupTrain:  epoch  0, batch  1267 | loss: 2.2735691MixupTrain:  epoch  0, batch  1268 | loss: 2.5979810MixupTrain:  epoch  0, batch  1269 | loss: 2.7821593MixupTrain:  epoch  0, batch  1270 | loss: 2.7745054MixupTrain:  epoch  0, batch  1271 | loss: 2.7779751MixupTrain:  epoch  0, batch  1272 | loss: 3.1182044MixupTrain:  epoch  0, batch  1273 | loss: 2.6713567MixupTrain:  epoch  0, batch  1274 | loss: 2.1114891MixupTrain:  epoch  0, batch  1275 | loss: 2.5333340MixupTrain:  epoch  0, batch  1276 | loss: 2.4564421MixupTrain:  epoch  0, batch  1277 | loss: 2.8440268MixupTrain:  epoch  0, batch  1278 | loss: 2.1804099MixupTrain:  epoch  0, batch  1279 | loss: 2.7683125MixupTrain:  epoch  0, batch  1280 | loss: 2.4721298MixupTrain:  epoch  0, batch  1281 | loss: 2.6180496MixupTrain:  epoch  0, batch  1282 | loss: 2.7325191MixupTrain:  epoch  0, batch  1283 | loss: 2.4434032MixupTrain:  epoch  0, batch  1284 | loss: 2.4097047MixupTrain:  epoch  0, batch  1285 | loss: 2.0753472MixupTrain:  epoch  0, batch  1286 | loss: 2.5672691MixupTrain:  epoch  0, batch  1287 | loss: 2.2941256MixupTrain:  epoch  0, batch  1288 | loss: 2.2367353MixupTrain:  epoch  0, batch  1289 | loss: 2.0126648MixupTrain:  epoch  0, batch  1290 | loss: 2.4641364MixupTrain:  epoch  0, batch  1291 | loss: 2.4847686MixupTrain:  epoch  0, batch  1292 | loss: 2.1389823MixupTrain:  epoch  0, batch  1293 | loss: 2.1071572MixupTrain:  epoch  0, batch  1294 | loss: 2.6205716MixupTrain:  epoch  0, batch  1295 | loss: 2.2282982MixupTrain:  epoch  0, batch  1296 | loss: 2.6694660MixupTrain:  epoch  0, batch  1297 | loss: 2.0972834MixupTrain:  epoch  0, batch  1298 | loss: 2.5204339MixupTrain:  epoch  0, batch  1299 | loss: 2.1802042MixupTrain:  epoch  0, batch  1300 | loss: 2.4298191MixupTrain:  epoch  0, batch  1301 | loss: 2.1490054MixupTrain:  epoch  0, batch  1302 | loss: 2.3194747MixupTrain:  epoch  0, batch  1303 | loss: 2.2712767MixupTrain:  epoch  0, batch  1304 | loss: 2.3720965MixupTrain:  epoch  0, batch  1305 | loss: 2.7015123MixupTrain:  epoch  0, batch  1306 | loss: 2.9563451MixupTrain:  epoch  0, batch  1307 | loss: 2.4795790MixupTrain:  epoch  0, batch  1308 | loss: 2.4931500MixupTrain:  epoch  0, batch  1309 | loss: 2.6080208MixupTrain:  epoch  0, batch  1310 | loss: 2.3482304MixupTrain:  epoch  0, batch  1311 | loss: 2.3521905MixupTrain:  epoch  0, batch  1312 | loss: 2.3064494MixupTrain:  epoch  0, batch  1313 | loss: 2.6298614MixupTrain:  epoch  0, batch  1314 | loss: 2.0908825MixupTrain:  epoch  0, batch  1315 | loss: 2.6249485MixupTrain:  epoch  0, batch  1316 | loss: 2.5315993MixupTrain:  epoch  0, batch  1317 | loss: 2.3361607MixupTrain:  epoch  0, batch  1318 | loss: 2.7734690MixupTrain:  epoch  0, batch  1319 | loss: 2.6901588MixupTrain:  epoch  0, batch  1320 | loss: 2.6063952MixupTrain:  epoch  0, batch  1321 | loss: 2.2478092MixupTrain:  epoch  0, batch  1322 | loss: 2.6313961MixupTrain:  epoch  0, batch  1323 | loss: 2.5568564MixupTrain:  epoch  0, batch  1324 | loss: 2.4116879MixupTrain:  epoch  0, batch  1325 | loss: 2.3412163MixupTrain:  epoch  0, batch  1326 | loss: 2.3984909MixupTrain:  epoch  0, batch  1327 | loss: 2.4215367MixupTrain:  epoch  0, batch  1328 | loss: 2.3487258MixupTrain:  epoch  0, batch  1329 | loss: 2.1511314MixupTrain:  epoch  0, batch  1330 | loss: 2.2815285MixupTrain:  epoch  0, batch  1331 | loss: 2.3839383MixupTrain:  epoch  0, batch  1332 | loss: 2.3002496MixupTrain:  epoch  0, batch  1333 | loss: 2.0848446MixupTrain:  epoch  0, batch  1334 | loss: 2.3654907MixupTrain:  epoch  0, batch  1335 | loss: 2.4612293MixupTrain:  epoch  0, batch  1336 | loss: 2.2459409MixupTrain:  epoch  0, batch  1337 | loss: 2.5999398MixupTrain:  epoch  0, batch  1338 | loss: 2.3975639MixupTrain:  epoch  0, batch  1339 | loss: 2.4355316MixupTrain:  epoch  0, batch  1340 | loss: 2.3735094MixupTrain:  epoch  0, batch  1341 | loss: 2.1139007MixupTrain:  epoch  0, batch  1342 | loss: 2.3311908MixupTrain:  epoch  0, batch  1343 | loss: 2.7551579MixupTrain:  epoch  0, batch  1344 | loss: 2.3130939MixupTrain:  epoch  0, batch  1345 | loss: 2.4656460MixupTrain:  epoch  0, batch  1346 | loss: 2.2620921MixupTrain:  epoch  0, batch  1347 | loss: 2.3798881MixupTrain:  epoch  0, batch  1348 | loss: 2.6954703MixupTrain:  epoch  0, batch  1349 | loss: 2.4275501MixupTrain:  epoch  0, batch  1350 | loss: 2.4596963MixupTrain:  epoch  0, batch  1351 | loss: 2.4866257MixupTrain:  epoch  0, batch  1352 | loss: 2.3139868MixupTrain:  epoch  0, batch  1353 | loss: 2.6690466MixupTrain:  epoch  0, batch  1354 | loss: 2.3557241MixupTrain:  epoch  0, batch  1355 | loss: 2.3046508MixupTrain:  epoch  0, batch  1356 | loss: 2.2272606MixupTrain:  epoch  0, batch  1357 | loss: 2.4574823MixupTrain:  epoch  0, batch  1358 | loss: 2.5360031MixupTrain:  epoch  0, batch  1359 | loss: 2.0402813MixupTrain:  epoch  0, batch  1360 | loss: 2.6255412MixupTrain:  epoch  0, batch  1361 | loss: 2.5540519MixupTrain:  epoch  0, batch  1362 | loss: 2.7050574MixupTrain:  epoch  0, batch  1363 | loss: 2.2582669MixupTrain:  epoch  0, batch  1364 | loss: 2.0186901MixupTrain:  epoch  0, batch  1365 | loss: 2.7826943MixupTrain:  epoch  0, batch  1366 | loss: 2.4277539MixupTrain:  epoch  0, batch  1367 | loss: 2.5863614MixupTrain:  epoch  0, batch  1368 | loss: 2.1149244MixupTrain:  epoch  0, batch  1369 | loss: 2.2941365MixupTrain:  epoch  0, batch  1370 | loss: 2.4151282MixupTrain:  epoch  0, batch  1371 | loss: 2.6434338MixupTrain:  epoch  0, batch  1372 | loss: 2.4866004MixupTrain:  epoch  0, batch  1373 | loss: 2.3083763MixupTrain:  epoch  0, batch  1374 | loss: 2.2460387MixupTrain:  epoch  0, batch  1375 | loss: 2.6703095MixupTrain:  epoch  0, batch  1376 | loss: 2.4632049MixupTrain:  epoch  0, batch  1377 | loss: 2.2384789MixupTrain:  epoch  0, batch  1378 | loss: 2.6854620MixupTrain:  epoch  0, batch  1379 | loss: 2.2860427MixupTrain:  epoch  0, batch  1380 | loss: 2.3328493MixupTrain:  epoch  0, batch  1381 | loss: 2.5908158MixupTrain:  epoch  0, batch  1382 | loss: 2.1566346MixupTrain:  epoch  0, batch  1383 | loss: 2.5516434MixupTrain:  epoch  0, batch  1384 | loss: 2.3090458MixupTrain:  epoch  0, batch  1385 | loss: 2.5741777MixupTrain:  epoch  0, batch  1386 | loss: 2.2400441MixupTrain:  epoch  0, batch  1387 | loss: 2.9552526MixupTrain:  epoch  0, batch  1388 | loss: 2.0264053MixupTrain:  epoch  0, batch  1389 | loss: 2.5527592MixupTrain:  epoch  0, batch  1390 | loss: 2.4589958MixupTrain:  epoch  0, batch  1391 | loss: 2.3213382MixupTrain:  epoch  0, batch  1392 | loss: 2.3809583MixupTrain:  epoch  0, batch  1393 | loss: 2.7233088MixupTrain:  epoch  0, batch  1394 | loss: 2.5626416MixupTrain:  epoch  0, batch  1395 | loss: 2.6117585MixupTrain:  epoch  0, batch  1396 | loss: 2.2212443MixupTrain:  epoch  0, batch  1397 | loss: 2.2004886MixupTrain:  epoch  0, batch  1398 | loss: 2.3720787MixupTrain:  epoch  0, batch  1399 | loss: 2.5669479MixupTrain:  epoch  0, batch  1400 | loss: 2.6114759MixupTrain:  epoch  0, batch  1401 | loss: 2.6972611MixupTrain:  epoch  0, batch  1402 | loss: 2.6391778MixupTrain:  epoch  0, batch  1403 | loss: 2.4763918MixupTrain:  epoch  0, batch  1404 | loss: 2.5603108MixupTrain:  epoch  0, batch  1405 | loss: 2.3943319MixupTrain:  epoch  0, batch  1406 | loss: 2.5888348MixupTrain:  epoch  0, batch  1407 | loss: 2.6385772MixupTrain:  epoch  0, batch  1408 | loss: 2.4700003MixupTrain:  epoch  0, batch  1409 | loss: 2.6837454MixupTrain:  epoch  0, batch  1410 | loss: 2.6373253MixupTrain:  epoch  0, batch  1411 | loss: 2.5187621MixupTrain:  epoch  0, batch  1412 | loss: 2.4171669MixupTrain:  epoch  0, batch  1413 | loss: 2.3460126MixupTrain:  epoch  0, batch  1414 | loss: 2.0871735MixupTrain:  epoch  0, batch  1415 | loss: 2.5406699MixupTrain:  epoch  0, batch  1416 | loss: 2.5744166MixupTrain:  epoch  0, batch  1417 | loss: 2.5419312MixupTrain:  epoch  0, batch  1418 | loss: 2.4687088MixupTrain:  epoch  0, batch  1419 | loss: 2.1454563MixupTrain:  epoch  0, batch  1420 | loss: 2.5279024MixupTrain:  epoch  0, batch  1421 | loss: 2.3154132MixupTrain:  epoch  0, batch  1422 | loss: 2.4566829MixupTrain:  epoch  0, batch  1423 | loss: 2.2464085MixupTrain:  epoch  0, batch  1424 | loss: 2.7643228MixupTrain:  epoch  0, batch  1425 | loss: 2.5660403MixupTrain:  epoch  0, batch  1426 | loss: 2.5623214MixupTrain:  epoch  0, batch  1427 | loss: 2.6604850MixupTrain:  epoch  0, batch  1428 | loss: 2.5192513MixupTrain:  epoch  0, batch  1429 | loss: 3.0437269MixupTrain:  epoch  0, batch  1430 | loss: 2.8159099MixupTrain:  epoch  0, batch  1431 | loss: 2.3687470MixupTrain:  epoch  0, batch  1432 | loss: 2.3570249MixupTrain:  epoch  0, batch  1433 | loss: 2.4105706MixupTrain:  epoch  0, batch  1434 | loss: 2.7648053MixupTrain:  epoch  0, batch  1435 | loss: 2.4165912MixupTrain:  epoch  0, batch  1436 | loss: 2.2953615MixupTrain:  epoch  0, batch  1437 | loss: 2.4551950MixupTrain:  epoch  0, batch  1438 | loss: 2.6094918MixupTrain:  epoch  0, batch  1439 | loss: 2.2601285MixupTrain:  epoch  0, batch  1440 | loss: 2.6966305MixupTrain:  epoch  0, batch  1441 | loss: 2.2340994MixupTrain:  epoch  0, batch  1442 | loss: 2.3069305MixupTrain:  epoch  0, batch  1443 | loss: 2.3146522MixupTrain:  epoch  0, batch  1444 | loss: 2.3608823MixupTrain:  epoch  0, batch  1445 | loss: 2.4299068MixupTrain:  epoch  0, batch  1446 | loss: 2.1379056MixupTrain:  epoch  0, batch  1447 | loss: 2.0080762MixupTrain:  epoch  0, batch  1448 | loss: 2.1751182MixupTrain:  epoch  0, batch  1449 | loss: 2.4051967MixupTrain:  epoch  0, batch  1450 | loss: 2.4085221MixupTrain:  epoch  0, batch  1451 | loss: 2.6866646MixupTrain:  epoch  0, batch  1452 | loss: 2.1303711MixupTrain:  epoch  0, batch  1453 | loss: 2.4657860MixupTrain:  epoch  0, batch  1454 | loss: 2.8673043MixupTrain:  epoch  0, batch  1455 | loss: 2.8500655MixupTrain:  epoch  0, batch  1456 | loss: 2.4319129MixupTrain:  epoch  0, batch  1457 | loss: 2.6738737MixupTrain:  epoch  0, batch  1458 | loss: 2.1414552MixupTrain:  epoch  0, batch  1459 | loss: 2.2489605MixupTrain:  epoch  0, batch  1460 | loss: 2.2505083MixupTrain:  epoch  0, batch  1461 | loss: 2.1021938MixupTrain:  epoch  0, batch  1462 | loss: 2.3474622MixupTrain:  epoch  0, batch  1463 | loss: 2.6367550MixupTrain:  epoch  0, batch  1464 | loss: 2.4723330MixupTrain:  epoch  0, batch  1465 | loss: 2.7988100MixupTrain:  epoch  0, batch  1466 | loss: 2.4955862MixupTrain:  epoch  0, batch  1467 | loss: 2.4472542MixupTrain:  epoch  0, batch  1468 | loss: 2.5502887MixupTrain:  epoch  0, batch  1469 | loss: 2.6714272MixupTrain:  epoch  0, batch  1470 | loss: 2.9485421MixupTrain:  epoch  0, batch  1471 | loss: 2.5043383MixupTrain:  epoch  0, batch  1472 | loss: 2.2511005MixupTrain:  epoch  0, batch  1473 | loss: 2.5376005MixupTrain:  epoch  0, batch  1474 | loss: 2.3747644MixupTrain:  epoch  0, batch  1475 | loss: 2.3448641MixupTrain:  epoch  0, batch  1476 | loss: 2.1855731MixupTrain:  epoch  0, batch  1477 | loss: 2.1932702MixupTrain:  epoch  0, batch  1478 | loss: 2.6704550MixupTrain:  epoch  0, batch  1479 | loss: 2.3348675MixupTrain:  epoch  0, batch  1480 | loss: 2.0254714MixupTrain:  epoch  0, batch  1481 | loss: 2.1217666MixupTrain:  epoch  0, batch  1482 | loss: 2.6374855MixupTrain:  epoch  0, batch  1483 | loss: 2.1638849MixupTrain:  epoch  0, batch  1484 | loss: 2.6005480MixupTrain:  epoch  0, batch  1485 | loss: 2.3341990MixupTrain:  epoch  0, batch  1486 | loss: 2.4590206MixupTrain:  epoch  0, batch  1487 | loss: 2.5327866MixupTrain:  epoch  0, batch  1488 | loss: 2.3905890MixupTrain:  epoch  0, batch  1489 | loss: 2.2517858MixupTrain:  epoch  0, batch  1490 | loss: 2.3655155MixupTrain:  epoch  0, batch  1491 | loss: 2.2714789MixupTrain:  epoch  0, batch  1492 | loss: 2.4213219MixupTrain:  epoch  0, batch  1493 | loss: 2.4343438MixupTrain:  epoch  0, batch  1494 | loss: 2.4762759MixupTrain:  epoch  0, batch  1495 | loss: 2.5764687MixupTrain:  epoch  0, batch  1496 | loss: 2.7436604MixupTrain:  epoch  0, batch  1497 | loss: 2.3341753MixupTrain:  epoch  0, batch  1498 | loss: 2.5874386MixupTrain:  epoch  0, batch  1499 | loss: 2.0607886MixupTrain:  epoch  0, batch  1500 | loss: 2.8041320MixupTrain:  epoch  0, batch  1501 | loss: 2.6892221MixupTrain:  epoch  0, batch  1502 | loss: 2.4221063MixupTrain:  epoch  0, batch  1503 | loss: 2.3863473MixupTrain:  epoch  0, batch  1504 | loss: 1.8036648MixupTrain:  epoch  0, batch  1505 | loss: 2.7247300MixupTrain:  epoch  0, batch  1506 | loss: 2.6171508MixupTrain:  epoch  0, batch  1507 | loss: 2.3529818MixupTrain:  epoch  0, batch  1508 | loss: 2.2185445MixupTrain:  epoch  0, batch  1509 | loss: 2.6193862MixupTrain:  epoch  0, batch  1510 | loss: 2.1777408MixupTrain:  epoch  0, batch  1511 | loss: 2.2003441MixupTrain:  epoch  0, batch  1512 | loss: 2.4911730MixupTrain:  epoch  0, batch  1513 | loss: 2.2240319MixupTrain:  epoch  0, batch  1514 | loss: 2.5055761MixupTrain:  epoch  0, batch  1515 | loss: 2.5710440MixupTrain:  epoch  0, batch  1516 | loss: 2.4551642MixupTrain:  epoch  0, batch  1517 | loss: 2.1487746MixupTrain:  epoch  0, batch  1518 | loss: 2.2151861MixupTrain:  epoch  0, batch  1519 | loss: 2.5598614MixupTrain:  epoch  0, batch  1520 | loss: 2.5138268MixupTrain:  epoch  0, batch  1521 | loss: 2.2381063MixupTrain:  epoch  0, batch  1522 | loss: 2.0433664MixupTrain:  epoch  0, batch  1523 | loss: 2.0911365MixupTrain:  epoch  0, batch  1524 | loss: 2.2713141MixupTrain:  epoch  0, batch  1525 | loss: 2.4283493MixupTrain:  epoch  0, batch  1526 | loss: 2.7730317MixupTrain:  epoch  0, batch  1527 | loss: 2.4472942MixupTrain:  epoch  0, batch  1528 | loss: 2.4387407MixupTrain:  epoch  0, batch  1529 | loss: 2.2919064MixupTrain:  epoch  0, batch  1530 | loss: 2.8118770MixupTrain:  epoch  0, batch  1531 | loss: 2.9069386MixupTrain:  epoch  0, batch  1532 | loss: 2.7810555MixupTrain:  epoch  0, batch  1533 | loss: 2.5057571MixupTrain:  epoch  0, batch  1534 | loss: 1.9883492MixupTrain:  epoch  0, batch  1535 | loss: 2.6216097MixupTrain:  epoch  0, batch  1536 | loss: 2.7371435MixupTrain:  epoch  0, batch  1537 | loss: 2.3721116MixupTrain:  epoch  0, batch  1538 | loss: 2.1508074MixupTrain:  epoch  0, batch  1539 | loss: 2.5416260MixupTrain:  epoch  0, batch  1540 | loss: 2.4723639MixupTrain:  epoch  0, batch  1541 | loss: 2.5220881MixupTrain:  epoch  0, batch  1542 | loss: 2.0957074MixupTrain:  epoch  0, batch  1543 | loss: 2.6665545MixupTrain:  epoch  0, batch  1544 | loss: 2.3912210MixupTrain:  epoch  0, batch  1545 | loss: 2.4579573MixupTrain:  epoch  0, batch  1546 | loss: 2.2498255MixupTrain:  epoch  0, batch  1547 | loss: 2.3661289MixupTrain:  epoch  0, batch  1548 | loss: 2.5132198MixupTrain:  epoch  0, batch  1549 | loss: 2.5161235MixupTrain:  epoch  0, batch  1550 | loss: 2.2767167MixupTrain:  epoch  0, batch  1551 | loss: 2.1508639MixupTrain:  epoch  0, batch  1552 | loss: 2.5807922MixupTrain:  epoch  0, batch  1553 | loss: 2.0309777MixupTrain:  epoch  0, batch  1554 | loss: 1.7951088MixupTrain:  epoch  0, batch  1555 | loss: 2.2491260MixupTrain:  epoch  0, batch  1556 | loss: 2.6455131MixupTrain:  epoch  0, batch  1557 | loss: 2.2787488MixupTrain:  epoch  0, batch  1558 | loss: 2.6681490MixupTrain:  epoch  0, batch  1559 | loss: 2.2394195MixupTrain:  epoch  0, batch  1560 | loss: 2.3839312MixupTrain:  epoch  0, batch  1561 | loss: 2.2128730MixupTrain:  epoch  0, batch  1562 | loss: 2.2668219MixupTrain:  epoch  0, batch  1563 | loss: 2.3073044MixupTrain:  epoch  0, batch  1564 | loss: 2.3454278MixupTrain:  epoch  0, batch  1565 | loss: 2.1479828MixupTrain:  epoch  0, batch  1566 | loss: 2.5992391MixupTrain:  epoch  0, batch  1567 | loss: 2.9109435MixupTrain:  epoch  0, batch  1568 | loss: 2.2815351MixupTrain:  epoch  0, batch  1569 | loss: 2.2186809MixupTrain:  epoch  0, batch  1570 | loss: 2.5698881MixupTrain:  epoch  0, batch  1571 | loss: 2.7143722MixupTrain:  epoch  0, batch  1572 | loss: 2.2318840MixupTrain:  epoch  0, batch  1573 | loss: 2.3854451MixupTrain:  epoch  0, batch  1574 | loss: 2.4026673MixupTrain:  epoch  0, batch  1575 | loss: 2.2588563MixupTrain:  epoch  0, batch  1576 | loss: 2.4976039MixupTrain:  epoch  0, batch  1577 | loss: 2.2158849MixupTrain:  epoch  0, batch  1578 | loss: 2.2866223MixupTrain:  epoch  0, batch  1579 | loss: 2.5270643MixupTrain:  epoch  0, batch  1580 | loss: 2.5843086MixupTrain:  epoch  0, batch  1581 | loss: 2.4625819MixupTrain:  epoch  0, batch  1582 | loss: 2.5077643MixupTrain:  epoch  0, batch  1583 | loss: 2.7981277MixupTrain:  epoch  0, batch  1584 | loss: 2.6548853MixupTrain:  epoch  0, batch  1585 | loss: 2.4581852MixupTrain:  epoch  0, batch  1586 | loss: 2.6573255MixupTrain:  epoch  0, batch  1587 | loss: 2.1934280MixupTrain:  epoch  0, batch  1588 | loss: 2.8515296MixupTrain:  epoch  0, batch  1589 | loss: 2.4636521MixupTrain:  epoch  0, batch  1590 | loss: 2.6936679MixupTrain:  epoch  0, batch  1591 | loss: 2.3345461MixupTrain:  epoch  0, batch  1592 | loss: 2.1768265MixupTrain:  epoch  0, batch  1593 | loss: 2.0609353MixupTrain:  epoch  0, batch  1594 | loss: 2.1088042MixupTrain:  epoch  0, batch  1595 | loss: 2.7355261MixupTrain:  epoch  0, batch  1596 | loss: 2.3550000MixupTrain:  epoch  0, batch  1597 | loss: 2.9132531MixupTrain:  epoch  0, batch  1598 | loss: 2.2645962MixupTrain:  epoch  0, batch  1599 | loss: 2.5534797MixupTrain:  epoch  0, batch  1600 | loss: 2.1849692MixupTrain:  epoch  0, batch  1601 | loss: 2.2505517MixupTrain:  epoch  0, batch  1602 | loss: 2.2547557MixupTrain:  epoch  0, batch  1603 | loss: 2.7190833MixupTrain:  epoch  0, batch  1604 | loss: 2.3040898MixupTrain:  epoch  0, batch  1605 | loss: 2.8203888MixupTrain:  epoch  0, batch  1606 | loss: 2.1770542MixupTrain:  epoch  0, batch  1607 | loss: 2.3527355MixupTrain:  epoch  0, batch  1608 | loss: 2.2273374MixupTrain:  epoch  0, batch  1609 | loss: 2.0625486MixupTrain:  epoch  0, batch  1610 | loss: 2.2912478MixupTrain:  epoch  0, batch  1611 | loss: 2.5485706MixupTrain:  epoch  0, batch  1612 | loss: 2.0354159MixupTrain:  epoch  0, batch  1613 | loss: 2.3551970MixupTrain:  epoch  0, batch  1614 | loss: 2.7109485MixupTrain:  epoch  0, batch  1615 | loss: 2.5657661MixupTrain:  epoch  0, batch  1616 | loss: 2.6771336MixupTrain:  epoch  0, batch  1617 | loss: 2.2188363MixupTrain:  epoch  0, batch  1618 | loss: 2.5726471MixupTrain:  epoch  0, batch  1619 | loss: 2.4564285MixupTrain:  epoch  0, batch  1620 | loss: 2.4298501MixupTrain:  epoch  0, batch  1621 | loss: 2.4259663MixupTrain:  epoch  0, batch  1622 | loss: 2.2169251MixupTrain:  epoch  0, batch  1623 | loss: 2.6911614MixupTrain:  epoch  0, batch  1624 | loss: 2.1800964MixupTrain:  epoch  0, batch  1625 | loss: 2.5798540MixupTrain:  epoch  0, batch  1626 | loss: 2.6769412MixupTrain:  epoch  0, batch  1627 | loss: 2.4890876MixupTrain:  epoch  0, batch  1628 | loss: 2.3793142MixupTrain:  epoch  0, batch  1629 | loss: 2.3859801MixupTrain:  epoch  0, batch  1630 | loss: 2.3702371MixupTrain:  epoch  0, batch  1631 | loss: 2.7127850MixupTrain:  epoch  0, batch  1632 | loss: 2.7131107MixupTrain:  epoch  0, batch  1633 | loss: 2.7035329MixupTrain:  epoch  0, batch  1634 | loss: 2.6186643MixupTrain:  epoch  0, batch  1635 | loss: 2.2814112MixupTrain:  epoch  0, batch  1636 | loss: 2.3048625MixupTrain:  epoch  0, batch  1637 | loss: 2.7900188MixupTrain:  epoch  0, batch  1638 | loss: 2.6129627MixupTrain:  epoch  0, batch  1639 | loss: 2.3485618MixupTrain:  epoch  0, batch  1640 | loss: 2.5255980MixupTrain:  epoch  0, batch  1641 | loss: 2.8400145MixupTrain:  epoch  0, batch  1642 | loss: 2.2966199MixupTrain:  epoch  0, batch  1643 | loss: 2.2465839MixupTrain:  epoch  0, batch  1644 | loss: 2.2992473MixupTrain:  epoch  0, batch  1645 | loss: 2.5180600MixupTrain:  epoch  0, batch  1646 | loss: 2.3034368MixupTrain:  epoch  0, batch  1647 | loss: 2.7580547MixupTrain:  epoch  0, batch  1648 | loss: 2.5855584MixupTrain:  epoch  0, batch  1649 | loss: 2.4994292MixupTrain:  epoch  0, batch  1650 | loss: 2.4093127MixupTrain:  epoch  0, batch  1651 | loss: 2.1409009MixupTrain:  epoch  0, batch  1652 | loss: 2.0536332MixupTrain:  epoch  0, batch  1653 | loss: 2.3015857MixupTrain:  epoch  0, batch  1654 | loss: 2.7006569MixupTrain:  epoch  0, batch  1655 | loss: 2.5171952MixupTrain:  epoch  0, batch  1656 | loss: 2.5159409MixupTrain:  epoch  0, batch  1657 | loss: 2.3855877MixupTrain:  epoch  0, batch  1658 | loss: 2.3807259MixupTrain:  epoch  0, batch  1659 | loss: 2.2303300MixupTrain:  epoch  0, batch  1660 | loss: 2.7639279MixupTrain:  epoch  0, batch  1661 | loss: 2.2965627MixupTrain:  epoch  0, batch  1662 | loss: 2.6840532MixupTrain:  epoch  0, batch  1663 | loss: 2.8810325MixupTrain:  epoch  0, batch  1664 | loss: 2.2084267MixupTrain:  epoch  0, batch  1665 | loss: 2.4825969MixupTrain:  epoch  0, batch  1666 | loss: 2.9377475MixupTrain:  epoch  0, batch  1667 | loss: 2.2675619MixupTrain:  epoch  0, batch  1668 | loss: 2.9938731MixupTrain:  epoch  0, batch  1669 | loss: 2.2581859MixupTrain:  epoch  0, batch  1670 | loss: 2.3554997MixupTrain:  epoch  0, batch  1671 | loss: 2.4288077MixupTrain:  epoch  0, batch  1672 | loss: 2.4401114MixupTrain:  epoch  0, batch  1673 | loss: 2.1494334MixupTrain:  epoch  0, batch  1674 | loss: 2.6242557MixupTrain:  epoch  0, batch  1675 | loss: 2.5703516MixupTrain:  epoch  0, batch  1676 | loss: 2.3539143MixupTrain:  epoch  0, batch  1677 | loss: 2.1430163MixupTrain:  epoch  0, batch  1678 | loss: 2.5948253MixupTrain:  epoch  0, batch  1679 | loss: 2.2688141MixupTrain:  epoch  0, batch  1680 | loss: 2.6024945MixupTrain:  epoch  0, batch  1681 | loss: 2.2778540MixupTrain:  epoch  0, batch  1682 | loss: 3.1851306MixupTrain:  epoch  0, batch  1683 | loss: 2.0962305MixupTrain:  epoch  0, batch  1684 | loss: 2.6392460MixupTrain:  epoch  0, batch  1685 | loss: 2.6244473MixupTrain:  epoch  0, batch  1686 | loss: 2.6007228MixupTrain:  epoch  0, batch  1687 | loss: 2.3956776MixupTrain:  epoch  0, batch  1688 | loss: 2.2919197MixupTrain:  epoch  0, batch  1689 | loss: 2.4863482MixupTrain:  epoch  0, batch  1690 | loss: 2.2847118MixupTrain:  epoch  0, batch  1691 | loss: 2.4631696MixupTrain:  epoch  0, batch  1692 | loss: 2.5139322MixupTrain:  epoch  0, batch  1693 | loss: 2.3431053MixupTrain:  epoch  0, batch  1694 | loss: 2.6391296MixupTrain:  epoch  0, batch  1695 | loss: 2.4725285MixupTrain:  epoch  0, batch  1696 | loss: 2.7422843MixupTrain:  epoch  0, batch  1697 | loss: 2.6537538MixupTrain:  epoch  0, batch  1698 | loss: 2.5485229MixupTrain:  epoch  0, batch  1699 | loss: 2.8340845MixupTrain:  epoch  0, batch  1700 | loss: 2.3461914MixupTrain:  epoch  0, batch  1701 | loss: 2.2060595MixupTrain:  epoch  0, batch  1702 | loss: 2.4027686MixupTrain:  epoch  0, batch  1703 | loss: 2.2317042MixupTrain:  epoch  0, batch  1704 | loss: 2.5170956MixupTrain:  epoch  0, batch  1705 | loss: 2.4655027MixupTrain:  epoch  0, batch  1706 | loss: 2.4779885MixupTrain:  epoch  0, batch  1707 | loss: 2.6672635MixupTrain:  epoch  0, batch  1708 | loss: 2.2932353MixupTrain:  epoch  0, batch  1709 | loss: 2.1470690MixupTrain:  epoch  0, batch  1710 | loss: 2.6438484MixupTrain:  epoch  0, batch  1711 | loss: 2.6784718MixupTrain:  epoch  0, batch  1712 | loss: 3.0356090MixupTrain:  epoch  0, batch  1713 | loss: 2.2974215MixupTrain:  epoch  0, batch  1714 | loss: 2.4232478MixupTrain:  epoch  0, batch  1715 | loss: 2.4060133MixupTrain:  epoch  0, batch  1716 | loss: 2.4331725MixupTrain:  epoch  0, batch  1717 | loss: 2.5476460MixupTrain:  epoch  0, batch  1718 | loss: 2.6071312MixupTrain:  epoch  0, batch  1719 | loss: 2.2414479MixupTrain:  epoch  0, batch  1720 | loss: 2.5839660MixupTrain:  epoch  0, batch  1721 | loss: 2.6181569MixupTrain:  epoch  0, batch  1722 | loss: 2.0872049MixupTrain:  epoch  0, batch  1723 | loss: 2.4503729MixupTrain:  epoch  0, batch  1724 | loss: 2.8030672MixupTrain:  epoch  0, batch  1725 | loss: 2.4735048MixupTrain:  epoch  0, batch  1726 | loss: 2.5368407MixupTrain:  epoch  0, batch  1727 | loss: 2.5472789MixupTrain:  epoch  0, batch  1728 | loss: 2.5048807MixupTrain:  epoch  0, batch  1729 | loss: 2.8593111MixupTrain:  epoch  0, batch  1730 | loss: 2.2129693MixupTrain:  epoch  0, batch  1731 | loss: 2.6027312MixupTrain:  epoch  0, batch  1732 | loss: 2.3936791MixupTrain:  epoch  0, batch  1733 | loss: 2.3920569MixupTrain:  epoch  0, batch  1734 | loss: 2.2904077MixupTrain:  epoch  0, batch  1735 | loss: 2.3262925MixupTrain:  epoch  0, batch  1736 | loss: 1.9895254MixupTrain:  epoch  0, batch  1737 | loss: 2.4166384MixupTrain:  epoch  0, batch  1738 | loss: 2.6458850MixupTrain:  epoch  0, batch  1739 | loss: 2.7729669MixupTrain:  epoch  0, batch  1740 | loss: 2.2484117MixupTrain:  epoch  0, batch  1741 | loss: 2.2429085MixupTrain:  epoch  0, batch  1742 | loss: 2.0055854MixupTrain:  epoch  0, batch  1743 | loss: 2.5467210MixupTrain:  epoch  0, batch  1744 | loss: 2.4485092MixupTrain:  epoch  0, batch  1745 | loss: 2.3254690MixupTrain:  epoch  0, batch  1746 | loss: 2.5202281MixupTrain:  epoch  0, batch  1747 | loss: 2.2950194MixupTrain:  epoch  0, batch  1748 | loss: 2.9182568MixupTrain:  epoch  0, batch  1749 | loss: 2.7584276MixupTrain:  epoch  0, batch  1750 | loss: 2.4303999MixupTrain:  epoch  0, batch  1751 | loss: 2.6887336MixupTrain:  epoch  0, batch  1752 | loss: 2.4794788MixupTrain:  epoch  0, batch  1753 | loss: 2.4539614MixupTrain:  epoch  0, batch  1754 | loss: 2.0182691MixupTrain:  epoch  0, batch  1755 | loss: 2.4324136MixupTrain:  epoch  0, batch  1756 | loss: 2.5092883MixupTrain:  epoch  0, batch  1757 | loss: 2.0881751MixupTrain:  epoch  0, batch  1758 | loss: 2.8867784MixupTrain:  epoch  0, batch  1759 | loss: 2.4992254MixupTrain:  epoch  0, batch  1760 | loss: 2.5640454MixupTrain:  epoch  0, batch  1761 | loss: 2.6313262MixupTrain:  epoch  0, batch  1762 | loss: 2.4527659MixupTrain:  epoch  0, batch  1763 | loss: 2.5573487MixupTrain:  epoch  0, batch  1764 | loss: 2.5160284MixupTrain:  epoch  0, batch  1765 | loss: 2.4040103MixupTrain:  epoch  0, batch  1766 | loss: 2.3432610MixupTrain:  epoch  0, batch  1767 | loss: 2.2953634MixupTrain:  epoch  0, batch  1768 | loss: 2.5190868MixupTrain:  epoch  0, batch  1769 | loss: 2.5682259MixupTrain:  epoch  0, batch  1770 | loss: 2.1712890MixupTrain:  epoch  0, batch  1771 | loss: 2.4288034MixupTrain:  epoch  0, batch  1772 | loss: 2.3360605MixupTrain:  epoch  0, batch  1773 | loss: 2.3610477MixupTrain:  epoch  0, batch  1774 | loss: 2.5268292MixupTrain:  epoch  0, batch  1775 | loss: 2.8710101MixupTrain:  epoch  0, batch  1776 | loss: 2.5745430MixupTrain:  epoch  0, batch  1777 | loss: 2.5871098MixupTrain:  epoch  0, batch  1778 | loss: 2.4958937MixupTrain:  epoch  0, batch  1779 | loss: 2.6652341MixupTrain:  epoch  0, batch  1780 | loss: 2.5546734MixupTrain:  epoch  0, batch  1781 | loss: 2.7019730MixupTrain:  epoch  0, batch  1782 | loss: 2.1722884MixupTrain:  epoch  0, batch  1783 | loss: 2.4563460MixupTrain:  epoch  0, batch  1784 | loss: 2.1642666MixupTrain:  epoch  0, batch  1785 | loss: 2.6796360MixupTrain:  epoch  0, batch  1786 | loss: 2.8309610MixupTrain:  epoch  0, batch  1787 | loss: 2.4689646MixupTrain:  epoch  0, batch  1788 | loss: 2.0543947MixupTrain:  epoch  0, batch  1789 | loss: 2.3832273MixupTrain:  epoch  0, batch  1790 | loss: 2.3346658MixupTrain:  epoch  0, batch  1791 | loss: 2.5147452MixupTrain:  epoch  0, batch  1792 | loss: 2.1165044MixupTrain:  epoch  0, batch  1793 | loss: 2.7094471MixupTrain:  epoch  0, batch  1794 | loss: 2.4428287MixupTrain:  epoch  0, batch  1795 | loss: 2.5255661MixupTrain:  epoch  0, batch  1796 | loss: 2.5351236MixupTrain:  epoch  0, batch  1797 | loss: 2.0786185MixupTrain:  epoch  0, batch  1798 | loss: 2.4796181MixupTrain:  epoch  0, batch  1799 | loss: 2.4259567MixupTrain:  epoch  0, batch  1800 | loss: 2.3190398MixupTrain:  epoch  0, batch  1801 | loss: 2.5718007MixupTrain:  epoch  0, batch  1802 | loss: 2.6127825MixupTrain:  epoch  0, batch  1803 | loss: 2.4706173MixupTrain:  epoch  0, batch  1804 | loss: 2.0904419MixupTrain:  epoch  0, batch  1805 | loss: 2.3240862MixupTrain:  epoch  0, batch  1806 | loss: 2.3664517MixupTrain:  epoch  0, batch  1807 | loss: 2.5344956MixupTrain:  epoch  0, batch  1808 | loss: 2.2224536MixupTrain:  epoch  0, batch  1809 | loss: 2.2673984MixupTrain:  epoch  0, batch  1810 | loss: 2.2556622MixupTrain:  epoch  0, batch  1811 | loss: 2.3573799MixupTrain:  epoch  0, batch  1812 | loss: 2.7307198MixupTrain:  epoch  0, batch  1813 | loss: 2.7210751MixupTrain:  epoch  0, batch  1814 | loss: 1.9419181MixupTrain:  epoch  0, batch  1815 | loss: 2.7237396MixupTrain:  epoch  0, batch  1816 | loss: 2.4124782MixupTrain:  epoch  0, batch  1817 | loss: 2.4051952MixupTrain:  epoch  0, batch  1818 | loss: 2.3523450MixupTrain:  epoch  0, batch  1819 | loss: 2.3384962MixupTrain:  epoch  0, batch  1820 | loss: 2.6629944MixupTrain:  epoch  0, batch  1821 | loss: 2.6307330MixupTrain:  epoch  0, batch  1822 | loss: 2.7785263MixupTrain:  epoch  0, batch  1823 | loss: 2.4097064MixupTrain:  epoch  0, batch  1824 | loss: 2.5089970MixupTrain:  epoch  0, batch  1825 | loss: 2.7855363MixupTrain:  epoch  0, batch  1826 | loss: 2.3784378MixupTrain:  epoch  0, batch  1827 | loss: 2.5170460MixupTrain:  epoch  0, batch  1828 | loss: 2.4703360MixupTrain:  epoch  0, batch  1829 | loss: 2.4506211MixupTrain:  epoch  0, batch  1830 | loss: 2.2514977MixupTrain:  epoch  0, batch  1831 | loss: 2.4750276MixupTrain:  epoch  0, batch  1832 | loss: 2.2425895MixupTrain:  epoch  0, batch  1833 | loss: 2.3730156MixupTrain:  epoch  0, batch  1834 | loss: 2.1675467MixupTrain:  epoch  0, batch  1835 | loss: 2.2419386MixupTrain:  epoch  0, batch  1836 | loss: 2.2394252MixupTrain:  epoch  0, batch  1837 | loss: 2.5206156MixupTrain:  epoch  0, batch  1838 | loss: 2.3414769MixupTrain:  epoch  0, batch  1839 | loss: 2.6860826MixupTrain:  epoch  0, batch  1840 | loss: 2.6701488MixupTrain:  epoch  0, batch  1841 | loss: 2.2068594MixupTrain:  epoch  0, batch  1842 | loss: 2.4020784MixupTrain:  epoch  0, batch  1843 | loss: 2.4775605MixupTrain:  epoch  0, batch  1844 | loss: 2.2113791MixupTrain:  epoch  0, batch  1845 | loss: 2.6511416MixupTrain:  epoch  0, batch  1846 | loss: 2.6238260MixupTrain:  epoch  0, batch  1847 | loss: 2.3674884MixupTrain:  epoch  0, batch  1848 | loss: 2.3849046MixupTrain:  epoch  0, batch  1849 | loss: 2.2300782MixupTrain:  epoch  0, batch  1850 | loss: 2.6878715MixupTrain:  epoch  0, batch  1851 | loss: 2.6589098MixupTrain:  epoch  0, batch  1852 | loss: 2.3561378MixupTrain:  epoch  0, batch  1853 | loss: 2.1621842MixupTrain:  epoch  0, batch  1854 | loss: 2.1979027MixupTrain:  epoch  0, batch  1855 | loss: 2.4856536MixupTrain:  epoch  0, batch  1856 | loss: 2.4673004MixupTrain:  epoch  0, batch  1857 | loss: 2.4213452MixupTrain:  epoch  0, batch  1858 | loss: 2.3552952MixupTrain:  epoch  0, batch  1859 | loss: 2.5532665MixupTrain:  epoch  0, batch  1860 | loss: 2.1840506MixupTrain:  epoch  0, batch  1861 | loss: 2.8033333MixupTrain:  epoch  0, batch  1862 | loss: 2.2132359MixupTrain:  epoch  0, batch  1863 | loss: 2.6118851MixupTrain:  epoch  0, batch  1864 | loss: 2.2858655MixupTrain:  epoch  0, batch  1865 | loss: 2.4932523MixupTrain:  epoch  0, batch  1866 | loss: 2.3023064MixupTrain:  epoch  0, batch  1867 | loss: 2.3219783MixupTrain:  epoch  0, batch  1868 | loss: 2.5785058MixupTrain:  epoch  0, batch  1869 | loss: 2.2831707MixupTrain:  epoch  0, batch  1870 | loss: 2.2827656MixupTrain:  epoch  0, batch  1871 | loss: 2.1979175MixupTrain:  epoch  0, batch  1872 | loss: 2.3638439MixupTrain:  epoch  0, batch  1873 | loss: 2.7313237MixupTrain:  epoch  0, batch  1874 | loss: 2.8636527MixupTrain:  epoch  0, batch  1875 | loss: 2.4958124MixupTrain:  epoch  0, batch  1876 | loss: 2.3767073MixupTrain:  epoch  0, batch  1877 | loss: 2.2894492MixupTrain:  epoch  0, batch  1878 | loss: 2.7455726MixupTrain:  epoch  0, batch  1879 | loss: 2.6376314MixupTrain:  epoch  0, batch  1880 | loss: 2.6407933MixupTrain:  epoch  0, batch  1881 | loss: 1.9728239MixupTrain:  epoch  0, batch  1882 | loss: 2.5082738MixupTrain:  epoch  0, batch  1883 | loss: 2.2570648MixupTrain:  epoch  0, batch  1884 | loss: 2.5167098MixupTrain:  epoch  0, batch  1885 | loss: 2.5239019MixupTrain:  epoch  0, batch  1886 | loss: 2.3168359MixupTrain:  epoch  0, batch  1887 | loss: 2.6304293MixupTrain:  epoch  0, batch  1888 | loss: 2.9916759MixupTrain:  epoch  0, batch  1889 | loss: 2.0226278MixupTrain:  epoch  0, batch  1890 | loss: 2.2705626MixupTrain:  epoch  0, batch  1891 | loss: 2.8561029MixupTrain:  epoch  0, batch  1892 | loss: 2.4005444MixupTrain:  epoch  0, batch  1893 | loss: 2.2748265MixupTrain:  epoch  0, batch  1894 | loss: 2.2656858MixupTrain:  epoch  0, batch  1895 | loss: 2.3966317MixupTrain:  epoch  0, batch  1896 | loss: 2.2793677MixupTrain:  epoch  0, batch  1897 | loss: 2.7805338MixupTrain:  epoch  0, batch  1898 | loss: 2.4713409MixupTrain:  epoch  0, batch  1899 | loss: 2.2497578MixupTrain:  epoch  0, batch  1900 | loss: 2.4032559MixupTrain:  epoch  0, batch  1901 | loss: 2.2608335MixupTrain:  epoch  0, batch  1902 | loss: 2.5171154MixupTrain:  epoch  0, batch  1903 | loss: 2.6127393MixupTrain:  epoch  0, batch  1904 | loss: 2.1951454MixupTrain:  epoch  0, batch  1905 | loss: 2.8312888MixupTrain:  epoch  0, batch  1906 | loss: 2.5477872MixupTrain:  epoch  0, batch  1907 | loss: 2.4285340MixupTrain:  epoch  0, batch  1908 | loss: 2.8128772MixupTrain:  epoch  0, batch  1909 | loss: 2.3464327MixupTrain:  epoch  0, batch  1910 | loss: 2.9032068MixupTrain:  epoch  0, batch  1911 | loss: 2.7752538MixupTrain:  epoch  0, batch  1912 | loss: 2.3158989MixupTrain:  epoch  0, batch  1913 | loss: 1.9717923MixupTrain:  epoch  0, batch  1914 | loss: 2.1457381MixupTrain:  epoch  0, batch  1915 | loss: 2.8614545MixupTrain:  epoch  0, batch  1916 | loss: 2.6768544MixupTrain:  epoch  0, batch  1917 | loss: 2.3726704MixupTrain:  epoch  0, batch  1918 | loss: 2.6393793MixupTrain:  epoch  0, batch  1919 | loss: 2.4718904MixupTrain:  epoch  0, batch  1920 | loss: 2.5478816MixupTrain:  epoch  0, batch  1921 | loss: 2.3246021MixupTrain:  epoch  0, batch  1922 | loss: 2.3113413MixupTrain:  epoch  0, batch  1923 | loss: 2.0984049MixupTrain:  epoch  0, batch  1924 | loss: 2.6270545MixupTrain:  epoch  0, batch  1925 | loss: 2.4731355MixupTrain:  epoch  0, batch  1926 | loss: 2.1899810MixupTrain:  epoch  0, batch  1927 | loss: 2.7359715MixupTrain:  epoch  0, batch  1928 | loss: 2.2711501MixupTrain:  epoch  0, batch  1929 | loss: 2.3826880MixupTrain:  epoch  0, batch  1930 | loss: 2.0337653MixupTrain:  epoch  0, batch  1931 | loss: 2.2325716MixupTrain:  epoch  0, batch  1932 | loss: 2.4648788MixupTrain:  epoch  0, batch  1933 | loss: 2.3793874MixupTrain:  epoch  0, batch  1934 | loss: 2.4139261MixupTrain:  epoch  0, batch  1935 | loss: 2.4154263MixupTrain:  epoch  0, batch  1936 | loss: 2.2708459MixupTrain:  epoch  0, batch  1937 | loss: 2.7204995MixupTrain:  epoch  0, batch  1938 | loss: 2.5807905MixupTrain:  epoch  0, batch  1939 | loss: 2.5539696MixupTrain:  epoch  0, batch  1940 | loss: 2.0833416MixupTrain:  epoch  0, batch  1941 | loss: 2.6342778MixupTrain:  epoch  0, batch  1942 | loss: 2.8113136MixupTrain:  epoch  0, batch  1943 | loss: 2.6397731MixupTrain:  epoch  0, batch  1944 | loss: 2.4488931MixupTrain:  epoch  0, batch  1945 | loss: 2.4387584MixupTrain:  epoch  0, batch  1946 | loss: 2.9433713MixupTrain:  epoch  0, batch  1947 | loss: 2.2594943MixupTrain:  epoch  0, batch  1948 | loss: 2.6681330MixupTrain:  epoch  0, batch  1949 | loss: 2.9350228MixupTrain:  epoch  0, batch  1950 | loss: 2.8646495MixupTrain:  epoch  0, batch  1951 | loss: 2.2835236MixupTrain:  epoch  0, batch  1952 | loss: 2.4965665MixupTrain:  epoch  0, batch  1953 | loss: 2.3189130MixupTrain:  epoch  0, batch  1954 | loss: 2.6286392MixupTrain:  epoch  0, batch  1955 | loss: 2.3587234MixupTrain:  epoch  0, batch  1956 | loss: 2.4625814MixupTrain:  epoch  0, batch  1957 | loss: 2.4071946MixupTrain:  epoch  0, batch  1958 | loss: 2.1347425MixupTrain:  epoch  0, batch  1959 | loss: 2.2232070MixupTrain:  epoch  0, batch  1960 | loss: 2.4234309MixupTrain:  epoch  0, batch  1961 | loss: 2.2984545MixupTrain:  epoch  0, batch  1962 | loss: 2.2445993MixupTrain:  epoch  0, batch  1963 | loss: 2.5425782MixupTrain:  epoch  0, batch  1964 | loss: 2.4840703MixupTrain:  epoch  0, batch  1965 | loss: 2.0902472MixupTrain:  epoch  0, batch  1966 | loss: 2.0780239MixupTrain:  epoch  0, batch  1967 | loss: 2.2624977MixupTrain:  epoch  0, batch  1968 | loss: 2.4718173MixupTrain:  epoch  0, batch  1969 | loss: 2.3257308MixupTrain:  epoch  0, batch  1970 | loss: 2.3973849MixupTrain:  epoch  0, batch  1971 | loss: 2.0925896MixupTrain:  epoch  0, batch  1972 | loss: 2.3118873MixupTrain:  epoch  0, batch  1973 | loss: 2.3600450MixupTrain:  epoch  0, batch  1974 | loss: 2.3009086MixupTrain:  epoch  0, batch  1975 | loss: 2.2028689MixupTrain:  epoch  0, batch  1976 | loss: 2.3864803MixupTrain:  epoch  0, batch  1977 | loss: 2.4822290MixupTrain:  epoch  0, batch  1978 | loss: 2.7698712MixupTrain:  epoch  0, batch  1979 | loss: 2.6960170MixupTrain:  epoch  0, batch  1980 | loss: 2.4153953MixupTrain:  epoch  0, batch  1981 | loss: 2.0924053MixupTrain:  epoch  0, batch  1982 | loss: 2.8088336MixupTrain:  epoch  0, batch  1983 | loss: 2.6060796MixupTrain:  epoch  0, batch  1984 | loss: 2.2296333MixupTrain:  epoch  0, batch  1985 | loss: 2.4213786MixupTrain:  epoch  0, batch  1986 | loss: 2.1215982MixupTrain:  epoch  0, batch  1987 | loss: 2.4013743MixupTrain:  epoch  0, batch  1988 | loss: 2.6153307MixupTrain:  epoch  0, batch  1989 | loss: 2.5050118MixupTrain:  epoch  0, batch  1990 | loss: 2.1073258MixupTrain:  epoch  0, batch  1991 | loss: 2.2167926MixupTrain:  epoch  0, batch  1992 | loss: 2.3227992MixupTrain:  epoch  0, batch  1993 | loss: 2.2193887MixupTrain:  epoch  0, batch  1994 | loss: 2.3389888MixupTrain:  epoch  0, batch  1995 | loss: 2.5406218MixupTrain:  epoch  0, batch  1996 | loss: 2.5842495MixupTrain:  epoch  0, batch  1997 | loss: 2.3780630MixupTrain:  epoch  0, batch  1998 | loss: 2.2310910MixupTrain:  epoch  0, batch  1999 | loss: 2.3387961MixupTrain:  epoch  0, batch  2000 | loss: 2.2478766MixupTrain:  epoch  0, batch  2001 | loss: 2.2041156MixupTrain:  epoch  0, batch  2002 | loss: 2.2161021MixupTrain:  epoch  0, batch  2003 | loss: 2.4009645MixupTrain:  epoch  0, batch  2004 | loss: 2.5771160MixupTrain:  epoch  0, batch  2005 | loss: 2.6135159MixupTrain:  epoch  0, batch  2006 | loss: 2.5217228MixupTrain:  epoch  0, batch  2007 | loss: 2.4714777MixupTrain:  epoch  0, batch  2008 | loss: 2.3796544MixupTrain:  epoch  0, batch  2009 | loss: 2.3376102MixupTrain:  epoch  0, batch  2010 | loss: 2.2172308MixupTrain:  epoch  0, batch  2011 | loss: 2.6596048MixupTrain:  epoch  0, batch  2012 | loss: 2.5845020MixupTrain:  epoch  0, batch  2013 | loss: 2.3613126MixupTrain:  epoch  0, batch  2014 | loss: 2.3813200MixupTrain:  epoch  0, batch  2015 | loss: 2.5076370MixupTrain:  epoch  0, batch  2016 | loss: 2.3354597MixupTrain:  epoch  0, batch  2017 | loss: 2.3635530MixupTrain:  epoch  0, batch  2018 | loss: 2.0401759MixupTrain:  epoch  0, batch  2019 | loss: 2.4016914MixupTrain:  epoch  0, batch  2020 | loss: 2.4202652MixupTrain:  epoch  0, batch  2021 | loss: 2.5980072MixupTrain:  epoch  0, batch  2022 | loss: 2.4091816MixupTrain:  epoch  0, batch  2023 | loss: 2.5355589MixupTrain:  epoch  0, batch  2024 | loss: 2.2747121MixupTrain:  epoch  0, batch  2025 | loss: 2.3224344MixupTrain:  epoch  0, batch  2026 | loss: 2.5205388MixupTrain:  epoch  0, batch  2027 | loss: 2.4084430MixupTrain:  epoch  0, batch  2028 | loss: 2.4166999MixupTrain:  epoch  0, batch  2029 | loss: 2.7035320MixupTrain:  epoch  0, batch  2030 | loss: 2.3829675MixupTrain:  epoch  0, batch  2031 | loss: 2.3872633MixupTrain:  epoch  0, batch  2032 | loss: 2.4625974MixupTrain:  epoch  0, batch  2033 | loss: 2.3493612MixupTrain:  epoch  0, batch  2034 | loss: 2.2806869MixupTrain:  epoch  0, batch  2035 | loss: 2.2587876MixupTrain:  epoch  0, batch  2036 | loss: 2.3902295MixupTrain:  epoch  0, batch  2037 | loss: 2.3068285MixupTrain:  epoch  0, batch  2038 | loss: 2.5678570MixupTrain:  epoch  0, batch  2039 | loss: 2.4123492MixupTrain:  epoch  0, batch  2040 | loss: 2.5428822MixupTrain:  epoch  0, batch  2041 | loss: 2.0821743MixupTrain:  epoch  0, batch  2042 | loss: 2.4544864MixupTrain:  epoch  0, batch  2043 | loss: 2.5710425MixupTrain:  epoch  0, batch  2044 | loss: 2.5144134MixupTrain:  epoch  0, batch  2045 | loss: 2.2750616MixupTrain:  epoch  0, batch  2046 | loss: 1.9033250MixupTrain:  epoch  0, batch  2047 | loss: 2.3301950MixupTrain:  epoch  0, batch  2048 | loss: 2.3039432MixupTrain:  epoch  0, batch  2049 | loss: 2.7211928MixupTrain:  epoch  0, batch  2050 | loss: 2.2773056MixupTrain:  epoch  0, batch  2051 | loss: 2.7139630MixupTrain:  epoch  0, batch  2052 | loss: 2.4428437MixupTrain:  epoch  0, batch  2053 | loss: 2.3010416MixupTrain:  epoch  0, batch  2054 | loss: 2.3752606MixupTrain:  epoch  0, batch  2055 | loss: 2.4531608MixupTrain:  epoch  0, batch  2056 | loss: 2.2363718MixupTrain:  epoch  0, batch  2057 | loss: 2.7250335MixupTrain:  epoch  0, batch  2058 | loss: 2.3739440MixupTrain:  epoch  0, batch  2059 | loss: 2.4162149MixupTrain:  epoch  0, batch  2060 | loss: 2.3472471MixupTrain:  epoch  0, batch  2061 | loss: 2.7873254MixupTrain:  epoch  0, batch  2062 | loss: 2.3973451MixupTrain:  epoch  0, batch  2063 | loss: 1.9352752MixupTrain:  epoch  0, batch  2064 | loss: 2.5267916MixupTrain:  epoch  0, batch  2065 | loss: 2.6882372MixupTrain:  epoch  0, batch  2066 | loss: 2.4497457MixupTrain:  epoch  0, batch  2067 | loss: 2.5992937MixupTrain:  epoch  0, batch  2068 | loss: 2.3733311MixupTrain:  epoch  0, batch  2069 | loss: 2.3169365MixupTrain:  epoch  0, batch  2070 | loss: 2.9176605MixupTrain:  epoch  0, batch  2071 | loss: 2.1194165MixupTrain:  epoch  0, batch  2072 | loss: 2.7827423MixupTrain:  epoch  0, batch  2073 | loss: 2.2246895MixupTrain:  epoch  0, batch  2074 | loss: 2.4319022MixupTrain:  epoch  0, batch  2075 | loss: 2.4571157MixupTrain:  epoch  0, batch  2076 | loss: 2.8284371MixupTrain:  epoch  0, batch  2077 | loss: 2.3003759MixupTrain:  epoch  0, batch  2078 | loss: 2.4541681MixupTrain:  epoch  0, batch  2079 | loss: 2.4582052MixupTrain:  epoch  0, batch  2080 | loss: 2.4098072MixupTrain:  epoch  0, batch  2081 | loss: 2.5925884MixupTrain:  epoch  0, batch  2082 | loss: 2.7388239MixupTrain:  epoch  0, batch  2083 | loss: 2.9197927MixupTrain:  epoch  0, batch  2084 | loss: 2.6395092MixupTrain:  epoch  0, batch  2085 | loss: 2.2439005MixupTrain:  epoch  0, batch  2086 | loss: 2.2836580MixupTrain:  epoch  0, batch  2087 | loss: 2.6980824MixupTrain:  epoch  0, batch  2088 | loss: 2.3528271MixupTrain:  epoch  0, batch  2089 | loss: 2.5609901MixupTrain:  epoch  0, batch  2090 | loss: 2.0613451MixupTrain:  epoch  0, batch  2091 | loss: 2.4095402MixupTrain:  epoch  0, batch  2092 | loss: 2.7752941MixupTrain:  epoch  0, batch  2093 | loss: 2.3192830MixupTrain:  epoch  0, batch  2094 | loss: 2.4324584MixupTrain:  epoch  0, batch  2095 | loss: 2.3971324MixupTrain:  epoch  0, batch  2096 | loss: 2.5673742MixupTrain:  epoch  0, batch  2097 | loss: 2.6879678MixupTrain:  epoch  0, batch  2098 | loss: 2.4414723MixupTrain:  epoch  0, batch  2099 | loss: 2.4330699MixupTrain:  epoch  0, batch  2100 | loss: 2.2579265MixupTrain:  epoch  0, batch  2101 | loss: 2.5930729MixupTrain:  epoch  0, batch  2102 | loss: 2.4741044MixupTrain:  epoch  0, batch  2103 | loss: 2.3933115MixupTrain:  epoch  0, batch  2104 | loss: 2.6167929MixupTrain:  epoch  0, batch  2105 | loss: 2.1991327MixupTrain:  epoch  0, batch  2106 | loss: 2.5046644MixupTrain:  epoch  0, batch  2107 | loss: 3.0738626MixupTrain:  epoch  0, batch  2108 | loss: 2.2999074MixupTrain:  epoch  0, batch  2109 | loss: 2.7671180MixupTrain:  epoch  0, batch  2110 | loss: 2.3637965MixupTrain:  epoch  0, batch  2111 | loss: 2.0592020MixupTrain:  epoch  0, batch  2112 | loss: 2.5193262MixupTrain:  epoch  0, batch  2113 | loss: 2.6542625MixupTrain:  epoch  0, batch  2114 | loss: 2.5100336MixupTrain:  epoch  0, batch  2115 | loss: 2.5429597MixupTrain:  epoch  0, batch  2116 | loss: 2.3617270MixupTrain:  epoch  0, batch  2117 | loss: 2.2996202MixupTrain:  epoch  0, batch  2118 | loss: 2.4174576MixupTrain:  epoch  0, batch  2119 | loss: 2.4727421MixupTrain:  epoch  0, batch  2120 | loss: 2.1460605MixupTrain:  epoch  0, batch  2121 | loss: 2.2980621MixupTrain:  epoch  0, batch  2122 | loss: 2.4242182MixupTrain:  epoch  0, batch  2123 | loss: 2.1300018MixupTrain:  epoch  0, batch  2124 | loss: 2.3071797MixupTrain:  epoch  0, batch  2125 | loss: 2.1797745MixupTrain:  epoch  0, batch  2126 | loss: 2.3607719MixupTrain:  epoch  0, batch  2127 | loss: 2.1977954MixupTrain:  epoch  0, batch  2128 | loss: 2.3917499MixupTrain:  epoch  0, batch  2129 | loss: 2.1205273MixupTrain:  epoch  0, batch  2130 | loss: 2.4819417MixupTrain:  epoch  0, batch  2131 | loss: 2.7871404MixupTrain:  epoch  0, batch  2132 | loss: 2.8082604MixupTrain:  epoch  0, batch  2133 | loss: 2.3139498MixupTrain:  epoch  0, batch  2134 | loss: 2.5762861MixupTrain:  epoch  0, batch  2135 | loss: 2.1794314MixupTrain:  epoch  0, batch  2136 | loss: 2.1637824MixupTrain:  epoch  0, batch  2137 | loss: 2.2209349MixupTrain:  epoch  0, batch  2138 | loss: 2.9682040MixupTrain:  epoch  0, batch  2139 | loss: 2.2080529MixupTrain:  epoch  0, batch  2140 | loss: 2.3709018MixupTrain:  epoch  0, batch  2141 | loss: 2.3799372MixupTrain:  epoch  0, batch  2142 | loss: 2.2486572MixupTrain:  epoch  0, batch  2143 | loss: 2.1658757MixupTrain:  epoch  0, batch  2144 | loss: 2.5667317MixupTrain:  epoch  0, batch  2145 | loss: 2.1975543MixupTrain:  epoch  0, batch  2146 | loss: 2.5280485MixupTrain:  epoch  0, batch  2147 | loss: 2.2837684MixupTrain:  epoch  0, batch  2148 | loss: 2.3044782MixupTrain:  epoch  0, batch  2149 | loss: 1.9849024MixupTrain:  epoch  0, batch  2150 | loss: 2.3377438MixupTrain:  epoch  0, batch  2151 | loss: 2.4837813MixupTrain:  epoch  0, batch  2152 | loss: 2.2079387MixupTrain:  epoch  0, batch  2153 | loss: 2.2589407MixupTrain:  epoch  0, batch  2154 | loss: 2.2162619MixupTrain:  epoch  0, batch  2155 | loss: 2.4145823MixupTrain:  epoch  0, batch  2156 | loss: 2.2924418MixupTrain:  epoch  0, batch  2157 | loss: 2.0383582MixupTrain:  epoch  0, batch  2158 | loss: 2.7188387MixupTrain:  epoch  0, batch  2159 | loss: 2.5321479MixupTrain:  epoch  0, batch  2160 | loss: 2.3336840MixupTrain:  epoch  0, batch  2161 | loss: 2.4756117MixupTrain:  epoch  0, batch  2162 | loss: 2.2490964MixupTrain:  epoch  0, batch  2163 | loss: 2.8659947MixupTrain:  epoch  0, batch  2164 | loss: 2.6224580MixupTrain:  epoch  0, batch  2165 | loss: 2.5142727MixupTrain:  epoch  0, batch  2166 | loss: 2.2161741MixupTrain:  epoch  0, batch  2167 | loss: 2.6403904MixupTrain:  epoch  0, batch  2168 | loss: 2.4197674MixupTrain:  epoch  0, batch  2169 | loss: 2.4215560MixupTrain:  epoch  0, batch  2170 | loss: 3.0784068MixupTrain:  epoch  0, batch  2171 | loss: 2.5873251MixupTrain:  epoch  0, batch  2172 | loss: 2.6763604MixupTrain:  epoch  0, batch  2173 | loss: 2.6432652MixupTrain:  epoch  0, batch  2174 | loss: 2.4113264MixupTrain:  epoch  0, batch  2175 | loss: 2.1590889MixupTrain:  epoch  0, batch  2176 | loss: 2.3800440MixupTrain:  epoch  0, batch  2177 | loss: 2.4781761MixupTrain:  epoch  0, batch  2178 | loss: 2.2318649MixupTrain:  epoch  0, batch  2179 | loss: 2.6575246MixupTrain:  epoch  0, batch  2180 | loss: 2.2624178MixupTrain:  epoch  0, batch  2181 | loss: 2.2591777MixupTrain:  epoch  0, batch  2182 | loss: 2.6429820MixupTrain:  epoch  0, batch  2183 | loss: 2.0839536MixupTrain:  epoch  0, batch  2184 | loss: 2.4238100MixupTrain:  epoch  0, batch  2185 | loss: 2.3776860MixupTrain:  epoch  0, batch  2186 | loss: 2.3765793MixupTrain:  epoch  0, batch  2187 | loss: 2.2812760MixupTrain:  epoch  0, batch  2188 | loss: 2.6211274MixupTrain:  epoch  0, batch  2189 | loss: 2.5509293MixupTrain:  epoch  0, batch  2190 | loss: 2.8298278MixupTrain:  epoch  0, batch  2191 | loss: 2.4950433MixupTrain:  epoch  0, batch  2192 | loss: 2.0883541MixupTrain:  epoch  0, batch  2193 | loss: 2.2688086MixupTrain:  epoch  0, batch  2194 | loss: 2.3120975MixupTrain:  epoch  0, batch  2195 | loss: 2.0277030MixupTrain:  epoch  0, batch  2196 | loss: 2.6492019MixupTrain:  epoch  0, batch  2197 | loss: 2.2964296MixupTrain:  epoch  0, batch  2198 | loss: 2.3906052MixupTrain:  epoch  0, batch  2199 | loss: 2.6407375MixupTrain:  epoch  0, batch  2200 | loss: 2.1846471MixupTrain:  epoch  0, batch  2201 | loss: 2.8155313MixupTrain:  epoch  0, batch  2202 | loss: 2.3833838MixupTrain:  epoch  0, batch  2203 | loss: 2.8148308MixupTrain:  epoch  0, batch  2204 | loss: 2.4061761MixupTrain:  epoch  0, batch  2205 | loss: 2.5614417MixupTrain:  epoch  0, batch  2206 | loss: 2.1426585MixupTrain:  epoch  0, batch  2207 | loss: 2.5075409MixupTrain:  epoch  0, batch  2208 | loss: 2.6180661MixupTrain:  epoch  0, batch  2209 | loss: 2.6127481MixupTrain:  epoch  0, batch  2210 | loss: 2.2253871MixupTrain:  epoch  0, batch  2211 | loss: 2.5974441MixupTrain:  epoch  0, batch  2212 | loss: 2.5367794MixupTrain:  epoch  0, batch  2213 | loss: 2.5328176MixupTrain:  epoch  0, batch  2214 | loss: 2.4073944MixupTrain:  epoch  0, batch  2215 | loss: 2.6608639MixupTrain:  epoch  0, batch  2216 | loss: 2.4734564MixupTrain:  epoch  0, batch  2217 | loss: 2.5292687MixupTrain:  epoch  0, batch  2218 | loss: 2.7474394MixupTrain:  epoch  0, batch  2219 | loss: 2.6752737MixupTrain:  epoch  0, batch  2220 | loss: 2.5785880MixupTrain:  epoch  0, batch  2221 | loss: 2.1467130MixupTrain:  epoch  0, batch  2222 | loss: 2.1692886MixupTrain:  epoch  0, batch  2223 | loss: 2.2365217MixupTrain:  epoch  0, batch  2224 | loss: 2.2027602MixupTrain:  epoch  0, batch  2225 | loss: 2.2678237MixupTrain:  epoch  0, batch  2226 | loss: 2.1194749MixupTrain:  epoch  0, batch  2227 | loss: 2.4418187MixupTrain:  epoch  0, batch  2228 | loss: 2.4586658MixupTrain:  epoch  0, batch  2229 | loss: 2.5608916MixupTrain:  epoch  0, batch  2230 | loss: 2.6443863MixupTrain:  epoch  0, batch  2231 | loss: 2.3538358MixupTrain:  epoch  0, batch  2232 | loss: 3.1023936MixupTrain:  epoch  0, batch  2233 | loss: 2.0497575MixupTrain:  epoch  0, batch  2234 | loss: 1.9750435MixupTrain:  epoch  0, batch  2235 | loss: 2.3504624
MemoryTrain:  epoch  0, batch     0 | loss: 2.4165967MemoryTrain:  epoch  0, batch     1 | loss: 3.6794536MemoryTrain:  epoch  0, batch     2 | loss: 2.3020954MemoryTrain:  epoch  0, batch     3 | loss: 2.7810855MemoryTrain:  epoch  0, batch     4 | loss: 2.7794008MemoryTrain:  epoch  0, batch     5 | loss: 2.0879872MemoryTrain:  epoch  0, batch     6 | loss: 2.2789524MemoryTrain:  epoch  0, batch     7 | loss: 2.2331126MemoryTrain:  epoch  0, batch     8 | loss: 2.9994972MemoryTrain:  epoch  0, batch     9 | loss: 2.0992937MemoryTrain:  epoch  0, batch    10 | loss: 1.9339006MemoryTrain:  epoch  0, batch    11 | loss: 2.1735778MemoryTrain:  epoch  0, batch    12 | loss: 2.7978086MemoryTrain:  epoch  0, batch    13 | loss: 2.1763649MemoryTrain:  epoch  0, batch    14 | loss: 1.9408438MemoryTrain:  epoch  0, batch    15 | loss: 1.8919125MemoryTrain:  epoch  1, batch     0 | loss: 1.8274543MemoryTrain:  epoch  1, batch     1 | loss: 2.0569775MemoryTrain:  epoch  1, batch     2 | loss: 1.9177227MemoryTrain:  epoch  1, batch     3 | loss: 2.0469832MemoryTrain:  epoch  1, batch     4 | loss: 1.8241422MemoryTrain:  epoch  1, batch     5 | loss: 1.8548033MemoryTrain:  epoch  1, batch     6 | loss: 1.8594043MemoryTrain:  epoch  1, batch     7 | loss: 1.8265605MemoryTrain:  epoch  1, batch     8 | loss: 1.8287345MemoryTrain:  epoch  1, batch     9 | loss: 1.8507489MemoryTrain:  epoch  1, batch    10 | loss: 1.8668449MemoryTrain:  epoch  1, batch    11 | loss: 1.8563437MemoryTrain:  epoch  1, batch    12 | loss: 1.8417944MemoryTrain:  epoch  1, batch    13 | loss: 1.8351867MemoryTrain:  epoch  1, batch    14 | loss: 1.8676149MemoryTrain:  epoch  1, batch    15 | loss: 2.2454724MemoryTrain:  epoch  2, batch     0 | loss: 2.0554457MemoryTrain:  epoch  2, batch     1 | loss: 1.9166582MemoryTrain:  epoch  2, batch     2 | loss: 1.8181385MemoryTrain:  epoch  2, batch     3 | loss: 1.8295085MemoryTrain:  epoch  2, batch     4 | loss: 1.8415647MemoryTrain:  epoch  2, batch     5 | loss: 1.8203574MemoryTrain:  epoch  2, batch     6 | loss: 1.8247597MemoryTrain:  epoch  2, batch     7 | loss: 1.8172129MemoryTrain:  epoch  2, batch     8 | loss: 1.8703413MemoryTrain:  epoch  2, batch     9 | loss: 1.8210144MemoryTrain:  epoch  2, batch    10 | loss: 1.8407600MemoryTrain:  epoch  2, batch    11 | loss: 1.8241789MemoryTrain:  epoch  2, batch    12 | loss: 1.8620343MemoryTrain:  epoch  2, batch    13 | loss: 1.8620576MemoryTrain:  epoch  2, batch    14 | loss: 1.8108110MemoryTrain:  epoch  2, batch    15 | loss: 1.8128097MemoryTrain:  epoch  3, batch     0 | loss: 1.8129854MemoryTrain:  epoch  3, batch     1 | loss: 1.8093377MemoryTrain:  epoch  3, batch     2 | loss: 1.8136706MemoryTrain:  epoch  3, batch     3 | loss: 1.8101647MemoryTrain:  epoch  3, batch     4 | loss: 1.8093436MemoryTrain:  epoch  3, batch     5 | loss: 1.8195927MemoryTrain:  epoch  3, batch     6 | loss: 1.8112826MemoryTrain:  epoch  3, batch     7 | loss: 1.8191859MemoryTrain:  epoch  3, batch     8 | loss: 1.8078837MemoryTrain:  epoch  3, batch     9 | loss: 1.8118215MemoryTrain:  epoch  3, batch    10 | loss: 1.8136797MemoryTrain:  epoch  3, batch    11 | loss: 1.8192782MemoryTrain:  epoch  3, batch    12 | loss: 1.8294690MemoryTrain:  epoch  3, batch    13 | loss: 1.8109179MemoryTrain:  epoch  3, batch    14 | loss: 1.8165376MemoryTrain:  epoch  3, batch    15 | loss: 1.8125143MemoryTrain:  epoch  4, batch     0 | loss: 1.8159251MemoryTrain:  epoch  4, batch     1 | loss: 1.8162416MemoryTrain:  epoch  4, batch     2 | loss: 1.8108010MemoryTrain:  epoch  4, batch     3 | loss: 1.8107940MemoryTrain:  epoch  4, batch     4 | loss: 1.8261374MemoryTrain:  epoch  4, batch     5 | loss: 1.8216019MemoryTrain:  epoch  4, batch     6 | loss: 1.8104980MemoryTrain:  epoch  4, batch     7 | loss: 1.8089433MemoryTrain:  epoch  4, batch     8 | loss: 1.8129708MemoryTrain:  epoch  4, batch     9 | loss: 1.8075863MemoryTrain:  epoch  4, batch    10 | loss: 1.8095808MemoryTrain:  epoch  4, batch    11 | loss: 1.8108307MemoryTrain:  epoch  4, batch    12 | loss: 1.8115196MemoryTrain:  epoch  4, batch    13 | loss: 1.8133750MemoryTrain:  epoch  4, batch    14 | loss: 1.8077004MemoryTrain:  epoch  4, batch    15 | loss: 1.8121331MemoryTrain:  epoch  5, batch     0 | loss: 1.8116030MemoryTrain:  epoch  5, batch     1 | loss: 1.8132063MemoryTrain:  epoch  5, batch     2 | loss: 1.8173084MemoryTrain:  epoch  5, batch     3 | loss: 1.8130182MemoryTrain:  epoch  5, batch     4 | loss: 1.8089372MemoryTrain:  epoch  5, batch     5 | loss: 1.8187330MemoryTrain:  epoch  5, batch     6 | loss: 1.8142962MemoryTrain:  epoch  5, batch     7 | loss: 1.8132820MemoryTrain:  epoch  5, batch     8 | loss: 1.8127935MemoryTrain:  epoch  5, batch     9 | loss: 1.8078607MemoryTrain:  epoch  5, batch    10 | loss: 1.8090466MemoryTrain:  epoch  5, batch    11 | loss: 1.8114042MemoryTrain:  epoch  5, batch    12 | loss: 1.8129177MemoryTrain:  epoch  5, batch    13 | loss: 1.8116697MemoryTrain:  epoch  5, batch    14 | loss: 1.8159714MemoryTrain:  epoch  5, batch    15 | loss: 1.8123884MemoryTrain:  epoch  6, batch     0 | loss: 1.8157427MemoryTrain:  epoch  6, batch     1 | loss: 1.8127501MemoryTrain:  epoch  6, batch     2 | loss: 1.8149018MemoryTrain:  epoch  6, batch     3 | loss: 1.8237071MemoryTrain:  epoch  6, batch     4 | loss: 1.8114426MemoryTrain:  epoch  6, batch     5 | loss: 1.8109642MemoryTrain:  epoch  6, batch     6 | loss: 1.8144840MemoryTrain:  epoch  6, batch     7 | loss: 1.8159246MemoryTrain:  epoch  6, batch     8 | loss: 1.8123643MemoryTrain:  epoch  6, batch     9 | loss: 1.8035573MemoryTrain:  epoch  6, batch    10 | loss: 1.8133134MemoryTrain:  epoch  6, batch    11 | loss: 1.8111391MemoryTrain:  epoch  6, batch    12 | loss: 1.8042514MemoryTrain:  epoch  6, batch    13 | loss: 1.8128498MemoryTrain:  epoch  6, batch    14 | loss: 1.8127460MemoryTrain:  epoch  6, batch    15 | loss: 1.8161730MemoryTrain:  epoch  7, batch     0 | loss: 1.8108336MemoryTrain:  epoch  7, batch     1 | loss: 1.8126690MemoryTrain:  epoch  7, batch     2 | loss: 1.8138397MemoryTrain:  epoch  7, batch     3 | loss: 1.8063400MemoryTrain:  epoch  7, batch     4 | loss: 1.8114533MemoryTrain:  epoch  7, batch     5 | loss: 1.8081347MemoryTrain:  epoch  7, batch     6 | loss: 1.8090683MemoryTrain:  epoch  7, batch     7 | loss: 1.8062129MemoryTrain:  epoch  7, batch     8 | loss: 1.8086326MemoryTrain:  epoch  7, batch     9 | loss: 1.8117797MemoryTrain:  epoch  7, batch    10 | loss: 1.8137853MemoryTrain:  epoch  7, batch    11 | loss: 1.8157198MemoryTrain:  epoch  7, batch    12 | loss: 1.8123753MemoryTrain:  epoch  7, batch    13 | loss: 1.8196577MemoryTrain:  epoch  7, batch    14 | loss: 1.8149347MemoryTrain:  epoch  7, batch    15 | loss: 1.8104585MemoryTrain:  epoch  8, batch     0 | loss: 1.8037786MemoryTrain:  epoch  8, batch     1 | loss: 1.8120733MemoryTrain:  epoch  8, batch     2 | loss: 1.8133922MemoryTrain:  epoch  8, batch     3 | loss: 1.8073883MemoryTrain:  epoch  8, batch     4 | loss: 1.8088956MemoryTrain:  epoch  8, batch     5 | loss: 1.8036931MemoryTrain:  epoch  8, batch     6 | loss: 1.8110654MemoryTrain:  epoch  8, batch     7 | loss: 1.8131531MemoryTrain:  epoch  8, batch     8 | loss: 1.8075349MemoryTrain:  epoch  8, batch     9 | loss: 1.8057680MemoryTrain:  epoch  8, batch    10 | loss: 1.8205359MemoryTrain:  epoch  8, batch    11 | loss: 1.8134439MemoryTrain:  epoch  8, batch    12 | loss: 1.8070508MemoryTrain:  epoch  8, batch    13 | loss: 1.8070310MemoryTrain:  epoch  8, batch    14 | loss: 1.8084486MemoryTrain:  epoch  8, batch    15 | loss: 1.8099912MemoryTrain:  epoch  9, batch     0 | loss: 1.8086858MemoryTrain:  epoch  9, batch     1 | loss: 1.8118246MemoryTrain:  epoch  9, batch     2 | loss: 1.8169475MemoryTrain:  epoch  9, batch     3 | loss: 1.8106902MemoryTrain:  epoch  9, batch     4 | loss: 1.8077489MemoryTrain:  epoch  9, batch     5 | loss: 1.8117862MemoryTrain:  epoch  9, batch     6 | loss: 1.8106294MemoryTrain:  epoch  9, batch     7 | loss: 1.8091887MemoryTrain:  epoch  9, batch     8 | loss: 1.8116901MemoryTrain:  epoch  9, batch     9 | loss: 1.8052673MemoryTrain:  epoch  9, batch    10 | loss: 1.8076475MemoryTrain:  epoch  9, batch    11 | loss: 1.8071045MemoryTrain:  epoch  9, batch    12 | loss: 1.8105966MemoryTrain:  epoch  9, batch    13 | loss: 1.8061078MemoryTrain:  epoch  9, batch    14 | loss: 1.8089939MemoryTrain:  epoch  9, batch    15 | loss: 1.8057474
[EVAL] batch:    0 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 96.88%   [EVAL] batch:    2 | acc: 100.00%,  total acc: 97.92%   [EVAL] batch:    3 | acc: 100.00%,  total acc: 98.44%   [EVAL] batch:    4 | acc: 100.00%,  total acc: 98.75%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 98.96%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 99.11%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 99.22%   [EVAL] batch:    8 | acc: 81.25%,  total acc: 97.22%   [EVAL] batch:    9 | acc: 43.75%,  total acc: 91.88%   [EVAL] batch:   10 | acc: 87.50%,  total acc: 91.48%   [EVAL] batch:   11 | acc: 100.00%,  total acc: 92.19%   [EVAL] batch:   12 | acc: 100.00%,  total acc: 92.79%   [EVAL] batch:   13 | acc: 75.00%,  total acc: 91.52%   
[EVAL] batch:    0 | acc: 0.00%,  total acc: 0.00%   [EVAL] batch:    1 | acc: 31.25%,  total acc: 15.62%   [EVAL] batch:    2 | acc: 6.25%,  total acc: 12.50%   [EVAL] batch:    3 | acc: 6.25%,  total acc: 10.94%   [EVAL] batch:    4 | acc: 6.25%,  total acc: 10.00%   [EVAL] batch:    5 | acc: 6.25%,  total acc: 9.38%   [EVAL] batch:    6 | acc: 6.25%,  total acc: 8.93%   [EVAL] batch:    7 | acc: 0.00%,  total acc: 7.81%   [EVAL] batch:    8 | acc: 0.00%,  total acc: 6.94%   [EVAL] batch:    9 | acc: 0.00%,  total acc: 6.25%   [EVAL] batch:   10 | acc: 0.00%,  total acc: 5.68%   [EVAL] batch:   11 | acc: 6.25%,  total acc: 5.73%   [EVAL] batch:   12 | acc: 12.50%,  total acc: 6.25%   [EVAL] batch:   13 | acc: 37.50%,  total acc: 8.48%   [EVAL] batch:   14 | acc: 43.75%,  total acc: 10.83%   [EVAL] batch:   15 | acc: 43.75%,  total acc: 12.89%   [EVAL] batch:   16 | acc: 50.00%,  total acc: 15.07%   [EVAL] batch:   17 | acc: 56.25%,  total acc: 17.36%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 19.74%   [EVAL] batch:   19 | acc: 56.25%,  total acc: 21.56%   [EVAL] batch:   20 | acc: 93.75%,  total acc: 25.00%   [EVAL] batch:   21 | acc: 93.75%,  total acc: 28.12%   [EVAL] batch:   22 | acc: 87.50%,  total acc: 30.71%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 33.33%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 35.75%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 38.22%   [EVAL] batch:   26 | acc: 50.00%,  total acc: 38.66%   [EVAL] batch:   27 | acc: 37.50%,  total acc: 38.62%   [EVAL] batch:   28 | acc: 6.25%,  total acc: 37.50%   [EVAL] batch:   29 | acc: 18.75%,  total acc: 36.88%   [EVAL] batch:   30 | acc: 18.75%,  total acc: 36.29%   [EVAL] batch:   31 | acc: 37.50%,  total acc: 36.33%   [EVAL] batch:   32 | acc: 6.25%,  total acc: 35.42%   [EVAL] batch:   33 | acc: 6.25%,  total acc: 34.56%   [EVAL] batch:   34 | acc: 6.25%,  total acc: 33.75%   [EVAL] batch:   35 | acc: 12.50%,  total acc: 33.16%   [EVAL] batch:   36 | acc: 0.00%,  total acc: 32.26%   [EVAL] batch:   37 | acc: 56.25%,  total acc: 32.89%   [EVAL] batch:   38 | acc: 68.75%,  total acc: 33.81%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 35.47%   [EVAL] batch:   40 | acc: 62.50%,  total acc: 36.13%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 37.65%   [EVAL] batch:   42 | acc: 0.00%,  total acc: 36.77%   [EVAL] batch:   43 | acc: 0.00%,  total acc: 35.94%   [EVAL] batch:   44 | acc: 0.00%,  total acc: 35.14%   [EVAL] batch:   45 | acc: 0.00%,  total acc: 34.38%   [EVAL] batch:   46 | acc: 18.75%,  total acc: 34.04%   [EVAL] batch:   47 | acc: 31.25%,  total acc: 33.98%   [EVAL] batch:   48 | acc: 6.25%,  total acc: 33.42%   [EVAL] batch:   49 | acc: 0.00%,  total acc: 32.75%   [EVAL] batch:   50 | acc: 0.00%,  total acc: 32.11%   [EVAL] batch:   51 | acc: 0.00%,  total acc: 31.49%   [EVAL] batch:   52 | acc: 0.00%,  total acc: 30.90%   [EVAL] batch:   53 | acc: 25.00%,  total acc: 30.79%   [EVAL] batch:   54 | acc: 81.25%,  total acc: 31.70%   [EVAL] batch:   55 | acc: 81.25%,  total acc: 32.59%   [EVAL] batch:   56 | acc: 75.00%,  total acc: 33.33%   [EVAL] batch:   57 | acc: 68.75%,  total acc: 33.94%   [EVAL] batch:   58 | acc: 62.50%,  total acc: 34.43%   [EVAL] batch:   59 | acc: 43.75%,  total acc: 34.58%   [EVAL] batch:   60 | acc: 12.50%,  total acc: 34.22%   [EVAL] batch:   61 | acc: 31.25%,  total acc: 34.17%   [EVAL] batch:   62 | acc: 12.50%,  total acc: 33.83%   [EVAL] batch:   63 | acc: 31.25%,  total acc: 33.79%   [EVAL] batch:   64 | acc: 18.75%,  total acc: 33.56%   [EVAL] batch:   65 | acc: 12.50%,  total acc: 33.24%   [EVAL] batch:   66 | acc: 18.75%,  total acc: 33.02%   [EVAL] batch:   67 | acc: 100.00%,  total acc: 34.01%   [EVAL] batch:   68 | acc: 50.00%,  total acc: 34.24%   [EVAL] batch:   69 | acc: 31.25%,  total acc: 34.20%   [EVAL] batch:   70 | acc: 56.25%,  total acc: 34.51%   [EVAL] batch:   71 | acc: 68.75%,  total acc: 34.98%   [EVAL] batch:   72 | acc: 100.00%,  total acc: 35.87%   [EVAL] batch:   73 | acc: 100.00%,  total acc: 36.74%   [EVAL] batch:   74 | acc: 100.00%,  total acc: 37.58%   [EVAL] batch:   75 | acc: 93.75%,  total acc: 38.32%   [EVAL] batch:   76 | acc: 100.00%,  total acc: 39.12%   [EVAL] batch:   77 | acc: 68.75%,  total acc: 39.50%   [EVAL] batch:   78 | acc: 0.00%,  total acc: 39.00%   [EVAL] batch:   79 | acc: 0.00%,  total acc: 38.52%   [EVAL] batch:   80 | acc: 0.00%,  total acc: 38.04%   [EVAL] batch:   81 | acc: 6.25%,  total acc: 37.65%   [EVAL] batch:   82 | acc: 0.00%,  total acc: 37.20%   [EVAL] batch:   83 | acc: 0.00%,  total acc: 36.76%   [EVAL] batch:   84 | acc: 37.50%,  total acc: 36.76%   [EVAL] batch:   85 | acc: 25.00%,  total acc: 36.63%   [EVAL] batch:   86 | acc: 31.25%,  total acc: 36.57%   [EVAL] batch:   87 | acc: 25.00%,  total acc: 36.43%   [EVAL] batch:   88 | acc: 31.25%,  total acc: 36.38%   [EVAL] batch:   89 | acc: 31.25%,  total acc: 36.32%   [EVAL] batch:   90 | acc: 50.00%,  total acc: 36.47%   [EVAL] batch:   91 | acc: 68.75%,  total acc: 36.82%   [EVAL] batch:   92 | acc: 50.00%,  total acc: 36.96%   [EVAL] batch:   93 | acc: 43.75%,  total acc: 37.03%   [EVAL] batch:   94 | acc: 50.00%,  total acc: 37.17%   [EVAL] batch:   95 | acc: 43.75%,  total acc: 37.24%   [EVAL] batch:   96 | acc: 31.25%,  total acc: 37.18%   [EVAL] batch:   97 | acc: 37.50%,  total acc: 37.18%   [EVAL] batch:   98 | acc: 37.50%,  total acc: 37.18%   [EVAL] batch:   99 | acc: 81.25%,  total acc: 37.62%   [EVAL] batch:  100 | acc: 87.50%,  total acc: 38.12%   [EVAL] batch:  101 | acc: 43.75%,  total acc: 38.17%   [EVAL] batch:  102 | acc: 93.75%,  total acc: 38.71%   [EVAL] batch:  103 | acc: 100.00%,  total acc: 39.30%   [EVAL] batch:  104 | acc: 93.75%,  total acc: 39.82%   [EVAL] batch:  105 | acc: 100.00%,  total acc: 40.39%   [EVAL] batch:  106 | acc: 68.75%,  total acc: 40.65%   [EVAL] batch:  107 | acc: 62.50%,  total acc: 40.86%   [EVAL] batch:  108 | acc: 75.00%,  total acc: 41.17%   [EVAL] batch:  109 | acc: 68.75%,  total acc: 41.42%   [EVAL] batch:  110 | acc: 87.50%,  total acc: 41.84%   [EVAL] batch:  111 | acc: 100.00%,  total acc: 42.35%   [EVAL] batch:  112 | acc: 75.00%,  total acc: 42.64%   [EVAL] batch:  113 | acc: 100.00%,  total acc: 43.15%   [EVAL] batch:  114 | acc: 93.75%,  total acc: 43.59%   [EVAL] batch:  115 | acc: 75.00%,  total acc: 43.86%   [EVAL] batch:  116 | acc: 93.75%,  total acc: 44.28%   [EVAL] batch:  117 | acc: 75.00%,  total acc: 44.54%   [EVAL] batch:  118 | acc: 75.00%,  total acc: 44.80%   [EVAL] batch:  119 | acc: 100.00%,  total acc: 45.26%   [EVAL] batch:  120 | acc: 93.75%,  total acc: 45.66%   [EVAL] batch:  121 | acc: 100.00%,  total acc: 46.11%   [EVAL] batch:  122 | acc: 100.00%,  total acc: 46.54%   [EVAL] batch:  123 | acc: 100.00%,  total acc: 46.98%   [EVAL] batch:  124 | acc: 100.00%,  total acc: 47.40%   [EVAL] batch:  125 | acc: 100.00%,  total acc: 47.82%   [EVAL] batch:  126 | acc: 100.00%,  total acc: 48.23%   [EVAL] batch:  127 | acc: 75.00%,  total acc: 48.44%   [EVAL] batch:  128 | acc: 50.00%,  total acc: 48.45%   [EVAL] batch:  129 | acc: 87.50%,  total acc: 48.75%   [EVAL] batch:  130 | acc: 100.00%,  total acc: 49.14%   [EVAL] batch:  131 | acc: 100.00%,  total acc: 49.53%   [EVAL] batch:  132 | acc: 62.50%,  total acc: 49.62%   
cur_acc:  ['0.8580', '0.8750', '0.8438', '0.9028', '0.6449', '0.7656', '0.8221', '0.9152']
his_acc:  ['0.8580', '0.8191', '0.7121', '0.6314', '0.6138', '0.5298', '0.4884', '0.4962']
--------Round  2
seed:  300
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 2 3 1 5 6 0 4]
prepared data!
CurrentTrain: epoch  0, batch     0 | loss: 12.2235289CurrentTrain: epoch  0, batch     1 | loss: 11.6012354CurrentTrain: epoch  0, batch     2 | loss: 11.5257454CurrentTrain: epoch  0, batch     3 | loss: 11.6904202CurrentTrain: epoch  0, batch     4 | loss: 10.9835796CurrentTrain: epoch  0, batch     5 | loss: 11.4194059CurrentTrain: epoch  0, batch     6 | loss: 11.3137150CurrentTrain: epoch  0, batch     7 | loss: 11.1523075CurrentTrain: epoch  0, batch     8 | loss: 10.7042618CurrentTrain: epoch  0, batch     9 | loss: 11.3345747CurrentTrain: epoch  0, batch    10 | loss: 10.9373703CurrentTrain: epoch  0, batch    11 | loss: 10.5601006CurrentTrain: epoch  0, batch    12 | loss: 11.0272827CurrentTrain: epoch  0, batch    13 | loss: 10.6640139CurrentTrain: epoch  0, batch    14 | loss: 9.9904108CurrentTrain: epoch  0, batch    15 | loss: 10.5560760CurrentTrain: epoch  0, batch    16 | loss: 9.8801861CurrentTrain: epoch  0, batch    17 | loss: 10.5686178CurrentTrain: epoch  0, batch    18 | loss: 9.9176397CurrentTrain: epoch  0, batch    19 | loss: 10.0305481CurrentTrain: epoch  0, batch    20 | loss: 11.0087309CurrentTrain: epoch  0, batch    21 | loss: 10.0851135CurrentTrain: epoch  0, batch    22 | loss: 10.2436237CurrentTrain: epoch  0, batch    23 | loss: 9.7869158CurrentTrain: epoch  0, batch    24 | loss: 10.8029518CurrentTrain: epoch  0, batch    25 | loss: 9.5900755CurrentTrain: epoch  0, batch    26 | loss: 10.1298637CurrentTrain: epoch  0, batch    27 | loss: 9.7597895CurrentTrain: epoch  0, batch    28 | loss: 9.5765381CurrentTrain: epoch  0, batch    29 | loss: 10.6666222CurrentTrain: epoch  0, batch    30 | loss: 10.2415333CurrentTrain: epoch  0, batch    31 | loss: 9.8458548CurrentTrain: epoch  0, batch    32 | loss: 9.8180456CurrentTrain: epoch  0, batch    33 | loss: 9.2173386CurrentTrain: epoch  0, batch    34 | loss: 9.9039907CurrentTrain: epoch  0, batch    35 | loss: 9.9288893CurrentTrain: epoch  0, batch    36 | loss: 10.4208393CurrentTrain: epoch  0, batch    37 | loss: 10.2407684CurrentTrain: epoch  1, batch     0 | loss: 9.5261593CurrentTrain: epoch  1, batch     1 | loss: 8.6924095CurrentTrain: epoch  1, batch     2 | loss: 9.3646431CurrentTrain: epoch  1, batch     3 | loss: 10.4240856CurrentTrain: epoch  1, batch     4 | loss: 9.9412327CurrentTrain: epoch  1, batch     5 | loss: 8.5328579CurrentTrain: epoch  1, batch     6 | loss: 9.5076294CurrentTrain: epoch  1, batch     7 | loss: 8.3821726CurrentTrain: epoch  1, batch     8 | loss: 9.4141350CurrentTrain: epoch  1, batch     9 | loss: 9.1764994CurrentTrain: epoch  1, batch    10 | loss: 9.9788189CurrentTrain: epoch  1, batch    11 | loss: 9.1200390CurrentTrain: epoch  1, batch    12 | loss: 9.3290348CurrentTrain: epoch  1, batch    13 | loss: 9.2806139CurrentTrain: epoch  1, batch    14 | loss: 9.2163420CurrentTrain: epoch  1, batch    15 | loss: 8.6268082CurrentTrain: epoch  1, batch    16 | loss: 8.9161806CurrentTrain: epoch  1, batch    17 | loss: 8.5738525CurrentTrain: epoch  1, batch    18 | loss: 8.8401871CurrentTrain: epoch  1, batch    19 | loss: 8.8012505CurrentTrain: epoch  1, batch    20 | loss: 8.9534941CurrentTrain: epoch  1, batch    21 | loss: 8.7734394CurrentTrain: epoch  1, batch    22 | loss: 8.3856926CurrentTrain: epoch  1, batch    23 | loss: 7.7867908CurrentTrain: epoch  1, batch    24 | loss: 8.2105236CurrentTrain: epoch  1, batch    25 | loss: 8.5588417CurrentTrain: epoch  1, batch    26 | loss: 8.2076626CurrentTrain: epoch  1, batch    27 | loss: 9.3603249CurrentTrain: epoch  1, batch    28 | loss: 7.9655094CurrentTrain: epoch  1, batch    29 | loss: 9.0838776CurrentTrain: epoch  1, batch    30 | loss: 8.3628798CurrentTrain: epoch  1, batch    31 | loss: 8.0664501CurrentTrain: epoch  1, batch    32 | loss: 8.1517239CurrentTrain: epoch  1, batch    33 | loss: 7.4297657CurrentTrain: epoch  1, batch    34 | loss: 7.6982636CurrentTrain: epoch  1, batch    35 | loss: 8.1527796CurrentTrain: epoch  1, batch    36 | loss: 8.2214308CurrentTrain: epoch  1, batch    37 | loss: 8.6178246CurrentTrain: epoch  2, batch     0 | loss: 8.1226301CurrentTrain: epoch  2, batch     1 | loss: 8.3084698CurrentTrain: epoch  2, batch     2 | loss: 8.0316963CurrentTrain: epoch  2, batch     3 | loss: 8.0500917CurrentTrain: epoch  2, batch     4 | loss: 8.2289238CurrentTrain: epoch  2, batch     5 | loss: 7.3855429CurrentTrain: epoch  2, batch     6 | loss: 7.6015353CurrentTrain: epoch  2, batch     7 | loss: 8.4907990CurrentTrain: epoch  2, batch     8 | loss: 7.4046979CurrentTrain: epoch  2, batch     9 | loss: 7.9526167CurrentTrain: epoch  2, batch    10 | loss: 8.6386967CurrentTrain: epoch  2, batch    11 | loss: 7.6446152CurrentTrain: epoch  2, batch    12 | loss: 7.5197120CurrentTrain: epoch  2, batch    13 | loss: 7.5708265CurrentTrain: epoch  2, batch    14 | loss: 7.0511937CurrentTrain: epoch  2, batch    15 | loss: 7.2505779CurrentTrain: epoch  2, batch    16 | loss: 8.2384539CurrentTrain: epoch  2, batch    17 | loss: 7.4479733CurrentTrain: epoch  2, batch    18 | loss: 8.3681459CurrentTrain: epoch  2, batch    19 | loss: 7.6288462CurrentTrain: epoch  2, batch    20 | loss: 8.1848164CurrentTrain: epoch  2, batch    21 | loss: 8.2998886CurrentTrain: epoch  2, batch    22 | loss: 6.6678123CurrentTrain: epoch  2, batch    23 | loss: 7.5567398CurrentTrain: epoch  2, batch    24 | loss: 7.1805491CurrentTrain: epoch  2, batch    25 | loss: 7.2397885CurrentTrain: epoch  2, batch    26 | loss: 7.3748751CurrentTrain: epoch  2, batch    27 | loss: 8.1420879CurrentTrain: epoch  2, batch    28 | loss: 7.3700409CurrentTrain: epoch  2, batch    29 | loss: 7.3289447CurrentTrain: epoch  2, batch    30 | loss: 7.8608675CurrentTrain: epoch  2, batch    31 | loss: 7.4112296CurrentTrain: epoch  2, batch    32 | loss: 6.5715413CurrentTrain: epoch  2, batch    33 | loss: 7.7304668CurrentTrain: epoch  2, batch    34 | loss: 7.6862307CurrentTrain: epoch  2, batch    35 | loss: 7.3744669CurrentTrain: epoch  2, batch    36 | loss: 7.6391673CurrentTrain: epoch  2, batch    37 | loss: 7.6384230CurrentTrain: epoch  3, batch     0 | loss: 6.9526005CurrentTrain: epoch  3, batch     1 | loss: 6.9352446CurrentTrain: epoch  3, batch     2 | loss: 7.5693951CurrentTrain: epoch  3, batch     3 | loss: 7.5147963CurrentTrain: epoch  3, batch     4 | loss: 7.5202107CurrentTrain: epoch  3, batch     5 | loss: 6.6781216CurrentTrain: epoch  3, batch     6 | loss: 7.8598270CurrentTrain: epoch  3, batch     7 | loss: 7.0131717CurrentTrain: epoch  3, batch     8 | loss: 7.0488162CurrentTrain: epoch  3, batch     9 | loss: 6.5135937CurrentTrain: epoch  3, batch    10 | loss: 7.0534897CurrentTrain: epoch  3, batch    11 | loss: 7.1865802CurrentTrain: epoch  3, batch    12 | loss: 6.2991724CurrentTrain: epoch  3, batch    13 | loss: 6.7319489CurrentTrain: epoch  3, batch    14 | loss: 6.6299314CurrentTrain: epoch  3, batch    15 | loss: 6.9258633CurrentTrain: epoch  3, batch    16 | loss: 6.9281969CurrentTrain: epoch  3, batch    17 | loss: 6.6365776CurrentTrain: epoch  3, batch    18 | loss: 7.0686121CurrentTrain: epoch  3, batch    19 | loss: 6.9434662CurrentTrain: epoch  3, batch    20 | loss: 6.4053082CurrentTrain: epoch  3, batch    21 | loss: 7.6111193CurrentTrain: epoch  3, batch    22 | loss: 7.0337820CurrentTrain: epoch  3, batch    23 | loss: 6.7422271CurrentTrain: epoch  3, batch    24 | loss: 6.8758883CurrentTrain: epoch  3, batch    25 | loss: 7.1140866CurrentTrain: epoch  3, batch    26 | loss: 6.8154402CurrentTrain: epoch  3, batch    27 | loss: 7.3271408CurrentTrain: epoch  3, batch    28 | loss: 7.0625839CurrentTrain: epoch  3, batch    29 | loss: 6.8716898CurrentTrain: epoch  3, batch    30 | loss: 6.3503251CurrentTrain: epoch  3, batch    31 | loss: 6.2356133CurrentTrain: epoch  3, batch    32 | loss: 6.5557985CurrentTrain: epoch  3, batch    33 | loss: 7.9598713CurrentTrain: epoch  3, batch    34 | loss: 6.9840403CurrentTrain: epoch  3, batch    35 | loss: 7.0934377CurrentTrain: epoch  3, batch    36 | loss: 7.0819778CurrentTrain: epoch  3, batch    37 | loss: 6.5163021CurrentTrain: epoch  4, batch     0 | loss: 7.1702003CurrentTrain: epoch  4, batch     1 | loss: 7.1052094CurrentTrain: epoch  4, batch     2 | loss: 6.6689324CurrentTrain: epoch  4, batch     3 | loss: 6.9101954CurrentTrain: epoch  4, batch     4 | loss: 7.0476985CurrentTrain: epoch  4, batch     5 | loss: 6.3322759CurrentTrain: epoch  4, batch     6 | loss: 6.4997368CurrentTrain: epoch  4, batch     7 | loss: 6.7569389CurrentTrain: epoch  4, batch     8 | loss: 6.3124533CurrentTrain: epoch  4, batch     9 | loss: 6.8162212CurrentTrain: epoch  4, batch    10 | loss: 6.4345541CurrentTrain: epoch  4, batch    11 | loss: 6.3310432CurrentTrain: epoch  4, batch    12 | loss: 5.9426465CurrentTrain: epoch  4, batch    13 | loss: 6.1724405CurrentTrain: epoch  4, batch    14 | loss: 6.6857653CurrentTrain: epoch  4, batch    15 | loss: 6.5288429CurrentTrain: epoch  4, batch    16 | loss: 6.7462583CurrentTrain: epoch  4, batch    17 | loss: 6.7955780CurrentTrain: epoch  4, batch    18 | loss: 6.7017679CurrentTrain: epoch  4, batch    19 | loss: 6.6497822CurrentTrain: epoch  4, batch    20 | loss: 6.7515059CurrentTrain: epoch  4, batch    21 | loss: 5.4568396CurrentTrain: epoch  4, batch    22 | loss: 6.7425737CurrentTrain: epoch  4, batch    23 | loss: 7.4248905CurrentTrain: epoch  4, batch    24 | loss: 6.8030601CurrentTrain: epoch  4, batch    25 | loss: 5.7128201CurrentTrain: epoch  4, batch    26 | loss: 6.0901766CurrentTrain: epoch  4, batch    27 | loss: 6.0195417CurrentTrain: epoch  4, batch    28 | loss: 5.8877831CurrentTrain: epoch  4, batch    29 | loss: 5.9017639CurrentTrain: epoch  4, batch    30 | loss: 5.9644861CurrentTrain: epoch  4, batch    31 | loss: 6.3193359CurrentTrain: epoch  4, batch    32 | loss: 6.4298000CurrentTrain: epoch  4, batch    33 | loss: 6.3905287CurrentTrain: epoch  4, batch    34 | loss: 5.6124401CurrentTrain: epoch  4, batch    35 | loss: 6.1344948CurrentTrain: epoch  4, batch    36 | loss: 6.2416821CurrentTrain: epoch  4, batch    37 | loss: 6.7295990CurrentTrain: epoch  5, batch     0 | loss: 6.0638447CurrentTrain: epoch  5, batch     1 | loss: 6.5099201CurrentTrain: epoch  5, batch     2 | loss: 6.3294730CurrentTrain: epoch  5, batch     3 | loss: 5.9556818CurrentTrain: epoch  5, batch     4 | loss: 5.5878048CurrentTrain: epoch  5, batch     5 | loss: 6.4758449CurrentTrain: epoch  5, batch     6 | loss: 6.0975027CurrentTrain: epoch  5, batch     7 | loss: 6.6805487CurrentTrain: epoch  5, batch     8 | loss: 5.6297979CurrentTrain: epoch  5, batch     9 | loss: 5.8817210CurrentTrain: epoch  5, batch    10 | loss: 5.3463736CurrentTrain: epoch  5, batch    11 | loss: 6.0796318CurrentTrain: epoch  5, batch    12 | loss: 6.1611595CurrentTrain: epoch  5, batch    13 | loss: 5.8811350CurrentTrain: epoch  5, batch    14 | loss: 6.4045796CurrentTrain: epoch  5, batch    15 | loss: 5.6460304CurrentTrain: epoch  5, batch    16 | loss: 5.6028724CurrentTrain: epoch  5, batch    17 | loss: 6.0058813CurrentTrain: epoch  5, batch    18 | loss: 5.4141655CurrentTrain: epoch  5, batch    19 | loss: 6.2086625CurrentTrain: epoch  5, batch    20 | loss: 5.7103853CurrentTrain: epoch  5, batch    21 | loss: 6.1477237CurrentTrain: epoch  5, batch    22 | loss: 5.3158579CurrentTrain: epoch  5, batch    23 | loss: 6.4904366CurrentTrain: epoch  5, batch    24 | loss: 5.8449993CurrentTrain: epoch  5, batch    25 | loss: 5.8837261CurrentTrain: epoch  5, batch    26 | loss: 5.7056332CurrentTrain: epoch  5, batch    27 | loss: 5.8060641CurrentTrain: epoch  5, batch    28 | loss: 5.5694952CurrentTrain: epoch  5, batch    29 | loss: 5.5440083CurrentTrain: epoch  5, batch    30 | loss: 5.0780563CurrentTrain: epoch  5, batch    31 | loss: 6.9819088CurrentTrain: epoch  5, batch    32 | loss: 5.5653896CurrentTrain: epoch  5, batch    33 | loss: 5.9810810CurrentTrain: epoch  5, batch    34 | loss: 5.7205348CurrentTrain: epoch  5, batch    35 | loss: 5.6590934CurrentTrain: epoch  5, batch    36 | loss: 5.4188609CurrentTrain: epoch  5, batch    37 | loss: 5.6370058CurrentTrain: epoch  6, batch     0 | loss: 6.1358523CurrentTrain: epoch  6, batch     1 | loss: 5.4234552CurrentTrain: epoch  6, batch     2 | loss: 5.5030365CurrentTrain: epoch  6, batch     3 | loss: 5.4956236CurrentTrain: epoch  6, batch     4 | loss: 5.3796434CurrentTrain: epoch  6, batch     5 | loss: 5.8246398CurrentTrain: epoch  6, batch     6 | loss: 5.3124366CurrentTrain: epoch  6, batch     7 | loss: 5.3673453CurrentTrain: epoch  6, batch     8 | loss: 5.1170020CurrentTrain: epoch  6, batch     9 | loss: 5.5554328CurrentTrain: epoch  6, batch    10 | loss: 5.4514837CurrentTrain: epoch  6, batch    11 | loss: 5.2072983CurrentTrain: epoch  6, batch    12 | loss: 5.5819921CurrentTrain: epoch  6, batch    13 | loss: 5.5284238CurrentTrain: epoch  6, batch    14 | loss: 5.5129395CurrentTrain: epoch  6, batch    15 | loss: 5.5518851CurrentTrain: epoch  6, batch    16 | loss: 5.8723001CurrentTrain: epoch  6, batch    17 | loss: 5.8069162CurrentTrain: epoch  6, batch    18 | loss: 5.9898615CurrentTrain: epoch  6, batch    19 | loss: 5.3905783CurrentTrain: epoch  6, batch    20 | loss: 5.5957661CurrentTrain: epoch  6, batch    21 | loss: 5.2736311CurrentTrain: epoch  6, batch    22 | loss: 5.6877246CurrentTrain: epoch  6, batch    23 | loss: 5.3700190CurrentTrain: epoch  6, batch    24 | loss: 5.9099770CurrentTrain: epoch  6, batch    25 | loss: 5.9062252CurrentTrain: epoch  6, batch    26 | loss: 5.0880518CurrentTrain: epoch  6, batch    27 | loss: 6.3377171CurrentTrain: epoch  6, batch    28 | loss: 5.6386800CurrentTrain: epoch  6, batch    29 | loss: 5.2615800CurrentTrain: epoch  6, batch    30 | loss: 5.7328978CurrentTrain: epoch  6, batch    31 | loss: 5.7445903CurrentTrain: epoch  6, batch    32 | loss: 5.4329548CurrentTrain: epoch  6, batch    33 | loss: 5.4067039CurrentTrain: epoch  6, batch    34 | loss: 5.7061162CurrentTrain: epoch  6, batch    35 | loss: 5.5632606CurrentTrain: epoch  6, batch    36 | loss: 6.0420170CurrentTrain: epoch  6, batch    37 | loss: 4.8924651CurrentTrain: epoch  7, batch     0 | loss: 5.3223524CurrentTrain: epoch  7, batch     1 | loss: 5.2712803CurrentTrain: epoch  7, batch     2 | loss: 5.1291885CurrentTrain: epoch  7, batch     3 | loss: 5.5866871CurrentTrain: epoch  7, batch     4 | loss: 5.2703133CurrentTrain: epoch  7, batch     5 | loss: 5.2885656CurrentTrain: epoch  7, batch     6 | loss: 5.2503104CurrentTrain: epoch  7, batch     7 | loss: 5.1253343CurrentTrain: epoch  7, batch     8 | loss: 5.4255157CurrentTrain: epoch  7, batch     9 | loss: 5.2402787CurrentTrain: epoch  7, batch    10 | loss: 5.3399220CurrentTrain: epoch  7, batch    11 | loss: 5.2283945CurrentTrain: epoch  7, batch    12 | loss: 5.7639842CurrentTrain: epoch  7, batch    13 | loss: 5.0452366CurrentTrain: epoch  7, batch    14 | loss: 5.3695588CurrentTrain: epoch  7, batch    15 | loss: 5.0102339CurrentTrain: epoch  7, batch    16 | loss: 4.9660373CurrentTrain: epoch  7, batch    17 | loss: 5.1004190CurrentTrain: epoch  7, batch    18 | loss: 5.7913666CurrentTrain: epoch  7, batch    19 | loss: 5.0827866CurrentTrain: epoch  7, batch    20 | loss: 5.2652025CurrentTrain: epoch  7, batch    21 | loss: 5.1868858CurrentTrain: epoch  7, batch    22 | loss: 5.8795671CurrentTrain: epoch  7, batch    23 | loss: 5.2625484CurrentTrain: epoch  7, batch    24 | loss: 5.3696251CurrentTrain: epoch  7, batch    25 | loss: 5.0030622CurrentTrain: epoch  7, batch    26 | loss: 5.2823572CurrentTrain: epoch  7, batch    27 | loss: 5.8802376CurrentTrain: epoch  7, batch    28 | loss: 5.4402351CurrentTrain: epoch  7, batch    29 | loss: 5.2253008CurrentTrain: epoch  7, batch    30 | loss: 4.9519720CurrentTrain: epoch  7, batch    31 | loss: 5.4786401CurrentTrain: epoch  7, batch    32 | loss: 5.0609975CurrentTrain: epoch  7, batch    33 | loss: 5.5265512CurrentTrain: epoch  7, batch    34 | loss: 5.4148798CurrentTrain: epoch  7, batch    35 | loss: 5.3916426CurrentTrain: epoch  7, batch    36 | loss: 5.6798849CurrentTrain: epoch  7, batch    37 | loss: 4.9304237CurrentTrain: epoch  8, batch     0 | loss: 5.2661433CurrentTrain: epoch  8, batch     1 | loss: 5.2813563CurrentTrain: epoch  8, batch     2 | loss: 4.9945636CurrentTrain: epoch  8, batch     3 | loss: 5.0611744CurrentTrain: epoch  8, batch     4 | loss: 5.0330563CurrentTrain: epoch  8, batch     5 | loss: 5.1592002CurrentTrain: epoch  8, batch     6 | loss: 5.0671940CurrentTrain: epoch  8, batch     7 | loss: 5.3456912CurrentTrain: epoch  8, batch     8 | loss: 5.5755839CurrentTrain: epoch  8, batch     9 | loss: 4.9678736CurrentTrain: epoch  8, batch    10 | loss: 5.3238401CurrentTrain: epoch  8, batch    11 | loss: 5.3905330CurrentTrain: epoch  8, batch    12 | loss: 5.1274366CurrentTrain: epoch  8, batch    13 | loss: 5.2200403CurrentTrain: epoch  8, batch    14 | loss: 5.0500274CurrentTrain: epoch  8, batch    15 | loss: 5.3302779CurrentTrain: epoch  8, batch    16 | loss: 5.3767262CurrentTrain: epoch  8, batch    17 | loss: 5.0386205CurrentTrain: epoch  8, batch    18 | loss: 5.1632056CurrentTrain: epoch  8, batch    19 | loss: 4.9310617CurrentTrain: epoch  8, batch    20 | loss: 5.0625210CurrentTrain: epoch  8, batch    21 | loss: 4.9970398CurrentTrain: epoch  8, batch    22 | loss: 5.2432747CurrentTrain: epoch  8, batch    23 | loss: 4.9008179CurrentTrain: epoch  8, batch    24 | loss: 5.0348969CurrentTrain: epoch  8, batch    25 | loss: 5.9137144CurrentTrain: epoch  8, batch    26 | loss: 4.9745903CurrentTrain: epoch  8, batch    27 | loss: 4.9717259CurrentTrain: epoch  8, batch    28 | loss: 4.9230428CurrentTrain: epoch  8, batch    29 | loss: 5.0081944CurrentTrain: epoch  8, batch    30 | loss: 4.8410225CurrentTrain: epoch  8, batch    31 | loss: 5.3595600CurrentTrain: epoch  8, batch    32 | loss: 5.0667229CurrentTrain: epoch  8, batch    33 | loss: 5.3267832CurrentTrain: epoch  8, batch    34 | loss: 5.8288541CurrentTrain: epoch  8, batch    35 | loss: 4.8750610CurrentTrain: epoch  8, batch    36 | loss: 5.0870757CurrentTrain: epoch  8, batch    37 | loss: 4.8982739CurrentTrain: epoch  9, batch     0 | loss: 5.0278521CurrentTrain: epoch  9, batch     1 | loss: 5.0443730CurrentTrain: epoch  9, batch     2 | loss: 5.1203442CurrentTrain: epoch  9, batch     3 | loss: 4.9747372CurrentTrain: epoch  9, batch     4 | loss: 4.9550591CurrentTrain: epoch  9, batch     5 | loss: 4.9425640CurrentTrain: epoch  9, batch     6 | loss: 5.1590147CurrentTrain: epoch  9, batch     7 | loss: 4.9942837CurrentTrain: epoch  9, batch     8 | loss: 5.1984777CurrentTrain: epoch  9, batch     9 | loss: 5.0505915CurrentTrain: epoch  9, batch    10 | loss: 4.9431801CurrentTrain: epoch  9, batch    11 | loss: 4.9884076CurrentTrain: epoch  9, batch    12 | loss: 4.8272181CurrentTrain: epoch  9, batch    13 | loss: 5.0113335CurrentTrain: epoch  9, batch    14 | loss: 4.9350376CurrentTrain: epoch  9, batch    15 | loss: 5.2500772CurrentTrain: epoch  9, batch    16 | loss: 4.8563576CurrentTrain: epoch  9, batch    17 | loss: 4.9644494CurrentTrain: epoch  9, batch    18 | loss: 5.4033704CurrentTrain: epoch  9, batch    19 | loss: 4.7974510CurrentTrain: epoch  9, batch    20 | loss: 5.0202074CurrentTrain: epoch  9, batch    21 | loss: 4.9257131CurrentTrain: epoch  9, batch    22 | loss: 4.9508648CurrentTrain: epoch  9, batch    23 | loss: 4.9035320CurrentTrain: epoch  9, batch    24 | loss: 5.0091434CurrentTrain: epoch  9, batch    25 | loss: 5.0253158CurrentTrain: epoch  9, batch    26 | loss: 4.8755970CurrentTrain: epoch  9, batch    27 | loss: 5.0673437CurrentTrain: epoch  9, batch    28 | loss: 4.8139763CurrentTrain: epoch  9, batch    29 | loss: 4.8387389CurrentTrain: epoch  9, batch    30 | loss: 5.2106128CurrentTrain: epoch  9, batch    31 | loss: 5.0102196CurrentTrain: epoch  9, batch    32 | loss: 5.2474909CurrentTrain: epoch  9, batch    33 | loss: 4.9042397CurrentTrain: epoch  9, batch    34 | loss: 4.7741499CurrentTrain: epoch  9, batch    35 | loss: 4.8608227CurrentTrain: epoch  9, batch    36 | loss: 4.8348632CurrentTrain: epoch  9, batch    37 | loss: 4.8774786
#### person countries of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person countries of residence" means a person is living in a country.
Here is an example:
Relation: person countries of residence
Context: embattled us attorney general alberto gonzales formally announced his resignation on monday , after months at the center of a raging political storm .
Head Entity: alberto gonzales
Tail Entity: us
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person countries of residence":
Relation: person countries of residence  
Context: After years of living in Paris, the renowned artist decided to return to his hometown in Italy.  
Head Entity: the renowned artist  
Tail Entity: Italy  

Relation: person countries of residence  
Context: Following her studies in London, she moved to Canada to start her career in technology.  
Head Entity: she  
Tail Entity: Canada  

Relation: person countries of residence  
Context: The famous actor has been residing in Australia for the past few years while filming his latest movie.  
Head Entity: The famous actor  
Tail Entity: Australia  

Relation: person countries of residence  
Context: After spending a decade in Japan, the scientist relocated to Germany for a new research opportunity.  
Head Entity: the scientist  
Tail Entity: Germany  

Relation: person countries of residence  
Context: He has lived in Brazil for most of his life, enjoying the vibrant culture and beautiful landscapes.  
Head Entity: He  
Tail Entity: Brazil  
#### organization top members employees ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization top members employees" means an organization 's employer is a person.
Here is an example:
Relation: organization top members employees
Context: `` the fdic has good intentions , and they are probably demonstrating things that can be done better , '' said bob davis , an executive vice president with the american bankers association .
Head Entity: american bankers association
Tail Entity: bob davis
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization top members employees":
Relation: organization top members employees  
Context: "During the annual meeting, the CEO of Tech Innovations, Sarah Lee, highlighted the contributions of her team."  
Head Entity: Tech Innovations  
Tail Entity: Sarah Lee  

Relation: organization top members employees  
Context: "In a recent interview, John Smith, the chief financial officer of Global Finance Corp, discussed the company's future."  
Head Entity: Global Finance Corp  
Tail Entity: John Smith  

Relation: organization top members employees  
Context: "The board of directors praised Maria Gonzalez, the head of marketing at Creative Solutions, for her innovative strategies."  
Head Entity: Creative Solutions  
Tail Entity: Maria Gonzalez  

Relation: organization top members employees  
Context: "At the charity gala, the founder of Green Earth Initiative, Tom Richards, spoke about the importance of sustainability."  
Head Entity: Green Earth Initiative  
Tail Entity: Tom Richards  

Relation: organization top members employees  
Context: "The principal of Riverside High School, Emily Johnson, announced new educational programs for the upcoming year."  
Head Entity: Riverside High School  
Tail Entity: Emily Johnson  
#### organization member of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization member of" means an organization is the member of an organization.
Here is an example:
Relation: organization member of
Context: rookie steve slaton rushed for 130 yards and two touchdowns monday as the houston texans trounced the jacksonville jaguars 30-17 in a national football league contest .
Head Entity: jacksonville jaguars
Tail Entity: national football league
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization member of":
Relation: organization member of  
Context: the united nations is an international organization founded in 1945 and currently has 193 member states.  
Head Entity: united nations  
Tail Entity: member states  

Relation: organization member of  
Context: the european union is a political and economic union of 27 member countries located primarily in europe.  
Head Entity: european union  
Tail Entity: member countries  

Relation: organization member of  
Context: the world health organization works with its 194 member states to improve global health standards.  
Head Entity: world health organization  
Tail Entity: member states  

Relation: organization member of  
Context: the national basketball association consists of 30 teams, each representing a different city or region in the united states and canada.  
Head Entity: national basketball association  
Tail Entity: teams  

Relation: organization member of  
Context: the international olympic committee oversees the organization of the olympic games and has 206 national olympic committees as members.  
Head Entity: international olympic committee  
Tail Entity: national olympic committees  
#### person origin ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person origin" means a person 's nationality is a country.
Here is an example:
Relation: person origin
Context: the former detainee , murat kurnaz , was turned over to german authorities and freed in 2006 after a personal plea from german chancellor angela merkel .
Head Entity: murat kurnaz
Tail Entity: german
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person origin":
Relation: person origin  
Context: The renowned physicist Albert Einstein was born in the Kingdom of Württemberg in the German Empire.  
Head Entity: Albert Einstein  
Tail Entity: German  

Relation: person origin  
Context: The famous author Gabriel García Márquez was born in Aracataca, Colombia, where he drew inspiration for many of his works.  
Head Entity: Gabriel García Márquez  
Tail Entity: Colombian  

Relation: person origin  
Context: The celebrated artist Frida Kahlo was born in Coyoacán, Mexico, and is known for her unique style and self-portraits.  
Head Entity: Frida Kahlo  
Tail Entity: Mexican  

Relation: person origin  
Context: The iconic singer Adele was born in Tottenham, London, England, and has won numerous awards for her music.  
Head Entity: Adele  
Tail Entity: British  

Relation: person origin  
Context: The influential civil rights leader Nelson Mandela was born in the village of Mvezo in South Africa.  
Head Entity: Nelson Mandela  
Tail Entity: South African  
#### person title ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person title" means a person 's title is a title.
Here is an example:
Relation: person title
Context: `` making the amendment retroactive will ... help repair the image of the sentencing guidelines in communities of color , '' naacp chairman julian bond wrote to the commission .
Head Entity: julian bond
Tail Entity: chairman
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person title":
Relation: person title  
Context: `` After years of dedicated service, the board appointed Dr. Emily Carter as the new president of the university. ''  
Head Entity: Dr. Emily Carter  
Tail Entity: president  

Relation: person title  
Context: `` In her acceptance speech, the newly elected mayor, Sarah Thompson, promised to focus on community development. ''  
Head Entity: Sarah Thompson  
Tail Entity: mayor  

Relation: person title  
Context: `` The renowned scientist, Dr. Alan Smith, received the prestigious award for his groundbreaking research in genetics. ''  
Head Entity: Dr. Alan Smith  
Tail Entity: scientist  

Relation: person title  
Context: `` As the chief executive officer of the company, Mark Johnson outlined his vision for the future during the annual meeting. ''  
Head Entity: Mark Johnson  
Tail Entity: chief executive officer  

Relation: person title  
Context: `` The famous author, Jane Doe, shared her insights on writing during the literary festival. ''  
Head Entity: Jane Doe  
Tail Entity: author  
#### organization country of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization country of headquarters" means an organization is located in a country.
Here is an example:
Relation: organization country of headquarters
Context: baghdad , oct 3 -lrb- xinhua -rrb- the irgc-qf attempts to destabilize the government of iraq , through iran 's `` militia-proxies '' inside iraq , it added .
Head Entity: irgc-qf
Tail Entity: iran
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization country of headquarters":
Relation: organization country of headquarters  
Context: in a recent report, the world health organization highlighted the need for improved healthcare systems in developing nations.  
Head Entity: world health organization  
Tail Entity: switzerland  

Relation: organization country of headquarters  
Context: the headquarters of the international monetary fund is located in the heart of washington, d.c., which is a hub for global finance.  
Head Entity: international monetary fund  
Tail Entity: united states  

Relation: organization country of headquarters  
Context: the european space agency announced its new satellite launch plans during a conference held in paris, which is known for its rich history in space exploration.  
Head Entity: european space agency  
Tail Entity: france  

Relation: organization country of headquarters  
Context: during the annual meeting, the united nations discussed various global issues, emphasizing its role in promoting peace and security from its base in new york.  
Head Entity: united nations  
Tail Entity: united states  

Relation: organization country of headquarters  
Context: the headquarters of the red cross is situated in geneva, where it coordinates humanitarian efforts worldwide.  
Head Entity: red cross  
Tail Entity: switzerland  
[EVAL] batch:    0 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    1 | acc: 81.25%,  total acc: 84.38%   [EVAL] batch:    2 | acc: 81.25%,  total acc: 83.33%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 84.38%   [EVAL] batch:    4 | acc: 87.50%,  total acc: 85.00%   [EVAL] batch:    5 | acc: 75.00%,  total acc: 83.33%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 85.71%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 87.50%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 88.89%   [EVAL] batch:    9 | acc: 93.75%,  total acc: 89.38%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 90.34%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 90.62%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 90.87%   [EVAL] batch:   13 | acc: 68.75%,  total acc: 89.29%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 88.33%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 86.33%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 85.66%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 84.38%   [EVAL] batch:   18 | acc: 81.25%,  total acc: 84.21%   [EVAL] batch:   19 | acc: 75.00%,  total acc: 83.75%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 84.52%   [EVAL] batch:   21 | acc: 100.00%,  total acc: 85.23%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 85.87%   [EVAL] batch:   23 | acc: 100.00%,  total acc: 86.46%   [EVAL] batch:   24 | acc: 100.00%,  total acc: 87.00%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 87.50%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 87.73%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 88.17%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 88.58%   [EVAL] batch:   29 | acc: 87.50%,  total acc: 88.54%   [EVAL] batch:   30 | acc: 81.25%,  total acc: 88.31%   [EVAL] batch:   31 | acc: 93.75%,  total acc: 88.48%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 86.93%   
[EVAL] batch:    0 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    1 | acc: 81.25%,  total acc: 84.38%   [EVAL] batch:    2 | acc: 81.25%,  total acc: 83.33%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 84.38%   [EVAL] batch:    4 | acc: 87.50%,  total acc: 85.00%   [EVAL] batch:    5 | acc: 75.00%,  total acc: 83.33%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 85.71%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 87.50%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 88.89%   [EVAL] batch:    9 | acc: 93.75%,  total acc: 89.38%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 90.34%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 90.62%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 90.87%   [EVAL] batch:   13 | acc: 68.75%,  total acc: 89.29%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 88.33%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 86.33%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 85.66%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 84.38%   [EVAL] batch:   18 | acc: 81.25%,  total acc: 84.21%   [EVAL] batch:   19 | acc: 75.00%,  total acc: 83.75%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 84.52%   [EVAL] batch:   21 | acc: 100.00%,  total acc: 85.23%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 85.87%   [EVAL] batch:   23 | acc: 100.00%,  total acc: 86.46%   [EVAL] batch:   24 | acc: 100.00%,  total acc: 87.00%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 87.50%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 87.73%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 88.17%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 88.58%   [EVAL] batch:   29 | acc: 87.50%,  total acc: 88.54%   [EVAL] batch:   30 | acc: 81.25%,  total acc: 88.31%   [EVAL] batch:   31 | acc: 93.75%,  total acc: 88.48%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 86.93%   
cur_acc:  ['0.8693']
his_acc:  ['0.8693']
CurrentTrain: epoch  0, batch     0 | loss: 7.2450051CurrentTrain: epoch  0, batch     1 | loss: 5.7905478CurrentTrain: epoch  1, batch     0 | loss: 5.5444226CurrentTrain: epoch  1, batch     1 | loss: 6.5063052CurrentTrain: epoch  2, batch     0 | loss: 5.4093285CurrentTrain: epoch  2, batch     1 | loss: 4.8179345CurrentTrain: epoch  3, batch     0 | loss: 4.9402122CurrentTrain: epoch  3, batch     1 | loss: 4.6359363CurrentTrain: epoch  4, batch     0 | loss: 4.2216988CurrentTrain: epoch  4, batch     1 | loss: 4.9159369CurrentTrain: epoch  5, batch     0 | loss: 3.8588192CurrentTrain: epoch  5, batch     1 | loss: 3.8879464CurrentTrain: epoch  6, batch     0 | loss: 3.8960366CurrentTrain: epoch  6, batch     1 | loss: 3.4131196CurrentTrain: epoch  7, batch     0 | loss: 3.7177508CurrentTrain: epoch  7, batch     1 | loss: 2.9366570CurrentTrain: epoch  8, batch     0 | loss: 3.6196628CurrentTrain: epoch  8, batch     1 | loss: 3.5788906CurrentTrain: epoch  9, batch     0 | loss: 3.2791355CurrentTrain: epoch  9, batch     1 | loss: 2.7208090
#### person cities of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person cities of residence" means a person is living in a city.
Here is an example:
Relation: person cities of residence
Context: tv-idol-johns -- atlanta -- `` american idol '' finalist michael johns moved to los angeles several years ago , but his heart is still in atlanta .
Head Entity: his
Tail Entity: atlanta
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person cities of residence":
Relation: person cities of residence  
Context: after years of living in new york city, the famous author decided to return to her hometown of boston, where she feels most at home.  
Head Entity: she  
Tail Entity: boston  

Relation: person cities of residence  
Context: despite being a global superstar, the singer often reminisces about her childhood in nashville, where she first discovered her love for music.  
Head Entity: she  
Tail Entity: nashville  

Relation: person cities of residence  
Context: the renowned scientist, who spent most of his career in san francisco, now resides in seattle, enjoying the vibrant tech community there.  
Head Entity: he  
Tail Entity: seattle  

Relation: person cities of residence  
Context: after moving from chicago to los angeles, the actor found that the sunny weather and laid-back lifestyle suited him much better.  
Head Entity: he  
Tail Entity: los angeles  

Relation: person cities of residence  
Context: although she was born in miami, the entrepreneur has made her mark in silicon valley, where she currently runs her successful startup.  
Head Entity: she  
Tail Entity: silicon valley  
#### person schools attended ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person schools attended" means a person 's school is an organization.
Here is an example:
Relation: person schools attended
Context: after world war ii , he attended the university of southern california , where he became editor of a college magazine .
Head Entity: he
Tail Entity: university of southern california
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person schools attended":
Relation: person schools attended  
Context: She graduated from Harvard University with a degree in economics before pursuing her career in finance.  
Head Entity: She  
Tail Entity: Harvard University  

Relation: person schools attended  
Context: After completing his high school education, John enrolled at Stanford University to study computer science.  
Head Entity: John  
Tail Entity: Stanford University  

Relation: person schools attended  
Context: Maria attended the University of Oxford for her postgraduate studies in literature, where she developed her passion for writing.  
Head Entity: Maria  
Tail Entity: University of Oxford  

Relation: person schools attended  
Context: Following his time in the military, he went to the Massachusetts Institute of Technology to study engineering.  
Head Entity: he  
Tail Entity: Massachusetts Institute of Technology  

Relation: person schools attended  
Context: During her youth, she spent several years at the University of California, Berkeley, where she majored in environmental science.  
Head Entity: she  
Tail Entity: University of California, Berkeley  
#### person country of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person country of death" means a person was died in a country.
Here is an example:
Relation: person country of death
Context: us republican congresswoman jo ann davis dies after fight with breast cancer
Head Entity: jo ann davis
Tail Entity: us
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person country of death":
1. Relation: person country of death  
   Context: renowned physicist stephen hawking passed away in cambridge, england.  
   Head Entity: stephen hawking  
   Tail Entity: england  

2. Relation: person country of death  
   Context: famous author gabriel garcia marquez died in mexico city, mexico.  
   Head Entity: gabriel garcia marquez  
   Tail Entity: mexico  

3. Relation: person country of death  
   Context: legendary musician freddie mercury succumbed to aids in london, united kingdom.  
   Head Entity: freddie mercury  
   Tail Entity: united kingdom  

4. Relation: person country of death  
   Context: beloved actor robin williams was found dead in his home in california, usa.  
   Head Entity: robin williams  
   Tail Entity: usa  

5. Relation: person country of death  
   Context: influential civil rights leader martin luther king jr. was assassinated in memphis, tennessee, usa.  
   Head Entity: martin luther king jr.  
   Tail Entity: usa  
#### person children ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person children" means a person 's children is a person.
Here is an example:
Relation: person children
Context: he is survived by two stepdaughters , barbara a. hammond and brenda l. stevenson ; a stepson , michael a. taylor ; two grandchildren and one great-grandchild .
Head Entity: he
Tail Entity: brenda l. stevenson
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person children":
Relation: person children  
Context: she has three children, including her son, john, and her daughters, emily and sarah, who are both very talented.  
Head Entity: she  
Tail Entity: emily  

Relation: person children  
Context: after the divorce, he took custody of his two daughters, lily and rose, who are now thriving in school.  
Head Entity: he  
Tail Entity: rose  

Relation: person children  
Context: the famous actor is a proud father of four, with his youngest being a daughter named sophia.  
Head Entity: the famous actor  
Tail Entity: sophia  

Relation: person children  
Context: they often visit their grandparents, who love spending time with their grandchildren, including max and olivia.  
Head Entity: they  
Tail Entity: max  

Relation: person children  
Context: she often shares stories about her two sons, aiden and ben, who are both passionate about sports.  
Head Entity: she  
Tail Entity: ben  
#### person charges ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person charges" means a person was charged with an event.
Here is an example:
Relation: person charges
Context: flowers always contended politics was behind the extortion investigation , but appeals courts ruled against him .
Head Entity: him
Tail Entity: extortion
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person charges":
Relation: person charges  
Context: The prosecutor announced that the suspect was formally charged with theft after the investigation concluded.  
Head Entity: suspect  
Tail Entity: theft  

Relation: person charges  
Context: After a lengthy trial, the jury found the defendant guilty, leading to charges being filed for fraud.  
Head Entity: defendant  
Tail Entity: fraud  

Relation: person charges  
Context: Authorities revealed that the politician faced charges related to bribery following the corruption scandal.  
Head Entity: politician  
Tail Entity: bribery  

Relation: person charges  
Context: The police confirmed that the individual was charged with assault after the altercation at the bar.  
Head Entity: individual  
Tail Entity: assault  

Relation: person charges  
Context: Following the investigation, the journalist was charged with libel for publishing false information.  
Head Entity: journalist  
Tail Entity: libel  
Mixup data size:  3730
MixupTrain:  epoch  0, batch     0 | loss: 4.5487700MixupTrain:  epoch  0, batch     1 | loss: 5.5347161MixupTrain:  epoch  0, batch     2 | loss: 5.5081286MixupTrain:  epoch  0, batch     3 | loss: 4.5098810MixupTrain:  epoch  0, batch     4 | loss: 5.0889149MixupTrain:  epoch  0, batch     5 | loss: 4.2781949MixupTrain:  epoch  0, batch     6 | loss: 3.9965115MixupTrain:  epoch  0, batch     7 | loss: 4.2693048MixupTrain:  epoch  0, batch     8 | loss: 4.3227158MixupTrain:  epoch  0, batch     9 | loss: 4.1294127MixupTrain:  epoch  0, batch    10 | loss: 4.3178058MixupTrain:  epoch  0, batch    11 | loss: 3.7962711MixupTrain:  epoch  0, batch    12 | loss: 3.8998439MixupTrain:  epoch  0, batch    13 | loss: 4.1286864MixupTrain:  epoch  0, batch    14 | loss: 3.5977800MixupTrain:  epoch  0, batch    15 | loss: 3.7079861MixupTrain:  epoch  0, batch    16 | loss: 4.0653653MixupTrain:  epoch  0, batch    17 | loss: 3.8173535MixupTrain:  epoch  0, batch    18 | loss: 3.8637161MixupTrain:  epoch  0, batch    19 | loss: 4.2293887MixupTrain:  epoch  0, batch    20 | loss: 3.1247978MixupTrain:  epoch  0, batch    21 | loss: 3.4300628MixupTrain:  epoch  0, batch    22 | loss: 3.5648639MixupTrain:  epoch  0, batch    23 | loss: 3.2923136MixupTrain:  epoch  0, batch    24 | loss: 3.3953397MixupTrain:  epoch  0, batch    25 | loss: 3.6770682MixupTrain:  epoch  0, batch    26 | loss: 3.1559138MixupTrain:  epoch  0, batch    27 | loss: 3.3293688MixupTrain:  epoch  0, batch    28 | loss: 3.1890156MixupTrain:  epoch  0, batch    29 | loss: 3.1490717MixupTrain:  epoch  0, batch    30 | loss: 3.2836554MixupTrain:  epoch  0, batch    31 | loss: 3.1881461MixupTrain:  epoch  0, batch    32 | loss: 3.1137409MixupTrain:  epoch  0, batch    33 | loss: 2.9572921MixupTrain:  epoch  0, batch    34 | loss: 2.5984137MixupTrain:  epoch  0, batch    35 | loss: 2.7607963MixupTrain:  epoch  0, batch    36 | loss: 3.2132962MixupTrain:  epoch  0, batch    37 | loss: 3.4046123MixupTrain:  epoch  0, batch    38 | loss: 3.0438011MixupTrain:  epoch  0, batch    39 | loss: 3.1728854MixupTrain:  epoch  0, batch    40 | loss: 3.0015869MixupTrain:  epoch  0, batch    41 | loss: 2.9788754MixupTrain:  epoch  0, batch    42 | loss: 2.9272413MixupTrain:  epoch  0, batch    43 | loss: 2.8812900MixupTrain:  epoch  0, batch    44 | loss: 2.6424839MixupTrain:  epoch  0, batch    45 | loss: 3.0297341MixupTrain:  epoch  0, batch    46 | loss: 3.0854797MixupTrain:  epoch  0, batch    47 | loss: 2.9396529MixupTrain:  epoch  0, batch    48 | loss: 2.7479832MixupTrain:  epoch  0, batch    49 | loss: 2.5590100MixupTrain:  epoch  0, batch    50 | loss: 2.8396001MixupTrain:  epoch  0, batch    51 | loss: 2.8206792MixupTrain:  epoch  0, batch    52 | loss: 2.7084064MixupTrain:  epoch  0, batch    53 | loss: 2.8671288MixupTrain:  epoch  0, batch    54 | loss: 3.0289416MixupTrain:  epoch  0, batch    55 | loss: 2.7990103MixupTrain:  epoch  0, batch    56 | loss: 2.6564901MixupTrain:  epoch  0, batch    57 | loss: 2.7380939MixupTrain:  epoch  0, batch    58 | loss: 2.6389825MixupTrain:  epoch  0, batch    59 | loss: 2.8336165MixupTrain:  epoch  0, batch    60 | loss: 2.7083650MixupTrain:  epoch  0, batch    61 | loss: 2.7087641MixupTrain:  epoch  0, batch    62 | loss: 2.4878957MixupTrain:  epoch  0, batch    63 | loss: 2.7498045MixupTrain:  epoch  0, batch    64 | loss: 2.3420377MixupTrain:  epoch  0, batch    65 | loss: 2.4617488MixupTrain:  epoch  0, batch    66 | loss: 2.4746132MixupTrain:  epoch  0, batch    67 | loss: 2.4240570MixupTrain:  epoch  0, batch    68 | loss: 2.3593698MixupTrain:  epoch  0, batch    69 | loss: 2.3788676MixupTrain:  epoch  0, batch    70 | loss: 2.6960604MixupTrain:  epoch  0, batch    71 | loss: 2.7252679MixupTrain:  epoch  0, batch    72 | loss: 2.6013660MixupTrain:  epoch  0, batch    73 | loss: 2.6122000MixupTrain:  epoch  0, batch    74 | loss: 2.4350843MixupTrain:  epoch  0, batch    75 | loss: 2.5098341MixupTrain:  epoch  0, batch    76 | loss: 2.4401920MixupTrain:  epoch  0, batch    77 | loss: 2.5129714MixupTrain:  epoch  0, batch    78 | loss: 2.4704847MixupTrain:  epoch  0, batch    79 | loss: 2.3748381MixupTrain:  epoch  0, batch    80 | loss: 2.3957682MixupTrain:  epoch  0, batch    81 | loss: 2.4390676MixupTrain:  epoch  0, batch    82 | loss: 2.4104114MixupTrain:  epoch  0, batch    83 | loss: 2.6090622MixupTrain:  epoch  0, batch    84 | loss: 2.5348117MixupTrain:  epoch  0, batch    85 | loss: 2.4782994MixupTrain:  epoch  0, batch    86 | loss: 2.3548927MixupTrain:  epoch  0, batch    87 | loss: 2.3359263MixupTrain:  epoch  0, batch    88 | loss: 2.4437363MixupTrain:  epoch  0, batch    89 | loss: 2.3085079MixupTrain:  epoch  0, batch    90 | loss: 2.5039492MixupTrain:  epoch  0, batch    91 | loss: 2.2466409MixupTrain:  epoch  0, batch    92 | loss: 2.3301730MixupTrain:  epoch  0, batch    93 | loss: 2.1113842MixupTrain:  epoch  0, batch    94 | loss: 2.2986796MixupTrain:  epoch  0, batch    95 | loss: 2.1700034MixupTrain:  epoch  0, batch    96 | loss: 2.3725524MixupTrain:  epoch  0, batch    97 | loss: 2.2085567MixupTrain:  epoch  0, batch    98 | loss: 2.2961049MixupTrain:  epoch  0, batch    99 | loss: 2.3380466MixupTrain:  epoch  0, batch   100 | loss: 2.2304893MixupTrain:  epoch  0, batch   101 | loss: 2.1591306MixupTrain:  epoch  0, batch   102 | loss: 2.3278756MixupTrain:  epoch  0, batch   103 | loss: 2.3388371MixupTrain:  epoch  0, batch   104 | loss: 2.3547492MixupTrain:  epoch  0, batch   105 | loss: 2.3057094MixupTrain:  epoch  0, batch   106 | loss: 2.4221542MixupTrain:  epoch  0, batch   107 | loss: 2.2863972MixupTrain:  epoch  0, batch   108 | loss: 2.3832150MixupTrain:  epoch  0, batch   109 | loss: 2.1534929MixupTrain:  epoch  0, batch   110 | loss: 2.4494967MixupTrain:  epoch  0, batch   111 | loss: 2.3136046MixupTrain:  epoch  0, batch   112 | loss: 2.1601582MixupTrain:  epoch  0, batch   113 | loss: 2.2622576MixupTrain:  epoch  0, batch   114 | loss: 2.3600388MixupTrain:  epoch  0, batch   115 | loss: 2.2162676MixupTrain:  epoch  0, batch   116 | loss: 2.2574873MixupTrain:  epoch  0, batch   117 | loss: 2.2644224MixupTrain:  epoch  0, batch   118 | loss: 2.2270777MixupTrain:  epoch  0, batch   119 | loss: 2.0955970MixupTrain:  epoch  0, batch   120 | loss: 2.3114283MixupTrain:  epoch  0, batch   121 | loss: 2.2310462MixupTrain:  epoch  0, batch   122 | loss: 2.1443539MixupTrain:  epoch  0, batch   123 | loss: 2.1830940MixupTrain:  epoch  0, batch   124 | loss: 2.1699274MixupTrain:  epoch  0, batch   125 | loss: 2.0807128MixupTrain:  epoch  0, batch   126 | loss: 2.2254272MixupTrain:  epoch  0, batch   127 | loss: 2.2408218MixupTrain:  epoch  0, batch   128 | loss: 2.1450698MixupTrain:  epoch  0, batch   129 | loss: 2.1764047MixupTrain:  epoch  0, batch   130 | loss: 2.1535640MixupTrain:  epoch  0, batch   131 | loss: 2.2050118MixupTrain:  epoch  0, batch   132 | loss: 2.2308815MixupTrain:  epoch  0, batch   133 | loss: 2.1205521MixupTrain:  epoch  0, batch   134 | loss: 2.0398364MixupTrain:  epoch  0, batch   135 | loss: 2.2629318MixupTrain:  epoch  0, batch   136 | loss: 2.1377926MixupTrain:  epoch  0, batch   137 | loss: 2.0983152MixupTrain:  epoch  0, batch   138 | loss: 2.3354344MixupTrain:  epoch  0, batch   139 | loss: 2.2297406MixupTrain:  epoch  0, batch   140 | loss: 2.1632228MixupTrain:  epoch  0, batch   141 | loss: 2.1589260MixupTrain:  epoch  0, batch   142 | loss: 2.3573420MixupTrain:  epoch  0, batch   143 | loss: 2.2818606MixupTrain:  epoch  0, batch   144 | loss: 2.0871212MixupTrain:  epoch  0, batch   145 | loss: 2.1375704MixupTrain:  epoch  0, batch   146 | loss: 2.1844783MixupTrain:  epoch  0, batch   147 | loss: 2.1796687MixupTrain:  epoch  0, batch   148 | loss: 2.1086214MixupTrain:  epoch  0, batch   149 | loss: 2.1678007MixupTrain:  epoch  0, batch   150 | loss: 2.1253405MixupTrain:  epoch  0, batch   151 | loss: 2.2350895MixupTrain:  epoch  0, batch   152 | loss: 2.1345806MixupTrain:  epoch  0, batch   153 | loss: 2.0990057MixupTrain:  epoch  0, batch   154 | loss: 2.2369199MixupTrain:  epoch  0, batch   155 | loss: 2.0292346MixupTrain:  epoch  0, batch   156 | loss: 2.1342022MixupTrain:  epoch  0, batch   157 | loss: 2.1331017MixupTrain:  epoch  0, batch   158 | loss: 2.0686719MixupTrain:  epoch  0, batch   159 | loss: 2.0716538MixupTrain:  epoch  0, batch   160 | loss: 2.1764407MixupTrain:  epoch  0, batch   161 | loss: 2.0978520MixupTrain:  epoch  0, batch   162 | loss: 2.1167459MixupTrain:  epoch  0, batch   163 | loss: 2.0699806MixupTrain:  epoch  0, batch   164 | loss: 2.0471458MixupTrain:  epoch  0, batch   165 | loss: 2.1092341MixupTrain:  epoch  0, batch   166 | loss: 2.0627115MixupTrain:  epoch  0, batch   167 | loss: 2.1415520MixupTrain:  epoch  0, batch   168 | loss: 2.2207658MixupTrain:  epoch  0, batch   169 | loss: 2.0636086MixupTrain:  epoch  0, batch   170 | loss: 2.1369386MixupTrain:  epoch  0, batch   171 | loss: 2.1730204MixupTrain:  epoch  0, batch   172 | loss: 2.1316578MixupTrain:  epoch  0, batch   173 | loss: 2.0919554MixupTrain:  epoch  0, batch   174 | loss: 2.1262369MixupTrain:  epoch  0, batch   175 | loss: 2.2649584MixupTrain:  epoch  0, batch   176 | loss: 2.3784118MixupTrain:  epoch  0, batch   177 | loss: 2.0961521MixupTrain:  epoch  0, batch   178 | loss: 2.1403809MixupTrain:  epoch  0, batch   179 | loss: 2.1499104MixupTrain:  epoch  0, batch   180 | loss: 2.0751343MixupTrain:  epoch  0, batch   181 | loss: 2.1630349MixupTrain:  epoch  0, batch   182 | loss: 2.1947181MixupTrain:  epoch  0, batch   183 | loss: 2.0237641MixupTrain:  epoch  0, batch   184 | loss: 2.2009373MixupTrain:  epoch  0, batch   185 | loss: 2.0642180MixupTrain:  epoch  0, batch   186 | loss: 2.0848083MixupTrain:  epoch  0, batch   187 | loss: 2.0282376MixupTrain:  epoch  0, batch   188 | loss: 2.0927939MixupTrain:  epoch  0, batch   189 | loss: 2.0655127MixupTrain:  epoch  0, batch   190 | loss: 2.1221662MixupTrain:  epoch  0, batch   191 | loss: 2.1130466MixupTrain:  epoch  0, batch   192 | loss: 2.1246781MixupTrain:  epoch  0, batch   193 | loss: 2.1113977MixupTrain:  epoch  0, batch   194 | loss: 2.0845699MixupTrain:  epoch  0, batch   195 | loss: 2.0564418MixupTrain:  epoch  0, batch   196 | loss: 2.0218344MixupTrain:  epoch  0, batch   197 | loss: 2.0488706MixupTrain:  epoch  0, batch   198 | loss: 2.1548676MixupTrain:  epoch  0, batch   199 | loss: 2.1255703MixupTrain:  epoch  0, batch   200 | loss: 2.0158558MixupTrain:  epoch  0, batch   201 | loss: 1.9611056MixupTrain:  epoch  0, batch   202 | loss: 2.0769176MixupTrain:  epoch  0, batch   203 | loss: 1.9351285MixupTrain:  epoch  0, batch   204 | loss: 2.0936112MixupTrain:  epoch  0, batch   205 | loss: 2.0211678MixupTrain:  epoch  0, batch   206 | loss: 2.1119237MixupTrain:  epoch  0, batch   207 | loss: 2.0262816MixupTrain:  epoch  0, batch   208 | loss: 2.0157259MixupTrain:  epoch  0, batch   209 | loss: 2.0841832MixupTrain:  epoch  0, batch   210 | loss: 2.0667024MixupTrain:  epoch  0, batch   211 | loss: 2.1331937MixupTrain:  epoch  0, batch   212 | loss: 2.0592179MixupTrain:  epoch  0, batch   213 | loss: 2.0767088MixupTrain:  epoch  0, batch   214 | loss: 2.0587149MixupTrain:  epoch  0, batch   215 | loss: 2.0237823MixupTrain:  epoch  0, batch   216 | loss: 2.0795152MixupTrain:  epoch  0, batch   217 | loss: 2.1378622MixupTrain:  epoch  0, batch   218 | loss: 2.0548191MixupTrain:  epoch  0, batch   219 | loss: 2.0097046MixupTrain:  epoch  0, batch   220 | loss: 2.0282779MixupTrain:  epoch  0, batch   221 | loss: 2.0803478MixupTrain:  epoch  0, batch   222 | loss: 2.0550928MixupTrain:  epoch  0, batch   223 | loss: 2.0532639MixupTrain:  epoch  0, batch   224 | loss: 2.0513301MixupTrain:  epoch  0, batch   225 | loss: 1.9501228MixupTrain:  epoch  0, batch   226 | loss: 2.1511211MixupTrain:  epoch  0, batch   227 | loss: 2.0512204MixupTrain:  epoch  0, batch   228 | loss: 2.0728810MixupTrain:  epoch  0, batch   229 | loss: 1.9279181MixupTrain:  epoch  0, batch   230 | loss: 2.1166878MixupTrain:  epoch  0, batch   231 | loss: 2.0538516MixupTrain:  epoch  0, batch   232 | loss: 1.9964321MixupTrain:  epoch  0, batch   233 | loss: 1.8400590
MemoryTrain:  epoch  0, batch     0 | loss: 1.9928936MemoryTrain:  epoch  0, batch     1 | loss: 2.7910447MemoryTrain:  epoch  0, batch     2 | loss: 3.0540028MemoryTrain:  epoch  0, batch     3 | loss: 2.8040483MemoryTrain:  epoch  0, batch     4 | loss: 2.5153859MemoryTrain:  epoch  1, batch     0 | loss: 1.8549324MemoryTrain:  epoch  1, batch     1 | loss: 1.8648046MemoryTrain:  epoch  1, batch     2 | loss: 1.8856862MemoryTrain:  epoch  1, batch     3 | loss: 1.8644060MemoryTrain:  epoch  1, batch     4 | loss: 1.8555765MemoryTrain:  epoch  2, batch     0 | loss: 1.8823452MemoryTrain:  epoch  2, batch     1 | loss: 1.8718657MemoryTrain:  epoch  2, batch     2 | loss: 1.8619535MemoryTrain:  epoch  2, batch     3 | loss: 1.8609941MemoryTrain:  epoch  2, batch     4 | loss: 1.8610374MemoryTrain:  epoch  3, batch     0 | loss: 1.8592322MemoryTrain:  epoch  3, batch     1 | loss: 1.8578892MemoryTrain:  epoch  3, batch     2 | loss: 1.8454200MemoryTrain:  epoch  3, batch     3 | loss: 1.8501494MemoryTrain:  epoch  3, batch     4 | loss: 1.8481765MemoryTrain:  epoch  4, batch     0 | loss: 1.8651042MemoryTrain:  epoch  4, batch     1 | loss: 1.8500786MemoryTrain:  epoch  4, batch     2 | loss: 1.8462362MemoryTrain:  epoch  4, batch     3 | loss: 1.8438581MemoryTrain:  epoch  4, batch     4 | loss: 1.8715987MemoryTrain:  epoch  5, batch     0 | loss: 1.8414110MemoryTrain:  epoch  5, batch     1 | loss: 1.8633426MemoryTrain:  epoch  5, batch     2 | loss: 1.8508289MemoryTrain:  epoch  5, batch     3 | loss: 1.8706501MemoryTrain:  epoch  5, batch     4 | loss: 1.8688281MemoryTrain:  epoch  6, batch     0 | loss: 1.8479919MemoryTrain:  epoch  6, batch     1 | loss: 1.8683867MemoryTrain:  epoch  6, batch     2 | loss: 1.8623418MemoryTrain:  epoch  6, batch     3 | loss: 1.8699398MemoryTrain:  epoch  6, batch     4 | loss: 1.8371141MemoryTrain:  epoch  7, batch     0 | loss: 1.8687165MemoryTrain:  epoch  7, batch     1 | loss: 1.8477113MemoryTrain:  epoch  7, batch     2 | loss: 1.8534781MemoryTrain:  epoch  7, batch     3 | loss: 1.8445740MemoryTrain:  epoch  7, batch     4 | loss: 1.8284973MemoryTrain:  epoch  8, batch     0 | loss: 1.8561301MemoryTrain:  epoch  8, batch     1 | loss: 1.8636947MemoryTrain:  epoch  8, batch     2 | loss: 1.8779043MemoryTrain:  epoch  8, batch     3 | loss: 1.8470935MemoryTrain:  epoch  8, batch     4 | loss: 1.8380370MemoryTrain:  epoch  9, batch     0 | loss: 1.8482749MemoryTrain:  epoch  9, batch     1 | loss: 1.8349562MemoryTrain:  epoch  9, batch     2 | loss: 1.8532951MemoryTrain:  epoch  9, batch     3 | loss: 1.8659863MemoryTrain:  epoch  9, batch     4 | loss: 1.9196074
[EVAL] batch:    0 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 96.88%   [EVAL] batch:    2 | acc: 87.50%,  total acc: 93.75%   [EVAL] batch:    3 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    4 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    5 | acc: 81.25%,  total acc: 91.67%   [EVAL] batch:    6 | acc: 87.50%,  total acc: 91.07%   [EVAL] batch:    7 | acc: 87.50%,  total acc: 90.62%   [EVAL] batch:    8 | acc: 93.75%,  total acc: 90.97%   [EVAL] batch:    9 | acc: 100.00%,  total acc: 91.88%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 92.61%   [EVAL] batch:   11 | acc: 100.00%,  total acc: 93.23%   [EVAL] batch:   12 | acc: 100.00%,  total acc: 93.75%   [EVAL] batch:   13 | acc: 100.00%,  total acc: 94.20%   [EVAL] batch:   14 | acc: 100.00%,  total acc: 94.58%   [EVAL] batch:   15 | acc: 100.00%,  total acc: 94.92%   [EVAL] batch:   16 | acc: 100.00%,  total acc: 95.22%   [EVAL] batch:   17 | acc: 25.00%,  total acc: 91.32%   
[EVAL] batch:    0 | acc: 43.75%,  total acc: 43.75%   [EVAL] batch:    1 | acc: 56.25%,  total acc: 50.00%   [EVAL] batch:    2 | acc: 56.25%,  total acc: 52.08%   [EVAL] batch:    3 | acc: 25.00%,  total acc: 45.31%   [EVAL] batch:    4 | acc: 56.25%,  total acc: 47.50%   [EVAL] batch:    5 | acc: 56.25%,  total acc: 48.96%   [EVAL] batch:    6 | acc: 87.50%,  total acc: 54.46%   [EVAL] batch:    7 | acc: 87.50%,  total acc: 58.59%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 63.19%   [EVAL] batch:    9 | acc: 87.50%,  total acc: 65.62%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 68.75%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 70.31%   [EVAL] batch:   12 | acc: 87.50%,  total acc: 71.63%   [EVAL] batch:   13 | acc: 68.75%,  total acc: 71.43%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 71.67%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 70.70%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 70.96%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 70.49%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 70.07%   [EVAL] batch:   19 | acc: 87.50%,  total acc: 70.94%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 72.32%   [EVAL] batch:   21 | acc: 100.00%,  total acc: 73.58%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 74.73%   [EVAL] batch:   23 | acc: 100.00%,  total acc: 75.78%   [EVAL] batch:   24 | acc: 100.00%,  total acc: 76.75%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 77.64%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 78.24%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 79.02%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 79.74%   [EVAL] batch:   29 | acc: 87.50%,  total acc: 80.00%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 80.65%   [EVAL] batch:   31 | acc: 93.75%,  total acc: 81.05%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 81.63%   [EVAL] batch:   33 | acc: 93.75%,  total acc: 81.99%   [EVAL] batch:   34 | acc: 87.50%,  total acc: 82.14%   [EVAL] batch:   35 | acc: 93.75%,  total acc: 82.47%   [EVAL] batch:   36 | acc: 93.75%,  total acc: 82.77%   [EVAL] batch:   37 | acc: 81.25%,  total acc: 82.73%   [EVAL] batch:   38 | acc: 87.50%,  total acc: 82.85%   [EVAL] batch:   39 | acc: 100.00%,  total acc: 83.28%   [EVAL] batch:   40 | acc: 81.25%,  total acc: 83.23%   [EVAL] batch:   41 | acc: 100.00%,  total acc: 83.63%   [EVAL] batch:   42 | acc: 100.00%,  total acc: 84.01%   [EVAL] batch:   43 | acc: 100.00%,  total acc: 84.38%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 84.72%   [EVAL] batch:   45 | acc: 100.00%,  total acc: 85.05%   [EVAL] batch:   46 | acc: 100.00%,  total acc: 85.37%   [EVAL] batch:   47 | acc: 100.00%,  total acc: 85.68%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 85.97%   [EVAL] batch:   49 | acc: 62.50%,  total acc: 85.50%   
cur_acc:  ['0.8693', '0.9132']
his_acc:  ['0.8693', '0.8550']
CurrentTrain: epoch  0, batch     0 | loss: 6.4429607CurrentTrain: epoch  0, batch     1 | loss: 8.0530176CurrentTrain: epoch  1, batch     0 | loss: 7.3697939CurrentTrain: epoch  1, batch     1 | loss: 5.1421647CurrentTrain: epoch  2, batch     0 | loss: 4.9137864CurrentTrain: epoch  2, batch     1 | loss: 5.4608445CurrentTrain: epoch  3, batch     0 | loss: 4.4410639CurrentTrain: epoch  3, batch     1 | loss: 5.8428102CurrentTrain: epoch  4, batch     0 | loss: 5.5853357CurrentTrain: epoch  4, batch     1 | loss: 3.1704409CurrentTrain: epoch  5, batch     0 | loss: 4.2801142CurrentTrain: epoch  5, batch     1 | loss: 4.3124385CurrentTrain: epoch  6, batch     0 | loss: 4.3176570CurrentTrain: epoch  6, batch     1 | loss: 3.2788565CurrentTrain: epoch  7, batch     0 | loss: 3.7265759CurrentTrain: epoch  7, batch     1 | loss: 2.9925306CurrentTrain: epoch  8, batch     0 | loss: 3.0908351CurrentTrain: epoch  8, batch     1 | loss: 3.6733077CurrentTrain: epoch  9, batch     0 | loss: 3.3068326CurrentTrain: epoch  9, batch     1 | loss: 2.9721808
#### person date of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person date of birth" means a person was born in a date.
Here is an example:
Relation: person date of birth
Context: kirkaldy , born irene morgan in baltimore , maryland , in 1917 , was arrested in 1944 for refusing to give up her seat on a greyhound bus heading from gloucester to baltimore , and for resisting arrest .
Head Entity: irene morgan
Tail Entity: 1917
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person date of birth":
Relation: person date of birth  
Context: born in 1985 in a small town in Texas, Sarah Johnson grew up with dreams of becoming a scientist.  
Head Entity: Sarah Johnson  
Tail Entity: 1985  

Relation: person date of birth  
Context: The famous actor, who was born in 1975, has starred in numerous blockbuster films throughout his career.  
Head Entity: The famous actor  
Tail Entity: 1975  

Relation: person date of birth  
Context: Albert Einstein, known for his contributions to physics, was born in Ulm, Germany, on March 14, 1879.  
Head Entity: Albert Einstein  
Tail Entity: March 14, 1879  

Relation: person date of birth  
Context: In 1990, a remarkable child prodigy was born in London, who would later revolutionize the tech industry.  
Head Entity: a remarkable child prodigy  
Tail Entity: 1990  

Relation: person date of birth  
Context: The renowned author, who penned several bestsellers, was born in 1965 in a small village in England.  
Head Entity: The renowned author  
Tail Entity: 1965  
#### person stateorprovince of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of birth" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of birth
Context: joseph simpson farland was born on aug 11 , 1914 , in clarksburg , wva , the only child of richard and grace simpson farland .
Head Entity: joseph simpson farland
Tail Entity: wva
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of birth":
Relation: person stateorprovince of birth  
Context: martha stewart was born on august 3, 1941, in jersey city, new jersey, to a middle-class family.  
Head Entity: martha stewart  
Tail Entity: new jersey  

Relation: person stateorprovince of birth  
Context: barack obama was born on august 4, 1961, in honolulu, hawaii, where he spent most of his childhood.  
Head Entity: barack obama  
Tail Entity: hawaii  

Relation: person stateorprovince of birth  
Context: taylor swift was born on december 13, 1989, in reading, pennsylvania, and later moved to nashville to pursue her music career.  
Head Entity: taylor swift  
Tail Entity: pennsylvania  

Relation: person stateorprovince of birth  
Context: elon musk was born on june 28, 1971, in pretoria, south africa, before moving to the united states for his studies.  
Head Entity: elon musk  
Tail Entity: south africa  

Relation: person stateorprovince of birth  
Context: oprah winfrey was born on january 29, 1954, in kosciusko, mississippi, and raised in poverty by her grandmother.  
Head Entity: oprah winfrey  
Tail Entity: mississippi  
#### person parents ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person parents" means a person 's parent is a person.
Here is an example:
Relation: person parents
Context: as the case developed , sandy 's mother , denise sandy , quietly made herself a spectral but central figure , by faithfully attending pretrial hearings .
Head Entity: sandy
Tail Entity: denise sandy
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person parents":
Relation: person parents  
Context: After the ceremony, Emily's father, John Smith, gave a heartfelt speech about family values and the importance of love.  
Head Entity: Emily  
Tail Entity: John Smith  

Relation: person parents  
Context: During the family reunion, Michael introduced his mother, Sarah Johnson, to his friends, highlighting her amazing cooking skills.  
Head Entity: Michael  
Tail Entity: Sarah Johnson  

Relation: person parents  
Context: In her memoir, Lisa described the influence of her father, Robert Brown, on her career choices and personal growth.  
Head Entity: Lisa  
Tail Entity: Robert Brown  

Relation: person parents  
Context: At the graduation ceremony, Tom proudly acknowledged his mother, Patricia White, for her unwavering support throughout his education.  
Head Entity: Tom  
Tail Entity: Patricia White  

Relation: person parents  
Context: As they reminisced about their childhood, Anna spoke fondly of her father, David Green, who always encouraged her artistic pursuits.  
Head Entity: Anna  
Tail Entity: David Green  
#### person employee of ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person employee of" means a person is an employee of an organization.
Here is an example:
Relation: person employee of
Context: seeking revenge , axel reunites with old pal sgt. billy rosewood -lrb- judge reinhold -rrb- and jon flint -lrb- hector elizondo -rrb- of the beverly hills police department .
Head Entity: hector elizondo
Tail Entity: beverly hills police department
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person employee of":
Relation: person employee of  
Context: After years of hard work, Sarah finally landed a job at the prestigious tech company, Innovatech Solutions, where she hopes to make a significant impact.  
Head Entity: Sarah  
Tail Entity: Innovatech Solutions  

Relation: person employee of  
Context: John has been with the marketing team at Global Media Corp for over a decade, contributing to numerous successful campaigns.  
Head Entity: John  
Tail Entity: Global Media Corp  

Relation: person employee of  
Context: Following his graduation, Mark accepted a position at Green Earth Landscaping, where he can pursue his passion for environmental sustainability.  
Head Entity: Mark  
Tail Entity: Green Earth Landscaping  

Relation: person employee of  
Context: Maria was thrilled to receive an offer from Apex Financial Services, a company known for its innovative approach to investment management.  
Head Entity: Maria  
Tail Entity: Apex Financial Services  

Relation: person employee of  
Context: After completing her internship, Emily was offered a full-time role at Bright Future Education, where she will help develop new learning programs.  
Head Entity: Emily  
Tail Entity: Bright Future Education  
#### person stateorprovince of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovince of death" means a person was died in a state or province.
Here is an example:
Relation: person stateorprovince of death
Context: irene morgan kirkaldy , 90 , who died of alzheimer 's disease aug. 10 at her home in gloucester , va. , quietly changed history in 1944 when she refused to give up her seat on a crowded greyhound bus to a white couple .
Head Entity: irene morgan kirkaldy
Tail Entity: va.
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovince of death":
Relation: person stateorprovince of death  
Context: john smith, 75, passed away peacefully on march 5 in his residence located in phoenix, arizona, surrounded by family and friends who cherished his memory.  
Head Entity: john smith  
Tail Entity: arizona  

Relation: person stateorprovince of death  
Context: the renowned author, emily bronte, died at the young age of 30 in haworth, west yorkshire, where she spent most of her life writing her famous novels.  
Head Entity: emily bronte  
Tail Entity: west yorkshire  

Relation: person stateorprovince of death  
Context: after a long battle with cancer, robert jones, 68, succumbed to his illness on january 15 in a hospital in miami, florida, leaving behind a legacy of kindness and generosity.  
Head Entity: robert jones  
Tail Entity: florida  

Relation: person stateorprovince of death  
Context: the beloved musician, prince, tragically passed away on april 21 at his estate in chanhassen, minnesota, shocking fans around the world with his sudden departure.  
Head Entity: prince  
Tail Entity: minnesota  

Relation: person stateorprovince of death  
Context: martha stewart's long-time friend, who was also a famous chef, died on february 14 in a quaint cottage in bridgehampton, new york, where they often spent summers together.  
Head Entity: martha stewart's long-time friend  
Tail Entity: new york  
Mixup data size:  6820
MixupTrain:  epoch  0, batch     0 | loss: 5.4223118MixupTrain:  epoch  0, batch     1 | loss: 5.1310654MixupTrain:  epoch  0, batch     2 | loss: 4.8277302MixupTrain:  epoch  0, batch     3 | loss: 5.1628456MixupTrain:  epoch  0, batch     4 | loss: 4.9391136MixupTrain:  epoch  0, batch     5 | loss: 4.8965659MixupTrain:  epoch  0, batch     6 | loss: 5.0389519MixupTrain:  epoch  0, batch     7 | loss: 4.9135275MixupTrain:  epoch  0, batch     8 | loss: 5.0664997MixupTrain:  epoch  0, batch     9 | loss: 4.2131281MixupTrain:  epoch  0, batch    10 | loss: 4.4961014MixupTrain:  epoch  0, batch    11 | loss: 4.0298381MixupTrain:  epoch  0, batch    12 | loss: 4.2031951MixupTrain:  epoch  0, batch    13 | loss: 4.5230865MixupTrain:  epoch  0, batch    14 | loss: 5.1403666MixupTrain:  epoch  0, batch    15 | loss: 4.7292075MixupTrain:  epoch  0, batch    16 | loss: 4.6731172MixupTrain:  epoch  0, batch    17 | loss: 4.1282673MixupTrain:  epoch  0, batch    18 | loss: 3.3134565MixupTrain:  epoch  0, batch    19 | loss: 3.3864613MixupTrain:  epoch  0, batch    20 | loss: 4.8196869MixupTrain:  epoch  0, batch    21 | loss: 4.5885534MixupTrain:  epoch  0, batch    22 | loss: 4.0394502MixupTrain:  epoch  0, batch    23 | loss: 3.8568597MixupTrain:  epoch  0, batch    24 | loss: 4.0437198MixupTrain:  epoch  0, batch    25 | loss: 4.3854218MixupTrain:  epoch  0, batch    26 | loss: 4.5788994MixupTrain:  epoch  0, batch    27 | loss: 4.5416498MixupTrain:  epoch  0, batch    28 | loss: 3.3847451MixupTrain:  epoch  0, batch    29 | loss: 4.3437967MixupTrain:  epoch  0, batch    30 | loss: 4.2611246MixupTrain:  epoch  0, batch    31 | loss: 3.5731535MixupTrain:  epoch  0, batch    32 | loss: 3.8304248MixupTrain:  epoch  0, batch    33 | loss: 3.9073815MixupTrain:  epoch  0, batch    34 | loss: 2.8159528MixupTrain:  epoch  0, batch    35 | loss: 4.1478519MixupTrain:  epoch  0, batch    36 | loss: 4.0717473MixupTrain:  epoch  0, batch    37 | loss: 3.2322507MixupTrain:  epoch  0, batch    38 | loss: 3.8628263MixupTrain:  epoch  0, batch    39 | loss: 3.6916146MixupTrain:  epoch  0, batch    40 | loss: 3.9462399MixupTrain:  epoch  0, batch    41 | loss: 3.2106194MixupTrain:  epoch  0, batch    42 | loss: 3.1584892MixupTrain:  epoch  0, batch    43 | loss: 3.6628366MixupTrain:  epoch  0, batch    44 | loss: 3.0683498MixupTrain:  epoch  0, batch    45 | loss: 4.0612926MixupTrain:  epoch  0, batch    46 | loss: 4.0828829MixupTrain:  epoch  0, batch    47 | loss: 3.7296185MixupTrain:  epoch  0, batch    48 | loss: 3.5055809MixupTrain:  epoch  0, batch    49 | loss: 3.7471046MixupTrain:  epoch  0, batch    50 | loss: 3.3094664MixupTrain:  epoch  0, batch    51 | loss: 3.5038710MixupTrain:  epoch  0, batch    52 | loss: 2.9923592MixupTrain:  epoch  0, batch    53 | loss: 3.2205858MixupTrain:  epoch  0, batch    54 | loss: 3.5566621MixupTrain:  epoch  0, batch    55 | loss: 3.6134667MixupTrain:  epoch  0, batch    56 | loss: 3.3588953MixupTrain:  epoch  0, batch    57 | loss: 3.1216259MixupTrain:  epoch  0, batch    58 | loss: 3.2922277MixupTrain:  epoch  0, batch    59 | loss: 3.3519969MixupTrain:  epoch  0, batch    60 | loss: 2.8001745MixupTrain:  epoch  0, batch    61 | loss: 3.3514998MixupTrain:  epoch  0, batch    62 | loss: 3.1228266MixupTrain:  epoch  0, batch    63 | loss: 3.1193509MixupTrain:  epoch  0, batch    64 | loss: 3.2525451MixupTrain:  epoch  0, batch    65 | loss: 3.4374304MixupTrain:  epoch  0, batch    66 | loss: 3.1295335MixupTrain:  epoch  0, batch    67 | loss: 2.8510749MixupTrain:  epoch  0, batch    68 | loss: 3.1494892MixupTrain:  epoch  0, batch    69 | loss: 2.6974242MixupTrain:  epoch  0, batch    70 | loss: 3.1737652MixupTrain:  epoch  0, batch    71 | loss: 3.2619834MixupTrain:  epoch  0, batch    72 | loss: 3.4479053MixupTrain:  epoch  0, batch    73 | loss: 2.8960202MixupTrain:  epoch  0, batch    74 | loss: 3.4343610MixupTrain:  epoch  0, batch    75 | loss: 2.7354856MixupTrain:  epoch  0, batch    76 | loss: 3.0565352MixupTrain:  epoch  0, batch    77 | loss: 3.1656492MixupTrain:  epoch  0, batch    78 | loss: 2.7831738MixupTrain:  epoch  0, batch    79 | loss: 2.8307748MixupTrain:  epoch  0, batch    80 | loss: 3.2008545MixupTrain:  epoch  0, batch    81 | loss: 2.6922517MixupTrain:  epoch  0, batch    82 | loss: 2.8051701MixupTrain:  epoch  0, batch    83 | loss: 2.5554502MixupTrain:  epoch  0, batch    84 | loss: 2.9480524MixupTrain:  epoch  0, batch    85 | loss: 3.0309482MixupTrain:  epoch  0, batch    86 | loss: 2.7628043MixupTrain:  epoch  0, batch    87 | loss: 3.0187011MixupTrain:  epoch  0, batch    88 | loss: 2.9349999MixupTrain:  epoch  0, batch    89 | loss: 2.5538867MixupTrain:  epoch  0, batch    90 | loss: 3.1688175MixupTrain:  epoch  0, batch    91 | loss: 2.5571094MixupTrain:  epoch  0, batch    92 | loss: 2.7650762MixupTrain:  epoch  0, batch    93 | loss: 2.8701601MixupTrain:  epoch  0, batch    94 | loss: 2.9737020MixupTrain:  epoch  0, batch    95 | loss: 3.2587409MixupTrain:  epoch  0, batch    96 | loss: 2.6854303MixupTrain:  epoch  0, batch    97 | loss: 3.1303582MixupTrain:  epoch  0, batch    98 | loss: 2.7512562MixupTrain:  epoch  0, batch    99 | loss: 2.5218515MixupTrain:  epoch  0, batch   100 | loss: 2.8323307MixupTrain:  epoch  0, batch   101 | loss: 2.8589673MixupTrain:  epoch  0, batch   102 | loss: 2.5337503MixupTrain:  epoch  0, batch   103 | loss: 3.0918956MixupTrain:  epoch  0, batch   104 | loss: 2.8092165MixupTrain:  epoch  0, batch   105 | loss: 2.9137282MixupTrain:  epoch  0, batch   106 | loss: 2.9181807MixupTrain:  epoch  0, batch   107 | loss: 2.9684761MixupTrain:  epoch  0, batch   108 | loss: 2.9447541MixupTrain:  epoch  0, batch   109 | loss: 2.7913375MixupTrain:  epoch  0, batch   110 | loss: 2.9172826MixupTrain:  epoch  0, batch   111 | loss: 2.8266807MixupTrain:  epoch  0, batch   112 | loss: 2.7190421MixupTrain:  epoch  0, batch   113 | loss: 2.7897801MixupTrain:  epoch  0, batch   114 | loss: 2.8773696MixupTrain:  epoch  0, batch   115 | loss: 2.8582845MixupTrain:  epoch  0, batch   116 | loss: 2.4123182MixupTrain:  epoch  0, batch   117 | loss: 2.7046499MixupTrain:  epoch  0, batch   118 | loss: 3.1244514MixupTrain:  epoch  0, batch   119 | loss: 2.9492903MixupTrain:  epoch  0, batch   120 | loss: 2.8307743MixupTrain:  epoch  0, batch   121 | loss: 2.6849852MixupTrain:  epoch  0, batch   122 | loss: 2.8881013MixupTrain:  epoch  0, batch   123 | loss: 2.6961691MixupTrain:  epoch  0, batch   124 | loss: 2.4578185MixupTrain:  epoch  0, batch   125 | loss: 2.6068270MixupTrain:  epoch  0, batch   126 | loss: 2.3495648MixupTrain:  epoch  0, batch   127 | loss: 2.9340434MixupTrain:  epoch  0, batch   128 | loss: 2.6225803MixupTrain:  epoch  0, batch   129 | loss: 2.4123278MixupTrain:  epoch  0, batch   130 | loss: 2.5492544MixupTrain:  epoch  0, batch   131 | loss: 2.8684287MixupTrain:  epoch  0, batch   132 | loss: 2.5530438MixupTrain:  epoch  0, batch   133 | loss: 2.7343249MixupTrain:  epoch  0, batch   134 | loss: 2.6676223MixupTrain:  epoch  0, batch   135 | loss: 2.7178378MixupTrain:  epoch  0, batch   136 | loss: 2.7574196MixupTrain:  epoch  0, batch   137 | loss: 2.7187994MixupTrain:  epoch  0, batch   138 | loss: 2.6137757MixupTrain:  epoch  0, batch   139 | loss: 2.9015219MixupTrain:  epoch  0, batch   140 | loss: 2.9848664MixupTrain:  epoch  0, batch   141 | loss: 2.7925029MixupTrain:  epoch  0, batch   142 | loss: 2.4557991MixupTrain:  epoch  0, batch   143 | loss: 2.9869223MixupTrain:  epoch  0, batch   144 | loss: 2.3711488MixupTrain:  epoch  0, batch   145 | loss: 2.4339612MixupTrain:  epoch  0, batch   146 | loss: 3.0629196MixupTrain:  epoch  0, batch   147 | loss: 2.6774437MixupTrain:  epoch  0, batch   148 | loss: 2.8289986MixupTrain:  epoch  0, batch   149 | loss: 2.7344229MixupTrain:  epoch  0, batch   150 | loss: 2.7586598MixupTrain:  epoch  0, batch   151 | loss: 2.7137713MixupTrain:  epoch  0, batch   152 | loss: 2.4737673MixupTrain:  epoch  0, batch   153 | loss: 2.7364438MixupTrain:  epoch  0, batch   154 | loss: 2.7333922MixupTrain:  epoch  0, batch   155 | loss: 2.4191904MixupTrain:  epoch  0, batch   156 | loss: 2.9500537MixupTrain:  epoch  0, batch   157 | loss: 2.5647230MixupTrain:  epoch  0, batch   158 | loss: 2.4146771MixupTrain:  epoch  0, batch   159 | loss: 3.3126757MixupTrain:  epoch  0, batch   160 | loss: 2.8334177MixupTrain:  epoch  0, batch   161 | loss: 2.6924777MixupTrain:  epoch  0, batch   162 | loss: 2.3766546MixupTrain:  epoch  0, batch   163 | loss: 2.4454453MixupTrain:  epoch  0, batch   164 | loss: 2.7000647MixupTrain:  epoch  0, batch   165 | loss: 2.5064654MixupTrain:  epoch  0, batch   166 | loss: 2.7992086MixupTrain:  epoch  0, batch   167 | loss: 2.8331642MixupTrain:  epoch  0, batch   168 | loss: 2.3748598MixupTrain:  epoch  0, batch   169 | loss: 2.5702162MixupTrain:  epoch  0, batch   170 | loss: 2.4330702MixupTrain:  epoch  0, batch   171 | loss: 2.7850177MixupTrain:  epoch  0, batch   172 | loss: 2.5673122MixupTrain:  epoch  0, batch   173 | loss: 2.3850770MixupTrain:  epoch  0, batch   174 | loss: 2.7206554MixupTrain:  epoch  0, batch   175 | loss: 2.5210133MixupTrain:  epoch  0, batch   176 | loss: 2.6372466MixupTrain:  epoch  0, batch   177 | loss: 2.7794662MixupTrain:  epoch  0, batch   178 | loss: 2.4156513MixupTrain:  epoch  0, batch   179 | loss: 2.5396042MixupTrain:  epoch  0, batch   180 | loss: 2.6289775MixupTrain:  epoch  0, batch   181 | loss: 2.6668742MixupTrain:  epoch  0, batch   182 | loss: 2.7303026MixupTrain:  epoch  0, batch   183 | loss: 2.6886597MixupTrain:  epoch  0, batch   184 | loss: 2.5584443MixupTrain:  epoch  0, batch   185 | loss: 2.3622262MixupTrain:  epoch  0, batch   186 | loss: 2.7099824MixupTrain:  epoch  0, batch   187 | loss: 2.5265729MixupTrain:  epoch  0, batch   188 | loss: 2.3414111MixupTrain:  epoch  0, batch   189 | loss: 2.3146167MixupTrain:  epoch  0, batch   190 | loss: 2.6400180MixupTrain:  epoch  0, batch   191 | loss: 2.7066679MixupTrain:  epoch  0, batch   192 | loss: 2.2989156MixupTrain:  epoch  0, batch   193 | loss: 2.6982622MixupTrain:  epoch  0, batch   194 | loss: 2.3400166MixupTrain:  epoch  0, batch   195 | loss: 2.3436756MixupTrain:  epoch  0, batch   196 | loss: 2.5821209MixupTrain:  epoch  0, batch   197 | loss: 2.5809698MixupTrain:  epoch  0, batch   198 | loss: 2.6325071MixupTrain:  epoch  0, batch   199 | loss: 2.3375649MixupTrain:  epoch  0, batch   200 | loss: 2.4216616MixupTrain:  epoch  0, batch   201 | loss: 2.7002640MixupTrain:  epoch  0, batch   202 | loss: 2.5960510MixupTrain:  epoch  0, batch   203 | loss: 2.3954248MixupTrain:  epoch  0, batch   204 | loss: 2.7165523MixupTrain:  epoch  0, batch   205 | loss: 2.3005376MixupTrain:  epoch  0, batch   206 | loss: 2.3058786MixupTrain:  epoch  0, batch   207 | loss: 2.3643284MixupTrain:  epoch  0, batch   208 | loss: 2.7795923MixupTrain:  epoch  0, batch   209 | loss: 2.4840147MixupTrain:  epoch  0, batch   210 | loss: 2.6658907MixupTrain:  epoch  0, batch   211 | loss: 2.5376406MixupTrain:  epoch  0, batch   212 | loss: 2.4959774MixupTrain:  epoch  0, batch   213 | loss: 2.4144983MixupTrain:  epoch  0, batch   214 | loss: 2.7242200MixupTrain:  epoch  0, batch   215 | loss: 2.5976405MixupTrain:  epoch  0, batch   216 | loss: 2.5107150MixupTrain:  epoch  0, batch   217 | loss: 2.6763501MixupTrain:  epoch  0, batch   218 | loss: 2.7165475MixupTrain:  epoch  0, batch   219 | loss: 2.4021282MixupTrain:  epoch  0, batch   220 | loss: 2.8222091MixupTrain:  epoch  0, batch   221 | loss: 2.5678525MixupTrain:  epoch  0, batch   222 | loss: 2.4436188MixupTrain:  epoch  0, batch   223 | loss: 2.2528272MixupTrain:  epoch  0, batch   224 | loss: 2.4678082MixupTrain:  epoch  0, batch   225 | loss: 2.7192917MixupTrain:  epoch  0, batch   226 | loss: 2.5312393MixupTrain:  epoch  0, batch   227 | loss: 2.5231884MixupTrain:  epoch  0, batch   228 | loss: 2.5794060MixupTrain:  epoch  0, batch   229 | loss: 2.6414022MixupTrain:  epoch  0, batch   230 | loss: 2.2288163MixupTrain:  epoch  0, batch   231 | loss: 2.5068393MixupTrain:  epoch  0, batch   232 | loss: 2.2776742MixupTrain:  epoch  0, batch   233 | loss: 2.7029915MixupTrain:  epoch  0, batch   234 | loss: 2.2821696MixupTrain:  epoch  0, batch   235 | loss: 2.4002433MixupTrain:  epoch  0, batch   236 | loss: 2.2452922MixupTrain:  epoch  0, batch   237 | loss: 2.5427728MixupTrain:  epoch  0, batch   238 | loss: 2.5218575MixupTrain:  epoch  0, batch   239 | loss: 2.6426506MixupTrain:  epoch  0, batch   240 | loss: 2.5158143MixupTrain:  epoch  0, batch   241 | loss: 2.6134214MixupTrain:  epoch  0, batch   242 | loss: 2.6675563MixupTrain:  epoch  0, batch   243 | loss: 2.2890508MixupTrain:  epoch  0, batch   244 | loss: 2.5515680MixupTrain:  epoch  0, batch   245 | loss: 2.2974663MixupTrain:  epoch  0, batch   246 | loss: 2.6821318MixupTrain:  epoch  0, batch   247 | loss: 2.4969995MixupTrain:  epoch  0, batch   248 | loss: 2.5150476MixupTrain:  epoch  0, batch   249 | loss: 2.4765408MixupTrain:  epoch  0, batch   250 | loss: 2.4364829MixupTrain:  epoch  0, batch   251 | loss: 2.5871999MixupTrain:  epoch  0, batch   252 | loss: 2.7308991MixupTrain:  epoch  0, batch   253 | loss: 2.5252032MixupTrain:  epoch  0, batch   254 | loss: 2.5931122MixupTrain:  epoch  0, batch   255 | loss: 2.5221391MixupTrain:  epoch  0, batch   256 | loss: 2.3381677MixupTrain:  epoch  0, batch   257 | loss: 2.3931680MixupTrain:  epoch  0, batch   258 | loss: 2.3266745MixupTrain:  epoch  0, batch   259 | loss: 2.4441042MixupTrain:  epoch  0, batch   260 | loss: 2.5370531MixupTrain:  epoch  0, batch   261 | loss: 2.3704927MixupTrain:  epoch  0, batch   262 | loss: 2.6599524MixupTrain:  epoch  0, batch   263 | loss: 2.4954951MixupTrain:  epoch  0, batch   264 | loss: 2.3741632MixupTrain:  epoch  0, batch   265 | loss: 2.4896655MixupTrain:  epoch  0, batch   266 | loss: 2.3073647MixupTrain:  epoch  0, batch   267 | loss: 2.4811420MixupTrain:  epoch  0, batch   268 | loss: 2.2954757MixupTrain:  epoch  0, batch   269 | loss: 2.4182022MixupTrain:  epoch  0, batch   270 | loss: 2.4282999MixupTrain:  epoch  0, batch   271 | loss: 2.7586260MixupTrain:  epoch  0, batch   272 | loss: 2.4750891MixupTrain:  epoch  0, batch   273 | loss: 2.7412820MixupTrain:  epoch  0, batch   274 | loss: 2.2575254MixupTrain:  epoch  0, batch   275 | loss: 2.5055432MixupTrain:  epoch  0, batch   276 | loss: 2.3240252MixupTrain:  epoch  0, batch   277 | loss: 2.6779375MixupTrain:  epoch  0, batch   278 | loss: 2.3280666MixupTrain:  epoch  0, batch   279 | loss: 2.7491798MixupTrain:  epoch  0, batch   280 | loss: 2.4845841MixupTrain:  epoch  0, batch   281 | loss: 2.2714186MixupTrain:  epoch  0, batch   282 | loss: 2.4359000MixupTrain:  epoch  0, batch   283 | loss: 2.6414566MixupTrain:  epoch  0, batch   284 | loss: 2.4617572MixupTrain:  epoch  0, batch   285 | loss: 2.5612197MixupTrain:  epoch  0, batch   286 | loss: 2.6333926MixupTrain:  epoch  0, batch   287 | loss: 2.4228175MixupTrain:  epoch  0, batch   288 | loss: 2.5242777MixupTrain:  epoch  0, batch   289 | loss: 2.5564632MixupTrain:  epoch  0, batch   290 | loss: 2.4855106MixupTrain:  epoch  0, batch   291 | loss: 2.5855041MixupTrain:  epoch  0, batch   292 | loss: 2.3950081MixupTrain:  epoch  0, batch   293 | loss: 2.5717726MixupTrain:  epoch  0, batch   294 | loss: 2.8643565MixupTrain:  epoch  0, batch   295 | loss: 2.3615451MixupTrain:  epoch  0, batch   296 | loss: 2.2042527MixupTrain:  epoch  0, batch   297 | loss: 2.5745125MixupTrain:  epoch  0, batch   298 | loss: 2.3114171MixupTrain:  epoch  0, batch   299 | loss: 2.4419570MixupTrain:  epoch  0, batch   300 | loss: 2.4109268MixupTrain:  epoch  0, batch   301 | loss: 2.5866237MixupTrain:  epoch  0, batch   302 | loss: 2.4533970MixupTrain:  epoch  0, batch   303 | loss: 2.1475019MixupTrain:  epoch  0, batch   304 | loss: 2.7184711MixupTrain:  epoch  0, batch   305 | loss: 2.5956714MixupTrain:  epoch  0, batch   306 | loss: 2.3840451MixupTrain:  epoch  0, batch   307 | loss: 2.4559507MixupTrain:  epoch  0, batch   308 | loss: 2.6028590MixupTrain:  epoch  0, batch   309 | loss: 2.7208278MixupTrain:  epoch  0, batch   310 | loss: 2.4350581MixupTrain:  epoch  0, batch   311 | loss: 2.6539950MixupTrain:  epoch  0, batch   312 | loss: 2.4362600MixupTrain:  epoch  0, batch   313 | loss: 2.6226892MixupTrain:  epoch  0, batch   314 | loss: 2.6864700MixupTrain:  epoch  0, batch   315 | loss: 2.5348053MixupTrain:  epoch  0, batch   316 | loss: 2.6667039MixupTrain:  epoch  0, batch   317 | loss: 2.5572805MixupTrain:  epoch  0, batch   318 | loss: 2.3584013MixupTrain:  epoch  0, batch   319 | loss: 2.6238647MixupTrain:  epoch  0, batch   320 | loss: 2.5004129MixupTrain:  epoch  0, batch   321 | loss: 2.3276403MixupTrain:  epoch  0, batch   322 | loss: 2.6626689MixupTrain:  epoch  0, batch   323 | loss: 2.4794250MixupTrain:  epoch  0, batch   324 | loss: 2.4147930MixupTrain:  epoch  0, batch   325 | loss: 2.4328804MixupTrain:  epoch  0, batch   326 | loss: 2.3474088MixupTrain:  epoch  0, batch   327 | loss: 2.4781075MixupTrain:  epoch  0, batch   328 | loss: 2.5918880MixupTrain:  epoch  0, batch   329 | loss: 2.3862345MixupTrain:  epoch  0, batch   330 | loss: 2.6163344MixupTrain:  epoch  0, batch   331 | loss: 2.2329068MixupTrain:  epoch  0, batch   332 | loss: 2.6741574MixupTrain:  epoch  0, batch   333 | loss: 2.4505606MixupTrain:  epoch  0, batch   334 | loss: 2.5873687MixupTrain:  epoch  0, batch   335 | loss: 2.4729061MixupTrain:  epoch  0, batch   336 | loss: 2.4616289MixupTrain:  epoch  0, batch   337 | loss: 2.5634627MixupTrain:  epoch  0, batch   338 | loss: 2.4075119MixupTrain:  epoch  0, batch   339 | loss: 2.2618904MixupTrain:  epoch  0, batch   340 | loss: 2.3725257MixupTrain:  epoch  0, batch   341 | loss: 2.6100750MixupTrain:  epoch  0, batch   342 | loss: 2.3973556MixupTrain:  epoch  0, batch   343 | loss: 2.5677750MixupTrain:  epoch  0, batch   344 | loss: 2.3229632MixupTrain:  epoch  0, batch   345 | loss: 2.5579600MixupTrain:  epoch  0, batch   346 | loss: 2.2497208MixupTrain:  epoch  0, batch   347 | loss: 2.5679810MixupTrain:  epoch  0, batch   348 | loss: 2.5328498MixupTrain:  epoch  0, batch   349 | loss: 2.6323328MixupTrain:  epoch  0, batch   350 | loss: 2.4973805MixupTrain:  epoch  0, batch   351 | loss: 2.3882670MixupTrain:  epoch  0, batch   352 | loss: 2.3691747MixupTrain:  epoch  0, batch   353 | loss: 2.7252686MixupTrain:  epoch  0, batch   354 | loss: 2.3333566MixupTrain:  epoch  0, batch   355 | loss: 2.5615768MixupTrain:  epoch  0, batch   356 | loss: 2.4586358MixupTrain:  epoch  0, batch   357 | loss: 2.4225247MixupTrain:  epoch  0, batch   358 | loss: 2.3839955MixupTrain:  epoch  0, batch   359 | loss: 2.4486482MixupTrain:  epoch  0, batch   360 | loss: 2.5866086MixupTrain:  epoch  0, batch   361 | loss: 2.5118721MixupTrain:  epoch  0, batch   362 | loss: 2.4009490MixupTrain:  epoch  0, batch   363 | loss: 2.5613949MixupTrain:  epoch  0, batch   364 | loss: 2.5111780MixupTrain:  epoch  0, batch   365 | loss: 2.4730065MixupTrain:  epoch  0, batch   366 | loss: 2.2465258MixupTrain:  epoch  0, batch   367 | loss: 2.3625851MixupTrain:  epoch  0, batch   368 | loss: 2.5623503MixupTrain:  epoch  0, batch   369 | loss: 2.4705999MixupTrain:  epoch  0, batch   370 | loss: 2.6355987MixupTrain:  epoch  0, batch   371 | loss: 2.5522983MixupTrain:  epoch  0, batch   372 | loss: 2.6100349MixupTrain:  epoch  0, batch   373 | loss: 2.5515394MixupTrain:  epoch  0, batch   374 | loss: 2.3982012MixupTrain:  epoch  0, batch   375 | loss: 2.3527932MixupTrain:  epoch  0, batch   376 | loss: 2.3675075MixupTrain:  epoch  0, batch   377 | loss: 2.4607015MixupTrain:  epoch  0, batch   378 | loss: 2.6738601MixupTrain:  epoch  0, batch   379 | loss: 2.3008070MixupTrain:  epoch  0, batch   380 | loss: 2.3309648MixupTrain:  epoch  0, batch   381 | loss: 2.1441917MixupTrain:  epoch  0, batch   382 | loss: 2.5585954MixupTrain:  epoch  0, batch   383 | loss: 2.5047517MixupTrain:  epoch  0, batch   384 | loss: 2.5125453MixupTrain:  epoch  0, batch   385 | loss: 2.3484790MixupTrain:  epoch  0, batch   386 | loss: 2.5214458MixupTrain:  epoch  0, batch   387 | loss: 2.4777334MixupTrain:  epoch  0, batch   388 | loss: 2.4374096MixupTrain:  epoch  0, batch   389 | loss: 2.4052763MixupTrain:  epoch  0, batch   390 | loss: 2.5655570MixupTrain:  epoch  0, batch   391 | loss: 2.4048781MixupTrain:  epoch  0, batch   392 | loss: 2.5730605MixupTrain:  epoch  0, batch   393 | loss: 2.3932967MixupTrain:  epoch  0, batch   394 | loss: 2.5990565MixupTrain:  epoch  0, batch   395 | loss: 2.1587195MixupTrain:  epoch  0, batch   396 | loss: 2.3083644MixupTrain:  epoch  0, batch   397 | loss: 2.0601511MixupTrain:  epoch  0, batch   398 | loss: 2.3919277MixupTrain:  epoch  0, batch   399 | loss: 2.2097182MixupTrain:  epoch  0, batch   400 | loss: 2.2331836MixupTrain:  epoch  0, batch   401 | loss: 2.4269655MixupTrain:  epoch  0, batch   402 | loss: 2.6863925MixupTrain:  epoch  0, batch   403 | loss: 2.5668039MixupTrain:  epoch  0, batch   404 | loss: 2.3789368MixupTrain:  epoch  0, batch   405 | loss: 2.4953034MixupTrain:  epoch  0, batch   406 | loss: 2.2105334MixupTrain:  epoch  0, batch   407 | loss: 2.3769853MixupTrain:  epoch  0, batch   408 | loss: 2.3331981MixupTrain:  epoch  0, batch   409 | loss: 2.2738905MixupTrain:  epoch  0, batch   410 | loss: 2.5369525MixupTrain:  epoch  0, batch   411 | loss: 2.5690253MixupTrain:  epoch  0, batch   412 | loss: 2.6392560MixupTrain:  epoch  0, batch   413 | loss: 2.6207933MixupTrain:  epoch  0, batch   414 | loss: 2.1932926MixupTrain:  epoch  0, batch   415 | loss: 2.3150468MixupTrain:  epoch  0, batch   416 | loss: 2.3633933MixupTrain:  epoch  0, batch   417 | loss: 2.2276039MixupTrain:  epoch  0, batch   418 | loss: 2.4649897MixupTrain:  epoch  0, batch   419 | loss: 2.5577192MixupTrain:  epoch  0, batch   420 | loss: 2.4910951MixupTrain:  epoch  0, batch   421 | loss: 2.3890276MixupTrain:  epoch  0, batch   422 | loss: 2.4236112MixupTrain:  epoch  0, batch   423 | loss: 2.3052180MixupTrain:  epoch  0, batch   424 | loss: 2.2104211MixupTrain:  epoch  0, batch   425 | loss: 2.4384975MixupTrain:  epoch  0, batch   426 | loss: 2.2929139
MemoryTrain:  epoch  0, batch     0 | loss: 2.3662472MemoryTrain:  epoch  0, batch     1 | loss: 3.5177681MemoryTrain:  epoch  0, batch     2 | loss: 3.5492516MemoryTrain:  epoch  0, batch     3 | loss: 3.3883090MemoryTrain:  epoch  0, batch     4 | loss: 2.7495000MemoryTrain:  epoch  0, batch     5 | loss: 2.2268708MemoryTrain:  epoch  1, batch     0 | loss: 1.8765563MemoryTrain:  epoch  1, batch     1 | loss: 1.8596325MemoryTrain:  epoch  1, batch     2 | loss: 1.8729465MemoryTrain:  epoch  1, batch     3 | loss: 1.8373871MemoryTrain:  epoch  1, batch     4 | loss: 1.8532860MemoryTrain:  epoch  1, batch     5 | loss: 1.8305920MemoryTrain:  epoch  2, batch     0 | loss: 1.8245101MemoryTrain:  epoch  2, batch     1 | loss: 1.8398095MemoryTrain:  epoch  2, batch     2 | loss: 1.8314031MemoryTrain:  epoch  2, batch     3 | loss: 1.8370634MemoryTrain:  epoch  2, batch     4 | loss: 1.8406758MemoryTrain:  epoch  2, batch     5 | loss: 1.8398671MemoryTrain:  epoch  3, batch     0 | loss: 1.8529276MemoryTrain:  epoch  3, batch     1 | loss: 1.8387845MemoryTrain:  epoch  3, batch     2 | loss: 1.8343809MemoryTrain:  epoch  3, batch     3 | loss: 1.8316213MemoryTrain:  epoch  3, batch     4 | loss: 1.8408620MemoryTrain:  epoch  3, batch     5 | loss: 1.8452233MemoryTrain:  epoch  4, batch     0 | loss: 1.8335669MemoryTrain:  epoch  4, batch     1 | loss: 1.8311572MemoryTrain:  epoch  4, batch     2 | loss: 1.8330653MemoryTrain:  epoch  4, batch     3 | loss: 1.8378766MemoryTrain:  epoch  4, batch     4 | loss: 1.8388306MemoryTrain:  epoch  4, batch     5 | loss: 1.8420843MemoryTrain:  epoch  5, batch     0 | loss: 1.8419607MemoryTrain:  epoch  5, batch     1 | loss: 1.8351464MemoryTrain:  epoch  5, batch     2 | loss: 1.8312607MemoryTrain:  epoch  5, batch     3 | loss: 1.8188564MemoryTrain:  epoch  5, batch     4 | loss: 1.8307486MemoryTrain:  epoch  5, batch     5 | loss: 1.8514408MemoryTrain:  epoch  6, batch     0 | loss: 1.8373220MemoryTrain:  epoch  6, batch     1 | loss: 1.8212838MemoryTrain:  epoch  6, batch     2 | loss: 1.8443149MemoryTrain:  epoch  6, batch     3 | loss: 1.8369410MemoryTrain:  epoch  6, batch     4 | loss: 1.8523884MemoryTrain:  epoch  6, batch     5 | loss: 1.8356912MemoryTrain:  epoch  7, batch     0 | loss: 1.8680270MemoryTrain:  epoch  7, batch     1 | loss: 1.8288182MemoryTrain:  epoch  7, batch     2 | loss: 1.8404217MemoryTrain:  epoch  7, batch     3 | loss: 1.8381603MemoryTrain:  epoch  7, batch     4 | loss: 1.8499222MemoryTrain:  epoch  7, batch     5 | loss: 1.8366244MemoryTrain:  epoch  8, batch     0 | loss: 1.8391049MemoryTrain:  epoch  8, batch     1 | loss: 1.8388870MemoryTrain:  epoch  8, batch     2 | loss: 1.8476975MemoryTrain:  epoch  8, batch     3 | loss: 1.8300277MemoryTrain:  epoch  8, batch     4 | loss: 1.8362241MemoryTrain:  epoch  8, batch     5 | loss: 1.8349364MemoryTrain:  epoch  9, batch     0 | loss: 1.8430173MemoryTrain:  epoch  9, batch     1 | loss: 1.8182888MemoryTrain:  epoch  9, batch     2 | loss: 1.8388425MemoryTrain:  epoch  9, batch     3 | loss: 1.8250623MemoryTrain:  epoch  9, batch     4 | loss: 1.8323708MemoryTrain:  epoch  9, batch     5 | loss: 1.8419399
[EVAL] batch:    0 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 93.75%   [EVAL] batch:    2 | acc: 100.00%,  total acc: 95.83%   [EVAL] batch:    3 | acc: 93.75%,  total acc: 95.31%   [EVAL] batch:    4 | acc: 100.00%,  total acc: 96.25%   [EVAL] batch:    5 | acc: 81.25%,  total acc: 93.75%   [EVAL] batch:    6 | acc: 75.00%,  total acc: 91.07%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 91.41%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 92.36%   [EVAL] batch:    9 | acc: 87.50%,  total acc: 91.88%   [EVAL] batch:   10 | acc: 87.50%,  total acc: 91.48%   [EVAL] batch:   11 | acc: 81.25%,  total acc: 90.62%   [EVAL] batch:   12 | acc: 100.00%,  total acc: 91.35%   [EVAL] batch:   13 | acc: 62.50%,  total acc: 89.29%   
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    1 | acc: 62.50%,  total acc: 71.88%   [EVAL] batch:    2 | acc: 75.00%,  total acc: 72.92%   [EVAL] batch:    3 | acc: 68.75%,  total acc: 71.88%   [EVAL] batch:    4 | acc: 75.00%,  total acc: 72.50%   [EVAL] batch:    5 | acc: 68.75%,  total acc: 71.88%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 75.89%   [EVAL] batch:    7 | acc: 87.50%,  total acc: 77.34%   [EVAL] batch:    8 | acc: 93.75%,  total acc: 79.17%   [EVAL] batch:    9 | acc: 81.25%,  total acc: 79.38%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 81.25%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 82.29%   [EVAL] batch:   12 | acc: 75.00%,  total acc: 81.73%   [EVAL] batch:   13 | acc: 50.00%,  total acc: 79.46%   [EVAL] batch:   14 | acc: 75.00%,  total acc: 79.17%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 77.73%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 77.57%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 76.74%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 75.99%   [EVAL] batch:   19 | acc: 87.50%,  total acc: 76.56%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 77.68%   [EVAL] batch:   21 | acc: 100.00%,  total acc: 78.69%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 79.62%   [EVAL] batch:   23 | acc: 100.00%,  total acc: 80.47%   [EVAL] batch:   24 | acc: 100.00%,  total acc: 81.25%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 81.97%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 82.41%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 83.04%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 83.62%   [EVAL] batch:   29 | acc: 81.25%,  total acc: 83.54%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 84.07%   [EVAL] batch:   31 | acc: 93.75%,  total acc: 84.38%   [EVAL] batch:   32 | acc: 100.00%,  total acc: 84.85%   [EVAL] batch:   33 | acc: 93.75%,  total acc: 85.11%   [EVAL] batch:   34 | acc: 87.50%,  total acc: 85.18%   [EVAL] batch:   35 | acc: 87.50%,  total acc: 85.24%   [EVAL] batch:   36 | acc: 93.75%,  total acc: 85.47%   [EVAL] batch:   37 | acc: 81.25%,  total acc: 85.36%   [EVAL] batch:   38 | acc: 68.75%,  total acc: 84.94%   [EVAL] batch:   39 | acc: 75.00%,  total acc: 84.69%   [EVAL] batch:   40 | acc: 37.50%,  total acc: 83.54%   [EVAL] batch:   41 | acc: 6.25%,  total acc: 81.70%   [EVAL] batch:   42 | acc: 12.50%,  total acc: 80.09%   [EVAL] batch:   43 | acc: 62.50%,  total acc: 79.69%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 80.14%   [EVAL] batch:   45 | acc: 100.00%,  total acc: 80.57%   [EVAL] batch:   46 | acc: 100.00%,  total acc: 80.98%   [EVAL] batch:   47 | acc: 100.00%,  total acc: 81.38%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 81.76%   [EVAL] batch:   49 | acc: 100.00%,  total acc: 82.12%   [EVAL] batch:   50 | acc: 87.50%,  total acc: 82.23%   [EVAL] batch:   51 | acc: 100.00%,  total acc: 82.57%   [EVAL] batch:   52 | acc: 100.00%,  total acc: 82.90%   [EVAL] batch:   53 | acc: 93.75%,  total acc: 83.10%   [EVAL] batch:   54 | acc: 93.75%,  total acc: 83.30%   [EVAL] batch:   55 | acc: 81.25%,  total acc: 83.26%   [EVAL] batch:   56 | acc: 81.25%,  total acc: 83.22%   [EVAL] batch:   57 | acc: 93.75%,  total acc: 83.41%   [EVAL] batch:   58 | acc: 93.75%,  total acc: 83.58%   [EVAL] batch:   59 | acc: 93.75%,  total acc: 83.75%   [EVAL] batch:   60 | acc: 75.00%,  total acc: 83.61%   [EVAL] batch:   61 | acc: 93.75%,  total acc: 83.77%   [EVAL] batch:   62 | acc: 100.00%,  total acc: 84.03%   [EVAL] batch:   63 | acc: 25.00%,  total acc: 83.11%   
cur_acc:  ['0.8693', '0.9132', '0.8929']
his_acc:  ['0.8693', '0.8550', '0.8311']
CurrentTrain: epoch  0, batch     0 | loss: 3.7392304CurrentTrain: epoch  0, batch     1 | loss: 4.3055577CurrentTrain: epoch  1, batch     0 | loss: 3.6193538CurrentTrain: epoch  1, batch     1 | loss: 2.6259847CurrentTrain: epoch  2, batch     0 | loss: 2.6236424CurrentTrain: epoch  2, batch     1 | loss: 2.9095731CurrentTrain: epoch  3, batch     0 | loss: 2.5207682CurrentTrain: epoch  3, batch     1 | loss: 2.6815553CurrentTrain: epoch  4, batch     0 | loss: 2.6281409CurrentTrain: epoch  4, batch     1 | loss: 2.5017717CurrentTrain: epoch  5, batch     0 | loss: 2.1555073CurrentTrain: epoch  5, batch     1 | loss: 3.0842826CurrentTrain: epoch  6, batch     0 | loss: 2.1679115CurrentTrain: epoch  6, batch     1 | loss: 2.3914309CurrentTrain: epoch  7, batch     0 | loss: 2.1038578CurrentTrain: epoch  7, batch     1 | loss: 2.2308278CurrentTrain: epoch  8, batch     0 | loss: 2.2340672CurrentTrain: epoch  8, batch     1 | loss: 1.8139482CurrentTrain: epoch  9, batch     0 | loss: 2.1227069CurrentTrain: epoch  9, batch     1 | loss: 1.8179618
#### organization founded ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization founded" means an organization was found in a date.
Here is an example:
Relation: organization founded
Context: pandit worked at the brokerage morgan stanley for about 11 years until 2005 , when he and some morgan stanley colleagues quit and later founded the hedge fund old lane partners .
Head Entity: old lane partners
Tail Entity: 2005
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization founded":
Relation: organization founded  
Context: In 1998, a group of engineers and entrepreneurs came together to establish the tech startup, Innovatech Solutions, which has since become a leader in software development.  
Head Entity: Innovatech Solutions  
Tail Entity: 1998  

Relation: organization founded  
Context: The non-profit organization Green Earth Initiative was established in 2010 to promote environmental awareness and sustainability practices across communities.  
Head Entity: Green Earth Initiative  
Tail Entity: 2010  

Relation: organization founded  
Context: After years of research and development, the pharmaceutical company HealthPlus was founded in 2015 to focus on innovative healthcare solutions.  
Head Entity: HealthPlus  
Tail Entity: 2015  

Relation: organization founded  
Context: In 2001, the fashion brand Urban Chic was founded by a group of designers who aimed to revolutionize streetwear with their unique styles.  
Head Entity: Urban Chic  
Tail Entity: 2001  

Relation: organization founded  
Context: The educational institution Future Leaders Academy was founded in 2020 to provide quality education and mentorship to underprivileged youth.  
Head Entity: Future Leaders Academy  
Tail Entity: 2020  
#### person age ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person age" means a person 's age is a number.
Here is an example:
Relation: person age
Context: virginia republican jo ann davis passed away on saturday at the age of 57 .
Head Entity: jo ann davis
Tail Entity: 57
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person age":
Relation: person age  
Context: the famous actor robert downey jr. celebrated his 56th birthday last week.  
Head Entity: robert downey jr.  
Tail Entity: 56  

Relation: person age  
Context: on her 30th birthday, emily decided to throw a big party for her friends.  
Head Entity: emily  
Tail Entity: 30  

Relation: person age  
Context: the renowned scientist albert einstein was born in 1879 and lived to be 76 years old.  
Head Entity: albert einstein  
Tail Entity: 76  

Relation: person age  
Context: during the interview, the journalist revealed that she is only 25 years old.  
Head Entity: the journalist  
Tail Entity: 25  

Relation: person age  
Context: my grandmother turned 85 last month, and we celebrated her life with a family gathering.  
Head Entity: my grandmother  
Tail Entity: 85  
#### person city of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person city of birth" means a person was born in a city.
Here is an example:
Relation: person city of birth
Context: joseph simpson farland was born on aug 11 , 1914 , in clarksburg , wva , the only child of richard and grace simpson farland .
Head Entity: joseph simpson farland
Tail Entity: clarksburg
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person city of birth":
Relation: person city of birth  
Context: marie curie was born in warsaw, poland, on november 7, 1867, and later became a renowned physicist and chemist.  
Head Entity: marie curie  
Tail Entity: warsaw  

Relation: person city of birth  
Context: barack obama was born in honolulu, hawaii, on august 4, 1961, and went on to become the 44th president of the united states.  
Head Entity: barack obama  
Tail Entity: honolulu  

Relation: person city of birth  
Context: frida kahlo was born in coyoacán, mexico city, on july 6, 1907, and is celebrated for her unique artistic style.  
Head Entity: frida kahlo  
Tail Entity: coyoacán  

Relation: person city of birth  
Context: nelson mandela was born in mvezo, south africa, on july 18, 1918, and became a key figure in the fight against apartheid.  
Head Entity: nelson mandela  
Tail Entity: mvezo  

Relation: person city of birth  
Context: agatha christie was born in torquay, england, on september 15, 1890, and is known for her detective novels.  
Head Entity: agatha christie  
Tail Entity: torquay  
#### organization members ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization members" means an organization 's member is an organization.
Here is an example:
Relation: organization members
Context: sun plays for the grand rapids flight of the international basketball league after toiling for the maryland nighthawks of the american basketball association , both development leagues for those who dream of an nba career .
Head Entity: american basketball association
Tail Entity: maryland nighthawks
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization members":
Relation: organization members  
Context: The New York Philharmonic is one of the oldest orchestras in the United States, and it has had many notable musicians, including members from the Boston Symphony Orchestra.  
Head Entity: Boston Symphony Orchestra  
Tail Entity: New York Philharmonic  

Relation: organization members  
Context: The National Football League has numerous teams, and the Dallas Cowboys are one of its most famous members, often competing against the New England Patriots.  
Head Entity: New England Patriots  
Tail Entity: Dallas Cowboys  

Relation: organization members  
Context: The United Nations consists of various specialized agencies, including the World Health Organization, which plays a crucial role in global health initiatives.  
Head Entity: World Health Organization  
Tail Entity: United Nations  

Relation: organization members  
Context: The International Olympic Committee oversees the Olympic Games and includes various national committees, such as the United States Olympic and Paralympic Committee.  
Head Entity: United States Olympic and Paralympic Committee  
Tail Entity: International Olympic Committee  

Relation: organization members  
Context: The European Union is made up of several member states, including Germany, which plays a significant role in the EU's economic policies.  
Head Entity: Germany  
Tail Entity: European Union  
#### person religion ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person religion" means an person is the member of a religion.
Here is an example:
Relation: person religion
Context: devout catholic miss boyle has been at the centre of a media storm since news emerged of how she wowed britain 's got talent judges simon cowell and piers morgan with her amazing opera voice .
Head Entity: boyle
Tail Entity: catholic
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person religion":
Relation: person religion  
Context: After years of dedication to her faith, Maria finally decided to become a nun, embracing her identity as a devoted member of the Catholic Church.  
Head Entity: Maria  
Tail Entity: Catholic Church  

Relation: person religion  
Context: The famous actor, known for his philanthropic work, often speaks about his deep connection to Buddhism and how it influences his life choices.  
Head Entity: actor  
Tail Entity: Buddhism  

Relation: person religion  
Context: Growing up in a Jewish household, David has always celebrated the traditions of his ancestors, feeling a strong bond with his Jewish heritage.  
Head Entity: David  
Tail Entity: Jewish  

Relation: person religion  
Context: As a prominent leader in the community, Imam Ali often shares his insights on Islam, guiding many towards a deeper understanding of their faith.  
Head Entity: Imam Ali  
Tail Entity: Islam  

Relation: person religion  
Context: The renowned author frequently discusses her experiences as a practicing Hindu, highlighting the importance of spirituality in her writing.  
Head Entity: author  
Tail Entity: Hindu  
Mixup data size:  10810
MixupTrain:  epoch  0, batch     0 | loss: 5.3906107MixupTrain:  epoch  0, batch     1 | loss: 4.7500229MixupTrain:  epoch  0, batch     2 | loss: 4.3249521MixupTrain:  epoch  0, batch     3 | loss: 4.2684016MixupTrain:  epoch  0, batch     4 | loss: 3.8932381MixupTrain:  epoch  0, batch     5 | loss: 4.2675562MixupTrain:  epoch  0, batch     6 | loss: 4.0765376MixupTrain:  epoch  0, batch     7 | loss: 4.1643171MixupTrain:  epoch  0, batch     8 | loss: 4.5437813MixupTrain:  epoch  0, batch     9 | loss: 4.6298685MixupTrain:  epoch  0, batch    10 | loss: 3.7836025MixupTrain:  epoch  0, batch    11 | loss: 4.6479259MixupTrain:  epoch  0, batch    12 | loss: 3.9949379MixupTrain:  epoch  0, batch    13 | loss: 3.3637142MixupTrain:  epoch  0, batch    14 | loss: 4.5445352MixupTrain:  epoch  0, batch    15 | loss: 3.6648722MixupTrain:  epoch  0, batch    16 | loss: 3.9322770MixupTrain:  epoch  0, batch    17 | loss: 4.1271744MixupTrain:  epoch  0, batch    18 | loss: 3.9794464MixupTrain:  epoch  0, batch    19 | loss: 3.6116610MixupTrain:  epoch  0, batch    20 | loss: 3.4070411MixupTrain:  epoch  0, batch    21 | loss: 3.4156828MixupTrain:  epoch  0, batch    22 | loss: 3.4338555MixupTrain:  epoch  0, batch    23 | loss: 3.6055226MixupTrain:  epoch  0, batch    24 | loss: 3.7286472MixupTrain:  epoch  0, batch    25 | loss: 3.5626445MixupTrain:  epoch  0, batch    26 | loss: 3.1566503MixupTrain:  epoch  0, batch    27 | loss: 3.6795378MixupTrain:  epoch  0, batch    28 | loss: 4.0725212MixupTrain:  epoch  0, batch    29 | loss: 3.4026752MixupTrain:  epoch  0, batch    30 | loss: 4.0422678MixupTrain:  epoch  0, batch    31 | loss: 3.7736549MixupTrain:  epoch  0, batch    32 | loss: 3.7396472MixupTrain:  epoch  0, batch    33 | loss: 2.9625616MixupTrain:  epoch  0, batch    34 | loss: 3.6486545MixupTrain:  epoch  0, batch    35 | loss: 3.3915133MixupTrain:  epoch  0, batch    36 | loss: 3.4543123MixupTrain:  epoch  0, batch    37 | loss: 3.1724548MixupTrain:  epoch  0, batch    38 | loss: 3.2262354MixupTrain:  epoch  0, batch    39 | loss: 3.1790648MixupTrain:  epoch  0, batch    40 | loss: 2.9273582MixupTrain:  epoch  0, batch    41 | loss: 3.1131697MixupTrain:  epoch  0, batch    42 | loss: 3.0170329MixupTrain:  epoch  0, batch    43 | loss: 2.9739285MixupTrain:  epoch  0, batch    44 | loss: 2.8883026MixupTrain:  epoch  0, batch    45 | loss: 3.8026977MixupTrain:  epoch  0, batch    46 | loss: 3.6885238MixupTrain:  epoch  0, batch    47 | loss: 3.2103379MixupTrain:  epoch  0, batch    48 | loss: 3.2036891MixupTrain:  epoch  0, batch    49 | loss: 3.2932274MixupTrain:  epoch  0, batch    50 | loss: 2.9854724MixupTrain:  epoch  0, batch    51 | loss: 3.3743997MixupTrain:  epoch  0, batch    52 | loss: 3.1236985MixupTrain:  epoch  0, batch    53 | loss: 3.0938258MixupTrain:  epoch  0, batch    54 | loss: 2.9517708MixupTrain:  epoch  0, batch    55 | loss: 2.8055551MixupTrain:  epoch  0, batch    56 | loss: 2.8976164MixupTrain:  epoch  0, batch    57 | loss: 3.1801105MixupTrain:  epoch  0, batch    58 | loss: 2.8628862MixupTrain:  epoch  0, batch    59 | loss: 3.1766102MixupTrain:  epoch  0, batch    60 | loss: 2.4856761MixupTrain:  epoch  0, batch    61 | loss: 3.0594044MixupTrain:  epoch  0, batch    62 | loss: 2.7916455MixupTrain:  epoch  0, batch    63 | loss: 2.7485955MixupTrain:  epoch  0, batch    64 | loss: 3.0741107MixupTrain:  epoch  0, batch    65 | loss: 2.7270384MixupTrain:  epoch  0, batch    66 | loss: 2.8133321MixupTrain:  epoch  0, batch    67 | loss: 2.6253877MixupTrain:  epoch  0, batch    68 | loss: 3.0128937MixupTrain:  epoch  0, batch    69 | loss: 2.6639667MixupTrain:  epoch  0, batch    70 | loss: 2.8265047MixupTrain:  epoch  0, batch    71 | loss: 2.8514929MixupTrain:  epoch  0, batch    72 | loss: 3.0494146MixupTrain:  epoch  0, batch    73 | loss: 2.8189993MixupTrain:  epoch  0, batch    74 | loss: 2.9722893MixupTrain:  epoch  0, batch    75 | loss: 2.7949102MixupTrain:  epoch  0, batch    76 | loss: 3.3494911MixupTrain:  epoch  0, batch    77 | loss: 3.1036389MixupTrain:  epoch  0, batch    78 | loss: 2.6620665MixupTrain:  epoch  0, batch    79 | loss: 2.9882376MixupTrain:  epoch  0, batch    80 | loss: 2.9254506MixupTrain:  epoch  0, batch    81 | loss: 2.7583997MixupTrain:  epoch  0, batch    82 | loss: 2.6423166MixupTrain:  epoch  0, batch    83 | loss: 2.7156625MixupTrain:  epoch  0, batch    84 | loss: 2.8941894MixupTrain:  epoch  0, batch    85 | loss: 2.9493475MixupTrain:  epoch  0, batch    86 | loss: 2.4114342MixupTrain:  epoch  0, batch    87 | loss: 2.8868217MixupTrain:  epoch  0, batch    88 | loss: 2.5191777MixupTrain:  epoch  0, batch    89 | loss: 2.6353040MixupTrain:  epoch  0, batch    90 | loss: 2.8801630MixupTrain:  epoch  0, batch    91 | loss: 2.7743413MixupTrain:  epoch  0, batch    92 | loss: 3.0466752MixupTrain:  epoch  0, batch    93 | loss: 2.6737955MixupTrain:  epoch  0, batch    94 | loss: 2.7847338MixupTrain:  epoch  0, batch    95 | loss: 2.6176476MixupTrain:  epoch  0, batch    96 | loss: 2.6509371MixupTrain:  epoch  0, batch    97 | loss: 2.6623888MixupTrain:  epoch  0, batch    98 | loss: 2.6038282MixupTrain:  epoch  0, batch    99 | loss: 2.9306803MixupTrain:  epoch  0, batch   100 | loss: 2.4436195MixupTrain:  epoch  0, batch   101 | loss: 2.5589399MixupTrain:  epoch  0, batch   102 | loss: 2.6726074MixupTrain:  epoch  0, batch   103 | loss: 2.7051849MixupTrain:  epoch  0, batch   104 | loss: 2.6155748MixupTrain:  epoch  0, batch   105 | loss: 2.5749760MixupTrain:  epoch  0, batch   106 | loss: 2.6509953MixupTrain:  epoch  0, batch   107 | loss: 2.4770954MixupTrain:  epoch  0, batch   108 | loss: 2.5572066MixupTrain:  epoch  0, batch   109 | loss: 2.8425786MixupTrain:  epoch  0, batch   110 | loss: 2.4975808MixupTrain:  epoch  0, batch   111 | loss: 2.5528002MixupTrain:  epoch  0, batch   112 | loss: 2.4810505MixupTrain:  epoch  0, batch   113 | loss: 2.7516928MixupTrain:  epoch  0, batch   114 | loss: 2.6825616MixupTrain:  epoch  0, batch   115 | loss: 2.4685354MixupTrain:  epoch  0, batch   116 | loss: 2.6213658MixupTrain:  epoch  0, batch   117 | loss: 2.9187193MixupTrain:  epoch  0, batch   118 | loss: 2.4401331MixupTrain:  epoch  0, batch   119 | loss: 2.7137008MixupTrain:  epoch  0, batch   120 | loss: 2.2839193MixupTrain:  epoch  0, batch   121 | loss: 2.6343286MixupTrain:  epoch  0, batch   122 | loss: 2.2600834MixupTrain:  epoch  0, batch   123 | loss: 2.5273442MixupTrain:  epoch  0, batch   124 | loss: 2.9311128MixupTrain:  epoch  0, batch   125 | loss: 2.8927870MixupTrain:  epoch  0, batch   126 | loss: 2.6070666MixupTrain:  epoch  0, batch   127 | loss: 2.4175067MixupTrain:  epoch  0, batch   128 | loss: 2.4348068MixupTrain:  epoch  0, batch   129 | loss: 2.7360930MixupTrain:  epoch  0, batch   130 | loss: 2.6231153MixupTrain:  epoch  0, batch   131 | loss: 2.3528664MixupTrain:  epoch  0, batch   132 | loss: 2.4116001MixupTrain:  epoch  0, batch   133 | loss: 2.7601104MixupTrain:  epoch  0, batch   134 | loss: 2.3450086MixupTrain:  epoch  0, batch   135 | loss: 2.2925448MixupTrain:  epoch  0, batch   136 | loss: 2.8913383MixupTrain:  epoch  0, batch   137 | loss: 2.7237108MixupTrain:  epoch  0, batch   138 | loss: 2.6335731MixupTrain:  epoch  0, batch   139 | loss: 2.5694041MixupTrain:  epoch  0, batch   140 | loss: 2.6514850MixupTrain:  epoch  0, batch   141 | loss: 2.1808283MixupTrain:  epoch  0, batch   142 | loss: 2.4093971MixupTrain:  epoch  0, batch   143 | loss: 2.7829328MixupTrain:  epoch  0, batch   144 | loss: 2.4537125MixupTrain:  epoch  0, batch   145 | loss: 2.6463535MixupTrain:  epoch  0, batch   146 | loss: 2.3696778MixupTrain:  epoch  0, batch   147 | loss: 2.2757571MixupTrain:  epoch  0, batch   148 | loss: 2.7877262MixupTrain:  epoch  0, batch   149 | loss: 2.7539501MixupTrain:  epoch  0, batch   150 | loss: 2.3963075MixupTrain:  epoch  0, batch   151 | loss: 2.8470392MixupTrain:  epoch  0, batch   152 | loss: 2.2686021MixupTrain:  epoch  0, batch   153 | loss: 2.3122296MixupTrain:  epoch  0, batch   154 | loss: 2.4651768MixupTrain:  epoch  0, batch   155 | loss: 2.4959629MixupTrain:  epoch  0, batch   156 | loss: 2.4581769MixupTrain:  epoch  0, batch   157 | loss: 2.5619812MixupTrain:  epoch  0, batch   158 | loss: 2.5122981MixupTrain:  epoch  0, batch   159 | loss: 2.2594590MixupTrain:  epoch  0, batch   160 | loss: 2.8535454MixupTrain:  epoch  0, batch   161 | loss: 2.4979730MixupTrain:  epoch  0, batch   162 | loss: 2.3608456MixupTrain:  epoch  0, batch   163 | loss: 2.5360911MixupTrain:  epoch  0, batch   164 | loss: 2.8000197MixupTrain:  epoch  0, batch   165 | loss: 2.4512661MixupTrain:  epoch  0, batch   166 | loss: 2.7214327MixupTrain:  epoch  0, batch   167 | loss: 2.3878007MixupTrain:  epoch  0, batch   168 | loss: 2.9762790MixupTrain:  epoch  0, batch   169 | loss: 2.4944081MixupTrain:  epoch  0, batch   170 | loss: 2.3593094MixupTrain:  epoch  0, batch   171 | loss: 2.6354687MixupTrain:  epoch  0, batch   172 | loss: 2.2419012MixupTrain:  epoch  0, batch   173 | loss: 2.5519936MixupTrain:  epoch  0, batch   174 | loss: 2.7243028MixupTrain:  epoch  0, batch   175 | loss: 2.4919701MixupTrain:  epoch  0, batch   176 | loss: 2.6597459MixupTrain:  epoch  0, batch   177 | loss: 2.4808545MixupTrain:  epoch  0, batch   178 | loss: 2.7249267MixupTrain:  epoch  0, batch   179 | loss: 2.6040993MixupTrain:  epoch  0, batch   180 | loss: 2.6125655MixupTrain:  epoch  0, batch   181 | loss: 2.5686679MixupTrain:  epoch  0, batch   182 | loss: 2.5275156MixupTrain:  epoch  0, batch   183 | loss: 2.4566915MixupTrain:  epoch  0, batch   184 | loss: 2.5381613MixupTrain:  epoch  0, batch   185 | loss: 2.3436928MixupTrain:  epoch  0, batch   186 | loss: 2.3327231MixupTrain:  epoch  0, batch   187 | loss: 2.5659666MixupTrain:  epoch  0, batch   188 | loss: 2.5007703MixupTrain:  epoch  0, batch   189 | loss: 2.2678809MixupTrain:  epoch  0, batch   190 | loss: 2.6115606MixupTrain:  epoch  0, batch   191 | loss: 2.4212487MixupTrain:  epoch  0, batch   192 | loss: 2.4385092MixupTrain:  epoch  0, batch   193 | loss: 2.3919730MixupTrain:  epoch  0, batch   194 | loss: 2.4988058MixupTrain:  epoch  0, batch   195 | loss: 2.3889639MixupTrain:  epoch  0, batch   196 | loss: 2.7642097MixupTrain:  epoch  0, batch   197 | loss: 2.5597811MixupTrain:  epoch  0, batch   198 | loss: 2.4742451MixupTrain:  epoch  0, batch   199 | loss: 2.4698772MixupTrain:  epoch  0, batch   200 | loss: 2.4470832MixupTrain:  epoch  0, batch   201 | loss: 2.4632466MixupTrain:  epoch  0, batch   202 | loss: 2.6084964MixupTrain:  epoch  0, batch   203 | loss: 2.2480531MixupTrain:  epoch  0, batch   204 | loss: 2.4974039MixupTrain:  epoch  0, batch   205 | loss: 2.3960481MixupTrain:  epoch  0, batch   206 | loss: 2.3880990MixupTrain:  epoch  0, batch   207 | loss: 2.3287053MixupTrain:  epoch  0, batch   208 | loss: 2.2671337MixupTrain:  epoch  0, batch   209 | loss: 2.5699248MixupTrain:  epoch  0, batch   210 | loss: 2.5564764MixupTrain:  epoch  0, batch   211 | loss: 2.2878013MixupTrain:  epoch  0, batch   212 | loss: 2.3913310MixupTrain:  epoch  0, batch   213 | loss: 2.5622807MixupTrain:  epoch  0, batch   214 | loss: 2.4566791MixupTrain:  epoch  0, batch   215 | loss: 2.2951722MixupTrain:  epoch  0, batch   216 | loss: 2.4026141MixupTrain:  epoch  0, batch   217 | loss: 2.3708754MixupTrain:  epoch  0, batch   218 | loss: 2.4600232MixupTrain:  epoch  0, batch   219 | loss: 2.4624128MixupTrain:  epoch  0, batch   220 | loss: 2.2145989MixupTrain:  epoch  0, batch   221 | loss: 2.5070744MixupTrain:  epoch  0, batch   222 | loss: 2.4250116MixupTrain:  epoch  0, batch   223 | loss: 2.3451681MixupTrain:  epoch  0, batch   224 | loss: 2.3793581MixupTrain:  epoch  0, batch   225 | loss: 2.3759871MixupTrain:  epoch  0, batch   226 | loss: 2.2447643MixupTrain:  epoch  0, batch   227 | loss: 2.2240424MixupTrain:  epoch  0, batch   228 | loss: 2.4075401MixupTrain:  epoch  0, batch   229 | loss: 2.4562783MixupTrain:  epoch  0, batch   230 | loss: 2.4086533MixupTrain:  epoch  0, batch   231 | loss: 2.3466115MixupTrain:  epoch  0, batch   232 | loss: 2.3816433MixupTrain:  epoch  0, batch   233 | loss: 2.5785728MixupTrain:  epoch  0, batch   234 | loss: 2.2338829MixupTrain:  epoch  0, batch   235 | loss: 2.2638121MixupTrain:  epoch  0, batch   236 | loss: 2.5632310MixupTrain:  epoch  0, batch   237 | loss: 2.4379492MixupTrain:  epoch  0, batch   238 | loss: 2.4868073MixupTrain:  epoch  0, batch   239 | loss: 2.3649421MixupTrain:  epoch  0, batch   240 | loss: 2.6569567MixupTrain:  epoch  0, batch   241 | loss: 2.3108990MixupTrain:  epoch  0, batch   242 | loss: 2.4795496MixupTrain:  epoch  0, batch   243 | loss: 2.3963799MixupTrain:  epoch  0, batch   244 | loss: 2.4659457MixupTrain:  epoch  0, batch   245 | loss: 2.7095160MixupTrain:  epoch  0, batch   246 | loss: 2.2668519MixupTrain:  epoch  0, batch   247 | loss: 2.5306182MixupTrain:  epoch  0, batch   248 | loss: 2.3954954MixupTrain:  epoch  0, batch   249 | loss: 2.3396788MixupTrain:  epoch  0, batch   250 | loss: 2.3269835MixupTrain:  epoch  0, batch   251 | loss: 2.4469843MixupTrain:  epoch  0, batch   252 | loss: 2.5020280MixupTrain:  epoch  0, batch   253 | loss: 2.4412556MixupTrain:  epoch  0, batch   254 | loss: 2.3833375MixupTrain:  epoch  0, batch   255 | loss: 2.4008684MixupTrain:  epoch  0, batch   256 | loss: 2.6146066MixupTrain:  epoch  0, batch   257 | loss: 2.4075229MixupTrain:  epoch  0, batch   258 | loss: 2.5653493MixupTrain:  epoch  0, batch   259 | loss: 2.4259665MixupTrain:  epoch  0, batch   260 | loss: 2.4524307MixupTrain:  epoch  0, batch   261 | loss: 2.5311184MixupTrain:  epoch  0, batch   262 | loss: 2.5518670MixupTrain:  epoch  0, batch   263 | loss: 2.2838912MixupTrain:  epoch  0, batch   264 | loss: 2.4067974MixupTrain:  epoch  0, batch   265 | loss: 2.3631539MixupTrain:  epoch  0, batch   266 | loss: 2.6492252MixupTrain:  epoch  0, batch   267 | loss: 2.4788184MixupTrain:  epoch  0, batch   268 | loss: 2.3710992MixupTrain:  epoch  0, batch   269 | loss: 2.4789138MixupTrain:  epoch  0, batch   270 | loss: 2.4521189MixupTrain:  epoch  0, batch   271 | loss: 2.5236652MixupTrain:  epoch  0, batch   272 | loss: 2.6900887MixupTrain:  epoch  0, batch   273 | loss: 2.6275125MixupTrain:  epoch  0, batch   274 | loss: 2.3917069MixupTrain:  epoch  0, batch   275 | loss: 2.3931956MixupTrain:  epoch  0, batch   276 | loss: 2.5132279MixupTrain:  epoch  0, batch   277 | loss: 2.5939231MixupTrain:  epoch  0, batch   278 | loss: 2.5669820MixupTrain:  epoch  0, batch   279 | loss: 2.7260275MixupTrain:  epoch  0, batch   280 | loss: 2.6221576MixupTrain:  epoch  0, batch   281 | loss: 2.6456485MixupTrain:  epoch  0, batch   282 | loss: 2.3140454MixupTrain:  epoch  0, batch   283 | loss: 2.4574296MixupTrain:  epoch  0, batch   284 | loss: 2.4752858MixupTrain:  epoch  0, batch   285 | loss: 2.3446691MixupTrain:  epoch  0, batch   286 | loss: 2.3109655MixupTrain:  epoch  0, batch   287 | loss: 2.4862902MixupTrain:  epoch  0, batch   288 | loss: 2.3956995MixupTrain:  epoch  0, batch   289 | loss: 2.1889637MixupTrain:  epoch  0, batch   290 | loss: 2.3927617MixupTrain:  epoch  0, batch   291 | loss: 2.4704344MixupTrain:  epoch  0, batch   292 | loss: 2.3147154MixupTrain:  epoch  0, batch   293 | loss: 2.4192443MixupTrain:  epoch  0, batch   294 | loss: 2.6787853MixupTrain:  epoch  0, batch   295 | loss: 2.5068884MixupTrain:  epoch  0, batch   296 | loss: 2.4061890MixupTrain:  epoch  0, batch   297 | loss: 2.5894854MixupTrain:  epoch  0, batch   298 | loss: 2.2008438MixupTrain:  epoch  0, batch   299 | loss: 2.2861533MixupTrain:  epoch  0, batch   300 | loss: 2.4422965MixupTrain:  epoch  0, batch   301 | loss: 2.4100864MixupTrain:  epoch  0, batch   302 | loss: 2.3762574MixupTrain:  epoch  0, batch   303 | loss: 2.2887688MixupTrain:  epoch  0, batch   304 | loss: 2.3754392MixupTrain:  epoch  0, batch   305 | loss: 2.3579736MixupTrain:  epoch  0, batch   306 | loss: 2.3302240MixupTrain:  epoch  0, batch   307 | loss: 2.4130220MixupTrain:  epoch  0, batch   308 | loss: 2.4190965MixupTrain:  epoch  0, batch   309 | loss: 2.4335384MixupTrain:  epoch  0, batch   310 | loss: 2.5529518MixupTrain:  epoch  0, batch   311 | loss: 2.3537869MixupTrain:  epoch  0, batch   312 | loss: 2.4838276MixupTrain:  epoch  0, batch   313 | loss: 2.4143505MixupTrain:  epoch  0, batch   314 | loss: 2.5217490MixupTrain:  epoch  0, batch   315 | loss: 2.4133396MixupTrain:  epoch  0, batch   316 | loss: 2.5538287MixupTrain:  epoch  0, batch   317 | loss: 2.6557608MixupTrain:  epoch  0, batch   318 | loss: 2.5197265MixupTrain:  epoch  0, batch   319 | loss: 2.4028878MixupTrain:  epoch  0, batch   320 | loss: 2.1828783MixupTrain:  epoch  0, batch   321 | loss: 2.4290948MixupTrain:  epoch  0, batch   322 | loss: 2.6052511MixupTrain:  epoch  0, batch   323 | loss: 2.2907448MixupTrain:  epoch  0, batch   324 | loss: 2.4802456MixupTrain:  epoch  0, batch   325 | loss: 2.4364738MixupTrain:  epoch  0, batch   326 | loss: 2.3791194MixupTrain:  epoch  0, batch   327 | loss: 2.2697730MixupTrain:  epoch  0, batch   328 | loss: 2.4397922MixupTrain:  epoch  0, batch   329 | loss: 2.6108561MixupTrain:  epoch  0, batch   330 | loss: 2.5331230MixupTrain:  epoch  0, batch   331 | loss: 2.5466452MixupTrain:  epoch  0, batch   332 | loss: 2.2904258MixupTrain:  epoch  0, batch   333 | loss: 2.3707275MixupTrain:  epoch  0, batch   334 | loss: 2.4212556MixupTrain:  epoch  0, batch   335 | loss: 2.1985042MixupTrain:  epoch  0, batch   336 | loss: 2.0476158MixupTrain:  epoch  0, batch   337 | loss: 2.4220953MixupTrain:  epoch  0, batch   338 | loss: 2.3934932MixupTrain:  epoch  0, batch   339 | loss: 2.3049438MixupTrain:  epoch  0, batch   340 | loss: 2.4653676MixupTrain:  epoch  0, batch   341 | loss: 2.7188439MixupTrain:  epoch  0, batch   342 | loss: 2.9178052MixupTrain:  epoch  0, batch   343 | loss: 2.2145820MixupTrain:  epoch  0, batch   344 | loss: 2.2702985MixupTrain:  epoch  0, batch   345 | loss: 2.5029466MixupTrain:  epoch  0, batch   346 | loss: 2.4791906MixupTrain:  epoch  0, batch   347 | loss: 2.0029676MixupTrain:  epoch  0, batch   348 | loss: 2.3231523MixupTrain:  epoch  0, batch   349 | loss: 2.4315329MixupTrain:  epoch  0, batch   350 | loss: 2.3082144MixupTrain:  epoch  0, batch   351 | loss: 2.2693386MixupTrain:  epoch  0, batch   352 | loss: 2.3261621MixupTrain:  epoch  0, batch   353 | loss: 2.2903972MixupTrain:  epoch  0, batch   354 | loss: 2.4537747MixupTrain:  epoch  0, batch   355 | loss: 2.4248700MixupTrain:  epoch  0, batch   356 | loss: 2.3508844MixupTrain:  epoch  0, batch   357 | loss: 2.2611113MixupTrain:  epoch  0, batch   358 | loss: 2.3659244MixupTrain:  epoch  0, batch   359 | loss: 2.3098240MixupTrain:  epoch  0, batch   360 | loss: 2.3449538MixupTrain:  epoch  0, batch   361 | loss: 2.5098836MixupTrain:  epoch  0, batch   362 | loss: 2.2987659MixupTrain:  epoch  0, batch   363 | loss: 2.3012910MixupTrain:  epoch  0, batch   364 | loss: 2.1619492MixupTrain:  epoch  0, batch   365 | loss: 2.2505460MixupTrain:  epoch  0, batch   366 | loss: 2.3239064MixupTrain:  epoch  0, batch   367 | loss: 2.4553919MixupTrain:  epoch  0, batch   368 | loss: 2.1830225MixupTrain:  epoch  0, batch   369 | loss: 2.4314508MixupTrain:  epoch  0, batch   370 | loss: 2.3470259MixupTrain:  epoch  0, batch   371 | loss: 2.4306502MixupTrain:  epoch  0, batch   372 | loss: 2.4658749MixupTrain:  epoch  0, batch   373 | loss: 2.3593640MixupTrain:  epoch  0, batch   374 | loss: 2.5151200MixupTrain:  epoch  0, batch   375 | loss: 2.2419887MixupTrain:  epoch  0, batch   376 | loss: 2.5078826MixupTrain:  epoch  0, batch   377 | loss: 2.2401471MixupTrain:  epoch  0, batch   378 | loss: 2.3291421MixupTrain:  epoch  0, batch   379 | loss: 2.2906582MixupTrain:  epoch  0, batch   380 | loss: 2.4937682MixupTrain:  epoch  0, batch   381 | loss: 2.2749760MixupTrain:  epoch  0, batch   382 | loss: 2.0504167MixupTrain:  epoch  0, batch   383 | loss: 2.5577033MixupTrain:  epoch  0, batch   384 | loss: 2.5652080MixupTrain:  epoch  0, batch   385 | loss: 2.2945561MixupTrain:  epoch  0, batch   386 | loss: 2.1443019MixupTrain:  epoch  0, batch   387 | loss: 2.2257600MixupTrain:  epoch  0, batch   388 | loss: 2.3918247MixupTrain:  epoch  0, batch   389 | loss: 2.5854821MixupTrain:  epoch  0, batch   390 | loss: 2.4517570MixupTrain:  epoch  0, batch   391 | loss: 2.3915143MixupTrain:  epoch  0, batch   392 | loss: 2.2827187MixupTrain:  epoch  0, batch   393 | loss: 2.4367242MixupTrain:  epoch  0, batch   394 | loss: 2.1591024MixupTrain:  epoch  0, batch   395 | loss: 2.3426957MixupTrain:  epoch  0, batch   396 | loss: 2.3783898MixupTrain:  epoch  0, batch   397 | loss: 2.4094896MixupTrain:  epoch  0, batch   398 | loss: 2.3983967MixupTrain:  epoch  0, batch   399 | loss: 2.2801733MixupTrain:  epoch  0, batch   400 | loss: 2.4975424MixupTrain:  epoch  0, batch   401 | loss: 2.5297458MixupTrain:  epoch  0, batch   402 | loss: 2.3766971MixupTrain:  epoch  0, batch   403 | loss: 2.3830347MixupTrain:  epoch  0, batch   404 | loss: 2.2529702MixupTrain:  epoch  0, batch   405 | loss: 2.6147075MixupTrain:  epoch  0, batch   406 | loss: 2.2001889MixupTrain:  epoch  0, batch   407 | loss: 2.4007027MixupTrain:  epoch  0, batch   408 | loss: 2.3932924MixupTrain:  epoch  0, batch   409 | loss: 2.4067407MixupTrain:  epoch  0, batch   410 | loss: 2.4469948MixupTrain:  epoch  0, batch   411 | loss: 2.2401340MixupTrain:  epoch  0, batch   412 | loss: 2.3477044MixupTrain:  epoch  0, batch   413 | loss: 2.4508410MixupTrain:  epoch  0, batch   414 | loss: 2.3552682MixupTrain:  epoch  0, batch   415 | loss: 2.5493650MixupTrain:  epoch  0, batch   416 | loss: 2.1844904MixupTrain:  epoch  0, batch   417 | loss: 2.2378707MixupTrain:  epoch  0, batch   418 | loss: 2.2470605MixupTrain:  epoch  0, batch   419 | loss: 2.3929052MixupTrain:  epoch  0, batch   420 | loss: 2.1138170MixupTrain:  epoch  0, batch   421 | loss: 2.2993188MixupTrain:  epoch  0, batch   422 | loss: 2.1198683MixupTrain:  epoch  0, batch   423 | loss: 2.2221453MixupTrain:  epoch  0, batch   424 | loss: 2.4166090MixupTrain:  epoch  0, batch   425 | loss: 2.5058968MixupTrain:  epoch  0, batch   426 | loss: 2.5307961MixupTrain:  epoch  0, batch   427 | loss: 2.4621933MixupTrain:  epoch  0, batch   428 | loss: 2.3968837MixupTrain:  epoch  0, batch   429 | loss: 2.5019789MixupTrain:  epoch  0, batch   430 | loss: 2.3209605MixupTrain:  epoch  0, batch   431 | loss: 2.3094516MixupTrain:  epoch  0, batch   432 | loss: 2.4098368MixupTrain:  epoch  0, batch   433 | loss: 2.4337912MixupTrain:  epoch  0, batch   434 | loss: 2.1018460MixupTrain:  epoch  0, batch   435 | loss: 2.3706567MixupTrain:  epoch  0, batch   436 | loss: 2.3680940MixupTrain:  epoch  0, batch   437 | loss: 2.2335806MixupTrain:  epoch  0, batch   438 | loss: 2.2665858MixupTrain:  epoch  0, batch   439 | loss: 2.3204179MixupTrain:  epoch  0, batch   440 | loss: 2.1454248MixupTrain:  epoch  0, batch   441 | loss: 2.4347343MixupTrain:  epoch  0, batch   442 | loss: 2.1501713MixupTrain:  epoch  0, batch   443 | loss: 2.1481268MixupTrain:  epoch  0, batch   444 | loss: 2.6317196MixupTrain:  epoch  0, batch   445 | loss: 2.6461978MixupTrain:  epoch  0, batch   446 | loss: 2.1035581MixupTrain:  epoch  0, batch   447 | loss: 2.4023252MixupTrain:  epoch  0, batch   448 | loss: 2.4514604MixupTrain:  epoch  0, batch   449 | loss: 2.2756696MixupTrain:  epoch  0, batch   450 | loss: 2.6870322MixupTrain:  epoch  0, batch   451 | loss: 2.3575516MixupTrain:  epoch  0, batch   452 | loss: 2.1040773MixupTrain:  epoch  0, batch   453 | loss: 2.4999897MixupTrain:  epoch  0, batch   454 | loss: 2.5693746MixupTrain:  epoch  0, batch   455 | loss: 2.4072704MixupTrain:  epoch  0, batch   456 | loss: 2.6294389MixupTrain:  epoch  0, batch   457 | loss: 2.2706017MixupTrain:  epoch  0, batch   458 | loss: 2.1695819MixupTrain:  epoch  0, batch   459 | loss: 2.3311424MixupTrain:  epoch  0, batch   460 | loss: 2.1557174MixupTrain:  epoch  0, batch   461 | loss: 2.6854081MixupTrain:  epoch  0, batch   462 | loss: 2.3506470MixupTrain:  epoch  0, batch   463 | loss: 2.2048955MixupTrain:  epoch  0, batch   464 | loss: 2.6632171MixupTrain:  epoch  0, batch   465 | loss: 2.3662655MixupTrain:  epoch  0, batch   466 | loss: 2.3010848MixupTrain:  epoch  0, batch   467 | loss: 2.2145512MixupTrain:  epoch  0, batch   468 | loss: 2.5722616MixupTrain:  epoch  0, batch   469 | loss: 2.5099487MixupTrain:  epoch  0, batch   470 | loss: 2.3735597MixupTrain:  epoch  0, batch   471 | loss: 2.5983875MixupTrain:  epoch  0, batch   472 | loss: 2.2391586MixupTrain:  epoch  0, batch   473 | loss: 2.5691743MixupTrain:  epoch  0, batch   474 | loss: 2.2184024MixupTrain:  epoch  0, batch   475 | loss: 2.3491030MixupTrain:  epoch  0, batch   476 | loss: 2.5602880MixupTrain:  epoch  0, batch   477 | loss: 2.0698948MixupTrain:  epoch  0, batch   478 | loss: 2.3673682MixupTrain:  epoch  0, batch   479 | loss: 2.5074980MixupTrain:  epoch  0, batch   480 | loss: 2.5858963MixupTrain:  epoch  0, batch   481 | loss: 2.3017058MixupTrain:  epoch  0, batch   482 | loss: 2.3691034MixupTrain:  epoch  0, batch   483 | loss: 2.1523538MixupTrain:  epoch  0, batch   484 | loss: 2.2944808MixupTrain:  epoch  0, batch   485 | loss: 2.3899114MixupTrain:  epoch  0, batch   486 | loss: 2.3073359MixupTrain:  epoch  0, batch   487 | loss: 2.6536357MixupTrain:  epoch  0, batch   488 | loss: 2.5928509MixupTrain:  epoch  0, batch   489 | loss: 2.3091369MixupTrain:  epoch  0, batch   490 | loss: 2.6189299MixupTrain:  epoch  0, batch   491 | loss: 2.4966922MixupTrain:  epoch  0, batch   492 | loss: 2.4622996MixupTrain:  epoch  0, batch   493 | loss: 2.4216576MixupTrain:  epoch  0, batch   494 | loss: 2.6381130MixupTrain:  epoch  0, batch   495 | loss: 2.3380857MixupTrain:  epoch  0, batch   496 | loss: 2.2999215MixupTrain:  epoch  0, batch   497 | loss: 2.4777310MixupTrain:  epoch  0, batch   498 | loss: 2.3103287MixupTrain:  epoch  0, batch   499 | loss: 2.4759998MixupTrain:  epoch  0, batch   500 | loss: 2.2460067MixupTrain:  epoch  0, batch   501 | loss: 2.4020741MixupTrain:  epoch  0, batch   502 | loss: 2.4659991MixupTrain:  epoch  0, batch   503 | loss: 2.2615962MixupTrain:  epoch  0, batch   504 | loss: 2.3364465MixupTrain:  epoch  0, batch   505 | loss: 2.2674077MixupTrain:  epoch  0, batch   506 | loss: 2.1862156MixupTrain:  epoch  0, batch   507 | loss: 2.2885370MixupTrain:  epoch  0, batch   508 | loss: 2.5533853MixupTrain:  epoch  0, batch   509 | loss: 2.2376866MixupTrain:  epoch  0, batch   510 | loss: 2.3105235MixupTrain:  epoch  0, batch   511 | loss: 2.4231381MixupTrain:  epoch  0, batch   512 | loss: 2.6742792MixupTrain:  epoch  0, batch   513 | loss: 2.2492878MixupTrain:  epoch  0, batch   514 | loss: 2.1656780MixupTrain:  epoch  0, batch   515 | loss: 2.4551296MixupTrain:  epoch  0, batch   516 | loss: 2.3665836MixupTrain:  epoch  0, batch   517 | loss: 2.4286451MixupTrain:  epoch  0, batch   518 | loss: 2.1875467MixupTrain:  epoch  0, batch   519 | loss: 2.5395982MixupTrain:  epoch  0, batch   520 | loss: 2.1690564MixupTrain:  epoch  0, batch   521 | loss: 2.2886922MixupTrain:  epoch  0, batch   522 | loss: 2.2634487MixupTrain:  epoch  0, batch   523 | loss: 2.8228002MixupTrain:  epoch  0, batch   524 | loss: 2.2717943MixupTrain:  epoch  0, batch   525 | loss: 2.5291214MixupTrain:  epoch  0, batch   526 | loss: 2.3354535MixupTrain:  epoch  0, batch   527 | loss: 2.2889314MixupTrain:  epoch  0, batch   528 | loss: 2.4207225MixupTrain:  epoch  0, batch   529 | loss: 2.4476273MixupTrain:  epoch  0, batch   530 | loss: 2.1665468MixupTrain:  epoch  0, batch   531 | loss: 2.3710408MixupTrain:  epoch  0, batch   532 | loss: 2.1447885MixupTrain:  epoch  0, batch   533 | loss: 2.2367058MixupTrain:  epoch  0, batch   534 | loss: 2.3159838MixupTrain:  epoch  0, batch   535 | loss: 2.5640340MixupTrain:  epoch  0, batch   536 | loss: 2.3680558MixupTrain:  epoch  0, batch   537 | loss: 2.2944515MixupTrain:  epoch  0, batch   538 | loss: 2.3240397MixupTrain:  epoch  0, batch   539 | loss: 2.2578907MixupTrain:  epoch  0, batch   540 | loss: 2.2963660MixupTrain:  epoch  0, batch   541 | loss: 2.5301766MixupTrain:  epoch  0, batch   542 | loss: 2.1281314MixupTrain:  epoch  0, batch   543 | loss: 2.6410136MixupTrain:  epoch  0, batch   544 | loss: 2.3353891MixupTrain:  epoch  0, batch   545 | loss: 2.4971883MixupTrain:  epoch  0, batch   546 | loss: 2.2948318MixupTrain:  epoch  0, batch   547 | loss: 2.4726481MixupTrain:  epoch  0, batch   548 | loss: 2.3246183MixupTrain:  epoch  0, batch   549 | loss: 2.4330184MixupTrain:  epoch  0, batch   550 | loss: 2.4587409MixupTrain:  epoch  0, batch   551 | loss: 2.2919362MixupTrain:  epoch  0, batch   552 | loss: 2.2389443MixupTrain:  epoch  0, batch   553 | loss: 2.2024071MixupTrain:  epoch  0, batch   554 | loss: 2.2465715MixupTrain:  epoch  0, batch   555 | loss: 2.4149632MixupTrain:  epoch  0, batch   556 | loss: 2.5498884MixupTrain:  epoch  0, batch   557 | loss: 2.3300064MixupTrain:  epoch  0, batch   558 | loss: 2.3789959MixupTrain:  epoch  0, batch   559 | loss: 2.2919719MixupTrain:  epoch  0, batch   560 | loss: 2.1816020MixupTrain:  epoch  0, batch   561 | loss: 2.2347803MixupTrain:  epoch  0, batch   562 | loss: 2.3223782MixupTrain:  epoch  0, batch   563 | loss: 2.2067301MixupTrain:  epoch  0, batch   564 | loss: 2.3382797MixupTrain:  epoch  0, batch   565 | loss: 2.5413914MixupTrain:  epoch  0, batch   566 | loss: 2.1963415MixupTrain:  epoch  0, batch   567 | loss: 2.5093057MixupTrain:  epoch  0, batch   568 | loss: 2.2806926MixupTrain:  epoch  0, batch   569 | loss: 2.3453529MixupTrain:  epoch  0, batch   570 | loss: 2.1773055MixupTrain:  epoch  0, batch   571 | loss: 2.5490673MixupTrain:  epoch  0, batch   572 | loss: 2.0753560MixupTrain:  epoch  0, batch   573 | loss: 2.5041318MixupTrain:  epoch  0, batch   574 | loss: 2.2389061MixupTrain:  epoch  0, batch   575 | loss: 2.1862526MixupTrain:  epoch  0, batch   576 | loss: 2.5305395MixupTrain:  epoch  0, batch   577 | loss: 2.2190535MixupTrain:  epoch  0, batch   578 | loss: 2.4437504MixupTrain:  epoch  0, batch   579 | loss: 2.1632981MixupTrain:  epoch  0, batch   580 | loss: 2.6282189MixupTrain:  epoch  0, batch   581 | loss: 2.6145296MixupTrain:  epoch  0, batch   582 | loss: 2.1752930MixupTrain:  epoch  0, batch   583 | loss: 2.2571559MixupTrain:  epoch  0, batch   584 | loss: 2.3117619MixupTrain:  epoch  0, batch   585 | loss: 2.2377324MixupTrain:  epoch  0, batch   586 | loss: 2.4037104MixupTrain:  epoch  0, batch   587 | loss: 2.2044525MixupTrain:  epoch  0, batch   588 | loss: 2.2795410MixupTrain:  epoch  0, batch   589 | loss: 2.3838713MixupTrain:  epoch  0, batch   590 | loss: 2.2029374MixupTrain:  epoch  0, batch   591 | loss: 2.3835008MixupTrain:  epoch  0, batch   592 | loss: 2.2728295MixupTrain:  epoch  0, batch   593 | loss: 2.2842429MixupTrain:  epoch  0, batch   594 | loss: 2.3237214MixupTrain:  epoch  0, batch   595 | loss: 2.3302379MixupTrain:  epoch  0, batch   596 | loss: 2.6805611MixupTrain:  epoch  0, batch   597 | loss: 2.4571419MixupTrain:  epoch  0, batch   598 | loss: 2.1717176MixupTrain:  epoch  0, batch   599 | loss: 2.2276716MixupTrain:  epoch  0, batch   600 | loss: 2.4776151MixupTrain:  epoch  0, batch   601 | loss: 2.2927065MixupTrain:  epoch  0, batch   602 | loss: 2.4199252MixupTrain:  epoch  0, batch   603 | loss: 2.4543166MixupTrain:  epoch  0, batch   604 | loss: 2.3926489MixupTrain:  epoch  0, batch   605 | loss: 2.2230682MixupTrain:  epoch  0, batch   606 | loss: 2.4150705MixupTrain:  epoch  0, batch   607 | loss: 2.4797852MixupTrain:  epoch  0, batch   608 | loss: 2.3335958MixupTrain:  epoch  0, batch   609 | loss: 2.3540444MixupTrain:  epoch  0, batch   610 | loss: 2.5339584MixupTrain:  epoch  0, batch   611 | loss: 2.1991897MixupTrain:  epoch  0, batch   612 | loss: 2.5156097MixupTrain:  epoch  0, batch   613 | loss: 2.4473898MixupTrain:  epoch  0, batch   614 | loss: 2.3994141MixupTrain:  epoch  0, batch   615 | loss: 2.4825132MixupTrain:  epoch  0, batch   616 | loss: 2.1556635MixupTrain:  epoch  0, batch   617 | loss: 2.2527528MixupTrain:  epoch  0, batch   618 | loss: 2.0957296MixupTrain:  epoch  0, batch   619 | loss: 2.2639351MixupTrain:  epoch  0, batch   620 | loss: 2.5523973MixupTrain:  epoch  0, batch   621 | loss: 2.0776620MixupTrain:  epoch  0, batch   622 | loss: 2.7306228MixupTrain:  epoch  0, batch   623 | loss: 2.3476160MixupTrain:  epoch  0, batch   624 | loss: 2.2386355MixupTrain:  epoch  0, batch   625 | loss: 2.3703585MixupTrain:  epoch  0, batch   626 | loss: 2.3602533MixupTrain:  epoch  0, batch   627 | loss: 2.5865874MixupTrain:  epoch  0, batch   628 | loss: 2.5329373MixupTrain:  epoch  0, batch   629 | loss: 2.2851801MixupTrain:  epoch  0, batch   630 | loss: 2.5306075MixupTrain:  epoch  0, batch   631 | loss: 2.4192998MixupTrain:  epoch  0, batch   632 | loss: 2.3446405MixupTrain:  epoch  0, batch   633 | loss: 2.2077904MixupTrain:  epoch  0, batch   634 | loss: 2.4199214MixupTrain:  epoch  0, batch   635 | loss: 2.5580201MixupTrain:  epoch  0, batch   636 | loss: 2.3206172MixupTrain:  epoch  0, batch   637 | loss: 2.4143867MixupTrain:  epoch  0, batch   638 | loss: 2.5182929MixupTrain:  epoch  0, batch   639 | loss: 2.2233360MixupTrain:  epoch  0, batch   640 | loss: 2.2722754MixupTrain:  epoch  0, batch   641 | loss: 2.0419278MixupTrain:  epoch  0, batch   642 | loss: 2.4230928MixupTrain:  epoch  0, batch   643 | loss: 2.3236766MixupTrain:  epoch  0, batch   644 | loss: 2.3295188MixupTrain:  epoch  0, batch   645 | loss: 2.2492583MixupTrain:  epoch  0, batch   646 | loss: 2.1107481MixupTrain:  epoch  0, batch   647 | loss: 2.3538446MixupTrain:  epoch  0, batch   648 | loss: 2.7205124MixupTrain:  epoch  0, batch   649 | loss: 2.3704181MixupTrain:  epoch  0, batch   650 | loss: 2.4967961MixupTrain:  epoch  0, batch   651 | loss: 2.3434057MixupTrain:  epoch  0, batch   652 | loss: 2.2094078MixupTrain:  epoch  0, batch   653 | loss: 2.4168580MixupTrain:  epoch  0, batch   654 | loss: 2.3055229MixupTrain:  epoch  0, batch   655 | loss: 2.3303468MixupTrain:  epoch  0, batch   656 | loss: 2.4021235MixupTrain:  epoch  0, batch   657 | loss: 2.2917576MixupTrain:  epoch  0, batch   658 | loss: 2.4284666MixupTrain:  epoch  0, batch   659 | loss: 2.4551177MixupTrain:  epoch  0, batch   660 | loss: 2.2742257MixupTrain:  epoch  0, batch   661 | loss: 2.3985457MixupTrain:  epoch  0, batch   662 | loss: 2.2938719MixupTrain:  epoch  0, batch   663 | loss: 2.3072538MixupTrain:  epoch  0, batch   664 | loss: 2.4746413MixupTrain:  epoch  0, batch   665 | loss: 2.1251853MixupTrain:  epoch  0, batch   666 | loss: 2.5243266MixupTrain:  epoch  0, batch   667 | loss: 2.4762831MixupTrain:  epoch  0, batch   668 | loss: 2.4819217MixupTrain:  epoch  0, batch   669 | loss: 2.1395044MixupTrain:  epoch  0, batch   670 | loss: 2.2487195MixupTrain:  epoch  0, batch   671 | loss: 2.6465452MixupTrain:  epoch  0, batch   672 | loss: 2.2372046MixupTrain:  epoch  0, batch   673 | loss: 2.3153913MixupTrain:  epoch  0, batch   674 | loss: 2.4897022MixupTrain:  epoch  0, batch   675 | loss: 2.1045799
MemoryTrain:  epoch  0, batch     0 | loss: 2.1997457MemoryTrain:  epoch  0, batch     1 | loss: 3.1665154MemoryTrain:  epoch  0, batch     2 | loss: 2.6611197MemoryTrain:  epoch  0, batch     3 | loss: 2.6544323MemoryTrain:  epoch  0, batch     4 | loss: 3.7015307MemoryTrain:  epoch  0, batch     5 | loss: 2.3408895MemoryTrain:  epoch  0, batch     6 | loss: 2.5917509MemoryTrain:  epoch  0, batch     7 | loss: 2.5992546MemoryTrain:  epoch  1, batch     0 | loss: 1.8446152MemoryTrain:  epoch  1, batch     1 | loss: 1.8694289MemoryTrain:  epoch  1, batch     2 | loss: 1.8433502MemoryTrain:  epoch  1, batch     3 | loss: 1.8608335MemoryTrain:  epoch  1, batch     4 | loss: 1.8462825MemoryTrain:  epoch  1, batch     5 | loss: 1.8539599MemoryTrain:  epoch  1, batch     6 | loss: 1.8506263MemoryTrain:  epoch  1, batch     7 | loss: 1.8769170MemoryTrain:  epoch  2, batch     0 | loss: 1.8479943MemoryTrain:  epoch  2, batch     1 | loss: 1.8295256MemoryTrain:  epoch  2, batch     2 | loss: 1.8344913MemoryTrain:  epoch  2, batch     3 | loss: 1.8425796MemoryTrain:  epoch  2, batch     4 | loss: 1.8262411MemoryTrain:  epoch  2, batch     5 | loss: 1.8261011MemoryTrain:  epoch  2, batch     6 | loss: 1.8304992MemoryTrain:  epoch  2, batch     7 | loss: 1.8416741MemoryTrain:  epoch  3, batch     0 | loss: 1.8162689MemoryTrain:  epoch  3, batch     1 | loss: 1.8236616MemoryTrain:  epoch  3, batch     2 | loss: 1.8348353MemoryTrain:  epoch  3, batch     3 | loss: 1.8311454MemoryTrain:  epoch  3, batch     4 | loss: 1.8261187MemoryTrain:  epoch  3, batch     5 | loss: 1.8337282MemoryTrain:  epoch  3, batch     6 | loss: 1.8141170MemoryTrain:  epoch  3, batch     7 | loss: 1.8237281MemoryTrain:  epoch  4, batch     0 | loss: 1.8139136MemoryTrain:  epoch  4, batch     1 | loss: 1.8240820MemoryTrain:  epoch  4, batch     2 | loss: 1.8229766MemoryTrain:  epoch  4, batch     3 | loss: 1.8241318MemoryTrain:  epoch  4, batch     4 | loss: 1.8280065MemoryTrain:  epoch  4, batch     5 | loss: 1.8195963MemoryTrain:  epoch  4, batch     6 | loss: 1.8291812MemoryTrain:  epoch  4, batch     7 | loss: 1.8299689MemoryTrain:  epoch  5, batch     0 | loss: 1.8278227MemoryTrain:  epoch  5, batch     1 | loss: 1.8299810MemoryTrain:  epoch  5, batch     2 | loss: 1.8147616MemoryTrain:  epoch  5, batch     3 | loss: 1.8327309MemoryTrain:  epoch  5, batch     4 | loss: 1.8246489MemoryTrain:  epoch  5, batch     5 | loss: 1.8183670MemoryTrain:  epoch  5, batch     6 | loss: 1.8169314MemoryTrain:  epoch  5, batch     7 | loss: 1.8205434MemoryTrain:  epoch  6, batch     0 | loss: 1.8299215MemoryTrain:  epoch  6, batch     1 | loss: 1.8209252MemoryTrain:  epoch  6, batch     2 | loss: 1.8222630MemoryTrain:  epoch  6, batch     3 | loss: 1.8214934MemoryTrain:  epoch  6, batch     4 | loss: 1.8166342MemoryTrain:  epoch  6, batch     5 | loss: 1.8222978MemoryTrain:  epoch  6, batch     6 | loss: 1.8217891MemoryTrain:  epoch  6, batch     7 | loss: 1.8234837MemoryTrain:  epoch  7, batch     0 | loss: 1.8167558MemoryTrain:  epoch  7, batch     1 | loss: 1.8216643MemoryTrain:  epoch  7, batch     2 | loss: 1.8268499MemoryTrain:  epoch  7, batch     3 | loss: 1.8152484MemoryTrain:  epoch  7, batch     4 | loss: 1.8308365MemoryTrain:  epoch  7, batch     5 | loss: 1.8164430MemoryTrain:  epoch  7, batch     6 | loss: 1.8201847MemoryTrain:  epoch  7, batch     7 | loss: 1.8155222MemoryTrain:  epoch  8, batch     0 | loss: 1.8232166MemoryTrain:  epoch  8, batch     1 | loss: 1.8107445MemoryTrain:  epoch  8, batch     2 | loss: 1.8174459MemoryTrain:  epoch  8, batch     3 | loss: 1.8269383MemoryTrain:  epoch  8, batch     4 | loss: 1.8247712MemoryTrain:  epoch  8, batch     5 | loss: 1.8193009MemoryTrain:  epoch  8, batch     6 | loss: 1.8113253MemoryTrain:  epoch  8, batch     7 | loss: 1.8169718MemoryTrain:  epoch  9, batch     0 | loss: 1.8175569MemoryTrain:  epoch  9, batch     1 | loss: 1.8198071MemoryTrain:  epoch  9, batch     2 | loss: 1.8182137MemoryTrain:  epoch  9, batch     3 | loss: 1.8104995MemoryTrain:  epoch  9, batch     4 | loss: 1.8110192MemoryTrain:  epoch  9, batch     5 | loss: 1.8211657MemoryTrain:  epoch  9, batch     6 | loss: 1.8121253MemoryTrain:  epoch  9, batch     7 | loss: 1.8219310
[EVAL] batch:    0 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    1 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    2 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    3 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    4 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 100.00%   [EVAL] batch:    8 | acc: 93.75%,  total acc: 99.31%   [EVAL] batch:    9 | acc: 56.25%,  total acc: 95.00%   [EVAL] batch:   10 | acc: 87.50%,  total acc: 94.32%   [EVAL] batch:   11 | acc: 100.00%,  total acc: 94.79%   [EVAL] batch:   12 | acc: 68.75%,  total acc: 92.79%   [EVAL] batch:   13 | acc: 68.75%,  total acc: 91.07%   
[EVAL] batch:    0 | acc: 18.75%,  total acc: 18.75%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 28.12%   [EVAL] batch:    2 | acc: 37.50%,  total acc: 31.25%   [EVAL] batch:    3 | acc: 18.75%,  total acc: 28.12%   [EVAL] batch:    4 | acc: 12.50%,  total acc: 25.00%   [EVAL] batch:    5 | acc: 37.50%,  total acc: 27.08%   [EVAL] batch:    6 | acc: 87.50%,  total acc: 35.71%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 42.97%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 49.31%   [EVAL] batch:    9 | acc: 93.75%,  total acc: 53.75%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 57.95%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 60.94%   [EVAL] batch:   12 | acc: 50.00%,  total acc: 60.10%   [EVAL] batch:   13 | acc: 25.00%,  total acc: 57.59%   [EVAL] batch:   14 | acc: 43.75%,  total acc: 56.67%   [EVAL] batch:   15 | acc: 43.75%,  total acc: 55.86%   [EVAL] batch:   16 | acc: 68.75%,  total acc: 56.62%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 56.94%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 57.24%   [EVAL] batch:   19 | acc: 62.50%,  total acc: 57.50%   [EVAL] batch:   20 | acc: 100.00%,  total acc: 59.52%   [EVAL] batch:   21 | acc: 100.00%,  total acc: 61.36%   [EVAL] batch:   22 | acc: 100.00%,  total acc: 63.04%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 64.32%   [EVAL] batch:   24 | acc: 100.00%,  total acc: 65.75%   [EVAL] batch:   25 | acc: 100.00%,  total acc: 67.07%   [EVAL] batch:   26 | acc: 93.75%,  total acc: 68.06%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 69.20%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 70.26%   [EVAL] batch:   29 | acc: 81.25%,  total acc: 70.62%   [EVAL] batch:   30 | acc: 87.50%,  total acc: 71.17%   [EVAL] batch:   31 | acc: 93.75%,  total acc: 71.88%   [EVAL] batch:   32 | acc: 56.25%,  total acc: 71.40%   [EVAL] batch:   33 | acc: 37.50%,  total acc: 70.40%   [EVAL] batch:   34 | acc: 31.25%,  total acc: 69.29%   [EVAL] batch:   35 | acc: 25.00%,  total acc: 68.06%   [EVAL] batch:   36 | acc: 50.00%,  total acc: 67.57%   [EVAL] batch:   37 | acc: 6.25%,  total acc: 65.95%   [EVAL] batch:   38 | acc: 50.00%,  total acc: 65.54%   [EVAL] batch:   39 | acc: 81.25%,  total acc: 65.94%   [EVAL] batch:   40 | acc: 50.00%,  total acc: 65.55%   [EVAL] batch:   41 | acc: 31.25%,  total acc: 64.73%   [EVAL] batch:   42 | acc: 43.75%,  total acc: 64.24%   [EVAL] batch:   43 | acc: 75.00%,  total acc: 64.49%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 65.28%   [EVAL] batch:   45 | acc: 100.00%,  total acc: 66.03%   [EVAL] batch:   46 | acc: 100.00%,  total acc: 66.76%   [EVAL] batch:   47 | acc: 100.00%,  total acc: 67.45%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 68.11%   [EVAL] batch:   49 | acc: 93.75%,  total acc: 68.62%   [EVAL] batch:   50 | acc: 87.50%,  total acc: 69.00%   [EVAL] batch:   51 | acc: 87.50%,  total acc: 69.35%   [EVAL] batch:   52 | acc: 87.50%,  total acc: 69.69%   [EVAL] batch:   53 | acc: 93.75%,  total acc: 70.14%   [EVAL] batch:   54 | acc: 87.50%,  total acc: 70.45%   [EVAL] batch:   55 | acc: 81.25%,  total acc: 70.65%   [EVAL] batch:   56 | acc: 87.50%,  total acc: 70.94%   [EVAL] batch:   57 | acc: 93.75%,  total acc: 71.34%   [EVAL] batch:   58 | acc: 87.50%,  total acc: 71.61%   [EVAL] batch:   59 | acc: 87.50%,  total acc: 71.88%   [EVAL] batch:   60 | acc: 75.00%,  total acc: 71.93%   [EVAL] batch:   61 | acc: 81.25%,  total acc: 72.08%   [EVAL] batch:   62 | acc: 81.25%,  total acc: 72.22%   [EVAL] batch:   63 | acc: 81.25%,  total acc: 72.36%   [EVAL] batch:   64 | acc: 100.00%,  total acc: 72.79%   [EVAL] batch:   65 | acc: 100.00%,  total acc: 73.20%   [EVAL] batch:   66 | acc: 100.00%,  total acc: 73.60%   [EVAL] batch:   67 | acc: 100.00%,  total acc: 73.99%   [EVAL] batch:   68 | acc: 100.00%,  total acc: 74.37%   [EVAL] batch:   69 | acc: 100.00%,  total acc: 74.73%   [EVAL] batch:   70 | acc: 100.00%,  total acc: 75.09%   [EVAL] batch:   71 | acc: 100.00%,  total acc: 75.43%   [EVAL] batch:   72 | acc: 56.25%,  total acc: 75.17%   [EVAL] batch:   73 | acc: 81.25%,  total acc: 75.25%   [EVAL] batch:   74 | acc: 100.00%,  total acc: 75.58%   [EVAL] batch:   75 | acc: 75.00%,  total acc: 75.58%   [EVAL] batch:   76 | acc: 87.50%,  total acc: 75.73%   [EVAL] batch:   77 | acc: 6.25%,  total acc: 74.84%   
cur_acc:  ['0.8693', '0.9132', '0.8929', '0.9107']
his_acc:  ['0.8693', '0.8550', '0.8311', '0.7484']
CurrentTrain: epoch  0, batch     0 | loss: 3.4375219CurrentTrain: epoch  0, batch     1 | loss: 5.3626809CurrentTrain: epoch  1, batch     0 | loss: 4.1058903CurrentTrain: epoch  1, batch     1 | loss: 3.1421814CurrentTrain: epoch  2, batch     0 | loss: 2.9440176CurrentTrain: epoch  2, batch     1 | loss: 2.9096024CurrentTrain: epoch  3, batch     0 | loss: 2.3051953CurrentTrain: epoch  3, batch     1 | loss: 2.7394748CurrentTrain: epoch  4, batch     0 | loss: 2.3934686CurrentTrain: epoch  4, batch     1 | loss: 1.9404166CurrentTrain: epoch  5, batch     0 | loss: 2.2086642CurrentTrain: epoch  5, batch     1 | loss: 1.9780995CurrentTrain: epoch  6, batch     0 | loss: 2.0682974CurrentTrain: epoch  6, batch     1 | loss: 1.8895680CurrentTrain: epoch  7, batch     0 | loss: 1.9992920CurrentTrain: epoch  7, batch     1 | loss: 1.8244087CurrentTrain: epoch  8, batch     0 | loss: 1.9159756CurrentTrain: epoch  8, batch     1 | loss: 1.7505597CurrentTrain: epoch  9, batch     0 | loss: 1.7540653CurrentTrain: epoch  9, batch     1 | loss: 1.8739741
#### person cause of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person cause of death" means a person was died of an event.
Here is an example:
Relation: person cause of death
Context: mr scheider had suffered from multiple myeloma for several years , and died of complications from a staph infection , his wife , brenda siemer , said .
Head Entity: mr scheider
Tail Entity: complications from a staph infection
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person cause of death":
Relation: person cause of death  
Context: after battling with lung cancer for over a year, john doe passed away peacefully in his sleep, surrounded by family.  
Head Entity: john doe  
Tail Entity: lung cancer  

Relation: person cause of death  
Context: the renowned scientist, dr. emily white, tragically lost her life due to a car accident while returning from a conference.  
Head Entity: dr. emily white  
Tail Entity: car accident  

Relation: person cause of death  
Context: following a long struggle with heart disease, mr. thomas jones succumbed to his illness last night at the hospital.  
Head Entity: mr. thomas jones  
Tail Entity: heart disease  

Relation: person cause of death  
Context: the beloved actor, samuel green, died from a drug overdose, shocking fans and colleagues alike.  
Head Entity: samuel green  
Tail Entity: drug overdose  

Relation: person cause of death  
Context: after a courageous fight against diabetes complications, mrs. linda brown passed away, leaving behind a legacy of kindness.  
Head Entity: mrs. linda brown  
Tail Entity: diabetes complications  
#### organization political religious affiliation ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization political religious affiliation" means an organization is the member of a religion.
Here is an example:
Relation: organization political religious affiliation
Context: clashes in late august in karbala between the mahdi army and a rival shiite militia , the badr organization , left at least 50 people dead .
Head Entity: badr organization
Tail Entity: shiite
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization political religious affiliation":
Relation: organization political religious affiliation  
Context: The recent conference held by the Islamic Society of North America aimed to strengthen ties between various Muslim organizations and promote interfaith dialogue.  
Head Entity: Islamic Society of North America  
Tail Entity: Islam  

Relation: organization political religious affiliation  
Context: The Catholic Church has been actively involved in various social justice initiatives, reflecting its commitment to the teachings of Christianity.  
Head Entity: Catholic Church  
Tail Entity: Christianity  

Relation: organization political religious affiliation  
Context: The Jewish Federation of Greater Los Angeles has launched several programs to support the local Jewish community and promote Jewish values.  
Head Entity: Jewish Federation of Greater Los Angeles  
Tail Entity: Judaism  

Relation: organization political religious affiliation  
Context: The World Sikh Organization has been advocating for the rights of Sikhs globally, emphasizing the importance of Sikh principles in their mission.  
Head Entity: World Sikh Organization  
Tail Entity: Sikhism  

Relation: organization political religious affiliation  
Context: The National Council of Churches has been working to unite various Christian denominations in addressing social issues and promoting peace.  
Head Entity: National Council of Churches  
Tail Entity: Christianity  
#### organization stateorprovince of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization stateorprovince of headquarters" means an organization is located in a state or province.
Here is an example:
Relation: organization stateorprovince of headquarters
Context: washington , nov 30 -lrb- xinhua -rrb- -- nasa has skipped space shuttle endeavour 's second landing opportunity at kennedy space center in florida on sunday afternoon due to bad weather , according to nasa tv .
Head Entity: kennedy space center
Tail Entity: florida
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization stateorprovince of headquarters":
Relation: organization stateorprovince of headquarters  
Context: the headquarters of the multinational technology company is located in cupertino, california, where it has been a significant player in the tech industry for decades.  
Head Entity: multinational technology company  
Tail Entity: california  

Relation: organization stateorprovince of headquarters  
Context: after years of expansion, the non-profit organization has established its main office in a historic building in downtown boston, massachusetts.  
Head Entity: non-profit organization  
Tail Entity: massachusetts  

Relation: organization stateorprovince of headquarters  
Context: the famous coffee chain has its corporate headquarters situated in seattle, washington, which is known for its vibrant coffee culture.  
Head Entity: coffee chain  
Tail Entity: washington  

Relation: organization stateorprovince of headquarters  
Context: the automotive manufacturer announced that its new headquarters will be built in a suburban area of detroit, michigan, to better serve its operations.  
Head Entity: automotive manufacturer  
Tail Entity: michigan  

Relation: organization stateorprovince of headquarters  
Context: the global consulting firm has moved its headquarters to a modern office space in new york city, new york, to attract top talent.  
Head Entity: global consulting firm  
Tail Entity: new york  
#### person other family ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person other family" means a person 's relative is a person.
Here is an example:
Relation: person other family
Context: parren mitchell 's sister-in-law , juanita jackson mitchell , was the long - time head and legal counsel of the maryland naacp .
Head Entity: parren mitchell
Tail Entity: juanita jackson mitchell
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person other family":
Relation: person other family  
Context: The famous actor, Tom Hanks, has a brother named Jim Hanks who is also involved in the film industry.  
Head Entity: Tom Hanks  
Tail Entity: Jim Hanks  

Relation: person other family  
Context: In her memoir, Michelle Obama writes about her close relationship with her brother, Craig Robinson, who has always been her support system.  
Head Entity: Michelle Obama  
Tail Entity: Craig Robinson  

Relation: person other family  
Context: During the family reunion, Sarah introduced her cousin, Emily, who had just returned from studying abroad.  
Head Entity: Sarah  
Tail Entity: Emily  

Relation: person other family  
Context: The renowned scientist, Albert Einstein, had a sister named Maria, who played a significant role in his early life.  
Head Entity: Albert Einstein  
Tail Entity: Maria Einstein  

Relation: person other family  
Context: At the wedding, John was thrilled to see his uncle, who had traveled from overseas to celebrate the special day.  
Head Entity: John  
Tail Entity: Uncle
#### person city of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person city of death" means a person was died in a city.
Here is an example:
Relation: person city of death
Context: irene morgan kirkaldy , 90 , who died of alzheimer 's disease aug. 10 at her home in gloucester , va. , quietly changed history in 1944 when she refused to give up her seat on a crowded greyhound bus to a white couple .
Head Entity: her
Tail Entity: gloucester
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person city of death":
Relation: person city of death  
Context: john smith, a renowned author, passed away on march 5 in his apartment located in new york city, leaving behind a legacy of literary works that inspired many.  
Head Entity: john smith  
Tail Entity: new york city  

Relation: person city of death  
Context: after a long battle with cancer, elizabeth taylor died on march 23 at a hospital in los angeles, where she had spent her final days surrounded by family and friends.  
Head Entity: elizabeth taylor  
Tail Entity: los angeles  

Relation: person city of death  
Context: the famous physicist, albert einstein, died on april 18, 1955, in princeton, new jersey, where he had lived for many years while working at the institute for advanced study.  
Head Entity: albert einstein  
Tail Entity: princeton  

Relation: person city of death  
Context: on january 1, 2020, the beloved actor, kobe bryant, tragically lost his life in a helicopter crash in calabasas, california, shocking fans around the world.  
Head Entity: kobe bryant  
Tail Entity: calabasas  

Relation: person city of death  
Context: the legendary musician, freddie mercury, passed away on november 24, 1991, at his home in london, england, leaving a profound impact on the music industry.  
Head Entity: freddie mercury  
Tail Entity: london  
Mixup data size:  15700
MixupTrain:  epoch  0, batch     0 | loss: 5.1188107MixupTrain:  epoch  0, batch     1 | loss: 3.9885263MixupTrain:  epoch  0, batch     2 | loss: 3.9921865MixupTrain:  epoch  0, batch     3 | loss: 4.5180211MixupTrain:  epoch  0, batch     4 | loss: 4.5526710MixupTrain:  epoch  0, batch     5 | loss: 3.8974500MixupTrain:  epoch  0, batch     6 | loss: 3.4716964MixupTrain:  epoch  0, batch     7 | loss: 4.1538677MixupTrain:  epoch  0, batch     8 | loss: 4.6819582MixupTrain:  epoch  0, batch     9 | loss: 3.5095623MixupTrain:  epoch  0, batch    10 | loss: 4.1615338MixupTrain:  epoch  0, batch    11 | loss: 4.6750941MixupTrain:  epoch  0, batch    12 | loss: 3.6802979MixupTrain:  epoch  0, batch    13 | loss: 3.9666457MixupTrain:  epoch  0, batch    14 | loss: 3.9253824MixupTrain:  epoch  0, batch    15 | loss: 4.0310674MixupTrain:  epoch  0, batch    16 | loss: 3.7002342MixupTrain:  epoch  0, batch    17 | loss: 3.9757385MixupTrain:  epoch  0, batch    18 | loss: 4.3221874MixupTrain:  epoch  0, batch    19 | loss: 3.4329767MixupTrain:  epoch  0, batch    20 | loss: 3.7991881MixupTrain:  epoch  0, batch    21 | loss: 3.7421093MixupTrain:  epoch  0, batch    22 | loss: 3.9374201MixupTrain:  epoch  0, batch    23 | loss: 3.4656768MixupTrain:  epoch  0, batch    24 | loss: 3.2996001MixupTrain:  epoch  0, batch    25 | loss: 3.1071110MixupTrain:  epoch  0, batch    26 | loss: 4.0038681MixupTrain:  epoch  0, batch    27 | loss: 3.3413887MixupTrain:  epoch  0, batch    28 | loss: 3.2640584MixupTrain:  epoch  0, batch    29 | loss: 3.5373938MixupTrain:  epoch  0, batch    30 | loss: 3.7103751MixupTrain:  epoch  0, batch    31 | loss: 3.0939815MixupTrain:  epoch  0, batch    32 | loss: 3.7217741MixupTrain:  epoch  0, batch    33 | loss: 3.2222600MixupTrain:  epoch  0, batch    34 | loss: 3.4861307MixupTrain:  epoch  0, batch    35 | loss: 2.5745468MixupTrain:  epoch  0, batch    36 | loss: 3.5450339MixupTrain:  epoch  0, batch    37 | loss: 3.8090997MixupTrain:  epoch  0, batch    38 | loss: 3.6180658MixupTrain:  epoch  0, batch    39 | loss: 3.0122366MixupTrain:  epoch  0, batch    40 | loss: 3.2305493MixupTrain:  epoch  0, batch    41 | loss: 3.4459858MixupTrain:  epoch  0, batch    42 | loss: 3.1744537MixupTrain:  epoch  0, batch    43 | loss: 3.0091186MixupTrain:  epoch  0, batch    44 | loss: 3.7705030MixupTrain:  epoch  0, batch    45 | loss: 2.9238553MixupTrain:  epoch  0, batch    46 | loss: 3.0376694MixupTrain:  epoch  0, batch    47 | loss: 2.6397405MixupTrain:  epoch  0, batch    48 | loss: 3.1508603MixupTrain:  epoch  0, batch    49 | loss: 3.2386961MixupTrain:  epoch  0, batch    50 | loss: 3.0059893MixupTrain:  epoch  0, batch    51 | loss: 3.5383158MixupTrain:  epoch  0, batch    52 | loss: 2.9209714MixupTrain:  epoch  0, batch    53 | loss: 2.5807652MixupTrain:  epoch  0, batch    54 | loss: 2.6729932MixupTrain:  epoch  0, batch    55 | loss: 2.6520090MixupTrain:  epoch  0, batch    56 | loss: 2.9078436MixupTrain:  epoch  0, batch    57 | loss: 3.1554976MixupTrain:  epoch  0, batch    58 | loss: 3.5751863MixupTrain:  epoch  0, batch    59 | loss: 2.7118378MixupTrain:  epoch  0, batch    60 | loss: 3.1552625MixupTrain:  epoch  0, batch    61 | loss: 3.0130711MixupTrain:  epoch  0, batch    62 | loss: 3.2193599MixupTrain:  epoch  0, batch    63 | loss: 2.9234579MixupTrain:  epoch  0, batch    64 | loss: 2.7898095MixupTrain:  epoch  0, batch    65 | loss: 2.9387469MixupTrain:  epoch  0, batch    66 | loss: 3.8713915MixupTrain:  epoch  0, batch    67 | loss: 3.2886572MixupTrain:  epoch  0, batch    68 | loss: 2.7900410MixupTrain:  epoch  0, batch    69 | loss: 2.9154396MixupTrain:  epoch  0, batch    70 | loss: 3.2408998MixupTrain:  epoch  0, batch    71 | loss: 2.6867919MixupTrain:  epoch  0, batch    72 | loss: 2.5778942MixupTrain:  epoch  0, batch    73 | loss: 3.1166801MixupTrain:  epoch  0, batch    74 | loss: 2.6117077MixupTrain:  epoch  0, batch    75 | loss: 2.6346998MixupTrain:  epoch  0, batch    76 | loss: 2.5122542MixupTrain:  epoch  0, batch    77 | loss: 3.5574703MixupTrain:  epoch  0, batch    78 | loss: 2.3209031MixupTrain:  epoch  0, batch    79 | loss: 2.5891643MixupTrain:  epoch  0, batch    80 | loss: 2.5688980MixupTrain:  epoch  0, batch    81 | loss: 2.7282789MixupTrain:  epoch  0, batch    82 | loss: 2.4591496MixupTrain:  epoch  0, batch    83 | loss: 2.8697011MixupTrain:  epoch  0, batch    84 | loss: 3.1046152MixupTrain:  epoch  0, batch    85 | loss: 2.4376922MixupTrain:  epoch  0, batch    86 | loss: 2.8030035MixupTrain:  epoch  0, batch    87 | loss: 2.6841908MixupTrain:  epoch  0, batch    88 | loss: 3.0936184MixupTrain:  epoch  0, batch    89 | loss: 2.4046493MixupTrain:  epoch  0, batch    90 | loss: 2.8942068MixupTrain:  epoch  0, batch    91 | loss: 2.9180930MixupTrain:  epoch  0, batch    92 | loss: 2.7854409MixupTrain:  epoch  0, batch    93 | loss: 3.0937843MixupTrain:  epoch  0, batch    94 | loss: 2.6543510MixupTrain:  epoch  0, batch    95 | loss: 3.0523410MixupTrain:  epoch  0, batch    96 | loss: 2.7234387MixupTrain:  epoch  0, batch    97 | loss: 2.6812451MixupTrain:  epoch  0, batch    98 | loss: 2.3063803MixupTrain:  epoch  0, batch    99 | loss: 2.3706808MixupTrain:  epoch  0, batch   100 | loss: 2.9719810MixupTrain:  epoch  0, batch   101 | loss: 3.5983281MixupTrain:  epoch  0, batch   102 | loss: 2.9484658MixupTrain:  epoch  0, batch   103 | loss: 2.7244701MixupTrain:  epoch  0, batch   104 | loss: 2.6092334MixupTrain:  epoch  0, batch   105 | loss: 2.7110994MixupTrain:  epoch  0, batch   106 | loss: 2.7899888MixupTrain:  epoch  0, batch   107 | loss: 3.2163491MixupTrain:  epoch  0, batch   108 | loss: 2.6637435MixupTrain:  epoch  0, batch   109 | loss: 2.4812055MixupTrain:  epoch  0, batch   110 | loss: 2.5912199MixupTrain:  epoch  0, batch   111 | loss: 2.7628207MixupTrain:  epoch  0, batch   112 | loss: 2.5443356MixupTrain:  epoch  0, batch   113 | loss: 2.3509192MixupTrain:  epoch  0, batch   114 | loss: 2.4364285MixupTrain:  epoch  0, batch   115 | loss: 3.0533881MixupTrain:  epoch  0, batch   116 | loss: 2.3515968MixupTrain:  epoch  0, batch   117 | loss: 2.6852612MixupTrain:  epoch  0, batch   118 | loss: 2.3889613MixupTrain:  epoch  0, batch   119 | loss: 2.7483809MixupTrain:  epoch  0, batch   120 | loss: 3.0037413MixupTrain:  epoch  0, batch   121 | loss: 2.5623035MixupTrain:  epoch  0, batch   122 | loss: 2.9916744MixupTrain:  epoch  0, batch   123 | loss: 2.8313599MixupTrain:  epoch  0, batch   124 | loss: 2.6321239MixupTrain:  epoch  0, batch   125 | loss: 2.8318501MixupTrain:  epoch  0, batch   126 | loss: 2.5963049MixupTrain:  epoch  0, batch   127 | loss: 2.6118565MixupTrain:  epoch  0, batch   128 | loss: 2.4422238MixupTrain:  epoch  0, batch   129 | loss: 2.5433965MixupTrain:  epoch  0, batch   130 | loss: 2.6207368MixupTrain:  epoch  0, batch   131 | loss: 2.6871850MixupTrain:  epoch  0, batch   132 | loss: 2.7878759MixupTrain:  epoch  0, batch   133 | loss: 2.2307568MixupTrain:  epoch  0, batch   134 | loss: 2.5650866MixupTrain:  epoch  0, batch   135 | loss: 2.6181436MixupTrain:  epoch  0, batch   136 | loss: 2.8639960MixupTrain:  epoch  0, batch   137 | loss: 2.2301314MixupTrain:  epoch  0, batch   138 | loss: 2.7861142MixupTrain:  epoch  0, batch   139 | loss: 2.4872739MixupTrain:  epoch  0, batch   140 | loss: 2.6703768MixupTrain:  epoch  0, batch   141 | loss: 2.2074292MixupTrain:  epoch  0, batch   142 | loss: 2.9351630MixupTrain:  epoch  0, batch   143 | loss: 2.7542338MixupTrain:  epoch  0, batch   144 | loss: 2.5213351MixupTrain:  epoch  0, batch   145 | loss: 2.5926089MixupTrain:  epoch  0, batch   146 | loss: 2.3246825MixupTrain:  epoch  0, batch   147 | loss: 2.5893846MixupTrain:  epoch  0, batch   148 | loss: 2.7812350MixupTrain:  epoch  0, batch   149 | loss: 2.4679728MixupTrain:  epoch  0, batch   150 | loss: 2.4316828MixupTrain:  epoch  0, batch   151 | loss: 3.4389334MixupTrain:  epoch  0, batch   152 | loss: 2.6136198MixupTrain:  epoch  0, batch   153 | loss: 2.0448177MixupTrain:  epoch  0, batch   154 | loss: 2.5144522MixupTrain:  epoch  0, batch   155 | loss: 2.5449247MixupTrain:  epoch  0, batch   156 | loss: 2.5415316MixupTrain:  epoch  0, batch   157 | loss: 2.6561127MixupTrain:  epoch  0, batch   158 | loss: 2.6341991MixupTrain:  epoch  0, batch   159 | loss: 2.5959678MixupTrain:  epoch  0, batch   160 | loss: 2.8538761MixupTrain:  epoch  0, batch   161 | loss: 2.4123135MixupTrain:  epoch  0, batch   162 | loss: 2.3950844MixupTrain:  epoch  0, batch   163 | loss: 2.8673689MixupTrain:  epoch  0, batch   164 | loss: 3.1947711MixupTrain:  epoch  0, batch   165 | loss: 2.4914393MixupTrain:  epoch  0, batch   166 | loss: 2.3916316MixupTrain:  epoch  0, batch   167 | loss: 2.9232178MixupTrain:  epoch  0, batch   168 | loss: 2.5153384MixupTrain:  epoch  0, batch   169 | loss: 2.6800804MixupTrain:  epoch  0, batch   170 | loss: 2.5460372MixupTrain:  epoch  0, batch   171 | loss: 2.6450315MixupTrain:  epoch  0, batch   172 | loss: 2.8939276MixupTrain:  epoch  0, batch   173 | loss: 2.5948396MixupTrain:  epoch  0, batch   174 | loss: 2.2615173MixupTrain:  epoch  0, batch   175 | loss: 2.1665828MixupTrain:  epoch  0, batch   176 | loss: 2.5265579MixupTrain:  epoch  0, batch   177 | loss: 2.4896994MixupTrain:  epoch  0, batch   178 | loss: 2.4738755MixupTrain:  epoch  0, batch   179 | loss: 2.4014812MixupTrain:  epoch  0, batch   180 | loss: 2.4892814MixupTrain:  epoch  0, batch   181 | loss: 2.4241247MixupTrain:  epoch  0, batch   182 | loss: 2.2084093MixupTrain:  epoch  0, batch   183 | loss: 2.5720415MixupTrain:  epoch  0, batch   184 | loss: 2.4645009MixupTrain:  epoch  0, batch   185 | loss: 2.0852399MixupTrain:  epoch  0, batch   186 | loss: 2.7926030MixupTrain:  epoch  0, batch   187 | loss: 2.4719009MixupTrain:  epoch  0, batch   188 | loss: 2.5085247MixupTrain:  epoch  0, batch   189 | loss: 2.5259964MixupTrain:  epoch  0, batch   190 | loss: 2.4155545MixupTrain:  epoch  0, batch   191 | loss: 2.6814132MixupTrain:  epoch  0, batch   192 | loss: 2.6436641MixupTrain:  epoch  0, batch   193 | loss: 2.6312134MixupTrain:  epoch  0, batch   194 | loss: 2.7070217MixupTrain:  epoch  0, batch   195 | loss: 2.9973598MixupTrain:  epoch  0, batch   196 | loss: 2.1729374MixupTrain:  epoch  0, batch   197 | loss: 2.7963560MixupTrain:  epoch  0, batch   198 | loss: 2.4261136MixupTrain:  epoch  0, batch   199 | loss: 2.3271387MixupTrain:  epoch  0, batch   200 | loss: 2.2967558MixupTrain:  epoch  0, batch   201 | loss: 2.3962202MixupTrain:  epoch  0, batch   202 | loss: 2.8241010MixupTrain:  epoch  0, batch   203 | loss: 2.5735023MixupTrain:  epoch  0, batch   204 | loss: 2.5484991MixupTrain:  epoch  0, batch   205 | loss: 2.5188680MixupTrain:  epoch  0, batch   206 | loss: 2.8474369MixupTrain:  epoch  0, batch   207 | loss: 2.2907495MixupTrain:  epoch  0, batch   208 | loss: 2.2439637MixupTrain:  epoch  0, batch   209 | loss: 2.5569489MixupTrain:  epoch  0, batch   210 | loss: 2.2175035MixupTrain:  epoch  0, batch   211 | loss: 2.2493277MixupTrain:  epoch  0, batch   212 | loss: 2.3963704MixupTrain:  epoch  0, batch   213 | loss: 2.2168012MixupTrain:  epoch  0, batch   214 | loss: 2.1818881MixupTrain:  epoch  0, batch   215 | loss: 2.3783069MixupTrain:  epoch  0, batch   216 | loss: 2.0814950MixupTrain:  epoch  0, batch   217 | loss: 2.6211228MixupTrain:  epoch  0, batch   218 | loss: 2.3454902MixupTrain:  epoch  0, batch   219 | loss: 2.6641016MixupTrain:  epoch  0, batch   220 | loss: 2.6776600MixupTrain:  epoch  0, batch   221 | loss: 2.6117113MixupTrain:  epoch  0, batch   222 | loss: 2.3854423MixupTrain:  epoch  0, batch   223 | loss: 2.4182551MixupTrain:  epoch  0, batch   224 | loss: 2.3918204MixupTrain:  epoch  0, batch   225 | loss: 2.3580670MixupTrain:  epoch  0, batch   226 | loss: 2.4438896MixupTrain:  epoch  0, batch   227 | loss: 2.6684213MixupTrain:  epoch  0, batch   228 | loss: 2.3299541MixupTrain:  epoch  0, batch   229 | loss: 2.1706395MixupTrain:  epoch  0, batch   230 | loss: 2.3569570MixupTrain:  epoch  0, batch   231 | loss: 2.3708217MixupTrain:  epoch  0, batch   232 | loss: 2.4217286MixupTrain:  epoch  0, batch   233 | loss: 2.9441900MixupTrain:  epoch  0, batch   234 | loss: 2.4395442MixupTrain:  epoch  0, batch   235 | loss: 2.1874723MixupTrain:  epoch  0, batch   236 | loss: 2.3698325MixupTrain:  epoch  0, batch   237 | loss: 2.3157384MixupTrain:  epoch  0, batch   238 | loss: 2.3201351MixupTrain:  epoch  0, batch   239 | loss: 2.3338456MixupTrain:  epoch  0, batch   240 | loss: 2.3708365MixupTrain:  epoch  0, batch   241 | loss: 2.5701716MixupTrain:  epoch  0, batch   242 | loss: 2.6303449MixupTrain:  epoch  0, batch   243 | loss: 2.1818833MixupTrain:  epoch  0, batch   244 | loss: 2.3296270MixupTrain:  epoch  0, batch   245 | loss: 2.6126308MixupTrain:  epoch  0, batch   246 | loss: 2.3713851MixupTrain:  epoch  0, batch   247 | loss: 2.0723236MixupTrain:  epoch  0, batch   248 | loss: 2.2787638MixupTrain:  epoch  0, batch   249 | loss: 2.4625399MixupTrain:  epoch  0, batch   250 | loss: 2.4529052MixupTrain:  epoch  0, batch   251 | loss: 2.6531181MixupTrain:  epoch  0, batch   252 | loss: 2.5379746MixupTrain:  epoch  0, batch   253 | loss: 2.8386145MixupTrain:  epoch  0, batch   254 | loss: 2.2740245MixupTrain:  epoch  0, batch   255 | loss: 2.7241583MixupTrain:  epoch  0, batch   256 | loss: 2.0166843MixupTrain:  epoch  0, batch   257 | loss: 2.4254019MixupTrain:  epoch  0, batch   258 | loss: 2.2152841MixupTrain:  epoch  0, batch   259 | loss: 2.4490399MixupTrain:  epoch  0, batch   260 | loss: 2.5758510MixupTrain:  epoch  0, batch   261 | loss: 2.7028840MixupTrain:  epoch  0, batch   262 | loss: 2.7738228MixupTrain:  epoch  0, batch   263 | loss: 2.5551102MixupTrain:  epoch  0, batch   264 | loss: 2.5737162MixupTrain:  epoch  0, batch   265 | loss: 2.2464654MixupTrain:  epoch  0, batch   266 | loss: 2.3518271MixupTrain:  epoch  0, batch   267 | loss: 2.4051185MixupTrain:  epoch  0, batch   268 | loss: 2.5180576MixupTrain:  epoch  0, batch   269 | loss: 2.7109113MixupTrain:  epoch  0, batch   270 | loss: 2.3395591MixupTrain:  epoch  0, batch   271 | loss: 2.5075655MixupTrain:  epoch  0, batch   272 | loss: 2.6698265MixupTrain:  epoch  0, batch   273 | loss: 2.7180793MixupTrain:  epoch  0, batch   274 | loss: 2.8448937MixupTrain:  epoch  0, batch   275 | loss: 2.3729842MixupTrain:  epoch  0, batch   276 | loss: 2.3603241MixupTrain:  epoch  0, batch   277 | loss: 2.4388127MixupTrain:  epoch  0, batch   278 | loss: 2.3121400MixupTrain:  epoch  0, batch   279 | loss: 2.3508930MixupTrain:  epoch  0, batch   280 | loss: 2.2854681MixupTrain:  epoch  0, batch   281 | loss: 2.2983284MixupTrain:  epoch  0, batch   282 | loss: 2.3646972MixupTrain:  epoch  0, batch   283 | loss: 2.5631912MixupTrain:  epoch  0, batch   284 | loss: 2.5041065MixupTrain:  epoch  0, batch   285 | loss: 2.4125261MixupTrain:  epoch  0, batch   286 | loss: 2.3145390MixupTrain:  epoch  0, batch   287 | loss: 2.2845688MixupTrain:  epoch  0, batch   288 | loss: 2.4110022MixupTrain:  epoch  0, batch   289 | loss: 2.1605420MixupTrain:  epoch  0, batch   290 | loss: 2.5250602MixupTrain:  epoch  0, batch   291 | loss: 2.7726927MixupTrain:  epoch  0, batch   292 | loss: 2.2505808MixupTrain:  epoch  0, batch   293 | loss: 2.5118506MixupTrain:  epoch  0, batch   294 | loss: 2.9037907MixupTrain:  epoch  0, batch   295 | loss: 2.5669963MixupTrain:  epoch  0, batch   296 | loss: 2.2806520MixupTrain:  epoch  0, batch   297 | loss: 2.2859263MixupTrain:  epoch  0, batch   298 | loss: 2.7641068MixupTrain:  epoch  0, batch   299 | loss: 2.3945346MixupTrain:  epoch  0, batch   300 | loss: 2.4542022MixupTrain:  epoch  0, batch   301 | loss: 2.5215781MixupTrain:  epoch  0, batch   302 | loss: 2.4230428MixupTrain:  epoch  0, batch   303 | loss: 2.8132174MixupTrain:  epoch  0, batch   304 | loss: 2.1575298MixupTrain:  epoch  0, batch   305 | loss: 2.3923113MixupTrain:  epoch  0, batch   306 | loss: 3.0398953MixupTrain:  epoch  0, batch   307 | loss: 2.4795537MixupTrain:  epoch  0, batch   308 | loss: 2.4342461MixupTrain:  epoch  0, batch   309 | loss: 2.6439345MixupTrain:  epoch  0, batch   310 | loss: 2.4653819MixupTrain:  epoch  0, batch   311 | loss: 2.0815415MixupTrain:  epoch  0, batch   312 | loss: 2.2169547MixupTrain:  epoch  0, batch   313 | loss: 2.4523695MixupTrain:  epoch  0, batch   314 | loss: 2.4831882MixupTrain:  epoch  0, batch   315 | loss: 2.3018374MixupTrain:  epoch  0, batch   316 | loss: 2.2848461MixupTrain:  epoch  0, batch   317 | loss: 2.2403760MixupTrain:  epoch  0, batch   318 | loss: 2.1764879MixupTrain:  epoch  0, batch   319 | loss: 2.2195110MixupTrain:  epoch  0, batch   320 | loss: 2.3864396MixupTrain:  epoch  0, batch   321 | loss: 2.4289348MixupTrain:  epoch  0, batch   322 | loss: 2.5016816MixupTrain:  epoch  0, batch   323 | loss: 2.2311492MixupTrain:  epoch  0, batch   324 | loss: 2.5001540MixupTrain:  epoch  0, batch   325 | loss: 2.4821005MixupTrain:  epoch  0, batch   326 | loss: 2.3565454MixupTrain:  epoch  0, batch   327 | loss: 2.2756028MixupTrain:  epoch  0, batch   328 | loss: 2.7574570MixupTrain:  epoch  0, batch   329 | loss: 2.4735770MixupTrain:  epoch  0, batch   330 | loss: 2.5475228MixupTrain:  epoch  0, batch   331 | loss: 2.3233337MixupTrain:  epoch  0, batch   332 | loss: 2.4757967MixupTrain:  epoch  0, batch   333 | loss: 2.1287827MixupTrain:  epoch  0, batch   334 | loss: 2.5822573MixupTrain:  epoch  0, batch   335 | loss: 2.4243505MixupTrain:  epoch  0, batch   336 | loss: 2.6400220MixupTrain:  epoch  0, batch   337 | loss: 2.3621480MixupTrain:  epoch  0, batch   338 | loss: 2.1477125MixupTrain:  epoch  0, batch   339 | loss: 2.6318073MixupTrain:  epoch  0, batch   340 | loss: 2.3808501MixupTrain:  epoch  0, batch   341 | loss: 2.5555751MixupTrain:  epoch  0, batch   342 | loss: 2.5148242MixupTrain:  epoch  0, batch   343 | loss: 2.1389160MixupTrain:  epoch  0, batch   344 | loss: 2.4328327MixupTrain:  epoch  0, batch   345 | loss: 2.3537064MixupTrain:  epoch  0, batch   346 | loss: 2.6565752MixupTrain:  epoch  0, batch   347 | loss: 2.6592770MixupTrain:  epoch  0, batch   348 | loss: 2.4672012MixupTrain:  epoch  0, batch   349 | loss: 2.4843283MixupTrain:  epoch  0, batch   350 | loss: 2.3604510MixupTrain:  epoch  0, batch   351 | loss: 2.6477866MixupTrain:  epoch  0, batch   352 | loss: 2.4251571MixupTrain:  epoch  0, batch   353 | loss: 2.4335642MixupTrain:  epoch  0, batch   354 | loss: 2.6157258MixupTrain:  epoch  0, batch   355 | loss: 2.5216122MixupTrain:  epoch  0, batch   356 | loss: 2.4952972MixupTrain:  epoch  0, batch   357 | loss: 2.4211926MixupTrain:  epoch  0, batch   358 | loss: 2.4234796MixupTrain:  epoch  0, batch   359 | loss: 2.6941576MixupTrain:  epoch  0, batch   360 | loss: 2.6851287MixupTrain:  epoch  0, batch   361 | loss: 2.5940926MixupTrain:  epoch  0, batch   362 | loss: 2.6139090MixupTrain:  epoch  0, batch   363 | loss: 2.6330578MixupTrain:  epoch  0, batch   364 | loss: 2.2989426MixupTrain:  epoch  0, batch   365 | loss: 2.2918510MixupTrain:  epoch  0, batch   366 | loss: 2.3677278MixupTrain:  epoch  0, batch   367 | loss: 2.9406195MixupTrain:  epoch  0, batch   368 | loss: 2.7746034MixupTrain:  epoch  0, batch   369 | loss: 2.8888335MixupTrain:  epoch  0, batch   370 | loss: 2.4849885MixupTrain:  epoch  0, batch   371 | loss: 2.2929647MixupTrain:  epoch  0, batch   372 | loss: 2.2083039MixupTrain:  epoch  0, batch   373 | loss: 2.3466692MixupTrain:  epoch  0, batch   374 | loss: 2.3458581MixupTrain:  epoch  0, batch   375 | loss: 2.4415450MixupTrain:  epoch  0, batch   376 | loss: 2.5336115MixupTrain:  epoch  0, batch   377 | loss: 2.4156556MixupTrain:  epoch  0, batch   378 | loss: 2.3462939MixupTrain:  epoch  0, batch   379 | loss: 2.5565007MixupTrain:  epoch  0, batch   380 | loss: 2.6703422MixupTrain:  epoch  0, batch   381 | loss: 2.4326525MixupTrain:  epoch  0, batch   382 | loss: 2.1479731MixupTrain:  epoch  0, batch   383 | loss: 2.5453606MixupTrain:  epoch  0, batch   384 | loss: 2.4289684MixupTrain:  epoch  0, batch   385 | loss: 2.5140209MixupTrain:  epoch  0, batch   386 | loss: 2.6652367MixupTrain:  epoch  0, batch   387 | loss: 2.2085764MixupTrain:  epoch  0, batch   388 | loss: 2.5476766MixupTrain:  epoch  0, batch   389 | loss: 2.6231663MixupTrain:  epoch  0, batch   390 | loss: 2.1166577MixupTrain:  epoch  0, batch   391 | loss: 2.1958756MixupTrain:  epoch  0, batch   392 | loss: 2.4579787MixupTrain:  epoch  0, batch   393 | loss: 2.2177017MixupTrain:  epoch  0, batch   394 | loss: 2.5228744MixupTrain:  epoch  0, batch   395 | loss: 2.4936147MixupTrain:  epoch  0, batch   396 | loss: 2.8421226MixupTrain:  epoch  0, batch   397 | loss: 2.3448277MixupTrain:  epoch  0, batch   398 | loss: 2.3694420MixupTrain:  epoch  0, batch   399 | loss: 2.2570972MixupTrain:  epoch  0, batch   400 | loss: 2.3137236MixupTrain:  epoch  0, batch   401 | loss: 2.2859552MixupTrain:  epoch  0, batch   402 | loss: 2.2073674MixupTrain:  epoch  0, batch   403 | loss: 2.2304177MixupTrain:  epoch  0, batch   404 | loss: 2.2211518MixupTrain:  epoch  0, batch   405 | loss: 2.2703094MixupTrain:  epoch  0, batch   406 | loss: 2.5858550MixupTrain:  epoch  0, batch   407 | loss: 2.3827953MixupTrain:  epoch  0, batch   408 | loss: 2.6609032MixupTrain:  epoch  0, batch   409 | loss: 2.5381577MixupTrain:  epoch  0, batch   410 | loss: 2.4515324MixupTrain:  epoch  0, batch   411 | loss: 2.6563315MixupTrain:  epoch  0, batch   412 | loss: 2.3951988MixupTrain:  epoch  0, batch   413 | loss: 2.4067645MixupTrain:  epoch  0, batch   414 | loss: 2.0870528MixupTrain:  epoch  0, batch   415 | loss: 2.3762653MixupTrain:  epoch  0, batch   416 | loss: 2.6513186MixupTrain:  epoch  0, batch   417 | loss: 2.3457215MixupTrain:  epoch  0, batch   418 | loss: 2.2570875MixupTrain:  epoch  0, batch   419 | loss: 2.3172808MixupTrain:  epoch  0, batch   420 | loss: 2.1220598MixupTrain:  epoch  0, batch   421 | loss: 2.1929774MixupTrain:  epoch  0, batch   422 | loss: 2.4168601MixupTrain:  epoch  0, batch   423 | loss: 2.3529387MixupTrain:  epoch  0, batch   424 | loss: 2.5619228MixupTrain:  epoch  0, batch   425 | loss: 2.2262361MixupTrain:  epoch  0, batch   426 | loss: 2.6360209MixupTrain:  epoch  0, batch   427 | loss: 2.4264703MixupTrain:  epoch  0, batch   428 | loss: 2.2470822MixupTrain:  epoch  0, batch   429 | loss: 2.4263158MixupTrain:  epoch  0, batch   430 | loss: 2.0718548MixupTrain:  epoch  0, batch   431 | loss: 2.2604280MixupTrain:  epoch  0, batch   432 | loss: 2.3483577MixupTrain:  epoch  0, batch   433 | loss: 2.5154281MixupTrain:  epoch  0, batch   434 | loss: 2.3450098MixupTrain:  epoch  0, batch   435 | loss: 2.4773502MixupTrain:  epoch  0, batch   436 | loss: 2.4177070MixupTrain:  epoch  0, batch   437 | loss: 2.6359885MixupTrain:  epoch  0, batch   438 | loss: 2.4684353MixupTrain:  epoch  0, batch   439 | loss: 2.2465906MixupTrain:  epoch  0, batch   440 | loss: 2.2266326MixupTrain:  epoch  0, batch   441 | loss: 2.4270205MixupTrain:  epoch  0, batch   442 | loss: 2.5580056MixupTrain:  epoch  0, batch   443 | loss: 2.7455325MixupTrain:  epoch  0, batch   444 | loss: 2.6696682MixupTrain:  epoch  0, batch   445 | loss: 2.3075900MixupTrain:  epoch  0, batch   446 | loss: 2.2259645MixupTrain:  epoch  0, batch   447 | loss: 2.4267871MixupTrain:  epoch  0, batch   448 | loss: 2.0300524MixupTrain:  epoch  0, batch   449 | loss: 2.3193145MixupTrain:  epoch  0, batch   450 | loss: 2.1192203MixupTrain:  epoch  0, batch   451 | loss: 2.5436926MixupTrain:  epoch  0, batch   452 | loss: 2.4513392MixupTrain:  epoch  0, batch   453 | loss: 2.1481898MixupTrain:  epoch  0, batch   454 | loss: 2.3996031MixupTrain:  epoch  0, batch   455 | loss: 2.3646741MixupTrain:  epoch  0, batch   456 | loss: 2.3449440MixupTrain:  epoch  0, batch   457 | loss: 2.2201638MixupTrain:  epoch  0, batch   458 | loss: 2.6472187MixupTrain:  epoch  0, batch   459 | loss: 2.5262747MixupTrain:  epoch  0, batch   460 | loss: 2.3725088MixupTrain:  epoch  0, batch   461 | loss: 2.5249128MixupTrain:  epoch  0, batch   462 | loss: 2.1328349MixupTrain:  epoch  0, batch   463 | loss: 2.2791810MixupTrain:  epoch  0, batch   464 | loss: 2.3689418MixupTrain:  epoch  0, batch   465 | loss: 2.3319235MixupTrain:  epoch  0, batch   466 | loss: 2.3572297MixupTrain:  epoch  0, batch   467 | loss: 2.4216824MixupTrain:  epoch  0, batch   468 | loss: 2.3975058MixupTrain:  epoch  0, batch   469 | loss: 2.0959847MixupTrain:  epoch  0, batch   470 | loss: 2.2405119MixupTrain:  epoch  0, batch   471 | loss: 2.2366073MixupTrain:  epoch  0, batch   472 | loss: 2.2257721MixupTrain:  epoch  0, batch   473 | loss: 2.2503591MixupTrain:  epoch  0, batch   474 | loss: 2.2473814MixupTrain:  epoch  0, batch   475 | loss: 2.4233329MixupTrain:  epoch  0, batch   476 | loss: 2.3334718MixupTrain:  epoch  0, batch   477 | loss: 2.4102054MixupTrain:  epoch  0, batch   478 | loss: 2.2853813MixupTrain:  epoch  0, batch   479 | loss: 2.2536554MixupTrain:  epoch  0, batch   480 | loss: 2.4172370MixupTrain:  epoch  0, batch   481 | loss: 2.3470955MixupTrain:  epoch  0, batch   482 | loss: 2.1672130MixupTrain:  epoch  0, batch   483 | loss: 2.6480937MixupTrain:  epoch  0, batch   484 | loss: 2.6341259MixupTrain:  epoch  0, batch   485 | loss: 2.4201188MixupTrain:  epoch  0, batch   486 | loss: 2.1329520MixupTrain:  epoch  0, batch   487 | loss: 2.3339739MixupTrain:  epoch  0, batch   488 | loss: 2.3069642MixupTrain:  epoch  0, batch   489 | loss: 2.3819916MixupTrain:  epoch  0, batch   490 | loss: 2.1885028MixupTrain:  epoch  0, batch   491 | loss: 2.3354907MixupTrain:  epoch  0, batch   492 | loss: 2.5377634MixupTrain:  epoch  0, batch   493 | loss: 2.3740003MixupTrain:  epoch  0, batch   494 | loss: 2.2573862MixupTrain:  epoch  0, batch   495 | loss: 2.6197851MixupTrain:  epoch  0, batch   496 | loss: 2.7763720MixupTrain:  epoch  0, batch   497 | loss: 2.5098343MixupTrain:  epoch  0, batch   498 | loss: 2.1505814MixupTrain:  epoch  0, batch   499 | loss: 2.3667951MixupTrain:  epoch  0, batch   500 | loss: 2.8768241MixupTrain:  epoch  0, batch   501 | loss: 2.0645120MixupTrain:  epoch  0, batch   502 | loss: 2.3388531MixupTrain:  epoch  0, batch   503 | loss: 2.4390082MixupTrain:  epoch  0, batch   504 | loss: 2.2219124MixupTrain:  epoch  0, batch   505 | loss: 2.3919101MixupTrain:  epoch  0, batch   506 | loss: 2.2532895MixupTrain:  epoch  0, batch   507 | loss: 2.2214785MixupTrain:  epoch  0, batch   508 | loss: 2.4141328MixupTrain:  epoch  0, batch   509 | loss: 2.2709012MixupTrain:  epoch  0, batch   510 | loss: 2.5313382MixupTrain:  epoch  0, batch   511 | loss: 2.2100911MixupTrain:  epoch  0, batch   512 | loss: 2.4174042MixupTrain:  epoch  0, batch   513 | loss: 2.1850402MixupTrain:  epoch  0, batch   514 | loss: 2.4744520MixupTrain:  epoch  0, batch   515 | loss: 2.4151073MixupTrain:  epoch  0, batch   516 | loss: 2.4687650MixupTrain:  epoch  0, batch   517 | loss: 2.4338179MixupTrain:  epoch  0, batch   518 | loss: 2.9024687MixupTrain:  epoch  0, batch   519 | loss: 2.4647596MixupTrain:  epoch  0, batch   520 | loss: 2.6425304MixupTrain:  epoch  0, batch   521 | loss: 2.3910208MixupTrain:  epoch  0, batch   522 | loss: 2.2858922MixupTrain:  epoch  0, batch   523 | loss: 2.4634712MixupTrain:  epoch  0, batch   524 | loss: 2.2085710MixupTrain:  epoch  0, batch   525 | loss: 2.2553723MixupTrain:  epoch  0, batch   526 | loss: 2.2189422MixupTrain:  epoch  0, batch   527 | loss: 2.4684052MixupTrain:  epoch  0, batch   528 | loss: 2.5604248MixupTrain:  epoch  0, batch   529 | loss: 2.5974669MixupTrain:  epoch  0, batch   530 | loss: 2.4941602MixupTrain:  epoch  0, batch   531 | loss: 2.4598045MixupTrain:  epoch  0, batch   532 | loss: 2.3784924MixupTrain:  epoch  0, batch   533 | loss: 2.6243565MixupTrain:  epoch  0, batch   534 | loss: 2.2562695MixupTrain:  epoch  0, batch   535 | loss: 2.3696337MixupTrain:  epoch  0, batch   536 | loss: 2.5182364MixupTrain:  epoch  0, batch   537 | loss: 2.5326858MixupTrain:  epoch  0, batch   538 | loss: 2.5216498MixupTrain:  epoch  0, batch   539 | loss: 2.3641241MixupTrain:  epoch  0, batch   540 | loss: 2.2374496MixupTrain:  epoch  0, batch   541 | loss: 2.4170196MixupTrain:  epoch  0, batch   542 | loss: 2.7487073MixupTrain:  epoch  0, batch   543 | loss: 2.5495267MixupTrain:  epoch  0, batch   544 | loss: 2.5482335MixupTrain:  epoch  0, batch   545 | loss: 2.3705101MixupTrain:  epoch  0, batch   546 | loss: 2.5190146MixupTrain:  epoch  0, batch   547 | loss: 2.4618475MixupTrain:  epoch  0, batch   548 | loss: 2.6353550MixupTrain:  epoch  0, batch   549 | loss: 2.4957304MixupTrain:  epoch  0, batch   550 | loss: 2.2827392MixupTrain:  epoch  0, batch   551 | loss: 2.1497464MixupTrain:  epoch  0, batch   552 | loss: 2.6057150MixupTrain:  epoch  0, batch   553 | loss: 2.5520704MixupTrain:  epoch  0, batch   554 | loss: 2.2242188MixupTrain:  epoch  0, batch   555 | loss: 2.7533221MixupTrain:  epoch  0, batch   556 | loss: 2.3244753MixupTrain:  epoch  0, batch   557 | loss: 2.4044433MixupTrain:  epoch  0, batch   558 | loss: 2.1102934MixupTrain:  epoch  0, batch   559 | loss: 2.1027622MixupTrain:  epoch  0, batch   560 | loss: 2.4239156MixupTrain:  epoch  0, batch   561 | loss: 2.1964383MixupTrain:  epoch  0, batch   562 | loss: 2.5035090MixupTrain:  epoch  0, batch   563 | loss: 2.2201269MixupTrain:  epoch  0, batch   564 | loss: 2.2502642MixupTrain:  epoch  0, batch   565 | loss: 2.2981176MixupTrain:  epoch  0, batch   566 | loss: 2.5538828MixupTrain:  epoch  0, batch   567 | loss: 2.4989934MixupTrain:  epoch  0, batch   568 | loss: 2.9651761MixupTrain:  epoch  0, batch   569 | loss: 2.3937223MixupTrain:  epoch  0, batch   570 | loss: 2.1920533MixupTrain:  epoch  0, batch   571 | loss: 2.6449919MixupTrain:  epoch  0, batch   572 | loss: 2.4912939MixupTrain:  epoch  0, batch   573 | loss: 2.3940256MixupTrain:  epoch  0, batch   574 | loss: 2.5127306MixupTrain:  epoch  0, batch   575 | loss: 2.2887359MixupTrain:  epoch  0, batch   576 | loss: 2.0447249MixupTrain:  epoch  0, batch   577 | loss: 2.4455333MixupTrain:  epoch  0, batch   578 | loss: 2.0759382MixupTrain:  epoch  0, batch   579 | loss: 2.1772926MixupTrain:  epoch  0, batch   580 | loss: 2.2209253MixupTrain:  epoch  0, batch   581 | loss: 2.4966173MixupTrain:  epoch  0, batch   582 | loss: 2.1604476MixupTrain:  epoch  0, batch   583 | loss: 2.3424993MixupTrain:  epoch  0, batch   584 | loss: 2.3393679MixupTrain:  epoch  0, batch   585 | loss: 2.4749293MixupTrain:  epoch  0, batch   586 | loss: 2.1434100MixupTrain:  epoch  0, batch   587 | loss: 2.4899220MixupTrain:  epoch  0, batch   588 | loss: 2.5829573MixupTrain:  epoch  0, batch   589 | loss: 2.5981879MixupTrain:  epoch  0, batch   590 | loss: 2.2505226MixupTrain:  epoch  0, batch   591 | loss: 2.3335390MixupTrain:  epoch  0, batch   592 | loss: 2.6523573MixupTrain:  epoch  0, batch   593 | loss: 2.5984488MixupTrain:  epoch  0, batch   594 | loss: 2.5524189MixupTrain:  epoch  0, batch   595 | loss: 2.2669592MixupTrain:  epoch  0, batch   596 | loss: 2.7598667MixupTrain:  epoch  0, batch   597 | loss: 2.5898333MixupTrain:  epoch  0, batch   598 | loss: 2.2590988MixupTrain:  epoch  0, batch   599 | loss: 2.7220297MixupTrain:  epoch  0, batch   600 | loss: 2.1634820MixupTrain:  epoch  0, batch   601 | loss: 2.6054969MixupTrain:  epoch  0, batch   602 | loss: 2.3819191MixupTrain:  epoch  0, batch   603 | loss: 2.4407785MixupTrain:  epoch  0, batch   604 | loss: 2.5931094MixupTrain:  epoch  0, batch   605 | loss: 2.6646500MixupTrain:  epoch  0, batch   606 | loss: 2.4762979MixupTrain:  epoch  0, batch   607 | loss: 2.1868682MixupTrain:  epoch  0, batch   608 | loss: 2.1991839MixupTrain:  epoch  0, batch   609 | loss: 2.2757547MixupTrain:  epoch  0, batch   610 | loss: 2.3559189MixupTrain:  epoch  0, batch   611 | loss: 1.9807580MixupTrain:  epoch  0, batch   612 | loss: 2.7197623MixupTrain:  epoch  0, batch   613 | loss: 2.5502753MixupTrain:  epoch  0, batch   614 | loss: 2.5633235MixupTrain:  epoch  0, batch   615 | loss: 2.2593150MixupTrain:  epoch  0, batch   616 | loss: 2.3121829MixupTrain:  epoch  0, batch   617 | loss: 2.4692211MixupTrain:  epoch  0, batch   618 | loss: 2.3702374MixupTrain:  epoch  0, batch   619 | loss: 2.3228173MixupTrain:  epoch  0, batch   620 | loss: 2.2021074MixupTrain:  epoch  0, batch   621 | loss: 2.2244449MixupTrain:  epoch  0, batch   622 | loss: 2.3987184MixupTrain:  epoch  0, batch   623 | loss: 2.4332607MixupTrain:  epoch  0, batch   624 | loss: 2.6398358MixupTrain:  epoch  0, batch   625 | loss: 2.3410013MixupTrain:  epoch  0, batch   626 | loss: 2.5814254MixupTrain:  epoch  0, batch   627 | loss: 2.0715966MixupTrain:  epoch  0, batch   628 | loss: 2.5659351MixupTrain:  epoch  0, batch   629 | loss: 2.2770703MixupTrain:  epoch  0, batch   630 | loss: 2.5702477MixupTrain:  epoch  0, batch   631 | loss: 2.0009611MixupTrain:  epoch  0, batch   632 | loss: 2.2126892MixupTrain:  epoch  0, batch   633 | loss: 2.4976630MixupTrain:  epoch  0, batch   634 | loss: 2.1415281MixupTrain:  epoch  0, batch   635 | loss: 2.1460245MixupTrain:  epoch  0, batch   636 | loss: 2.4128070MixupTrain:  epoch  0, batch   637 | loss: 2.5490882MixupTrain:  epoch  0, batch   638 | loss: 2.3154030MixupTrain:  epoch  0, batch   639 | loss: 2.1579933MixupTrain:  epoch  0, batch   640 | loss: 2.3121233MixupTrain:  epoch  0, batch   641 | loss: 2.1373880MixupTrain:  epoch  0, batch   642 | loss: 1.9675541MixupTrain:  epoch  0, batch   643 | loss: 2.3299146MixupTrain:  epoch  0, batch   644 | loss: 2.4988201MixupTrain:  epoch  0, batch   645 | loss: 1.9619269MixupTrain:  epoch  0, batch   646 | loss: 2.3971210MixupTrain:  epoch  0, batch   647 | loss: 2.2714763MixupTrain:  epoch  0, batch   648 | loss: 2.3884933MixupTrain:  epoch  0, batch   649 | loss: 2.2064965MixupTrain:  epoch  0, batch   650 | loss: 2.3316498MixupTrain:  epoch  0, batch   651 | loss: 2.3496194MixupTrain:  epoch  0, batch   652 | loss: 2.7300298MixupTrain:  epoch  0, batch   653 | loss: 2.3311300MixupTrain:  epoch  0, batch   654 | loss: 2.4979596MixupTrain:  epoch  0, batch   655 | loss: 2.3892961MixupTrain:  epoch  0, batch   656 | loss: 2.5319281MixupTrain:  epoch  0, batch   657 | loss: 2.3094923MixupTrain:  epoch  0, batch   658 | loss: 2.5497334MixupTrain:  epoch  0, batch   659 | loss: 2.5883141MixupTrain:  epoch  0, batch   660 | loss: 2.2954752MixupTrain:  epoch  0, batch   661 | loss: 2.7249999MixupTrain:  epoch  0, batch   662 | loss: 2.4837456MixupTrain:  epoch  0, batch   663 | loss: 2.1624312MixupTrain:  epoch  0, batch   664 | loss: 2.3970785MixupTrain:  epoch  0, batch   665 | loss: 2.3528240MixupTrain:  epoch  0, batch   666 | loss: 2.3033764MixupTrain:  epoch  0, batch   667 | loss: 2.3316708MixupTrain:  epoch  0, batch   668 | loss: 2.8698716MixupTrain:  epoch  0, batch   669 | loss: 2.4146245MixupTrain:  epoch  0, batch   670 | loss: 2.2937281MixupTrain:  epoch  0, batch   671 | loss: 2.2945652MixupTrain:  epoch  0, batch   672 | loss: 2.3872712MixupTrain:  epoch  0, batch   673 | loss: 2.2531826MixupTrain:  epoch  0, batch   674 | loss: 2.2634554MixupTrain:  epoch  0, batch   675 | loss: 2.3118100MixupTrain:  epoch  0, batch   676 | loss: 2.4564490MixupTrain:  epoch  0, batch   677 | loss: 2.3094811MixupTrain:  epoch  0, batch   678 | loss: 2.0739238MixupTrain:  epoch  0, batch   679 | loss: 2.2089131MixupTrain:  epoch  0, batch   680 | loss: 2.2214296MixupTrain:  epoch  0, batch   681 | loss: 2.4816861MixupTrain:  epoch  0, batch   682 | loss: 2.1874537MixupTrain:  epoch  0, batch   683 | loss: 2.3097839MixupTrain:  epoch  0, batch   684 | loss: 2.7875466MixupTrain:  epoch  0, batch   685 | loss: 2.2162955MixupTrain:  epoch  0, batch   686 | loss: 2.2251608MixupTrain:  epoch  0, batch   687 | loss: 2.2271981MixupTrain:  epoch  0, batch   688 | loss: 2.5540061MixupTrain:  epoch  0, batch   689 | loss: 2.4864490MixupTrain:  epoch  0, batch   690 | loss: 2.2685742MixupTrain:  epoch  0, batch   691 | loss: 2.2210131MixupTrain:  epoch  0, batch   692 | loss: 2.2949052MixupTrain:  epoch  0, batch   693 | loss: 2.1985109MixupTrain:  epoch  0, batch   694 | loss: 2.4652781MixupTrain:  epoch  0, batch   695 | loss: 2.4885097MixupTrain:  epoch  0, batch   696 | loss: 2.3224487MixupTrain:  epoch  0, batch   697 | loss: 2.5297632MixupTrain:  epoch  0, batch   698 | loss: 2.4051895MixupTrain:  epoch  0, batch   699 | loss: 2.5611687MixupTrain:  epoch  0, batch   700 | loss: 2.2242517MixupTrain:  epoch  0, batch   701 | loss: 2.1517992MixupTrain:  epoch  0, batch   702 | loss: 2.4007797MixupTrain:  epoch  0, batch   703 | loss: 2.3717785MixupTrain:  epoch  0, batch   704 | loss: 2.2448006MixupTrain:  epoch  0, batch   705 | loss: 2.2152905MixupTrain:  epoch  0, batch   706 | loss: 2.6983194MixupTrain:  epoch  0, batch   707 | loss: 2.2389896MixupTrain:  epoch  0, batch   708 | loss: 2.3037205MixupTrain:  epoch  0, batch   709 | loss: 2.1723721MixupTrain:  epoch  0, batch   710 | loss: 2.5055671MixupTrain:  epoch  0, batch   711 | loss: 2.5098484MixupTrain:  epoch  0, batch   712 | loss: 2.3422737MixupTrain:  epoch  0, batch   713 | loss: 2.6602142MixupTrain:  epoch  0, batch   714 | loss: 2.2298822MixupTrain:  epoch  0, batch   715 | loss: 2.2138972MixupTrain:  epoch  0, batch   716 | loss: 2.3789318MixupTrain:  epoch  0, batch   717 | loss: 2.3092806MixupTrain:  epoch  0, batch   718 | loss: 2.5608847MixupTrain:  epoch  0, batch   719 | loss: 2.1825085MixupTrain:  epoch  0, batch   720 | loss: 2.6662235MixupTrain:  epoch  0, batch   721 | loss: 2.3515124MixupTrain:  epoch  0, batch   722 | loss: 2.4865656MixupTrain:  epoch  0, batch   723 | loss: 2.3103380MixupTrain:  epoch  0, batch   724 | loss: 2.4814839MixupTrain:  epoch  0, batch   725 | loss: 2.3907948MixupTrain:  epoch  0, batch   726 | loss: 2.4300089MixupTrain:  epoch  0, batch   727 | loss: 2.4661715MixupTrain:  epoch  0, batch   728 | loss: 2.3978925MixupTrain:  epoch  0, batch   729 | loss: 2.3545799MixupTrain:  epoch  0, batch   730 | loss: 2.2823782MixupTrain:  epoch  0, batch   731 | loss: 2.5344558MixupTrain:  epoch  0, batch   732 | loss: 2.3232279MixupTrain:  epoch  0, batch   733 | loss: 2.8247237MixupTrain:  epoch  0, batch   734 | loss: 2.4125881MixupTrain:  epoch  0, batch   735 | loss: 2.1679740MixupTrain:  epoch  0, batch   736 | loss: 2.1161220MixupTrain:  epoch  0, batch   737 | loss: 2.5683124MixupTrain:  epoch  0, batch   738 | loss: 2.5998230MixupTrain:  epoch  0, batch   739 | loss: 2.3082585MixupTrain:  epoch  0, batch   740 | loss: 2.2873812MixupTrain:  epoch  0, batch   741 | loss: 2.2756200MixupTrain:  epoch  0, batch   742 | loss: 2.2396748MixupTrain:  epoch  0, batch   743 | loss: 2.3572602MixupTrain:  epoch  0, batch   744 | loss: 2.4302123MixupTrain:  epoch  0, batch   745 | loss: 2.2763686MixupTrain:  epoch  0, batch   746 | loss: 2.2041082MixupTrain:  epoch  0, batch   747 | loss: 2.5169506MixupTrain:  epoch  0, batch   748 | loss: 2.3330941MixupTrain:  epoch  0, batch   749 | loss: 2.4550295MixupTrain:  epoch  0, batch   750 | loss: 2.4170227MixupTrain:  epoch  0, batch   751 | loss: 2.3543410MixupTrain:  epoch  0, batch   752 | loss: 2.2304211MixupTrain:  epoch  0, batch   753 | loss: 2.2702820MixupTrain:  epoch  0, batch   754 | loss: 2.4924004MixupTrain:  epoch  0, batch   755 | loss: 2.3242390MixupTrain:  epoch  0, batch   756 | loss: 2.4770217MixupTrain:  epoch  0, batch   757 | loss: 2.2504752MixupTrain:  epoch  0, batch   758 | loss: 2.5608027MixupTrain:  epoch  0, batch   759 | loss: 2.1902051MixupTrain:  epoch  0, batch   760 | loss: 2.4748797MixupTrain:  epoch  0, batch   761 | loss: 2.4948120MixupTrain:  epoch  0, batch   762 | loss: 2.3118422MixupTrain:  epoch  0, batch   763 | loss: 2.3139365MixupTrain:  epoch  0, batch   764 | loss: 2.3344166MixupTrain:  epoch  0, batch   765 | loss: 2.3631182MixupTrain:  epoch  0, batch   766 | loss: 2.3509443MixupTrain:  epoch  0, batch   767 | loss: 2.2168593MixupTrain:  epoch  0, batch   768 | loss: 2.3987269MixupTrain:  epoch  0, batch   769 | loss: 2.3590493MixupTrain:  epoch  0, batch   770 | loss: 2.4874153MixupTrain:  epoch  0, batch   771 | loss: 2.2075515MixupTrain:  epoch  0, batch   772 | loss: 2.2698057MixupTrain:  epoch  0, batch   773 | loss: 2.3307600MixupTrain:  epoch  0, batch   774 | loss: 2.3796520MixupTrain:  epoch  0, batch   775 | loss: 2.2795091MixupTrain:  epoch  0, batch   776 | loss: 2.2213964MixupTrain:  epoch  0, batch   777 | loss: 2.2642589MixupTrain:  epoch  0, batch   778 | loss: 2.4107442MixupTrain:  epoch  0, batch   779 | loss: 2.2815521MixupTrain:  epoch  0, batch   780 | loss: 2.3906088MixupTrain:  epoch  0, batch   781 | loss: 2.5132356MixupTrain:  epoch  0, batch   782 | loss: 2.4676263MixupTrain:  epoch  0, batch   783 | loss: 2.2352734MixupTrain:  epoch  0, batch   784 | loss: 2.6368651MixupTrain:  epoch  0, batch   785 | loss: 2.4322624MixupTrain:  epoch  0, batch   786 | loss: 2.2504196MixupTrain:  epoch  0, batch   787 | loss: 2.0314183MixupTrain:  epoch  0, batch   788 | loss: 2.7098646MixupTrain:  epoch  0, batch   789 | loss: 2.4476101MixupTrain:  epoch  0, batch   790 | loss: 2.6884251MixupTrain:  epoch  0, batch   791 | loss: 2.6689117MixupTrain:  epoch  0, batch   792 | loss: 2.3456812MixupTrain:  epoch  0, batch   793 | loss: 2.1483808MixupTrain:  epoch  0, batch   794 | loss: 2.3744314MixupTrain:  epoch  0, batch   795 | loss: 2.4413245MixupTrain:  epoch  0, batch   796 | loss: 2.1812503MixupTrain:  epoch  0, batch   797 | loss: 2.4417877MixupTrain:  epoch  0, batch   798 | loss: 2.5701866MixupTrain:  epoch  0, batch   799 | loss: 2.2424603MixupTrain:  epoch  0, batch   800 | loss: 2.3399496MixupTrain:  epoch  0, batch   801 | loss: 2.2870548MixupTrain:  epoch  0, batch   802 | loss: 2.3385723MixupTrain:  epoch  0, batch   803 | loss: 2.2684071MixupTrain:  epoch  0, batch   804 | loss: 2.3046696MixupTrain:  epoch  0, batch   805 | loss: 2.4392118MixupTrain:  epoch  0, batch   806 | loss: 2.2988853MixupTrain:  epoch  0, batch   807 | loss: 2.3079917MixupTrain:  epoch  0, batch   808 | loss: 2.1928048MixupTrain:  epoch  0, batch   809 | loss: 2.4093494MixupTrain:  epoch  0, batch   810 | loss: 2.0569506MixupTrain:  epoch  0, batch   811 | loss: 2.1874270MixupTrain:  epoch  0, batch   812 | loss: 2.4307401MixupTrain:  epoch  0, batch   813 | loss: 2.0381935MixupTrain:  epoch  0, batch   814 | loss: 2.3776572MixupTrain:  epoch  0, batch   815 | loss: 2.0183856MixupTrain:  epoch  0, batch   816 | loss: 2.3570652MixupTrain:  epoch  0, batch   817 | loss: 2.3142202MixupTrain:  epoch  0, batch   818 | loss: 2.3158755MixupTrain:  epoch  0, batch   819 | loss: 2.3120804MixupTrain:  epoch  0, batch   820 | loss: 2.3499055MixupTrain:  epoch  0, batch   821 | loss: 2.2151399MixupTrain:  epoch  0, batch   822 | loss: 2.3513150MixupTrain:  epoch  0, batch   823 | loss: 2.3297896MixupTrain:  epoch  0, batch   824 | loss: 2.2954512MixupTrain:  epoch  0, batch   825 | loss: 2.2918818MixupTrain:  epoch  0, batch   826 | loss: 2.3111258MixupTrain:  epoch  0, batch   827 | loss: 2.3975115MixupTrain:  epoch  0, batch   828 | loss: 2.6574988MixupTrain:  epoch  0, batch   829 | loss: 2.1932578MixupTrain:  epoch  0, batch   830 | loss: 2.3017497MixupTrain:  epoch  0, batch   831 | loss: 2.0554366MixupTrain:  epoch  0, batch   832 | loss: 2.2837982MixupTrain:  epoch  0, batch   833 | loss: 1.9748013MixupTrain:  epoch  0, batch   834 | loss: 2.4576306MixupTrain:  epoch  0, batch   835 | loss: 2.5166488MixupTrain:  epoch  0, batch   836 | loss: 2.2913766MixupTrain:  epoch  0, batch   837 | loss: 2.5095587MixupTrain:  epoch  0, batch   838 | loss: 2.3714223MixupTrain:  epoch  0, batch   839 | loss: 2.7026384MixupTrain:  epoch  0, batch   840 | loss: 2.3834167MixupTrain:  epoch  0, batch   841 | loss: 2.5281916MixupTrain:  epoch  0, batch   842 | loss: 2.3178563MixupTrain:  epoch  0, batch   843 | loss: 2.5759454MixupTrain:  epoch  0, batch   844 | loss: 2.1944499MixupTrain:  epoch  0, batch   845 | loss: 2.4659362MixupTrain:  epoch  0, batch   846 | loss: 2.9632697MixupTrain:  epoch  0, batch   847 | loss: 2.4448671MixupTrain:  epoch  0, batch   848 | loss: 2.4074104MixupTrain:  epoch  0, batch   849 | loss: 2.2106929MixupTrain:  epoch  0, batch   850 | loss: 2.2721202MixupTrain:  epoch  0, batch   851 | loss: 2.2671669MixupTrain:  epoch  0, batch   852 | loss: 2.3058941MixupTrain:  epoch  0, batch   853 | loss: 2.6122622MixupTrain:  epoch  0, batch   854 | loss: 2.5801961MixupTrain:  epoch  0, batch   855 | loss: 2.4874508MixupTrain:  epoch  0, batch   856 | loss: 2.5359888MixupTrain:  epoch  0, batch   857 | loss: 2.3731041MixupTrain:  epoch  0, batch   858 | loss: 2.3752012MixupTrain:  epoch  0, batch   859 | loss: 2.3816702MixupTrain:  epoch  0, batch   860 | loss: 2.5950966MixupTrain:  epoch  0, batch   861 | loss: 2.8547757MixupTrain:  epoch  0, batch   862 | loss: 2.1320584MixupTrain:  epoch  0, batch   863 | loss: 2.4545753MixupTrain:  epoch  0, batch   864 | loss: 2.6107726MixupTrain:  epoch  0, batch   865 | loss: 2.1270137MixupTrain:  epoch  0, batch   866 | loss: 2.3284817MixupTrain:  epoch  0, batch   867 | loss: 2.2991166MixupTrain:  epoch  0, batch   868 | loss: 2.2295411MixupTrain:  epoch  0, batch   869 | loss: 2.9530790MixupTrain:  epoch  0, batch   870 | loss: 2.3859458MixupTrain:  epoch  0, batch   871 | loss: 2.3378489MixupTrain:  epoch  0, batch   872 | loss: 2.6384139MixupTrain:  epoch  0, batch   873 | loss: 2.2855165MixupTrain:  epoch  0, batch   874 | loss: 2.3800604MixupTrain:  epoch  0, batch   875 | loss: 2.2506967MixupTrain:  epoch  0, batch   876 | loss: 2.4975841MixupTrain:  epoch  0, batch   877 | loss: 2.5288134MixupTrain:  epoch  0, batch   878 | loss: 2.3785820MixupTrain:  epoch  0, batch   879 | loss: 2.3603392MixupTrain:  epoch  0, batch   880 | loss: 2.1658249MixupTrain:  epoch  0, batch   881 | loss: 2.6699829MixupTrain:  epoch  0, batch   882 | loss: 2.1302154MixupTrain:  epoch  0, batch   883 | loss: 2.3347301MixupTrain:  epoch  0, batch   884 | loss: 2.3000751MixupTrain:  epoch  0, batch   885 | loss: 2.4076433MixupTrain:  epoch  0, batch   886 | loss: 2.5336297MixupTrain:  epoch  0, batch   887 | loss: 2.3682311MixupTrain:  epoch  0, batch   888 | loss: 2.3073673MixupTrain:  epoch  0, batch   889 | loss: 2.5130148MixupTrain:  epoch  0, batch   890 | loss: 2.2536120MixupTrain:  epoch  0, batch   891 | loss: 2.2745862MixupTrain:  epoch  0, batch   892 | loss: 2.2730167MixupTrain:  epoch  0, batch   893 | loss: 2.7225707MixupTrain:  epoch  0, batch   894 | loss: 2.2193689MixupTrain:  epoch  0, batch   895 | loss: 2.5005276MixupTrain:  epoch  0, batch   896 | loss: 2.0342104MixupTrain:  epoch  0, batch   897 | loss: 2.4430945MixupTrain:  epoch  0, batch   898 | loss: 2.4582672MixupTrain:  epoch  0, batch   899 | loss: 2.3389850MixupTrain:  epoch  0, batch   900 | loss: 2.4353247MixupTrain:  epoch  0, batch   901 | loss: 2.3605213MixupTrain:  epoch  0, batch   902 | loss: 2.2772484MixupTrain:  epoch  0, batch   903 | loss: 2.5516508MixupTrain:  epoch  0, batch   904 | loss: 2.7514658MixupTrain:  epoch  0, batch   905 | loss: 2.3191187MixupTrain:  epoch  0, batch   906 | loss: 2.3921523MixupTrain:  epoch  0, batch   907 | loss: 2.5680811MixupTrain:  epoch  0, batch   908 | loss: 2.0663767MixupTrain:  epoch  0, batch   909 | loss: 2.1180034MixupTrain:  epoch  0, batch   910 | loss: 2.2775807MixupTrain:  epoch  0, batch   911 | loss: 2.4999728MixupTrain:  epoch  0, batch   912 | loss: 2.2155175MixupTrain:  epoch  0, batch   913 | loss: 2.4936781MixupTrain:  epoch  0, batch   914 | loss: 2.3904405MixupTrain:  epoch  0, batch   915 | loss: 2.3439016MixupTrain:  epoch  0, batch   916 | loss: 2.1678364MixupTrain:  epoch  0, batch   917 | loss: 2.0377994MixupTrain:  epoch  0, batch   918 | loss: 2.4484978MixupTrain:  epoch  0, batch   919 | loss: 2.1908340MixupTrain:  epoch  0, batch   920 | loss: 2.2559874MixupTrain:  epoch  0, batch   921 | loss: 2.1748149MixupTrain:  epoch  0, batch   922 | loss: 2.3269279MixupTrain:  epoch  0, batch   923 | loss: 2.2164211MixupTrain:  epoch  0, batch   924 | loss: 2.5854855MixupTrain:  epoch  0, batch   925 | loss: 2.6192036MixupTrain:  epoch  0, batch   926 | loss: 2.3813794MixupTrain:  epoch  0, batch   927 | loss: 2.3739758MixupTrain:  epoch  0, batch   928 | loss: 2.2054141MixupTrain:  epoch  0, batch   929 | loss: 2.5687001MixupTrain:  epoch  0, batch   930 | loss: 2.3084395MixupTrain:  epoch  0, batch   931 | loss: 2.2831583MixupTrain:  epoch  0, batch   932 | loss: 2.5555103MixupTrain:  epoch  0, batch   933 | loss: 2.3762867MixupTrain:  epoch  0, batch   934 | loss: 2.2507024MixupTrain:  epoch  0, batch   935 | loss: 2.3472588MixupTrain:  epoch  0, batch   936 | loss: 2.2718158MixupTrain:  epoch  0, batch   937 | loss: 2.2089734MixupTrain:  epoch  0, batch   938 | loss: 2.4332604MixupTrain:  epoch  0, batch   939 | loss: 2.4231963MixupTrain:  epoch  0, batch   940 | loss: 2.2160292MixupTrain:  epoch  0, batch   941 | loss: 2.2914467MixupTrain:  epoch  0, batch   942 | loss: 2.5459809MixupTrain:  epoch  0, batch   943 | loss: 2.3270774MixupTrain:  epoch  0, batch   944 | loss: 2.4180851MixupTrain:  epoch  0, batch   945 | loss: 2.5122495MixupTrain:  epoch  0, batch   946 | loss: 2.1797419MixupTrain:  epoch  0, batch   947 | loss: 2.3648095MixupTrain:  epoch  0, batch   948 | loss: 2.3652906MixupTrain:  epoch  0, batch   949 | loss: 2.6048269MixupTrain:  epoch  0, batch   950 | loss: 2.3025517MixupTrain:  epoch  0, batch   951 | loss: 2.2241669MixupTrain:  epoch  0, batch   952 | loss: 2.6401644MixupTrain:  epoch  0, batch   953 | loss: 2.4136021MixupTrain:  epoch  0, batch   954 | loss: 2.2721078MixupTrain:  epoch  0, batch   955 | loss: 2.6757846MixupTrain:  epoch  0, batch   956 | loss: 2.2324657MixupTrain:  epoch  0, batch   957 | loss: 2.4286451MixupTrain:  epoch  0, batch   958 | loss: 2.0512955MixupTrain:  epoch  0, batch   959 | loss: 2.4479861MixupTrain:  epoch  0, batch   960 | loss: 2.4817064MixupTrain:  epoch  0, batch   961 | loss: 2.0070119MixupTrain:  epoch  0, batch   962 | loss: 2.3163900MixupTrain:  epoch  0, batch   963 | loss: 2.6023149MixupTrain:  epoch  0, batch   964 | loss: 2.2084723MixupTrain:  epoch  0, batch   965 | loss: 2.4819226MixupTrain:  epoch  0, batch   966 | loss: 2.4995980MixupTrain:  epoch  0, batch   967 | loss: 2.6419806MixupTrain:  epoch  0, batch   968 | loss: 2.2345252MixupTrain:  epoch  0, batch   969 | loss: 2.2292681MixupTrain:  epoch  0, batch   970 | loss: 2.1955290MixupTrain:  epoch  0, batch   971 | loss: 2.5469589MixupTrain:  epoch  0, batch   972 | loss: 2.2257123MixupTrain:  epoch  0, batch   973 | loss: 2.1912339MixupTrain:  epoch  0, batch   974 | loss: 2.7575417MixupTrain:  epoch  0, batch   975 | loss: 2.3121476MixupTrain:  epoch  0, batch   976 | loss: 2.4858963MixupTrain:  epoch  0, batch   977 | loss: 2.4166932MixupTrain:  epoch  0, batch   978 | loss: 2.4926500MixupTrain:  epoch  0, batch   979 | loss: 2.4814310MixupTrain:  epoch  0, batch   980 | loss: 2.2549391MixupTrain:  epoch  0, batch   981 | loss: 2.0209160
MemoryTrain:  epoch  0, batch     0 | loss: 2.1957519MemoryTrain:  epoch  0, batch     1 | loss: 2.8825212MemoryTrain:  epoch  0, batch     2 | loss: 2.4678102MemoryTrain:  epoch  0, batch     3 | loss: 2.8691258MemoryTrain:  epoch  0, batch     4 | loss: 3.7532125MemoryTrain:  epoch  0, batch     5 | loss: 2.1917064MemoryTrain:  epoch  0, batch     6 | loss: 2.3558326MemoryTrain:  epoch  0, batch     7 | loss: 2.3718853MemoryTrain:  epoch  0, batch     8 | loss: 2.2624240MemoryTrain:  epoch  0, batch     9 | loss: 2.0751529MemoryTrain:  epoch  1, batch     0 | loss: 1.8552021MemoryTrain:  epoch  1, batch     1 | loss: 1.8350849MemoryTrain:  epoch  1, batch     2 | loss: 1.8514543MemoryTrain:  epoch  1, batch     3 | loss: 1.8448790MemoryTrain:  epoch  1, batch     4 | loss: 1.8412571MemoryTrain:  epoch  1, batch     5 | loss: 1.8340175MemoryTrain:  epoch  1, batch     6 | loss: 1.8430724MemoryTrain:  epoch  1, batch     7 | loss: 1.8357089MemoryTrain:  epoch  1, batch     8 | loss: 1.8198704MemoryTrain:  epoch  1, batch     9 | loss: 1.8438413MemoryTrain:  epoch  2, batch     0 | loss: 1.8208995MemoryTrain:  epoch  2, batch     1 | loss: 1.8408716MemoryTrain:  epoch  2, batch     2 | loss: 1.8193173MemoryTrain:  epoch  2, batch     3 | loss: 1.8162575MemoryTrain:  epoch  2, batch     4 | loss: 1.8319976MemoryTrain:  epoch  2, batch     5 | loss: 1.8194981MemoryTrain:  epoch  2, batch     6 | loss: 1.8295300MemoryTrain:  epoch  2, batch     7 | loss: 1.8215349MemoryTrain:  epoch  2, batch     8 | loss: 1.8181039MemoryTrain:  epoch  2, batch     9 | loss: 1.8205103MemoryTrain:  epoch  3, batch     0 | loss: 1.8216206MemoryTrain:  epoch  3, batch     1 | loss: 1.8318501MemoryTrain:  epoch  3, batch     2 | loss: 1.8120872MemoryTrain:  epoch  3, batch     3 | loss: 1.8218455MemoryTrain:  epoch  3, batch     4 | loss: 1.8123441MemoryTrain:  epoch  3, batch     5 | loss: 1.8218253MemoryTrain:  epoch  3, batch     6 | loss: 1.8244385MemoryTrain:  epoch  3, batch     7 | loss: 1.8135264MemoryTrain:  epoch  3, batch     8 | loss: 1.8152101MemoryTrain:  epoch  3, batch     9 | loss: 1.8147056MemoryTrain:  epoch  4, batch     0 | loss: 1.8251700MemoryTrain:  epoch  4, batch     1 | loss: 1.8143878MemoryTrain:  epoch  4, batch     2 | loss: 1.8114944MemoryTrain:  epoch  4, batch     3 | loss: 1.8162887MemoryTrain:  epoch  4, batch     4 | loss: 1.8213215MemoryTrain:  epoch  4, batch     5 | loss: 1.8169303MemoryTrain:  epoch  4, batch     6 | loss: 1.8063591MemoryTrain:  epoch  4, batch     7 | loss: 1.8202956MemoryTrain:  epoch  4, batch     8 | loss: 1.8214949MemoryTrain:  epoch  4, batch     9 | loss: 1.8275135MemoryTrain:  epoch  5, batch     0 | loss: 1.8155775MemoryTrain:  epoch  5, batch     1 | loss: 1.8169036MemoryTrain:  epoch  5, batch     2 | loss: 1.8107443MemoryTrain:  epoch  5, batch     3 | loss: 1.8152403MemoryTrain:  epoch  5, batch     4 | loss: 1.8115577MemoryTrain:  epoch  5, batch     5 | loss: 1.8104500MemoryTrain:  epoch  5, batch     6 | loss: 1.8193147MemoryTrain:  epoch  5, batch     7 | loss: 1.8186846MemoryTrain:  epoch  5, batch     8 | loss: 1.8121670MemoryTrain:  epoch  5, batch     9 | loss: 1.8177176MemoryTrain:  epoch  6, batch     0 | loss: 1.8163074MemoryTrain:  epoch  6, batch     1 | loss: 1.8201535MemoryTrain:  epoch  6, batch     2 | loss: 1.8086867MemoryTrain:  epoch  6, batch     3 | loss: 1.8279605MemoryTrain:  epoch  6, batch     4 | loss: 1.8140235MemoryTrain:  epoch  6, batch     5 | loss: 1.8100560MemoryTrain:  epoch  6, batch     6 | loss: 1.8125715MemoryTrain:  epoch  6, batch     7 | loss: 1.8162084MemoryTrain:  epoch  6, batch     8 | loss: 1.8146217MemoryTrain:  epoch  6, batch     9 | loss: 1.8193487MemoryTrain:  epoch  7, batch     0 | loss: 1.8208067MemoryTrain:  epoch  7, batch     1 | loss: 1.8162062MemoryTrain:  epoch  7, batch     2 | loss: 1.8299127MemoryTrain:  epoch  7, batch     3 | loss: 1.8315969MemoryTrain:  epoch  7, batch     4 | loss: 1.8179684MemoryTrain:  epoch  7, batch     5 | loss: 1.8157126MemoryTrain:  epoch  7, batch     6 | loss: 1.8145378MemoryTrain:  epoch  7, batch     7 | loss: 1.8133376MemoryTrain:  epoch  7, batch     8 | loss: 1.8184234MemoryTrain:  epoch  7, batch     9 | loss: 1.8206996MemoryTrain:  epoch  8, batch     0 | loss: 1.8210571MemoryTrain:  epoch  8, batch     1 | loss: 1.8072451MemoryTrain:  epoch  8, batch     2 | loss: 1.8159891MemoryTrain:  epoch  8, batch     3 | loss: 1.8238332MemoryTrain:  epoch  8, batch     4 | loss: 1.8150978MemoryTrain:  epoch  8, batch     5 | loss: 1.8157344MemoryTrain:  epoch  8, batch     6 | loss: 1.8232793MemoryTrain:  epoch  8, batch     7 | loss: 1.8197037MemoryTrain:  epoch  8, batch     8 | loss: 1.8134449MemoryTrain:  epoch  8, batch     9 | loss: 1.8193258MemoryTrain:  epoch  9, batch     0 | loss: 1.8208983MemoryTrain:  epoch  9, batch     1 | loss: 1.8180459MemoryTrain:  epoch  9, batch     2 | loss: 1.8182534MemoryTrain:  epoch  9, batch     3 | loss: 1.8198863MemoryTrain:  epoch  9, batch     4 | loss: 1.8115168MemoryTrain:  epoch  9, batch     5 | loss: 1.8166239MemoryTrain:  epoch  9, batch     6 | loss: 1.8123813MemoryTrain:  epoch  9, batch     7 | loss: 1.8134959MemoryTrain:  epoch  9, batch     8 | loss: 1.8119291MemoryTrain:  epoch  9, batch     9 | loss: 1.8136466
[EVAL] batch:    0 | acc: 62.50%,  total acc: 62.50%   [EVAL] batch:    1 | acc: 75.00%,  total acc: 68.75%   [EVAL] batch:    2 | acc: 81.25%,  total acc: 72.92%   [EVAL] batch:    3 | acc: 75.00%,  total acc: 73.44%   [EVAL] batch:    4 | acc: 100.00%,  total acc: 78.75%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 82.29%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 84.82%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 85.94%   [EVAL] batch:    8 | acc: 87.50%,  total acc: 86.11%   [EVAL] batch:    9 | acc: 87.50%,  total acc: 86.25%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 87.50%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:   12 | acc: 50.00%,  total acc: 84.62%   
[EVAL] batch:    0 | acc: 25.00%,  total acc: 25.00%   [EVAL] batch:    1 | acc: 43.75%,  total acc: 34.38%   [EVAL] batch:    2 | acc: 43.75%,  total acc: 37.50%   [EVAL] batch:    3 | acc: 18.75%,  total acc: 32.81%   [EVAL] batch:    4 | acc: 31.25%,  total acc: 32.50%   [EVAL] batch:    5 | acc: 37.50%,  total acc: 33.33%   [EVAL] batch:    6 | acc: 87.50%,  total acc: 41.07%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 47.66%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 53.47%   [EVAL] batch:    9 | acc: 87.50%,  total acc: 56.88%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 60.80%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 63.02%   [EVAL] batch:   12 | acc: 50.00%,  total acc: 62.02%   [EVAL] batch:   13 | acc: 25.00%,  total acc: 59.38%   [EVAL] batch:   14 | acc: 43.75%,  total acc: 58.33%   [EVAL] batch:   15 | acc: 43.75%,  total acc: 57.42%   [EVAL] batch:   16 | acc: 68.75%,  total acc: 58.09%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 58.33%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 58.55%   [EVAL] batch:   19 | acc: 62.50%,  total acc: 58.75%   [EVAL] batch:   20 | acc: 93.75%,  total acc: 60.42%   [EVAL] batch:   21 | acc: 93.75%,  total acc: 61.93%   [EVAL] batch:   22 | acc: 87.50%,  total acc: 63.04%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 64.32%   [EVAL] batch:   24 | acc: 100.00%,  total acc: 65.75%   [EVAL] batch:   25 | acc: 93.75%,  total acc: 66.83%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 67.59%   [EVAL] batch:   27 | acc: 75.00%,  total acc: 67.86%   [EVAL] batch:   28 | acc: 87.50%,  total acc: 68.53%   [EVAL] batch:   29 | acc: 62.50%,  total acc: 68.33%   [EVAL] batch:   30 | acc: 68.75%,  total acc: 68.35%   [EVAL] batch:   31 | acc: 75.00%,  total acc: 68.55%   [EVAL] batch:   32 | acc: 43.75%,  total acc: 67.80%   [EVAL] batch:   33 | acc: 12.50%,  total acc: 66.18%   [EVAL] batch:   34 | acc: 18.75%,  total acc: 64.82%   [EVAL] batch:   35 | acc: 18.75%,  total acc: 63.54%   [EVAL] batch:   36 | acc: 18.75%,  total acc: 62.33%   [EVAL] batch:   37 | acc: 0.00%,  total acc: 60.69%   [EVAL] batch:   38 | acc: 25.00%,  total acc: 59.78%   [EVAL] batch:   39 | acc: 75.00%,  total acc: 60.16%   [EVAL] batch:   40 | acc: 50.00%,  total acc: 59.91%   [EVAL] batch:   41 | acc: 18.75%,  total acc: 58.93%   [EVAL] batch:   42 | acc: 37.50%,  total acc: 58.43%   [EVAL] batch:   43 | acc: 68.75%,  total acc: 58.66%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 59.58%   [EVAL] batch:   45 | acc: 100.00%,  total acc: 60.46%   [EVAL] batch:   46 | acc: 100.00%,  total acc: 61.30%   [EVAL] batch:   47 | acc: 100.00%,  total acc: 62.11%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 62.88%   [EVAL] batch:   49 | acc: 100.00%,  total acc: 63.62%   [EVAL] batch:   50 | acc: 43.75%,  total acc: 63.24%   [EVAL] batch:   51 | acc: 0.00%,  total acc: 62.02%   [EVAL] batch:   52 | acc: 6.25%,  total acc: 60.97%   [EVAL] batch:   53 | acc: 0.00%,  total acc: 59.84%   [EVAL] batch:   54 | acc: 0.00%,  total acc: 58.75%   [EVAL] batch:   55 | acc: 0.00%,  total acc: 57.70%   [EVAL] batch:   56 | acc: 50.00%,  total acc: 57.57%   [EVAL] batch:   57 | acc: 87.50%,  total acc: 58.08%   [EVAL] batch:   58 | acc: 68.75%,  total acc: 58.26%   [EVAL] batch:   59 | acc: 87.50%,  total acc: 58.75%   [EVAL] batch:   60 | acc: 75.00%,  total acc: 59.02%   [EVAL] batch:   61 | acc: 62.50%,  total acc: 59.07%   [EVAL] batch:   62 | acc: 93.75%,  total acc: 59.62%   [EVAL] batch:   63 | acc: 93.75%,  total acc: 60.16%   [EVAL] batch:   64 | acc: 100.00%,  total acc: 60.77%   [EVAL] batch:   65 | acc: 100.00%,  total acc: 61.36%   [EVAL] batch:   66 | acc: 100.00%,  total acc: 61.94%   [EVAL] batch:   67 | acc: 100.00%,  total acc: 62.50%   [EVAL] batch:   68 | acc: 100.00%,  total acc: 63.04%   [EVAL] batch:   69 | acc: 100.00%,  total acc: 63.57%   [EVAL] batch:   70 | acc: 100.00%,  total acc: 64.08%   [EVAL] batch:   71 | acc: 93.75%,  total acc: 64.50%   [EVAL] batch:   72 | acc: 37.50%,  total acc: 64.13%   [EVAL] batch:   73 | acc: 68.75%,  total acc: 64.19%   [EVAL] batch:   74 | acc: 100.00%,  total acc: 64.67%   [EVAL] batch:   75 | acc: 100.00%,  total acc: 65.13%   [EVAL] batch:   76 | acc: 100.00%,  total acc: 65.58%   [EVAL] batch:   77 | acc: 62.50%,  total acc: 65.54%   [EVAL] batch:   78 | acc: 75.00%,  total acc: 65.66%   [EVAL] batch:   79 | acc: 81.25%,  total acc: 65.86%   [EVAL] batch:   80 | acc: 75.00%,  total acc: 65.97%   [EVAL] batch:   81 | acc: 100.00%,  total acc: 66.39%   [EVAL] batch:   82 | acc: 100.00%,  total acc: 66.79%   [EVAL] batch:   83 | acc: 100.00%,  total acc: 67.19%   [EVAL] batch:   84 | acc: 93.75%,  total acc: 67.50%   [EVAL] batch:   85 | acc: 93.75%,  total acc: 67.81%   [EVAL] batch:   86 | acc: 81.25%,  total acc: 67.96%   [EVAL] batch:   87 | acc: 100.00%,  total acc: 68.32%   [EVAL] batch:   88 | acc: 87.50%,  total acc: 68.54%   [EVAL] batch:   89 | acc: 56.25%,  total acc: 68.40%   
cur_acc:  ['0.8693', '0.9132', '0.8929', '0.9107', '0.8462']
his_acc:  ['0.8693', '0.8550', '0.8311', '0.7484', '0.6840']
CurrentTrain: epoch  0, batch     0 | loss: 6.0219703CurrentTrain: epoch  0, batch     1 | loss: 5.0637665CurrentTrain: epoch  1, batch     0 | loss: 4.8938632CurrentTrain: epoch  1, batch     1 | loss: 5.4117508CurrentTrain: epoch  2, batch     0 | loss: 4.7919807CurrentTrain: epoch  2, batch     1 | loss: 4.7431741CurrentTrain: epoch  3, batch     0 | loss: 5.2100835CurrentTrain: epoch  3, batch     1 | loss: 3.4834740CurrentTrain: epoch  4, batch     0 | loss: 3.8545797CurrentTrain: epoch  4, batch     1 | loss: 4.3692636CurrentTrain: epoch  5, batch     0 | loss: 3.5747252CurrentTrain: epoch  5, batch     1 | loss: 3.6945775CurrentTrain: epoch  6, batch     0 | loss: 3.6340516CurrentTrain: epoch  6, batch     1 | loss: 3.5650907CurrentTrain: epoch  7, batch     0 | loss: 3.7708142CurrentTrain: epoch  7, batch     1 | loss: 2.3808153CurrentTrain: epoch  8, batch     0 | loss: 3.1274691CurrentTrain: epoch  8, batch     1 | loss: 2.2711403CurrentTrain: epoch  9, batch     0 | loss: 2.4629817CurrentTrain: epoch  9, batch     1 | loss: 2.5238867
#### person stateorprovinces of residence ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person stateorprovinces of residence" means a person is living in a state or province.
Here is an example:
Relation: person stateorprovinces of residence
Context: ny-schools-chief -lrb- new york -rrb- -- cathleen p. black , mayor michael r. bloomberg 's choice to be the next chancellor of new york city 's public-school system , has during more than 40 years in the media business broken numerous glass ceilings -- and amassed a fortune -- with quick and cold-blooded decision making , crystal-clear goal setting , and an all-surpassing attention to the bottom line .
Head Entity: cathleen p. black
Tail Entity: new york
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person stateorprovinces of residence":
Relation: person stateorprovinces of residence  
Context: After years of living in the bustling city, actor Tom Hanks has decided to settle down in a quieter area, choosing to make his home in the picturesque state of California.  
Head Entity: Tom Hanks  
Tail Entity: California  

Relation: person stateorprovinces of residence  
Context: The renowned author J.K. Rowling has spent much of her life in Edinburgh, where she found inspiration for her famous Harry Potter series.  
Head Entity: J.K. Rowling  
Tail Entity: Edinburgh  

Relation: person stateorprovinces of residence  
Context: Following his successful career in the tech industry, entrepreneur Elon Musk has moved to Texas, where he plans to expand his business ventures.  
Head Entity: Elon Musk  
Tail Entity: Texas  

Relation: person stateorprovinces of residence  
Context: After retiring from professional basketball, Michael Jordan chose to reside in Florida, enjoying the warm climate and vibrant community.  
Head Entity: Michael Jordan  
Tail Entity: Florida  

Relation: person stateorprovinces of residence  
Context: The famous singer Adele has made her home in Los Angeles, where she enjoys the sunny weather and the entertainment industry.  
Head Entity: Adele  
Tail Entity: Los Angeles  
#### person date of death ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person date of death" means a person was died on a date.
Here is an example:
Relation: person date of death
Context: today the nypd upgraded the charges to include murder , in the case of brooklyn gay-bashing/robbery victim michael sandy , who died on friday after being taken off life-support .
Head Entity: michael sandy
Tail Entity: friday
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person date of death":
Relation: person date of death  
Context: The renowned physicist Stephen Hawking passed away peacefully at his home in Cambridge on March 14, 2018, at the age of 76.  
Head Entity: Stephen Hawking  
Tail Entity: March 14, 2018  

Relation: person date of death  
Context: The beloved actor Robin Williams was found dead in his home in Paradise Cay, California, on August 11, 2014, which shocked fans around the world.  
Head Entity: Robin Williams  
Tail Entity: August 11, 2014  

Relation: person date of death  
Context: The famous author Gabriel García Márquez, known for his magical realism, died on April 17, 2014, in Mexico City.  
Head Entity: Gabriel García Márquez  
Tail Entity: April 17, 2014  

Relation: person date of death  
Context: The legendary musician David Bowie passed away after a long battle with cancer on January 10, 2016, just two days after his birthday.  
Head Entity: David Bowie  
Tail Entity: January 10, 2016  

Relation: person date of death  
Context: The civil rights leader Martin Luther King Jr. was assassinated on April 4, 1968, in Memphis, Tennessee, leaving a lasting legacy.  
Head Entity: Martin Luther King Jr.  
Tail Entity: April 4, 1968  
#### organization number of employees members ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization number of employees members" means the number of an organization 's employees is a number.
Here is an example:
Relation: organization number of employees members
Context: with the sweep of a federal regulator 's pen , massachusetts stands to gain a new life-science giant in april : covidien , a medical - supplies maker with thousands of products and more than 43,000 employees worldwide .
Head Entity: covidien
Tail Entity: 43,000
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization number of employees members":
Relation: organization number of employees members  
Context: The tech company Apple has been expanding its workforce significantly, currently employing over 147,000 people across the globe.  
Head Entity: Apple  
Tail Entity: 147,000  

Relation: organization number of employees members  
Context: In 2022, the multinational corporation Amazon reported a staggering total of 1.5 million employees, making it one of the largest employers in the world.  
Head Entity: Amazon  
Tail Entity: 1.5 million  

Relation: organization number of employees members  
Context: Google, known for its innovative technology and services, has a workforce that exceeds 156,000 employees as of the latest reports.  
Head Entity: Google  
Tail Entity: 156,000  

Relation: organization number of employees members  
Context: The automotive giant Toyota has a global workforce of approximately 360,000 employees, contributing to its status as a leading car manufacturer.  
Head Entity: Toyota  
Tail Entity: 360,000  

Relation: organization number of employees members  
Context: With a commitment to sustainability, the renewable energy company NextEra Energy employs around 15,000 individuals dedicated to clean energy solutions.  
Head Entity: NextEra Energy  
Tail Entity: 15,000  
#### person alternate names ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person alternate names" means a person 's alias is a person.
Here is an example:
Relation: person alternate names
Context: a judge in new york city said remy ma , whose real name is remy smith , said thursday that the hip-hopper could not leave the united states for a five-country european concert tour .
Head Entity: remy smith
Tail Entity: remy ma
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person alternate names":
Relation: person alternate names  
Context: The famous author Samuel Langhorne Clemens, better known by his pen name Mark Twain, wrote many classic novels.  
Head Entity: Samuel Langhorne Clemens  
Tail Entity: Mark Twain  

Relation: person alternate names  
Context: The musician Stefani Joanne Angelina Germanotta, who is widely recognized as Lady Gaga, has made a significant impact on pop culture.  
Head Entity: Stefani Joanne Angelina Germanotta  
Tail Entity: Lady Gaga  

Relation: person alternate names  
Context: The actor and filmmaker known as Orson Welles was born George Orson Welles and is famous for his innovative work in cinema.  
Head Entity: George Orson Welles  
Tail Entity: Orson Welles  

Relation: person alternate names  
Context: The renowned physicist Albert Einstein, who is often referred to simply as Einstein, developed the theory of relativity.  
Head Entity: Albert Einstein  
Tail Entity: Einstein  

Relation: person alternate names  
Context: The legendary singer and songwriter Robert Zimmerman is better known by his stage name Bob Dylan.  
Head Entity: Robert Zimmerman  
Tail Entity: Bob Dylan  
#### person spouse ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person spouse" means a person 's spouse is a person.
Here is an example:
Relation: person spouse
Context: smits stands at the center of this multigenerational saga as alex vega , the adopted son of rum and sugar baron pancho duque -lrb- elizondo -rrb- and his wife , amalia -lrb- moreno -rrb- .
Head Entity: elizondo
Tail Entity: moreno
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person spouse":
Relation: person spouse  
Context: After years of working together, the renowned artist, jennifer lopez, finally tied the knot with her long-time partner, marc anthony, in a lavish ceremony.  
Head Entity: lopez  
Tail Entity: anthony  

Relation: person spouse  
Context: In a heartwarming ceremony, the famous actor, tom hanks, exchanged vows with his beloved wife, rita wilson, surrounded by family and friends.  
Head Entity: hanks  
Tail Entity: wilson  

Relation: person spouse  
Context: The couple, prince harry and meghan markle, celebrated their love with a royal wedding that captivated millions around the world.  
Head Entity: harry  
Tail Entity: markle  

Relation: person spouse  
Context: The legendary musician, paul mccartney, has been happily married to his wife, nancy shevell, for several years now.  
Head Entity: mccartney  
Tail Entity: shevell  

Relation: person spouse  
Context: The beloved television host, oprah winfrey, has shared a beautiful life with her partner, stedman graham, for decades.  
Head Entity: winfrey  
Tail Entity: graham  
Mixup data size:  21490
MixupTrain:  epoch  0, batch     0 | loss: 3.8967710MixupTrain:  epoch  0, batch     1 | loss: 4.0738244MixupTrain:  epoch  0, batch     2 | loss: 3.1270463MixupTrain:  epoch  0, batch     3 | loss: 3.6358371MixupTrain:  epoch  0, batch     4 | loss: 3.3013315MixupTrain:  epoch  0, batch     5 | loss: 3.2092633MixupTrain:  epoch  0, batch     6 | loss: 4.6425858MixupTrain:  epoch  0, batch     7 | loss: 4.2309957MixupTrain:  epoch  0, batch     8 | loss: 3.3994601MixupTrain:  epoch  0, batch     9 | loss: 3.9794521MixupTrain:  epoch  0, batch    10 | loss: 3.4140964MixupTrain:  epoch  0, batch    11 | loss: 3.4403157MixupTrain:  epoch  0, batch    12 | loss: 3.3018584MixupTrain:  epoch  0, batch    13 | loss: 3.1321018MixupTrain:  epoch  0, batch    14 | loss: 2.9087205MixupTrain:  epoch  0, batch    15 | loss: 3.3493524MixupTrain:  epoch  0, batch    16 | loss: 3.4081187MixupTrain:  epoch  0, batch    17 | loss: 3.0625699MixupTrain:  epoch  0, batch    18 | loss: 2.9284918MixupTrain:  epoch  0, batch    19 | loss: 4.1595964MixupTrain:  epoch  0, batch    20 | loss: 3.0958357MixupTrain:  epoch  0, batch    21 | loss: 2.5421882MixupTrain:  epoch  0, batch    22 | loss: 3.3718333MixupTrain:  epoch  0, batch    23 | loss: 3.1799839MixupTrain:  epoch  0, batch    24 | loss: 3.3090792MixupTrain:  epoch  0, batch    25 | loss: 4.1949463MixupTrain:  epoch  0, batch    26 | loss: 3.3741632MixupTrain:  epoch  0, batch    27 | loss: 2.9025769MixupTrain:  epoch  0, batch    28 | loss: 3.0141687MixupTrain:  epoch  0, batch    29 | loss: 3.4699380MixupTrain:  epoch  0, batch    30 | loss: 2.5362949MixupTrain:  epoch  0, batch    31 | loss: 2.9046197MixupTrain:  epoch  0, batch    32 | loss: 2.9568419MixupTrain:  epoch  0, batch    33 | loss: 2.3260312MixupTrain:  epoch  0, batch    34 | loss: 3.0556619MixupTrain:  epoch  0, batch    35 | loss: 2.7994301MixupTrain:  epoch  0, batch    36 | loss: 3.4799099MixupTrain:  epoch  0, batch    37 | loss: 3.3406844MixupTrain:  epoch  0, batch    38 | loss: 2.3649468MixupTrain:  epoch  0, batch    39 | loss: 3.5894334MixupTrain:  epoch  0, batch    40 | loss: 2.3568649MixupTrain:  epoch  0, batch    41 | loss: 3.1495316MixupTrain:  epoch  0, batch    42 | loss: 2.4277916MixupTrain:  epoch  0, batch    43 | loss: 2.6467052MixupTrain:  epoch  0, batch    44 | loss: 2.9007149MixupTrain:  epoch  0, batch    45 | loss: 3.1384568MixupTrain:  epoch  0, batch    46 | loss: 2.2264113MixupTrain:  epoch  0, batch    47 | loss: 2.2500176MixupTrain:  epoch  0, batch    48 | loss: 2.6556325MixupTrain:  epoch  0, batch    49 | loss: 3.4866941MixupTrain:  epoch  0, batch    50 | loss: 2.7511835MixupTrain:  epoch  0, batch    51 | loss: 2.3082480MixupTrain:  epoch  0, batch    52 | loss: 2.5309458MixupTrain:  epoch  0, batch    53 | loss: 3.3809884MixupTrain:  epoch  0, batch    54 | loss: 2.8023520MixupTrain:  epoch  0, batch    55 | loss: 2.4589987MixupTrain:  epoch  0, batch    56 | loss: 2.5479584MixupTrain:  epoch  0, batch    57 | loss: 2.6916299MixupTrain:  epoch  0, batch    58 | loss: 2.8537459MixupTrain:  epoch  0, batch    59 | loss: 2.5539153MixupTrain:  epoch  0, batch    60 | loss: 2.3487864MixupTrain:  epoch  0, batch    61 | loss: 2.4605784MixupTrain:  epoch  0, batch    62 | loss: 2.8246493MixupTrain:  epoch  0, batch    63 | loss: 2.5208819MixupTrain:  epoch  0, batch    64 | loss: 2.6940260MixupTrain:  epoch  0, batch    65 | loss: 2.8039207MixupTrain:  epoch  0, batch    66 | loss: 2.2519207MixupTrain:  epoch  0, batch    67 | loss: 2.4776106MixupTrain:  epoch  0, batch    68 | loss: 2.8992760MixupTrain:  epoch  0, batch    69 | loss: 2.3203621MixupTrain:  epoch  0, batch    70 | loss: 2.6789012MixupTrain:  epoch  0, batch    71 | loss: 3.1947196MixupTrain:  epoch  0, batch    72 | loss: 3.5542326MixupTrain:  epoch  0, batch    73 | loss: 2.5623693MixupTrain:  epoch  0, batch    74 | loss: 2.5813379MixupTrain:  epoch  0, batch    75 | loss: 2.6257999MixupTrain:  epoch  0, batch    76 | loss: 2.3648329MixupTrain:  epoch  0, batch    77 | loss: 2.3466909MixupTrain:  epoch  0, batch    78 | loss: 2.4468656MixupTrain:  epoch  0, batch    79 | loss: 2.6206717MixupTrain:  epoch  0, batch    80 | loss: 3.4627738MixupTrain:  epoch  0, batch    81 | loss: 2.8097057MixupTrain:  epoch  0, batch    82 | loss: 2.8174007MixupTrain:  epoch  0, batch    83 | loss: 2.9000237MixupTrain:  epoch  0, batch    84 | loss: 2.5838895MixupTrain:  epoch  0, batch    85 | loss: 2.6458933MixupTrain:  epoch  0, batch    86 | loss: 3.0303812MixupTrain:  epoch  0, batch    87 | loss: 2.5219083MixupTrain:  epoch  0, batch    88 | loss: 2.6873398MixupTrain:  epoch  0, batch    89 | loss: 2.6072841MixupTrain:  epoch  0, batch    90 | loss: 2.3382618MixupTrain:  epoch  0, batch    91 | loss: 2.5763488MixupTrain:  epoch  0, batch    92 | loss: 2.4496403MixupTrain:  epoch  0, batch    93 | loss: 2.3592901MixupTrain:  epoch  0, batch    94 | loss: 2.9073687MixupTrain:  epoch  0, batch    95 | loss: 3.3281257MixupTrain:  epoch  0, batch    96 | loss: 2.8671100MixupTrain:  epoch  0, batch    97 | loss: 2.6169119MixupTrain:  epoch  0, batch    98 | loss: 2.7422740MixupTrain:  epoch  0, batch    99 | loss: 2.5459042MixupTrain:  epoch  0, batch   100 | loss: 2.9737942MixupTrain:  epoch  0, batch   101 | loss: 2.6151981MixupTrain:  epoch  0, batch   102 | loss: 2.5990529MixupTrain:  epoch  0, batch   103 | loss: 2.2729566MixupTrain:  epoch  0, batch   104 | loss: 2.6131456MixupTrain:  epoch  0, batch   105 | loss: 2.6403415MixupTrain:  epoch  0, batch   106 | loss: 2.4602125MixupTrain:  epoch  0, batch   107 | loss: 2.8697824MixupTrain:  epoch  0, batch   108 | loss: 2.4500871MixupTrain:  epoch  0, batch   109 | loss: 2.5240786MixupTrain:  epoch  0, batch   110 | loss: 2.2966697MixupTrain:  epoch  0, batch   111 | loss: 2.3522000MixupTrain:  epoch  0, batch   112 | loss: 2.7090383MixupTrain:  epoch  0, batch   113 | loss: 2.6979842MixupTrain:  epoch  0, batch   114 | loss: 2.4211884MixupTrain:  epoch  0, batch   115 | loss: 2.4556594MixupTrain:  epoch  0, batch   116 | loss: 2.3924413MixupTrain:  epoch  0, batch   117 | loss: 2.4904633MixupTrain:  epoch  0, batch   118 | loss: 2.5788138MixupTrain:  epoch  0, batch   119 | loss: 2.4646089MixupTrain:  epoch  0, batch   120 | loss: 2.5503449MixupTrain:  epoch  0, batch   121 | loss: 2.6550703MixupTrain:  epoch  0, batch   122 | loss: 2.4294753MixupTrain:  epoch  0, batch   123 | loss: 2.6045983MixupTrain:  epoch  0, batch   124 | loss: 2.3325520MixupTrain:  epoch  0, batch   125 | loss: 2.5947473MixupTrain:  epoch  0, batch   126 | loss: 2.6691256MixupTrain:  epoch  0, batch   127 | loss: 2.7658007MixupTrain:  epoch  0, batch   128 | loss: 2.0368979MixupTrain:  epoch  0, batch   129 | loss: 2.2065306MixupTrain:  epoch  0, batch   130 | loss: 2.4914899MixupTrain:  epoch  0, batch   131 | loss: 2.3059368MixupTrain:  epoch  0, batch   132 | loss: 2.1973610MixupTrain:  epoch  0, batch   133 | loss: 2.5074036MixupTrain:  epoch  0, batch   134 | loss: 2.5109611MixupTrain:  epoch  0, batch   135 | loss: 2.6785595MixupTrain:  epoch  0, batch   136 | loss: 2.5402441MixupTrain:  epoch  0, batch   137 | loss: 2.1313705MixupTrain:  epoch  0, batch   138 | loss: 2.2114387MixupTrain:  epoch  0, batch   139 | loss: 2.5373960MixupTrain:  epoch  0, batch   140 | loss: 2.3423784MixupTrain:  epoch  0, batch   141 | loss: 2.2149191MixupTrain:  epoch  0, batch   142 | loss: 2.2106781MixupTrain:  epoch  0, batch   143 | loss: 2.5126536MixupTrain:  epoch  0, batch   144 | loss: 2.6210148MixupTrain:  epoch  0, batch   145 | loss: 2.1322484MixupTrain:  epoch  0, batch   146 | loss: 2.2721438MixupTrain:  epoch  0, batch   147 | loss: 2.8148322MixupTrain:  epoch  0, batch   148 | loss: 2.6849298MixupTrain:  epoch  0, batch   149 | loss: 2.1866298MixupTrain:  epoch  0, batch   150 | loss: 2.0760581MixupTrain:  epoch  0, batch   151 | loss: 2.4942255MixupTrain:  epoch  0, batch   152 | loss: 2.2297242MixupTrain:  epoch  0, batch   153 | loss: 2.2767544MixupTrain:  epoch  0, batch   154 | loss: 2.4356537MixupTrain:  epoch  0, batch   155 | loss: 2.1751499MixupTrain:  epoch  0, batch   156 | loss: 2.7063963MixupTrain:  epoch  0, batch   157 | loss: 2.5179689MixupTrain:  epoch  0, batch   158 | loss: 2.1701047MixupTrain:  epoch  0, batch   159 | loss: 2.1830959MixupTrain:  epoch  0, batch   160 | loss: 2.6283646MixupTrain:  epoch  0, batch   161 | loss: 2.2079308MixupTrain:  epoch  0, batch   162 | loss: 2.4701915MixupTrain:  epoch  0, batch   163 | loss: 2.2695632MixupTrain:  epoch  0, batch   164 | loss: 2.3785295MixupTrain:  epoch  0, batch   165 | loss: 2.7389112MixupTrain:  epoch  0, batch   166 | loss: 2.2621083MixupTrain:  epoch  0, batch   167 | loss: 2.5138996MixupTrain:  epoch  0, batch   168 | loss: 2.2425833MixupTrain:  epoch  0, batch   169 | loss: 2.2615070MixupTrain:  epoch  0, batch   170 | loss: 2.2194366MixupTrain:  epoch  0, batch   171 | loss: 2.3721128MixupTrain:  epoch  0, batch   172 | loss: 2.5214047MixupTrain:  epoch  0, batch   173 | loss: 1.8744693MixupTrain:  epoch  0, batch   174 | loss: 2.4550438MixupTrain:  epoch  0, batch   175 | loss: 2.3817351MixupTrain:  epoch  0, batch   176 | loss: 2.2709208MixupTrain:  epoch  0, batch   177 | loss: 2.2861524MixupTrain:  epoch  0, batch   178 | loss: 2.3934944MixupTrain:  epoch  0, batch   179 | loss: 2.1294978MixupTrain:  epoch  0, batch   180 | loss: 2.5747781MixupTrain:  epoch  0, batch   181 | loss: 2.4565730MixupTrain:  epoch  0, batch   182 | loss: 2.2505875MixupTrain:  epoch  0, batch   183 | loss: 2.0143590MixupTrain:  epoch  0, batch   184 | loss: 2.7185397MixupTrain:  epoch  0, batch   185 | loss: 2.3686423MixupTrain:  epoch  0, batch   186 | loss: 2.4442973MixupTrain:  epoch  0, batch   187 | loss: 2.5083780MixupTrain:  epoch  0, batch   188 | loss: 2.4897335MixupTrain:  epoch  0, batch   189 | loss: 2.3437662MixupTrain:  epoch  0, batch   190 | loss: 1.9978937MixupTrain:  epoch  0, batch   191 | loss: 2.5423307MixupTrain:  epoch  0, batch   192 | loss: 2.5597324MixupTrain:  epoch  0, batch   193 | loss: 2.2351696MixupTrain:  epoch  0, batch   194 | loss: 2.4711528MixupTrain:  epoch  0, batch   195 | loss: 2.2287676MixupTrain:  epoch  0, batch   196 | loss: 2.2885242MixupTrain:  epoch  0, batch   197 | loss: 2.3688407MixupTrain:  epoch  0, batch   198 | loss: 2.3480654MixupTrain:  epoch  0, batch   199 | loss: 2.1951289MixupTrain:  epoch  0, batch   200 | loss: 2.2213554MixupTrain:  epoch  0, batch   201 | loss: 2.8260937MixupTrain:  epoch  0, batch   202 | loss: 2.3826058MixupTrain:  epoch  0, batch   203 | loss: 2.2895195MixupTrain:  epoch  0, batch   204 | loss: 2.5457139MixupTrain:  epoch  0, batch   205 | loss: 2.3012891MixupTrain:  epoch  0, batch   206 | loss: 2.2781444MixupTrain:  epoch  0, batch   207 | loss: 2.7865665MixupTrain:  epoch  0, batch   208 | loss: 1.9451290MixupTrain:  epoch  0, batch   209 | loss: 2.3445868MixupTrain:  epoch  0, batch   210 | loss: 2.2786343MixupTrain:  epoch  0, batch   211 | loss: 2.1994720MixupTrain:  epoch  0, batch   212 | loss: 2.3182507MixupTrain:  epoch  0, batch   213 | loss: 2.3355439MixupTrain:  epoch  0, batch   214 | loss: 2.4961438MixupTrain:  epoch  0, batch   215 | loss: 2.1750765MixupTrain:  epoch  0, batch   216 | loss: 2.2996864MixupTrain:  epoch  0, batch   217 | loss: 2.4378178MixupTrain:  epoch  0, batch   218 | loss: 2.2711582MixupTrain:  epoch  0, batch   219 | loss: 2.3632479MixupTrain:  epoch  0, batch   220 | loss: 2.1843057MixupTrain:  epoch  0, batch   221 | loss: 2.5008821MixupTrain:  epoch  0, batch   222 | loss: 2.1884093MixupTrain:  epoch  0, batch   223 | loss: 2.3172264MixupTrain:  epoch  0, batch   224 | loss: 2.3295884MixupTrain:  epoch  0, batch   225 | loss: 2.2332544MixupTrain:  epoch  0, batch   226 | loss: 2.5351372MixupTrain:  epoch  0, batch   227 | loss: 2.2677417MixupTrain:  epoch  0, batch   228 | loss: 2.1757922MixupTrain:  epoch  0, batch   229 | loss: 2.3500576MixupTrain:  epoch  0, batch   230 | loss: 2.3994801MixupTrain:  epoch  0, batch   231 | loss: 2.2294846MixupTrain:  epoch  0, batch   232 | loss: 2.3284512MixupTrain:  epoch  0, batch   233 | loss: 2.4339900MixupTrain:  epoch  0, batch   234 | loss: 2.1522291MixupTrain:  epoch  0, batch   235 | loss: 2.2216704MixupTrain:  epoch  0, batch   236 | loss: 2.3875723MixupTrain:  epoch  0, batch   237 | loss: 2.2885807MixupTrain:  epoch  0, batch   238 | loss: 2.1866689MixupTrain:  epoch  0, batch   239 | loss: 2.1935554MixupTrain:  epoch  0, batch   240 | loss: 2.4151642MixupTrain:  epoch  0, batch   241 | loss: 2.3920209MixupTrain:  epoch  0, batch   242 | loss: 2.3230286MixupTrain:  epoch  0, batch   243 | loss: 2.3586745MixupTrain:  epoch  0, batch   244 | loss: 2.3495278MixupTrain:  epoch  0, batch   245 | loss: 2.3664000MixupTrain:  epoch  0, batch   246 | loss: 2.2133698MixupTrain:  epoch  0, batch   247 | loss: 2.7641842MixupTrain:  epoch  0, batch   248 | loss: 2.3565807MixupTrain:  epoch  0, batch   249 | loss: 2.3981705MixupTrain:  epoch  0, batch   250 | loss: 2.7112036MixupTrain:  epoch  0, batch   251 | loss: 2.2808416MixupTrain:  epoch  0, batch   252 | loss: 2.3291433MixupTrain:  epoch  0, batch   253 | loss: 2.0160499MixupTrain:  epoch  0, batch   254 | loss: 2.5712914MixupTrain:  epoch  0, batch   255 | loss: 2.0891218MixupTrain:  epoch  0, batch   256 | loss: 2.3717384MixupTrain:  epoch  0, batch   257 | loss: 2.1522679MixupTrain:  epoch  0, batch   258 | loss: 2.3260636MixupTrain:  epoch  0, batch   259 | loss: 2.5301657MixupTrain:  epoch  0, batch   260 | loss: 2.2825918MixupTrain:  epoch  0, batch   261 | loss: 2.1050212MixupTrain:  epoch  0, batch   262 | loss: 2.2105212MixupTrain:  epoch  0, batch   263 | loss: 2.2503185MixupTrain:  epoch  0, batch   264 | loss: 2.1862636MixupTrain:  epoch  0, batch   265 | loss: 2.2830637MixupTrain:  epoch  0, batch   266 | loss: 2.0721583MixupTrain:  epoch  0, batch   267 | loss: 2.0548587MixupTrain:  epoch  0, batch   268 | loss: 1.9927410MixupTrain:  epoch  0, batch   269 | loss: 2.3461020MixupTrain:  epoch  0, batch   270 | loss: 2.3804047MixupTrain:  epoch  0, batch   271 | loss: 1.9840295MixupTrain:  epoch  0, batch   272 | loss: 2.0175633MixupTrain:  epoch  0, batch   273 | loss: 2.7381606MixupTrain:  epoch  0, batch   274 | loss: 2.3760719MixupTrain:  epoch  0, batch   275 | loss: 2.5670371MixupTrain:  epoch  0, batch   276 | loss: 2.2192273MixupTrain:  epoch  0, batch   277 | loss: 2.4665813MixupTrain:  epoch  0, batch   278 | loss: 2.3027847MixupTrain:  epoch  0, batch   279 | loss: 2.2929053MixupTrain:  epoch  0, batch   280 | loss: 2.2087944MixupTrain:  epoch  0, batch   281 | loss: 2.2013535MixupTrain:  epoch  0, batch   282 | loss: 2.3146100MixupTrain:  epoch  0, batch   283 | loss: 2.3775811MixupTrain:  epoch  0, batch   284 | loss: 2.1388292MixupTrain:  epoch  0, batch   285 | loss: 2.2884698MixupTrain:  epoch  0, batch   286 | loss: 2.2395959MixupTrain:  epoch  0, batch   287 | loss: 2.1538105MixupTrain:  epoch  0, batch   288 | loss: 2.1702256MixupTrain:  epoch  0, batch   289 | loss: 2.6051688MixupTrain:  epoch  0, batch   290 | loss: 2.3411295MixupTrain:  epoch  0, batch   291 | loss: 2.2073793MixupTrain:  epoch  0, batch   292 | loss: 2.1826377MixupTrain:  epoch  0, batch   293 | loss: 2.3726330MixupTrain:  epoch  0, batch   294 | loss: 1.9618983MixupTrain:  epoch  0, batch   295 | loss: 2.4658587MixupTrain:  epoch  0, batch   296 | loss: 2.2273033MixupTrain:  epoch  0, batch   297 | loss: 2.4260888MixupTrain:  epoch  0, batch   298 | loss: 2.5819702MixupTrain:  epoch  0, batch   299 | loss: 2.5539179MixupTrain:  epoch  0, batch   300 | loss: 2.0668483MixupTrain:  epoch  0, batch   301 | loss: 2.2040601MixupTrain:  epoch  0, batch   302 | loss: 2.3162727MixupTrain:  epoch  0, batch   303 | loss: 2.3771763MixupTrain:  epoch  0, batch   304 | loss: 2.3960214MixupTrain:  epoch  0, batch   305 | loss: 2.3146303MixupTrain:  epoch  0, batch   306 | loss: 2.1925125MixupTrain:  epoch  0, batch   307 | loss: 2.3660271MixupTrain:  epoch  0, batch   308 | loss: 2.4395335MixupTrain:  epoch  0, batch   309 | loss: 2.1832771MixupTrain:  epoch  0, batch   310 | loss: 2.0972950MixupTrain:  epoch  0, batch   311 | loss: 2.2090249MixupTrain:  epoch  0, batch   312 | loss: 2.7020040MixupTrain:  epoch  0, batch   313 | loss: 2.3540514MixupTrain:  epoch  0, batch   314 | loss: 2.6392214MixupTrain:  epoch  0, batch   315 | loss: 2.1408219MixupTrain:  epoch  0, batch   316 | loss: 2.5206580MixupTrain:  epoch  0, batch   317 | loss: 2.3173265MixupTrain:  epoch  0, batch   318 | loss: 2.3761864MixupTrain:  epoch  0, batch   319 | loss: 2.5056899MixupTrain:  epoch  0, batch   320 | loss: 2.2972980MixupTrain:  epoch  0, batch   321 | loss: 2.2490711MixupTrain:  epoch  0, batch   322 | loss: 2.0937276MixupTrain:  epoch  0, batch   323 | loss: 2.0972159MixupTrain:  epoch  0, batch   324 | loss: 2.4816668MixupTrain:  epoch  0, batch   325 | loss: 2.3513231MixupTrain:  epoch  0, batch   326 | loss: 2.2698841MixupTrain:  epoch  0, batch   327 | loss: 2.0862317MixupTrain:  epoch  0, batch   328 | loss: 2.3936028MixupTrain:  epoch  0, batch   329 | loss: 2.4114904MixupTrain:  epoch  0, batch   330 | loss: 2.2401295MixupTrain:  epoch  0, batch   331 | loss: 2.4535029MixupTrain:  epoch  0, batch   332 | loss: 2.6957855MixupTrain:  epoch  0, batch   333 | loss: 2.2476134MixupTrain:  epoch  0, batch   334 | loss: 2.4949827MixupTrain:  epoch  0, batch   335 | loss: 2.6710558MixupTrain:  epoch  0, batch   336 | loss: 2.3806877MixupTrain:  epoch  0, batch   337 | loss: 2.4523714MixupTrain:  epoch  0, batch   338 | loss: 2.6039672MixupTrain:  epoch  0, batch   339 | loss: 2.1580164MixupTrain:  epoch  0, batch   340 | loss: 2.2257056MixupTrain:  epoch  0, batch   341 | loss: 2.2490294MixupTrain:  epoch  0, batch   342 | loss: 2.5920701MixupTrain:  epoch  0, batch   343 | loss: 2.2879052MixupTrain:  epoch  0, batch   344 | loss: 2.1887736MixupTrain:  epoch  0, batch   345 | loss: 2.4519534MixupTrain:  epoch  0, batch   346 | loss: 2.7146435MixupTrain:  epoch  0, batch   347 | loss: 2.5225806MixupTrain:  epoch  0, batch   348 | loss: 2.4032376MixupTrain:  epoch  0, batch   349 | loss: 2.2143526MixupTrain:  epoch  0, batch   350 | loss: 2.0596993MixupTrain:  epoch  0, batch   351 | loss: 2.3380463MixupTrain:  epoch  0, batch   352 | loss: 2.2091534MixupTrain:  epoch  0, batch   353 | loss: 2.2798870MixupTrain:  epoch  0, batch   354 | loss: 2.2422888MixupTrain:  epoch  0, batch   355 | loss: 2.3223753MixupTrain:  epoch  0, batch   356 | loss: 2.4947557MixupTrain:  epoch  0, batch   357 | loss: 2.3954675MixupTrain:  epoch  0, batch   358 | loss: 2.3224177MixupTrain:  epoch  0, batch   359 | loss: 2.3546443MixupTrain:  epoch  0, batch   360 | loss: 2.3623748MixupTrain:  epoch  0, batch   361 | loss: 2.1292076MixupTrain:  epoch  0, batch   362 | loss: 2.0809085MixupTrain:  epoch  0, batch   363 | loss: 2.3282573MixupTrain:  epoch  0, batch   364 | loss: 1.9677444MixupTrain:  epoch  0, batch   365 | loss: 2.4162393MixupTrain:  epoch  0, batch   366 | loss: 2.0779538MixupTrain:  epoch  0, batch   367 | loss: 2.3291698MixupTrain:  epoch  0, batch   368 | loss: 2.3831573MixupTrain:  epoch  0, batch   369 | loss: 2.0443513MixupTrain:  epoch  0, batch   370 | loss: 2.2742367MixupTrain:  epoch  0, batch   371 | loss: 2.4019868MixupTrain:  epoch  0, batch   372 | loss: 2.2030258MixupTrain:  epoch  0, batch   373 | loss: 2.2803705MixupTrain:  epoch  0, batch   374 | loss: 2.2296491MixupTrain:  epoch  0, batch   375 | loss: 2.4252200MixupTrain:  epoch  0, batch   376 | loss: 2.0706010MixupTrain:  epoch  0, batch   377 | loss: 2.3269618MixupTrain:  epoch  0, batch   378 | loss: 2.3653364MixupTrain:  epoch  0, batch   379 | loss: 2.5546269MixupTrain:  epoch  0, batch   380 | loss: 2.1130352MixupTrain:  epoch  0, batch   381 | loss: 2.3651085MixupTrain:  epoch  0, batch   382 | loss: 2.1043537MixupTrain:  epoch  0, batch   383 | loss: 2.1561151MixupTrain:  epoch  0, batch   384 | loss: 2.1747942MixupTrain:  epoch  0, batch   385 | loss: 2.1837587MixupTrain:  epoch  0, batch   386 | loss: 2.3179986MixupTrain:  epoch  0, batch   387 | loss: 2.3758254MixupTrain:  epoch  0, batch   388 | loss: 2.1791215MixupTrain:  epoch  0, batch   389 | loss: 2.3149383MixupTrain:  epoch  0, batch   390 | loss: 2.3127723MixupTrain:  epoch  0, batch   391 | loss: 2.2288713MixupTrain:  epoch  0, batch   392 | loss: 2.1635389MixupTrain:  epoch  0, batch   393 | loss: 2.3568063MixupTrain:  epoch  0, batch   394 | loss: 2.2946136MixupTrain:  epoch  0, batch   395 | loss: 2.2224631MixupTrain:  epoch  0, batch   396 | loss: 2.1974945MixupTrain:  epoch  0, batch   397 | loss: 2.2490644MixupTrain:  epoch  0, batch   398 | loss: 2.5330873MixupTrain:  epoch  0, batch   399 | loss: 2.2012141MixupTrain:  epoch  0, batch   400 | loss: 2.1160059MixupTrain:  epoch  0, batch   401 | loss: 2.2953734MixupTrain:  epoch  0, batch   402 | loss: 2.4986656MixupTrain:  epoch  0, batch   403 | loss: 2.2812297MixupTrain:  epoch  0, batch   404 | loss: 2.1819773MixupTrain:  epoch  0, batch   405 | loss: 2.4115939MixupTrain:  epoch  0, batch   406 | loss: 2.3184035MixupTrain:  epoch  0, batch   407 | loss: 2.4153104MixupTrain:  epoch  0, batch   408 | loss: 2.3208349MixupTrain:  epoch  0, batch   409 | loss: 2.1250505MixupTrain:  epoch  0, batch   410 | loss: 2.1377387MixupTrain:  epoch  0, batch   411 | loss: 2.1466691MixupTrain:  epoch  0, batch   412 | loss: 2.2576101MixupTrain:  epoch  0, batch   413 | loss: 2.1517696MixupTrain:  epoch  0, batch   414 | loss: 2.2116237MixupTrain:  epoch  0, batch   415 | loss: 2.0731635MixupTrain:  epoch  0, batch   416 | loss: 2.1644506MixupTrain:  epoch  0, batch   417 | loss: 2.1406903MixupTrain:  epoch  0, batch   418 | loss: 2.2450564MixupTrain:  epoch  0, batch   419 | loss: 2.2334476MixupTrain:  epoch  0, batch   420 | loss: 2.1873579MixupTrain:  epoch  0, batch   421 | loss: 2.3411884MixupTrain:  epoch  0, batch   422 | loss: 2.2366612MixupTrain:  epoch  0, batch   423 | loss: 2.2893543MixupTrain:  epoch  0, batch   424 | loss: 2.4388149MixupTrain:  epoch  0, batch   425 | loss: 2.0155880MixupTrain:  epoch  0, batch   426 | loss: 2.3262548MixupTrain:  epoch  0, batch   427 | loss: 2.2128816MixupTrain:  epoch  0, batch   428 | loss: 2.3608370MixupTrain:  epoch  0, batch   429 | loss: 2.2652214MixupTrain:  epoch  0, batch   430 | loss: 1.9806240MixupTrain:  epoch  0, batch   431 | loss: 2.0519125MixupTrain:  epoch  0, batch   432 | loss: 2.0727699MixupTrain:  epoch  0, batch   433 | loss: 2.2030566MixupTrain:  epoch  0, batch   434 | loss: 2.1607873MixupTrain:  epoch  0, batch   435 | loss: 2.3847580MixupTrain:  epoch  0, batch   436 | loss: 2.1251817MixupTrain:  epoch  0, batch   437 | loss: 2.3381238MixupTrain:  epoch  0, batch   438 | loss: 2.2077336MixupTrain:  epoch  0, batch   439 | loss: 2.1174269MixupTrain:  epoch  0, batch   440 | loss: 2.0150657MixupTrain:  epoch  0, batch   441 | loss: 2.4161787MixupTrain:  epoch  0, batch   442 | loss: 2.3463461MixupTrain:  epoch  0, batch   443 | loss: 2.3391726MixupTrain:  epoch  0, batch   444 | loss: 2.3661196MixupTrain:  epoch  0, batch   445 | loss: 2.1199207MixupTrain:  epoch  0, batch   446 | loss: 2.3166504MixupTrain:  epoch  0, batch   447 | loss: 2.1744282MixupTrain:  epoch  0, batch   448 | loss: 2.3468261MixupTrain:  epoch  0, batch   449 | loss: 2.2549088MixupTrain:  epoch  0, batch   450 | loss: 2.0772338MixupTrain:  epoch  0, batch   451 | loss: 2.0394075MixupTrain:  epoch  0, batch   452 | loss: 2.1149011MixupTrain:  epoch  0, batch   453 | loss: 2.2523141MixupTrain:  epoch  0, batch   454 | loss: 2.1143031MixupTrain:  epoch  0, batch   455 | loss: 2.3700273MixupTrain:  epoch  0, batch   456 | loss: 2.1567948MixupTrain:  epoch  0, batch   457 | loss: 1.9103138MixupTrain:  epoch  0, batch   458 | loss: 2.4722667MixupTrain:  epoch  0, batch   459 | loss: 1.9853710MixupTrain:  epoch  0, batch   460 | loss: 2.2587497MixupTrain:  epoch  0, batch   461 | loss: 2.3135326MixupTrain:  epoch  0, batch   462 | loss: 2.3873398MixupTrain:  epoch  0, batch   463 | loss: 2.1727295MixupTrain:  epoch  0, batch   464 | loss: 2.1976352MixupTrain:  epoch  0, batch   465 | loss: 2.2655392MixupTrain:  epoch  0, batch   466 | loss: 2.4564543MixupTrain:  epoch  0, batch   467 | loss: 2.1444900MixupTrain:  epoch  0, batch   468 | loss: 2.4845796MixupTrain:  epoch  0, batch   469 | loss: 2.1054721MixupTrain:  epoch  0, batch   470 | loss: 2.3991911MixupTrain:  epoch  0, batch   471 | loss: 2.3564234MixupTrain:  epoch  0, batch   472 | loss: 2.3591011MixupTrain:  epoch  0, batch   473 | loss: 2.1873083MixupTrain:  epoch  0, batch   474 | loss: 2.2848148MixupTrain:  epoch  0, batch   475 | loss: 2.4029665MixupTrain:  epoch  0, batch   476 | loss: 2.3055656MixupTrain:  epoch  0, batch   477 | loss: 2.3206875MixupTrain:  epoch  0, batch   478 | loss: 2.5324497MixupTrain:  epoch  0, batch   479 | loss: 2.0535724MixupTrain:  epoch  0, batch   480 | loss: 2.2386069MixupTrain:  epoch  0, batch   481 | loss: 2.1536920MixupTrain:  epoch  0, batch   482 | loss: 2.3039660MixupTrain:  epoch  0, batch   483 | loss: 2.3383794MixupTrain:  epoch  0, batch   484 | loss: 2.4928029MixupTrain:  epoch  0, batch   485 | loss: 2.1350694MixupTrain:  epoch  0, batch   486 | loss: 2.5544190MixupTrain:  epoch  0, batch   487 | loss: 2.1853848MixupTrain:  epoch  0, batch   488 | loss: 2.4584374MixupTrain:  epoch  0, batch   489 | loss: 2.4605494MixupTrain:  epoch  0, batch   490 | loss: 2.2522159MixupTrain:  epoch  0, batch   491 | loss: 2.0570989MixupTrain:  epoch  0, batch   492 | loss: 2.3655949MixupTrain:  epoch  0, batch   493 | loss: 2.3002167MixupTrain:  epoch  0, batch   494 | loss: 2.2285137MixupTrain:  epoch  0, batch   495 | loss: 2.2393618MixupTrain:  epoch  0, batch   496 | loss: 2.2549257MixupTrain:  epoch  0, batch   497 | loss: 2.2089391MixupTrain:  epoch  0, batch   498 | loss: 2.1344366MixupTrain:  epoch  0, batch   499 | loss: 2.4163930MixupTrain:  epoch  0, batch   500 | loss: 2.2405283MixupTrain:  epoch  0, batch   501 | loss: 2.3855977MixupTrain:  epoch  0, batch   502 | loss: 2.1631360MixupTrain:  epoch  0, batch   503 | loss: 2.3864090MixupTrain:  epoch  0, batch   504 | loss: 2.1990454MixupTrain:  epoch  0, batch   505 | loss: 2.2095954MixupTrain:  epoch  0, batch   506 | loss: 2.2981644MixupTrain:  epoch  0, batch   507 | loss: 2.2024860MixupTrain:  epoch  0, batch   508 | loss: 2.3955865MixupTrain:  epoch  0, batch   509 | loss: 2.5534916MixupTrain:  epoch  0, batch   510 | loss: 2.1619170MixupTrain:  epoch  0, batch   511 | loss: 2.4534202MixupTrain:  epoch  0, batch   512 | loss: 2.0570893MixupTrain:  epoch  0, batch   513 | loss: 2.5235474MixupTrain:  epoch  0, batch   514 | loss: 2.1789291MixupTrain:  epoch  0, batch   515 | loss: 2.1691923MixupTrain:  epoch  0, batch   516 | loss: 2.3573241MixupTrain:  epoch  0, batch   517 | loss: 2.2132449MixupTrain:  epoch  0, batch   518 | loss: 2.3015752MixupTrain:  epoch  0, batch   519 | loss: 2.2511482MixupTrain:  epoch  0, batch   520 | loss: 2.3475938MixupTrain:  epoch  0, batch   521 | loss: 2.1411672MixupTrain:  epoch  0, batch   522 | loss: 2.1035254MixupTrain:  epoch  0, batch   523 | loss: 2.1583998MixupTrain:  epoch  0, batch   524 | loss: 2.3326511MixupTrain:  epoch  0, batch   525 | loss: 2.2966912MixupTrain:  epoch  0, batch   526 | loss: 2.0387392MixupTrain:  epoch  0, batch   527 | loss: 2.2615604MixupTrain:  epoch  0, batch   528 | loss: 2.2026501MixupTrain:  epoch  0, batch   529 | loss: 2.1848776MixupTrain:  epoch  0, batch   530 | loss: 2.0604804MixupTrain:  epoch  0, batch   531 | loss: 2.5691164MixupTrain:  epoch  0, batch   532 | loss: 2.1100209MixupTrain:  epoch  0, batch   533 | loss: 2.2828245MixupTrain:  epoch  0, batch   534 | loss: 2.2683945MixupTrain:  epoch  0, batch   535 | loss: 2.3581607MixupTrain:  epoch  0, batch   536 | loss: 2.1270256MixupTrain:  epoch  0, batch   537 | loss: 2.4121048MixupTrain:  epoch  0, batch   538 | loss: 2.4419122MixupTrain:  epoch  0, batch   539 | loss: 2.1633444MixupTrain:  epoch  0, batch   540 | loss: 2.1824987MixupTrain:  epoch  0, batch   541 | loss: 2.1556597MixupTrain:  epoch  0, batch   542 | loss: 2.3032804MixupTrain:  epoch  0, batch   543 | loss: 2.4314253MixupTrain:  epoch  0, batch   544 | loss: 2.4084301MixupTrain:  epoch  0, batch   545 | loss: 2.5032077MixupTrain:  epoch  0, batch   546 | loss: 2.3786478MixupTrain:  epoch  0, batch   547 | loss: 2.1947460MixupTrain:  epoch  0, batch   548 | loss: 2.0932703MixupTrain:  epoch  0, batch   549 | loss: 2.3448286MixupTrain:  epoch  0, batch   550 | loss: 2.4791479MixupTrain:  epoch  0, batch   551 | loss: 2.3612449MixupTrain:  epoch  0, batch   552 | loss: 2.3181090MixupTrain:  epoch  0, batch   553 | loss: 2.2991900MixupTrain:  epoch  0, batch   554 | loss: 2.0786850MixupTrain:  epoch  0, batch   555 | loss: 2.0713997MixupTrain:  epoch  0, batch   556 | loss: 1.9100510MixupTrain:  epoch  0, batch   557 | loss: 2.2153978MixupTrain:  epoch  0, batch   558 | loss: 2.1269112MixupTrain:  epoch  0, batch   559 | loss: 2.0797026MixupTrain:  epoch  0, batch   560 | loss: 2.2659359MixupTrain:  epoch  0, batch   561 | loss: 2.6476912MixupTrain:  epoch  0, batch   562 | loss: 2.3315616MixupTrain:  epoch  0, batch   563 | loss: 2.2028353MixupTrain:  epoch  0, batch   564 | loss: 2.4408031MixupTrain:  epoch  0, batch   565 | loss: 2.2207832MixupTrain:  epoch  0, batch   566 | loss: 2.5077782MixupTrain:  epoch  0, batch   567 | loss: 2.2710862MixupTrain:  epoch  0, batch   568 | loss: 2.4627099MixupTrain:  epoch  0, batch   569 | loss: 2.2918048MixupTrain:  epoch  0, batch   570 | loss: 2.3102336MixupTrain:  epoch  0, batch   571 | loss: 2.2593045MixupTrain:  epoch  0, batch   572 | loss: 2.3677950MixupTrain:  epoch  0, batch   573 | loss: 2.2818460MixupTrain:  epoch  0, batch   574 | loss: 2.1156244MixupTrain:  epoch  0, batch   575 | loss: 2.2372756MixupTrain:  epoch  0, batch   576 | loss: 2.0450788MixupTrain:  epoch  0, batch   577 | loss: 2.1782937MixupTrain:  epoch  0, batch   578 | loss: 2.1438882MixupTrain:  epoch  0, batch   579 | loss: 2.4389136MixupTrain:  epoch  0, batch   580 | loss: 2.1896820MixupTrain:  epoch  0, batch   581 | loss: 1.9753220MixupTrain:  epoch  0, batch   582 | loss: 2.3440137MixupTrain:  epoch  0, batch   583 | loss: 2.2757626MixupTrain:  epoch  0, batch   584 | loss: 2.1069300MixupTrain:  epoch  0, batch   585 | loss: 2.3113492MixupTrain:  epoch  0, batch   586 | loss: 1.9015719MixupTrain:  epoch  0, batch   587 | loss: 2.0303755MixupTrain:  epoch  0, batch   588 | loss: 2.0957022MixupTrain:  epoch  0, batch   589 | loss: 2.1285813MixupTrain:  epoch  0, batch   590 | loss: 2.2785635MixupTrain:  epoch  0, batch   591 | loss: 2.0930896MixupTrain:  epoch  0, batch   592 | loss: 2.0733342MixupTrain:  epoch  0, batch   593 | loss: 2.2103834MixupTrain:  epoch  0, batch   594 | loss: 2.2656894MixupTrain:  epoch  0, batch   595 | loss: 2.1384187MixupTrain:  epoch  0, batch   596 | loss: 2.3745708MixupTrain:  epoch  0, batch   597 | loss: 1.9886463MixupTrain:  epoch  0, batch   598 | loss: 2.3247881MixupTrain:  epoch  0, batch   599 | loss: 2.0976887MixupTrain:  epoch  0, batch   600 | loss: 2.4342828MixupTrain:  epoch  0, batch   601 | loss: 2.0724177MixupTrain:  epoch  0, batch   602 | loss: 2.0812171MixupTrain:  epoch  0, batch   603 | loss: 2.1793995MixupTrain:  epoch  0, batch   604 | loss: 2.1231499MixupTrain:  epoch  0, batch   605 | loss: 2.1650157MixupTrain:  epoch  0, batch   606 | loss: 2.3014305MixupTrain:  epoch  0, batch   607 | loss: 2.3870335MixupTrain:  epoch  0, batch   608 | loss: 2.5907974MixupTrain:  epoch  0, batch   609 | loss: 2.0384209MixupTrain:  epoch  0, batch   610 | loss: 2.1161294MixupTrain:  epoch  0, batch   611 | loss: 2.0833888MixupTrain:  epoch  0, batch   612 | loss: 2.3487012MixupTrain:  epoch  0, batch   613 | loss: 2.1341095MixupTrain:  epoch  0, batch   614 | loss: 2.4632363MixupTrain:  epoch  0, batch   615 | loss: 2.1190801MixupTrain:  epoch  0, batch   616 | loss: 2.5735040MixupTrain:  epoch  0, batch   617 | loss: 2.1124923MixupTrain:  epoch  0, batch   618 | loss: 2.4500353MixupTrain:  epoch  0, batch   619 | loss: 2.3346946MixupTrain:  epoch  0, batch   620 | loss: 2.0723825MixupTrain:  epoch  0, batch   621 | loss: 2.3614564MixupTrain:  epoch  0, batch   622 | loss: 2.1670613MixupTrain:  epoch  0, batch   623 | loss: 2.2263327MixupTrain:  epoch  0, batch   624 | loss: 2.3170853MixupTrain:  epoch  0, batch   625 | loss: 2.2854905MixupTrain:  epoch  0, batch   626 | loss: 2.3047101MixupTrain:  epoch  0, batch   627 | loss: 2.2829885MixupTrain:  epoch  0, batch   628 | loss: 2.2716198MixupTrain:  epoch  0, batch   629 | loss: 2.3704665MixupTrain:  epoch  0, batch   630 | loss: 2.4841621MixupTrain:  epoch  0, batch   631 | loss: 2.2988739MixupTrain:  epoch  0, batch   632 | loss: 2.3249676MixupTrain:  epoch  0, batch   633 | loss: 2.4460452MixupTrain:  epoch  0, batch   634 | loss: 2.1408386MixupTrain:  epoch  0, batch   635 | loss: 2.4242179MixupTrain:  epoch  0, batch   636 | loss: 2.2441492MixupTrain:  epoch  0, batch   637 | loss: 2.1094642MixupTrain:  epoch  0, batch   638 | loss: 2.2670226MixupTrain:  epoch  0, batch   639 | loss: 2.5193348MixupTrain:  epoch  0, batch   640 | loss: 2.2781837MixupTrain:  epoch  0, batch   641 | loss: 2.2180283MixupTrain:  epoch  0, batch   642 | loss: 2.5300202MixupTrain:  epoch  0, batch   643 | loss: 2.1810489MixupTrain:  epoch  0, batch   644 | loss: 2.0097580MixupTrain:  epoch  0, batch   645 | loss: 2.3931353MixupTrain:  epoch  0, batch   646 | loss: 2.1616106MixupTrain:  epoch  0, batch   647 | loss: 2.0078297MixupTrain:  epoch  0, batch   648 | loss: 2.1853013MixupTrain:  epoch  0, batch   649 | loss: 2.3795917MixupTrain:  epoch  0, batch   650 | loss: 2.2103577MixupTrain:  epoch  0, batch   651 | loss: 2.4671719MixupTrain:  epoch  0, batch   652 | loss: 2.1698821MixupTrain:  epoch  0, batch   653 | loss: 2.4360051MixupTrain:  epoch  0, batch   654 | loss: 2.1643217MixupTrain:  epoch  0, batch   655 | loss: 2.2562151MixupTrain:  epoch  0, batch   656 | loss: 2.2973659MixupTrain:  epoch  0, batch   657 | loss: 2.6789072MixupTrain:  epoch  0, batch   658 | loss: 2.2790453MixupTrain:  epoch  0, batch   659 | loss: 2.2979398MixupTrain:  epoch  0, batch   660 | loss: 2.1702135MixupTrain:  epoch  0, batch   661 | loss: 1.9678030MixupTrain:  epoch  0, batch   662 | loss: 2.3409371MixupTrain:  epoch  0, batch   663 | loss: 2.1376917MixupTrain:  epoch  0, batch   664 | loss: 2.1460838MixupTrain:  epoch  0, batch   665 | loss: 2.4423862MixupTrain:  epoch  0, batch   666 | loss: 2.0259886MixupTrain:  epoch  0, batch   667 | loss: 2.1053357MixupTrain:  epoch  0, batch   668 | loss: 2.1351607MixupTrain:  epoch  0, batch   669 | loss: 2.4251399MixupTrain:  epoch  0, batch   670 | loss: 2.5620496MixupTrain:  epoch  0, batch   671 | loss: 2.0812078MixupTrain:  epoch  0, batch   672 | loss: 2.5538106MixupTrain:  epoch  0, batch   673 | loss: 2.3012052MixupTrain:  epoch  0, batch   674 | loss: 2.1931248MixupTrain:  epoch  0, batch   675 | loss: 2.0081017MixupTrain:  epoch  0, batch   676 | loss: 2.3045163MixupTrain:  epoch  0, batch   677 | loss: 2.0849767MixupTrain:  epoch  0, batch   678 | loss: 2.3680389MixupTrain:  epoch  0, batch   679 | loss: 2.2536175MixupTrain:  epoch  0, batch   680 | loss: 2.1602297MixupTrain:  epoch  0, batch   681 | loss: 2.0880582MixupTrain:  epoch  0, batch   682 | loss: 2.1749537MixupTrain:  epoch  0, batch   683 | loss: 2.6697717MixupTrain:  epoch  0, batch   684 | loss: 1.9443406MixupTrain:  epoch  0, batch   685 | loss: 2.4717467MixupTrain:  epoch  0, batch   686 | loss: 2.6198182MixupTrain:  epoch  0, batch   687 | loss: 2.5192151MixupTrain:  epoch  0, batch   688 | loss: 2.2423353MixupTrain:  epoch  0, batch   689 | loss: 2.2699523MixupTrain:  epoch  0, batch   690 | loss: 2.1755970MixupTrain:  epoch  0, batch   691 | loss: 2.0975313MixupTrain:  epoch  0, batch   692 | loss: 1.9137038MixupTrain:  epoch  0, batch   693 | loss: 2.1025305MixupTrain:  epoch  0, batch   694 | loss: 2.0948780MixupTrain:  epoch  0, batch   695 | loss: 2.3922262MixupTrain:  epoch  0, batch   696 | loss: 2.0008843MixupTrain:  epoch  0, batch   697 | loss: 2.3252933MixupTrain:  epoch  0, batch   698 | loss: 2.3735666MixupTrain:  epoch  0, batch   699 | loss: 2.3278079MixupTrain:  epoch  0, batch   700 | loss: 2.1490116MixupTrain:  epoch  0, batch   701 | loss: 2.3939614MixupTrain:  epoch  0, batch   702 | loss: 2.1455898MixupTrain:  epoch  0, batch   703 | loss: 2.4984570MixupTrain:  epoch  0, batch   704 | loss: 2.0962207MixupTrain:  epoch  0, batch   705 | loss: 2.1883078MixupTrain:  epoch  0, batch   706 | loss: 2.1296744MixupTrain:  epoch  0, batch   707 | loss: 2.1982086MixupTrain:  epoch  0, batch   708 | loss: 2.0650289MixupTrain:  epoch  0, batch   709 | loss: 2.1313887MixupTrain:  epoch  0, batch   710 | loss: 2.2845559MixupTrain:  epoch  0, batch   711 | loss: 2.3390338MixupTrain:  epoch  0, batch   712 | loss: 2.2759578MixupTrain:  epoch  0, batch   713 | loss: 2.2990608MixupTrain:  epoch  0, batch   714 | loss: 2.5152452MixupTrain:  epoch  0, batch   715 | loss: 2.4017200MixupTrain:  epoch  0, batch   716 | loss: 2.3184803MixupTrain:  epoch  0, batch   717 | loss: 2.2004180MixupTrain:  epoch  0, batch   718 | loss: 1.9865211MixupTrain:  epoch  0, batch   719 | loss: 2.0384500MixupTrain:  epoch  0, batch   720 | loss: 2.0709646MixupTrain:  epoch  0, batch   721 | loss: 2.2697995MixupTrain:  epoch  0, batch   722 | loss: 2.3198354MixupTrain:  epoch  0, batch   723 | loss: 2.3133194MixupTrain:  epoch  0, batch   724 | loss: 2.1712050MixupTrain:  epoch  0, batch   725 | loss: 2.2640562MixupTrain:  epoch  0, batch   726 | loss: 2.2234378MixupTrain:  epoch  0, batch   727 | loss: 2.2318678MixupTrain:  epoch  0, batch   728 | loss: 2.4370944MixupTrain:  epoch  0, batch   729 | loss: 2.4266386MixupTrain:  epoch  0, batch   730 | loss: 2.4026904MixupTrain:  epoch  0, batch   731 | loss: 2.3157792MixupTrain:  epoch  0, batch   732 | loss: 2.2257748MixupTrain:  epoch  0, batch   733 | loss: 2.2372813MixupTrain:  epoch  0, batch   734 | loss: 2.1245055MixupTrain:  epoch  0, batch   735 | loss: 2.5378947MixupTrain:  epoch  0, batch   736 | loss: 2.2478788MixupTrain:  epoch  0, batch   737 | loss: 2.3883886MixupTrain:  epoch  0, batch   738 | loss: 2.4723303MixupTrain:  epoch  0, batch   739 | loss: 2.2603743MixupTrain:  epoch  0, batch   740 | loss: 2.1902323MixupTrain:  epoch  0, batch   741 | loss: 2.0658746MixupTrain:  epoch  0, batch   742 | loss: 2.1708627MixupTrain:  epoch  0, batch   743 | loss: 2.6635354MixupTrain:  epoch  0, batch   744 | loss: 2.1048620MixupTrain:  epoch  0, batch   745 | loss: 2.2961850MixupTrain:  epoch  0, batch   746 | loss: 2.1013205MixupTrain:  epoch  0, batch   747 | loss: 2.0714738MixupTrain:  epoch  0, batch   748 | loss: 2.3332748MixupTrain:  epoch  0, batch   749 | loss: 2.2233577MixupTrain:  epoch  0, batch   750 | loss: 2.1413455MixupTrain:  epoch  0, batch   751 | loss: 2.2492390MixupTrain:  epoch  0, batch   752 | loss: 2.2071311MixupTrain:  epoch  0, batch   753 | loss: 2.1546741MixupTrain:  epoch  0, batch   754 | loss: 2.1954777MixupTrain:  epoch  0, batch   755 | loss: 2.0330939MixupTrain:  epoch  0, batch   756 | loss: 2.3465233MixupTrain:  epoch  0, batch   757 | loss: 2.2470984MixupTrain:  epoch  0, batch   758 | loss: 2.2125697MixupTrain:  epoch  0, batch   759 | loss: 2.0939441MixupTrain:  epoch  0, batch   760 | loss: 2.1458867MixupTrain:  epoch  0, batch   761 | loss: 2.3408036MixupTrain:  epoch  0, batch   762 | loss: 2.2777591MixupTrain:  epoch  0, batch   763 | loss: 2.2477865MixupTrain:  epoch  0, batch   764 | loss: 2.1465557MixupTrain:  epoch  0, batch   765 | loss: 2.0315683MixupTrain:  epoch  0, batch   766 | loss: 2.2913318MixupTrain:  epoch  0, batch   767 | loss: 2.3264887MixupTrain:  epoch  0, batch   768 | loss: 2.2200069MixupTrain:  epoch  0, batch   769 | loss: 2.2433290MixupTrain:  epoch  0, batch   770 | loss: 2.3000898MixupTrain:  epoch  0, batch   771 | loss: 2.2014420MixupTrain:  epoch  0, batch   772 | loss: 2.1533058MixupTrain:  epoch  0, batch   773 | loss: 2.4797311MixupTrain:  epoch  0, batch   774 | loss: 2.2790966MixupTrain:  epoch  0, batch   775 | loss: 2.2567163MixupTrain:  epoch  0, batch   776 | loss: 2.2331145MixupTrain:  epoch  0, batch   777 | loss: 2.1748869MixupTrain:  epoch  0, batch   778 | loss: 2.1146932MixupTrain:  epoch  0, batch   779 | loss: 2.3422153MixupTrain:  epoch  0, batch   780 | loss: 2.3407626MixupTrain:  epoch  0, batch   781 | loss: 2.1410890MixupTrain:  epoch  0, batch   782 | loss: 2.1424513MixupTrain:  epoch  0, batch   783 | loss: 2.2601085MixupTrain:  epoch  0, batch   784 | loss: 2.2990320MixupTrain:  epoch  0, batch   785 | loss: 2.2658181MixupTrain:  epoch  0, batch   786 | loss: 2.3509479MixupTrain:  epoch  0, batch   787 | loss: 2.3399200MixupTrain:  epoch  0, batch   788 | loss: 2.1398282MixupTrain:  epoch  0, batch   789 | loss: 2.2244272MixupTrain:  epoch  0, batch   790 | loss: 2.3884084MixupTrain:  epoch  0, batch   791 | loss: 2.2140493MixupTrain:  epoch  0, batch   792 | loss: 2.0760813MixupTrain:  epoch  0, batch   793 | loss: 2.1792326MixupTrain:  epoch  0, batch   794 | loss: 2.4868488MixupTrain:  epoch  0, batch   795 | loss: 2.1448712MixupTrain:  epoch  0, batch   796 | loss: 2.1766205MixupTrain:  epoch  0, batch   797 | loss: 2.3898120MixupTrain:  epoch  0, batch   798 | loss: 2.4336436MixupTrain:  epoch  0, batch   799 | loss: 2.2807131MixupTrain:  epoch  0, batch   800 | loss: 2.3327534MixupTrain:  epoch  0, batch   801 | loss: 2.2529554MixupTrain:  epoch  0, batch   802 | loss: 2.2026007MixupTrain:  epoch  0, batch   803 | loss: 2.1052964MixupTrain:  epoch  0, batch   804 | loss: 1.9419794MixupTrain:  epoch  0, batch   805 | loss: 2.0721233MixupTrain:  epoch  0, batch   806 | loss: 2.3989110MixupTrain:  epoch  0, batch   807 | loss: 2.0598397MixupTrain:  epoch  0, batch   808 | loss: 2.0401459MixupTrain:  epoch  0, batch   809 | loss: 1.8736377MixupTrain:  epoch  0, batch   810 | loss: 2.3483915MixupTrain:  epoch  0, batch   811 | loss: 2.2941985MixupTrain:  epoch  0, batch   812 | loss: 2.4000087MixupTrain:  epoch  0, batch   813 | loss: 2.1585402MixupTrain:  epoch  0, batch   814 | loss: 2.1246080MixupTrain:  epoch  0, batch   815 | loss: 2.3084188MixupTrain:  epoch  0, batch   816 | loss: 2.3133755MixupTrain:  epoch  0, batch   817 | loss: 2.2937679MixupTrain:  epoch  0, batch   818 | loss: 2.2076054MixupTrain:  epoch  0, batch   819 | loss: 2.4007719MixupTrain:  epoch  0, batch   820 | loss: 2.1720948MixupTrain:  epoch  0, batch   821 | loss: 2.4480281MixupTrain:  epoch  0, batch   822 | loss: 2.1238480MixupTrain:  epoch  0, batch   823 | loss: 2.2555456MixupTrain:  epoch  0, batch   824 | loss: 2.2171702MixupTrain:  epoch  0, batch   825 | loss: 2.0915279MixupTrain:  epoch  0, batch   826 | loss: 2.1502180MixupTrain:  epoch  0, batch   827 | loss: 2.1841178MixupTrain:  epoch  0, batch   828 | loss: 2.3065190MixupTrain:  epoch  0, batch   829 | loss: 2.2278285MixupTrain:  epoch  0, batch   830 | loss: 2.3388195MixupTrain:  epoch  0, batch   831 | loss: 2.1638556MixupTrain:  epoch  0, batch   832 | loss: 2.4546204MixupTrain:  epoch  0, batch   833 | loss: 2.1482339MixupTrain:  epoch  0, batch   834 | loss: 1.9855158MixupTrain:  epoch  0, batch   835 | loss: 2.3817954MixupTrain:  epoch  0, batch   836 | loss: 2.2609701MixupTrain:  epoch  0, batch   837 | loss: 2.2785332MixupTrain:  epoch  0, batch   838 | loss: 2.5261579MixupTrain:  epoch  0, batch   839 | loss: 2.0611682MixupTrain:  epoch  0, batch   840 | loss: 2.2742982MixupTrain:  epoch  0, batch   841 | loss: 2.4949098MixupTrain:  epoch  0, batch   842 | loss: 2.1289248MixupTrain:  epoch  0, batch   843 | loss: 2.1136277MixupTrain:  epoch  0, batch   844 | loss: 1.9233677MixupTrain:  epoch  0, batch   845 | loss: 2.0188956MixupTrain:  epoch  0, batch   846 | loss: 2.4194698MixupTrain:  epoch  0, batch   847 | loss: 2.4360504MixupTrain:  epoch  0, batch   848 | loss: 2.2307849MixupTrain:  epoch  0, batch   849 | loss: 2.1452239MixupTrain:  epoch  0, batch   850 | loss: 2.1181610MixupTrain:  epoch  0, batch   851 | loss: 2.2036126MixupTrain:  epoch  0, batch   852 | loss: 2.3805122MixupTrain:  epoch  0, batch   853 | loss: 2.4684830MixupTrain:  epoch  0, batch   854 | loss: 2.3660769MixupTrain:  epoch  0, batch   855 | loss: 2.1909599MixupTrain:  epoch  0, batch   856 | loss: 2.1709442MixupTrain:  epoch  0, batch   857 | loss: 2.1221251MixupTrain:  epoch  0, batch   858 | loss: 2.4785342MixupTrain:  epoch  0, batch   859 | loss: 2.1900628MixupTrain:  epoch  0, batch   860 | loss: 2.1145313MixupTrain:  epoch  0, batch   861 | loss: 2.3192310MixupTrain:  epoch  0, batch   862 | loss: 2.0508859MixupTrain:  epoch  0, batch   863 | loss: 2.3920877MixupTrain:  epoch  0, batch   864 | loss: 2.1677365MixupTrain:  epoch  0, batch   865 | loss: 2.2333927MixupTrain:  epoch  0, batch   866 | loss: 2.3221798MixupTrain:  epoch  0, batch   867 | loss: 2.2193840MixupTrain:  epoch  0, batch   868 | loss: 2.0455897MixupTrain:  epoch  0, batch   869 | loss: 1.9945633MixupTrain:  epoch  0, batch   870 | loss: 2.1930976MixupTrain:  epoch  0, batch   871 | loss: 2.3734133MixupTrain:  epoch  0, batch   872 | loss: 2.4184761MixupTrain:  epoch  0, batch   873 | loss: 2.3223352MixupTrain:  epoch  0, batch   874 | loss: 2.2579670MixupTrain:  epoch  0, batch   875 | loss: 2.3587182MixupTrain:  epoch  0, batch   876 | loss: 2.2802944MixupTrain:  epoch  0, batch   877 | loss: 2.3473361MixupTrain:  epoch  0, batch   878 | loss: 2.2301848MixupTrain:  epoch  0, batch   879 | loss: 2.4792321MixupTrain:  epoch  0, batch   880 | loss: 2.4302483MixupTrain:  epoch  0, batch   881 | loss: 2.1658418MixupTrain:  epoch  0, batch   882 | loss: 2.0180078MixupTrain:  epoch  0, batch   883 | loss: 2.2426438MixupTrain:  epoch  0, batch   884 | loss: 2.1588829MixupTrain:  epoch  0, batch   885 | loss: 2.2129173MixupTrain:  epoch  0, batch   886 | loss: 2.3753350MixupTrain:  epoch  0, batch   887 | loss: 2.2873933MixupTrain:  epoch  0, batch   888 | loss: 2.1530552MixupTrain:  epoch  0, batch   889 | loss: 2.1010709MixupTrain:  epoch  0, batch   890 | loss: 2.3030324MixupTrain:  epoch  0, batch   891 | loss: 2.3811369MixupTrain:  epoch  0, batch   892 | loss: 2.1440754MixupTrain:  epoch  0, batch   893 | loss: 2.1098809MixupTrain:  epoch  0, batch   894 | loss: 2.0835862MixupTrain:  epoch  0, batch   895 | loss: 2.1545050MixupTrain:  epoch  0, batch   896 | loss: 2.0870099MixupTrain:  epoch  0, batch   897 | loss: 2.3322771MixupTrain:  epoch  0, batch   898 | loss: 2.1852045MixupTrain:  epoch  0, batch   899 | loss: 1.9967299MixupTrain:  epoch  0, batch   900 | loss: 2.3728232MixupTrain:  epoch  0, batch   901 | loss: 2.3450437MixupTrain:  epoch  0, batch   902 | loss: 2.2578664MixupTrain:  epoch  0, batch   903 | loss: 2.1259475MixupTrain:  epoch  0, batch   904 | loss: 2.1724610MixupTrain:  epoch  0, batch   905 | loss: 2.1704938MixupTrain:  epoch  0, batch   906 | loss: 2.2571197MixupTrain:  epoch  0, batch   907 | loss: 2.1924887MixupTrain:  epoch  0, batch   908 | loss: 2.6389031MixupTrain:  epoch  0, batch   909 | loss: 2.2358098MixupTrain:  epoch  0, batch   910 | loss: 2.1148679MixupTrain:  epoch  0, batch   911 | loss: 2.1935320MixupTrain:  epoch  0, batch   912 | loss: 2.3257790MixupTrain:  epoch  0, batch   913 | loss: 2.1845994MixupTrain:  epoch  0, batch   914 | loss: 2.3603904MixupTrain:  epoch  0, batch   915 | loss: 2.2852111MixupTrain:  epoch  0, batch   916 | loss: 2.2229981MixupTrain:  epoch  0, batch   917 | loss: 2.2534673MixupTrain:  epoch  0, batch   918 | loss: 2.2169695MixupTrain:  epoch  0, batch   919 | loss: 2.3737946MixupTrain:  epoch  0, batch   920 | loss: 2.4669354MixupTrain:  epoch  0, batch   921 | loss: 2.1061699MixupTrain:  epoch  0, batch   922 | loss: 2.3103480MixupTrain:  epoch  0, batch   923 | loss: 2.3964655MixupTrain:  epoch  0, batch   924 | loss: 2.2818217MixupTrain:  epoch  0, batch   925 | loss: 2.1645255MixupTrain:  epoch  0, batch   926 | loss: 1.9367721MixupTrain:  epoch  0, batch   927 | loss: 2.2281637MixupTrain:  epoch  0, batch   928 | loss: 2.4009917MixupTrain:  epoch  0, batch   929 | loss: 2.3018060MixupTrain:  epoch  0, batch   930 | loss: 2.2511716MixupTrain:  epoch  0, batch   931 | loss: 2.1865559MixupTrain:  epoch  0, batch   932 | loss: 2.1785007MixupTrain:  epoch  0, batch   933 | loss: 2.0956960MixupTrain:  epoch  0, batch   934 | loss: 2.4047046MixupTrain:  epoch  0, batch   935 | loss: 2.0859332MixupTrain:  epoch  0, batch   936 | loss: 2.2026508MixupTrain:  epoch  0, batch   937 | loss: 2.1625178MixupTrain:  epoch  0, batch   938 | loss: 2.4317594MixupTrain:  epoch  0, batch   939 | loss: 2.1496272MixupTrain:  epoch  0, batch   940 | loss: 2.3025279MixupTrain:  epoch  0, batch   941 | loss: 2.3804965MixupTrain:  epoch  0, batch   942 | loss: 2.4050641MixupTrain:  epoch  0, batch   943 | loss: 2.2591639MixupTrain:  epoch  0, batch   944 | loss: 2.2411733MixupTrain:  epoch  0, batch   945 | loss: 2.3011737MixupTrain:  epoch  0, batch   946 | loss: 2.4050388MixupTrain:  epoch  0, batch   947 | loss: 2.2709398MixupTrain:  epoch  0, batch   948 | loss: 2.1832011MixupTrain:  epoch  0, batch   949 | loss: 2.4360487MixupTrain:  epoch  0, batch   950 | loss: 2.3021603MixupTrain:  epoch  0, batch   951 | loss: 2.3341641MixupTrain:  epoch  0, batch   952 | loss: 2.5150957MixupTrain:  epoch  0, batch   953 | loss: 2.1710618MixupTrain:  epoch  0, batch   954 | loss: 2.1793506MixupTrain:  epoch  0, batch   955 | loss: 2.1313136MixupTrain:  epoch  0, batch   956 | loss: 2.1681285MixupTrain:  epoch  0, batch   957 | loss: 2.1016181MixupTrain:  epoch  0, batch   958 | loss: 2.1568112MixupTrain:  epoch  0, batch   959 | loss: 2.1520724MixupTrain:  epoch  0, batch   960 | loss: 2.4723721MixupTrain:  epoch  0, batch   961 | loss: 2.1410005MixupTrain:  epoch  0, batch   962 | loss: 2.1951168MixupTrain:  epoch  0, batch   963 | loss: 2.3999579MixupTrain:  epoch  0, batch   964 | loss: 2.3148258MixupTrain:  epoch  0, batch   965 | loss: 2.1998208MixupTrain:  epoch  0, batch   966 | loss: 2.4707246MixupTrain:  epoch  0, batch   967 | loss: 2.2110553MixupTrain:  epoch  0, batch   968 | loss: 2.3110409MixupTrain:  epoch  0, batch   969 | loss: 2.1939678MixupTrain:  epoch  0, batch   970 | loss: 1.9432447MixupTrain:  epoch  0, batch   971 | loss: 1.8381451MixupTrain:  epoch  0, batch   972 | loss: 2.2803278MixupTrain:  epoch  0, batch   973 | loss: 2.2083237MixupTrain:  epoch  0, batch   974 | loss: 2.0410290MixupTrain:  epoch  0, batch   975 | loss: 2.3762398MixupTrain:  epoch  0, batch   976 | loss: 2.3248224MixupTrain:  epoch  0, batch   977 | loss: 2.2434459MixupTrain:  epoch  0, batch   978 | loss: 2.2560487MixupTrain:  epoch  0, batch   979 | loss: 2.3824675MixupTrain:  epoch  0, batch   980 | loss: 2.1493673MixupTrain:  epoch  0, batch   981 | loss: 2.3726811MixupTrain:  epoch  0, batch   982 | loss: 2.1881080MixupTrain:  epoch  0, batch   983 | loss: 2.1439087MixupTrain:  epoch  0, batch   984 | loss: 2.2815318MixupTrain:  epoch  0, batch   985 | loss: 2.2513676MixupTrain:  epoch  0, batch   986 | loss: 2.4342093MixupTrain:  epoch  0, batch   987 | loss: 1.9394701MixupTrain:  epoch  0, batch   988 | loss: 2.1482942MixupTrain:  epoch  0, batch   989 | loss: 2.2824366MixupTrain:  epoch  0, batch   990 | loss: 2.4232388MixupTrain:  epoch  0, batch   991 | loss: 2.2503660MixupTrain:  epoch  0, batch   992 | loss: 2.0117981MixupTrain:  epoch  0, batch   993 | loss: 2.1941304MixupTrain:  epoch  0, batch   994 | loss: 2.4250970MixupTrain:  epoch  0, batch   995 | loss: 2.1008525MixupTrain:  epoch  0, batch   996 | loss: 2.1500967MixupTrain:  epoch  0, batch   997 | loss: 2.0917683MixupTrain:  epoch  0, batch   998 | loss: 2.2207587MixupTrain:  epoch  0, batch   999 | loss: 2.1752653MixupTrain:  epoch  0, batch  1000 | loss: 2.2016609MixupTrain:  epoch  0, batch  1001 | loss: 2.0587707MixupTrain:  epoch  0, batch  1002 | loss: 2.1598175MixupTrain:  epoch  0, batch  1003 | loss: 2.2961843MixupTrain:  epoch  0, batch  1004 | loss: 2.2607594MixupTrain:  epoch  0, batch  1005 | loss: 2.0723107MixupTrain:  epoch  0, batch  1006 | loss: 2.1996953MixupTrain:  epoch  0, batch  1007 | loss: 2.3138428MixupTrain:  epoch  0, batch  1008 | loss: 2.3424392MixupTrain:  epoch  0, batch  1009 | loss: 2.1978958MixupTrain:  epoch  0, batch  1010 | loss: 2.0574882MixupTrain:  epoch  0, batch  1011 | loss: 2.1777782MixupTrain:  epoch  0, batch  1012 | loss: 2.0355051MixupTrain:  epoch  0, batch  1013 | loss: 2.1791363MixupTrain:  epoch  0, batch  1014 | loss: 2.3036525MixupTrain:  epoch  0, batch  1015 | loss: 2.2509189MixupTrain:  epoch  0, batch  1016 | loss: 2.2126122MixupTrain:  epoch  0, batch  1017 | loss: 2.2704403MixupTrain:  epoch  0, batch  1018 | loss: 2.2323980MixupTrain:  epoch  0, batch  1019 | loss: 2.3061676MixupTrain:  epoch  0, batch  1020 | loss: 2.2599387MixupTrain:  epoch  0, batch  1021 | loss: 2.3267901MixupTrain:  epoch  0, batch  1022 | loss: 2.2559807MixupTrain:  epoch  0, batch  1023 | loss: 2.1382265MixupTrain:  epoch  0, batch  1024 | loss: 2.2726433MixupTrain:  epoch  0, batch  1025 | loss: 2.2500906MixupTrain:  epoch  0, batch  1026 | loss: 2.1866903MixupTrain:  epoch  0, batch  1027 | loss: 2.1035063MixupTrain:  epoch  0, batch  1028 | loss: 2.1338408MixupTrain:  epoch  0, batch  1029 | loss: 2.0089552MixupTrain:  epoch  0, batch  1030 | loss: 2.3954954MixupTrain:  epoch  0, batch  1031 | loss: 1.9755913MixupTrain:  epoch  0, batch  1032 | loss: 2.2528625MixupTrain:  epoch  0, batch  1033 | loss: 2.3174500MixupTrain:  epoch  0, batch  1034 | loss: 2.2540870MixupTrain:  epoch  0, batch  1035 | loss: 2.1294200MixupTrain:  epoch  0, batch  1036 | loss: 2.1632018MixupTrain:  epoch  0, batch  1037 | loss: 2.1991873MixupTrain:  epoch  0, batch  1038 | loss: 2.1587439MixupTrain:  epoch  0, batch  1039 | loss: 2.0664337MixupTrain:  epoch  0, batch  1040 | loss: 2.2185130MixupTrain:  epoch  0, batch  1041 | loss: 2.0967700MixupTrain:  epoch  0, batch  1042 | loss: 2.2351179MixupTrain:  epoch  0, batch  1043 | loss: 2.4039435MixupTrain:  epoch  0, batch  1044 | loss: 2.1924510MixupTrain:  epoch  0, batch  1045 | loss: 2.0200634MixupTrain:  epoch  0, batch  1046 | loss: 2.0333004MixupTrain:  epoch  0, batch  1047 | loss: 2.1639223MixupTrain:  epoch  0, batch  1048 | loss: 2.1341021MixupTrain:  epoch  0, batch  1049 | loss: 1.9624926MixupTrain:  epoch  0, batch  1050 | loss: 2.2515974MixupTrain:  epoch  0, batch  1051 | loss: 2.3148618MixupTrain:  epoch  0, batch  1052 | loss: 2.3377926MixupTrain:  epoch  0, batch  1053 | loss: 2.0066285MixupTrain:  epoch  0, batch  1054 | loss: 2.1589890MixupTrain:  epoch  0, batch  1055 | loss: 2.3990262MixupTrain:  epoch  0, batch  1056 | loss: 2.3029819MixupTrain:  epoch  0, batch  1057 | loss: 2.3346982MixupTrain:  epoch  0, batch  1058 | loss: 2.4370134MixupTrain:  epoch  0, batch  1059 | loss: 2.1388454MixupTrain:  epoch  0, batch  1060 | loss: 2.5703824MixupTrain:  epoch  0, batch  1061 | loss: 1.9652935MixupTrain:  epoch  0, batch  1062 | loss: 2.3565946MixupTrain:  epoch  0, batch  1063 | loss: 1.9089482MixupTrain:  epoch  0, batch  1064 | loss: 2.0782428MixupTrain:  epoch  0, batch  1065 | loss: 2.3298950MixupTrain:  epoch  0, batch  1066 | loss: 1.9958267MixupTrain:  epoch  0, batch  1067 | loss: 2.2716231MixupTrain:  epoch  0, batch  1068 | loss: 2.2992597MixupTrain:  epoch  0, batch  1069 | loss: 2.3896027MixupTrain:  epoch  0, batch  1070 | loss: 2.2481325MixupTrain:  epoch  0, batch  1071 | loss: 2.3391099MixupTrain:  epoch  0, batch  1072 | loss: 2.0342276MixupTrain:  epoch  0, batch  1073 | loss: 2.4905915MixupTrain:  epoch  0, batch  1074 | loss: 2.1448543MixupTrain:  epoch  0, batch  1075 | loss: 2.1559784MixupTrain:  epoch  0, batch  1076 | loss: 2.1058588MixupTrain:  epoch  0, batch  1077 | loss: 2.1962574MixupTrain:  epoch  0, batch  1078 | loss: 2.0545652MixupTrain:  epoch  0, batch  1079 | loss: 2.1219082MixupTrain:  epoch  0, batch  1080 | loss: 2.1892214MixupTrain:  epoch  0, batch  1081 | loss: 2.1581562MixupTrain:  epoch  0, batch  1082 | loss: 1.9514537MixupTrain:  epoch  0, batch  1083 | loss: 2.3153765MixupTrain:  epoch  0, batch  1084 | loss: 2.2234173MixupTrain:  epoch  0, batch  1085 | loss: 2.2010915MixupTrain:  epoch  0, batch  1086 | loss: 2.2796202MixupTrain:  epoch  0, batch  1087 | loss: 2.0216885MixupTrain:  epoch  0, batch  1088 | loss: 2.0305037MixupTrain:  epoch  0, batch  1089 | loss: 2.3401823MixupTrain:  epoch  0, batch  1090 | loss: 2.2069972MixupTrain:  epoch  0, batch  1091 | loss: 2.5093513MixupTrain:  epoch  0, batch  1092 | loss: 2.4419861MixupTrain:  epoch  0, batch  1093 | loss: 2.1612551MixupTrain:  epoch  0, batch  1094 | loss: 2.4967208MixupTrain:  epoch  0, batch  1095 | loss: 2.2220135MixupTrain:  epoch  0, batch  1096 | loss: 2.2198801MixupTrain:  epoch  0, batch  1097 | loss: 2.2070966MixupTrain:  epoch  0, batch  1098 | loss: 2.0501771MixupTrain:  epoch  0, batch  1099 | loss: 2.1046841MixupTrain:  epoch  0, batch  1100 | loss: 2.3428259MixupTrain:  epoch  0, batch  1101 | loss: 2.1902695MixupTrain:  epoch  0, batch  1102 | loss: 2.2192907MixupTrain:  epoch  0, batch  1103 | loss: 2.0888841MixupTrain:  epoch  0, batch  1104 | loss: 2.0737851MixupTrain:  epoch  0, batch  1105 | loss: 2.3116350MixupTrain:  epoch  0, batch  1106 | loss: 2.3518074MixupTrain:  epoch  0, batch  1107 | loss: 2.2363062MixupTrain:  epoch  0, batch  1108 | loss: 1.9976944MixupTrain:  epoch  0, batch  1109 | loss: 2.2145748MixupTrain:  epoch  0, batch  1110 | loss: 2.3494735MixupTrain:  epoch  0, batch  1111 | loss: 2.4230194MixupTrain:  epoch  0, batch  1112 | loss: 1.9166788MixupTrain:  epoch  0, batch  1113 | loss: 2.1162057MixupTrain:  epoch  0, batch  1114 | loss: 2.1871023MixupTrain:  epoch  0, batch  1115 | loss: 1.9971366MixupTrain:  epoch  0, batch  1116 | loss: 2.0345092MixupTrain:  epoch  0, batch  1117 | loss: 2.0766292MixupTrain:  epoch  0, batch  1118 | loss: 2.6443450MixupTrain:  epoch  0, batch  1119 | loss: 2.2304623MixupTrain:  epoch  0, batch  1120 | loss: 2.5096140MixupTrain:  epoch  0, batch  1121 | loss: 2.3445210MixupTrain:  epoch  0, batch  1122 | loss: 2.1768379MixupTrain:  epoch  0, batch  1123 | loss: 1.9959791MixupTrain:  epoch  0, batch  1124 | loss: 2.1986787MixupTrain:  epoch  0, batch  1125 | loss: 1.9934431MixupTrain:  epoch  0, batch  1126 | loss: 2.2794304MixupTrain:  epoch  0, batch  1127 | loss: 2.4632132MixupTrain:  epoch  0, batch  1128 | loss: 2.1167598MixupTrain:  epoch  0, batch  1129 | loss: 2.2119434MixupTrain:  epoch  0, batch  1130 | loss: 2.1377022MixupTrain:  epoch  0, batch  1131 | loss: 2.3865461MixupTrain:  epoch  0, batch  1132 | loss: 1.9263071MixupTrain:  epoch  0, batch  1133 | loss: 2.1089449MixupTrain:  epoch  0, batch  1134 | loss: 2.2297506MixupTrain:  epoch  0, batch  1135 | loss: 2.0642762MixupTrain:  epoch  0, batch  1136 | loss: 2.3601420MixupTrain:  epoch  0, batch  1137 | loss: 2.1394167MixupTrain:  epoch  0, batch  1138 | loss: 2.1993439MixupTrain:  epoch  0, batch  1139 | loss: 2.3228121MixupTrain:  epoch  0, batch  1140 | loss: 2.1316600MixupTrain:  epoch  0, batch  1141 | loss: 2.1792095MixupTrain:  epoch  0, batch  1142 | loss: 2.1614292MixupTrain:  epoch  0, batch  1143 | loss: 2.1466856MixupTrain:  epoch  0, batch  1144 | loss: 2.4105048MixupTrain:  epoch  0, batch  1145 | loss: 2.1164966MixupTrain:  epoch  0, batch  1146 | loss: 2.1027331MixupTrain:  epoch  0, batch  1147 | loss: 2.3287678MixupTrain:  epoch  0, batch  1148 | loss: 2.4096432MixupTrain:  epoch  0, batch  1149 | loss: 2.1988087MixupTrain:  epoch  0, batch  1150 | loss: 2.0418656MixupTrain:  epoch  0, batch  1151 | loss: 2.1461153MixupTrain:  epoch  0, batch  1152 | loss: 2.0099254MixupTrain:  epoch  0, batch  1153 | loss: 2.1292610MixupTrain:  epoch  0, batch  1154 | loss: 2.1372671MixupTrain:  epoch  0, batch  1155 | loss: 2.4000809MixupTrain:  epoch  0, batch  1156 | loss: 2.1802764MixupTrain:  epoch  0, batch  1157 | loss: 2.2122531MixupTrain:  epoch  0, batch  1158 | loss: 2.1485729MixupTrain:  epoch  0, batch  1159 | loss: 2.4039316MixupTrain:  epoch  0, batch  1160 | loss: 2.0726454MixupTrain:  epoch  0, batch  1161 | loss: 2.2571604MixupTrain:  epoch  0, batch  1162 | loss: 2.3159747MixupTrain:  epoch  0, batch  1163 | loss: 2.3698955MixupTrain:  epoch  0, batch  1164 | loss: 2.0330567MixupTrain:  epoch  0, batch  1165 | loss: 2.1619539MixupTrain:  epoch  0, batch  1166 | loss: 2.1636720MixupTrain:  epoch  0, batch  1167 | loss: 2.1355383MixupTrain:  epoch  0, batch  1168 | loss: 2.3103836MixupTrain:  epoch  0, batch  1169 | loss: 2.1175022MixupTrain:  epoch  0, batch  1170 | loss: 1.9785171MixupTrain:  epoch  0, batch  1171 | loss: 2.1141090MixupTrain:  epoch  0, batch  1172 | loss: 2.3262982MixupTrain:  epoch  0, batch  1173 | loss: 2.1410246MixupTrain:  epoch  0, batch  1174 | loss: 2.0680776MixupTrain:  epoch  0, batch  1175 | loss: 2.4018607MixupTrain:  epoch  0, batch  1176 | loss: 2.3214562MixupTrain:  epoch  0, batch  1177 | loss: 2.1245456MixupTrain:  epoch  0, batch  1178 | loss: 2.1204405MixupTrain:  epoch  0, batch  1179 | loss: 2.3468239MixupTrain:  epoch  0, batch  1180 | loss: 2.2463450MixupTrain:  epoch  0, batch  1181 | loss: 2.1539040MixupTrain:  epoch  0, batch  1182 | loss: 2.4067740MixupTrain:  epoch  0, batch  1183 | loss: 2.2210550MixupTrain:  epoch  0, batch  1184 | loss: 2.1834068MixupTrain:  epoch  0, batch  1185 | loss: 2.2399426MixupTrain:  epoch  0, batch  1186 | loss: 2.4456558MixupTrain:  epoch  0, batch  1187 | loss: 2.0562966MixupTrain:  epoch  0, batch  1188 | loss: 2.2395422MixupTrain:  epoch  0, batch  1189 | loss: 2.5117364MixupTrain:  epoch  0, batch  1190 | loss: 2.1875148MixupTrain:  epoch  0, batch  1191 | loss: 2.0562053MixupTrain:  epoch  0, batch  1192 | loss: 2.0502210MixupTrain:  epoch  0, batch  1193 | loss: 2.3028023MixupTrain:  epoch  0, batch  1194 | loss: 2.2400899MixupTrain:  epoch  0, batch  1195 | loss: 2.1571729MixupTrain:  epoch  0, batch  1196 | loss: 2.3379610MixupTrain:  epoch  0, batch  1197 | loss: 2.2256787MixupTrain:  epoch  0, batch  1198 | loss: 2.0736752MixupTrain:  epoch  0, batch  1199 | loss: 2.4363208MixupTrain:  epoch  0, batch  1200 | loss: 2.1784060MixupTrain:  epoch  0, batch  1201 | loss: 2.2899110MixupTrain:  epoch  0, batch  1202 | loss: 2.4009254MixupTrain:  epoch  0, batch  1203 | loss: 1.9319489MixupTrain:  epoch  0, batch  1204 | loss: 2.0257621MixupTrain:  epoch  0, batch  1205 | loss: 2.1476974MixupTrain:  epoch  0, batch  1206 | loss: 2.1676722MixupTrain:  epoch  0, batch  1207 | loss: 2.1527400MixupTrain:  epoch  0, batch  1208 | loss: 2.1418602MixupTrain:  epoch  0, batch  1209 | loss: 2.3016722MixupTrain:  epoch  0, batch  1210 | loss: 2.0743885MixupTrain:  epoch  0, batch  1211 | loss: 2.4323759MixupTrain:  epoch  0, batch  1212 | loss: 2.2029314MixupTrain:  epoch  0, batch  1213 | loss: 2.2749817MixupTrain:  epoch  0, batch  1214 | loss: 2.0904012MixupTrain:  epoch  0, batch  1215 | loss: 2.5598769MixupTrain:  epoch  0, batch  1216 | loss: 2.1240635MixupTrain:  epoch  0, batch  1217 | loss: 2.2345295MixupTrain:  epoch  0, batch  1218 | loss: 2.0403938MixupTrain:  epoch  0, batch  1219 | loss: 2.3686481MixupTrain:  epoch  0, batch  1220 | loss: 2.2028599MixupTrain:  epoch  0, batch  1221 | loss: 2.0875077MixupTrain:  epoch  0, batch  1222 | loss: 1.9741100MixupTrain:  epoch  0, batch  1223 | loss: 2.1063738MixupTrain:  epoch  0, batch  1224 | loss: 2.4663472MixupTrain:  epoch  0, batch  1225 | loss: 1.9313681MixupTrain:  epoch  0, batch  1226 | loss: 2.1238928MixupTrain:  epoch  0, batch  1227 | loss: 2.3832059MixupTrain:  epoch  0, batch  1228 | loss: 2.1887288MixupTrain:  epoch  0, batch  1229 | loss: 2.1381121MixupTrain:  epoch  0, batch  1230 | loss: 2.3155293MixupTrain:  epoch  0, batch  1231 | loss: 2.1232748MixupTrain:  epoch  0, batch  1232 | loss: 2.3157835MixupTrain:  epoch  0, batch  1233 | loss: 2.2916040MixupTrain:  epoch  0, batch  1234 | loss: 2.4122264MixupTrain:  epoch  0, batch  1235 | loss: 2.0764470MixupTrain:  epoch  0, batch  1236 | loss: 2.4352624MixupTrain:  epoch  0, batch  1237 | loss: 2.2126281MixupTrain:  epoch  0, batch  1238 | loss: 2.0179472MixupTrain:  epoch  0, batch  1239 | loss: 2.3173521MixupTrain:  epoch  0, batch  1240 | loss: 2.1715674MixupTrain:  epoch  0, batch  1241 | loss: 2.4819031MixupTrain:  epoch  0, batch  1242 | loss: 2.2060885MixupTrain:  epoch  0, batch  1243 | loss: 2.0516212MixupTrain:  epoch  0, batch  1244 | loss: 2.1023908MixupTrain:  epoch  0, batch  1245 | loss: 2.0681293MixupTrain:  epoch  0, batch  1246 | loss: 2.1078529MixupTrain:  epoch  0, batch  1247 | loss: 2.2589226MixupTrain:  epoch  0, batch  1248 | loss: 1.9733686MixupTrain:  epoch  0, batch  1249 | loss: 2.2266409MixupTrain:  epoch  0, batch  1250 | loss: 2.2145827MixupTrain:  epoch  0, batch  1251 | loss: 1.9480342MixupTrain:  epoch  0, batch  1252 | loss: 2.1066029MixupTrain:  epoch  0, batch  1253 | loss: 2.1873460MixupTrain:  epoch  0, batch  1254 | loss: 2.1711893MixupTrain:  epoch  0, batch  1255 | loss: 2.5535414MixupTrain:  epoch  0, batch  1256 | loss: 2.2042360MixupTrain:  epoch  0, batch  1257 | loss: 2.0771089MixupTrain:  epoch  0, batch  1258 | loss: 2.0660765MixupTrain:  epoch  0, batch  1259 | loss: 2.1337621MixupTrain:  epoch  0, batch  1260 | loss: 2.1055691MixupTrain:  epoch  0, batch  1261 | loss: 2.3111165MixupTrain:  epoch  0, batch  1262 | loss: 2.0022151MixupTrain:  epoch  0, batch  1263 | loss: 2.2007270MixupTrain:  epoch  0, batch  1264 | loss: 2.3122244MixupTrain:  epoch  0, batch  1265 | loss: 2.2061043MixupTrain:  epoch  0, batch  1266 | loss: 2.1818874MixupTrain:  epoch  0, batch  1267 | loss: 2.2142572MixupTrain:  epoch  0, batch  1268 | loss: 2.2468846MixupTrain:  epoch  0, batch  1269 | loss: 2.3289890MixupTrain:  epoch  0, batch  1270 | loss: 1.9371933MixupTrain:  epoch  0, batch  1271 | loss: 2.0554204MixupTrain:  epoch  0, batch  1272 | loss: 2.2772403MixupTrain:  epoch  0, batch  1273 | loss: 2.2568355MixupTrain:  epoch  0, batch  1274 | loss: 2.0826266MixupTrain:  epoch  0, batch  1275 | loss: 2.0404725MixupTrain:  epoch  0, batch  1276 | loss: 2.3449349MixupTrain:  epoch  0, batch  1277 | loss: 2.2808361MixupTrain:  epoch  0, batch  1278 | loss: 2.1368580MixupTrain:  epoch  0, batch  1279 | loss: 2.2677848MixupTrain:  epoch  0, batch  1280 | loss: 2.2055221MixupTrain:  epoch  0, batch  1281 | loss: 2.2761250MixupTrain:  epoch  0, batch  1282 | loss: 2.1956804MixupTrain:  epoch  0, batch  1283 | loss: 2.1969817MixupTrain:  epoch  0, batch  1284 | loss: 2.2060137MixupTrain:  epoch  0, batch  1285 | loss: 2.5217690MixupTrain:  epoch  0, batch  1286 | loss: 2.2084198MixupTrain:  epoch  0, batch  1287 | loss: 2.2126603MixupTrain:  epoch  0, batch  1288 | loss: 2.3213146MixupTrain:  epoch  0, batch  1289 | loss: 2.4398255MixupTrain:  epoch  0, batch  1290 | loss: 2.2519431MixupTrain:  epoch  0, batch  1291 | loss: 2.2989473MixupTrain:  epoch  0, batch  1292 | loss: 2.1937125MixupTrain:  epoch  0, batch  1293 | loss: 2.1374152MixupTrain:  epoch  0, batch  1294 | loss: 2.3190815MixupTrain:  epoch  0, batch  1295 | loss: 2.1975670MixupTrain:  epoch  0, batch  1296 | loss: 2.3521969MixupTrain:  epoch  0, batch  1297 | loss: 2.2546923MixupTrain:  epoch  0, batch  1298 | loss: 2.3042819MixupTrain:  epoch  0, batch  1299 | loss: 2.2857618MixupTrain:  epoch  0, batch  1300 | loss: 2.1470990MixupTrain:  epoch  0, batch  1301 | loss: 2.2172749MixupTrain:  epoch  0, batch  1302 | loss: 1.9723768MixupTrain:  epoch  0, batch  1303 | loss: 2.3293166MixupTrain:  epoch  0, batch  1304 | loss: 1.9420997MixupTrain:  epoch  0, batch  1305 | loss: 2.2228239MixupTrain:  epoch  0, batch  1306 | loss: 2.2957249MixupTrain:  epoch  0, batch  1307 | loss: 2.2454071MixupTrain:  epoch  0, batch  1308 | loss: 2.2434201MixupTrain:  epoch  0, batch  1309 | loss: 2.0586629MixupTrain:  epoch  0, batch  1310 | loss: 1.9501648MixupTrain:  epoch  0, batch  1311 | loss: 2.1271439MixupTrain:  epoch  0, batch  1312 | loss: 2.2761087MixupTrain:  epoch  0, batch  1313 | loss: 2.2786326MixupTrain:  epoch  0, batch  1314 | loss: 2.3795776MixupTrain:  epoch  0, batch  1315 | loss: 2.5591812MixupTrain:  epoch  0, batch  1316 | loss: 2.0633235MixupTrain:  epoch  0, batch  1317 | loss: 2.2790656MixupTrain:  epoch  0, batch  1318 | loss: 2.4952435MixupTrain:  epoch  0, batch  1319 | loss: 2.1744256MixupTrain:  epoch  0, batch  1320 | loss: 2.2281480MixupTrain:  epoch  0, batch  1321 | loss: 2.2706997MixupTrain:  epoch  0, batch  1322 | loss: 2.0969164MixupTrain:  epoch  0, batch  1323 | loss: 2.3474455MixupTrain:  epoch  0, batch  1324 | loss: 2.2132068MixupTrain:  epoch  0, batch  1325 | loss: 2.2226260MixupTrain:  epoch  0, batch  1326 | loss: 2.2713313MixupTrain:  epoch  0, batch  1327 | loss: 2.2162509MixupTrain:  epoch  0, batch  1328 | loss: 2.2018547MixupTrain:  epoch  0, batch  1329 | loss: 2.3381586MixupTrain:  epoch  0, batch  1330 | loss: 2.2480190MixupTrain:  epoch  0, batch  1331 | loss: 2.3271239MixupTrain:  epoch  0, batch  1332 | loss: 2.4538057MixupTrain:  epoch  0, batch  1333 | loss: 1.9576372MixupTrain:  epoch  0, batch  1334 | loss: 2.2181535MixupTrain:  epoch  0, batch  1335 | loss: 2.3056393MixupTrain:  epoch  0, batch  1336 | loss: 2.2910018MixupTrain:  epoch  0, batch  1337 | loss: 2.2362986MixupTrain:  epoch  0, batch  1338 | loss: 2.0688806MixupTrain:  epoch  0, batch  1339 | loss: 2.3788099MixupTrain:  epoch  0, batch  1340 | loss: 2.0549483MixupTrain:  epoch  0, batch  1341 | loss: 2.2564425MixupTrain:  epoch  0, batch  1342 | loss: 2.2258825MixupTrain:  epoch  0, batch  1343 | loss: 1.8006375
MemoryTrain:  epoch  0, batch     0 | loss: 1.9092288MemoryTrain:  epoch  0, batch     1 | loss: 2.0532484MemoryTrain:  epoch  0, batch     2 | loss: 2.4291000MemoryTrain:  epoch  0, batch     3 | loss: 2.4979806MemoryTrain:  epoch  0, batch     4 | loss: 2.5665586MemoryTrain:  epoch  0, batch     5 | loss: 2.4380078MemoryTrain:  epoch  0, batch     6 | loss: 2.4033661MemoryTrain:  epoch  0, batch     7 | loss: 1.9648490MemoryTrain:  epoch  0, batch     8 | loss: 2.6108916MemoryTrain:  epoch  0, batch     9 | loss: 2.5389435MemoryTrain:  epoch  0, batch    10 | loss: 2.4207082MemoryTrain:  epoch  0, batch    11 | loss: 2.0422993MemoryTrain:  epoch  1, batch     0 | loss: 1.8430352MemoryTrain:  epoch  1, batch     1 | loss: 1.8698728MemoryTrain:  epoch  1, batch     2 | loss: 1.8437648MemoryTrain:  epoch  1, batch     3 | loss: 1.8675785MemoryTrain:  epoch  1, batch     4 | loss: 1.8498600MemoryTrain:  epoch  1, batch     5 | loss: 1.9178953MemoryTrain:  epoch  1, batch     6 | loss: 1.8701062MemoryTrain:  epoch  1, batch     7 | loss: 1.9208101MemoryTrain:  epoch  1, batch     8 | loss: 1.8466249MemoryTrain:  epoch  1, batch     9 | loss: 2.0952857MemoryTrain:  epoch  1, batch    10 | loss: 1.8756745MemoryTrain:  epoch  1, batch    11 | loss: 1.8592494MemoryTrain:  epoch  2, batch     0 | loss: 1.8356204MemoryTrain:  epoch  2, batch     1 | loss: 1.8324329MemoryTrain:  epoch  2, batch     2 | loss: 1.8256416MemoryTrain:  epoch  2, batch     3 | loss: 1.8191767MemoryTrain:  epoch  2, batch     4 | loss: 1.8093255MemoryTrain:  epoch  2, batch     5 | loss: 1.8346710MemoryTrain:  epoch  2, batch     6 | loss: 1.8499036MemoryTrain:  epoch  2, batch     7 | loss: 1.8107760MemoryTrain:  epoch  2, batch     8 | loss: 1.8156433MemoryTrain:  epoch  2, batch     9 | loss: 1.8161452MemoryTrain:  epoch  2, batch    10 | loss: 1.8161275MemoryTrain:  epoch  2, batch    11 | loss: 1.8071316MemoryTrain:  epoch  3, batch     0 | loss: 1.8105125MemoryTrain:  epoch  3, batch     1 | loss: 1.8169242MemoryTrain:  epoch  3, batch     2 | loss: 1.8115678MemoryTrain:  epoch  3, batch     3 | loss: 1.8134198MemoryTrain:  epoch  3, batch     4 | loss: 1.8091962MemoryTrain:  epoch  3, batch     5 | loss: 1.8232980MemoryTrain:  epoch  3, batch     6 | loss: 1.8286494MemoryTrain:  epoch  3, batch     7 | loss: 1.8122046MemoryTrain:  epoch  3, batch     8 | loss: 1.8198943MemoryTrain:  epoch  3, batch     9 | loss: 1.8098058MemoryTrain:  epoch  3, batch    10 | loss: 1.8278928MemoryTrain:  epoch  3, batch    11 | loss: 1.8187602MemoryTrain:  epoch  4, batch     0 | loss: 1.8173542MemoryTrain:  epoch  4, batch     1 | loss: 1.8144159MemoryTrain:  epoch  4, batch     2 | loss: 1.8170938MemoryTrain:  epoch  4, batch     3 | loss: 1.8196669MemoryTrain:  epoch  4, batch     4 | loss: 1.8830087MemoryTrain:  epoch  4, batch     5 | loss: 1.8146532MemoryTrain:  epoch  4, batch     6 | loss: 1.8224447MemoryTrain:  epoch  4, batch     7 | loss: 1.8138733MemoryTrain:  epoch  4, batch     8 | loss: 1.8271502MemoryTrain:  epoch  4, batch     9 | loss: 1.8075871MemoryTrain:  epoch  4, batch    10 | loss: 1.8226143MemoryTrain:  epoch  4, batch    11 | loss: 1.8195412MemoryTrain:  epoch  5, batch     0 | loss: 1.8188264MemoryTrain:  epoch  5, batch     1 | loss: 1.8498507MemoryTrain:  epoch  5, batch     2 | loss: 1.8428872MemoryTrain:  epoch  5, batch     3 | loss: 1.8205274MemoryTrain:  epoch  5, batch     4 | loss: 1.8519418MemoryTrain:  epoch  5, batch     5 | loss: 1.8142654MemoryTrain:  epoch  5, batch     6 | loss: 1.8431318MemoryTrain:  epoch  5, batch     7 | loss: 1.8879397MemoryTrain:  epoch  5, batch     8 | loss: 1.8212004MemoryTrain:  epoch  5, batch     9 | loss: 1.8073415MemoryTrain:  epoch  5, batch    10 | loss: 1.8125160MemoryTrain:  epoch  5, batch    11 | loss: 1.8050228MemoryTrain:  epoch  6, batch     0 | loss: 1.8194207MemoryTrain:  epoch  6, batch     1 | loss: 1.8277395MemoryTrain:  epoch  6, batch     2 | loss: 1.8085043MemoryTrain:  epoch  6, batch     3 | loss: 1.8098032MemoryTrain:  epoch  6, batch     4 | loss: 1.8084307MemoryTrain:  epoch  6, batch     5 | loss: 1.8091767MemoryTrain:  epoch  6, batch     6 | loss: 1.8061094MemoryTrain:  epoch  6, batch     7 | loss: 1.8090345MemoryTrain:  epoch  6, batch     8 | loss: 1.8105404MemoryTrain:  epoch  6, batch     9 | loss: 1.8125038MemoryTrain:  epoch  6, batch    10 | loss: 1.8107512MemoryTrain:  epoch  6, batch    11 | loss: 1.8117594MemoryTrain:  epoch  7, batch     0 | loss: 1.8105115MemoryTrain:  epoch  7, batch     1 | loss: 1.8113251MemoryTrain:  epoch  7, batch     2 | loss: 1.8090408MemoryTrain:  epoch  7, batch     3 | loss: 1.8148589MemoryTrain:  epoch  7, batch     4 | loss: 1.8105595MemoryTrain:  epoch  7, batch     5 | loss: 1.8110036MemoryTrain:  epoch  7, batch     6 | loss: 1.8162370MemoryTrain:  epoch  7, batch     7 | loss: 1.8099532MemoryTrain:  epoch  7, batch     8 | loss: 1.8131447MemoryTrain:  epoch  7, batch     9 | loss: 1.8104515MemoryTrain:  epoch  7, batch    10 | loss: 1.8112806MemoryTrain:  epoch  7, batch    11 | loss: 1.8110508MemoryTrain:  epoch  8, batch     0 | loss: 1.8115163MemoryTrain:  epoch  8, batch     1 | loss: 1.8159685MemoryTrain:  epoch  8, batch     2 | loss: 1.8110371MemoryTrain:  epoch  8, batch     3 | loss: 1.8100126MemoryTrain:  epoch  8, batch     4 | loss: 1.8099787MemoryTrain:  epoch  8, batch     5 | loss: 1.8102982MemoryTrain:  epoch  8, batch     6 | loss: 1.8052783MemoryTrain:  epoch  8, batch     7 | loss: 1.8082480MemoryTrain:  epoch  8, batch     8 | loss: 1.8109285MemoryTrain:  epoch  8, batch     9 | loss: 1.8101885MemoryTrain:  epoch  8, batch    10 | loss: 1.8065876MemoryTrain:  epoch  8, batch    11 | loss: 1.8090661MemoryTrain:  epoch  9, batch     0 | loss: 1.8091739MemoryTrain:  epoch  9, batch     1 | loss: 1.8079400MemoryTrain:  epoch  9, batch     2 | loss: 1.8146675MemoryTrain:  epoch  9, batch     3 | loss: 1.8104879MemoryTrain:  epoch  9, batch     4 | loss: 1.8097522MemoryTrain:  epoch  9, batch     5 | loss: 1.8111212MemoryTrain:  epoch  9, batch     6 | loss: 1.8077896MemoryTrain:  epoch  9, batch     7 | loss: 1.8087144MemoryTrain:  epoch  9, batch     8 | loss: 1.8089931MemoryTrain:  epoch  9, batch     9 | loss: 1.8162379MemoryTrain:  epoch  9, batch    10 | loss: 1.8098979MemoryTrain:  epoch  9, batch    11 | loss: 1.8034486
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    1 | acc: 68.75%,  total acc: 71.88%   [EVAL] batch:    2 | acc: 75.00%,  total acc: 72.92%   [EVAL] batch:    3 | acc: 87.50%,  total acc: 76.56%   [EVAL] batch:    4 | acc: 87.50%,  total acc: 78.75%   [EVAL] batch:    5 | acc: 93.75%,  total acc: 81.25%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 83.93%   [EVAL] batch:    7 | acc: 87.50%,  total acc: 84.38%   [EVAL] batch:    8 | acc: 81.25%,  total acc: 84.03%   [EVAL] batch:    9 | acc: 93.75%,  total acc: 85.00%   [EVAL] batch:   10 | acc: 81.25%,  total acc: 84.66%   [EVAL] batch:   11 | acc: 100.00%,  total acc: 85.94%   [EVAL] batch:   12 | acc: 93.75%,  total acc: 86.54%   [EVAL] batch:   13 | acc: 93.75%,  total acc: 87.05%   [EVAL] batch:   14 | acc: 43.75%,  total acc: 84.17%   
[EVAL] batch:    0 | acc: 50.00%,  total acc: 50.00%   [EVAL] batch:    1 | acc: 56.25%,  total acc: 53.12%   [EVAL] batch:    2 | acc: 56.25%,  total acc: 54.17%   [EVAL] batch:    3 | acc: 43.75%,  total acc: 51.56%   [EVAL] batch:    4 | acc: 50.00%,  total acc: 51.25%   [EVAL] batch:    5 | acc: 43.75%,  total acc: 50.00%   [EVAL] batch:    6 | acc: 100.00%,  total acc: 57.14%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 61.72%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 65.97%   [EVAL] batch:    9 | acc: 87.50%,  total acc: 68.12%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 71.02%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 72.40%   [EVAL] batch:   12 | acc: 50.00%,  total acc: 70.67%   [EVAL] batch:   13 | acc: 25.00%,  total acc: 67.41%   [EVAL] batch:   14 | acc: 50.00%,  total acc: 66.25%   [EVAL] batch:   15 | acc: 56.25%,  total acc: 65.62%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 66.18%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 65.97%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 65.79%   [EVAL] batch:   19 | acc: 81.25%,  total acc: 66.56%   [EVAL] batch:   20 | acc: 93.75%,  total acc: 67.86%   [EVAL] batch:   21 | acc: 93.75%,  total acc: 69.03%   [EVAL] batch:   22 | acc: 93.75%,  total acc: 70.11%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 71.09%   [EVAL] batch:   24 | acc: 100.00%,  total acc: 72.25%   [EVAL] batch:   25 | acc: 93.75%,  total acc: 73.08%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 73.61%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 74.33%   [EVAL] batch:   28 | acc: 87.50%,  total acc: 74.78%   [EVAL] batch:   29 | acc: 68.75%,  total acc: 74.58%   [EVAL] batch:   30 | acc: 81.25%,  total acc: 74.80%   [EVAL] batch:   31 | acc: 75.00%,  total acc: 74.80%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 73.67%   [EVAL] batch:   33 | acc: 0.00%,  total acc: 71.51%   [EVAL] batch:   34 | acc: 12.50%,  total acc: 69.82%   [EVAL] batch:   35 | acc: 6.25%,  total acc: 68.06%   [EVAL] batch:   36 | acc: 0.00%,  total acc: 66.22%   [EVAL] batch:   37 | acc: 0.00%,  total acc: 64.47%   [EVAL] batch:   38 | acc: 18.75%,  total acc: 63.30%   [EVAL] batch:   39 | acc: 75.00%,  total acc: 63.59%   [EVAL] batch:   40 | acc: 25.00%,  total acc: 62.65%   [EVAL] batch:   41 | acc: 25.00%,  total acc: 61.76%   [EVAL] batch:   42 | acc: 37.50%,  total acc: 61.19%   [EVAL] batch:   43 | acc: 75.00%,  total acc: 61.51%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 62.36%   [EVAL] batch:   45 | acc: 100.00%,  total acc: 63.18%   [EVAL] batch:   46 | acc: 100.00%,  total acc: 63.96%   [EVAL] batch:   47 | acc: 100.00%,  total acc: 64.71%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 65.43%   [EVAL] batch:   49 | acc: 100.00%,  total acc: 66.12%   [EVAL] batch:   50 | acc: 31.25%,  total acc: 65.44%   [EVAL] batch:   51 | acc: 31.25%,  total acc: 64.78%   [EVAL] batch:   52 | acc: 25.00%,  total acc: 64.03%   [EVAL] batch:   53 | acc: 25.00%,  total acc: 63.31%   [EVAL] batch:   54 | acc: 12.50%,  total acc: 62.39%   [EVAL] batch:   55 | acc: 18.75%,  total acc: 61.61%   [EVAL] batch:   56 | acc: 56.25%,  total acc: 61.51%   [EVAL] batch:   57 | acc: 93.75%,  total acc: 62.07%   [EVAL] batch:   58 | acc: 68.75%,  total acc: 62.18%   [EVAL] batch:   59 | acc: 87.50%,  total acc: 62.60%   [EVAL] batch:   60 | acc: 62.50%,  total acc: 62.60%   [EVAL] batch:   61 | acc: 68.75%,  total acc: 62.70%   [EVAL] batch:   62 | acc: 75.00%,  total acc: 62.90%   [EVAL] batch:   63 | acc: 81.25%,  total acc: 63.18%   [EVAL] batch:   64 | acc: 100.00%,  total acc: 63.75%   [EVAL] batch:   65 | acc: 100.00%,  total acc: 64.30%   [EVAL] batch:   66 | acc: 100.00%,  total acc: 64.83%   [EVAL] batch:   67 | acc: 100.00%,  total acc: 65.35%   [EVAL] batch:   68 | acc: 100.00%,  total acc: 65.85%   [EVAL] batch:   69 | acc: 100.00%,  total acc: 66.34%   [EVAL] batch:   70 | acc: 100.00%,  total acc: 66.81%   [EVAL] batch:   71 | acc: 93.75%,  total acc: 67.19%   [EVAL] batch:   72 | acc: 37.50%,  total acc: 66.78%   [EVAL] batch:   73 | acc: 68.75%,  total acc: 66.81%   [EVAL] batch:   74 | acc: 87.50%,  total acc: 67.08%   [EVAL] batch:   75 | acc: 93.75%,  total acc: 67.43%   [EVAL] batch:   76 | acc: 93.75%,  total acc: 67.78%   [EVAL] batch:   77 | acc: 50.00%,  total acc: 67.55%   [EVAL] batch:   78 | acc: 75.00%,  total acc: 67.64%   [EVAL] batch:   79 | acc: 75.00%,  total acc: 67.73%   [EVAL] batch:   80 | acc: 75.00%,  total acc: 67.82%   [EVAL] batch:   81 | acc: 100.00%,  total acc: 68.22%   [EVAL] batch:   82 | acc: 100.00%,  total acc: 68.60%   [EVAL] batch:   83 | acc: 93.75%,  total acc: 68.90%   [EVAL] batch:   84 | acc: 68.75%,  total acc: 68.90%   [EVAL] batch:   85 | acc: 37.50%,  total acc: 68.53%   [EVAL] batch:   86 | acc: 43.75%,  total acc: 68.25%   [EVAL] batch:   87 | acc: 62.50%,  total acc: 68.18%   [EVAL] batch:   88 | acc: 50.00%,  total acc: 67.98%   [EVAL] batch:   89 | acc: 68.75%,  total acc: 67.99%   [EVAL] batch:   90 | acc: 62.50%,  total acc: 67.93%   [EVAL] batch:   91 | acc: 81.25%,  total acc: 68.07%   [EVAL] batch:   92 | acc: 81.25%,  total acc: 68.21%   [EVAL] batch:   93 | acc: 81.25%,  total acc: 68.35%   [EVAL] batch:   94 | acc: 93.75%,  total acc: 68.62%   [EVAL] batch:   95 | acc: 93.75%,  total acc: 68.88%   [EVAL] batch:   96 | acc: 100.00%,  total acc: 69.20%   [EVAL] batch:   97 | acc: 81.25%,  total acc: 69.32%   [EVAL] batch:   98 | acc: 87.50%,  total acc: 69.51%   [EVAL] batch:   99 | acc: 87.50%,  total acc: 69.69%   [EVAL] batch:  100 | acc: 87.50%,  total acc: 69.86%   [EVAL] batch:  101 | acc: 93.75%,  total acc: 70.10%   [EVAL] batch:  102 | acc: 93.75%,  total acc: 70.33%   [EVAL] batch:  103 | acc: 100.00%,  total acc: 70.61%   [EVAL] batch:  104 | acc: 6.25%,  total acc: 70.00%   
cur_acc:  ['0.8693', '0.9132', '0.8929', '0.9107', '0.8462', '0.8417']
his_acc:  ['0.8693', '0.8550', '0.8311', '0.7484', '0.6840', '0.7000']
CurrentTrain: epoch  0, batch     0 | loss: 5.9746118CurrentTrain: epoch  0, batch     1 | loss: 5.6714487CurrentTrain: epoch  1, batch     0 | loss: 5.7126441CurrentTrain: epoch  1, batch     1 | loss: 3.8575871CurrentTrain: epoch  2, batch     0 | loss: 5.5201855CurrentTrain: epoch  2, batch     1 | loss: 3.1646881CurrentTrain: epoch  3, batch     0 | loss: 3.9346147CurrentTrain: epoch  3, batch     1 | loss: 3.9331050CurrentTrain: epoch  4, batch     0 | loss: 3.7986853CurrentTrain: epoch  4, batch     1 | loss: 4.0146475CurrentTrain: epoch  5, batch     0 | loss: 2.7483597CurrentTrain: epoch  5, batch     1 | loss: 5.3648572CurrentTrain: epoch  6, batch     0 | loss: 3.5566893CurrentTrain: epoch  6, batch     1 | loss: 2.2812817CurrentTrain: epoch  7, batch     0 | loss: 3.1021662CurrentTrain: epoch  7, batch     1 | loss: 2.1444273CurrentTrain: epoch  8, batch     0 | loss: 2.3643258CurrentTrain: epoch  8, batch     1 | loss: 2.6399608CurrentTrain: epoch  9, batch     0 | loss: 2.6769557CurrentTrain: epoch  9, batch     1 | loss: 1.9748982
#### person country of birth ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person country of birth" means a person was born in a country.
Here is an example:
Relation: person country of birth
Context: in testimony by satellite link from germany to a house of representatives ' panel , murat kurnaz recounted his five-year detention , alleging a wide range of torture and abuse .
Head Entity: murat kurnaz
Tail Entity: germany
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person country of birth":
Relation: person country of birth  
Context: The famous physicist Albert Einstein was born in the Kingdom of Württemberg in the German Empire.  
Head Entity: Albert Einstein  
Tail Entity: Germany  

Relation: person country of birth  
Context: During her acceptance speech, the actress Lupita Nyong'o proudly mentioned her roots, stating that she was born in Mexico before moving to Kenya.  
Head Entity: Lupita Nyong'o  
Tail Entity: Mexico  

Relation: person country of birth  
Context: The renowned author Gabriel García Márquez often reflected on his childhood in Aracataca, Colombia, which shaped his literary voice.  
Head Entity: Gabriel García Márquez  
Tail Entity: Colombia  

Relation: person country of birth  
Context: In a recent interview, the musician Shakira discussed her early life in Barranquilla, Colombia, where she was born and raised.  
Head Entity: Shakira  
Tail Entity: Colombia  

Relation: person country of birth  
Context: The celebrated scientist Marie Curie was born in Warsaw, Poland, before moving to France to continue her groundbreaking research.  
Head Entity: Marie Curie  
Tail Entity: Poland  
#### organization website ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization website" means an organization 's website is an url.
Here is an example:
Relation: organization website
Context: http://www.pentaxsailaway.com/ paul j. sail away with pentax sweepstakes
Head Entity: pentax
Tail Entity: http://www.pentaxsailaway.com/
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization website":
Relation: organization website  
Context: Visit our official site at https://www.techinnovators.com for the latest updates.  
Head Entity: Tech Innovators  
Tail Entity: https://www.techinnovators.com  

Relation: organization website  
Context: For more information, check out the website of Green Earth Initiative at http://www.greenearth.org.  
Head Entity: Green Earth Initiative  
Tail Entity: http://www.greenearth.org  

Relation: organization website  
Context: The blog post can be found on the company’s website: https://www.creativeworks.com/blog.  
Head Entity: Creative Works  
Tail Entity: https://www.creativeworks.com/blog  

Relation: organization website  
Context: You can learn more about our services by visiting our website at http://www.healthcareplus.com.  
Head Entity: Healthcare Plus  
Tail Entity: http://www.healthcareplus.com  

Relation: organization website  
Context: Explore our projects and initiatives at https://www.artisticvisions.org.  
Head Entity: Artistic Visions  
Tail Entity: https://www.artisticvisions.org  
#### organization shareholders ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization shareholders" means an organization was invested by a person.
Here is an example:
Relation: organization shareholders
Context: new york 2008-01-14 15:45:15 utc in february 2000 several investors bought stakes of undisclosed size in zagat , including general atlantic llc , a private equity firm ; the venture capital firm kleiner perkins caufield & byers ; investment bank allen & co as well as nancy peretsman , executive vice president at allen ; former microsoft corp executive nathan myhrvold and nicholas negroponte , a computer scientist who founded the massachusetts institute of technology 's media lab and the one laptop per child project .
Head Entity: zagat
Tail Entity: nancy peretsman , executive vice president at allen
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization shareholders":
Relation: organization shareholders  
Context: in 2015, several prominent investors, including the venture capital firm sequoia capital and billionaire entrepreneur elon musk, acquired shares in the innovative tech startup, spacex, which is known for its ambitious plans to colonize mars.  
Head Entity: spacex  
Tail Entity: elon musk  

Relation: organization shareholders  
Context: during the funding round in 2019, the online retail giant, amazon, attracted investments from various hedge funds, including the well-known blackrock and vanguard group, which significantly increased their stakes in the company.  
Head Entity: amazon  
Tail Entity: blackrock  

Relation: organization shareholders  
Context: in 2020, the electric vehicle manufacturer, tesla, saw a surge in investments from several high-profile individuals, including tim cook, the ceo of apple, who purchased a considerable number of shares in the company.  
Head Entity: tesla  
Tail Entity: tim cook  

Relation: organization shareholders  
Context: the biotechnology firm, moderna, received substantial investments from various institutional investors, including fidelity investments and the well-respected t. rowe price, during its rapid growth phase in 2021.  
Head Entity: moderna  
Tail Entity: fidelity investments  

Relation: organization shareholders  
Context: in 2018, the social media platform, facebook, attracted significant investments from several venture capital firms, including a16z and greylock partners, which boosted its market presence.  
Head Entity: facebook  
Tail Entity: a16z  
#### organization dissolved ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization dissolved" means an organization was dissolved in a date.
Here is an example:
Relation: organization dissolved
Context: the tse suffered its worst-ever system crash in november 2005 which paralyzed the world 's second largest bourse and forced it to shelve plan for a listing of its own .
Head Entity: tse
Tail Entity: november 2005
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization dissolved":
Relation: organization dissolved  
Context: The once-prominent tech startup, Innovatech, officially ceased operations in March 2020 after struggling to secure funding.  
Head Entity: Innovatech  
Tail Entity: March 2020  

Relation: organization dissolved  
Context: After years of financial difficulties, the local charity, Helping Hands, announced its closure in January 2019, leaving many in the community without support.  
Head Entity: Helping Hands  
Tail Entity: January 2019  

Relation: organization dissolved  
Context: The historic publishing house, Classic Reads, was dissolved in July 2021, marking the end of an era in literary history.  
Head Entity: Classic Reads  
Tail Entity: July 2021  

Relation: organization dissolved  
Context: Following a series of scandals, the nonprofit organization, Clean Water Initiative, was officially dissolved in February 2022.  
Head Entity: Clean Water Initiative  
Tail Entity: February 2022  

Relation: organization dissolved  
Context: The beloved local theater company, Stage Dreams, announced its dissolution in December 2018 due to declining ticket sales and lack of funding.  
Head Entity: Stage Dreams  
Tail Entity: December 2018  
#### organization founded by ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization founded by" means an organization was found by a person.
Here is an example:
Relation: organization founded by
Context: `` i have no greater obligation than to ensure the safely of airline travelers in this country , '' transportation secretary ray lahood said in a joint statement with j. randolph babbitt , administrator of the federal aviation administration , that was issued on the eve of a senate hearing on aviation safety .
Head Entity: federal aviation administration
Tail Entity: j. randolph babbitt
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization founded by":
Relation: organization founded by  
Context: In 1975, the renowned physicist and entrepreneur, Dr. John Smith, established Quantum Innovations, a company dedicated to advancing quantum computing technologies.  
Head Entity: Quantum Innovations  
Tail Entity: Dr. John Smith  

Relation: organization founded by  
Context: The charity organization, Hope for Tomorrow, was created in 2010 by the well-known philanthropist, Sarah Johnson, to support underprivileged children.  
Head Entity: Hope for Tomorrow  
Tail Entity: Sarah Johnson  

Relation: organization founded by  
Context: In the early 2000s, the tech startup, GreenTech Solutions, was founded by environmentalist and engineer, Mark Thompson, to promote sustainable energy practices.  
Head Entity: GreenTech Solutions  
Tail Entity: Mark Thompson  

Relation: organization founded by  
Context: The prestigious art gallery, Modern Visions, was opened in 2015 by celebrated artist, Emily Chen, to showcase contemporary art from emerging talents.  
Head Entity: Modern Visions  
Tail Entity: Emily Chen  

Relation: organization founded by  
Context: The innovative educational platform, LearnSmart, was launched in 2018 by former teacher, David Lee, to enhance online learning experiences for students worldwide.  
Head Entity: LearnSmart  
Tail Entity: David Lee  
Mixup data size:  28180
MixupTrain:  epoch  0, batch     0 | loss: 4.4976096MixupTrain:  epoch  0, batch     1 | loss: 4.3345628MixupTrain:  epoch  0, batch     2 | loss: 4.0324235MixupTrain:  epoch  0, batch     3 | loss: 3.7675395MixupTrain:  epoch  0, batch     5 | loss: 4.2843742MixupTrain:  epoch  0, batch     6 | loss: 4.6170902MixupTrain:  epoch  0, batch     7 | loss: 4.0612431MixupTrain:  epoch  0, batch     8 | loss: 3.2346194MixupTrain:  epoch  0, batch     9 | loss: 4.3345799MixupTrain:  epoch  0, batch    10 | loss: 5.9019918MixupTrain:  epoch  0, batch    11 | loss: 5.3990011MixupTrain:  epoch  0, batch    12 | loss: 3.7496939MixupTrain:  epoch  0, batch    13 | loss: 3.4131365MixupTrain:  epoch  0, batch    14 | loss: 4.3895245MixupTrain:  epoch  0, batch    15 | loss: 3.2256658MixupTrain:  epoch  0, batch    16 | loss: 3.0931067MixupTrain:  epoch  0, batch    17 | loss: 4.0101752MixupTrain:  epoch  0, batch    18 | loss: 3.9084380MixupTrain:  epoch  0, batch    19 | loss: 3.9360352MixupTrain:  epoch  0, batch    20 | loss: 5.4448752MixupTrain:  epoch  0, batch    21 | loss: 3.6542203MixupTrain:  epoch  0, batch    22 | loss: 4.4982796MixupTrain:  epoch  0, batch    23 | loss: 3.9815359MixupTrain:  epoch  0, batch    24 | loss: 3.3741844MixupTrain:  epoch  0, batch    25 | loss: 4.5157566MixupTrain:  epoch  0, batch    26 | loss: 3.7147973MixupTrain:  epoch  0, batch    27 | loss: 4.2527709MixupTrain:  epoch  0, batch    28 | loss: 3.9626207MixupTrain:  epoch  0, batch    30 | loss: 3.3616748MixupTrain:  epoch  0, batch    31 | loss: 3.6113958MixupTrain:  epoch  0, batch    32 | loss: 4.3161368MixupTrain:  epoch  0, batch    33 | loss: 3.8233113MixupTrain:  epoch  0, batch    34 | loss: 3.9938302MixupTrain:  epoch  0, batch    35 | loss: 3.7710793MixupTrain:  epoch  0, batch    36 | loss: 4.2687025MixupTrain:  epoch  0, batch    37 | loss: 4.0731058MixupTrain:  epoch  0, batch    38 | loss: 3.1668203MixupTrain:  epoch  0, batch    39 | loss: 4.4540119MixupTrain:  epoch  0, batch    40 | loss: 3.4691358MixupTrain:  epoch  0, batch    41 | loss: 3.8474228MixupTrain:  epoch  0, batch    42 | loss: 4.3264446MixupTrain:  epoch  0, batch    43 | loss: 3.5975986MixupTrain:  epoch  0, batch    44 | loss: 3.9402478MixupTrain:  epoch  0, batch    45 | loss: 4.6639628MixupTrain:  epoch  0, batch    46 | loss: 3.6117644MixupTrain:  epoch  0, batch    47 | loss: 3.4778562MixupTrain:  epoch  0, batch    48 | loss: 3.7463558MixupTrain:  epoch  0, batch    49 | loss: 3.8382416MixupTrain:  epoch  0, batch    50 | loss: 2.7739687MixupTrain:  epoch  0, batch    51 | loss: 3.9482250MixupTrain:  epoch  0, batch    54 | loss: 3.6622591MixupTrain:  epoch  0, batch    55 | loss: 3.4147904MixupTrain:  epoch  0, batch    57 | loss: 2.9010329MixupTrain:  epoch  0, batch    58 | loss: 3.1511524MixupTrain:  epoch  0, batch    59 | loss: 3.9187796MixupTrain:  epoch  0, batch    60 | loss: 2.7953084MixupTrain:  epoch  0, batch    61 | loss: 3.6210573MixupTrain:  epoch  0, batch    62 | loss: 2.8890519MixupTrain:  epoch  0, batch    63 | loss: 3.7560198MixupTrain:  epoch  0, batch    64 | loss: 3.3788488MixupTrain:  epoch  0, batch    65 | loss: 3.0498757MixupTrain:  epoch  0, batch    66 | loss: 3.4650478MixupTrain:  epoch  0, batch    67 | loss: 3.1012223MixupTrain:  epoch  0, batch    68 | loss: 3.4958358MixupTrain:  epoch  0, batch    69 | loss: 3.4089940MixupTrain:  epoch  0, batch    71 | loss: 3.9233103MixupTrain:  epoch  0, batch    72 | loss: 2.9257960MixupTrain:  epoch  0, batch    73 | loss: 3.5813210MixupTrain:  epoch  0, batch    74 | loss: 3.7033653MixupTrain:  epoch  0, batch    75 | loss: 3.5044158MixupTrain:  epoch  0, batch    76 | loss: 2.8099513MixupTrain:  epoch  0, batch    77 | loss: 3.4717338MixupTrain:  epoch  0, batch    78 | loss: 2.9506521MixupTrain:  epoch  0, batch    79 | loss: 2.9458163MixupTrain:  epoch  0, batch    80 | loss: 3.2711339MixupTrain:  epoch  0, batch    81 | loss: 3.0592153MixupTrain:  epoch  0, batch    82 | loss: 3.3374946MixupTrain:  epoch  0, batch    83 | loss: 3.5818624MixupTrain:  epoch  0, batch    84 | loss: 3.4311750MixupTrain:  epoch  0, batch    85 | loss: 2.9000947MixupTrain:  epoch  0, batch    86 | loss: 2.9005053MixupTrain:  epoch  0, batch    87 | loss: 3.5185120MixupTrain:  epoch  0, batch    88 | loss: 3.0450218MixupTrain:  epoch  0, batch    89 | loss: 3.3349807MixupTrain:  epoch  0, batch    90 | loss: 3.5282772MixupTrain:  epoch  0, batch    91 | loss: 3.2452497MixupTrain:  epoch  0, batch    92 | loss: 3.1410480MixupTrain:  epoch  0, batch    93 | loss: 3.9475522MixupTrain:  epoch  0, batch    94 | loss: 3.1178632MixupTrain:  epoch  0, batch    95 | loss: 3.0685472MixupTrain:  epoch  0, batch    96 | loss: 2.7705376MixupTrain:  epoch  0, batch    97 | loss: 2.9983907MixupTrain:  epoch  0, batch    98 | loss: 2.3109403MixupTrain:  epoch  0, batch    99 | loss: 3.2038107MixupTrain:  epoch  0, batch   100 | loss: 2.6302612MixupTrain:  epoch  0, batch   101 | loss: 3.0705159MixupTrain:  epoch  0, batch   102 | loss: 2.8589134MixupTrain:  epoch  0, batch   105 | loss: 3.0836484MixupTrain:  epoch  0, batch   106 | loss: 2.6319406MixupTrain:  epoch  0, batch   107 | loss: 3.2765689MixupTrain:  epoch  0, batch   110 | loss: 3.2966111MixupTrain:  epoch  0, batch   112 | loss: 4.1104355MixupTrain:  epoch  0, batch   113 | loss: 2.8981366MixupTrain:  epoch  0, batch   114 | loss: 2.6167347MixupTrain:  epoch  0, batch   115 | loss: 2.5227365MixupTrain:  epoch  0, batch   117 | loss: 2.4671614MixupTrain:  epoch  0, batch   118 | loss: 3.1743174MixupTrain:  epoch  0, batch   119 | loss: 2.5721855MixupTrain:  epoch  0, batch   120 | loss: 3.0842850MixupTrain:  epoch  0, batch   121 | loss: 2.6646328MixupTrain:  epoch  0, batch   122 | loss: 2.8740830MixupTrain:  epoch  0, batch   123 | loss: 3.0499687MixupTrain:  epoch  0, batch   124 | loss: 2.8458123MixupTrain:  epoch  0, batch   125 | loss: 3.1302829MixupTrain:  epoch  0, batch   126 | loss: 2.7685826MixupTrain:  epoch  0, batch   127 | loss: 3.2230868MixupTrain:  epoch  0, batch   129 | loss: 3.2631598MixupTrain:  epoch  0, batch   130 | loss: 3.1685991MixupTrain:  epoch  0, batch   131 | loss: 2.9050899MixupTrain:  epoch  0, batch   132 | loss: 3.2186995MixupTrain:  epoch  0, batch   134 | loss: 3.3618133MixupTrain:  epoch  0, batch   135 | loss: 2.3737342MixupTrain:  epoch  0, batch   137 | loss: 3.5970187MixupTrain:  epoch  0, batch   139 | loss: 2.6823483MixupTrain:  epoch  0, batch   140 | loss: 3.1686568MixupTrain:  epoch  0, batch   141 | loss: 2.7527838MixupTrain:  epoch  0, batch   142 | loss: 3.5436368MixupTrain:  epoch  0, batch   143 | loss: 2.9205403MixupTrain:  epoch  0, batch   145 | loss: 2.8854675MixupTrain:  epoch  0, batch   146 | loss: 2.7480021MixupTrain:  epoch  0, batch   147 | loss: 2.7277603MixupTrain:  epoch  0, batch   148 | loss: 2.9955177MixupTrain:  epoch  0, batch   149 | loss: 2.9119527MixupTrain:  epoch  0, batch   151 | loss: 2.4294627MixupTrain:  epoch  0, batch   152 | loss: 2.8866215MixupTrain:  epoch  0, batch   154 | loss: 2.8162832MixupTrain:  epoch  0, batch   156 | loss: 2.9959474MixupTrain:  epoch  0, batch   157 | loss: 2.7728453MixupTrain:  epoch  0, batch   158 | loss: 2.4004734MixupTrain:  epoch  0, batch   159 | loss: 2.9381807MixupTrain:  epoch  0, batch   160 | loss: 2.8219886MixupTrain:  epoch  0, batch   161 | loss: 2.9139152MixupTrain:  epoch  0, batch   162 | loss: 2.8925338MixupTrain:  epoch  0, batch   163 | loss: 3.0188174MixupTrain:  epoch  0, batch   164 | loss: 2.7102516MixupTrain:  epoch  0, batch   165 | loss: 2.9468350MixupTrain:  epoch  0, batch   166 | loss: 2.7129881MixupTrain:  epoch  0, batch   167 | loss: 2.3636360MixupTrain:  epoch  0, batch   168 | loss: 2.9120574MixupTrain:  epoch  0, batch   172 | loss: 2.8404076MixupTrain:  epoch  0, batch   173 | loss: 2.3890319MixupTrain:  epoch  0, batch   174 | loss: 3.9472723MixupTrain:  epoch  0, batch   175 | loss: 2.9640744MixupTrain:  epoch  0, batch   176 | loss: 2.7660065MixupTrain:  epoch  0, batch   177 | loss: 2.9471831MixupTrain:  epoch  0, batch   179 | loss: 3.1883094MixupTrain:  epoch  0, batch   180 | loss: 2.6872170MixupTrain:  epoch  0, batch   181 | loss: 2.7821047MixupTrain:  epoch  0, batch   182 | loss: 3.0166979MixupTrain:  epoch  0, batch   183 | loss: 3.1251264MixupTrain:  epoch  0, batch   184 | loss: 3.0529606MixupTrain:  epoch  0, batch   185 | loss: 2.4769688MixupTrain:  epoch  0, batch   186 | loss: 2.8798761MixupTrain:  epoch  0, batch   187 | loss: 2.9029825MixupTrain:  epoch  0, batch   188 | loss: 3.0256538MixupTrain:  epoch  0, batch   189 | loss: 2.7498579MixupTrain:  epoch  0, batch   190 | loss: 2.9875398MixupTrain:  epoch  0, batch   191 | loss: 3.3433099MixupTrain:  epoch  0, batch   192 | loss: 2.7923393MixupTrain:  epoch  0, batch   194 | loss: 2.6336389MixupTrain:  epoch  0, batch   195 | loss: 2.6529708MixupTrain:  epoch  0, batch   196 | loss: 2.9526076MixupTrain:  epoch  0, batch   197 | loss: 2.9255624MixupTrain:  epoch  0, batch   198 | loss: 2.3417621MixupTrain:  epoch  0, batch   199 | loss: 2.8251364MixupTrain:  epoch  0, batch   200 | loss: 3.0172553MixupTrain:  epoch  0, batch   201 | loss: 2.4687161MixupTrain:  epoch  0, batch   202 | loss: 2.8951817MixupTrain:  epoch  0, batch   203 | loss: 3.3287003MixupTrain:  epoch  0, batch   204 | loss: 2.7290902MixupTrain:  epoch  0, batch   206 | loss: 2.7171826MixupTrain:  epoch  0, batch   207 | loss: 2.7303786MixupTrain:  epoch  0, batch   208 | loss: 2.6725655MixupTrain:  epoch  0, batch   209 | loss: 2.8809917MixupTrain:  epoch  0, batch   210 | loss: 3.0524902MixupTrain:  epoch  0, batch   212 | loss: 2.6608782MixupTrain:  epoch  0, batch   213 | loss: 2.7960272MixupTrain:  epoch  0, batch   214 | loss: 3.2091126MixupTrain:  epoch  0, batch   215 | loss: 2.4755514MixupTrain:  epoch  0, batch   216 | loss: 2.8005860MixupTrain:  epoch  0, batch   217 | loss: 2.7714195MixupTrain:  epoch  0, batch   218 | loss: 3.1576591MixupTrain:  epoch  0, batch   219 | loss: 2.9333320MixupTrain:  epoch  0, batch   220 | loss: 3.3019528MixupTrain:  epoch  0, batch   221 | loss: 3.0108111MixupTrain:  epoch  0, batch   222 | loss: 2.6714458MixupTrain:  epoch  0, batch   223 | loss: 2.8612127MixupTrain:  epoch  0, batch   224 | loss: 2.5779247MixupTrain:  epoch  0, batch   225 | loss: 2.7126827MixupTrain:  epoch  0, batch   226 | loss: 2.8181682MixupTrain:  epoch  0, batch   227 | loss: 3.0822821MixupTrain:  epoch  0, batch   228 | loss: 2.8517354MixupTrain:  epoch  0, batch   229 | loss: 3.0471399MixupTrain:  epoch  0, batch   230 | loss: 2.9927588MixupTrain:  epoch  0, batch   231 | loss: 2.7869463MixupTrain:  epoch  0, batch   232 | loss: 2.4511428MixupTrain:  epoch  0, batch   233 | loss: 2.8234999MixupTrain:  epoch  0, batch   234 | loss: 2.7328486MixupTrain:  epoch  0, batch   236 | loss: 3.0531306MixupTrain:  epoch  0, batch   237 | loss: 2.5529566MixupTrain:  epoch  0, batch   238 | loss: 2.9343829MixupTrain:  epoch  0, batch   239 | loss: 3.1520665MixupTrain:  epoch  0, batch   240 | loss: 2.9533215MixupTrain:  epoch  0, batch   241 | loss: 2.4313622MixupTrain:  epoch  0, batch   242 | loss: 2.7608085MixupTrain:  epoch  0, batch   243 | loss: 2.9783316MixupTrain:  epoch  0, batch   245 | loss: 2.5095763MixupTrain:  epoch  0, batch   246 | loss: 3.1065760MixupTrain:  epoch  0, batch   247 | loss: 3.0136406MixupTrain:  epoch  0, batch   248 | loss: 2.4967065MixupTrain:  epoch  0, batch   249 | loss: 2.8712676MixupTrain:  epoch  0, batch   252 | loss: 2.6972380MixupTrain:  epoch  0, batch   253 | loss: 2.9332530MixupTrain:  epoch  0, batch   254 | loss: 2.6668131MixupTrain:  epoch  0, batch   255 | loss: 2.6395173MixupTrain:  epoch  0, batch   256 | loss: 2.6310735MixupTrain:  epoch  0, batch   257 | loss: 3.0444140MixupTrain:  epoch  0, batch   258 | loss: 2.8085809MixupTrain:  epoch  0, batch   259 | loss: 2.5654857MixupTrain:  epoch  0, batch   260 | loss: 2.7412066MixupTrain:  epoch  0, batch   261 | loss: 2.8805070MixupTrain:  epoch  0, batch   263 | loss: 2.6740184MixupTrain:  epoch  0, batch   264 | loss: 2.8657718MixupTrain:  epoch  0, batch   265 | loss: 2.5723867MixupTrain:  epoch  0, batch   266 | loss: 2.7996984MixupTrain:  epoch  0, batch   267 | loss: 2.5449932MixupTrain:  epoch  0, batch   268 | loss: 2.7577047MixupTrain:  epoch  0, batch   269 | loss: 3.0602045MixupTrain:  epoch  0, batch   270 | loss: 2.7604675MixupTrain:  epoch  0, batch   271 | loss: 2.7655528MixupTrain:  epoch  0, batch   272 | loss: 2.7626686MixupTrain:  epoch  0, batch   273 | loss: 2.6754403MixupTrain:  epoch  0, batch   274 | loss: 2.9597886MixupTrain:  epoch  0, batch   275 | loss: 2.6708057MixupTrain:  epoch  0, batch   276 | loss: 2.6238942MixupTrain:  epoch  0, batch   278 | loss: 2.8431482MixupTrain:  epoch  0, batch   279 | loss: 2.5720606MixupTrain:  epoch  0, batch   280 | loss: 2.7614532MixupTrain:  epoch  0, batch   281 | loss: 2.6100960MixupTrain:  epoch  0, batch   282 | loss: 2.9851046MixupTrain:  epoch  0, batch   283 | loss: 2.5436840MixupTrain:  epoch  0, batch   284 | loss: 2.5284808MixupTrain:  epoch  0, batch   285 | loss: 2.3768721MixupTrain:  epoch  0, batch   286 | loss: 2.2899489MixupTrain:  epoch  0, batch   287 | loss: 2.3494039MixupTrain:  epoch  0, batch   288 | loss: 2.7174983MixupTrain:  epoch  0, batch   289 | loss: 2.3661699MixupTrain:  epoch  0, batch   290 | loss: 2.6619873MixupTrain:  epoch  0, batch   291 | loss: 2.7306767MixupTrain:  epoch  0, batch   293 | loss: 2.4813585MixupTrain:  epoch  0, batch   294 | loss: 3.0968761MixupTrain:  epoch  0, batch   295 | loss: 2.2136924MixupTrain:  epoch  0, batch   296 | loss: 2.6291728MixupTrain:  epoch  0, batch   297 | loss: 3.2734489MixupTrain:  epoch  0, batch   298 | loss: 2.7500284MixupTrain:  epoch  0, batch   300 | loss: 2.4326167MixupTrain:  epoch  0, batch   301 | loss: 2.7514486MixupTrain:  epoch  0, batch   302 | loss: 2.6109347MixupTrain:  epoch  0, batch   303 | loss: 3.2232814MixupTrain:  epoch  0, batch   304 | loss: 2.3790431MixupTrain:  epoch  0, batch   305 | loss: 2.9082592MixupTrain:  epoch  0, batch   306 | loss: 3.1041079MixupTrain:  epoch  0, batch   307 | loss: 2.6417518MixupTrain:  epoch  0, batch   308 | loss: 3.0037978MixupTrain:  epoch  0, batch   309 | loss: 3.3272090MixupTrain:  epoch  0, batch   310 | loss: 3.1775684MixupTrain:  epoch  0, batch   311 | loss: 2.8887665MixupTrain:  epoch  0, batch   312 | loss: 2.6304073MixupTrain:  epoch  0, batch   313 | loss: 2.0343432MixupTrain:  epoch  0, batch   314 | loss: 2.8056598MixupTrain:  epoch  0, batch   315 | loss: 2.9487591MixupTrain:  epoch  0, batch   316 | loss: 2.6023350MixupTrain:  epoch  0, batch   317 | loss: 3.0062971MixupTrain:  epoch  0, batch   319 | loss: 2.3769283MixupTrain:  epoch  0, batch   320 | loss: 2.6389832MixupTrain:  epoch  0, batch   321 | loss: 2.6182914MixupTrain:  epoch  0, batch   322 | loss: 2.7485304MixupTrain:  epoch  0, batch   323 | loss: 2.8688900MixupTrain:  epoch  0, batch   324 | loss: 2.8380120MixupTrain:  epoch  0, batch   325 | loss: 2.9721708MixupTrain:  epoch  0, batch   326 | loss: 2.6944141MixupTrain:  epoch  0, batch   327 | loss: 2.5814114MixupTrain:  epoch  0, batch   328 | loss: 2.8532858MixupTrain:  epoch  0, batch   330 | loss: 2.8135955MixupTrain:  epoch  0, batch   331 | loss: 2.8965926MixupTrain:  epoch  0, batch   332 | loss: 2.4769430MixupTrain:  epoch  0, batch   333 | loss: 2.7940156MixupTrain:  epoch  0, batch   334 | loss: 2.6139684MixupTrain:  epoch  0, batch   335 | loss: 2.6949964MixupTrain:  epoch  0, batch   337 | loss: 2.9466839MixupTrain:  epoch  0, batch   339 | loss: 3.0998261MixupTrain:  epoch  0, batch   341 | loss: 2.9379961MixupTrain:  epoch  0, batch   343 | loss: 2.7114470MixupTrain:  epoch  0, batch   346 | loss: 2.7332821MixupTrain:  epoch  0, batch   348 | loss: 2.4655619MixupTrain:  epoch  0, batch   349 | loss: 2.6267316MixupTrain:  epoch  0, batch   350 | loss: 2.7627017MixupTrain:  epoch  0, batch   351 | loss: 2.5966592MixupTrain:  epoch  0, batch   352 | loss: 2.3782251MixupTrain:  epoch  0, batch   353 | loss: 2.8582737MixupTrain:  epoch  0, batch   354 | loss: 2.3125949MixupTrain:  epoch  0, batch   355 | loss: 2.6640601MixupTrain:  epoch  0, batch   356 | loss: 2.7524281MixupTrain:  epoch  0, batch   357 | loss: 3.0234053MixupTrain:  epoch  0, batch   358 | loss: 2.3202324MixupTrain:  epoch  0, batch   359 | loss: 2.3900745MixupTrain:  epoch  0, batch   360 | loss: 2.6107931MixupTrain:  epoch  0, batch   361 | loss: 2.7771847MixupTrain:  epoch  0, batch   362 | loss: 2.5501137MixupTrain:  epoch  0, batch   365 | loss: 2.8308883MixupTrain:  epoch  0, batch   366 | loss: 2.6608343MixupTrain:  epoch  0, batch   367 | loss: 2.6536129MixupTrain:  epoch  0, batch   368 | loss: 2.7149482MixupTrain:  epoch  0, batch   369 | loss: 2.8147240MixupTrain:  epoch  0, batch   370 | loss: 2.3601427MixupTrain:  epoch  0, batch   371 | loss: 2.5575571MixupTrain:  epoch  0, batch   372 | loss: 2.6485934MixupTrain:  epoch  0, batch   373 | loss: 2.4622846MixupTrain:  epoch  0, batch   374 | loss: 2.6860387MixupTrain:  epoch  0, batch   375 | loss: 2.4651926MixupTrain:  epoch  0, batch   376 | loss: 2.6340313MixupTrain:  epoch  0, batch   377 | loss: 2.5592771MixupTrain:  epoch  0, batch   378 | loss: 2.4937513MixupTrain:  epoch  0, batch   379 | loss: 2.9585118MixupTrain:  epoch  0, batch   380 | loss: 2.8741262MixupTrain:  epoch  0, batch   381 | loss: 2.4746456MixupTrain:  epoch  0, batch   382 | loss: 3.0196476MixupTrain:  epoch  0, batch   383 | loss: 2.5772390MixupTrain:  epoch  0, batch   384 | loss: 2.5606661MixupTrain:  epoch  0, batch   385 | loss: 2.8817096MixupTrain:  epoch  0, batch   386 | loss: 2.7052319MixupTrain:  epoch  0, batch   387 | loss: 2.4772263MixupTrain:  epoch  0, batch   388 | loss: 2.2869000MixupTrain:  epoch  0, batch   389 | loss: 2.7345459MixupTrain:  epoch  0, batch   390 | loss: 2.5539982MixupTrain:  epoch  0, batch   392 | loss: 2.5497398MixupTrain:  epoch  0, batch   393 | loss: 2.4994099MixupTrain:  epoch  0, batch   394 | loss: 2.6342165MixupTrain:  epoch  0, batch   395 | loss: 2.1775589MixupTrain:  epoch  0, batch   396 | loss: 2.5116277MixupTrain:  epoch  0, batch   397 | loss: 2.7479310MixupTrain:  epoch  0, batch   398 | loss: 2.2271705MixupTrain:  epoch  0, batch   399 | loss: 2.2127013MixupTrain:  epoch  0, batch   400 | loss: 2.7816865MixupTrain:  epoch  0, batch   401 | loss: 2.6047735MixupTrain:  epoch  0, batch   402 | loss: 3.3584423MixupTrain:  epoch  0, batch   403 | loss: 2.6085649MixupTrain:  epoch  0, batch   404 | loss: 2.7131422MixupTrain:  epoch  0, batch   405 | loss: 2.4995115MixupTrain:  epoch  0, batch   406 | loss: 3.0156548MixupTrain:  epoch  0, batch   407 | loss: 3.0632062MixupTrain:  epoch  0, batch   409 | loss: 2.5597501MixupTrain:  epoch  0, batch   410 | loss: 2.8246555MixupTrain:  epoch  0, batch   412 | loss: 2.3598967MixupTrain:  epoch  0, batch   413 | loss: 2.7166896MixupTrain:  epoch  0, batch   414 | loss: 2.9715023MixupTrain:  epoch  0, batch   416 | loss: 2.5729294MixupTrain:  epoch  0, batch   417 | loss: 2.8635981MixupTrain:  epoch  0, batch   419 | loss: 2.2283795MixupTrain:  epoch  0, batch   420 | loss: 2.9874983MixupTrain:  epoch  0, batch   421 | loss: 2.7328351MixupTrain:  epoch  0, batch   422 | loss: 2.9185543MixupTrain:  epoch  0, batch   423 | loss: 2.8733811MixupTrain:  epoch  0, batch   424 | loss: 2.6993036MixupTrain:  epoch  0, batch   425 | loss: 2.7297778MixupTrain:  epoch  0, batch   426 | loss: 2.4858539MixupTrain:  epoch  0, batch   429 | loss: 2.4020214MixupTrain:  epoch  0, batch   430 | loss: 2.2514510MixupTrain:  epoch  0, batch   431 | loss: 2.3057225MixupTrain:  epoch  0, batch   432 | loss: 2.6073284MixupTrain:  epoch  0, batch   433 | loss: 3.0387216MixupTrain:  epoch  0, batch   434 | loss: 2.4093990MixupTrain:  epoch  0, batch   435 | loss: 2.3781483MixupTrain:  epoch  0, batch   436 | loss: 2.5404813MixupTrain:  epoch  0, batch   437 | loss: 2.9380560MixupTrain:  epoch  0, batch   438 | loss: 2.5920067MixupTrain:  epoch  0, batch   439 | loss: 2.5020065MixupTrain:  epoch  0, batch   440 | loss: 2.6407137MixupTrain:  epoch  0, batch   441 | loss: 2.8112810MixupTrain:  epoch  0, batch   442 | loss: 2.7361038MixupTrain:  epoch  0, batch   443 | loss: 2.9358177MixupTrain:  epoch  0, batch   444 | loss: 2.3247030MixupTrain:  epoch  0, batch   445 | loss: 3.2501628MixupTrain:  epoch  0, batch   446 | loss: 2.8937712MixupTrain:  epoch  0, batch   447 | loss: 2.7703066MixupTrain:  epoch  0, batch   448 | loss: 2.5843341MixupTrain:  epoch  0, batch   449 | loss: 2.7838275MixupTrain:  epoch  0, batch   450 | loss: 3.1713581MixupTrain:  epoch  0, batch   451 | loss: 2.9480081MixupTrain:  epoch  0, batch   452 | loss: 2.4063962MixupTrain:  epoch  0, batch   453 | loss: 3.1246281MixupTrain:  epoch  0, batch   455 | loss: 2.9287796MixupTrain:  epoch  0, batch   456 | loss: 2.5998080MixupTrain:  epoch  0, batch   457 | loss: 2.6927905MixupTrain:  epoch  0, batch   458 | loss: 2.3043771MixupTrain:  epoch  0, batch   459 | loss: 2.9988251MixupTrain:  epoch  0, batch   460 | loss: 3.0999961MixupTrain:  epoch  0, batch   461 | loss: 2.4957080MixupTrain:  epoch  0, batch   462 | loss: 2.6131194MixupTrain:  epoch  0, batch   464 | loss: 2.4052658MixupTrain:  epoch  0, batch   465 | loss: 2.6590090MixupTrain:  epoch  0, batch   466 | loss: 2.9168675MixupTrain:  epoch  0, batch   467 | loss: 3.2480135MixupTrain:  epoch  0, batch   469 | loss: 2.6904848MixupTrain:  epoch  0, batch   470 | loss: 2.6907215MixupTrain:  epoch  0, batch   471 | loss: 2.3636937MixupTrain:  epoch  0, batch   472 | loss: 2.6599853MixupTrain:  epoch  0, batch   473 | loss: 2.5380692MixupTrain:  epoch  0, batch   475 | loss: 2.7173243MixupTrain:  epoch  0, batch   476 | loss: 3.1605091MixupTrain:  epoch  0, batch   477 | loss: 2.3394678MixupTrain:  epoch  0, batch   478 | loss: 2.3466678MixupTrain:  epoch  0, batch   479 | loss: 2.7914236MixupTrain:  epoch  0, batch   480 | loss: 2.9221215MixupTrain:  epoch  0, batch   481 | loss: 2.2665541MixupTrain:  epoch  0, batch   482 | loss: 2.6149383MixupTrain:  epoch  0, batch   483 | loss: 2.4407375MixupTrain:  epoch  0, batch   484 | loss: 2.4600353MixupTrain:  epoch  0, batch   485 | loss: 2.7152929MixupTrain:  epoch  0, batch   486 | loss: 2.2181756MixupTrain:  epoch  0, batch   487 | loss: 2.5201259MixupTrain:  epoch  0, batch   488 | loss: 2.8084621MixupTrain:  epoch  0, batch   489 | loss: 2.4992120MixupTrain:  epoch  0, batch   490 | loss: 2.4357421MixupTrain:  epoch  0, batch   491 | loss: 2.4290421MixupTrain:  epoch  0, batch   492 | loss: 2.2293932MixupTrain:  epoch  0, batch   493 | loss: 3.0469995MixupTrain:  epoch  0, batch   494 | loss: 3.5496449MixupTrain:  epoch  0, batch   495 | loss: 2.5748711MixupTrain:  epoch  0, batch   496 | loss: 2.5940943MixupTrain:  epoch  0, batch   497 | loss: 2.7486801MixupTrain:  epoch  0, batch   498 | loss: 2.3687747MixupTrain:  epoch  0, batch   500 | loss: 2.3586106MixupTrain:  epoch  0, batch   501 | loss: 2.7294204MixupTrain:  epoch  0, batch   502 | loss: 2.5550127MixupTrain:  epoch  0, batch   504 | loss: 2.7314456MixupTrain:  epoch  0, batch   505 | loss: 3.1761346MixupTrain:  epoch  0, batch   506 | loss: 2.8101954MixupTrain:  epoch  0, batch   507 | loss: 2.7404168MixupTrain:  epoch  0, batch   508 | loss: 2.7514355MixupTrain:  epoch  0, batch   509 | loss: 2.7205725MixupTrain:  epoch  0, batch   510 | loss: 2.3301704MixupTrain:  epoch  0, batch   511 | loss: 2.8915615MixupTrain:  epoch  0, batch   512 | loss: 2.5305138MixupTrain:  epoch  0, batch   513 | loss: 3.1038101MixupTrain:  epoch  0, batch   514 | loss: 2.6961298MixupTrain:  epoch  0, batch   515 | loss: 2.6563966MixupTrain:  epoch  0, batch   516 | loss: 2.5835102MixupTrain:  epoch  0, batch   518 | loss: 2.6142867MixupTrain:  epoch  0, batch   519 | loss: 2.5298274MixupTrain:  epoch  0, batch   520 | loss: 2.6225727MixupTrain:  epoch  0, batch   521 | loss: 2.9921827MixupTrain:  epoch  0, batch   522 | loss: 2.6909466MixupTrain:  epoch  0, batch   523 | loss: 2.4815483MixupTrain:  epoch  0, batch   524 | loss: 2.5516517MixupTrain:  epoch  0, batch   525 | loss: 2.7804799MixupTrain:  epoch  0, batch   526 | loss: 2.8554602MixupTrain:  epoch  0, batch   527 | loss: 3.0336223MixupTrain:  epoch  0, batch   528 | loss: 2.5498240MixupTrain:  epoch  0, batch   529 | loss: 2.4040084MixupTrain:  epoch  0, batch   530 | loss: 2.8044040MixupTrain:  epoch  0, batch   531 | loss: 2.8799801MixupTrain:  epoch  0, batch   532 | loss: 2.5919838MixupTrain:  epoch  0, batch   533 | loss: 2.5987029MixupTrain:  epoch  0, batch   534 | loss: 2.7821317MixupTrain:  epoch  0, batch   535 | loss: 2.7028928MixupTrain:  epoch  0, batch   537 | loss: 2.2786903MixupTrain:  epoch  0, batch   538 | loss: 2.8327999MixupTrain:  epoch  0, batch   539 | loss: 2.6207948MixupTrain:  epoch  0, batch   540 | loss: 2.4894469MixupTrain:  epoch  0, batch   541 | loss: 2.3868878MixupTrain:  epoch  0, batch   542 | loss: 2.1091015MixupTrain:  epoch  0, batch   543 | loss: 2.5128951MixupTrain:  epoch  0, batch   544 | loss: 2.0954218MixupTrain:  epoch  0, batch   545 | loss: 2.5217996MixupTrain:  epoch  0, batch   547 | loss: 2.4518495MixupTrain:  epoch  0, batch   548 | loss: 2.5920730MixupTrain:  epoch  0, batch   549 | loss: 2.5860796MixupTrain:  epoch  0, batch   550 | loss: 2.5933027MixupTrain:  epoch  0, batch   551 | loss: 2.9044638MixupTrain:  epoch  0, batch   552 | loss: 2.3413913MixupTrain:  epoch  0, batch   553 | loss: 2.0312541MixupTrain:  epoch  0, batch   554 | loss: 2.7965715MixupTrain:  epoch  0, batch   555 | loss: 2.6012702MixupTrain:  epoch  0, batch   556 | loss: 2.2312164MixupTrain:  epoch  0, batch   557 | loss: 2.4267688MixupTrain:  epoch  0, batch   558 | loss: 3.2980535MixupTrain:  epoch  0, batch   559 | loss: 2.6828403MixupTrain:  epoch  0, batch   560 | loss: 2.8680751MixupTrain:  epoch  0, batch   561 | loss: 2.7193828MixupTrain:  epoch  0, batch   562 | loss: 2.6146135MixupTrain:  epoch  0, batch   563 | loss: 2.7914886MixupTrain:  epoch  0, batch   564 | loss: 2.4285691MixupTrain:  epoch  0, batch   565 | loss: 2.5028644MixupTrain:  epoch  0, batch   566 | loss: 2.1895239MixupTrain:  epoch  0, batch   567 | loss: 2.3885157MixupTrain:  epoch  0, batch   568 | loss: 2.5646486MixupTrain:  epoch  0, batch   569 | loss: 2.7798214MixupTrain:  epoch  0, batch   570 | loss: 2.5949564MixupTrain:  epoch  0, batch   571 | loss: 2.2095728MixupTrain:  epoch  0, batch   572 | loss: 2.8049285MixupTrain:  epoch  0, batch   573 | loss: 2.3744755MixupTrain:  epoch  0, batch   574 | loss: 2.6028264MixupTrain:  epoch  0, batch   575 | loss: 2.6885748MixupTrain:  epoch  0, batch   576 | loss: 2.8807724MixupTrain:  epoch  0, batch   577 | loss: 2.6335206MixupTrain:  epoch  0, batch   578 | loss: 2.7204561MixupTrain:  epoch  0, batch   579 | loss: 2.4401450MixupTrain:  epoch  0, batch   581 | loss: 2.5208702MixupTrain:  epoch  0, batch   582 | loss: 2.9379821MixupTrain:  epoch  0, batch   583 | loss: 2.8514152MixupTrain:  epoch  0, batch   584 | loss: 2.7445145MixupTrain:  epoch  0, batch   585 | loss: 2.5076065MixupTrain:  epoch  0, batch   587 | loss: 2.5008438MixupTrain:  epoch  0, batch   588 | loss: 2.6178083MixupTrain:  epoch  0, batch   589 | loss: 2.6180260MixupTrain:  epoch  0, batch   590 | loss: 2.3037105MixupTrain:  epoch  0, batch   591 | loss: 3.0685425MixupTrain:  epoch  0, batch   592 | loss: 2.8743582MixupTrain:  epoch  0, batch   593 | loss: 2.5636764MixupTrain:  epoch  0, batch   594 | loss: 2.6663361MixupTrain:  epoch  0, batch   595 | loss: 3.0174708MixupTrain:  epoch  0, batch   596 | loss: 2.5046587MixupTrain:  epoch  0, batch   597 | loss: 2.3439198MixupTrain:  epoch  0, batch   598 | loss: 2.4430676MixupTrain:  epoch  0, batch   599 | loss: 2.8086677MixupTrain:  epoch  0, batch   600 | loss: 2.7986846MixupTrain:  epoch  0, batch   601 | loss: 2.4818358MixupTrain:  epoch  0, batch   602 | loss: 2.6016417MixupTrain:  epoch  0, batch   603 | loss: 3.0612864MixupTrain:  epoch  0, batch   604 | loss: 2.7878156MixupTrain:  epoch  0, batch   605 | loss: 2.8295071MixupTrain:  epoch  0, batch   606 | loss: 2.7206285MixupTrain:  epoch  0, batch   607 | loss: 3.1789589MixupTrain:  epoch  0, batch   608 | loss: 2.4425280MixupTrain:  epoch  0, batch   609 | loss: 2.4260974MixupTrain:  epoch  0, batch   610 | loss: 2.4592214MixupTrain:  epoch  0, batch   611 | loss: 2.3419194MixupTrain:  epoch  0, batch   612 | loss: 2.5426216MixupTrain:  epoch  0, batch   613 | loss: 2.1509590MixupTrain:  epoch  0, batch   614 | loss: 2.8370183MixupTrain:  epoch  0, batch   615 | loss: 2.6019635MixupTrain:  epoch  0, batch   617 | loss: 2.3815908MixupTrain:  epoch  0, batch   618 | loss: 3.0761414MixupTrain:  epoch  0, batch   619 | loss: 2.2769775MixupTrain:  epoch  0, batch   620 | loss: 2.4733558MixupTrain:  epoch  0, batch   621 | loss: 2.7832665MixupTrain:  epoch  0, batch   622 | loss: 2.4253154MixupTrain:  epoch  0, batch   623 | loss: 3.0495362MixupTrain:  epoch  0, batch   624 | loss: 2.7597654MixupTrain:  epoch  0, batch   625 | loss: 2.7255099MixupTrain:  epoch  0, batch   626 | loss: 2.0735753MixupTrain:  epoch  0, batch   627 | loss: 2.3507576MixupTrain:  epoch  0, batch   628 | loss: 2.7444234MixupTrain:  epoch  0, batch   629 | loss: 2.2520263MixupTrain:  epoch  0, batch   631 | loss: 2.7678008MixupTrain:  epoch  0, batch   632 | loss: 2.6088824MixupTrain:  epoch  0, batch   633 | loss: 2.7680535MixupTrain:  epoch  0, batch   635 | loss: 2.9934282MixupTrain:  epoch  0, batch   636 | loss: 2.9093876MixupTrain:  epoch  0, batch   637 | loss: 2.4878874MixupTrain:  epoch  0, batch   638 | loss: 2.3659277MixupTrain:  epoch  0, batch   639 | loss: 2.6715755MixupTrain:  epoch  0, batch   641 | loss: 3.0103011MixupTrain:  epoch  0, batch   642 | loss: 2.2880898MixupTrain:  epoch  0, batch   643 | loss: 2.4063866MixupTrain:  epoch  0, batch   644 | loss: 2.9164200MixupTrain:  epoch  0, batch   645 | loss: 2.4833276MixupTrain:  epoch  0, batch   646 | loss: 2.3511188MixupTrain:  epoch  0, batch   647 | loss: 2.4817734MixupTrain:  epoch  0, batch   648 | loss: 2.1061180MixupTrain:  epoch  0, batch   649 | loss: 2.4212801MixupTrain:  epoch  0, batch   650 | loss: 2.2814770MixupTrain:  epoch  0, batch   651 | loss: 2.3033814MixupTrain:  epoch  0, batch   652 | loss: 3.3054514MixupTrain:  epoch  0, batch   653 | loss: 2.4573278MixupTrain:  epoch  0, batch   654 | loss: 2.3962584MixupTrain:  epoch  0, batch   655 | loss: 2.6731498MixupTrain:  epoch  0, batch   656 | loss: 2.2519946MixupTrain:  epoch  0, batch   657 | loss: 2.5380931MixupTrain:  epoch  0, batch   659 | loss: 2.4076834MixupTrain:  epoch  0, batch   660 | loss: 2.5581398MixupTrain:  epoch  0, batch   661 | loss: 2.3814173MixupTrain:  epoch  0, batch   663 | loss: 2.4953198MixupTrain:  epoch  0, batch   664 | loss: 2.2763298MixupTrain:  epoch  0, batch   665 | loss: 2.2493100MixupTrain:  epoch  0, batch   666 | loss: 2.1020527MixupTrain:  epoch  0, batch   667 | loss: 2.9861794MixupTrain:  epoch  0, batch   668 | loss: 2.1094944MixupTrain:  epoch  0, batch   669 | loss: 2.5922279MixupTrain:  epoch  0, batch   670 | loss: 2.6305387MixupTrain:  epoch  0, batch   671 | loss: 2.6341467MixupTrain:  epoch  0, batch   672 | loss: 3.0349071MixupTrain:  epoch  0, batch   673 | loss: 2.8903863MixupTrain:  epoch  0, batch   674 | loss: 2.5921512MixupTrain:  epoch  0, batch   676 | loss: 3.1920924MixupTrain:  epoch  0, batch   677 | loss: 2.5923033MixupTrain:  epoch  0, batch   678 | loss: 2.6028640MixupTrain:  epoch  0, batch   679 | loss: 2.4639220MixupTrain:  epoch  0, batch   680 | loss: 2.5395570MixupTrain:  epoch  0, batch   682 | loss: 3.1094692MixupTrain:  epoch  0, batch   683 | loss: 2.5049980MixupTrain:  epoch  0, batch   684 | loss: 2.4772542MixupTrain:  epoch  0, batch   685 | loss: 2.4426966MixupTrain:  epoch  0, batch   686 | loss: 2.5549183MixupTrain:  epoch  0, batch   687 | loss: 2.5852885MixupTrain:  epoch  0, batch   688 | loss: 2.2038422MixupTrain:  epoch  0, batch   689 | loss: 2.7757442MixupTrain:  epoch  0, batch   690 | loss: 2.0892293MixupTrain:  epoch  0, batch   692 | loss: 2.2960880MixupTrain:  epoch  0, batch   694 | loss: 3.2235515MixupTrain:  epoch  0, batch   695 | loss: 2.5159771MixupTrain:  epoch  0, batch   696 | loss: 2.6543262MixupTrain:  epoch  0, batch   697 | loss: 2.4677219MixupTrain:  epoch  0, batch   698 | loss: 3.0007682MixupTrain:  epoch  0, batch   699 | loss: 2.5941689MixupTrain:  epoch  0, batch   700 | loss: 2.8213248MixupTrain:  epoch  0, batch   701 | loss: 2.5156100MixupTrain:  epoch  0, batch   703 | loss: 2.3773937MixupTrain:  epoch  0, batch   704 | loss: 2.7653337MixupTrain:  epoch  0, batch   705 | loss: 3.0149434MixupTrain:  epoch  0, batch   706 | loss: 2.8264563MixupTrain:  epoch  0, batch   707 | loss: 2.3087745MixupTrain:  epoch  0, batch   708 | loss: 2.2331092MixupTrain:  epoch  0, batch   709 | loss: 2.2547851MixupTrain:  epoch  0, batch   710 | loss: 2.7114916MixupTrain:  epoch  0, batch   711 | loss: 2.2381375MixupTrain:  epoch  0, batch   712 | loss: 2.3991189MixupTrain:  epoch  0, batch   713 | loss: 2.5651546MixupTrain:  epoch  0, batch   714 | loss: 2.8100367MixupTrain:  epoch  0, batch   715 | loss: 2.6429839MixupTrain:  epoch  0, batch   716 | loss: 2.9862354MixupTrain:  epoch  0, batch   717 | loss: 2.4300008MixupTrain:  epoch  0, batch   718 | loss: 2.1560807MixupTrain:  epoch  0, batch   719 | loss: 2.7209454MixupTrain:  epoch  0, batch   720 | loss: 2.8014958MixupTrain:  epoch  0, batch   721 | loss: 2.9575799MixupTrain:  epoch  0, batch   722 | loss: 2.3679805MixupTrain:  epoch  0, batch   723 | loss: 2.4613366MixupTrain:  epoch  0, batch   725 | loss: 2.1976013MixupTrain:  epoch  0, batch   726 | loss: 2.4386637MixupTrain:  epoch  0, batch   727 | loss: 2.3575206MixupTrain:  epoch  0, batch   728 | loss: 2.6680083MixupTrain:  epoch  0, batch   729 | loss: 2.7009449MixupTrain:  epoch  0, batch   730 | loss: 2.8929749MixupTrain:  epoch  0, batch   731 | loss: 2.5965858MixupTrain:  epoch  0, batch   733 | loss: 2.3822613MixupTrain:  epoch  0, batch   734 | loss: 2.8057468MixupTrain:  epoch  0, batch   735 | loss: 2.5815420MixupTrain:  epoch  0, batch   736 | loss: 2.5145588MixupTrain:  epoch  0, batch   737 | loss: 2.5543442MixupTrain:  epoch  0, batch   739 | loss: 2.5338111MixupTrain:  epoch  0, batch   740 | loss: 3.0792913MixupTrain:  epoch  0, batch   741 | loss: 2.6374824MixupTrain:  epoch  0, batch   742 | loss: 2.4585731MixupTrain:  epoch  0, batch   743 | loss: 2.5250566MixupTrain:  epoch  0, batch   744 | loss: 2.6092830MixupTrain:  epoch  0, batch   745 | loss: 2.5719218MixupTrain:  epoch  0, batch   746 | loss: 2.4579377MixupTrain:  epoch  0, batch   747 | loss: 2.7908907MixupTrain:  epoch  0, batch   748 | loss: 3.0905194MixupTrain:  epoch  0, batch   749 | loss: 2.6294136MixupTrain:  epoch  0, batch   751 | loss: 2.7809112MixupTrain:  epoch  0, batch   752 | loss: 2.8993421MixupTrain:  epoch  0, batch   753 | loss: 2.6998425MixupTrain:  epoch  0, batch   754 | loss: 2.6600499MixupTrain:  epoch  0, batch   755 | loss: 2.7254596MixupTrain:  epoch  0, batch   756 | loss: 2.5804083MixupTrain:  epoch  0, batch   757 | loss: 2.9685984MixupTrain:  epoch  0, batch   758 | loss: 2.5369191MixupTrain:  epoch  0, batch   759 | loss: 2.5657697MixupTrain:  epoch  0, batch   760 | loss: 2.5799925MixupTrain:  epoch  0, batch   762 | loss: 2.5119824MixupTrain:  epoch  0, batch   764 | loss: 2.8537798MixupTrain:  epoch  0, batch   765 | loss: 3.0608425MixupTrain:  epoch  0, batch   766 | loss: 2.6160917MixupTrain:  epoch  0, batch   767 | loss: 2.3942077MixupTrain:  epoch  0, batch   768 | loss: 2.4073708MixupTrain:  epoch  0, batch   769 | loss: 2.6511979MixupTrain:  epoch  0, batch   771 | loss: 2.4403062MixupTrain:  epoch  0, batch   773 | loss: 2.6692247MixupTrain:  epoch  0, batch   774 | loss: 2.7289279MixupTrain:  epoch  0, batch   775 | loss: 2.1548016MixupTrain:  epoch  0, batch   776 | loss: 2.2852802MixupTrain:  epoch  0, batch   777 | loss: 2.3013062MixupTrain:  epoch  0, batch   778 | loss: 2.6678343MixupTrain:  epoch  0, batch   780 | loss: 2.3917317MixupTrain:  epoch  0, batch   782 | loss: 2.7442708MixupTrain:  epoch  0, batch   783 | loss: 2.4579680MixupTrain:  epoch  0, batch   784 | loss: 2.6372068MixupTrain:  epoch  0, batch   785 | loss: 2.4024165MixupTrain:  epoch  0, batch   786 | loss: 2.4288301MixupTrain:  epoch  0, batch   787 | loss: 2.5966122MixupTrain:  epoch  0, batch   788 | loss: 2.7861481MixupTrain:  epoch  0, batch   789 | loss: 2.1414366MixupTrain:  epoch  0, batch   790 | loss: 2.4945388MixupTrain:  epoch  0, batch   791 | loss: 2.5794353MixupTrain:  epoch  0, batch   792 | loss: 2.4889398MixupTrain:  epoch  0, batch   794 | loss: 2.4517586MixupTrain:  epoch  0, batch   795 | loss: 2.5066392MixupTrain:  epoch  0, batch   796 | loss: 2.4674518MixupTrain:  epoch  0, batch   797 | loss: 2.7983894MixupTrain:  epoch  0, batch   798 | loss: 2.7908621MixupTrain:  epoch  0, batch   799 | loss: 2.5132902MixupTrain:  epoch  0, batch   800 | loss: 2.8131466MixupTrain:  epoch  0, batch   801 | loss: 2.4073956MixupTrain:  epoch  0, batch   802 | loss: 2.6392612MixupTrain:  epoch  0, batch   803 | loss: 2.6920629MixupTrain:  epoch  0, batch   804 | loss: 2.4873171MixupTrain:  epoch  0, batch   805 | loss: 2.6925869MixupTrain:  epoch  0, batch   806 | loss: 2.7583609MixupTrain:  epoch  0, batch   807 | loss: 2.5776558MixupTrain:  epoch  0, batch   808 | loss: 2.6608334MixupTrain:  epoch  0, batch   809 | loss: 2.7269926MixupTrain:  epoch  0, batch   810 | loss: 3.0044849MixupTrain:  epoch  0, batch   812 | loss: 2.8645282MixupTrain:  epoch  0, batch   813 | loss: 2.8461068MixupTrain:  epoch  0, batch   814 | loss: 2.7089813MixupTrain:  epoch  0, batch   815 | loss: 2.9999650MixupTrain:  epoch  0, batch   816 | loss: 2.6606221MixupTrain:  epoch  0, batch   817 | loss: 2.6724362MixupTrain:  epoch  0, batch   818 | loss: 2.8962648MixupTrain:  epoch  0, batch   819 | loss: 2.3986695MixupTrain:  epoch  0, batch   820 | loss: 2.5792830MixupTrain:  epoch  0, batch   821 | loss: 2.7126412MixupTrain:  epoch  0, batch   822 | loss: 2.6768038MixupTrain:  epoch  0, batch   823 | loss: 2.7223921MixupTrain:  epoch  0, batch   824 | loss: 2.9449389MixupTrain:  epoch  0, batch   825 | loss: 2.7848167MixupTrain:  epoch  0, batch   826 | loss: 2.4593327MixupTrain:  epoch  0, batch   827 | loss: 2.6524830MixupTrain:  epoch  0, batch   828 | loss: 2.5935779MixupTrain:  epoch  0, batch   830 | loss: 2.5429573MixupTrain:  epoch  0, batch   831 | loss: 2.4993911MixupTrain:  epoch  0, batch   833 | loss: 2.7508202MixupTrain:  epoch  0, batch   834 | loss: 2.5470753MixupTrain:  epoch  0, batch   835 | loss: 2.7777343MixupTrain:  epoch  0, batch   836 | loss: 2.4748979MixupTrain:  epoch  0, batch   837 | loss: 2.7466559MixupTrain:  epoch  0, batch   838 | loss: 2.6159775MixupTrain:  epoch  0, batch   839 | loss: 2.5689669MixupTrain:  epoch  0, batch   840 | loss: 2.5078487MixupTrain:  epoch  0, batch   841 | loss: 2.8089774MixupTrain:  epoch  0, batch   842 | loss: 2.3540106MixupTrain:  epoch  0, batch   843 | loss: 2.4648597MixupTrain:  epoch  0, batch   844 | loss: 2.3300219MixupTrain:  epoch  0, batch   845 | loss: 2.7787902MixupTrain:  epoch  0, batch   846 | loss: 2.3228662MixupTrain:  epoch  0, batch   848 | loss: 2.8916140MixupTrain:  epoch  0, batch   849 | loss: 2.2258267MixupTrain:  epoch  0, batch   850 | loss: 2.5382125MixupTrain:  epoch  0, batch   851 | loss: 2.4388456MixupTrain:  epoch  0, batch   853 | loss: 2.3587599MixupTrain:  epoch  0, batch   854 | loss: 2.6519694MixupTrain:  epoch  0, batch   856 | loss: 2.9545143MixupTrain:  epoch  0, batch   857 | loss: 2.4926801MixupTrain:  epoch  0, batch   859 | loss: 2.2625103MixupTrain:  epoch  0, batch   860 | loss: 2.8183143MixupTrain:  epoch  0, batch   861 | loss: 2.6277893MixupTrain:  epoch  0, batch   862 | loss: 2.5869365MixupTrain:  epoch  0, batch   863 | loss: 2.5553894MixupTrain:  epoch  0, batch   864 | loss: 2.4818339MixupTrain:  epoch  0, batch   865 | loss: 2.8460407MixupTrain:  epoch  0, batch   866 | loss: 2.5480533MixupTrain:  epoch  0, batch   867 | loss: 2.4309402MixupTrain:  epoch  0, batch   868 | loss: 2.5251915MixupTrain:  epoch  0, batch   869 | loss: 2.2808173MixupTrain:  epoch  0, batch   870 | loss: 2.4975362MixupTrain:  epoch  0, batch   871 | loss: 2.4437990MixupTrain:  epoch  0, batch   872 | loss: 3.1305146MixupTrain:  epoch  0, batch   874 | loss: 2.4880018MixupTrain:  epoch  0, batch   875 | loss: 2.7074649MixupTrain:  epoch  0, batch   876 | loss: 2.7974868MixupTrain:  epoch  0, batch   877 | loss: 2.6371040MixupTrain:  epoch  0, batch   878 | loss: 2.5088260MixupTrain:  epoch  0, batch   879 | loss: 2.6137938MixupTrain:  epoch  0, batch   880 | loss: 2.3216362MixupTrain:  epoch  0, batch   881 | loss: 2.6339746MixupTrain:  epoch  0, batch   882 | loss: 2.2497921MixupTrain:  epoch  0, batch   883 | loss: 2.4915011MixupTrain:  epoch  0, batch   884 | loss: 2.4270015MixupTrain:  epoch  0, batch   885 | loss: 2.2319212MixupTrain:  epoch  0, batch   886 | loss: 2.8134034MixupTrain:  epoch  0, batch   887 | loss: 2.7726996MixupTrain:  epoch  0, batch   888 | loss: 2.7515004MixupTrain:  epoch  0, batch   889 | loss: 2.4052110MixupTrain:  epoch  0, batch   891 | loss: 2.8482897MixupTrain:  epoch  0, batch   892 | loss: 2.6682754MixupTrain:  epoch  0, batch   893 | loss: 2.3954990MixupTrain:  epoch  0, batch   894 | loss: 2.5145988MixupTrain:  epoch  0, batch   895 | loss: 3.0048041MixupTrain:  epoch  0, batch   896 | loss: 2.4942813MixupTrain:  epoch  0, batch   897 | loss: 2.8074641MixupTrain:  epoch  0, batch   899 | loss: 2.0622640MixupTrain:  epoch  0, batch   900 | loss: 2.3210373MixupTrain:  epoch  0, batch   901 | loss: 2.1642818MixupTrain:  epoch  0, batch   902 | loss: 2.6366405MixupTrain:  epoch  0, batch   904 | loss: 2.3091617MixupTrain:  epoch  0, batch   906 | loss: 3.0439882MixupTrain:  epoch  0, batch   907 | loss: 2.2627857MixupTrain:  epoch  0, batch   908 | loss: 2.1135545MixupTrain:  epoch  0, batch   909 | loss: 2.4181221MixupTrain:  epoch  0, batch   910 | loss: 2.3728580MixupTrain:  epoch  0, batch   912 | loss: 2.5372362MixupTrain:  epoch  0, batch   913 | loss: 2.5710301MixupTrain:  epoch  0, batch   914 | loss: 2.5523708MixupTrain:  epoch  0, batch   915 | loss: 2.2230554MixupTrain:  epoch  0, batch   916 | loss: 3.0937023MixupTrain:  epoch  0, batch   917 | loss: 2.5781338MixupTrain:  epoch  0, batch   918 | loss: 2.9341216MixupTrain:  epoch  0, batch   919 | loss: 2.5989742MixupTrain:  epoch  0, batch   920 | loss: 2.9658322MixupTrain:  epoch  0, batch   921 | loss: 2.4860225MixupTrain:  epoch  0, batch   922 | loss: 2.5487084MixupTrain:  epoch  0, batch   923 | loss: 2.4818397MixupTrain:  epoch  0, batch   924 | loss: 2.5013356MixupTrain:  epoch  0, batch   925 | loss: 2.3781629MixupTrain:  epoch  0, batch   926 | loss: 2.5116467MixupTrain:  epoch  0, batch   927 | loss: 2.3142612MixupTrain:  epoch  0, batch   928 | loss: 2.2970881MixupTrain:  epoch  0, batch   929 | loss: 2.2685864MixupTrain:  epoch  0, batch   930 | loss: 2.3885479MixupTrain:  epoch  0, batch   931 | loss: 2.7671559MixupTrain:  epoch  0, batch   933 | loss: 2.2579689MixupTrain:  epoch  0, batch   934 | loss: 2.9418135MixupTrain:  epoch  0, batch   935 | loss: 2.6075053MixupTrain:  epoch  0, batch   936 | loss: 2.8270648MixupTrain:  epoch  0, batch   937 | loss: 2.4522417MixupTrain:  epoch  0, batch   939 | loss: 2.6313210MixupTrain:  epoch  0, batch   941 | loss: 2.5530627MixupTrain:  epoch  0, batch   942 | loss: 2.5881925MixupTrain:  epoch  0, batch   943 | loss: 2.7361083MixupTrain:  epoch  0, batch   944 | loss: 2.5704141MixupTrain:  epoch  0, batch   945 | loss: 2.4286876MixupTrain:  epoch  0, batch   946 | loss: 2.5122354MixupTrain:  epoch  0, batch   947 | loss: 2.9121408MixupTrain:  epoch  0, batch   948 | loss: 2.3413551MixupTrain:  epoch  0, batch   949 | loss: 2.4124851MixupTrain:  epoch  0, batch   950 | loss: 2.3793168MixupTrain:  epoch  0, batch   952 | loss: 2.5501895MixupTrain:  epoch  0, batch   953 | loss: 2.5382481MixupTrain:  epoch  0, batch   954 | loss: 2.4812021MixupTrain:  epoch  0, batch   955 | loss: 2.8201013MixupTrain:  epoch  0, batch   957 | loss: 2.4274592MixupTrain:  epoch  0, batch   958 | loss: 2.9264548MixupTrain:  epoch  0, batch   959 | loss: 2.5154014MixupTrain:  epoch  0, batch   960 | loss: 2.5179496MixupTrain:  epoch  0, batch   961 | loss: 2.3952785MixupTrain:  epoch  0, batch   962 | loss: 2.5638988MixupTrain:  epoch  0, batch   963 | loss: 2.4789021MixupTrain:  epoch  0, batch   964 | loss: 2.6007614MixupTrain:  epoch  0, batch   965 | loss: 2.4497156MixupTrain:  epoch  0, batch   966 | loss: 2.5333259MixupTrain:  epoch  0, batch   967 | loss: 2.2175937MixupTrain:  epoch  0, batch   968 | loss: 2.7678654MixupTrain:  epoch  0, batch   969 | loss: 2.2421417MixupTrain:  epoch  0, batch   970 | loss: 2.4927721MixupTrain:  epoch  0, batch   971 | loss: 2.9843426MixupTrain:  epoch  0, batch   972 | loss: 3.1938095MixupTrain:  epoch  0, batch   973 | loss: 2.9264827MixupTrain:  epoch  0, batch   975 | loss: 2.6390164MixupTrain:  epoch  0, batch   976 | loss: 2.4139073MixupTrain:  epoch  0, batch   977 | loss: 2.8870497MixupTrain:  epoch  0, batch   978 | loss: 2.2927613MixupTrain:  epoch  0, batch   979 | loss: 2.4483209MixupTrain:  epoch  0, batch   980 | loss: 2.2434855MixupTrain:  epoch  0, batch   982 | loss: 2.3806581MixupTrain:  epoch  0, batch   983 | loss: 2.8609951MixupTrain:  epoch  0, batch   984 | loss: 2.9986458MixupTrain:  epoch  0, batch   985 | loss: 2.7737880MixupTrain:  epoch  0, batch   986 | loss: 2.5053248MixupTrain:  epoch  0, batch   987 | loss: 2.2490046MixupTrain:  epoch  0, batch   988 | loss: 2.8587344MixupTrain:  epoch  0, batch   989 | loss: 2.5928049MixupTrain:  epoch  0, batch   992 | loss: 2.1073406MixupTrain:  epoch  0, batch   993 | loss: 2.7398365MixupTrain:  epoch  0, batch   994 | loss: 2.1203599MixupTrain:  epoch  0, batch   995 | loss: 2.6216345MixupTrain:  epoch  0, batch   996 | loss: 2.5988135MixupTrain:  epoch  0, batch   997 | loss: 2.7610869MixupTrain:  epoch  0, batch   998 | loss: 2.5300188MixupTrain:  epoch  0, batch  1000 | loss: 2.0803833MixupTrain:  epoch  0, batch  1001 | loss: 2.5122237MixupTrain:  epoch  0, batch  1003 | loss: 2.1397624MixupTrain:  epoch  0, batch  1004 | loss: 2.5447943MixupTrain:  epoch  0, batch  1006 | loss: 2.3274903MixupTrain:  epoch  0, batch  1007 | loss: 2.1017857MixupTrain:  epoch  0, batch  1008 | loss: 2.7915473MixupTrain:  epoch  0, batch  1009 | loss: 2.4270236MixupTrain:  epoch  0, batch  1010 | loss: 2.6546230MixupTrain:  epoch  0, batch  1011 | loss: 2.7198029MixupTrain:  epoch  0, batch  1012 | loss: 2.8971090MixupTrain:  epoch  0, batch  1013 | loss: 2.3906257MixupTrain:  epoch  0, batch  1014 | loss: 2.5134871MixupTrain:  epoch  0, batch  1015 | loss: 2.6588469MixupTrain:  epoch  0, batch  1017 | loss: 2.4408488MixupTrain:  epoch  0, batch  1018 | loss: 2.4624195MixupTrain:  epoch  0, batch  1019 | loss: 2.7868514MixupTrain:  epoch  0, batch  1021 | loss: 2.5813084MixupTrain:  epoch  0, batch  1022 | loss: 2.3356709MixupTrain:  epoch  0, batch  1023 | loss: 2.4321189MixupTrain:  epoch  0, batch  1024 | loss: 2.6009598MixupTrain:  epoch  0, batch  1025 | loss: 2.4427361MixupTrain:  epoch  0, batch  1026 | loss: 2.5119159MixupTrain:  epoch  0, batch  1027 | loss: 2.6689715MixupTrain:  epoch  0, batch  1028 | loss: 2.4148231MixupTrain:  epoch  0, batch  1029 | loss: 2.4330125MixupTrain:  epoch  0, batch  1030 | loss: 2.5828199MixupTrain:  epoch  0, batch  1031 | loss: 2.4739580MixupTrain:  epoch  0, batch  1032 | loss: 2.8399098MixupTrain:  epoch  0, batch  1033 | loss: 2.3300390MixupTrain:  epoch  0, batch  1035 | loss: 2.3026462MixupTrain:  epoch  0, batch  1036 | loss: 2.6542172MixupTrain:  epoch  0, batch  1037 | loss: 2.7088385MixupTrain:  epoch  0, batch  1038 | loss: 2.6649680MixupTrain:  epoch  0, batch  1039 | loss: 2.9937930MixupTrain:  epoch  0, batch  1040 | loss: 2.3219271MixupTrain:  epoch  0, batch  1041 | loss: 2.4963198MixupTrain:  epoch  0, batch  1042 | loss: 2.4866965MixupTrain:  epoch  0, batch  1043 | loss: 2.2179027MixupTrain:  epoch  0, batch  1045 | loss: 2.3502512MixupTrain:  epoch  0, batch  1047 | loss: 2.6869528MixupTrain:  epoch  0, batch  1048 | loss: 2.5971014MixupTrain:  epoch  0, batch  1049 | loss: 2.4185677MixupTrain:  epoch  0, batch  1050 | loss: 2.8038380MixupTrain:  epoch  0, batch  1051 | loss: 2.4116886MixupTrain:  epoch  0, batch  1052 | loss: 2.7347426MixupTrain:  epoch  0, batch  1053 | loss: 2.6714644MixupTrain:  epoch  0, batch  1054 | loss: 2.4816189MixupTrain:  epoch  0, batch  1055 | loss: 2.9599743MixupTrain:  epoch  0, batch  1056 | loss: 2.5367804MixupTrain:  epoch  0, batch  1057 | loss: 2.3435946MixupTrain:  epoch  0, batch  1058 | loss: 2.4650981MixupTrain:  epoch  0, batch  1059 | loss: 2.3118949MixupTrain:  epoch  0, batch  1060 | loss: 2.9144001MixupTrain:  epoch  0, batch  1061 | loss: 2.4018128MixupTrain:  epoch  0, batch  1062 | loss: 2.6220808MixupTrain:  epoch  0, batch  1063 | loss: 2.6380754MixupTrain:  epoch  0, batch  1065 | loss: 2.4116714MixupTrain:  epoch  0, batch  1066 | loss: 2.3717365MixupTrain:  epoch  0, batch  1067 | loss: 2.4971299MixupTrain:  epoch  0, batch  1068 | loss: 2.5692747MixupTrain:  epoch  0, batch  1069 | loss: 2.8784003MixupTrain:  epoch  0, batch  1070 | loss: 2.3261931MixupTrain:  epoch  0, batch  1071 | loss: 2.7176998MixupTrain:  epoch  0, batch  1074 | loss: 2.8193073MixupTrain:  epoch  0, batch  1075 | loss: 2.3340607MixupTrain:  epoch  0, batch  1076 | loss: 2.4684539MixupTrain:  epoch  0, batch  1078 | loss: 2.2411561MixupTrain:  epoch  0, batch  1079 | loss: 2.7679138MixupTrain:  epoch  0, batch  1080 | loss: 2.6199675MixupTrain:  epoch  0, batch  1081 | loss: 2.7006567MixupTrain:  epoch  0, batch  1082 | loss: 2.3371520MixupTrain:  epoch  0, batch  1083 | loss: 2.3321755MixupTrain:  epoch  0, batch  1084 | loss: 2.9575534MixupTrain:  epoch  0, batch  1085 | loss: 2.9126024MixupTrain:  epoch  0, batch  1086 | loss: 2.2138536MixupTrain:  epoch  0, batch  1087 | loss: 3.1291735MixupTrain:  epoch  0, batch  1088 | loss: 2.6171048MixupTrain:  epoch  0, batch  1089 | loss: 2.5262260MixupTrain:  epoch  0, batch  1090 | loss: 2.3309896MixupTrain:  epoch  0, batch  1091 | loss: 2.2128839MixupTrain:  epoch  0, batch  1092 | loss: 2.7818670MixupTrain:  epoch  0, batch  1093 | loss: 2.1686058MixupTrain:  epoch  0, batch  1094 | loss: 2.5777757MixupTrain:  epoch  0, batch  1095 | loss: 2.5465868MixupTrain:  epoch  0, batch  1096 | loss: 2.9348509MixupTrain:  epoch  0, batch  1097 | loss: 2.7769940MixupTrain:  epoch  0, batch  1098 | loss: 2.1543527MixupTrain:  epoch  0, batch  1101 | loss: 2.6416726MixupTrain:  epoch  0, batch  1102 | loss: 2.9675672MixupTrain:  epoch  0, batch  1103 | loss: 1.9444581MixupTrain:  epoch  0, batch  1104 | loss: 2.1968348MixupTrain:  epoch  0, batch  1105 | loss: 2.4552894MixupTrain:  epoch  0, batch  1106 | loss: 2.5841293MixupTrain:  epoch  0, batch  1107 | loss: 2.5266495MixupTrain:  epoch  0, batch  1108 | loss: 2.5869930MixupTrain:  epoch  0, batch  1109 | loss: 2.2760305MixupTrain:  epoch  0, batch  1110 | loss: 2.6604586MixupTrain:  epoch  0, batch  1111 | loss: 2.2457278MixupTrain:  epoch  0, batch  1113 | loss: 2.5811956MixupTrain:  epoch  0, batch  1114 | loss: 2.7610357MixupTrain:  epoch  0, batch  1116 | loss: 2.6471186MixupTrain:  epoch  0, batch  1117 | loss: 2.4412851MixupTrain:  epoch  0, batch  1118 | loss: 2.6446261MixupTrain:  epoch  0, batch  1119 | loss: 2.6953528MixupTrain:  epoch  0, batch  1120 | loss: 2.6309562MixupTrain:  epoch  0, batch  1121 | loss: 2.4256749MixupTrain:  epoch  0, batch  1122 | loss: 2.5055461MixupTrain:  epoch  0, batch  1123 | loss: 2.4445667MixupTrain:  epoch  0, batch  1124 | loss: 2.3848367MixupTrain:  epoch  0, batch  1126 | loss: 2.6776128MixupTrain:  epoch  0, batch  1129 | loss: 2.4749296MixupTrain:  epoch  0, batch  1130 | loss: 2.3346760MixupTrain:  epoch  0, batch  1131 | loss: 2.2654881MixupTrain:  epoch  0, batch  1132 | loss: 2.7822266MixupTrain:  epoch  0, batch  1133 | loss: 2.1988306MixupTrain:  epoch  0, batch  1134 | loss: 2.4074321MixupTrain:  epoch  0, batch  1135 | loss: 2.5347500MixupTrain:  epoch  0, batch  1136 | loss: 2.7717957MixupTrain:  epoch  0, batch  1137 | loss: 2.4803867MixupTrain:  epoch  0, batch  1138 | loss: 2.6466680MixupTrain:  epoch  0, batch  1139 | loss: 2.6120112MixupTrain:  epoch  0, batch  1141 | loss: 2.2103248MixupTrain:  epoch  0, batch  1142 | loss: 2.6614394MixupTrain:  epoch  0, batch  1144 | loss: 3.1627965MixupTrain:  epoch  0, batch  1145 | loss: 2.9798708MixupTrain:  epoch  0, batch  1146 | loss: 2.7050886MixupTrain:  epoch  0, batch  1147 | loss: 2.3330593MixupTrain:  epoch  0, batch  1148 | loss: 2.2327394MixupTrain:  epoch  0, batch  1150 | loss: 2.9450159MixupTrain:  epoch  0, batch  1151 | loss: 2.4275713MixupTrain:  epoch  0, batch  1152 | loss: 2.8966298MixupTrain:  epoch  0, batch  1153 | loss: 2.5257382MixupTrain:  epoch  0, batch  1154 | loss: 2.6305594MixupTrain:  epoch  0, batch  1155 | loss: 2.6994448MixupTrain:  epoch  0, batch  1156 | loss: 2.4398022MixupTrain:  epoch  0, batch  1157 | loss: 2.4749308MixupTrain:  epoch  0, batch  1159 | loss: 2.2963305MixupTrain:  epoch  0, batch  1160 | loss: 2.4825022MixupTrain:  epoch  0, batch  1161 | loss: 2.6401970MixupTrain:  epoch  0, batch  1162 | loss: 2.6815708MixupTrain:  epoch  0, batch  1163 | loss: 2.2691383MixupTrain:  epoch  0, batch  1164 | loss: 2.3130631MixupTrain:  epoch  0, batch  1165 | loss: 2.6283288MixupTrain:  epoch  0, batch  1166 | loss: 2.3168993MixupTrain:  epoch  0, batch  1168 | loss: 2.9499168MixupTrain:  epoch  0, batch  1169 | loss: 2.6904449MixupTrain:  epoch  0, batch  1171 | loss: 2.1468055MixupTrain:  epoch  0, batch  1172 | loss: 2.7706230MixupTrain:  epoch  0, batch  1173 | loss: 2.6966810MixupTrain:  epoch  0, batch  1174 | loss: 2.3930125MixupTrain:  epoch  0, batch  1175 | loss: 2.3881326MixupTrain:  epoch  0, batch  1177 | loss: 2.7156568MixupTrain:  epoch  0, batch  1178 | loss: 2.7490366MixupTrain:  epoch  0, batch  1179 | loss: 2.3888140MixupTrain:  epoch  0, batch  1180 | loss: 2.1726258MixupTrain:  epoch  0, batch  1181 | loss: 2.7425306MixupTrain:  epoch  0, batch  1182 | loss: 2.2431207MixupTrain:  epoch  0, batch  1183 | loss: 2.9227719MixupTrain:  epoch  0, batch  1184 | loss: 2.7571726MixupTrain:  epoch  0, batch  1185 | loss: 2.6921794MixupTrain:  epoch  0, batch  1186 | loss: 2.7538557MixupTrain:  epoch  0, batch  1187 | loss: 2.4358702MixupTrain:  epoch  0, batch  1188 | loss: 2.5157266MixupTrain:  epoch  0, batch  1189 | loss: 2.6282616MixupTrain:  epoch  0, batch  1190 | loss: 2.2495255MixupTrain:  epoch  0, batch  1191 | loss: 2.1787257MixupTrain:  epoch  0, batch  1192 | loss: 2.4042833MixupTrain:  epoch  0, batch  1193 | loss: 2.9949639MixupTrain:  epoch  0, batch  1194 | loss: 2.5186923MixupTrain:  epoch  0, batch  1195 | loss: 2.5197873MixupTrain:  epoch  0, batch  1196 | loss: 2.8125896MixupTrain:  epoch  0, batch  1197 | loss: 2.7030699MixupTrain:  epoch  0, batch  1198 | loss: 2.7883215MixupTrain:  epoch  0, batch  1199 | loss: 2.5314903MixupTrain:  epoch  0, batch  1200 | loss: 2.8653409MixupTrain:  epoch  0, batch  1201 | loss: 2.7533259MixupTrain:  epoch  0, batch  1202 | loss: 2.9219160MixupTrain:  epoch  0, batch  1203 | loss: 2.4925013MixupTrain:  epoch  0, batch  1204 | loss: 2.5255620MixupTrain:  epoch  0, batch  1205 | loss: 2.1859946MixupTrain:  epoch  0, batch  1206 | loss: 2.5648925MixupTrain:  epoch  0, batch  1207 | loss: 2.5006008MixupTrain:  epoch  0, batch  1208 | loss: 2.6102285MixupTrain:  epoch  0, batch  1209 | loss: 2.3956273MixupTrain:  epoch  0, batch  1210 | loss: 2.7281227MixupTrain:  epoch  0, batch  1211 | loss: 2.6457775MixupTrain:  epoch  0, batch  1212 | loss: 2.6016765MixupTrain:  epoch  0, batch  1213 | loss: 2.6830666MixupTrain:  epoch  0, batch  1214 | loss: 2.6579227MixupTrain:  epoch  0, batch  1215 | loss: 2.9355526MixupTrain:  epoch  0, batch  1216 | loss: 2.1986811MixupTrain:  epoch  0, batch  1217 | loss: 2.8251648MixupTrain:  epoch  0, batch  1218 | loss: 2.6071134MixupTrain:  epoch  0, batch  1219 | loss: 3.0696702MixupTrain:  epoch  0, batch  1220 | loss: 2.7517817MixupTrain:  epoch  0, batch  1221 | loss: 2.5877604MixupTrain:  epoch  0, batch  1223 | loss: 2.6530447MixupTrain:  epoch  0, batch  1224 | loss: 2.4911928MixupTrain:  epoch  0, batch  1225 | loss: 2.6733437MixupTrain:  epoch  0, batch  1226 | loss: 2.6392608MixupTrain:  epoch  0, batch  1227 | loss: 2.6067312MixupTrain:  epoch  0, batch  1228 | loss: 2.4853821MixupTrain:  epoch  0, batch  1229 | loss: 2.6618257MixupTrain:  epoch  0, batch  1230 | loss: 2.7321634MixupTrain:  epoch  0, batch  1231 | loss: 2.7247365MixupTrain:  epoch  0, batch  1232 | loss: 2.6870439MixupTrain:  epoch  0, batch  1234 | loss: 2.4200735MixupTrain:  epoch  0, batch  1235 | loss: 2.7358918MixupTrain:  epoch  0, batch  1236 | loss: 2.6937132MixupTrain:  epoch  0, batch  1237 | loss: 2.5858715MixupTrain:  epoch  0, batch  1238 | loss: 2.8851242MixupTrain:  epoch  0, batch  1239 | loss: 2.5177336MixupTrain:  epoch  0, batch  1241 | loss: 2.5010281MixupTrain:  epoch  0, batch  1242 | loss: 2.6480179MixupTrain:  epoch  0, batch  1243 | loss: 2.4526563MixupTrain:  epoch  0, batch  1244 | loss: 2.7314544MixupTrain:  epoch  0, batch  1245 | loss: 2.7654791MixupTrain:  epoch  0, batch  1246 | loss: 2.5367074MixupTrain:  epoch  0, batch  1247 | loss: 2.6613832MixupTrain:  epoch  0, batch  1248 | loss: 2.3637359MixupTrain:  epoch  0, batch  1250 | loss: 2.1585345MixupTrain:  epoch  0, batch  1251 | loss: 2.1069911MixupTrain:  epoch  0, batch  1252 | loss: 2.8019290MixupTrain:  epoch  0, batch  1253 | loss: 2.2206244MixupTrain:  epoch  0, batch  1254 | loss: 2.5402603MixupTrain:  epoch  0, batch  1255 | loss: 2.5081830MixupTrain:  epoch  0, batch  1256 | loss: 2.7075071MixupTrain:  epoch  0, batch  1257 | loss: 2.6950524MixupTrain:  epoch  0, batch  1259 | loss: 3.0260205MixupTrain:  epoch  0, batch  1260 | loss: 2.6098859MixupTrain:  epoch  0, batch  1261 | loss: 2.4505129MixupTrain:  epoch  0, batch  1262 | loss: 2.7812219MixupTrain:  epoch  0, batch  1263 | loss: 2.5518713MixupTrain:  epoch  0, batch  1264 | loss: 2.6996093MixupTrain:  epoch  0, batch  1265 | loss: 2.3630655MixupTrain:  epoch  0, batch  1266 | loss: 2.6573758MixupTrain:  epoch  0, batch  1267 | loss: 2.3256297MixupTrain:  epoch  0, batch  1268 | loss: 2.6343250MixupTrain:  epoch  0, batch  1270 | loss: 2.5282192MixupTrain:  epoch  0, batch  1271 | loss: 2.4927034MixupTrain:  epoch  0, batch  1272 | loss: 2.4398453MixupTrain:  epoch  0, batch  1273 | loss: 2.1548457MixupTrain:  epoch  0, batch  1274 | loss: 2.9186468MixupTrain:  epoch  0, batch  1275 | loss: 2.3355405MixupTrain:  epoch  0, batch  1276 | loss: 2.7522750MixupTrain:  epoch  0, batch  1277 | loss: 2.5417786MixupTrain:  epoch  0, batch  1278 | loss: 2.5088060MixupTrain:  epoch  0, batch  1279 | loss: 2.4003160MixupTrain:  epoch  0, batch  1280 | loss: 2.7855177MixupTrain:  epoch  0, batch  1282 | loss: 2.5852983MixupTrain:  epoch  0, batch  1283 | loss: 2.5744967MixupTrain:  epoch  0, batch  1284 | loss: 2.4917433MixupTrain:  epoch  0, batch  1285 | loss: 2.6662283MixupTrain:  epoch  0, batch  1286 | loss: 2.5189323MixupTrain:  epoch  0, batch  1288 | loss: 1.9599628MixupTrain:  epoch  0, batch  1291 | loss: 2.2332246MixupTrain:  epoch  0, batch  1292 | loss: 2.6181908MixupTrain:  epoch  0, batch  1293 | loss: 2.4010267MixupTrain:  epoch  0, batch  1294 | loss: 2.4994764MixupTrain:  epoch  0, batch  1298 | loss: 2.4142375MixupTrain:  epoch  0, batch  1299 | loss: 2.3491766MixupTrain:  epoch  0, batch  1300 | loss: 2.7023020MixupTrain:  epoch  0, batch  1301 | loss: 2.6473608MixupTrain:  epoch  0, batch  1302 | loss: 2.6932874MixupTrain:  epoch  0, batch  1303 | loss: 2.5842414MixupTrain:  epoch  0, batch  1304 | loss: 2.7544508MixupTrain:  epoch  0, batch  1305 | loss: 2.5495539MixupTrain:  epoch  0, batch  1306 | loss: 2.6866393MixupTrain:  epoch  0, batch  1307 | loss: 2.5771894MixupTrain:  epoch  0, batch  1308 | loss: 2.6752696MixupTrain:  epoch  0, batch  1309 | loss: 2.6165113MixupTrain:  epoch  0, batch  1310 | loss: 2.6517515MixupTrain:  epoch  0, batch  1311 | loss: 2.8470685MixupTrain:  epoch  0, batch  1312 | loss: 2.4980245MixupTrain:  epoch  0, batch  1313 | loss: 2.8883734MixupTrain:  epoch  0, batch  1314 | loss: 2.3051949MixupTrain:  epoch  0, batch  1315 | loss: 2.3638520MixupTrain:  epoch  0, batch  1317 | loss: 2.8996105MixupTrain:  epoch  0, batch  1318 | loss: 2.7659383MixupTrain:  epoch  0, batch  1319 | loss: 2.4353557MixupTrain:  epoch  0, batch  1320 | loss: 2.4175615MixupTrain:  epoch  0, batch  1321 | loss: 2.5415692MixupTrain:  epoch  0, batch  1322 | loss: 2.3221898MixupTrain:  epoch  0, batch  1323 | loss: 2.4086611MixupTrain:  epoch  0, batch  1324 | loss: 2.1036775MixupTrain:  epoch  0, batch  1325 | loss: 2.6070366MixupTrain:  epoch  0, batch  1326 | loss: 2.5341761MixupTrain:  epoch  0, batch  1327 | loss: 2.4020376MixupTrain:  epoch  0, batch  1328 | loss: 2.3910422MixupTrain:  epoch  0, batch  1329 | loss: 2.2706137MixupTrain:  epoch  0, batch  1330 | loss: 2.9955959MixupTrain:  epoch  0, batch  1331 | loss: 2.2396102MixupTrain:  epoch  0, batch  1332 | loss: 2.5938704MixupTrain:  epoch  0, batch  1333 | loss: 2.1796064MixupTrain:  epoch  0, batch  1334 | loss: 2.5625887MixupTrain:  epoch  0, batch  1335 | loss: 2.6315892MixupTrain:  epoch  0, batch  1336 | loss: 3.1165612MixupTrain:  epoch  0, batch  1337 | loss: 2.7483282MixupTrain:  epoch  0, batch  1338 | loss: 2.4001801MixupTrain:  epoch  0, batch  1339 | loss: 2.9085512MixupTrain:  epoch  0, batch  1341 | loss: 2.3169012MixupTrain:  epoch  0, batch  1342 | loss: 2.6409044MixupTrain:  epoch  0, batch  1344 | loss: 2.6253600MixupTrain:  epoch  0, batch  1346 | loss: 2.3810029MixupTrain:  epoch  0, batch  1347 | loss: 2.3208842MixupTrain:  epoch  0, batch  1348 | loss: 2.6882474MixupTrain:  epoch  0, batch  1350 | loss: 2.8183408MixupTrain:  epoch  0, batch  1351 | loss: 2.6018593MixupTrain:  epoch  0, batch  1352 | loss: 2.2196851MixupTrain:  epoch  0, batch  1353 | loss: 2.4472370MixupTrain:  epoch  0, batch  1354 | loss: 2.6607220MixupTrain:  epoch  0, batch  1355 | loss: 2.4211755MixupTrain:  epoch  0, batch  1356 | loss: 2.3838010MixupTrain:  epoch  0, batch  1357 | loss: 2.6556289MixupTrain:  epoch  0, batch  1358 | loss: 2.5383658MixupTrain:  epoch  0, batch  1360 | loss: 2.7733450MixupTrain:  epoch  0, batch  1361 | loss: 2.6186395MixupTrain:  epoch  0, batch  1362 | loss: 2.3707266MixupTrain:  epoch  0, batch  1363 | loss: 2.6367099MixupTrain:  epoch  0, batch  1364 | loss: 2.2651055MixupTrain:  epoch  0, batch  1365 | loss: 2.3988447MixupTrain:  epoch  0, batch  1367 | loss: 2.8850064MixupTrain:  epoch  0, batch  1368 | loss: 2.5361643MixupTrain:  epoch  0, batch  1370 | loss: 2.4216206MixupTrain:  epoch  0, batch  1372 | loss: 2.4453931MixupTrain:  epoch  0, batch  1373 | loss: 2.6923747MixupTrain:  epoch  0, batch  1374 | loss: 2.4479232MixupTrain:  epoch  0, batch  1375 | loss: 2.2305076MixupTrain:  epoch  0, batch  1376 | loss: 2.4960520MixupTrain:  epoch  0, batch  1377 | loss: 2.9528327MixupTrain:  epoch  0, batch  1379 | loss: 2.6633143MixupTrain:  epoch  0, batch  1381 | loss: 2.5655863MixupTrain:  epoch  0, batch  1382 | loss: 2.3850772MixupTrain:  epoch  0, batch  1383 | loss: 2.3495650MixupTrain:  epoch  0, batch  1385 | loss: 2.6470718MixupTrain:  epoch  0, batch  1386 | loss: 2.4252477MixupTrain:  epoch  0, batch  1387 | loss: 2.2580657MixupTrain:  epoch  0, batch  1388 | loss: 2.5579000MixupTrain:  epoch  0, batch  1389 | loss: 3.0978723MixupTrain:  epoch  0, batch  1392 | loss: 2.6795928MixupTrain:  epoch  0, batch  1393 | loss: 2.9510365MixupTrain:  epoch  0, batch  1394 | loss: 2.5276206MixupTrain:  epoch  0, batch  1395 | loss: 2.1462295MixupTrain:  epoch  0, batch  1396 | loss: 2.2263184MixupTrain:  epoch  0, batch  1397 | loss: 2.1123607MixupTrain:  epoch  0, batch  1398 | loss: 2.7340827MixupTrain:  epoch  0, batch  1399 | loss: 2.6175342MixupTrain:  epoch  0, batch  1402 | loss: 2.5951133MixupTrain:  epoch  0, batch  1403 | loss: 2.5224547MixupTrain:  epoch  0, batch  1404 | loss: 2.2852402MixupTrain:  epoch  0, batch  1405 | loss: 2.4540701MixupTrain:  epoch  0, batch  1407 | loss: 2.5796568MixupTrain:  epoch  0, batch  1408 | loss: 2.5189810MixupTrain:  epoch  0, batch  1409 | loss: 2.3067760MixupTrain:  epoch  0, batch  1410 | loss: 2.4075961MixupTrain:  epoch  0, batch  1411 | loss: 2.7360916MixupTrain:  epoch  0, batch  1412 | loss: 2.7662342MixupTrain:  epoch  0, batch  1413 | loss: 2.3544369MixupTrain:  epoch  0, batch  1415 | loss: 2.3977914MixupTrain:  epoch  0, batch  1416 | loss: 2.8500214MixupTrain:  epoch  0, batch  1418 | loss: 2.6957119MixupTrain:  epoch  0, batch  1420 | loss: 2.8225036MixupTrain:  epoch  0, batch  1421 | loss: 2.4017262MixupTrain:  epoch  0, batch  1422 | loss: 2.5371094MixupTrain:  epoch  0, batch  1423 | loss: 2.2208340MixupTrain:  epoch  0, batch  1425 | loss: 2.7683752MixupTrain:  epoch  0, batch  1427 | loss: 2.5538836MixupTrain:  epoch  0, batch  1430 | loss: 2.6369312MixupTrain:  epoch  0, batch  1431 | loss: 2.7157204MixupTrain:  epoch  0, batch  1432 | loss: 2.6230729MixupTrain:  epoch  0, batch  1434 | loss: 2.6594734MixupTrain:  epoch  0, batch  1435 | loss: 2.6492825MixupTrain:  epoch  0, batch  1436 | loss: 2.5838418MixupTrain:  epoch  0, batch  1437 | loss: 2.4291062MixupTrain:  epoch  0, batch  1438 | loss: 2.5003891MixupTrain:  epoch  0, batch  1439 | loss: 2.4886091MixupTrain:  epoch  0, batch  1440 | loss: 2.6320722MixupTrain:  epoch  0, batch  1441 | loss: 2.7622194MixupTrain:  epoch  0, batch  1442 | loss: 2.3648403MixupTrain:  epoch  0, batch  1443 | loss: 2.4607077MixupTrain:  epoch  0, batch  1444 | loss: 2.4529288MixupTrain:  epoch  0, batch  1445 | loss: 2.5534461MixupTrain:  epoch  0, batch  1446 | loss: 2.6564903MixupTrain:  epoch  0, batch  1448 | loss: 2.7912307MixupTrain:  epoch  0, batch  1449 | loss: 2.5741587MixupTrain:  epoch  0, batch  1450 | loss: 2.7062087MixupTrain:  epoch  0, batch  1451 | loss: 2.3645570MixupTrain:  epoch  0, batch  1452 | loss: 2.3838348MixupTrain:  epoch  0, batch  1453 | loss: 2.4755688MixupTrain:  epoch  0, batch  1454 | loss: 2.5480187MixupTrain:  epoch  0, batch  1455 | loss: 2.3792782MixupTrain:  epoch  0, batch  1456 | loss: 2.5809193MixupTrain:  epoch  0, batch  1457 | loss: 2.2673793MixupTrain:  epoch  0, batch  1458 | loss: 2.2959175MixupTrain:  epoch  0, batch  1459 | loss: 2.4399147MixupTrain:  epoch  0, batch  1460 | loss: 2.1865320MixupTrain:  epoch  0, batch  1461 | loss: 2.9168251MixupTrain:  epoch  0, batch  1462 | loss: 2.2202463MixupTrain:  epoch  0, batch  1463 | loss: 2.9079223MixupTrain:  epoch  0, batch  1465 | loss: 2.1637697MixupTrain:  epoch  0, batch  1466 | loss: 2.5634251MixupTrain:  epoch  0, batch  1467 | loss: 2.2016463MixupTrain:  epoch  0, batch  1468 | loss: 2.6979389MixupTrain:  epoch  0, batch  1469 | loss: 2.5341737MixupTrain:  epoch  0, batch  1471 | loss: 2.1335411MixupTrain:  epoch  0, batch  1472 | loss: 2.3841248MixupTrain:  epoch  0, batch  1473 | loss: 2.3899741MixupTrain:  epoch  0, batch  1474 | loss: 2.4129674MixupTrain:  epoch  0, batch  1475 | loss: 2.4990773MixupTrain:  epoch  0, batch  1476 | loss: 2.5156910MixupTrain:  epoch  0, batch  1477 | loss: 2.3661797MixupTrain:  epoch  0, batch  1478 | loss: 2.6380382MixupTrain:  epoch  0, batch  1479 | loss: 2.4258890MixupTrain:  epoch  0, batch  1480 | loss: 2.4514091MixupTrain:  epoch  0, batch  1481 | loss: 2.6209226MixupTrain:  epoch  0, batch  1482 | loss: 2.2601256MixupTrain:  epoch  0, batch  1483 | loss: 2.2625713MixupTrain:  epoch  0, batch  1484 | loss: 2.4717126MixupTrain:  epoch  0, batch  1485 | loss: 2.5534284MixupTrain:  epoch  0, batch  1486 | loss: 3.0103693MixupTrain:  epoch  0, batch  1487 | loss: 2.5511677MixupTrain:  epoch  0, batch  1488 | loss: 2.6018879MixupTrain:  epoch  0, batch  1489 | loss: 2.5409961MixupTrain:  epoch  0, batch  1491 | loss: 2.5405109MixupTrain:  epoch  0, batch  1492 | loss: 2.8232508MixupTrain:  epoch  0, batch  1493 | loss: 2.2091541MixupTrain:  epoch  0, batch  1494 | loss: 2.7659557MixupTrain:  epoch  0, batch  1496 | loss: 2.4947114MixupTrain:  epoch  0, batch  1497 | loss: 3.1357260MixupTrain:  epoch  0, batch  1498 | loss: 2.7190146MixupTrain:  epoch  0, batch  1499 | loss: 2.8508558MixupTrain:  epoch  0, batch  1500 | loss: 2.4624200MixupTrain:  epoch  0, batch  1502 | loss: 2.4222784MixupTrain:  epoch  0, batch  1503 | loss: 2.6158357MixupTrain:  epoch  0, batch  1505 | loss: 2.6569853MixupTrain:  epoch  0, batch  1506 | loss: 2.5445647MixupTrain:  epoch  0, batch  1508 | loss: 2.7273364MixupTrain:  epoch  0, batch  1510 | loss: 2.8467832MixupTrain:  epoch  0, batch  1511 | loss: 2.5653830MixupTrain:  epoch  0, batch  1512 | loss: 2.4696574MixupTrain:  epoch  0, batch  1513 | loss: 2.4581978MixupTrain:  epoch  0, batch  1514 | loss: 2.5254998MixupTrain:  epoch  0, batch  1515 | loss: 2.8381674MixupTrain:  epoch  0, batch  1516 | loss: 2.4478815MixupTrain:  epoch  0, batch  1517 | loss: 2.3650093MixupTrain:  epoch  0, batch  1518 | loss: 2.7063677MixupTrain:  epoch  0, batch  1519 | loss: 2.8945103MixupTrain:  epoch  0, batch  1520 | loss: 2.5678186MixupTrain:  epoch  0, batch  1521 | loss: 2.5275435MixupTrain:  epoch  0, batch  1522 | loss: 2.4362149MixupTrain:  epoch  0, batch  1523 | loss: 2.2185385MixupTrain:  epoch  0, batch  1524 | loss: 2.7419567MixupTrain:  epoch  0, batch  1525 | loss: 2.8857865MixupTrain:  epoch  0, batch  1526 | loss: 2.6697094MixupTrain:  epoch  0, batch  1527 | loss: 2.3168135MixupTrain:  epoch  0, batch  1529 | loss: 2.6420245MixupTrain:  epoch  0, batch  1531 | loss: 3.2107031MixupTrain:  epoch  0, batch  1532 | loss: 2.3559260MixupTrain:  epoch  0, batch  1533 | loss: 2.7636051MixupTrain:  epoch  0, batch  1534 | loss: 2.4699674MixupTrain:  epoch  0, batch  1535 | loss: 2.4450555MixupTrain:  epoch  0, batch  1536 | loss: 2.6072941MixupTrain:  epoch  0, batch  1537 | loss: 2.2914941MixupTrain:  epoch  0, batch  1540 | loss: 2.6999042MixupTrain:  epoch  0, batch  1542 | loss: 2.5364695MixupTrain:  epoch  0, batch  1544 | loss: 2.5449829MixupTrain:  epoch  0, batch  1545 | loss: 2.5606573MixupTrain:  epoch  0, batch  1546 | loss: 2.5672829MixupTrain:  epoch  0, batch  1547 | loss: 2.9699893MixupTrain:  epoch  0, batch  1548 | loss: 2.6029649MixupTrain:  epoch  0, batch  1549 | loss: 2.4049437MixupTrain:  epoch  0, batch  1550 | loss: 2.4829404MixupTrain:  epoch  0, batch  1551 | loss: 2.7384043MixupTrain:  epoch  0, batch  1552 | loss: 2.5880187MixupTrain:  epoch  0, batch  1553 | loss: 2.5428081MixupTrain:  epoch  0, batch  1555 | loss: 3.0031137MixupTrain:  epoch  0, batch  1556 | loss: 2.8138106MixupTrain:  epoch  0, batch  1557 | loss: 2.2974939MixupTrain:  epoch  0, batch  1558 | loss: 2.4706655MixupTrain:  epoch  0, batch  1559 | loss: 3.0243735MixupTrain:  epoch  0, batch  1560 | loss: 2.2552109MixupTrain:  epoch  0, batch  1561 | loss: 2.5742397MixupTrain:  epoch  0, batch  1563 | loss: 2.3540540MixupTrain:  epoch  0, batch  1564 | loss: 2.2428551MixupTrain:  epoch  0, batch  1565 | loss: 2.3785272MixupTrain:  epoch  0, batch  1566 | loss: 2.4198930MixupTrain:  epoch  0, batch  1567 | loss: 2.3571975MixupTrain:  epoch  0, batch  1569 | loss: 2.4191928MixupTrain:  epoch  0, batch  1570 | loss: 2.1351247MixupTrain:  epoch  0, batch  1571 | loss: 2.6709938MixupTrain:  epoch  0, batch  1572 | loss: 2.2258396MixupTrain:  epoch  0, batch  1573 | loss: 2.2594681MixupTrain:  epoch  0, batch  1576 | loss: 2.4531236MixupTrain:  epoch  0, batch  1577 | loss: 2.5048611MixupTrain:  epoch  0, batch  1578 | loss: 2.8167443MixupTrain:  epoch  0, batch  1579 | loss: 2.7584083MixupTrain:  epoch  0, batch  1580 | loss: 2.7392631MixupTrain:  epoch  0, batch  1581 | loss: 2.2249651MixupTrain:  epoch  0, batch  1582 | loss: 2.5660949MixupTrain:  epoch  0, batch  1583 | loss: 2.4153345MixupTrain:  epoch  0, batch  1584 | loss: 2.2928734MixupTrain:  epoch  0, batch  1585 | loss: 2.4404111MixupTrain:  epoch  0, batch  1586 | loss: 2.4402866MixupTrain:  epoch  0, batch  1587 | loss: 2.6654592MixupTrain:  epoch  0, batch  1588 | loss: 2.6485205MixupTrain:  epoch  0, batch  1590 | loss: 2.8971198MixupTrain:  epoch  0, batch  1592 | loss: 2.4713018MixupTrain:  epoch  0, batch  1593 | loss: 3.1727600MixupTrain:  epoch  0, batch  1594 | loss: 2.9496512MixupTrain:  epoch  0, batch  1595 | loss: 2.6525073MixupTrain:  epoch  0, batch  1596 | loss: 2.5898824MixupTrain:  epoch  0, batch  1597 | loss: 2.7069356MixupTrain:  epoch  0, batch  1598 | loss: 2.6704731MixupTrain:  epoch  0, batch  1599 | loss: 2.3335876MixupTrain:  epoch  0, batch  1600 | loss: 2.1993451MixupTrain:  epoch  0, batch  1601 | loss: 2.5604978MixupTrain:  epoch  0, batch  1602 | loss: 2.6825862MixupTrain:  epoch  0, batch  1603 | loss: 2.5470061MixupTrain:  epoch  0, batch  1604 | loss: 2.5397670MixupTrain:  epoch  0, batch  1606 | loss: 2.4690168MixupTrain:  epoch  0, batch  1607 | loss: 2.5139868MixupTrain:  epoch  0, batch  1608 | loss: 2.6708915MixupTrain:  epoch  0, batch  1609 | loss: 2.6800041MixupTrain:  epoch  0, batch  1610 | loss: 2.5491736MixupTrain:  epoch  0, batch  1611 | loss: 2.3646164MixupTrain:  epoch  0, batch  1612 | loss: 2.5872540MixupTrain:  epoch  0, batch  1613 | loss: 2.6965132MixupTrain:  epoch  0, batch  1614 | loss: 2.9572413MixupTrain:  epoch  0, batch  1615 | loss: 2.5854168MixupTrain:  epoch  0, batch  1616 | loss: 2.3630810MixupTrain:  epoch  0, batch  1617 | loss: 2.3742166MixupTrain:  epoch  0, batch  1618 | loss: 2.5339847MixupTrain:  epoch  0, batch  1619 | loss: 2.3678453MixupTrain:  epoch  0, batch  1620 | loss: 2.6512823MixupTrain:  epoch  0, batch  1621 | loss: 2.2549911MixupTrain:  epoch  0, batch  1622 | loss: 2.7561297MixupTrain:  epoch  0, batch  1623 | loss: 2.3367112MixupTrain:  epoch  0, batch  1625 | loss: 2.3334799MixupTrain:  epoch  0, batch  1626 | loss: 2.7452099MixupTrain:  epoch  0, batch  1627 | loss: 2.2901042MixupTrain:  epoch  0, batch  1628 | loss: 2.9264581MixupTrain:  epoch  0, batch  1629 | loss: 2.8684042MixupTrain:  epoch  0, batch  1630 | loss: 2.3851013MixupTrain:  epoch  0, batch  1631 | loss: 2.9472380MixupTrain:  epoch  0, batch  1632 | loss: 2.2871215MixupTrain:  epoch  0, batch  1633 | loss: 2.4240463MixupTrain:  epoch  0, batch  1634 | loss: 2.7241189MixupTrain:  epoch  0, batch  1635 | loss: 2.4366403MixupTrain:  epoch  0, batch  1636 | loss: 2.7679245MixupTrain:  epoch  0, batch  1637 | loss: 2.6740127MixupTrain:  epoch  0, batch  1638 | loss: 2.6531365MixupTrain:  epoch  0, batch  1639 | loss: 2.5463386MixupTrain:  epoch  0, batch  1640 | loss: 2.2616124MixupTrain:  epoch  0, batch  1641 | loss: 2.4669135MixupTrain:  epoch  0, batch  1642 | loss: 2.1699195MixupTrain:  epoch  0, batch  1643 | loss: 2.1789596MixupTrain:  epoch  0, batch  1644 | loss: 2.5715160MixupTrain:  epoch  0, batch  1645 | loss: 2.1368740MixupTrain:  epoch  0, batch  1646 | loss: 2.4280090MixupTrain:  epoch  0, batch  1647 | loss: 2.4951758MixupTrain:  epoch  0, batch  1648 | loss: 2.2488770MixupTrain:  epoch  0, batch  1649 | loss: 2.6192284MixupTrain:  epoch  0, batch  1650 | loss: 2.5839353MixupTrain:  epoch  0, batch  1651 | loss: 2.3762434MixupTrain:  epoch  0, batch  1652 | loss: 2.3094878MixupTrain:  epoch  0, batch  1653 | loss: 2.5284822MixupTrain:  epoch  0, batch  1654 | loss: 2.5968795MixupTrain:  epoch  0, batch  1655 | loss: 2.9188032MixupTrain:  epoch  0, batch  1656 | loss: 2.3827305MixupTrain:  epoch  0, batch  1657 | loss: 2.8638330MixupTrain:  epoch  0, batch  1658 | loss: 2.3602927MixupTrain:  epoch  0, batch  1659 | loss: 2.5043089MixupTrain:  epoch  0, batch  1660 | loss: 2.5060859MixupTrain:  epoch  0, batch  1661 | loss: 2.6559501MixupTrain:  epoch  0, batch  1662 | loss: 2.7694359MixupTrain:  epoch  0, batch  1663 | loss: 2.4684536MixupTrain:  epoch  0, batch  1664 | loss: 2.0582881MixupTrain:  epoch  0, batch  1665 | loss: 2.6544461MixupTrain:  epoch  0, batch  1667 | loss: 2.6307807MixupTrain:  epoch  0, batch  1668 | loss: 2.5123591MixupTrain:  epoch  0, batch  1669 | loss: 2.2536976MixupTrain:  epoch  0, batch  1670 | loss: 2.3862185MixupTrain:  epoch  0, batch  1671 | loss: 2.4019067MixupTrain:  epoch  0, batch  1672 | loss: 2.6678691MixupTrain:  epoch  0, batch  1673 | loss: 2.6350248MixupTrain:  epoch  0, batch  1674 | loss: 2.4451647MixupTrain:  epoch  0, batch  1675 | loss: 2.6397622MixupTrain:  epoch  0, batch  1677 | loss: 2.3896799MixupTrain:  epoch  0, batch  1678 | loss: 2.2824483MixupTrain:  epoch  0, batch  1679 | loss: 2.4857674MixupTrain:  epoch  0, batch  1681 | loss: 2.3940458MixupTrain:  epoch  0, batch  1682 | loss: 2.3544776MixupTrain:  epoch  0, batch  1683 | loss: 2.5076468MixupTrain:  epoch  0, batch  1684 | loss: 2.3555927MixupTrain:  epoch  0, batch  1686 | loss: 2.6081142MixupTrain:  epoch  0, batch  1687 | loss: 2.1071017MixupTrain:  epoch  0, batch  1688 | loss: 2.5934067MixupTrain:  epoch  0, batch  1689 | loss: 2.6592562MixupTrain:  epoch  0, batch  1690 | loss: 2.3980532MixupTrain:  epoch  0, batch  1692 | loss: 2.5307736MixupTrain:  epoch  0, batch  1693 | loss: 2.4505701MixupTrain:  epoch  0, batch  1694 | loss: 2.3834386MixupTrain:  epoch  0, batch  1695 | loss: 2.7229381MixupTrain:  epoch  0, batch  1696 | loss: 2.5986719MixupTrain:  epoch  0, batch  1697 | loss: 2.5110297MixupTrain:  epoch  0, batch  1698 | loss: 2.6070364MixupTrain:  epoch  0, batch  1699 | loss: 2.2930007MixupTrain:  epoch  0, batch  1700 | loss: 2.4299264MixupTrain:  epoch  0, batch  1701 | loss: 2.3626547MixupTrain:  epoch  0, batch  1703 | loss: 2.5778432MixupTrain:  epoch  0, batch  1705 | loss: 2.6713340MixupTrain:  epoch  0, batch  1706 | loss: 2.7829289MixupTrain:  epoch  0, batch  1707 | loss: 2.4002242MixupTrain:  epoch  0, batch  1708 | loss: 2.6130948MixupTrain:  epoch  0, batch  1709 | loss: 2.8467340MixupTrain:  epoch  0, batch  1710 | loss: 2.4158192MixupTrain:  epoch  0, batch  1712 | loss: 2.3201673MixupTrain:  epoch  0, batch  1713 | loss: 2.5234153MixupTrain:  epoch  0, batch  1714 | loss: 2.4940422MixupTrain:  epoch  0, batch  1715 | loss: 2.4583335MixupTrain:  epoch  0, batch  1717 | loss: 2.3214688MixupTrain:  epoch  0, batch  1719 | loss: 2.8168113MixupTrain:  epoch  0, batch  1720 | loss: 2.3986874MixupTrain:  epoch  0, batch  1722 | loss: 2.4297214MixupTrain:  epoch  0, batch  1723 | loss: 2.3135526MixupTrain:  epoch  0, batch  1725 | loss: 2.7303674MixupTrain:  epoch  0, batch  1726 | loss: 2.6231332MixupTrain:  epoch  0, batch  1727 | loss: 2.7785406MixupTrain:  epoch  0, batch  1729 | loss: 2.4140053MixupTrain:  epoch  0, batch  1730 | loss: 2.3164945MixupTrain:  epoch  0, batch  1732 | loss: 2.8558378MixupTrain:  epoch  0, batch  1733 | loss: 2.5676765MixupTrain:  epoch  0, batch  1734 | loss: 2.7186451MixupTrain:  epoch  0, batch  1735 | loss: 2.4478576MixupTrain:  epoch  0, batch  1737 | loss: 2.7616296MixupTrain:  epoch  0, batch  1738 | loss: 2.5796325MixupTrain:  epoch  0, batch  1741 | loss: 2.5532231MixupTrain:  epoch  0, batch  1742 | loss: 3.0780704MixupTrain:  epoch  0, batch  1743 | loss: 2.7341981MixupTrain:  epoch  0, batch  1744 | loss: 2.6330323MixupTrain:  epoch  0, batch  1745 | loss: 2.3133965MixupTrain:  epoch  0, batch  1746 | loss: 2.6561236MixupTrain:  epoch  0, batch  1747 | loss: 2.2480774MixupTrain:  epoch  0, batch  1748 | loss: 2.5489979MixupTrain:  epoch  0, batch  1749 | loss: 2.5028951MixupTrain:  epoch  0, batch  1750 | loss: 2.5866830MixupTrain:  epoch  0, batch  1751 | loss: 2.4862933MixupTrain:  epoch  0, batch  1752 | loss: 2.5108030MixupTrain:  epoch  0, batch  1753 | loss: 2.7789721MixupTrain:  epoch  0, batch  1754 | loss: 2.7977219MixupTrain:  epoch  0, batch  1755 | loss: 2.3774376MixupTrain:  epoch  0, batch  1756 | loss: 2.5771904MixupTrain:  epoch  0, batch  1758 | loss: 2.6273713MixupTrain:  epoch  0, batch  1760 | loss: 3.1087599MixupTrain:  epoch  0, batch  1761 | loss: 2.7675834
MemoryTrain:  epoch  0, batch     0 | loss: 2.6581335MemoryTrain:  epoch  0, batch     1 | loss: 2.8098903MemoryTrain:  epoch  0, batch     2 | loss: 2.6063490MemoryTrain:  epoch  0, batch     3 | loss: 2.3939061MemoryTrain:  epoch  0, batch     4 | loss: 2.7187974MemoryTrain:  epoch  0, batch     5 | loss: 2.0074072MemoryTrain:  epoch  0, batch     6 | loss: 3.0344930MemoryTrain:  epoch  0, batch     7 | loss: 2.7194471MemoryTrain:  epoch  0, batch     8 | loss: 4.0126143MemoryTrain:  epoch  0, batch     9 | loss: 2.7899170MemoryTrain:  epoch  0, batch    10 | loss: 2.3125563MemoryTrain:  epoch  0, batch    11 | loss: 2.0192795MemoryTrain:  epoch  0, batch    12 | loss: 2.1545043MemoryTrain:  epoch  0, batch    13 | loss: 2.1471863MemoryTrain:  epoch  1, batch     0 | loss: 1.8307316MemoryTrain:  epoch  1, batch     1 | loss: 1.8756275MemoryTrain:  epoch  1, batch     2 | loss: 1.8414388MemoryTrain:  epoch  1, batch     3 | loss: 1.8638234MemoryTrain:  epoch  1, batch     4 | loss: 1.8264105MemoryTrain:  epoch  1, batch     5 | loss: 1.8593900MemoryTrain:  epoch  1, batch     6 | loss: 1.8322605MemoryTrain:  epoch  1, batch     7 | loss: 1.8664646MemoryTrain:  epoch  1, batch     8 | loss: 1.8249958MemoryTrain:  epoch  1, batch     9 | loss: 1.8309658MemoryTrain:  epoch  1, batch    10 | loss: 1.8581421MemoryTrain:  epoch  1, batch    11 | loss: 1.8292296MemoryTrain:  epoch  1, batch    12 | loss: 1.8426470MemoryTrain:  epoch  1, batch    13 | loss: 1.8308283MemoryTrain:  epoch  2, batch     0 | loss: 1.8211098MemoryTrain:  epoch  2, batch     1 | loss: 1.8415637MemoryTrain:  epoch  2, batch     2 | loss: 1.8199017MemoryTrain:  epoch  2, batch     3 | loss: 1.8287226MemoryTrain:  epoch  2, batch     4 | loss: 1.8248389MemoryTrain:  epoch  2, batch     5 | loss: 1.8225842MemoryTrain:  epoch  2, batch     6 | loss: 1.8149016MemoryTrain:  epoch  2, batch     7 | loss: 1.8316951MemoryTrain:  epoch  2, batch     8 | loss: 1.8232406MemoryTrain:  epoch  2, batch     9 | loss: 1.8621641MemoryTrain:  epoch  2, batch    10 | loss: 1.8270210MemoryTrain:  epoch  2, batch    11 | loss: 1.8930063MemoryTrain:  epoch  2, batch    12 | loss: 1.8156399MemoryTrain:  epoch  2, batch    13 | loss: 1.8204768MemoryTrain:  epoch  3, batch     0 | loss: 1.8138580MemoryTrain:  epoch  3, batch     1 | loss: 1.8328104MemoryTrain:  epoch  3, batch     2 | loss: 1.8897756MemoryTrain:  epoch  3, batch     3 | loss: 1.8342050MemoryTrain:  epoch  3, batch     4 | loss: 1.8079340MemoryTrain:  epoch  3, batch     5 | loss: 1.8050826MemoryTrain:  epoch  3, batch     6 | loss: 1.8120251MemoryTrain:  epoch  3, batch     7 | loss: 1.8134359MemoryTrain:  epoch  3, batch     8 | loss: 1.8221406MemoryTrain:  epoch  3, batch     9 | loss: 1.8437866MemoryTrain:  epoch  3, batch    10 | loss: 1.8084059MemoryTrain:  epoch  3, batch    11 | loss: 1.8140292MemoryTrain:  epoch  3, batch    12 | loss: 1.8101788MemoryTrain:  epoch  3, batch    13 | loss: 1.8258585MemoryTrain:  epoch  4, batch     0 | loss: 1.8127699MemoryTrain:  epoch  4, batch     1 | loss: 1.8139839MemoryTrain:  epoch  4, batch     2 | loss: 1.8100355MemoryTrain:  epoch  4, batch     3 | loss: 1.8185002MemoryTrain:  epoch  4, batch     4 | loss: 1.8185062MemoryTrain:  epoch  4, batch     5 | loss: 1.8101740MemoryTrain:  epoch  4, batch     6 | loss: 1.8117493MemoryTrain:  epoch  4, batch     7 | loss: 1.8126297MemoryTrain:  epoch  4, batch     8 | loss: 1.8131604MemoryTrain:  epoch  4, batch     9 | loss: 1.8151307MemoryTrain:  epoch  4, batch    10 | loss: 1.8130975MemoryTrain:  epoch  4, batch    11 | loss: 1.8101828MemoryTrain:  epoch  4, batch    12 | loss: 1.8114972MemoryTrain:  epoch  4, batch    13 | loss: 1.8189211MemoryTrain:  epoch  5, batch     0 | loss: 1.8060150MemoryTrain:  epoch  5, batch     1 | loss: 1.8042629MemoryTrain:  epoch  5, batch     2 | loss: 1.8149216MemoryTrain:  epoch  5, batch     3 | loss: 1.8115848MemoryTrain:  epoch  5, batch     4 | loss: 1.8208742MemoryTrain:  epoch  5, batch     5 | loss: 1.8110416MemoryTrain:  epoch  5, batch     6 | loss: 1.8148822MemoryTrain:  epoch  5, batch     7 | loss: 1.8163044MemoryTrain:  epoch  5, batch     8 | loss: 1.8138847MemoryTrain:  epoch  5, batch     9 | loss: 1.8092921MemoryTrain:  epoch  5, batch    10 | loss: 1.8082877MemoryTrain:  epoch  5, batch    11 | loss: 1.8105758MemoryTrain:  epoch  5, batch    12 | loss: 1.8068975MemoryTrain:  epoch  5, batch    13 | loss: 1.8211453MemoryTrain:  epoch  6, batch     0 | loss: 1.8144916MemoryTrain:  epoch  6, batch     1 | loss: 1.8091433MemoryTrain:  epoch  6, batch     2 | loss: 1.8088548MemoryTrain:  epoch  6, batch     3 | loss: 1.8044780MemoryTrain:  epoch  6, batch     4 | loss: 1.8110790MemoryTrain:  epoch  6, batch     5 | loss: 1.8106358MemoryTrain:  epoch  6, batch     6 | loss: 1.8126518MemoryTrain:  epoch  6, batch     7 | loss: 1.8064564MemoryTrain:  epoch  6, batch     8 | loss: 1.8131295MemoryTrain:  epoch  6, batch     9 | loss: 1.8173096MemoryTrain:  epoch  6, batch    10 | loss: 1.8148873MemoryTrain:  epoch  6, batch    11 | loss: 1.8124242MemoryTrain:  epoch  6, batch    12 | loss: 1.8143919MemoryTrain:  epoch  6, batch    13 | loss: 1.8136075MemoryTrain:  epoch  7, batch     0 | loss: 1.8119423MemoryTrain:  epoch  7, batch     1 | loss: 1.8114182MemoryTrain:  epoch  7, batch     2 | loss: 1.8070407MemoryTrain:  epoch  7, batch     3 | loss: 1.8183107MemoryTrain:  epoch  7, batch     4 | loss: 1.8177598MemoryTrain:  epoch  7, batch     5 | loss: 1.8159695MemoryTrain:  epoch  7, batch     6 | loss: 1.8084430MemoryTrain:  epoch  7, batch     7 | loss: 1.8124539MemoryTrain:  epoch  7, batch     8 | loss: 1.8131928MemoryTrain:  epoch  7, batch     9 | loss: 1.8090336MemoryTrain:  epoch  7, batch    10 | loss: 1.8190866MemoryTrain:  epoch  7, batch    11 | loss: 1.8124527MemoryTrain:  epoch  7, batch    12 | loss: 1.8107996MemoryTrain:  epoch  7, batch    13 | loss: 1.8109591MemoryTrain:  epoch  8, batch     0 | loss: 1.8086275MemoryTrain:  epoch  8, batch     1 | loss: 1.8122773MemoryTrain:  epoch  8, batch     2 | loss: 1.8102318MemoryTrain:  epoch  8, batch     3 | loss: 1.8108783MemoryTrain:  epoch  8, batch     4 | loss: 1.8129116MemoryTrain:  epoch  8, batch     5 | loss: 1.8037157MemoryTrain:  epoch  8, batch     6 | loss: 1.8130307MemoryTrain:  epoch  8, batch     7 | loss: 1.8057468MemoryTrain:  epoch  8, batch     8 | loss: 1.8105800MemoryTrain:  epoch  8, batch     9 | loss: 1.8135872MemoryTrain:  epoch  8, batch    10 | loss: 1.8060231MemoryTrain:  epoch  8, batch    11 | loss: 1.8061626MemoryTrain:  epoch  8, batch    12 | loss: 1.8136638MemoryTrain:  epoch  8, batch    13 | loss: 1.8103099MemoryTrain:  epoch  9, batch     0 | loss: 1.8090611MemoryTrain:  epoch  9, batch     1 | loss: 1.8174815MemoryTrain:  epoch  9, batch     2 | loss: 1.8096843MemoryTrain:  epoch  9, batch     3 | loss: 1.8144000MemoryTrain:  epoch  9, batch     4 | loss: 1.8098500MemoryTrain:  epoch  9, batch     5 | loss: 1.8144460MemoryTrain:  epoch  9, batch     6 | loss: 1.8111355MemoryTrain:  epoch  9, batch     7 | loss: 1.8045468MemoryTrain:  epoch  9, batch     8 | loss: 1.8080647MemoryTrain:  epoch  9, batch     9 | loss: 1.8104029MemoryTrain:  epoch  9, batch    10 | loss: 1.8070853MemoryTrain:  epoch  9, batch    11 | loss: 1.8175994MemoryTrain:  epoch  9, batch    12 | loss: 1.8126087MemoryTrain:  epoch  9, batch    13 | loss: 1.8200858
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 84.38%   [EVAL] batch:    2 | acc: 87.50%,  total acc: 85.42%   [EVAL] batch:    3 | acc: 81.25%,  total acc: 84.38%   [EVAL] batch:    4 | acc: 81.25%,  total acc: 83.75%   [EVAL] batch:    5 | acc: 93.75%,  total acc: 85.42%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 86.61%   [EVAL] batch:    7 | acc: 12.50%,  total acc: 77.34%   
[EVAL] batch:    0 | acc: 0.00%,  total acc: 0.00%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 18.75%   [EVAL] batch:    2 | acc: 6.25%,  total acc: 14.58%   [EVAL] batch:    3 | acc: 12.50%,  total acc: 14.06%   [EVAL] batch:    4 | acc: 12.50%,  total acc: 13.75%   [EVAL] batch:    5 | acc: 18.75%,  total acc: 14.58%   [EVAL] batch:    6 | acc: 6.25%,  total acc: 13.39%   [EVAL] batch:    7 | acc: 0.00%,  total acc: 11.72%   [EVAL] batch:    8 | acc: 6.25%,  total acc: 11.11%   [EVAL] batch:    9 | acc: 12.50%,  total acc: 11.25%   [EVAL] batch:   10 | acc: 6.25%,  total acc: 10.80%   [EVAL] batch:   11 | acc: 12.50%,  total acc: 10.94%   [EVAL] batch:   12 | acc: 0.00%,  total acc: 10.10%   [EVAL] batch:   13 | acc: 25.00%,  total acc: 11.16%   [EVAL] batch:   14 | acc: 50.00%,  total acc: 13.75%   [EVAL] batch:   15 | acc: 50.00%,  total acc: 16.02%   [EVAL] batch:   16 | acc: 75.00%,  total acc: 19.49%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 21.88%   [EVAL] batch:   18 | acc: 62.50%,  total acc: 24.01%   [EVAL] batch:   19 | acc: 75.00%,  total acc: 26.56%   [EVAL] batch:   20 | acc: 93.75%,  total acc: 29.76%   [EVAL] batch:   21 | acc: 81.25%,  total acc: 32.10%   [EVAL] batch:   22 | acc: 87.50%,  total acc: 34.51%   [EVAL] batch:   23 | acc: 93.75%,  total acc: 36.98%   [EVAL] batch:   24 | acc: 93.75%,  total acc: 39.25%   [EVAL] batch:   25 | acc: 93.75%,  total acc: 41.35%   [EVAL] batch:   26 | acc: 62.50%,  total acc: 42.13%   [EVAL] batch:   27 | acc: 56.25%,  total acc: 42.63%   [EVAL] batch:   28 | acc: 75.00%,  total acc: 43.75%   [EVAL] batch:   29 | acc: 50.00%,  total acc: 43.96%   [EVAL] batch:   30 | acc: 56.25%,  total acc: 44.35%   [EVAL] batch:   31 | acc: 68.75%,  total acc: 45.12%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 44.89%   [EVAL] batch:   33 | acc: 18.75%,  total acc: 44.12%   [EVAL] batch:   34 | acc: 18.75%,  total acc: 43.39%   [EVAL] batch:   35 | acc: 25.00%,  total acc: 42.88%   [EVAL] batch:   36 | acc: 18.75%,  total acc: 42.23%   [EVAL] batch:   37 | acc: 0.00%,  total acc: 41.12%   [EVAL] batch:   38 | acc: 25.00%,  total acc: 40.71%   [EVAL] batch:   39 | acc: 75.00%,  total acc: 41.56%   [EVAL] batch:   40 | acc: 31.25%,  total acc: 41.31%   [EVAL] batch:   41 | acc: 12.50%,  total acc: 40.62%   [EVAL] batch:   42 | acc: 25.00%,  total acc: 40.26%   [EVAL] batch:   43 | acc: 75.00%,  total acc: 41.05%   [EVAL] batch:   44 | acc: 100.00%,  total acc: 42.36%   [EVAL] batch:   45 | acc: 100.00%,  total acc: 43.61%   [EVAL] batch:   46 | acc: 100.00%,  total acc: 44.81%   [EVAL] batch:   47 | acc: 100.00%,  total acc: 45.96%   [EVAL] batch:   48 | acc: 100.00%,  total acc: 47.07%   [EVAL] batch:   49 | acc: 87.50%,  total acc: 47.88%   [EVAL] batch:   50 | acc: 31.25%,  total acc: 47.55%   [EVAL] batch:   51 | acc: 0.00%,  total acc: 46.63%   [EVAL] batch:   52 | acc: 6.25%,  total acc: 45.87%   [EVAL] batch:   53 | acc: 0.00%,  total acc: 45.02%   [EVAL] batch:   54 | acc: 0.00%,  total acc: 44.20%   [EVAL] batch:   55 | acc: 0.00%,  total acc: 43.42%   [EVAL] batch:   56 | acc: 56.25%,  total acc: 43.64%   [EVAL] batch:   57 | acc: 93.75%,  total acc: 44.50%   [EVAL] batch:   58 | acc: 75.00%,  total acc: 45.02%   [EVAL] batch:   59 | acc: 93.75%,  total acc: 45.83%   [EVAL] batch:   60 | acc: 75.00%,  total acc: 46.31%   [EVAL] batch:   61 | acc: 75.00%,  total acc: 46.77%   [EVAL] batch:   62 | acc: 75.00%,  total acc: 47.22%   [EVAL] batch:   63 | acc: 68.75%,  total acc: 47.56%   [EVAL] batch:   64 | acc: 81.25%,  total acc: 48.08%   [EVAL] batch:   65 | acc: 87.50%,  total acc: 48.67%   [EVAL] batch:   66 | acc: 100.00%,  total acc: 49.44%   [EVAL] batch:   67 | acc: 100.00%,  total acc: 50.18%   [EVAL] batch:   68 | acc: 100.00%,  total acc: 50.91%   [EVAL] batch:   69 | acc: 100.00%,  total acc: 51.61%   [EVAL] batch:   70 | acc: 100.00%,  total acc: 52.29%   [EVAL] batch:   71 | acc: 93.75%,  total acc: 52.86%   [EVAL] batch:   72 | acc: 12.50%,  total acc: 52.31%   [EVAL] batch:   73 | acc: 0.00%,  total acc: 51.60%   [EVAL] batch:   74 | acc: 81.25%,  total acc: 52.00%   [EVAL] batch:   75 | acc: 93.75%,  total acc: 52.55%   [EVAL] batch:   76 | acc: 100.00%,  total acc: 53.17%   [EVAL] batch:   77 | acc: 50.00%,  total acc: 53.12%   [EVAL] batch:   78 | acc: 75.00%,  total acc: 53.40%   [EVAL] batch:   79 | acc: 75.00%,  total acc: 53.67%   [EVAL] batch:   80 | acc: 62.50%,  total acc: 53.78%   [EVAL] batch:   81 | acc: 93.75%,  total acc: 54.27%   [EVAL] batch:   82 | acc: 100.00%,  total acc: 54.82%   [EVAL] batch:   83 | acc: 93.75%,  total acc: 55.28%   [EVAL] batch:   84 | acc: 50.00%,  total acc: 55.22%   [EVAL] batch:   85 | acc: 37.50%,  total acc: 55.01%   [EVAL] batch:   86 | acc: 43.75%,  total acc: 54.89%   [EVAL] batch:   87 | acc: 56.25%,  total acc: 54.90%   [EVAL] batch:   88 | acc: 50.00%,  total acc: 54.85%   [EVAL] batch:   89 | acc: 56.25%,  total acc: 54.86%   [EVAL] batch:   90 | acc: 37.50%,  total acc: 54.67%   [EVAL] batch:   91 | acc: 56.25%,  total acc: 54.69%   [EVAL] batch:   92 | acc: 68.75%,  total acc: 54.84%   [EVAL] batch:   93 | acc: 62.50%,  total acc: 54.92%   [EVAL] batch:   94 | acc: 62.50%,  total acc: 55.00%   [EVAL] batch:   95 | acc: 93.75%,  total acc: 55.40%   [EVAL] batch:   96 | acc: 100.00%,  total acc: 55.86%   [EVAL] batch:   97 | acc: 87.50%,  total acc: 56.19%   [EVAL] batch:   98 | acc: 93.75%,  total acc: 56.57%   [EVAL] batch:   99 | acc: 81.25%,  total acc: 56.81%   [EVAL] batch:  100 | acc: 87.50%,  total acc: 57.12%   [EVAL] batch:  101 | acc: 87.50%,  total acc: 57.41%   [EVAL] batch:  102 | acc: 87.50%,  total acc: 57.71%   [EVAL] batch:  103 | acc: 87.50%,  total acc: 57.99%   [EVAL] batch:  104 | acc: 75.00%,  total acc: 58.15%   [EVAL] batch:  105 | acc: 93.75%,  total acc: 58.49%   [EVAL] batch:  106 | acc: 87.50%,  total acc: 58.76%   [EVAL] batch:  107 | acc: 81.25%,  total acc: 58.97%   [EVAL] batch:  108 | acc: 81.25%,  total acc: 59.17%   [EVAL] batch:  109 | acc: 93.75%,  total acc: 59.49%   [EVAL] batch:  110 | acc: 93.75%,  total acc: 59.80%   [EVAL] batch:  111 | acc: 18.75%,  total acc: 59.43%   
cur_acc:  ['0.8693', '0.9132', '0.8929', '0.9107', '0.8462', '0.8417', '0.7734']
his_acc:  ['0.8693', '0.8550', '0.8311', '0.7484', '0.6840', '0.7000', '0.5943']
CurrentTrain: epoch  0, batch     0 | loss: 9.1093445CurrentTrain: epoch  0, batch     1 | loss: 8.5064106CurrentTrain: epoch  1, batch     0 | loss: 8.3382025CurrentTrain: epoch  1, batch     1 | loss: 7.1452188CurrentTrain: epoch  2, batch     0 | loss: 7.5079679CurrentTrain: epoch  2, batch     1 | loss: 4.8634944CurrentTrain: epoch  3, batch     0 | loss: 6.7971482CurrentTrain: epoch  3, batch     1 | loss: 5.4134469CurrentTrain: epoch  4, batch     0 | loss: 6.5137715CurrentTrain: epoch  4, batch     1 | loss: 6.0423646CurrentTrain: epoch  5, batch     0 | loss: 5.6404996CurrentTrain: epoch  5, batch     1 | loss: 6.5520616CurrentTrain: epoch  6, batch     0 | loss: 6.1323061CurrentTrain: epoch  6, batch     1 | loss: 4.8902435CurrentTrain: epoch  7, batch     0 | loss: 6.3266993CurrentTrain: epoch  7, batch     1 | loss: 4.6393104CurrentTrain: epoch  8, batch     0 | loss: 4.7504311CurrentTrain: epoch  8, batch     1 | loss: 7.7247348CurrentTrain: epoch  9, batch     0 | loss: 6.2347155CurrentTrain: epoch  9, batch     1 | loss: 6.2508397
#### organization subsidiaries ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization subsidiaries" means an organization 's subsidiary is an organization.
Here is an example:
Relation: organization subsidiaries
Context: firstgroup , britain 's largest bus operator , entered the north american market in 1999 when it acquired ryder public transportation services inc. .
Head Entity: firstgroup
Tail Entity: ryder public transportation services inc.
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization subsidiaries":
Relation: organization subsidiaries  
Context: Alphabet Inc. has several subsidiaries, including YouTube, which it acquired in 2006 for $1.65 billion.  
Head Entity: Alphabet Inc.  
Tail Entity: YouTube  

Relation: organization subsidiaries  
Context: In 2015, Facebook acquired WhatsApp, a subsidiary that has grown rapidly since its inception.  
Head Entity: Facebook  
Tail Entity: WhatsApp  

Relation: organization subsidiaries  
Context: The Coca-Cola Company owns several subsidiaries, including Minute Maid, which specializes in fruit juices.  
Head Entity: The Coca-Cola Company  
Tail Entity: Minute Maid  

Relation: organization subsidiaries  
Context: Amazon's acquisition of Whole Foods in 2017 added a new subsidiary to its portfolio, enhancing its grocery business.  
Head Entity: Amazon  
Tail Entity: Whole Foods  

Relation: organization subsidiaries  
Context: General Electric has a diverse range of subsidiaries, one of which is GE Aviation, a leader in jet engine manufacturing.  
Head Entity: General Electric  
Tail Entity: GE Aviation  
#### organization parents ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization parents" means an organization 's parent is an organization.
Here is an example:
Relation: organization parents
Context: those who try to salvage possessions from the debris of their homes can easily turn into victims too , said dr. irwin redlener , director of the national center for disaster preparedness at columbia university mailman school of medicine .
Head Entity: national center for disaster preparedness
Tail Entity: columbia university mailman school of medicine
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization parents":
Relation: organization parents  
Context: The tech giant Google has been a subsidiary of Alphabet Inc. since its restructuring in 2015, allowing for greater focus on its various ventures.  
Head Entity: Google  
Tail Entity: Alphabet Inc.  

Relation: organization parents  
Context: The renowned research institution MIT is part of the larger Massachusetts Institute of Technology system, which encompasses several affiliated organizations.  
Head Entity: MIT  
Tail Entity: Massachusetts Institute of Technology  

Relation: organization parents  
Context: The popular social media platform Instagram operates under the umbrella of its parent company, Meta Platforms, Inc., which oversees multiple applications.  
Head Entity: Instagram  
Tail Entity: Meta Platforms, Inc.  

Relation: organization parents  
Context: The global beverage company Coca-Cola is a subsidiary of The Coca-Cola Company, which manages a wide range of brands and products.  
Head Entity: Coca-Cola  
Tail Entity: The Coca-Cola Company  

Relation: organization parents  
Context: The prestigious university Stanford is part of the larger Stanford University system, which includes various research and educational organizations.  
Head Entity: Stanford  
Tail Entity: Stanford University
#### organization alternate names ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization alternate names" means a person 's alias is a person.
Here is an example:
Relation: organization alternate names
Context: the talks between graham and pak ui-chun were held in a `` friendly '' manner , the official korean central news agency -lrb- kcna -rrb- said , without giving details .
Head Entity: kcna
Tail Entity: korean central news agency
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization alternate names":
Relation: organization alternate names  
Context: The International Monetary Fund, often referred to as the IMF, has released its latest economic forecast.  
Head Entity: IMF  
Tail Entity: International Monetary Fund  

Relation: organization alternate names  
Context: The World Health Organization, commonly known as WHO, has declared a public health emergency.  
Head Entity: WHO  
Tail Entity: World Health Organization  

Relation: organization alternate names  
Context: The National Aeronautics and Space Administration, abbreviated as NASA, is planning a new mission to Mars.  
Head Entity: NASA  
Tail Entity: National Aeronautics and Space Administration  

Relation: organization alternate names  
Context: The Federal Bureau of Investigation, or FBI, has launched an investigation into the matter.  
Head Entity: FBI  
Tail Entity: Federal Bureau of Investigation  

Relation: organization alternate names  
Context: The Central Intelligence Agency, often called the CIA, has been involved in various covert operations.  
Head Entity: CIA  
Tail Entity: Central Intelligence Agency  
#### organization city of headquarters ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "organization city of headquarters" means an organization is located in a city.
Here is an example:
Relation: organization city of headquarters
Context: ------ london 2008-05-20 07:23:45 utc enodis plc endorses sweetened takeover bid by us company manitowoc illinois tool works of glenville , illinois , which had offered 282 pence -lrb- us$ 551 euro3 54 -rrb- per share , said monday that it was considering its position .
Head Entity: illinois tool works
Tail Entity: glenville
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "organization city of headquarters":
Relation: organization city of headquarters  
Context: ------ san francisco 2010-11-15 12:45:00 utc the tech giant apple inc. has announced plans to expand its headquarters in cupertino, california, which is expected to create thousands of new jobs in the area.  
Head Entity: apple inc.  
Tail Entity: cupertino  

Relation: organization city of headquarters  
Context: ------ new york 2015-03-10 09:30:00 utc the financial services firm goldman sachs is headquartered in new york city, where it has been a major player in the investment banking sector for decades.  
Head Entity: goldman sachs  
Tail Entity: new york city  

Relation: organization city of headquarters  
Context: ------ seattle 2018-07-22 14:00:00 utc amazon.com, inc. has its headquarters in seattle, washington, and continues to grow its presence in the tech industry with various innovations and services.  
Head Entity: amazon.com, inc.  
Tail Entity: seattle  

Relation: organization city of headquarters  
Context: ------ boston 2021-01-05 16:20:00 utc the biotechnology company moderna, known for its mRNA technology, is based in cambridge, massachusetts, where it conducts much of its research and development.  
Head Entity: moderna  
Tail Entity: cambridge  

Relation: organization city of headquarters  
Context: ------ austin 2019-09-30 11:15:00 utc the software company oracle has established its new headquarters in austin, texas, marking a significant shift from its previous location in california.  
Head Entity: oracle  
Tail Entity: austin  
#### person siblings ####
You are a data scientist working on a relation extraction task. Please do the following task and do not give output in the markdown format.One sample in relation extraction datasets consists of a relation, a context, a pair of head and tail entities in the context.The head entity has the relation with the tail entity.
Relation "person siblings" means a person 's sibling is a person.
Here is an example:
Relation: person siblings
Context: `` holly and sanjaya are headed to -lsb- the hawaiian island of -rsb- kauai tomorrow morning so she can meet his parents . ''
Head Entity: she
Tail Entity: sanjaya
Please generate 5 diversity samples (must have full : Relation , Context , Head Entity , Tail Entity) like the above example for the relation "person siblings":
Relation: person siblings  
Context: `` during the family reunion, john introduced his sister to everyone at the picnic. ''  
Head Entity: his sister  
Tail Entity: john  

Relation: person siblings  
Context: `` emily and her brother spent the afternoon playing video games together in their living room. ''  
Head Entity: her brother  
Tail Entity: emily  

Relation: person siblings  
Context: `` at the wedding, mark was excited to see his sister, who had traveled from another state to attend. ''  
Head Entity: his sister  
Tail Entity: mark  

Relation: person siblings  
Context: `` after the graduation ceremony, lucas and his sibling took a memorable photo together on stage. ''  
Head Entity: his sibling  
Tail Entity: lucas  

Relation: person siblings  
Context: `` during the holidays, jessica always looks forward to spending time with her brother and catching up. ''  
Head Entity: her brother  
Tail Entity: jessica  
Mixup data size:  35770
MixupTrain:  epoch  0, batch     0 | loss: 3.4390347MixupTrain:  epoch  0, batch     1 | loss: 3.3091006MixupTrain:  epoch  0, batch     2 | loss: 2.8855219MixupTrain:  epoch  0, batch     3 | loss: 4.5728893MixupTrain:  epoch  0, batch     4 | loss: 3.2116320MixupTrain:  epoch  0, batch     5 | loss: 4.5975261MixupTrain:  epoch  0, batch     6 | loss: 4.1373696MixupTrain:  epoch  0, batch     7 | loss: 3.9409385MixupTrain:  epoch  0, batch     8 | loss: 3.6420116MixupTrain:  epoch  0, batch     9 | loss: 3.9181976MixupTrain:  epoch  0, batch    10 | loss: 4.3445282MixupTrain:  epoch  0, batch    11 | loss: 4.1803155MixupTrain:  epoch  0, batch    12 | loss: 3.6503243MixupTrain:  epoch  0, batch    13 | loss: 3.1021028MixupTrain:  epoch  0, batch    14 | loss: 4.9277344MixupTrain:  epoch  0, batch    15 | loss: 4.0103035MixupTrain:  epoch  0, batch    16 | loss: 4.1109695MixupTrain:  epoch  0, batch    17 | loss: 3.9645343MixupTrain:  epoch  0, batch    18 | loss: 3.1793516MixupTrain:  epoch  0, batch    19 | loss: 4.2573218MixupTrain:  epoch  0, batch    20 | loss: 3.7260365MixupTrain:  epoch  0, batch    21 | loss: 3.6885922MixupTrain:  epoch  0, batch    22 | loss: 4.2309046MixupTrain:  epoch  0, batch    23 | loss: 3.7137065MixupTrain:  epoch  0, batch    24 | loss: 2.7694964MixupTrain:  epoch  0, batch    25 | loss: 4.0256829MixupTrain:  epoch  0, batch    26 | loss: 3.7535200MixupTrain:  epoch  0, batch    27 | loss: 4.0094137MixupTrain:  epoch  0, batch    28 | loss: 2.9731798MixupTrain:  epoch  0, batch    29 | loss: 2.7849345MixupTrain:  epoch  0, batch    30 | loss: 3.9345829MixupTrain:  epoch  0, batch    31 | loss: 3.2524040MixupTrain:  epoch  0, batch    32 | loss: 4.6949940MixupTrain:  epoch  0, batch    33 | loss: 3.8769341MixupTrain:  epoch  0, batch    34 | loss: 3.8778138MixupTrain:  epoch  0, batch    35 | loss: 3.3146515MixupTrain:  epoch  0, batch    36 | loss: 4.6980429MixupTrain:  epoch  0, batch    37 | loss: 3.6651459MixupTrain:  epoch  0, batch    38 | loss: 3.0940952MixupTrain:  epoch  0, batch    39 | loss: 4.1592298MixupTrain:  epoch  0, batch    40 | loss: 3.1161051MixupTrain:  epoch  0, batch    41 | loss: 2.9502869MixupTrain:  epoch  0, batch    42 | loss: 4.1346312MixupTrain:  epoch  0, batch    43 | loss: 3.6586633MixupTrain:  epoch  0, batch    44 | loss: 3.5733900MixupTrain:  epoch  0, batch    45 | loss: 4.1612239MixupTrain:  epoch  0, batch    46 | loss: 3.5346403MixupTrain:  epoch  0, batch    47 | loss: 3.8389635MixupTrain:  epoch  0, batch    48 | loss: 3.2483418MixupTrain:  epoch  0, batch    49 | loss: 3.7108407MixupTrain:  epoch  0, batch    50 | loss: 3.1185727MixupTrain:  epoch  0, batch    51 | loss: 4.2440538MixupTrain:  epoch  0, batch    52 | loss: 3.7547977MixupTrain:  epoch  0, batch    53 | loss: 3.3983951MixupTrain:  epoch  0, batch    54 | loss: 2.8824596MixupTrain:  epoch  0, batch    55 | loss: 3.5187275MixupTrain:  epoch  0, batch    56 | loss: 3.8275576MixupTrain:  epoch  0, batch    57 | loss: 3.1969523MixupTrain:  epoch  0, batch    58 | loss: 2.3449323MixupTrain:  epoch  0, batch    59 | loss: 3.5767615MixupTrain:  epoch  0, batch    60 | loss: 3.9489465MixupTrain:  epoch  0, batch    61 | loss: 3.9891765MixupTrain:  epoch  0, batch    62 | loss: 3.9735837MixupTrain:  epoch  0, batch    63 | loss: 3.7487607MixupTrain:  epoch  0, batch    64 | loss: 3.5839539MixupTrain:  epoch  0, batch    65 | loss: 3.1673963MixupTrain:  epoch  0, batch    66 | loss: 3.7025793MixupTrain:  epoch  0, batch    67 | loss: 3.8226485MixupTrain:  epoch  0, batch    68 | loss: 3.2944865MixupTrain:  epoch  0, batch    69 | loss: 2.7547445MixupTrain:  epoch  0, batch    70 | loss: 3.5084012MixupTrain:  epoch  0, batch    71 | loss: 3.5257866MixupTrain:  epoch  0, batch    72 | loss: 3.7786384MixupTrain:  epoch  0, batch    73 | loss: 2.7794788MixupTrain:  epoch  0, batch    74 | loss: 3.7634165MixupTrain:  epoch  0, batch    75 | loss: 3.6730957MixupTrain:  epoch  0, batch    76 | loss: 3.4840162MixupTrain:  epoch  0, batch    77 | loss: 3.2617421MixupTrain:  epoch  0, batch    78 | loss: 3.5392795MixupTrain:  epoch  0, batch    79 | loss: 4.2281265MixupTrain:  epoch  0, batch    80 | loss: 3.9021060MixupTrain:  epoch  0, batch    81 | loss: 2.7697990MixupTrain:  epoch  0, batch    82 | loss: 2.8916574MixupTrain:  epoch  0, batch    83 | loss: 3.2116575MixupTrain:  epoch  0, batch    84 | loss: 2.2864609MixupTrain:  epoch  0, batch    85 | loss: 3.2009203MixupTrain:  epoch  0, batch    86 | loss: 3.3863783MixupTrain:  epoch  0, batch    87 | loss: 3.0933585MixupTrain:  epoch  0, batch    88 | loss: 3.4315901MixupTrain:  epoch  0, batch    89 | loss: 3.2547452MixupTrain:  epoch  0, batch    90 | loss: 3.7032242MixupTrain:  epoch  0, batch    91 | loss: 3.0009551MixupTrain:  epoch  0, batch    92 | loss: 2.8203411MixupTrain:  epoch  0, batch    93 | loss: 3.1496081MixupTrain:  epoch  0, batch    94 | loss: 3.5655942MixupTrain:  epoch  0, batch    95 | loss: 3.8504114MixupTrain:  epoch  0, batch    96 | loss: 3.4674661MixupTrain:  epoch  0, batch    97 | loss: 2.8646486MixupTrain:  epoch  0, batch    98 | loss: 3.0055263MixupTrain:  epoch  0, batch    99 | loss: 2.8010573MixupTrain:  epoch  0, batch   100 | loss: 2.8651240MixupTrain:  epoch  0, batch   101 | loss: 3.6806731MixupTrain:  epoch  0, batch   102 | loss: 2.4772162MixupTrain:  epoch  0, batch   103 | loss: 3.2737961MixupTrain:  epoch  0, batch   104 | loss: 3.1966434MixupTrain:  epoch  0, batch   105 | loss: 3.0607233MixupTrain:  epoch  0, batch   106 | loss: 3.3238473MixupTrain:  epoch  0, batch   107 | loss: 2.8010087MixupTrain:  epoch  0, batch   108 | loss: 3.4580190MixupTrain:  epoch  0, batch   109 | loss: 3.6574495MixupTrain:  epoch  0, batch   110 | loss: 2.4729218MixupTrain:  epoch  0, batch   111 | loss: 3.2123566MixupTrain:  epoch  0, batch   112 | loss: 2.5757031MixupTrain:  epoch  0, batch   113 | loss: 2.9419813MixupTrain:  epoch  0, batch   114 | loss: 3.5465295MixupTrain:  epoch  0, batch   115 | loss: 3.2277930MixupTrain:  epoch  0, batch   116 | loss: 3.5822210MixupTrain:  epoch  0, batch   117 | loss: 2.8315940MixupTrain:  epoch  0, batch   118 | loss: 2.1233277MixupTrain:  epoch  0, batch   119 | loss: 2.9346070MixupTrain:  epoch  0, batch   120 | loss: 2.8953967MixupTrain:  epoch  0, batch   121 | loss: 2.8208323MixupTrain:  epoch  0, batch   122 | loss: 2.7507765MixupTrain:  epoch  0, batch   123 | loss: 3.3573325MixupTrain:  epoch  0, batch   124 | loss: 3.0388646MixupTrain:  epoch  0, batch   125 | loss: 3.2505488MixupTrain:  epoch  0, batch   126 | loss: 3.5474083MixupTrain:  epoch  0, batch   127 | loss: 3.1968675MixupTrain:  epoch  0, batch   128 | loss: 3.0661678MixupTrain:  epoch  0, batch   129 | loss: 3.1336222MixupTrain:  epoch  0, batch   130 | loss: 3.6622486MixupTrain:  epoch  0, batch   131 | loss: 3.2945385MixupTrain:  epoch  0, batch   132 | loss: 3.4384151MixupTrain:  epoch  0, batch   133 | loss: 3.6099060MixupTrain:  epoch  0, batch   134 | loss: 2.9166861MixupTrain:  epoch  0, batch   135 | loss: 2.5952933MixupTrain:  epoch  0, batch   136 | loss: 2.8186510MixupTrain:  epoch  0, batch   137 | loss: 2.8300729MixupTrain:  epoch  0, batch   138 | loss: 3.5396917MixupTrain:  epoch  0, batch   139 | loss: 3.4106588MixupTrain:  epoch  0, batch   140 | loss: 2.0319765MixupTrain:  epoch  0, batch   141 | loss: 3.3987763MixupTrain:  epoch  0, batch   142 | loss: 3.0799928MixupTrain:  epoch  0, batch   143 | loss: 2.7380114MixupTrain:  epoch  0, batch   144 | loss: 4.5750999MixupTrain:  epoch  0, batch   145 | loss: 2.5604382MixupTrain:  epoch  0, batch   146 | loss: 3.1500082MixupTrain:  epoch  0, batch   147 | loss: 2.8290820MixupTrain:  epoch  0, batch   148 | loss: 3.0542576MixupTrain:  epoch  0, batch   149 | loss: 3.8144641MixupTrain:  epoch  0, batch   150 | loss: 3.2990451MixupTrain:  epoch  0, batch   151 | loss: 3.5108283MixupTrain:  epoch  0, batch   152 | loss: 2.9245977MixupTrain:  epoch  0, batch   153 | loss: 2.8137584MixupTrain:  epoch  0, batch   154 | loss: 3.3018320MixupTrain:  epoch  0, batch   155 | loss: 2.6954350MixupTrain:  epoch  0, batch   156 | loss: 2.9284997MixupTrain:  epoch  0, batch   157 | loss: 3.1873603MixupTrain:  epoch  0, batch   158 | loss: 3.3865409MixupTrain:  epoch  0, batch   159 | loss: 3.2650764MixupTrain:  epoch  0, batch   160 | loss: 3.1503611MixupTrain:  epoch  0, batch   161 | loss: 3.8818445MixupTrain:  epoch  0, batch   162 | loss: 3.2418430MixupTrain:  epoch  0, batch   163 | loss: 2.6885970MixupTrain:  epoch  0, batch   164 | loss: 2.8549418MixupTrain:  epoch  0, batch   165 | loss: 2.7568367MixupTrain:  epoch  0, batch   166 | loss: 2.8877044MixupTrain:  epoch  0, batch   167 | loss: 2.4475937MixupTrain:  epoch  0, batch   168 | loss: 3.3350747MixupTrain:  epoch  0, batch   169 | loss: 3.8841221MixupTrain:  epoch  0, batch   170 | loss: 3.0501478MixupTrain:  epoch  0, batch   171 | loss: 2.9595716MixupTrain:  epoch  0, batch   172 | loss: 4.0554376MixupTrain:  epoch  0, batch   173 | loss: 2.7256706MixupTrain:  epoch  0, batch   174 | loss: 3.2866437MixupTrain:  epoch  0, batch   175 | loss: 2.9453173MixupTrain:  epoch  0, batch   176 | loss: 2.6630211MixupTrain:  epoch  0, batch   177 | loss: 3.2250218MixupTrain:  epoch  0, batch   178 | loss: 2.8605461MixupTrain:  epoch  0, batch   179 | loss: 3.1137652MixupTrain:  epoch  0, batch   180 | loss: 3.9417686MixupTrain:  epoch  0, batch   181 | loss: 2.9176455MixupTrain:  epoch  0, batch   182 | loss: 2.5989356MixupTrain:  epoch  0, batch   183 | loss: 2.8171887MixupTrain:  epoch  0, batch   184 | loss: 2.9200931MixupTrain:  epoch  0, batch   185 | loss: 2.7836380MixupTrain:  epoch  0, batch   186 | loss: 2.6857545MixupTrain:  epoch  0, batch   187 | loss: 3.1324444MixupTrain:  epoch  0, batch   188 | loss: 3.9226079MixupTrain:  epoch  0, batch   189 | loss: 2.4985614MixupTrain:  epoch  0, batch   190 | loss: 3.7790270MixupTrain:  epoch  0, batch   191 | loss: 2.7282019MixupTrain:  epoch  0, batch   192 | loss: 3.1725056MixupTrain:  epoch  0, batch   193 | loss: 2.9595137MixupTrain:  epoch  0, batch   194 | loss: 3.4137580MixupTrain:  epoch  0, batch   195 | loss: 3.2416000MixupTrain:  epoch  0, batch   196 | loss: 3.0928564MixupTrain:  epoch  0, batch   197 | loss: 3.8825645MixupTrain:  epoch  0, batch   198 | loss: 3.3561168MixupTrain:  epoch  0, batch   199 | loss: 2.5062747MixupTrain:  epoch  0, batch   200 | loss: 2.5948353MixupTrain:  epoch  0, batch   201 | loss: 2.3079331MixupTrain:  epoch  0, batch   202 | loss: 2.9930086MixupTrain:  epoch  0, batch   203 | loss: 3.5992975MixupTrain:  epoch  0, batch   204 | loss: 2.7913322MixupTrain:  epoch  0, batch   205 | loss: 2.9351673MixupTrain:  epoch  0, batch   206 | loss: 2.6342564MixupTrain:  epoch  0, batch   207 | loss: 2.7504969MixupTrain:  epoch  0, batch   208 | loss: 3.2128282MixupTrain:  epoch  0, batch   209 | loss: 2.6428885MixupTrain:  epoch  0, batch   210 | loss: 3.4288187MixupTrain:  epoch  0, batch   211 | loss: 2.7582030MixupTrain:  epoch  0, batch   212 | loss: 2.9716878MixupTrain:  epoch  0, batch   213 | loss: 2.6339214MixupTrain:  epoch  0, batch   214 | loss: 2.6581354MixupTrain:  epoch  0, batch   215 | loss: 3.6517859MixupTrain:  epoch  0, batch   216 | loss: 2.6021638MixupTrain:  epoch  0, batch   217 | loss: 2.6020527MixupTrain:  epoch  0, batch   218 | loss: 2.3830633MixupTrain:  epoch  0, batch   219 | loss: 3.3926978MixupTrain:  epoch  0, batch   220 | loss: 2.7642891MixupTrain:  epoch  0, batch   221 | loss: 2.9788899MixupTrain:  epoch  0, batch   222 | loss: 2.3599086MixupTrain:  epoch  0, batch   223 | loss: 2.9145391MixupTrain:  epoch  0, batch   224 | loss: 2.3768883MixupTrain:  epoch  0, batch   225 | loss: 2.7469490MixupTrain:  epoch  0, batch   226 | loss: 2.8096652MixupTrain:  epoch  0, batch   227 | loss: 2.6778426MixupTrain:  epoch  0, batch   228 | loss: 3.2780259MixupTrain:  epoch  0, batch   229 | loss: 3.0682082MixupTrain:  epoch  0, batch   230 | loss: 2.6244030MixupTrain:  epoch  0, batch   231 | loss: 2.9209313MixupTrain:  epoch  0, batch   232 | loss: 2.6618004MixupTrain:  epoch  0, batch   233 | loss: 2.5765247MixupTrain:  epoch  0, batch   234 | loss: 3.5611305MixupTrain:  epoch  0, batch   235 | loss: 3.3452582MixupTrain:  epoch  0, batch   236 | loss: 2.9593987MixupTrain:  epoch  0, batch   237 | loss: 2.8804612MixupTrain:  epoch  0, batch   238 | loss: 2.9294660MixupTrain:  epoch  0, batch   239 | loss: 2.8190842MixupTrain:  epoch  0, batch   240 | loss: 2.5961065MixupTrain:  epoch  0, batch   241 | loss: 2.6329560MixupTrain:  epoch  0, batch   242 | loss: 2.8871779MixupTrain:  epoch  0, batch   243 | loss: 3.5681117MixupTrain:  epoch  0, batch   244 | loss: 2.7503605MixupTrain:  epoch  0, batch   245 | loss: 2.5246079MixupTrain:  epoch  0, batch   246 | loss: 2.4616456MixupTrain:  epoch  0, batch   247 | loss: 3.5769649MixupTrain:  epoch  0, batch   248 | loss: 3.0727258MixupTrain:  epoch  0, batch   249 | loss: 2.6057825MixupTrain:  epoch  0, batch   250 | loss: 3.0341434MixupTrain:  epoch  0, batch   251 | loss: 3.3659692MixupTrain:  epoch  0, batch   252 | loss: 3.2964051MixupTrain:  epoch  0, batch   253 | loss: 2.7924519MixupTrain:  epoch  0, batch   254 | loss: 2.9210107MixupTrain:  epoch  0, batch   255 | loss: 3.5781612MixupTrain:  epoch  0, batch   256 | loss: 2.8210590MixupTrain:  epoch  0, batch   257 | loss: 2.7837548MixupTrain:  epoch  0, batch   258 | loss: 3.3209305MixupTrain:  epoch  0, batch   259 | loss: 2.8191695MixupTrain:  epoch  0, batch   260 | loss: 2.8187013MixupTrain:  epoch  0, batch   261 | loss: 3.5730743MixupTrain:  epoch  0, batch   262 | loss: 2.7767897MixupTrain:  epoch  0, batch   263 | loss: 3.0619645MixupTrain:  epoch  0, batch   264 | loss: 2.5130925MixupTrain:  epoch  0, batch   265 | loss: 2.7412674MixupTrain:  epoch  0, batch   266 | loss: 2.3845224MixupTrain:  epoch  0, batch   267 | loss: 2.3338130MixupTrain:  epoch  0, batch   268 | loss: 2.5073271MixupTrain:  epoch  0, batch   269 | loss: 2.5962021MixupTrain:  epoch  0, batch   270 | loss: 3.1533012MixupTrain:  epoch  0, batch   271 | loss: 3.0334692MixupTrain:  epoch  0, batch   272 | loss: 2.5748084MixupTrain:  epoch  0, batch   273 | loss: 2.4809084MixupTrain:  epoch  0, batch   274 | loss: 3.3819022MixupTrain:  epoch  0, batch   275 | loss: 2.6472232MixupTrain:  epoch  0, batch   276 | loss: 3.1367185MixupTrain:  epoch  0, batch   277 | loss: 2.8709893MixupTrain:  epoch  0, batch   278 | loss: 3.0278387MixupTrain:  epoch  0, batch   279 | loss: 2.8991330MixupTrain:  epoch  0, batch   280 | loss: 2.8286092MixupTrain:  epoch  0, batch   281 | loss: 2.7839286MixupTrain:  epoch  0, batch   282 | loss: 3.0169284MixupTrain:  epoch  0, batch   283 | loss: 3.5143859MixupTrain:  epoch  0, batch   284 | loss: 2.4505033MixupTrain:  epoch  0, batch   285 | loss: 2.9795473MixupTrain:  epoch  0, batch   286 | loss: 3.4879389MixupTrain:  epoch  0, batch   287 | loss: 3.0746851MixupTrain:  epoch  0, batch   288 | loss: 3.2256765MixupTrain:  epoch  0, batch   289 | loss: 3.0907719MixupTrain:  epoch  0, batch   290 | loss: 3.2875452MixupTrain:  epoch  0, batch   291 | loss: 2.6138902MixupTrain:  epoch  0, batch   292 | loss: 2.7889967MixupTrain:  epoch  0, batch   293 | loss: 2.9018664MixupTrain:  epoch  0, batch   294 | loss: 2.8044553MixupTrain:  epoch  0, batch   295 | loss: 2.9804144MixupTrain:  epoch  0, batch   296 | loss: 2.8081067MixupTrain:  epoch  0, batch   297 | loss: 3.6305497MixupTrain:  epoch  0, batch   298 | loss: 3.0743406MixupTrain:  epoch  0, batch   299 | loss: 3.1326189MixupTrain:  epoch  0, batch   300 | loss: 2.7887337MixupTrain:  epoch  0, batch   301 | loss: 3.1135693MixupTrain:  epoch  0, batch   302 | loss: 2.7289145MixupTrain:  epoch  0, batch   303 | loss: 2.7819488MixupTrain:  epoch  0, batch   304 | loss: 3.2846682MixupTrain:  epoch  0, batch   305 | loss: 2.2697308MixupTrain:  epoch  0, batch   306 | loss: 3.3517804MixupTrain:  epoch  0, batch   307 | loss: 3.0143337MixupTrain:  epoch  0, batch   308 | loss: 2.7094431MixupTrain:  epoch  0, batch   309 | loss: 3.6408482MixupTrain:  epoch  0, batch   310 | loss: 2.9245319MixupTrain:  epoch  0, batch   311 | loss: 2.3948212MixupTrain:  epoch  0, batch   312 | loss: 2.6204281MixupTrain:  epoch  0, batch   313 | loss: 3.0353982MixupTrain:  epoch  0, batch   314 | loss: 2.8124151MixupTrain:  epoch  0, batch   315 | loss: 3.4594679MixupTrain:  epoch  0, batch   316 | loss: 2.7747135MixupTrain:  epoch  0, batch   317 | loss: 2.6955070MixupTrain:  epoch  0, batch   318 | loss: 3.3600106MixupTrain:  epoch  0, batch   319 | loss: 3.1451774MixupTrain:  epoch  0, batch   320 | loss: 3.6368537MixupTrain:  epoch  0, batch   321 | loss: 3.3700402MixupTrain:  epoch  0, batch   322 | loss: 2.8816752MixupTrain:  epoch  0, batch   323 | loss: 3.3124437MixupTrain:  epoch  0, batch   324 | loss: 2.5918911MixupTrain:  epoch  0, batch   325 | loss: 2.8129830MixupTrain:  epoch  0, batch   326 | loss: 2.9004045MixupTrain:  epoch  0, batch   327 | loss: 2.4573460MixupTrain:  epoch  0, batch   328 | loss: 3.6396937MixupTrain:  epoch  0, batch   329 | loss: 2.9852152MixupTrain:  epoch  0, batch   330 | loss: 3.0889583MixupTrain:  epoch  0, batch   331 | loss: 2.8612792MixupTrain:  epoch  0, batch   332 | loss: 3.0036149MixupTrain:  epoch  0, batch   333 | loss: 2.9954596MixupTrain:  epoch  0, batch   334 | loss: 3.3596697MixupTrain:  epoch  0, batch   335 | loss: 1.9818444MixupTrain:  epoch  0, batch   336 | loss: 2.8594337MixupTrain:  epoch  0, batch   337 | loss: 3.3749995MixupTrain:  epoch  0, batch   338 | loss: 2.5377965MixupTrain:  epoch  0, batch   339 | loss: 2.4019637MixupTrain:  epoch  0, batch   340 | loss: 3.0547976MixupTrain:  epoch  0, batch   341 | loss: 2.8204455MixupTrain:  epoch  0, batch   342 | loss: 2.8403890MixupTrain:  epoch  0, batch   343 | loss: 2.9819570MixupTrain:  epoch  0, batch   344 | loss: 2.7604661MixupTrain:  epoch  0, batch   345 | loss: 3.1410441MixupTrain:  epoch  0, batch   346 | loss: 2.9438858MixupTrain:  epoch  0, batch   347 | loss: 3.3875837MixupTrain:  epoch  0, batch   348 | loss: 2.6720920MixupTrain:  epoch  0, batch   349 | loss: 2.7462454MixupTrain:  epoch  0, batch   350 | loss: 2.9434965MixupTrain:  epoch  0, batch   351 | loss: 2.4331312MixupTrain:  epoch  0, batch   352 | loss: 2.6781592MixupTrain:  epoch  0, batch   353 | loss: 2.2807302MixupTrain:  epoch  0, batch   354 | loss: 2.7311268MixupTrain:  epoch  0, batch   355 | loss: 2.9272349MixupTrain:  epoch  0, batch   356 | loss: 3.0518286MixupTrain:  epoch  0, batch   357 | loss: 2.8895822MixupTrain:  epoch  0, batch   358 | loss: 2.9029078MixupTrain:  epoch  0, batch   359 | loss: 3.3179083MixupTrain:  epoch  0, batch   360 | loss: 2.6281040MixupTrain:  epoch  0, batch   361 | loss: 2.1755092MixupTrain:  epoch  0, batch   362 | loss: 3.2896004MixupTrain:  epoch  0, batch   363 | loss: 3.3192258MixupTrain:  epoch  0, batch   364 | loss: 2.3587549MixupTrain:  epoch  0, batch   365 | loss: 2.6267285MixupTrain:  epoch  0, batch   366 | loss: 2.3868446MixupTrain:  epoch  0, batch   367 | loss: 2.5618336MixupTrain:  epoch  0, batch   368 | loss: 2.5598354MixupTrain:  epoch  0, batch   369 | loss: 2.8400064MixupTrain:  epoch  0, batch   370 | loss: 2.8650370MixupTrain:  epoch  0, batch   371 | loss: 2.8566635MixupTrain:  epoch  0, batch   372 | loss: 3.0002618MixupTrain:  epoch  0, batch   373 | loss: 2.5501800MixupTrain:  epoch  0, batch   374 | loss: 2.4615431MixupTrain:  epoch  0, batch   375 | loss: 3.3950729MixupTrain:  epoch  0, batch   376 | loss: 2.8798354MixupTrain:  epoch  0, batch   377 | loss: 2.8087168MixupTrain:  epoch  0, batch   378 | loss: 2.9239926MixupTrain:  epoch  0, batch   379 | loss: 2.8714371MixupTrain:  epoch  0, batch   380 | loss: 2.8858271MixupTrain:  epoch  0, batch   381 | loss: 2.2393169MixupTrain:  epoch  0, batch   382 | loss: 2.6420038MixupTrain:  epoch  0, batch   383 | loss: 2.9556911MixupTrain:  epoch  0, batch   384 | loss: 2.6677771MixupTrain:  epoch  0, batch   385 | loss: 2.6943026MixupTrain:  epoch  0, batch   386 | loss: 3.2073550MixupTrain:  epoch  0, batch   387 | loss: 2.3718033MixupTrain:  epoch  0, batch   388 | loss: 2.8785853MixupTrain:  epoch  0, batch   389 | loss: 2.7509463MixupTrain:  epoch  0, batch   390 | loss: 3.2815499MixupTrain:  epoch  0, batch   391 | loss: 2.6288757MixupTrain:  epoch  0, batch   392 | loss: 2.8981237MixupTrain:  epoch  0, batch   393 | loss: 2.3302197MixupTrain:  epoch  0, batch   394 | loss: 2.6704805MixupTrain:  epoch  0, batch   395 | loss: 3.1457820MixupTrain:  epoch  0, batch   396 | loss: 2.8315477MixupTrain:  epoch  0, batch   397 | loss: 2.5228806MixupTrain:  epoch  0, batch   398 | loss: 2.6823552MixupTrain:  epoch  0, batch   399 | loss: 2.9851084MixupTrain:  epoch  0, batch   400 | loss: 2.4715085MixupTrain:  epoch  0, batch   401 | loss: 3.6037860MixupTrain:  epoch  0, batch   402 | loss: 3.7597830MixupTrain:  epoch  0, batch   403 | loss: 2.2588148MixupTrain:  epoch  0, batch   404 | loss: 2.9046183MixupTrain:  epoch  0, batch   405 | loss: 2.5872159MixupTrain:  epoch  0, batch   406 | loss: 2.7199998MixupTrain:  epoch  0, batch   407 | loss: 3.0003872MixupTrain:  epoch  0, batch   408 | loss: 2.7986135MixupTrain:  epoch  0, batch   409 | loss: 2.4059017MixupTrain:  epoch  0, batch   410 | loss: 3.8620059MixupTrain:  epoch  0, batch   411 | loss: 3.2813036MixupTrain:  epoch  0, batch   412 | loss: 2.9219208MixupTrain:  epoch  0, batch   413 | loss: 2.9956961MixupTrain:  epoch  0, batch   414 | loss: 2.5013065MixupTrain:  epoch  0, batch   415 | loss: 2.5958834MixupTrain:  epoch  0, batch   416 | loss: 2.4012208MixupTrain:  epoch  0, batch   417 | loss: 2.3641071MixupTrain:  epoch  0, batch   418 | loss: 2.9625230MixupTrain:  epoch  0, batch   419 | loss: 3.0147314MixupTrain:  epoch  0, batch   420 | loss: 2.8414187MixupTrain:  epoch  0, batch   421 | loss: 2.8911040MixupTrain:  epoch  0, batch   422 | loss: 2.1902452MixupTrain:  epoch  0, batch   423 | loss: 2.3311658MixupTrain:  epoch  0, batch   424 | loss: 2.3506393MixupTrain:  epoch  0, batch   425 | loss: 2.5576873MixupTrain:  epoch  0, batch   426 | loss: 2.4446168MixupTrain:  epoch  0, batch   427 | loss: 2.4000816MixupTrain:  epoch  0, batch   428 | loss: 2.6187806MixupTrain:  epoch  0, batch   429 | loss: 2.4505849MixupTrain:  epoch  0, batch   430 | loss: 2.6722064MixupTrain:  epoch  0, batch   431 | loss: 2.5798357MixupTrain:  epoch  0, batch   432 | loss: 2.3940618MixupTrain:  epoch  0, batch   433 | loss: 2.6684608MixupTrain:  epoch  0, batch   434 | loss: 2.8471653MixupTrain:  epoch  0, batch   435 | loss: 2.6691637MixupTrain:  epoch  0, batch   436 | loss: 2.8430188MixupTrain:  epoch  0, batch   437 | loss: 3.2722185MixupTrain:  epoch  0, batch   438 | loss: 3.5708416MixupTrain:  epoch  0, batch   439 | loss: 2.9540858MixupTrain:  epoch  0, batch   440 | loss: 2.6833417MixupTrain:  epoch  0, batch   441 | loss: 3.0416751MixupTrain:  epoch  0, batch   442 | loss: 2.2460647MixupTrain:  epoch  0, batch   443 | loss: 2.1367049MixupTrain:  epoch  0, batch   444 | loss: 3.0621614MixupTrain:  epoch  0, batch   445 | loss: 2.9270568MixupTrain:  epoch  0, batch   446 | loss: 2.4184537MixupTrain:  epoch  0, batch   447 | loss: 3.0156426MixupTrain:  epoch  0, batch   448 | loss: 2.6411011MixupTrain:  epoch  0, batch   449 | loss: 2.7520013MixupTrain:  epoch  0, batch   450 | loss: 2.8275428MixupTrain:  epoch  0, batch   451 | loss: 2.9633551MixupTrain:  epoch  0, batch   452 | loss: 3.2249126MixupTrain:  epoch  0, batch   453 | loss: 3.3218956MixupTrain:  epoch  0, batch   454 | loss: 2.4278595MixupTrain:  epoch  0, batch   455 | loss: 2.9212639MixupTrain:  epoch  0, batch   456 | loss: 2.6314161MixupTrain:  epoch  0, batch   457 | loss: 2.4950237MixupTrain:  epoch  0, batch   458 | loss: 3.1829419MixupTrain:  epoch  0, batch   459 | loss: 3.2539155MixupTrain:  epoch  0, batch   460 | loss: 2.5403862MixupTrain:  epoch  0, batch   461 | loss: 2.7419734MixupTrain:  epoch  0, batch   462 | loss: 3.3664370MixupTrain:  epoch  0, batch   463 | loss: 3.1290686MixupTrain:  epoch  0, batch   464 | loss: 2.4255028MixupTrain:  epoch  0, batch   465 | loss: 2.3848569MixupTrain:  epoch  0, batch   466 | loss: 3.1768181MixupTrain:  epoch  0, batch   467 | loss: 2.8062694MixupTrain:  epoch  0, batch   468 | loss: 2.9330285MixupTrain:  epoch  0, batch   469 | loss: 2.7159028MixupTrain:  epoch  0, batch   470 | loss: 2.9962473MixupTrain:  epoch  0, batch   471 | loss: 2.9795866MixupTrain:  epoch  0, batch   472 | loss: 3.1011674MixupTrain:  epoch  0, batch   473 | loss: 3.2018976MixupTrain:  epoch  0, batch   474 | loss: 2.6893978MixupTrain:  epoch  0, batch   475 | loss: 3.2532668MixupTrain:  epoch  0, batch   476 | loss: 3.1574287MixupTrain:  epoch  0, batch   477 | loss: 2.6768816MixupTrain:  epoch  0, batch   478 | loss: 2.8043354MixupTrain:  epoch  0, batch   479 | loss: 2.9037633MixupTrain:  epoch  0, batch   480 | loss: 3.2804127MixupTrain:  epoch  0, batch   481 | loss: 3.1340692MixupTrain:  epoch  0, batch   482 | loss: 3.0778904MixupTrain:  epoch  0, batch   483 | loss: 2.8856688MixupTrain:  epoch  0, batch   484 | loss: 3.7702045MixupTrain:  epoch  0, batch   485 | loss: 3.1703744MixupTrain:  epoch  0, batch   486 | loss: 2.8938696MixupTrain:  epoch  0, batch   487 | loss: 3.0007601MixupTrain:  epoch  0, batch   488 | loss: 2.5035729MixupTrain:  epoch  0, batch   489 | loss: 2.6610651MixupTrain:  epoch  0, batch   490 | loss: 2.3646371MixupTrain:  epoch  0, batch   491 | loss: 3.0639529MixupTrain:  epoch  0, batch   492 | loss: 2.4030857MixupTrain:  epoch  0, batch   493 | loss: 3.0005083MixupTrain:  epoch  0, batch   494 | loss: 2.1260705MixupTrain:  epoch  0, batch   495 | loss: 2.2387395MixupTrain:  epoch  0, batch   496 | loss: 2.7039049MixupTrain:  epoch  0, batch   497 | loss: 2.1783726MixupTrain:  epoch  0, batch   498 | loss: 2.3593726MixupTrain:  epoch  0, batch   499 | loss: 2.2056360MixupTrain:  epoch  0, batch   500 | loss: 1.9935687MixupTrain:  epoch  0, batch   501 | loss: 3.0643170MixupTrain:  epoch  0, batch   502 | loss: 3.1107597MixupTrain:  epoch  0, batch   503 | loss: 2.3961124MixupTrain:  epoch  0, batch   504 | loss: 3.1255932MixupTrain:  epoch  0, batch   505 | loss: 2.4472594MixupTrain:  epoch  0, batch   506 | loss: 2.6541464MixupTrain:  epoch  0, batch   507 | loss: 2.9375982MixupTrain:  epoch  0, batch   508 | loss: 2.7152185MixupTrain:  epoch  0, batch   509 | loss: 2.7379203MixupTrain:  epoch  0, batch   510 | loss: 2.9539230MixupTrain:  epoch  0, batch   511 | loss: 3.3603714MixupTrain:  epoch  0, batch   512 | loss: 3.1280923MixupTrain:  epoch  0, batch   513 | loss: 3.4573240MixupTrain:  epoch  0, batch   514 | loss: 2.4999199MixupTrain:  epoch  0, batch   515 | loss: 2.7092483MixupTrain:  epoch  0, batch   516 | loss: 2.7274709MixupTrain:  epoch  0, batch   517 | loss: 2.6471529MixupTrain:  epoch  0, batch   518 | loss: 2.5612304MixupTrain:  epoch  0, batch   519 | loss: 3.0306637MixupTrain:  epoch  0, batch   520 | loss: 2.7506602MixupTrain:  epoch  0, batch   521 | loss: 3.1123867MixupTrain:  epoch  0, batch   522 | loss: 2.9621887MixupTrain:  epoch  0, batch   523 | loss: 2.4310446MixupTrain:  epoch  0, batch   524 | loss: 2.7339971MixupTrain:  epoch  0, batch   525 | loss: 2.5263946MixupTrain:  epoch  0, batch   526 | loss: 2.7201133MixupTrain:  epoch  0, batch   527 | loss: 3.2296984MixupTrain:  epoch  0, batch   528 | loss: 2.6673245MixupTrain:  epoch  0, batch   529 | loss: 2.7945306MixupTrain:  epoch  0, batch   530 | loss: 3.0240555MixupTrain:  epoch  0, batch   531 | loss: 3.0826156MixupTrain:  epoch  0, batch   532 | loss: 2.4093862MixupTrain:  epoch  0, batch   533 | loss: 2.7337840MixupTrain:  epoch  0, batch   534 | loss: 3.0324259MixupTrain:  epoch  0, batch   535 | loss: 2.5718851MixupTrain:  epoch  0, batch   536 | loss: 2.5845981MixupTrain:  epoch  0, batch   537 | loss: 2.7610345MixupTrain:  epoch  0, batch   538 | loss: 3.1553423MixupTrain:  epoch  0, batch   539 | loss: 2.4573917MixupTrain:  epoch  0, batch   540 | loss: 2.7988074MixupTrain:  epoch  0, batch   541 | loss: 2.7739856MixupTrain:  epoch  0, batch   542 | loss: 2.3643017MixupTrain:  epoch  0, batch   543 | loss: 2.1034553MixupTrain:  epoch  0, batch   544 | loss: 2.6041145MixupTrain:  epoch  0, batch   545 | loss: 2.8498545MixupTrain:  epoch  0, batch   546 | loss: 2.5710745MixupTrain:  epoch  0, batch   547 | loss: 2.8360028MixupTrain:  epoch  0, batch   548 | loss: 2.8242464MixupTrain:  epoch  0, batch   549 | loss: 2.4541245MixupTrain:  epoch  0, batch   550 | loss: 2.5501885MixupTrain:  epoch  0, batch   551 | loss: 3.0460162MixupTrain:  epoch  0, batch   552 | loss: 2.7830963MixupTrain:  epoch  0, batch   553 | loss: 3.1075790MixupTrain:  epoch  0, batch   554 | loss: 2.7049527MixupTrain:  epoch  0, batch   555 | loss: 2.4889987MixupTrain:  epoch  0, batch   556 | loss: 2.6831617MixupTrain:  epoch  0, batch   557 | loss: 2.5951934MixupTrain:  epoch  0, batch   558 | loss: 2.3860426MixupTrain:  epoch  0, batch   559 | loss: 2.9008765MixupTrain:  epoch  0, batch   560 | loss: 2.7368922MixupTrain:  epoch  0, batch   561 | loss: 2.7449353MixupTrain:  epoch  0, batch   562 | loss: 2.6620712MixupTrain:  epoch  0, batch   563 | loss: 3.2730227MixupTrain:  epoch  0, batch   564 | loss: 3.0513124MixupTrain:  epoch  0, batch   565 | loss: 2.5034425MixupTrain:  epoch  0, batch   566 | loss: 3.4224670MixupTrain:  epoch  0, batch   567 | loss: 2.9616308MixupTrain:  epoch  0, batch   568 | loss: 2.2281246MixupTrain:  epoch  0, batch   569 | loss: 2.3003216MixupTrain:  epoch  0, batch   570 | loss: 3.1232638MixupTrain:  epoch  0, batch   571 | loss: 2.9041181MixupTrain:  epoch  0, batch   572 | loss: 2.8603973MixupTrain:  epoch  0, batch   573 | loss: 3.0839949MixupTrain:  epoch  0, batch   574 | loss: 2.9762130MixupTrain:  epoch  0, batch   575 | loss: 2.9476829MixupTrain:  epoch  0, batch   576 | loss: 2.4199712MixupTrain:  epoch  0, batch   577 | loss: 2.6940656MixupTrain:  epoch  0, batch   578 | loss: 2.2871280MixupTrain:  epoch  0, batch   579 | loss: 3.4384987MixupTrain:  epoch  0, batch   580 | loss: 3.1812463MixupTrain:  epoch  0, batch   581 | loss: 2.3626707MixupTrain:  epoch  0, batch   582 | loss: 2.7571206MixupTrain:  epoch  0, batch   583 | loss: 2.9112768MixupTrain:  epoch  0, batch   584 | loss: 2.7636971MixupTrain:  epoch  0, batch   585 | loss: 2.5455883MixupTrain:  epoch  0, batch   586 | loss: 2.5160685MixupTrain:  epoch  0, batch   587 | loss: 2.7815936MixupTrain:  epoch  0, batch   588 | loss: 2.8203402MixupTrain:  epoch  0, batch   589 | loss: 2.4009628MixupTrain:  epoch  0, batch   590 | loss: 2.4908974MixupTrain:  epoch  0, batch   591 | loss: 2.9382200MixupTrain:  epoch  0, batch   592 | loss: 2.4833217MixupTrain:  epoch  0, batch   593 | loss: 2.9787655MixupTrain:  epoch  0, batch   594 | loss: 3.0028362MixupTrain:  epoch  0, batch   595 | loss: 2.9146080MixupTrain:  epoch  0, batch   596 | loss: 2.7105489MixupTrain:  epoch  0, batch   597 | loss: 2.2930536MixupTrain:  epoch  0, batch   598 | loss: 2.5479631MixupTrain:  epoch  0, batch   599 | loss: 2.8387122MixupTrain:  epoch  0, batch   600 | loss: 3.1347671MixupTrain:  epoch  0, batch   601 | loss: 2.3610344MixupTrain:  epoch  0, batch   602 | loss: 2.4317927MixupTrain:  epoch  0, batch   603 | loss: 2.6496792MixupTrain:  epoch  0, batch   604 | loss: 2.7024422MixupTrain:  epoch  0, batch   605 | loss: 2.7389836MixupTrain:  epoch  0, batch   606 | loss: 2.8645446MixupTrain:  epoch  0, batch   607 | loss: 2.8032866MixupTrain:  epoch  0, batch   608 | loss: 2.9124913MixupTrain:  epoch  0, batch   609 | loss: 2.4238057MixupTrain:  epoch  0, batch   610 | loss: 2.1567125MixupTrain:  epoch  0, batch   611 | loss: 2.5593903MixupTrain:  epoch  0, batch   612 | loss: 2.4745097MixupTrain:  epoch  0, batch   613 | loss: 2.8471084MixupTrain:  epoch  0, batch   614 | loss: 2.8401158MixupTrain:  epoch  0, batch   615 | loss: 2.4445868MixupTrain:  epoch  0, batch   616 | loss: 2.9365091MixupTrain:  epoch  0, batch   617 | loss: 2.7446446MixupTrain:  epoch  0, batch   618 | loss: 2.4270844MixupTrain:  epoch  0, batch   619 | loss: 1.9634395MixupTrain:  epoch  0, batch   620 | loss: 2.6898499MixupTrain:  epoch  0, batch   621 | loss: 2.6522493MixupTrain:  epoch  0, batch   622 | loss: 2.8733039MixupTrain:  epoch  0, batch   623 | loss: 2.0835772MixupTrain:  epoch  0, batch   624 | loss: 2.6386402MixupTrain:  epoch  0, batch   625 | loss: 2.7445076MixupTrain:  epoch  0, batch   626 | loss: 2.3983302MixupTrain:  epoch  0, batch   627 | loss: 2.7675123MixupTrain:  epoch  0, batch   628 | loss: 2.9912572MixupTrain:  epoch  0, batch   629 | loss: 3.1066525MixupTrain:  epoch  0, batch   630 | loss: 2.8209548MixupTrain:  epoch  0, batch   631 | loss: 2.5462737MixupTrain:  epoch  0, batch   632 | loss: 2.8959827MixupTrain:  epoch  0, batch   633 | loss: 2.4530880MixupTrain:  epoch  0, batch   634 | loss: 2.9781783MixupTrain:  epoch  0, batch   635 | loss: 2.7763653MixupTrain:  epoch  0, batch   636 | loss: 2.6437373MixupTrain:  epoch  0, batch   637 | loss: 3.0779366MixupTrain:  epoch  0, batch   638 | loss: 2.5725384MixupTrain:  epoch  0, batch   639 | loss: 2.5181458MixupTrain:  epoch  0, batch   640 | loss: 3.1227078MixupTrain:  epoch  0, batch   641 | loss: 2.7601790MixupTrain:  epoch  0, batch   642 | loss: 2.2057624MixupTrain:  epoch  0, batch   643 | loss: 3.1859174MixupTrain:  epoch  0, batch   644 | loss: 2.4254074MixupTrain:  epoch  0, batch   645 | loss: 2.9095998MixupTrain:  epoch  0, batch   646 | loss: 3.1083426MixupTrain:  epoch  0, batch   647 | loss: 2.7929242MixupTrain:  epoch  0, batch   648 | loss: 2.9587412MixupTrain:  epoch  0, batch   649 | loss: 2.7305450MixupTrain:  epoch  0, batch   650 | loss: 3.2378840MixupTrain:  epoch  0, batch   651 | loss: 2.3818169MixupTrain:  epoch  0, batch   652 | loss: 2.4015908MixupTrain:  epoch  0, batch   653 | loss: 2.4204402MixupTrain:  epoch  0, batch   654 | loss: 2.9817379MixupTrain:  epoch  0, batch   655 | loss: 2.5182719MixupTrain:  epoch  0, batch   656 | loss: 3.1332984MixupTrain:  epoch  0, batch   657 | loss: 2.7694736MixupTrain:  epoch  0, batch   658 | loss: 2.7641575MixupTrain:  epoch  0, batch   659 | loss: 2.8717618MixupTrain:  epoch  0, batch   660 | loss: 3.0145082MixupTrain:  epoch  0, batch   661 | loss: 2.6655517MixupTrain:  epoch  0, batch   662 | loss: 2.8591895MixupTrain:  epoch  0, batch   663 | loss: 2.9351995MixupTrain:  epoch  0, batch   664 | loss: 2.8655498MixupTrain:  epoch  0, batch   665 | loss: 2.8209805MixupTrain:  epoch  0, batch   666 | loss: 3.1007166MixupTrain:  epoch  0, batch   667 | loss: 2.8297856MixupTrain:  epoch  0, batch   668 | loss: 2.5593710MixupTrain:  epoch  0, batch   669 | loss: 2.7266037MixupTrain:  epoch  0, batch   670 | loss: 2.3180296MixupTrain:  epoch  0, batch   671 | loss: 2.8874993MixupTrain:  epoch  0, batch   672 | loss: 2.7496951MixupTrain:  epoch  0, batch   673 | loss: 2.3873012MixupTrain:  epoch  0, batch   674 | loss: 2.7152901MixupTrain:  epoch  0, batch   675 | loss: 3.0757213MixupTrain:  epoch  0, batch   676 | loss: 3.1015198MixupTrain:  epoch  0, batch   677 | loss: 2.7620175MixupTrain:  epoch  0, batch   678 | loss: 2.2787070MixupTrain:  epoch  0, batch   679 | loss: 2.7648230MixupTrain:  epoch  0, batch   680 | loss: 2.5639668MixupTrain:  epoch  0, batch   681 | loss: 3.1071460MixupTrain:  epoch  0, batch   682 | loss: 2.8498797MixupTrain:  epoch  0, batch   683 | loss: 2.1117449MixupTrain:  epoch  0, batch   684 | loss: 3.0942354MixupTrain:  epoch  0, batch   685 | loss: 2.9623079MixupTrain:  epoch  0, batch   686 | loss: 3.2810102MixupTrain:  epoch  0, batch   687 | loss: 3.7132950MixupTrain:  epoch  0, batch   688 | loss: 2.8580370MixupTrain:  epoch  0, batch   689 | loss: 2.8400297MixupTrain:  epoch  0, batch   690 | loss: 2.8092492MixupTrain:  epoch  0, batch   691 | loss: 2.8550756MixupTrain:  epoch  0, batch   692 | loss: 2.4892328MixupTrain:  epoch  0, batch   693 | loss: 3.2568235MixupTrain:  epoch  0, batch   694 | loss: 2.7333643MixupTrain:  epoch  0, batch   695 | loss: 3.0543947MixupTrain:  epoch  0, batch   696 | loss: 3.0297756MixupTrain:  epoch  0, batch   697 | loss: 2.3044016MixupTrain:  epoch  0, batch   698 | loss: 2.6123703MixupTrain:  epoch  0, batch   699 | loss: 2.4303463MixupTrain:  epoch  0, batch   700 | loss: 3.0811446MixupTrain:  epoch  0, batch   701 | loss: 2.8962495MixupTrain:  epoch  0, batch   702 | loss: 3.2667212MixupTrain:  epoch  0, batch   703 | loss: 3.0957251MixupTrain:  epoch  0, batch   704 | loss: 2.7240050MixupTrain:  epoch  0, batch   705 | loss: 2.8874650MixupTrain:  epoch  0, batch   706 | loss: 2.8857229MixupTrain:  epoch  0, batch   707 | loss: 2.4779329MixupTrain:  epoch  0, batch   708 | loss: 2.4990211MixupTrain:  epoch  0, batch   709 | loss: 3.4423492MixupTrain:  epoch  0, batch   710 | loss: 2.5637047MixupTrain:  epoch  0, batch   711 | loss: 2.9222798MixupTrain:  epoch  0, batch   712 | loss: 2.7866383MixupTrain:  epoch  0, batch   713 | loss: 3.4353881MixupTrain:  epoch  0, batch   714 | loss: 2.4214175MixupTrain:  epoch  0, batch   715 | loss: 2.5126643MixupTrain:  epoch  0, batch   716 | loss: 2.8425653MixupTrain:  epoch  0, batch   717 | loss: 2.7334807MixupTrain:  epoch  0, batch   718 | loss: 2.6730947MixupTrain:  epoch  0, batch   719 | loss: 2.6245244MixupTrain:  epoch  0, batch   720 | loss: 2.9864852MixupTrain:  epoch  0, batch   721 | loss: 2.8528357MixupTrain:  epoch  0, batch   722 | loss: 2.3326468MixupTrain:  epoch  0, batch   723 | loss: 2.3044636MixupTrain:  epoch  0, batch   724 | loss: 2.7904086MixupTrain:  epoch  0, batch   725 | loss: 2.6213241MixupTrain:  epoch  0, batch   726 | loss: 2.8878551MixupTrain:  epoch  0, batch   727 | loss: 2.8925080MixupTrain:  epoch  0, batch   728 | loss: 2.9453721MixupTrain:  epoch  0, batch   729 | loss: 2.1692171MixupTrain:  epoch  0, batch   730 | loss: 2.7176697MixupTrain:  epoch  0, batch   731 | loss: 2.8873830MixupTrain:  epoch  0, batch   732 | loss: 2.9349892MixupTrain:  epoch  0, batch   733 | loss: 2.6383853MixupTrain:  epoch  0, batch   734 | loss: 3.0570755MixupTrain:  epoch  0, batch   735 | loss: 2.8766835MixupTrain:  epoch  0, batch   736 | loss: 2.8867354MixupTrain:  epoch  0, batch   737 | loss: 2.7680123MixupTrain:  epoch  0, batch   738 | loss: 3.2721243MixupTrain:  epoch  0, batch   739 | loss: 2.5469651MixupTrain:  epoch  0, batch   740 | loss: 2.9151597MixupTrain:  epoch  0, batch   741 | loss: 3.2170110MixupTrain:  epoch  0, batch   742 | loss: 2.5559859MixupTrain:  epoch  0, batch   743 | loss: 3.2981808MixupTrain:  epoch  0, batch   744 | loss: 2.8125291MixupTrain:  epoch  0, batch   745 | loss: 3.2618332MixupTrain:  epoch  0, batch   746 | loss: 2.4349585MixupTrain:  epoch  0, batch   747 | loss: 3.2227364MixupTrain:  epoch  0, batch   748 | loss: 2.3391590MixupTrain:  epoch  0, batch   749 | loss: 2.8143201MixupTrain:  epoch  0, batch   750 | loss: 2.6940327MixupTrain:  epoch  0, batch   751 | loss: 2.7645826MixupTrain:  epoch  0, batch   752 | loss: 3.1281230MixupTrain:  epoch  0, batch   753 | loss: 3.1441197MixupTrain:  epoch  0, batch   754 | loss: 2.7873986MixupTrain:  epoch  0, batch   755 | loss: 2.1700385MixupTrain:  epoch  0, batch   756 | loss: 2.4405751MixupTrain:  epoch  0, batch   757 | loss: 2.9303999MixupTrain:  epoch  0, batch   758 | loss: 2.3570035MixupTrain:  epoch  0, batch   759 | loss: 2.2997208MixupTrain:  epoch  0, batch   760 | loss: 2.7207162MixupTrain:  epoch  0, batch   761 | loss: 2.5737326MixupTrain:  epoch  0, batch   762 | loss: 3.0984356MixupTrain:  epoch  0, batch   763 | loss: 2.7886720MixupTrain:  epoch  0, batch   764 | loss: 2.9555097MixupTrain:  epoch  0, batch   765 | loss: 2.6019306MixupTrain:  epoch  0, batch   766 | loss: 2.6872845MixupTrain:  epoch  0, batch   767 | loss: 2.8973267MixupTrain:  epoch  0, batch   768 | loss: 3.1315966MixupTrain:  epoch  0, batch   769 | loss: 2.2888532MixupTrain:  epoch  0, batch   770 | loss: 2.7988615MixupTrain:  epoch  0, batch   771 | loss: 2.4858241MixupTrain:  epoch  0, batch   772 | loss: 2.5893707MixupTrain:  epoch  0, batch   773 | loss: 2.4273076MixupTrain:  epoch  0, batch   774 | loss: 2.2848957MixupTrain:  epoch  0, batch   775 | loss: 2.5426025MixupTrain:  epoch  0, batch   776 | loss: 2.5336647MixupTrain:  epoch  0, batch   777 | loss: 2.5439358MixupTrain:  epoch  0, batch   778 | loss: 2.5110645MixupTrain:  epoch  0, batch   779 | loss: 2.7197690MixupTrain:  epoch  0, batch   780 | loss: 2.7360916MixupTrain:  epoch  0, batch   781 | loss: 2.8593392MixupTrain:  epoch  0, batch   782 | loss: 2.3121939MixupTrain:  epoch  0, batch   783 | loss: 3.0329456MixupTrain:  epoch  0, batch   784 | loss: 2.9179485MixupTrain:  epoch  0, batch   785 | loss: 3.5192485MixupTrain:  epoch  0, batch   786 | loss: 2.6712508MixupTrain:  epoch  0, batch   787 | loss: 3.1089206MixupTrain:  epoch  0, batch   788 | loss: 2.7468536MixupTrain:  epoch  0, batch   789 | loss: 3.1050119MixupTrain:  epoch  0, batch   790 | loss: 2.1117687MixupTrain:  epoch  0, batch   791 | loss: 2.9434874MixupTrain:  epoch  0, batch   792 | loss: 2.4927838MixupTrain:  epoch  0, batch   793 | loss: 3.0624866MixupTrain:  epoch  0, batch   794 | loss: 2.7648168MixupTrain:  epoch  0, batch   795 | loss: 2.8364778MixupTrain:  epoch  0, batch   796 | loss: 2.6796503MixupTrain:  epoch  0, batch   797 | loss: 2.5418024MixupTrain:  epoch  0, batch   798 | loss: 2.8772056MixupTrain:  epoch  0, batch   799 | loss: 2.7403936MixupTrain:  epoch  0, batch   800 | loss: 2.9443541MixupTrain:  epoch  0, batch   801 | loss: 3.0879211MixupTrain:  epoch  0, batch   802 | loss: 2.8449914MixupTrain:  epoch  0, batch   803 | loss: 2.3717704MixupTrain:  epoch  0, batch   804 | loss: 2.6098557MixupTrain:  epoch  0, batch   805 | loss: 2.5057116MixupTrain:  epoch  0, batch   806 | loss: 3.0161572MixupTrain:  epoch  0, batch   807 | loss: 2.9041889MixupTrain:  epoch  0, batch   808 | loss: 3.0863411MixupTrain:  epoch  0, batch   809 | loss: 3.0605383MixupTrain:  epoch  0, batch   810 | loss: 2.2885230MixupTrain:  epoch  0, batch   811 | loss: 2.8203683MixupTrain:  epoch  0, batch   812 | loss: 2.7338026MixupTrain:  epoch  0, batch   813 | loss: 2.5606370MixupTrain:  epoch  0, batch   814 | loss: 3.2290580MixupTrain:  epoch  0, batch   815 | loss: 2.6008182MixupTrain:  epoch  0, batch   816 | loss: 2.9712062MixupTrain:  epoch  0, batch   817 | loss: 2.8430209MixupTrain:  epoch  0, batch   818 | loss: 2.8711805MixupTrain:  epoch  0, batch   819 | loss: 2.3050089MixupTrain:  epoch  0, batch   820 | loss: 2.2960813MixupTrain:  epoch  0, batch   821 | loss: 3.1642270MixupTrain:  epoch  0, batch   822 | loss: 2.3375103MixupTrain:  epoch  0, batch   823 | loss: 2.7650924MixupTrain:  epoch  0, batch   824 | loss: 2.7838750MixupTrain:  epoch  0, batch   825 | loss: 2.7210262MixupTrain:  epoch  0, batch   826 | loss: 2.5146265MixupTrain:  epoch  0, batch   827 | loss: 3.1845863MixupTrain:  epoch  0, batch   828 | loss: 2.7344313MixupTrain:  epoch  0, batch   829 | loss: 2.4233828MixupTrain:  epoch  0, batch   830 | loss: 2.5377085MixupTrain:  epoch  0, batch   831 | loss: 2.5950754MixupTrain:  epoch  0, batch   832 | loss: 2.6798005MixupTrain:  epoch  0, batch   833 | loss: 2.9299402MixupTrain:  epoch  0, batch   834 | loss: 2.6164513MixupTrain:  epoch  0, batch   835 | loss: 2.6253607MixupTrain:  epoch  0, batch   836 | loss: 2.8421407MixupTrain:  epoch  0, batch   837 | loss: 2.9040341MixupTrain:  epoch  0, batch   838 | loss: 2.9511752MixupTrain:  epoch  0, batch   839 | loss: 2.7439096MixupTrain:  epoch  0, batch   840 | loss: 3.0043333MixupTrain:  epoch  0, batch   841 | loss: 2.6022034MixupTrain:  epoch  0, batch   842 | loss: 3.3359218MixupTrain:  epoch  0, batch   843 | loss: 2.8531947MixupTrain:  epoch  0, batch   844 | loss: 2.8525732MixupTrain:  epoch  0, batch   845 | loss: 2.8040049MixupTrain:  epoch  0, batch   846 | loss: 3.2178569MixupTrain:  epoch  0, batch   847 | loss: 2.5403533MixupTrain:  epoch  0, batch   848 | loss: 2.9745212MixupTrain:  epoch  0, batch   849 | loss: 2.8855209MixupTrain:  epoch  0, batch   850 | loss: 2.8005166MixupTrain:  epoch  0, batch   851 | loss: 2.9359412MixupTrain:  epoch  0, batch   852 | loss: 2.7894068MixupTrain:  epoch  0, batch   853 | loss: 3.0381761MixupTrain:  epoch  0, batch   854 | loss: 2.4964843MixupTrain:  epoch  0, batch   855 | loss: 2.9411085MixupTrain:  epoch  0, batch   856 | loss: 2.7292249MixupTrain:  epoch  0, batch   857 | loss: 2.8111451MixupTrain:  epoch  0, batch   858 | loss: 3.3636405MixupTrain:  epoch  0, batch   859 | loss: 2.3989429MixupTrain:  epoch  0, batch   860 | loss: 2.5899634MixupTrain:  epoch  0, batch   861 | loss: 2.6593280MixupTrain:  epoch  0, batch   862 | loss: 2.3619773MixupTrain:  epoch  0, batch   863 | loss: 2.4111197MixupTrain:  epoch  0, batch   864 | loss: 2.8128467MixupTrain:  epoch  0, batch   865 | loss: 2.7596321MixupTrain:  epoch  0, batch   866 | loss: 2.7633336MixupTrain:  epoch  0, batch   867 | loss: 2.4547031MixupTrain:  epoch  0, batch   868 | loss: 2.6552730MixupTrain:  epoch  0, batch   869 | loss: 2.6216660MixupTrain:  epoch  0, batch   870 | loss: 2.8902555MixupTrain:  epoch  0, batch   871 | loss: 2.1335254MixupTrain:  epoch  0, batch   872 | loss: 2.6089783MixupTrain:  epoch  0, batch   873 | loss: 2.8781676MixupTrain:  epoch  0, batch   874 | loss: 2.6616511MixupTrain:  epoch  0, batch   875 | loss: 2.9893041MixupTrain:  epoch  0, batch   876 | loss: 2.5886378MixupTrain:  epoch  0, batch   877 | loss: 2.8457525MixupTrain:  epoch  0, batch   878 | loss: 3.1609755MixupTrain:  epoch  0, batch   879 | loss: 3.0939951MixupTrain:  epoch  0, batch   880 | loss: 2.8996661MixupTrain:  epoch  0, batch   881 | loss: 2.8388724MixupTrain:  epoch  0, batch   882 | loss: 2.7410421MixupTrain:  epoch  0, batch   883 | loss: 3.4377813MixupTrain:  epoch  0, batch   884 | loss: 3.0207407MixupTrain:  epoch  0, batch   885 | loss: 2.5664153MixupTrain:  epoch  0, batch   886 | loss: 2.3747718MixupTrain:  epoch  0, batch   887 | loss: 3.2922220MixupTrain:  epoch  0, batch   888 | loss: 2.4374344MixupTrain:  epoch  0, batch   889 | loss: 2.5148664MixupTrain:  epoch  0, batch   890 | loss: 2.7447047MixupTrain:  epoch  0, batch   891 | loss: 2.7827735MixupTrain:  epoch  0, batch   892 | loss: 2.2793260MixupTrain:  epoch  0, batch   893 | loss: 2.5708899MixupTrain:  epoch  0, batch   894 | loss: 2.6576447MixupTrain:  epoch  0, batch   895 | loss: 2.8540277MixupTrain:  epoch  0, batch   896 | loss: 2.8395386MixupTrain:  epoch  0, batch   897 | loss: 3.0062780MixupTrain:  epoch  0, batch   898 | loss: 2.3930840MixupTrain:  epoch  0, batch   899 | loss: 2.8223121MixupTrain:  epoch  0, batch   900 | loss: 2.4652219MixupTrain:  epoch  0, batch   901 | loss: 2.9096045MixupTrain:  epoch  0, batch   902 | loss: 3.1367652MixupTrain:  epoch  0, batch   903 | loss: 2.9505172MixupTrain:  epoch  0, batch   904 | loss: 2.8873894MixupTrain:  epoch  0, batch   905 | loss: 2.4734907MixupTrain:  epoch  0, batch   906 | loss: 2.5266881MixupTrain:  epoch  0, batch   907 | loss: 2.8375397MixupTrain:  epoch  0, batch   908 | loss: 2.6628110MixupTrain:  epoch  0, batch   909 | loss: 3.2701113MixupTrain:  epoch  0, batch   910 | loss: 2.8798900MixupTrain:  epoch  0, batch   911 | loss: 2.5296316MixupTrain:  epoch  0, batch   912 | loss: 2.5192654MixupTrain:  epoch  0, batch   913 | loss: 3.0696125MixupTrain:  epoch  0, batch   914 | loss: 2.5866709MixupTrain:  epoch  0, batch   915 | loss: 2.4670410MixupTrain:  epoch  0, batch   916 | loss: 2.8592815MixupTrain:  epoch  0, batch   917 | loss: 2.6410885MixupTrain:  epoch  0, batch   918 | loss: 2.7027185MixupTrain:  epoch  0, batch   919 | loss: 2.1265903MixupTrain:  epoch  0, batch   920 | loss: 2.7160265MixupTrain:  epoch  0, batch   921 | loss: 2.6422834MixupTrain:  epoch  0, batch   922 | loss: 2.5969503MixupTrain:  epoch  0, batch   923 | loss: 3.0082355MixupTrain:  epoch  0, batch   924 | loss: 3.2641530MixupTrain:  epoch  0, batch   925 | loss: 2.4296937MixupTrain:  epoch  0, batch   926 | loss: 2.6339231MixupTrain:  epoch  0, batch   927 | loss: 2.7169790MixupTrain:  epoch  0, batch   928 | loss: 2.7831306MixupTrain:  epoch  0, batch   929 | loss: 2.9924717MixupTrain:  epoch  0, batch   930 | loss: 2.6396155MixupTrain:  epoch  0, batch   931 | loss: 3.0626254MixupTrain:  epoch  0, batch   932 | loss: 2.3941603MixupTrain:  epoch  0, batch   933 | loss: 2.8920274MixupTrain:  epoch  0, batch   934 | loss: 2.8271363MixupTrain:  epoch  0, batch   935 | loss: 2.1453543MixupTrain:  epoch  0, batch   936 | loss: 2.5846262MixupTrain:  epoch  0, batch   937 | loss: 2.5997972MixupTrain:  epoch  0, batch   938 | loss: 2.4325833MixupTrain:  epoch  0, batch   939 | loss: 2.0831676MixupTrain:  epoch  0, batch   940 | loss: 2.8782248MixupTrain:  epoch  0, batch   941 | loss: 2.3741839MixupTrain:  epoch  0, batch   942 | loss: 3.3497677MixupTrain:  epoch  0, batch   943 | loss: 2.8736026MixupTrain:  epoch  0, batch   944 | loss: 2.9554338MixupTrain:  epoch  0, batch   945 | loss: 2.6458602MixupTrain:  epoch  0, batch   946 | loss: 2.2657807MixupTrain:  epoch  0, batch   947 | loss: 3.2065024MixupTrain:  epoch  0, batch   948 | loss: 2.7327557MixupTrain:  epoch  0, batch   949 | loss: 2.3557363MixupTrain:  epoch  0, batch   950 | loss: 2.4959874MixupTrain:  epoch  0, batch   951 | loss: 2.7735777MixupTrain:  epoch  0, batch   952 | loss: 2.8439693MixupTrain:  epoch  0, batch   953 | loss: 2.7567315MixupTrain:  epoch  0, batch   954 | loss: 2.6385405MixupTrain:  epoch  0, batch   955 | loss: 2.3187137MixupTrain:  epoch  0, batch   956 | loss: 2.3381550MixupTrain:  epoch  0, batch   957 | loss: 2.7052205MixupTrain:  epoch  0, batch   958 | loss: 2.8319070MixupTrain:  epoch  0, batch   959 | loss: 2.5210316MixupTrain:  epoch  0, batch   960 | loss: 2.6495826MixupTrain:  epoch  0, batch   961 | loss: 3.4265060MixupTrain:  epoch  0, batch   962 | loss: 3.0507238MixupTrain:  epoch  0, batch   963 | loss: 2.6211500MixupTrain:  epoch  0, batch   964 | loss: 2.7581234MixupTrain:  epoch  0, batch   965 | loss: 2.5606465MixupTrain:  epoch  0, batch   966 | loss: 2.9374986MixupTrain:  epoch  0, batch   967 | loss: 2.6236525MixupTrain:  epoch  0, batch   968 | loss: 2.1594322MixupTrain:  epoch  0, batch   969 | loss: 2.2475648MixupTrain:  epoch  0, batch   970 | loss: 2.5287900MixupTrain:  epoch  0, batch   971 | loss: 2.7581921MixupTrain:  epoch  0, batch   972 | loss: 2.8384314MixupTrain:  epoch  0, batch   973 | loss: 2.8695345MixupTrain:  epoch  0, batch   974 | loss: 2.2522690MixupTrain:  epoch  0, batch   975 | loss: 2.7518098MixupTrain:  epoch  0, batch   976 | loss: 2.2653310MixupTrain:  epoch  0, batch   977 | loss: 2.5373402MixupTrain:  epoch  0, batch   978 | loss: 2.9642715MixupTrain:  epoch  0, batch   979 | loss: 2.7909408MixupTrain:  epoch  0, batch   980 | loss: 2.8372242MixupTrain:  epoch  0, batch   981 | loss: 2.9031332MixupTrain:  epoch  0, batch   982 | loss: 2.8577099MixupTrain:  epoch  0, batch   983 | loss: 2.6397753MixupTrain:  epoch  0, batch   984 | loss: 2.8596692MixupTrain:  epoch  0, batch   985 | loss: 3.1554151MixupTrain:  epoch  0, batch   986 | loss: 2.8963082MixupTrain:  epoch  0, batch   987 | loss: 2.7963901MixupTrain:  epoch  0, batch   988 | loss: 2.9568248MixupTrain:  epoch  0, batch   989 | loss: 2.7734113MixupTrain:  epoch  0, batch   990 | loss: 2.6653488MixupTrain:  epoch  0, batch   991 | loss: 2.6346011MixupTrain:  epoch  0, batch   992 | loss: 2.9554729MixupTrain:  epoch  0, batch   993 | loss: 2.5258272MixupTrain:  epoch  0, batch   994 | loss: 3.0363731MixupTrain:  epoch  0, batch   995 | loss: 2.9409976MixupTrain:  epoch  0, batch   996 | loss: 2.9072373MixupTrain:  epoch  0, batch   997 | loss: 2.9536273MixupTrain:  epoch  0, batch   998 | loss: 2.4722033MixupTrain:  epoch  0, batch   999 | loss: 2.8543224MixupTrain:  epoch  0, batch  1000 | loss: 2.8471999MixupTrain:  epoch  0, batch  1001 | loss: 2.0806818MixupTrain:  epoch  0, batch  1002 | loss: 2.6333108MixupTrain:  epoch  0, batch  1003 | loss: 2.9058371MixupTrain:  epoch  0, batch  1004 | loss: 2.5717313MixupTrain:  epoch  0, batch  1005 | loss: 2.7614009MixupTrain:  epoch  0, batch  1006 | loss: 3.0873365MixupTrain:  epoch  0, batch  1007 | loss: 2.7110114MixupTrain:  epoch  0, batch  1008 | loss: 2.5001578MixupTrain:  epoch  0, batch  1009 | loss: 2.7826080MixupTrain:  epoch  0, batch  1010 | loss: 2.5538061MixupTrain:  epoch  0, batch  1011 | loss: 2.5047221MixupTrain:  epoch  0, batch  1012 | loss: 2.9175351MixupTrain:  epoch  0, batch  1013 | loss: 2.9692791MixupTrain:  epoch  0, batch  1014 | loss: 2.9206080MixupTrain:  epoch  0, batch  1015 | loss: 2.3594055MixupTrain:  epoch  0, batch  1016 | loss: 2.5709527MixupTrain:  epoch  0, batch  1017 | loss: 2.3112206MixupTrain:  epoch  0, batch  1018 | loss: 2.4669948MixupTrain:  epoch  0, batch  1019 | loss: 2.7106085MixupTrain:  epoch  0, batch  1020 | loss: 2.7578068MixupTrain:  epoch  0, batch  1021 | loss: 2.6114407MixupTrain:  epoch  0, batch  1022 | loss: 2.3150039MixupTrain:  epoch  0, batch  1023 | loss: 2.4200075MixupTrain:  epoch  0, batch  1024 | loss: 2.5977149MixupTrain:  epoch  0, batch  1025 | loss: 3.1023822MixupTrain:  epoch  0, batch  1026 | loss: 2.1757174MixupTrain:  epoch  0, batch  1027 | loss: 2.5436258MixupTrain:  epoch  0, batch  1028 | loss: 2.4041777MixupTrain:  epoch  0, batch  1029 | loss: 2.4141560MixupTrain:  epoch  0, batch  1030 | loss: 2.8399017MixupTrain:  epoch  0, batch  1031 | loss: 2.9237325MixupTrain:  epoch  0, batch  1032 | loss: 2.6736393MixupTrain:  epoch  0, batch  1033 | loss: 2.6958282MixupTrain:  epoch  0, batch  1034 | loss: 2.6214197MixupTrain:  epoch  0, batch  1035 | loss: 2.6130097MixupTrain:  epoch  0, batch  1036 | loss: 2.9353621MixupTrain:  epoch  0, batch  1037 | loss: 2.6287322MixupTrain:  epoch  0, batch  1038 | loss: 2.9083695MixupTrain:  epoch  0, batch  1039 | loss: 2.4417315MixupTrain:  epoch  0, batch  1040 | loss: 2.5840714MixupTrain:  epoch  0, batch  1041 | loss: 2.5881169MixupTrain:  epoch  0, batch  1042 | loss: 2.7346859MixupTrain:  epoch  0, batch  1043 | loss: 2.3452609MixupTrain:  epoch  0, batch  1044 | loss: 2.6793075MixupTrain:  epoch  0, batch  1045 | loss: 2.9273820MixupTrain:  epoch  0, batch  1046 | loss: 2.5503688MixupTrain:  epoch  0, batch  1047 | loss: 2.2701719MixupTrain:  epoch  0, batch  1048 | loss: 3.0254669MixupTrain:  epoch  0, batch  1049 | loss: 2.7936983MixupTrain:  epoch  0, batch  1050 | loss: 2.6257522MixupTrain:  epoch  0, batch  1051 | loss: 2.8710196MixupTrain:  epoch  0, batch  1052 | loss: 2.8096647MixupTrain:  epoch  0, batch  1053 | loss: 3.1918352MixupTrain:  epoch  0, batch  1054 | loss: 2.5660717MixupTrain:  epoch  0, batch  1055 | loss: 2.8671560MixupTrain:  epoch  0, batch  1056 | loss: 2.4501595MixupTrain:  epoch  0, batch  1057 | loss: 2.4793882MixupTrain:  epoch  0, batch  1058 | loss: 2.6475425MixupTrain:  epoch  0, batch  1059 | loss: 3.0285716MixupTrain:  epoch  0, batch  1060 | loss: 2.9478917MixupTrain:  epoch  0, batch  1061 | loss: 2.5921419MixupTrain:  epoch  0, batch  1062 | loss: 2.9522581MixupTrain:  epoch  0, batch  1063 | loss: 2.1919758MixupTrain:  epoch  0, batch  1064 | loss: 2.8206563MixupTrain:  epoch  0, batch  1065 | loss: 2.1564798MixupTrain:  epoch  0, batch  1066 | loss: 2.6848593MixupTrain:  epoch  0, batch  1067 | loss: 2.4227440MixupTrain:  epoch  0, batch  1068 | loss: 2.7416697MixupTrain:  epoch  0, batch  1069 | loss: 2.5901763MixupTrain:  epoch  0, batch  1070 | loss: 2.2129152MixupTrain:  epoch  0, batch  1071 | loss: 3.2669253MixupTrain:  epoch  0, batch  1072 | loss: 2.3158154MixupTrain:  epoch  0, batch  1073 | loss: 2.7984414MixupTrain:  epoch  0, batch  1074 | loss: 2.9120035MixupTrain:  epoch  0, batch  1075 | loss: 2.5675159MixupTrain:  epoch  0, batch  1076 | loss: 2.7170160MixupTrain:  epoch  0, batch  1077 | loss: 2.5352974MixupTrain:  epoch  0, batch  1078 | loss: 2.5182920MixupTrain:  epoch  0, batch  1079 | loss: 2.3758156MixupTrain:  epoch  0, batch  1080 | loss: 2.2506621MixupTrain:  epoch  0, batch  1081 | loss: 2.4571433MixupTrain:  epoch  0, batch  1082 | loss: 2.6371760MixupTrain:  epoch  0, batch  1083 | loss: 2.3941646MixupTrain:  epoch  0, batch  1084 | loss: 2.5101094MixupTrain:  epoch  0, batch  1085 | loss: 2.7008345MixupTrain:  epoch  0, batch  1086 | loss: 2.1551230MixupTrain:  epoch  0, batch  1087 | loss: 2.2466869MixupTrain:  epoch  0, batch  1088 | loss: 2.3144605MixupTrain:  epoch  0, batch  1089 | loss: 2.4452403MixupTrain:  epoch  0, batch  1090 | loss: 2.7280514MixupTrain:  epoch  0, batch  1091 | loss: 2.5799119MixupTrain:  epoch  0, batch  1092 | loss: 2.4018111MixupTrain:  epoch  0, batch  1093 | loss: 3.0455217MixupTrain:  epoch  0, batch  1094 | loss: 2.6329551MixupTrain:  epoch  0, batch  1095 | loss: 2.6265864MixupTrain:  epoch  0, batch  1096 | loss: 2.9126112MixupTrain:  epoch  0, batch  1097 | loss: 3.3348699MixupTrain:  epoch  0, batch  1098 | loss: 2.6513758MixupTrain:  epoch  0, batch  1099 | loss: 2.5695777MixupTrain:  epoch  0, batch  1100 | loss: 2.4183626MixupTrain:  epoch  0, batch  1101 | loss: 2.8397448MixupTrain:  epoch  0, batch  1102 | loss: 2.6719522MixupTrain:  epoch  0, batch  1103 | loss: 2.5286591MixupTrain:  epoch  0, batch  1104 | loss: 2.1529162MixupTrain:  epoch  0, batch  1105 | loss: 2.6665268MixupTrain:  epoch  0, batch  1106 | loss: 2.5425169MixupTrain:  epoch  0, batch  1107 | loss: 3.4600816MixupTrain:  epoch  0, batch  1108 | loss: 2.8423285MixupTrain:  epoch  0, batch  1109 | loss: 2.3715925MixupTrain:  epoch  0, batch  1110 | loss: 2.6235628MixupTrain:  epoch  0, batch  1111 | loss: 2.8276191MixupTrain:  epoch  0, batch  1112 | loss: 2.9043612MixupTrain:  epoch  0, batch  1113 | loss: 2.9161673MixupTrain:  epoch  0, batch  1114 | loss: 2.8424678MixupTrain:  epoch  0, batch  1115 | loss: 3.5016344MixupTrain:  epoch  0, batch  1116 | loss: 3.2279873MixupTrain:  epoch  0, batch  1117 | loss: 2.8018229MixupTrain:  epoch  0, batch  1118 | loss: 2.6111701MixupTrain:  epoch  0, batch  1119 | loss: 2.5978813MixupTrain:  epoch  0, batch  1120 | loss: 2.9500093MixupTrain:  epoch  0, batch  1121 | loss: 2.8505468MixupTrain:  epoch  0, batch  1122 | loss: 2.7470386MixupTrain:  epoch  0, batch  1123 | loss: 2.5891466MixupTrain:  epoch  0, batch  1124 | loss: 2.2930830MixupTrain:  epoch  0, batch  1125 | loss: 2.6203663MixupTrain:  epoch  0, batch  1126 | loss: 2.4190192MixupTrain:  epoch  0, batch  1127 | loss: 2.7358479MixupTrain:  epoch  0, batch  1128 | loss: 2.3136673MixupTrain:  epoch  0, batch  1129 | loss: 2.4254622MixupTrain:  epoch  0, batch  1130 | loss: 2.4254425MixupTrain:  epoch  0, batch  1131 | loss: 2.6649551MixupTrain:  epoch  0, batch  1132 | loss: 2.6442900MixupTrain:  epoch  0, batch  1133 | loss: 2.4776096MixupTrain:  epoch  0, batch  1134 | loss: 2.3689454MixupTrain:  epoch  0, batch  1135 | loss: 2.5190279MixupTrain:  epoch  0, batch  1136 | loss: 3.1646156MixupTrain:  epoch  0, batch  1137 | loss: 2.6850309MixupTrain:  epoch  0, batch  1138 | loss: 2.6914895MixupTrain:  epoch  0, batch  1139 | loss: 2.7359004MixupTrain:  epoch  0, batch  1140 | loss: 2.4693282MixupTrain:  epoch  0, batch  1141 | loss: 2.0571399MixupTrain:  epoch  0, batch  1142 | loss: 2.8169103MixupTrain:  epoch  0, batch  1143 | loss: 2.6055155MixupTrain:  epoch  0, batch  1144 | loss: 2.8821418MixupTrain:  epoch  0, batch  1145 | loss: 2.7537279MixupTrain:  epoch  0, batch  1146 | loss: 2.7715497MixupTrain:  epoch  0, batch  1147 | loss: 2.3873518MixupTrain:  epoch  0, batch  1148 | loss: 2.3934236MixupTrain:  epoch  0, batch  1149 | loss: 2.6262755MixupTrain:  epoch  0, batch  1150 | loss: 3.0940282MixupTrain:  epoch  0, batch  1151 | loss: 2.3575301MixupTrain:  epoch  0, batch  1152 | loss: 3.0327001MixupTrain:  epoch  0, batch  1153 | loss: 3.4667413MixupTrain:  epoch  0, batch  1154 | loss: 2.6218963MixupTrain:  epoch  0, batch  1155 | loss: 3.3517799MixupTrain:  epoch  0, batch  1156 | loss: 2.6661506MixupTrain:  epoch  0, batch  1157 | loss: 2.6894486MixupTrain:  epoch  0, batch  1158 | loss: 3.1074185MixupTrain:  epoch  0, batch  1159 | loss: 2.5021250MixupTrain:  epoch  0, batch  1160 | loss: 3.1893985MixupTrain:  epoch  0, batch  1161 | loss: 2.6337681MixupTrain:  epoch  0, batch  1162 | loss: 2.8918037MixupTrain:  epoch  0, batch  1163 | loss: 2.7053227MixupTrain:  epoch  0, batch  1164 | loss: 2.4128966MixupTrain:  epoch  0, batch  1165 | loss: 2.6191411MixupTrain:  epoch  0, batch  1166 | loss: 3.2503209MixupTrain:  epoch  0, batch  1167 | loss: 2.5057969MixupTrain:  epoch  0, batch  1168 | loss: 3.5914495MixupTrain:  epoch  0, batch  1169 | loss: 2.4384537MixupTrain:  epoch  0, batch  1170 | loss: 2.6140661MixupTrain:  epoch  0, batch  1171 | loss: 2.4613118MixupTrain:  epoch  0, batch  1172 | loss: 2.8367441MixupTrain:  epoch  0, batch  1173 | loss: 2.3673034MixupTrain:  epoch  0, batch  1174 | loss: 2.4621978MixupTrain:  epoch  0, batch  1175 | loss: 2.8970747MixupTrain:  epoch  0, batch  1176 | loss: 2.4037023MixupTrain:  epoch  0, batch  1177 | loss: 2.8396745MixupTrain:  epoch  0, batch  1178 | loss: 2.8904648MixupTrain:  epoch  0, batch  1179 | loss: 2.5949283MixupTrain:  epoch  0, batch  1180 | loss: 2.8650665MixupTrain:  epoch  0, batch  1181 | loss: 2.7502537MixupTrain:  epoch  0, batch  1182 | loss: 2.7951999MixupTrain:  epoch  0, batch  1183 | loss: 2.5087695MixupTrain:  epoch  0, batch  1184 | loss: 2.8045790MixupTrain:  epoch  0, batch  1185 | loss: 2.2028215MixupTrain:  epoch  0, batch  1186 | loss: 2.5222068MixupTrain:  epoch  0, batch  1187 | loss: 2.6579199MixupTrain:  epoch  0, batch  1188 | loss: 2.6035423MixupTrain:  epoch  0, batch  1189 | loss: 2.8150442MixupTrain:  epoch  0, batch  1190 | loss: 2.9077744MixupTrain:  epoch  0, batch  1191 | loss: 2.6660590MixupTrain:  epoch  0, batch  1192 | loss: 2.6964619MixupTrain:  epoch  0, batch  1193 | loss: 2.1676300MixupTrain:  epoch  0, batch  1194 | loss: 2.7346666MixupTrain:  epoch  0, batch  1195 | loss: 2.6150594MixupTrain:  epoch  0, batch  1196 | loss: 2.5238218MixupTrain:  epoch  0, batch  1197 | loss: 2.8067670MixupTrain:  epoch  0, batch  1198 | loss: 2.7072120MixupTrain:  epoch  0, batch  1199 | loss: 2.7935672MixupTrain:  epoch  0, batch  1200 | loss: 2.2970090MixupTrain:  epoch  0, batch  1201 | loss: 2.9285941MixupTrain:  epoch  0, batch  1202 | loss: 2.2941675MixupTrain:  epoch  0, batch  1203 | loss: 3.0287609MixupTrain:  epoch  0, batch  1204 | loss: 2.5079565MixupTrain:  epoch  0, batch  1205 | loss: 3.3901882MixupTrain:  epoch  0, batch  1206 | loss: 2.8381805MixupTrain:  epoch  0, batch  1207 | loss: 2.4062057MixupTrain:  epoch  0, batch  1208 | loss: 2.6631701MixupTrain:  epoch  0, batch  1209 | loss: 2.7634575MixupTrain:  epoch  0, batch  1210 | loss: 2.6416199MixupTrain:  epoch  0, batch  1211 | loss: 2.4281604MixupTrain:  epoch  0, batch  1212 | loss: 2.8417389MixupTrain:  epoch  0, batch  1213 | loss: 3.1320877MixupTrain:  epoch  0, batch  1214 | loss: 2.5235004MixupTrain:  epoch  0, batch  1215 | loss: 2.4915686MixupTrain:  epoch  0, batch  1216 | loss: 3.0884442MixupTrain:  epoch  0, batch  1217 | loss: 3.3917711MixupTrain:  epoch  0, batch  1218 | loss: 2.2218571MixupTrain:  epoch  0, batch  1219 | loss: 2.7951090MixupTrain:  epoch  0, batch  1220 | loss: 2.4597197MixupTrain:  epoch  0, batch  1221 | loss: 2.8305564MixupTrain:  epoch  0, batch  1222 | loss: 2.9848690MixupTrain:  epoch  0, batch  1223 | loss: 2.8465576MixupTrain:  epoch  0, batch  1224 | loss: 2.4816458MixupTrain:  epoch  0, batch  1225 | loss: 3.0130026MixupTrain:  epoch  0, batch  1226 | loss: 3.1866002MixupTrain:  epoch  0, batch  1227 | loss: 2.2484632MixupTrain:  epoch  0, batch  1228 | loss: 2.5414968MixupTrain:  epoch  0, batch  1229 | loss: 2.8948789MixupTrain:  epoch  0, batch  1230 | loss: 2.4201283MixupTrain:  epoch  0, batch  1231 | loss: 2.5450528MixupTrain:  epoch  0, batch  1232 | loss: 2.8031354MixupTrain:  epoch  0, batch  1233 | loss: 3.1794577MixupTrain:  epoch  0, batch  1234 | loss: 2.5679712MixupTrain:  epoch  0, batch  1235 | loss: 2.6415894MixupTrain:  epoch  0, batch  1236 | loss: 2.6428471MixupTrain:  epoch  0, batch  1237 | loss: 2.7116704MixupTrain:  epoch  0, batch  1238 | loss: 3.1571217MixupTrain:  epoch  0, batch  1239 | loss: 2.5687389MixupTrain:  epoch  0, batch  1240 | loss: 3.4375572MixupTrain:  epoch  0, batch  1241 | loss: 2.7841244MixupTrain:  epoch  0, batch  1242 | loss: 2.7031898MixupTrain:  epoch  0, batch  1243 | loss: 2.8216641MixupTrain:  epoch  0, batch  1244 | loss: 2.6107116MixupTrain:  epoch  0, batch  1245 | loss: 2.4261603MixupTrain:  epoch  0, batch  1246 | loss: 2.3413138MixupTrain:  epoch  0, batch  1247 | loss: 2.8114967MixupTrain:  epoch  0, batch  1248 | loss: 2.8507724MixupTrain:  epoch  0, batch  1249 | loss: 2.7642457MixupTrain:  epoch  0, batch  1250 | loss: 2.3990159MixupTrain:  epoch  0, batch  1251 | loss: 2.7675202MixupTrain:  epoch  0, batch  1252 | loss: 2.5276413MixupTrain:  epoch  0, batch  1253 | loss: 2.4369674MixupTrain:  epoch  0, batch  1254 | loss: 3.2543025MixupTrain:  epoch  0, batch  1255 | loss: 2.2095633MixupTrain:  epoch  0, batch  1256 | loss: 2.7496495MixupTrain:  epoch  0, batch  1257 | loss: 2.5492697MixupTrain:  epoch  0, batch  1258 | loss: 2.3601835MixupTrain:  epoch  0, batch  1259 | loss: 2.4634972MixupTrain:  epoch  0, batch  1260 | loss: 2.7530239MixupTrain:  epoch  0, batch  1261 | loss: 2.6895878MixupTrain:  epoch  0, batch  1262 | loss: 2.7397590MixupTrain:  epoch  0, batch  1263 | loss: 2.6046884MixupTrain:  epoch  0, batch  1264 | loss: 2.8424165MixupTrain:  epoch  0, batch  1265 | loss: 2.9519782MixupTrain:  epoch  0, batch  1266 | loss: 2.7229788MixupTrain:  epoch  0, batch  1267 | loss: 3.1223414MixupTrain:  epoch  0, batch  1268 | loss: 2.8336196MixupTrain:  epoch  0, batch  1269 | loss: 2.5362544MixupTrain:  epoch  0, batch  1270 | loss: 2.6951056MixupTrain:  epoch  0, batch  1271 | loss: 3.0343013MixupTrain:  epoch  0, batch  1272 | loss: 2.9412026MixupTrain:  epoch  0, batch  1273 | loss: 2.7326481MixupTrain:  epoch  0, batch  1274 | loss: 2.2698724MixupTrain:  epoch  0, batch  1275 | loss: 2.4356289MixupTrain:  epoch  0, batch  1276 | loss: 2.1398792MixupTrain:  epoch  0, batch  1277 | loss: 2.3025324MixupTrain:  epoch  0, batch  1278 | loss: 2.8617897MixupTrain:  epoch  0, batch  1279 | loss: 2.7189274MixupTrain:  epoch  0, batch  1280 | loss: 2.8053107MixupTrain:  epoch  0, batch  1281 | loss: 2.6580396MixupTrain:  epoch  0, batch  1282 | loss: 2.8645885MixupTrain:  epoch  0, batch  1283 | loss: 2.7521977MixupTrain:  epoch  0, batch  1284 | loss: 2.9526539MixupTrain:  epoch  0, batch  1285 | loss: 2.7835870MixupTrain:  epoch  0, batch  1286 | loss: 2.6475191MixupTrain:  epoch  0, batch  1287 | loss: 2.7185435MixupTrain:  epoch  0, batch  1288 | loss: 2.6245446MixupTrain:  epoch  0, batch  1289 | loss: 3.1150818MixupTrain:  epoch  0, batch  1290 | loss: 2.5481319MixupTrain:  epoch  0, batch  1291 | loss: 2.5770578MixupTrain:  epoch  0, batch  1292 | loss: 2.8512323MixupTrain:  epoch  0, batch  1293 | loss: 2.0211346MixupTrain:  epoch  0, batch  1294 | loss: 2.8673351MixupTrain:  epoch  0, batch  1295 | loss: 2.4540975MixupTrain:  epoch  0, batch  1296 | loss: 2.3777356MixupTrain:  epoch  0, batch  1297 | loss: 2.3121648MixupTrain:  epoch  0, batch  1298 | loss: 2.9561739MixupTrain:  epoch  0, batch  1299 | loss: 2.6105533MixupTrain:  epoch  0, batch  1300 | loss: 2.7370543MixupTrain:  epoch  0, batch  1301 | loss: 2.9058752MixupTrain:  epoch  0, batch  1302 | loss: 2.5074258{'ids': [101, 2132, 1997, 1996, 9593, 102, 2197, 2005, 2023, 1010, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 4]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 5]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 3]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 5]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 3]}
{'ids': [101, 2342, 5678, 1234, 4321, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [5, 3]}
#############params############
cuda:0
Task=Tacred, 5-shot
Encoding model: bert
pattern=hardprompt
mem=1, margin=0.3, gen=0, gen_num=5
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
[EVAL] batch:    0 | acc: 50.00%,  total acc: 50.00%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 43.75%   [EVAL] batch:    2 | acc: 50.00%,  total acc: 45.83%   [EVAL] batch:    3 | acc: 50.00%,  total acc: 46.88%   [EVAL] batch:    4 | acc: 50.00%,  total acc: 47.50%   [EVAL] batch:    5 | acc: 50.00%,  total acc: 47.92%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 54.46%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 60.16%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 64.58%   [EVAL] batch:    9 | acc: 75.00%,  total acc: 65.62%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 68.18%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 69.79%   [EVAL] batch:   12 | acc: 50.00%,  total acc: 68.27%   [EVAL] batch:   13 | acc: 37.50%,  total acc: 66.07%   [EVAL] batch:   14 | acc: 68.75%,  total acc: 66.25%   [EVAL] batch:   15 | acc: 68.75%,  total acc: 66.41%   [EVAL] batch:   16 | acc: 81.25%,  total acc: 67.28%   [EVAL] batch:   17 | acc: 68.75%,  total acc: 67.36%   [EVAL] batch:   18 | acc: 68.75%,  total acc: 67.43%   [EVAL] batch:   19 | acc: 68.75%,  total acc: 67.50%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 68.45%   [EVAL] batch:   21 | acc: 68.75%,  total acc: 68.47%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 69.02%   [EVAL] batch:   23 | acc: 81.25%,  total acc: 69.53%   [EVAL] batch:   24 | acc: 81.25%,  total acc: 70.00%   [EVAL] batch:   25 | acc: 75.00%,  total acc: 70.19%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 70.83%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 71.65%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 72.63%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 73.54%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 74.40%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 75.20%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 74.05%   
[EVAL] batch:    0 | acc: 50.00%,  total acc: 50.00%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 43.75%   [EVAL] batch:    2 | acc: 50.00%,  total acc: 45.83%   [EVAL] batch:    3 | acc: 50.00%,  total acc: 46.88%   [EVAL] batch:    4 | acc: 50.00%,  total acc: 47.50%   [EVAL] batch:    5 | acc: 50.00%,  total acc: 47.92%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 54.46%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 60.16%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 64.58%   [EVAL] batch:    9 | acc: 75.00%,  total acc: 65.62%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 68.18%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 69.79%   [EVAL] batch:   12 | acc: 50.00%,  total acc: 68.27%   [EVAL] batch:   13 | acc: 37.50%,  total acc: 66.07%   [EVAL] batch:   14 | acc: 68.75%,  total acc: 66.25%   [EVAL] batch:   15 | acc: 68.75%,  total acc: 66.41%   [EVAL] batch:   16 | acc: 81.25%,  total acc: 67.28%   [EVAL] batch:   17 | acc: 68.75%,  total acc: 67.36%   [EVAL] batch:   18 | acc: 68.75%,  total acc: 67.43%   [EVAL] batch:   19 | acc: 68.75%,  total acc: 67.50%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 68.45%   [EVAL] batch:   21 | acc: 68.75%,  total acc: 68.47%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 69.02%   [EVAL] batch:   23 | acc: 81.25%,  total acc: 69.53%   [EVAL] batch:   24 | acc: 81.25%,  total acc: 70.00%   [EVAL] batch:   25 | acc: 75.00%,  total acc: 70.19%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 70.83%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 71.65%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 72.63%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 73.54%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 74.40%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 75.20%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 74.05%   
cur_acc:  ['0.7405']
his_acc:  ['0.7405']
Mixup data size:  555
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2197, 2005, 2023, 1010, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 4]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 5]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 3]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 5]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 3]}
{'ids': [101, 2342, 5678, 1234, 4321, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [5, 3]}
#############params############
cuda:0
Task=Tacred, 5-shot
Encoding model: bert
pattern=hardprompt
mem=1, margin=0.3, gen=0, gen_num=5
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
[EVAL] batch:    0 | acc: 50.00%,  total acc: 50.00%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 43.75%   [EVAL] batch:    2 | acc: 50.00%,  total acc: 45.83%   [EVAL] batch:    3 | acc: 50.00%,  total acc: 46.88%   [EVAL] batch:    4 | acc: 50.00%,  total acc: 47.50%   [EVAL] batch:    5 | acc: 50.00%,  total acc: 47.92%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 54.46%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 60.16%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 64.58%   [EVAL] batch:    9 | acc: 75.00%,  total acc: 65.62%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 68.18%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 69.79%   [EVAL] batch:   12 | acc: 50.00%,  total acc: 68.27%   [EVAL] batch:   13 | acc: 37.50%,  total acc: 66.07%   [EVAL] batch:   14 | acc: 68.75%,  total acc: 66.25%   [EVAL] batch:   15 | acc: 68.75%,  total acc: 66.41%   [EVAL] batch:   16 | acc: 81.25%,  total acc: 67.28%   [EVAL] batch:   17 | acc: 68.75%,  total acc: 67.36%   [EVAL] batch:   18 | acc: 68.75%,  total acc: 67.43%   [EVAL] batch:   19 | acc: 68.75%,  total acc: 67.50%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 68.45%   [EVAL] batch:   21 | acc: 68.75%,  total acc: 68.47%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 69.02%   [EVAL] batch:   23 | acc: 81.25%,  total acc: 69.53%   [EVAL] batch:   24 | acc: 81.25%,  total acc: 70.00%   [EVAL] batch:   25 | acc: 75.00%,  total acc: 70.19%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 70.83%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 71.65%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 72.63%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 73.54%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 74.40%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 75.20%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 74.05%   
[EVAL] batch:    0 | acc: 50.00%,  total acc: 50.00%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 43.75%   [EVAL] batch:    2 | acc: 50.00%,  total acc: 45.83%   [EVAL] batch:    3 | acc: 50.00%,  total acc: 46.88%   [EVAL] batch:    4 | acc: 50.00%,  total acc: 47.50%   [EVAL] batch:    5 | acc: 50.00%,  total acc: 47.92%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 54.46%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 60.16%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 64.58%   [EVAL] batch:    9 | acc: 75.00%,  total acc: 65.62%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 68.18%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 69.79%   [EVAL] batch:   12 | acc: 50.00%,  total acc: 68.27%   [EVAL] batch:   13 | acc: 37.50%,  total acc: 66.07%   [EVAL] batch:   14 | acc: 68.75%,  total acc: 66.25%   [EVAL] batch:   15 | acc: 68.75%,  total acc: 66.41%   [EVAL] batch:   16 | acc: 81.25%,  total acc: 67.28%   [EVAL] batch:   17 | acc: 68.75%,  total acc: 67.36%   [EVAL] batch:   18 | acc: 68.75%,  total acc: 67.43%   [EVAL] batch:   19 | acc: 68.75%,  total acc: 67.50%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 68.45%   [EVAL] batch:   21 | acc: 68.75%,  total acc: 68.47%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 69.02%   [EVAL] batch:   23 | acc: 81.25%,  total acc: 69.53%   [EVAL] batch:   24 | acc: 81.25%,  total acc: 70.00%   [EVAL] batch:   25 | acc: 75.00%,  total acc: 70.19%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 70.83%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 71.65%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 72.63%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 73.54%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 74.40%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 75.20%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 74.05%   
cur_acc:  ['0.7405']
his_acc:  ['0.7405']
Mixup data size:  555
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2197, 2005, 2023, 1010, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 4]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 5]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 3]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 5]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 3]}
{'ids': [101, 2342, 5678, 1234, 4321, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [5, 3]}
#############params############
cuda:0
Task=Tacred, 5-shot
Encoding model: bert
pattern=hardprompt
mem=1, margin=0.3, gen=0, gen_num=5
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
[EVAL] batch:    0 | acc: 50.00%,  total acc: 50.00%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 43.75%   [EVAL] batch:    2 | acc: 50.00%,  total acc: 45.83%   [EVAL] batch:    3 | acc: 50.00%,  total acc: 46.88%   [EVAL] batch:    4 | acc: 50.00%,  total acc: 47.50%   [EVAL] batch:    5 | acc: 50.00%,  total acc: 47.92%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 54.46%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 60.16%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 64.58%   [EVAL] batch:    9 | acc: 75.00%,  total acc: 65.62%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 68.18%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 69.79%   [EVAL] batch:   12 | acc: 50.00%,  total acc: 68.27%   [EVAL] batch:   13 | acc: 37.50%,  total acc: 66.07%   [EVAL] batch:   14 | acc: 68.75%,  total acc: 66.25%   [EVAL] batch:   15 | acc: 68.75%,  total acc: 66.41%   [EVAL] batch:   16 | acc: 81.25%,  total acc: 67.28%   [EVAL] batch:   17 | acc: 68.75%,  total acc: 67.36%   [EVAL] batch:   18 | acc: 68.75%,  total acc: 67.43%   [EVAL] batch:   19 | acc: 68.75%,  total acc: 67.50%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 68.45%   [EVAL] batch:   21 | acc: 68.75%,  total acc: 68.47%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 69.02%   [EVAL] batch:   23 | acc: 81.25%,  total acc: 69.53%   [EVAL] batch:   24 | acc: 81.25%,  total acc: 70.00%   [EVAL] batch:   25 | acc: 75.00%,  total acc: 70.19%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 70.83%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 71.65%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 72.63%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 73.54%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 74.40%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 75.20%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 74.05%   
[EVAL] batch:    0 | acc: 50.00%,  total acc: 50.00%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 43.75%   [EVAL] batch:    2 | acc: 50.00%,  total acc: 45.83%   [EVAL] batch:    3 | acc: 50.00%,  total acc: 46.88%   [EVAL] batch:    4 | acc: 50.00%,  total acc: 47.50%   [EVAL] batch:    5 | acc: 50.00%,  total acc: 47.92%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 54.46%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 60.16%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 64.58%   [EVAL] batch:    9 | acc: 75.00%,  total acc: 65.62%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 68.18%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 69.79%   [EVAL] batch:   12 | acc: 50.00%,  total acc: 68.27%   [EVAL] batch:   13 | acc: 37.50%,  total acc: 66.07%   [EVAL] batch:   14 | acc: 68.75%,  total acc: 66.25%   [EVAL] batch:   15 | acc: 68.75%,  total acc: 66.41%   [EVAL] batch:   16 | acc: 81.25%,  total acc: 67.28%   [EVAL] batch:   17 | acc: 68.75%,  total acc: 67.36%   [EVAL] batch:   18 | acc: 68.75%,  total acc: 67.43%   [EVAL] batch:   19 | acc: 68.75%,  total acc: 67.50%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 68.45%   [EVAL] batch:   21 | acc: 68.75%,  total acc: 68.47%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 69.02%   [EVAL] batch:   23 | acc: 81.25%,  total acc: 69.53%   [EVAL] batch:   24 | acc: 81.25%,  total acc: 70.00%   [EVAL] batch:   25 | acc: 75.00%,  total acc: 70.19%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 70.83%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 71.65%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 72.63%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 73.54%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 74.40%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 75.20%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 74.05%   
cur_acc:  ['0.7405']
his_acc:  ['0.7405']
Mixup data size:  555
MixupTrain:  epoch  0, batch     0 | loss: 6.9805498MixupTrain:  epoch  0, batch     1 | loss: 5.6734581MixupTrain:  epoch  0, batch     2 | loss: 5.5817380MixupTrain:  epoch  0, batch     3 | loss: 5.8070755MixupTrain:  epoch  0, batch     4 | loss: 4.3956223MixupTrain:  epoch  0, batch     5 | loss: 5.1118484MixupTrain:  epoch  0, batch     6 | loss: 4.0295706MixupTrain:  epoch  0, batch     7 | loss: 4.8405533MixupTrain:  epoch  0, batch     8 | loss: 4.2003145MixupTrain:  epoch  0, batch     9 | loss: 4.1614070MixupTrain:  epoch  0, batch    10 | loss: 3.9721327MixupTrain:  epoch  0, batch    11 | loss: 3.6145289MixupTrain:  epoch  0, batch    12 | loss: 3.4786892MixupTrain:  epoch  0, batch    13 | loss: 3.8534591MixupTrain:  epoch  0, batch    14 | loss: 3.4968147MixupTrain:  epoch  0, batch    15 | loss: 2.8494925MixupTrain:  epoch  0, batch    16 | loss: 2.8844137MixupTrain:  epoch  0, batch    17 | loss: 2.9716887MixupTrain:  epoch  0, batch    18 | loss: 3.1413474MixupTrain:  epoch  0, batch    19 | loss: 1.9500759MixupTrain:  epoch  0, batch    20 | loss: 2.4652946MixupTrain:  epoch  0, batch    21 | loss: 2.2703662MixupTrain:  epoch  0, batch    22 | loss: 2.3696613MixupTrain:  epoch  0, batch    23 | loss: 2.6188095MixupTrain:  epoch  0, batch    24 | loss: 2.4763832MixupTrain:  epoch  0, batch    25 | loss: 2.0848598MixupTrain:  epoch  0, batch    26 | loss: 2.1007004MixupTrain:  epoch  0, batch    27 | loss: 2.4218976MixupTrain:  epoch  0, batch    28 | loss: 1.4803264MixupTrain:  epoch  0, batch    29 | loss: 2.3274984MixupTrain:  epoch  0, batch    30 | loss: 2.2179513MixupTrain:  epoch  0, batch    31 | loss: 1.4130318MixupTrain:  epoch  0, batch    32 | loss: 1.7106066MixupTrain:  epoch  0, batch    33 | loss: 1.2920177MixupTrain:  epoch  0, batch    34 | loss: 2.1255965
MemoryTrain:  epoch  0, batch     0 | loss: 0.8498343MemoryTrain:  epoch  1, batch     0 | loss: 0.0145093MemoryTrain:  epoch  2, batch     0 | loss: 0.0065697MemoryTrain:  epoch  3, batch     0 | loss: 0.0053809MemoryTrain:  epoch  4, batch     0 | loss: 0.0078473MemoryTrain:  epoch  5, batch     0 | loss: 0.0103376MemoryTrain:  epoch  6, batch     0 | loss: 0.0064634MemoryTrain:  epoch  7, batch     0 | loss: 0.0034220MemoryTrain:  epoch  8, batch     0 | loss: 0.0036619MemoryTrain:  epoch  9, batch     0 | loss: 0.0056114
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    1 | acc: 100.00%,  total acc: 90.62%   [EVAL] batch:    2 | acc: 100.00%,  total acc: 93.75%   [EVAL] batch:    3 | acc: 100.00%,  total acc: 95.31%   [EVAL] batch:    4 | acc: 100.00%,  total acc: 96.25%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 96.88%   [EVAL] batch:    6 | acc: 68.75%,  total acc: 92.86%   [EVAL] batch:    7 | acc: 56.25%,  total acc: 88.28%   [EVAL] batch:    8 | acc: 62.50%,  total acc: 85.42%   [EVAL] batch:    9 | acc: 50.00%,  total acc: 81.88%   [EVAL] batch:   10 | acc: 31.25%,  total acc: 77.27%   [EVAL] batch:   11 | acc: 50.00%,  total acc: 75.00%   [EVAL] batch:   12 | acc: 31.25%,  total acc: 71.63%   [EVAL] batch:   13 | acc: 0.00%,  total acc: 66.52%   
[EVAL] batch:    0 | acc: 25.00%,  total acc: 25.00%   [EVAL] batch:    1 | acc: 6.25%,  total acc: 15.62%   [EVAL] batch:    2 | acc: 12.50%,  total acc: 14.58%   [EVAL] batch:    3 | acc: 6.25%,  total acc: 12.50%   [EVAL] batch:    4 | acc: 6.25%,  total acc: 11.25%   [EVAL] batch:    5 | acc: 25.00%,  total acc: 13.54%   [EVAL] batch:    6 | acc: 62.50%,  total acc: 20.54%   [EVAL] batch:    7 | acc: 81.25%,  total acc: 28.12%   [EVAL] batch:    8 | acc: 93.75%,  total acc: 35.42%   [EVAL] batch:    9 | acc: 50.00%,  total acc: 36.88%   [EVAL] batch:   10 | acc: 81.25%,  total acc: 40.91%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 44.79%   [EVAL] batch:   12 | acc: 37.50%,  total acc: 44.23%   [EVAL] batch:   13 | acc: 31.25%,  total acc: 43.30%   [EVAL] batch:   14 | acc: 68.75%,  total acc: 45.00%   [EVAL] batch:   15 | acc: 62.50%,  total acc: 46.09%   [EVAL] batch:   16 | acc: 56.25%,  total acc: 46.69%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 47.57%   [EVAL] batch:   18 | acc: 56.25%,  total acc: 48.03%   [EVAL] batch:   19 | acc: 68.75%,  total acc: 49.06%   [EVAL] batch:   20 | acc: 75.00%,  total acc: 50.30%   [EVAL] batch:   21 | acc: 75.00%,  total acc: 51.42%   [EVAL] batch:   22 | acc: 75.00%,  total acc: 52.45%   [EVAL] batch:   23 | acc: 87.50%,  total acc: 53.91%   [EVAL] batch:   24 | acc: 62.50%,  total acc: 54.25%   [EVAL] batch:   25 | acc: 81.25%,  total acc: 55.29%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 56.48%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 58.04%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 59.48%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 60.83%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 62.10%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 63.28%   [EVAL] batch:   32 | acc: 93.75%,  total acc: 64.20%   [EVAL] batch:   33 | acc: 87.50%,  total acc: 64.89%   [EVAL] batch:   34 | acc: 100.00%,  total acc: 65.89%   [EVAL] batch:   35 | acc: 100.00%,  total acc: 66.84%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 67.74%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 68.59%   [EVAL] batch:   38 | acc: 93.75%,  total acc: 69.23%   [EVAL] batch:   39 | acc: 43.75%,  total acc: 68.59%   [EVAL] batch:   40 | acc: 62.50%,  total acc: 68.45%   [EVAL] batch:   41 | acc: 50.00%,  total acc: 68.01%   [EVAL] batch:   42 | acc: 50.00%,  total acc: 67.59%   [EVAL] batch:   43 | acc: 37.50%,  total acc: 66.90%   [EVAL] batch:   44 | acc: 37.50%,  total acc: 66.25%   [EVAL] batch:   45 | acc: 12.50%,  total acc: 65.08%   [EVAL] batch:   46 | acc: 0.00%,  total acc: 63.70%   
cur_acc:  ['0.7405', '0.6652']
his_acc:  ['0.7405', '0.6370']
Mixup data size:  745
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2197, 2005, 2023, 1010, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 4]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 5]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 3]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 5]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 3]}
{'ids': [101, 2342, 5678, 1234, 4321, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [5, 3]}
#############params############
cuda:0
Task=Tacred, 5-shot
Encoding model: bert
pattern=hardprompt
mem=1, margin=0.3, gen=0, gen_num=5
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
[EVAL] batch:    0 | acc: 50.00%,  total acc: 50.00%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 43.75%   [EVAL] batch:    2 | acc: 50.00%,  total acc: 45.83%   [EVAL] batch:    3 | acc: 50.00%,  total acc: 46.88%   [EVAL] batch:    4 | acc: 50.00%,  total acc: 47.50%   [EVAL] batch:    5 | acc: 50.00%,  total acc: 47.92%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 54.46%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 60.16%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 64.58%   [EVAL] batch:    9 | acc: 75.00%,  total acc: 65.62%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 68.18%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 69.79%   [EVAL] batch:   12 | acc: 50.00%,  total acc: 68.27%   [EVAL] batch:   13 | acc: 37.50%,  total acc: 66.07%   [EVAL] batch:   14 | acc: 68.75%,  total acc: 66.25%   [EVAL] batch:   15 | acc: 68.75%,  total acc: 66.41%   [EVAL] batch:   16 | acc: 81.25%,  total acc: 67.28%   [EVAL] batch:   17 | acc: 68.75%,  total acc: 67.36%   [EVAL] batch:   18 | acc: 68.75%,  total acc: 67.43%   [EVAL] batch:   19 | acc: 68.75%,  total acc: 67.50%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 68.45%   [EVAL] batch:   21 | acc: 68.75%,  total acc: 68.47%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 69.02%   [EVAL] batch:   23 | acc: 81.25%,  total acc: 69.53%   [EVAL] batch:   24 | acc: 81.25%,  total acc: 70.00%   [EVAL] batch:   25 | acc: 75.00%,  total acc: 70.19%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 70.83%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 71.65%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 72.63%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 73.54%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 74.40%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 75.20%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 74.05%   
[EVAL] batch:    0 | acc: 50.00%,  total acc: 50.00%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 43.75%   [EVAL] batch:    2 | acc: 50.00%,  total acc: 45.83%   [EVAL] batch:    3 | acc: 50.00%,  total acc: 46.88%   [EVAL] batch:    4 | acc: 50.00%,  total acc: 47.50%   [EVAL] batch:    5 | acc: 50.00%,  total acc: 47.92%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 54.46%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 60.16%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 64.58%   [EVAL] batch:    9 | acc: 75.00%,  total acc: 65.62%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 68.18%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 69.79%   [EVAL] batch:   12 | acc: 50.00%,  total acc: 68.27%   [EVAL] batch:   13 | acc: 37.50%,  total acc: 66.07%   [EVAL] batch:   14 | acc: 68.75%,  total acc: 66.25%   [EVAL] batch:   15 | acc: 68.75%,  total acc: 66.41%   [EVAL] batch:   16 | acc: 81.25%,  total acc: 67.28%   [EVAL] batch:   17 | acc: 68.75%,  total acc: 67.36%   [EVAL] batch:   18 | acc: 68.75%,  total acc: 67.43%   [EVAL] batch:   19 | acc: 68.75%,  total acc: 67.50%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 68.45%   [EVAL] batch:   21 | acc: 68.75%,  total acc: 68.47%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 69.02%   [EVAL] batch:   23 | acc: 81.25%,  total acc: 69.53%   [EVAL] batch:   24 | acc: 81.25%,  total acc: 70.00%   [EVAL] batch:   25 | acc: 75.00%,  total acc: 70.19%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 70.83%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 71.65%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 72.63%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 73.54%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 74.40%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 75.20%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 74.05%   
cur_acc:  ['0.7405']
his_acc:  ['0.7405']
Mixup data size:  555
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([32, 768])
shape mask hidden torch.Size([22, 768])
shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch     0 | loss: 6.9805498shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch     1 | loss: 5.6734581shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch     2 | loss: 5.5817380shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch     3 | loss: 5.8070755shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch     4 | loss: 4.3956223shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch     5 | loss: 5.1118484shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch     6 | loss: 4.0295706shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch     7 | loss: 4.8405533shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch     8 | loss: 4.2003145shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch     9 | loss: 4.1614070shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    10 | loss: 3.9721327shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    11 | loss: 3.6145289shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    12 | loss: 3.4786892shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    13 | loss: 3.8534591shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    14 | loss: 3.4968147shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    15 | loss: 2.8494925shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    16 | loss: 2.8844137shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    17 | loss: 2.9716887shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    18 | loss: 3.1413474shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    19 | loss: 1.9500759shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    20 | loss: 2.4652946shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    21 | loss: 2.2703662shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    22 | loss: 2.3696613shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    23 | loss: 2.6188095shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    24 | loss: 2.4763832shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    25 | loss: 2.0848598shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    26 | loss: 2.1007004shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    27 | loss: 2.4218976shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    28 | loss: 1.4803264shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    29 | loss: 2.3274984shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    30 | loss: 2.2179513shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    31 | loss: 1.4130318shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    32 | loss: 1.7106066shape mask hidden torch.Size([32, 768])
MixupTrain:  epoch  0, batch    33 | loss: 1.2920177shape mask hidden torch.Size([22, 768])
MixupTrain:  epoch  0, batch    34 | loss: 2.1255965
MemoryTrain:  epoch  0, batch     0 | loss: 0.8498343MemoryTrain:  epoch  1, batch     0 | loss: 0.0145093MemoryTrain:  epoch  2, batch     0 | loss: 0.0065697MemoryTrain:  epoch  3, batch     0 | loss: 0.0053809MemoryTrain:  epoch  4, batch     0 | loss: 0.0078473MemoryTrain:  epoch  5, batch     0 | loss: 0.0103376MemoryTrain:  epoch  6, batch     0 | loss: 0.0064634MemoryTrain:  epoch  7, batch     0 | loss: 0.0034220MemoryTrain:  epoch  8, batch     0 | loss: 0.0036619MemoryTrain:  epoch  9, batch     0 | loss: 0.0056114
[EVAL] batch:    0 | acc: 81.25%,  total acc: 81.25%   [EVAL] batch:    1 | acc: 100.00%,  total acc: 90.62%   [EVAL] batch:    2 | acc: 100.00%,  total acc: 93.75%   [EVAL] batch:    3 | acc: 100.00%,  total acc: 95.31%   [EVAL] batch:    4 | acc: 100.00%,  total acc: 96.25%   [EVAL] batch:    5 | acc: 100.00%,  total acc: 96.88%   [EVAL] batch:    6 | acc: 68.75%,  total acc: 92.86%   [EVAL] batch:    7 | acc: 56.25%,  total acc: 88.28%   [EVAL] batch:    8 | acc: 62.50%,  total acc: 85.42%   [EVAL] batch:    9 | acc: 50.00%,  total acc: 81.88%   [EVAL] batch:   10 | acc: 31.25%,  total acc: 77.27%   [EVAL] batch:   11 | acc: 50.00%,  total acc: 75.00%   [EVAL] batch:   12 | acc: 31.25%,  total acc: 71.63%   [EVAL] batch:   13 | acc: 0.00%,  total acc: 66.52%   
[EVAL] batch:    0 | acc: 25.00%,  total acc: 25.00%   [EVAL] batch:    1 | acc: 6.25%,  total acc: 15.62%   [EVAL] batch:    2 | acc: 12.50%,  total acc: 14.58%   [EVAL] batch:    3 | acc: 6.25%,  total acc: 12.50%   [EVAL] batch:    4 | acc: 6.25%,  total acc: 11.25%   [EVAL] batch:    5 | acc: 25.00%,  total acc: 13.54%   [EVAL] batch:    6 | acc: 62.50%,  total acc: 20.54%   [EVAL] batch:    7 | acc: 81.25%,  total acc: 28.12%   [EVAL] batch:    8 | acc: 93.75%,  total acc: 35.42%   [EVAL] batch:    9 | acc: 50.00%,  total acc: 36.88%   [EVAL] batch:   10 | acc: 81.25%,  total acc: 40.91%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 44.79%   [EVAL] batch:   12 | acc: 37.50%,  total acc: 44.23%   [EVAL] batch:   13 | acc: 31.25%,  total acc: 43.30%   [EVAL] batch:   14 | acc: 68.75%,  total acc: 45.00%   [EVAL] batch:   15 | acc: 62.50%,  total acc: 46.09%   [EVAL] batch:   16 | acc: 56.25%,  total acc: 46.69%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 47.57%   [EVAL] batch:   18 | acc: 56.25%,  total acc: 48.03%   [EVAL] batch:   19 | acc: 68.75%,  total acc: 49.06%   [EVAL] batch:   20 | acc: 75.00%,  total acc: 50.30%   [EVAL] batch:   21 | acc: 75.00%,  total acc: 51.42%   [EVAL] batch:   22 | acc: 75.00%,  total acc: 52.45%   [EVAL] batch:   23 | acc: 87.50%,  total acc: 53.91%   [EVAL] batch:   24 | acc: 62.50%,  total acc: 54.25%   [EVAL] batch:   25 | acc: 81.25%,  total acc: 55.29%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 56.48%   [EVAL] batch:   27 | acc: 100.00%,  total acc: 58.04%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 59.48%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 60.83%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 62.10%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 63.28%   [EVAL] batch:   32 | acc: 93.75%,  total acc: 64.20%   [EVAL] batch:   33 | acc: 87.50%,  total acc: 64.89%   [EVAL] batch:   34 | acc: 100.00%,  total acc: 65.89%   [EVAL] batch:   35 | acc: 100.00%,  total acc: 66.84%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 67.74%   [EVAL] batch:   37 | acc: 100.00%,  total acc: 68.59%   [EVAL] batch:   38 | acc: 93.75%,  total acc: 69.23%   [EVAL] batch:   39 | acc: 43.75%,  total acc: 68.59%   [EVAL] batch:   40 | acc: 62.50%,  total acc: 68.45%   [EVAL] batch:   41 | acc: 50.00%,  total acc: 68.01%   [EVAL] batch:   42 | acc: 50.00%,  total acc: 67.59%   [EVAL] batch:   43 | acc: 37.50%,  total acc: 66.90%   [EVAL] batch:   44 | acc: 37.50%,  total acc: 66.25%   [EVAL] batch:   45 | acc: 12.50%,  total acc: 65.08%   [EVAL] batch:   46 | acc: 0.00%,  total acc: 63.70%   
cur_acc:  ['0.7405', '0.6652']
his_acc:  ['0.7405', '0.6370']
Mixup data size:  745
shape mask hidden torch.Size([31, 768])
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2197, 2005, 2023, 1010, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 4]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 5]}
{'ids': [101, 2132, 1997, 1996, 9593, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [6, 3]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 2342, 5678, 1234, 4321, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 5]}
{'ids': [101, 2197, 2005, 2023, 1010, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [4, 3]}
{'ids': [101, 2342, 5678, 1234, 4321, 102, 6789, 8765, 4321, 1234, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'relation': [5, 3]}
#############params############
cuda:0
Task=Tacred, 5-shot
Encoding model: bert
pattern=hardprompt
mem=1, margin=0.3, gen=0, gen_num=5
#############params############
--------Round  0
seed:  100
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/train.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/valid.pkl
data/CFRLTacred/CFRLdata_6_100_5_5/_process_BERT_hardprompt/test.pkl
Task_order: [7 3 0 5 4 1 6 2]
prepared data!
[EVAL] batch:    0 | acc: 50.00%,  total acc: 50.00%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 43.75%   [EVAL] batch:    2 | acc: 50.00%,  total acc: 45.83%   [EVAL] batch:    3 | acc: 50.00%,  total acc: 46.88%   [EVAL] batch:    4 | acc: 50.00%,  total acc: 47.50%   [EVAL] batch:    5 | acc: 50.00%,  total acc: 47.92%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 54.46%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 60.16%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 64.58%   [EVAL] batch:    9 | acc: 75.00%,  total acc: 65.62%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 68.18%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 69.79%   [EVAL] batch:   12 | acc: 50.00%,  total acc: 68.27%   [EVAL] batch:   13 | acc: 37.50%,  total acc: 66.07%   [EVAL] batch:   14 | acc: 68.75%,  total acc: 66.25%   [EVAL] batch:   15 | acc: 68.75%,  total acc: 66.41%   [EVAL] batch:   16 | acc: 81.25%,  total acc: 67.28%   [EVAL] batch:   17 | acc: 68.75%,  total acc: 67.36%   [EVAL] batch:   18 | acc: 68.75%,  total acc: 67.43%   [EVAL] batch:   19 | acc: 68.75%,  total acc: 67.50%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 68.45%   [EVAL] batch:   21 | acc: 68.75%,  total acc: 68.47%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 69.02%   [EVAL] batch:   23 | acc: 81.25%,  total acc: 69.53%   [EVAL] batch:   24 | acc: 81.25%,  total acc: 70.00%   [EVAL] batch:   25 | acc: 75.00%,  total acc: 70.19%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 70.83%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 71.65%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 72.63%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 73.54%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 74.40%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 75.20%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 74.05%   
[EVAL] batch:    0 | acc: 50.00%,  total acc: 50.00%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 43.75%   [EVAL] batch:    2 | acc: 50.00%,  total acc: 45.83%   [EVAL] batch:    3 | acc: 50.00%,  total acc: 46.88%   [EVAL] batch:    4 | acc: 50.00%,  total acc: 47.50%   [EVAL] batch:    5 | acc: 50.00%,  total acc: 47.92%   [EVAL] batch:    6 | acc: 93.75%,  total acc: 54.46%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 60.16%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 64.58%   [EVAL] batch:    9 | acc: 75.00%,  total acc: 65.62%   [EVAL] batch:   10 | acc: 93.75%,  total acc: 68.18%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 69.79%   [EVAL] batch:   12 | acc: 50.00%,  total acc: 68.27%   [EVAL] batch:   13 | acc: 37.50%,  total acc: 66.07%   [EVAL] batch:   14 | acc: 68.75%,  total acc: 66.25%   [EVAL] batch:   15 | acc: 68.75%,  total acc: 66.41%   [EVAL] batch:   16 | acc: 81.25%,  total acc: 67.28%   [EVAL] batch:   17 | acc: 68.75%,  total acc: 67.36%   [EVAL] batch:   18 | acc: 68.75%,  total acc: 67.43%   [EVAL] batch:   19 | acc: 68.75%,  total acc: 67.50%   [EVAL] batch:   20 | acc: 87.50%,  total acc: 68.45%   [EVAL] batch:   21 | acc: 68.75%,  total acc: 68.47%   [EVAL] batch:   22 | acc: 81.25%,  total acc: 69.02%   [EVAL] batch:   23 | acc: 81.25%,  total acc: 69.53%   [EVAL] batch:   24 | acc: 81.25%,  total acc: 70.00%   [EVAL] batch:   25 | acc: 75.00%,  total acc: 70.19%   [EVAL] batch:   26 | acc: 87.50%,  total acc: 70.83%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 71.65%   [EVAL] batch:   28 | acc: 100.00%,  total acc: 72.63%   [EVAL] batch:   29 | acc: 100.00%,  total acc: 73.54%   [EVAL] batch:   30 | acc: 100.00%,  total acc: 74.40%   [EVAL] batch:   31 | acc: 100.00%,  total acc: 75.20%   [EVAL] batch:   32 | acc: 37.50%,  total acc: 74.05%   
cur_acc:  ['0.7405']
his_acc:  ['0.7405']
Mixup data size:  555
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
MixupTrain:  epoch  0, batch     0 | loss: 7.4359398something wrong with mask positions
MixupTrain:  epoch  0, batch     1 | loss: 7.0643473something wrong with mask positions
MixupTrain:  epoch  0, batch     2 | loss: 6.8407974something wrong with mask positions
MixupTrain:  epoch  0, batch     3 | loss: 6.8950396something wrong with mask positions
MixupTrain:  epoch  0, batch     4 | loss: 6.5395098something wrong with mask positions
MixupTrain:  epoch  0, batch     5 | loss: 6.5086498something wrong with mask positions
MixupTrain:  epoch  0, batch     6 | loss: 6.5156960something wrong with mask positions
MixupTrain:  epoch  0, batch     7 | loss: 6.4163179something wrong with mask positions
MixupTrain:  epoch  0, batch     8 | loss: 6.1397200something wrong with mask positions
MixupTrain:  epoch  0, batch     9 | loss: 6.1879797something wrong with mask positions
MixupTrain:  epoch  0, batch    10 | loss: 5.8375368something wrong with mask positions
MixupTrain:  epoch  0, batch    11 | loss: 5.7805853something wrong with mask positions
MixupTrain:  epoch  0, batch    12 | loss: 6.0002155something wrong with mask positions
MixupTrain:  epoch  0, batch    13 | loss: 5.5723805something wrong with mask positions
MixupTrain:  epoch  0, batch    14 | loss: 5.6196671something wrong with mask positions
MixupTrain:  epoch  0, batch    15 | loss: 5.4881783something wrong with mask positions
MixupTrain:  epoch  0, batch    16 | loss: 5.5503788something wrong with mask positions
MixupTrain:  epoch  0, batch    17 | loss: 5.0099726something wrong with mask positions
MixupTrain:  epoch  0, batch    18 | loss: 4.9809275something wrong with mask positions
MixupTrain:  epoch  0, batch    19 | loss: 4.9928660something wrong with mask positions
MixupTrain:  epoch  0, batch    20 | loss: 5.0568857something wrong with mask positions
MixupTrain:  epoch  0, batch    21 | loss: 4.9557686something wrong with mask positions
MixupTrain:  epoch  0, batch    22 | loss: 4.9273639something wrong with mask positions
MixupTrain:  epoch  0, batch    23 | loss: 5.0106363something wrong with mask positions
MixupTrain:  epoch  0, batch    24 | loss: 5.0383806something wrong with mask positions
MixupTrain:  epoch  0, batch    25 | loss: 4.8679767something wrong with mask positions
MixupTrain:  epoch  0, batch    26 | loss: 4.6345100something wrong with mask positions
MixupTrain:  epoch  0, batch    27 | loss: 4.8946657something wrong with mask positions
MixupTrain:  epoch  0, batch    28 | loss: 4.7488961something wrong with mask positions
MixupTrain:  epoch  0, batch    29 | loss: 4.6340275something wrong with mask positions
MixupTrain:  epoch  0, batch    30 | loss: 4.5279379something wrong with mask positions
MixupTrain:  epoch  0, batch    31 | loss: 4.2307110something wrong with mask positions
MixupTrain:  epoch  0, batch    32 | loss: 4.7407866something wrong with mask positions
MixupTrain:  epoch  0, batch    33 | loss: 4.3529587something wrong with mask positions
MixupTrain:  epoch  0, batch    34 | loss: 4.5938315
MemoryTrain:  epoch  0, batch     0 | loss: 2.7189739MemoryTrain:  epoch  1, batch     0 | loss: 1.4709884MemoryTrain:  epoch  2, batch     0 | loss: 0.9603523MemoryTrain:  epoch  3, batch     0 | loss: 0.6141912MemoryTrain:  epoch  4, batch     0 | loss: 0.5557512MemoryTrain:  epoch  5, batch     0 | loss: 0.2569957MemoryTrain:  epoch  6, batch     0 | loss: 0.1892994MemoryTrain:  epoch  7, batch     0 | loss: 0.1093220MemoryTrain:  epoch  8, batch     0 | loss: 0.0790131MemoryTrain:  epoch  9, batch     0 | loss: 0.0800169
[EVAL] batch:    0 | acc: 68.75%,  total acc: 68.75%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 81.25%   [EVAL] batch:    2 | acc: 100.00%,  total acc: 87.50%   [EVAL] batch:    3 | acc: 100.00%,  total acc: 90.62%   [EVAL] batch:    4 | acc: 93.75%,  total acc: 91.25%   [EVAL] batch:    5 | acc: 81.25%,  total acc: 89.58%   [EVAL] batch:    6 | acc: 56.25%,  total acc: 84.82%   [EVAL] batch:    7 | acc: 43.75%,  total acc: 79.69%   [EVAL] batch:    8 | acc: 37.50%,  total acc: 75.00%   [EVAL] batch:    9 | acc: 18.75%,  total acc: 69.38%   [EVAL] batch:   10 | acc: 31.25%,  total acc: 65.91%   [EVAL] batch:   11 | acc: 18.75%,  total acc: 61.98%   [EVAL] batch:   12 | acc: 12.50%,  total acc: 58.17%   [EVAL] batch:   13 | acc: 0.00%,  total acc: 54.02%   
[EVAL] batch:    0 | acc: 31.25%,  total acc: 31.25%   [EVAL] batch:    1 | acc: 6.25%,  total acc: 18.75%   [EVAL] batch:    2 | acc: 18.75%,  total acc: 18.75%   [EVAL] batch:    3 | acc: 18.75%,  total acc: 18.75%   [EVAL] batch:    4 | acc: 18.75%,  total acc: 18.75%   [EVAL] batch:    5 | acc: 31.25%,  total acc: 20.83%   [EVAL] batch:    6 | acc: 75.00%,  total acc: 28.57%   [EVAL] batch:    7 | acc: 100.00%,  total acc: 37.50%   [EVAL] batch:    8 | acc: 100.00%,  total acc: 44.44%   [EVAL] batch:    9 | acc: 87.50%,  total acc: 48.75%   [EVAL] batch:   10 | acc: 100.00%,  total acc: 53.41%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 56.77%   [EVAL] batch:   12 | acc: 68.75%,  total acc: 57.69%   [EVAL] batch:   13 | acc: 43.75%,  total acc: 56.70%   [EVAL] batch:   14 | acc: 62.50%,  total acc: 57.08%   [EVAL] batch:   15 | acc: 75.00%,  total acc: 58.20%   [EVAL] batch:   16 | acc: 56.25%,  total acc: 58.09%   [EVAL] batch:   17 | acc: 62.50%,  total acc: 58.33%   [EVAL] batch:   18 | acc: 56.25%,  total acc: 58.22%   [EVAL] batch:   19 | acc: 62.50%,  total acc: 58.44%   [EVAL] batch:   20 | acc: 25.00%,  total acc: 56.85%   [EVAL] batch:   21 | acc: 25.00%,  total acc: 55.40%   [EVAL] batch:   22 | acc: 43.75%,  total acc: 54.89%   [EVAL] batch:   23 | acc: 68.75%,  total acc: 55.47%   [EVAL] batch:   24 | acc: 37.50%,  total acc: 54.75%   [EVAL] batch:   25 | acc: 50.00%,  total acc: 54.57%   [EVAL] batch:   26 | acc: 62.50%,  total acc: 54.86%   [EVAL] batch:   27 | acc: 93.75%,  total acc: 56.25%   [EVAL] batch:   28 | acc: 93.75%,  total acc: 57.54%   [EVAL] batch:   29 | acc: 87.50%,  total acc: 58.54%   [EVAL] batch:   30 | acc: 93.75%,  total acc: 59.68%   [EVAL] batch:   31 | acc: 93.75%,  total acc: 60.74%   [EVAL] batch:   32 | acc: 87.50%,  total acc: 61.55%   [EVAL] batch:   33 | acc: 75.00%,  total acc: 61.95%   [EVAL] batch:   34 | acc: 100.00%,  total acc: 63.04%   [EVAL] batch:   35 | acc: 100.00%,  total acc: 64.06%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 65.03%   [EVAL] batch:   37 | acc: 93.75%,  total acc: 65.79%   [EVAL] batch:   38 | acc: 62.50%,  total acc: 65.71%   [EVAL] batch:   39 | acc: 43.75%,  total acc: 65.16%   [EVAL] batch:   40 | acc: 31.25%,  total acc: 64.33%   [EVAL] batch:   41 | acc: 25.00%,  total acc: 63.39%   [EVAL] batch:   42 | acc: 31.25%,  total acc: 62.65%   [EVAL] batch:   43 | acc: 25.00%,  total acc: 61.79%   [EVAL] batch:   44 | acc: 12.50%,  total acc: 60.69%   [EVAL] batch:   45 | acc: 6.25%,  total acc: 59.51%   [EVAL] batch:   46 | acc: 0.00%,  total acc: 58.24%   
cur_acc:  ['0.7405', '0.5402']
his_acc:  ['0.7405', '0.5824']
Mixup data size:  745
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
MixupTrain:  epoch  0, batch     0 | loss: 9.6940479something wrong with mask positions
MixupTrain:  epoch  0, batch     1 | loss: 9.0979424something wrong with mask positions
MixupTrain:  epoch  0, batch     2 | loss: 8.4782372something wrong with mask positions
MixupTrain:  epoch  0, batch     3 | loss: 7.6807051something wrong with mask positions
MixupTrain:  epoch  0, batch     4 | loss: 7.6111412something wrong with mask positions
MixupTrain:  epoch  0, batch     5 | loss: 7.5053701something wrong with mask positions
MixupTrain:  epoch  0, batch     6 | loss: 6.9587464something wrong with mask positions
MixupTrain:  epoch  0, batch     7 | loss: 6.7938051something wrong with mask positions
MixupTrain:  epoch  0, batch     8 | loss: 6.7366242something wrong with mask positions
MixupTrain:  epoch  0, batch     9 | loss: 6.6862020something wrong with mask positions
MixupTrain:  epoch  0, batch    10 | loss: 6.5352602something wrong with mask positions
MixupTrain:  epoch  0, batch    11 | loss: 6.6676474something wrong with mask positions
MixupTrain:  epoch  0, batch    12 | loss: 6.3833313something wrong with mask positions
MixupTrain:  epoch  0, batch    13 | loss: 6.5006008something wrong with mask positions
MixupTrain:  epoch  0, batch    14 | loss: 6.4692760something wrong with mask positions
MixupTrain:  epoch  0, batch    15 | loss: 6.3527865something wrong with mask positions
MixupTrain:  epoch  0, batch    16 | loss: 6.5565867something wrong with mask positions
MixupTrain:  epoch  0, batch    17 | loss: 6.6598721something wrong with mask positions
MixupTrain:  epoch  0, batch    18 | loss: 6.3009329something wrong with mask positions
MixupTrain:  epoch  0, batch    19 | loss: 6.4455581something wrong with mask positions
MixupTrain:  epoch  0, batch    20 | loss: 6.3826938something wrong with mask positions
MixupTrain:  epoch  0, batch    21 | loss: 6.1853828something wrong with mask positions
MixupTrain:  epoch  0, batch    22 | loss: 6.1062193something wrong with mask positions
MixupTrain:  epoch  0, batch    23 | loss: 6.1589479something wrong with mask positions
MixupTrain:  epoch  0, batch    24 | loss: 5.8555250something wrong with mask positions
MixupTrain:  epoch  0, batch    25 | loss: 6.3816705something wrong with mask positions
MixupTrain:  epoch  0, batch    26 | loss: 6.1895285something wrong with mask positions
MixupTrain:  epoch  0, batch    27 | loss: 5.9760351something wrong with mask positions
MixupTrain:  epoch  0, batch    28 | loss: 6.0345726something wrong with mask positions
MixupTrain:  epoch  0, batch    29 | loss: 6.1528649something wrong with mask positions
MixupTrain:  epoch  0, batch    30 | loss: 5.8723125something wrong with mask positions
MixupTrain:  epoch  0, batch    31 | loss: 6.1399374something wrong with mask positions
MixupTrain:  epoch  0, batch    32 | loss: 5.8657265something wrong with mask positions
MixupTrain:  epoch  0, batch    33 | loss: 5.7450047something wrong with mask positions
MixupTrain:  epoch  0, batch    34 | loss: 5.7284026something wrong with mask positions
MixupTrain:  epoch  0, batch    35 | loss: 5.6266050something wrong with mask positions
MixupTrain:  epoch  0, batch    36 | loss: 5.6945047something wrong with mask positions
MixupTrain:  epoch  0, batch    37 | loss: 5.5292187something wrong with mask positions
MixupTrain:  epoch  0, batch    38 | loss: 5.4558492something wrong with mask positions
MixupTrain:  epoch  0, batch    39 | loss: 5.3529539something wrong with mask positions
MixupTrain:  epoch  0, batch    40 | loss: 5.4494057something wrong with mask positions
MixupTrain:  epoch  0, batch    41 | loss: 5.4695950something wrong with mask positions
MixupTrain:  epoch  0, batch    42 | loss: 5.3218117something wrong with mask positions
MixupTrain:  epoch  0, batch    43 | loss: 5.4358773something wrong with mask positions
MixupTrain:  epoch  0, batch    44 | loss: 5.4969511something wrong with mask positions
MixupTrain:  epoch  0, batch    45 | loss: 5.3850822something wrong with mask positions
MixupTrain:  epoch  0, batch    46 | loss: 5.1592164
MemoryTrain:  epoch  0, batch     0 | loss: 0.3683320MemoryTrain:  epoch  1, batch     0 | loss: 0.1851160MemoryTrain:  epoch  2, batch     0 | loss: 0.0532767MemoryTrain:  epoch  3, batch     0 | loss: 0.0370304MemoryTrain:  epoch  4, batch     0 | loss: 0.0435746MemoryTrain:  epoch  5, batch     0 | loss: 0.0421366MemoryTrain:  epoch  6, batch     0 | loss: 0.0248583MemoryTrain:  epoch  7, batch     0 | loss: 0.0182040MemoryTrain:  epoch  8, batch     0 | loss: 0.0146536MemoryTrain:  epoch  9, batch     0 | loss: 0.0162978
[EVAL] batch:    0 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    1 | acc: 81.25%,  total acc: 84.38%   [EVAL] batch:    2 | acc: 75.00%,  total acc: 81.25%   [EVAL] batch:    3 | acc: 0.00%,  total acc: 60.94%   [EVAL] batch:    4 | acc: 0.00%,  total acc: 48.75%   [EVAL] batch:    5 | acc: 0.00%,  total acc: 40.62%   [EVAL] batch:    6 | acc: 0.00%,  total acc: 34.82%   [EVAL] batch:    7 | acc: 0.00%,  total acc: 30.47%   
[EVAL] batch:    0 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:    1 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:    2 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:    3 | acc: 12.50%,  total acc: 7.81%   [EVAL] batch:    4 | acc: 6.25%,  total acc: 7.50%   [EVAL] batch:    5 | acc: 12.50%,  total acc: 8.33%   [EVAL] batch:    6 | acc: 62.50%,  total acc: 16.07%   [EVAL] batch:    7 | acc: 87.50%,  total acc: 25.00%   [EVAL] batch:    8 | acc: 87.50%,  total acc: 31.94%   [EVAL] batch:    9 | acc: 81.25%,  total acc: 36.88%   [EVAL] batch:   10 | acc: 87.50%,  total acc: 41.48%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 45.83%   [EVAL] batch:   12 | acc: 43.75%,  total acc: 45.67%   [EVAL] batch:   13 | acc: 25.00%,  total acc: 44.20%   [EVAL] batch:   14 | acc: 56.25%,  total acc: 45.00%   [EVAL] batch:   15 | acc: 62.50%,  total acc: 46.09%   [EVAL] batch:   16 | acc: 50.00%,  total acc: 46.32%   [EVAL] batch:   17 | acc: 56.25%,  total acc: 46.88%   [EVAL] batch:   18 | acc: 56.25%,  total acc: 47.37%   [EVAL] batch:   19 | acc: 62.50%,  total acc: 48.12%   [EVAL] batch:   20 | acc: 25.00%,  total acc: 47.02%   [EVAL] batch:   21 | acc: 18.75%,  total acc: 45.74%   [EVAL] batch:   22 | acc: 37.50%,  total acc: 45.38%   [EVAL] batch:   23 | acc: 50.00%,  total acc: 45.57%   [EVAL] batch:   24 | acc: 50.00%,  total acc: 45.75%   [EVAL] batch:   25 | acc: 43.75%,  total acc: 45.67%   [EVAL] batch:   26 | acc: 50.00%,  total acc: 45.83%   [EVAL] batch:   27 | acc: 50.00%,  total acc: 45.98%   [EVAL] batch:   28 | acc: 68.75%,  total acc: 46.77%   [EVAL] batch:   29 | acc: 62.50%,  total acc: 47.29%   [EVAL] batch:   30 | acc: 50.00%,  total acc: 47.38%   [EVAL] batch:   31 | acc: 62.50%,  total acc: 47.85%   [EVAL] batch:   32 | acc: 68.75%,  total acc: 48.48%   [EVAL] batch:   33 | acc: 75.00%,  total acc: 49.26%   [EVAL] batch:   34 | acc: 100.00%,  total acc: 50.71%   [EVAL] batch:   35 | acc: 100.00%,  total acc: 52.08%   [EVAL] batch:   36 | acc: 100.00%,  total acc: 53.38%   [EVAL] batch:   37 | acc: 93.75%,  total acc: 54.44%   [EVAL] batch:   38 | acc: 75.00%,  total acc: 54.97%   [EVAL] batch:   39 | acc: 31.25%,  total acc: 54.37%   [EVAL] batch:   40 | acc: 31.25%,  total acc: 53.81%   [EVAL] batch:   41 | acc: 37.50%,  total acc: 53.42%   [EVAL] batch:   42 | acc: 25.00%,  total acc: 52.76%   [EVAL] batch:   43 | acc: 18.75%,  total acc: 51.99%   [EVAL] batch:   44 | acc: 18.75%,  total acc: 51.25%   [EVAL] batch:   45 | acc: 6.25%,  total acc: 50.27%   [EVAL] batch:   46 | acc: 81.25%,  total acc: 50.93%   [EVAL] batch:   47 | acc: 81.25%,  total acc: 51.56%   [EVAL] batch:   48 | acc: 81.25%,  total acc: 52.17%   [EVAL] batch:   49 | acc: 0.00%,  total acc: 51.12%   [EVAL] batch:   50 | acc: 0.00%,  total acc: 50.12%   [EVAL] batch:   51 | acc: 0.00%,  total acc: 49.16%   [EVAL] batch:   52 | acc: 0.00%,  total acc: 48.23%   [EVAL] batch:   53 | acc: 0.00%,  total acc: 47.34%   
cur_acc:  ['0.7405', '0.5402', '0.3047']
his_acc:  ['0.7405', '0.5824', '0.4734']
Mixup data size:  960
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
MixupTrain:  epoch  0, batch     0 | loss: 6.6010427something wrong with mask positions
MixupTrain:  epoch  0, batch     1 | loss: 6.6074257something wrong with mask positions
MixupTrain:  epoch  0, batch     2 | loss: 6.2290201something wrong with mask positions
MixupTrain:  epoch  0, batch     3 | loss: 6.2834482something wrong with mask positions
MixupTrain:  epoch  0, batch     4 | loss: 5.6593599something wrong with mask positions
MixupTrain:  epoch  0, batch     5 | loss: 5.9192915something wrong with mask positions
MixupTrain:  epoch  0, batch     6 | loss: 6.1612625something wrong with mask positions
MixupTrain:  epoch  0, batch     7 | loss: 5.9853253something wrong with mask positions
MixupTrain:  epoch  0, batch     8 | loss: 5.8886895something wrong with mask positions
MixupTrain:  epoch  0, batch     9 | loss: 5.7133121something wrong with mask positions
MixupTrain:  epoch  0, batch    10 | loss: 6.0110345something wrong with mask positions
MixupTrain:  epoch  0, batch    11 | loss: 6.1377239something wrong with mask positions
MixupTrain:  epoch  0, batch    12 | loss: 5.8188257something wrong with mask positions
MixupTrain:  epoch  0, batch    13 | loss: 5.5040126something wrong with mask positions
MixupTrain:  epoch  0, batch    14 | loss: 5.6023011something wrong with mask positions
MixupTrain:  epoch  0, batch    15 | loss: 5.7427368something wrong with mask positions
MixupTrain:  epoch  0, batch    16 | loss: 5.3885751something wrong with mask positions
MixupTrain:  epoch  0, batch    17 | loss: 5.4864073something wrong with mask positions
MixupTrain:  epoch  0, batch    18 | loss: 5.3345523something wrong with mask positions
MixupTrain:  epoch  0, batch    19 | loss: 5.2171392something wrong with mask positions
MixupTrain:  epoch  0, batch    20 | loss: 5.4068079something wrong with mask positions
MixupTrain:  epoch  0, batch    21 | loss: 5.0836668something wrong with mask positions
MixupTrain:  epoch  0, batch    22 | loss: 5.5177021something wrong with mask positions
MixupTrain:  epoch  0, batch    23 | loss: 5.3736601something wrong with mask positions
MixupTrain:  epoch  0, batch    24 | loss: 5.0245333something wrong with mask positions
MixupTrain:  epoch  0, batch    25 | loss: 5.1710978something wrong with mask positions
MixupTrain:  epoch  0, batch    26 | loss: 5.1435604something wrong with mask positions
MixupTrain:  epoch  0, batch    27 | loss: 5.3460860something wrong with mask positions
MixupTrain:  epoch  0, batch    28 | loss: 5.2529516something wrong with mask positions
MixupTrain:  epoch  0, batch    29 | loss: 5.2280931something wrong with mask positions
MixupTrain:  epoch  0, batch    30 | loss: 4.5421195something wrong with mask positions
MixupTrain:  epoch  0, batch    31 | loss: 5.1168671something wrong with mask positions
MixupTrain:  epoch  0, batch    32 | loss: 4.8599739something wrong with mask positions
MixupTrain:  epoch  0, batch    33 | loss: 5.0282125something wrong with mask positions
MixupTrain:  epoch  0, batch    34 | loss: 5.0534596something wrong with mask positions
MixupTrain:  epoch  0, batch    35 | loss: 4.8332448something wrong with mask positions
MixupTrain:  epoch  0, batch    36 | loss: 4.7882385something wrong with mask positions
MixupTrain:  epoch  0, batch    37 | loss: 5.1349697something wrong with mask positions
MixupTrain:  epoch  0, batch    38 | loss: 4.3482103something wrong with mask positions
MixupTrain:  epoch  0, batch    39 | loss: 4.5372686something wrong with mask positions
MixupTrain:  epoch  0, batch    40 | loss: 4.9544802something wrong with mask positions
MixupTrain:  epoch  0, batch    41 | loss: 4.7769260something wrong with mask positions
MixupTrain:  epoch  0, batch    42 | loss: 4.9023895something wrong with mask positions
MixupTrain:  epoch  0, batch    43 | loss: 4.1969795something wrong with mask positions
MixupTrain:  epoch  0, batch    44 | loss: 4.6647630something wrong with mask positions
MixupTrain:  epoch  0, batch    45 | loss: 4.4784765something wrong with mask positions
MixupTrain:  epoch  0, batch    46 | loss: 4.5667286something wrong with mask positions
MixupTrain:  epoch  0, batch    47 | loss: 4.5364437something wrong with mask positions
MixupTrain:  epoch  0, batch    48 | loss: 4.4298105something wrong with mask positions
MixupTrain:  epoch  0, batch    49 | loss: 4.0635037something wrong with mask positions
MixupTrain:  epoch  0, batch    50 | loss: 5.0019355something wrong with mask positions
MixupTrain:  epoch  0, batch    51 | loss: 4.5547996something wrong with mask positions
MixupTrain:  epoch  0, batch    52 | loss: 3.7618670something wrong with mask positions
MixupTrain:  epoch  0, batch    53 | loss: 3.8998222something wrong with mask positions
MixupTrain:  epoch  0, batch    54 | loss: 3.7830358something wrong with mask positions
MixupTrain:  epoch  0, batch    55 | loss: 3.7974906something wrong with mask positions
MixupTrain:  epoch  0, batch    56 | loss: 3.6667247something wrong with mask positions
MixupTrain:  epoch  0, batch    57 | loss: 4.4104624something wrong with mask positions
MixupTrain:  epoch  0, batch    58 | loss: 3.2764480something wrong with mask positions
MixupTrain:  epoch  0, batch    59 | loss: 3.5780396
MemoryTrain:  epoch  0, batch     0 | loss: 0.0172133MemoryTrain:  epoch  0, batch     1 | loss: 0.0540982MemoryTrain:  epoch  1, batch     0 | loss: 0.0180645MemoryTrain:  epoch  1, batch     1 | loss: 0.0426076MemoryTrain:  epoch  2, batch     0 | loss: 0.0168579MemoryTrain:  epoch  2, batch     1 | loss: 0.0073662MemoryTrain:  epoch  3, batch     0 | loss: 0.0090486MemoryTrain:  epoch  3, batch     1 | loss: 0.0050237MemoryTrain:  epoch  4, batch     0 | loss: 0.0073529MemoryTrain:  epoch  4, batch     1 | loss: 0.0042701MemoryTrain:  epoch  5, batch     0 | loss: 0.0084185MemoryTrain:  epoch  5, batch     1 | loss: 0.0043093MemoryTrain:  epoch  6, batch     0 | loss: 0.0131204MemoryTrain:  epoch  6, batch     1 | loss: 0.0046876MemoryTrain:  epoch  7, batch     0 | loss: 0.0054666MemoryTrain:  epoch  7, batch     1 | loss: 0.0057877MemoryTrain:  epoch  8, batch     0 | loss: 0.0062031MemoryTrain:  epoch  8, batch     1 | loss: 0.0041326MemoryTrain:  epoch  9, batch     0 | loss: 0.0062817MemoryTrain:  epoch  9, batch     1 | loss: 0.0037739
[EVAL] batch:    0 | acc: 75.00%,  total acc: 75.00%   [EVAL] batch:    1 | acc: 56.25%,  total acc: 65.62%   [EVAL] batch:    2 | acc: 87.50%,  total acc: 72.92%   [EVAL] batch:    3 | acc: 75.00%,  total acc: 73.44%   [EVAL] batch:    4 | acc: 37.50%,  total acc: 66.25%   [EVAL] batch:    5 | acc: 56.25%,  total acc: 64.58%   [EVAL] batch:    6 | acc: 62.50%,  total acc: 64.29%   [EVAL] batch:    7 | acc: 37.50%,  total acc: 60.94%   [EVAL] batch:    8 | acc: 6.25%,  total acc: 54.86%   [EVAL] batch:    9 | acc: 12.50%,  total acc: 50.62%   [EVAL] batch:   10 | acc: 25.00%,  total acc: 48.30%   [EVAL] batch:   11 | acc: 37.50%,  total acc: 47.40%   [EVAL] batch:   12 | acc: 18.75%,  total acc: 45.19%   
[EVAL] batch:    0 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:    1 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:    2 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:    3 | acc: 12.50%,  total acc: 7.81%   [EVAL] batch:    4 | acc: 6.25%,  total acc: 7.50%   [EVAL] batch:    5 | acc: 12.50%,  total acc: 8.33%   [EVAL] batch:    6 | acc: 56.25%,  total acc: 15.18%   [EVAL] batch:    7 | acc: 68.75%,  total acc: 21.88%   [EVAL] batch:    8 | acc: 87.50%,  total acc: 29.17%   [EVAL] batch:    9 | acc: 50.00%,  total acc: 31.25%   [EVAL] batch:   10 | acc: 68.75%,  total acc: 34.66%   [EVAL] batch:   11 | acc: 93.75%,  total acc: 39.58%   [EVAL] batch:   12 | acc: 31.25%,  total acc: 38.94%   [EVAL] batch:   13 | acc: 18.75%,  total acc: 37.50%   [EVAL] batch:   14 | acc: 43.75%,  total acc: 37.92%   [EVAL] batch:   15 | acc: 25.00%,  total acc: 37.11%   [EVAL] batch:   16 | acc: 25.00%,  total acc: 36.40%   [EVAL] batch:   17 | acc: 25.00%,  total acc: 35.76%   [EVAL] batch:   18 | acc: 25.00%,  total acc: 35.20%   [EVAL] batch:   19 | acc: 37.50%,  total acc: 35.31%   [EVAL] batch:   20 | acc: 25.00%,  total acc: 34.82%   [EVAL] batch:   21 | acc: 12.50%,  total acc: 33.81%   [EVAL] batch:   22 | acc: 43.75%,  total acc: 34.24%   [EVAL] batch:   23 | acc: 43.75%,  total acc: 34.64%   [EVAL] batch:   24 | acc: 31.25%,  total acc: 34.50%   [EVAL] batch:   25 | acc: 37.50%,  total acc: 34.62%   [EVAL] batch:   26 | acc: 43.75%,  total acc: 34.95%   [EVAL] batch:   27 | acc: 37.50%,  total acc: 35.04%   [EVAL] batch:   28 | acc: 43.75%,  total acc: 35.34%   [EVAL] batch:   29 | acc: 37.50%,  total acc: 35.42%   [EVAL] batch:   30 | acc: 31.25%,  total acc: 35.28%   [EVAL] batch:   31 | acc: 37.50%,  total acc: 35.35%   [EVAL] batch:   32 | acc: 50.00%,  total acc: 35.80%   [EVAL] batch:   33 | acc: 50.00%,  total acc: 36.21%   [EVAL] batch:   34 | acc: 81.25%,  total acc: 37.50%   [EVAL] batch:   35 | acc: 62.50%,  total acc: 38.19%   [EVAL] batch:   36 | acc: 50.00%,  total acc: 38.51%   [EVAL] batch:   37 | acc: 81.25%,  total acc: 39.64%   [EVAL] batch:   38 | acc: 56.25%,  total acc: 40.06%   [EVAL] batch:   39 | acc: 25.00%,  total acc: 39.69%   [EVAL] batch:   40 | acc: 18.75%,  total acc: 39.18%   [EVAL] batch:   41 | acc: 18.75%,  total acc: 38.69%   [EVAL] batch:   42 | acc: 12.50%,  total acc: 38.08%   [EVAL] batch:   43 | acc: 12.50%,  total acc: 37.50%   [EVAL] batch:   44 | acc: 6.25%,  total acc: 36.81%   [EVAL] batch:   45 | acc: 6.25%,  total acc: 36.14%   [EVAL] batch:   46 | acc: 18.75%,  total acc: 35.77%   [EVAL] batch:   47 | acc: 56.25%,  total acc: 36.20%   [EVAL] batch:   48 | acc: 81.25%,  total acc: 37.12%   [EVAL] batch:   49 | acc: 0.00%,  total acc: 36.38%   [EVAL] batch:   50 | acc: 0.00%,  total acc: 35.66%   [EVAL] batch:   51 | acc: 0.00%,  total acc: 34.98%   [EVAL] batch:   52 | acc: 0.00%,  total acc: 34.32%   [EVAL] batch:   53 | acc: 62.50%,  total acc: 34.84%   [EVAL] batch:   54 | acc: 56.25%,  total acc: 35.23%   [EVAL] batch:   55 | acc: 81.25%,  total acc: 36.05%   [EVAL] batch:   56 | acc: 81.25%,  total acc: 36.84%   [EVAL] batch:   57 | acc: 43.75%,  total acc: 36.96%   [EVAL] batch:   58 | acc: 62.50%,  total acc: 37.39%   [EVAL] batch:   59 | acc: 50.00%,  total acc: 37.60%   [EVAL] batch:   60 | acc: 37.50%,  total acc: 37.60%   [EVAL] batch:   61 | acc: 18.75%,  total acc: 37.30%   [EVAL] batch:   62 | acc: 6.25%,  total acc: 36.81%   [EVAL] batch:   63 | acc: 31.25%,  total acc: 36.72%   [EVAL] batch:   64 | acc: 31.25%,  total acc: 36.63%   [EVAL] batch:   65 | acc: 25.00%,  total acc: 36.46%   
cur_acc:  ['0.7405', '0.5402', '0.3047', '0.4519']
his_acc:  ['0.7405', '0.5824', '0.4734', '0.3646']
Mixup data size:  1200
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
MixupTrain:  epoch  0, batch     0 | loss: 5.2628098something wrong with mask positions
MixupTrain:  epoch  0, batch     1 | loss: 5.5041246something wrong with mask positions
MixupTrain:  epoch  0, batch     2 | loss: 5.2452230something wrong with mask positions
MixupTrain:  epoch  0, batch     3 | loss: 5.6717873something wrong with mask positions
MixupTrain:  epoch  0, batch     4 | loss: 5.6850019something wrong with mask positions
MixupTrain:  epoch  0, batch     5 | loss: 5.2716866something wrong with mask positions
MixupTrain:  epoch  0, batch     6 | loss: 4.8397679something wrong with mask positions
MixupTrain:  epoch  0, batch     7 | loss: 5.6490650something wrong with mask positions
MixupTrain:  epoch  0, batch     8 | loss: 4.7313857something wrong with mask positions
MixupTrain:  epoch  0, batch     9 | loss: 5.1426163something wrong with mask positions
MixupTrain:  epoch  0, batch    10 | loss: 5.2984791something wrong with mask positions
MixupTrain:  epoch  0, batch    11 | loss: 4.7503090something wrong with mask positions
MixupTrain:  epoch  0, batch    12 | loss: 5.5824509something wrong with mask positions
MixupTrain:  epoch  0, batch    13 | loss: 4.0400915something wrong with mask positions
MixupTrain:  epoch  0, batch    14 | loss: 4.7361641something wrong with mask positions
MixupTrain:  epoch  0, batch    15 | loss: 5.1528764something wrong with mask positions
MixupTrain:  epoch  0, batch    16 | loss: 5.0967407something wrong with mask positions
MixupTrain:  epoch  0, batch    17 | loss: 4.3815575something wrong with mask positions
MixupTrain:  epoch  0, batch    18 | loss: 4.5755167something wrong with mask positions
MixupTrain:  epoch  0, batch    19 | loss: 4.2132168something wrong with mask positions
MixupTrain:  epoch  0, batch    20 | loss: 4.8045278something wrong with mask positions
MixupTrain:  epoch  0, batch    21 | loss: 4.3403025something wrong with mask positions
MixupTrain:  epoch  0, batch    22 | loss: 4.7731371something wrong with mask positions
MixupTrain:  epoch  0, batch    23 | loss: 4.0975714something wrong with mask positions
MixupTrain:  epoch  0, batch    24 | loss: 4.3048353something wrong with mask positions
MixupTrain:  epoch  0, batch    25 | loss: 4.0554619something wrong with mask positions
MixupTrain:  epoch  0, batch    26 | loss: 3.9498370something wrong with mask positions
MixupTrain:  epoch  0, batch    27 | loss: 2.8196690something wrong with mask positions
MixupTrain:  epoch  0, batch    28 | loss: 3.7828100something wrong with mask positions
MixupTrain:  epoch  0, batch    29 | loss: 3.5642509something wrong with mask positions
MixupTrain:  epoch  0, batch    30 | loss: 2.9618952something wrong with mask positions
MixupTrain:  epoch  0, batch    31 | loss: 3.7698202something wrong with mask positions
MixupTrain:  epoch  0, batch    32 | loss: 3.6710744something wrong with mask positions
MixupTrain:  epoch  0, batch    33 | loss: 3.2813263something wrong with mask positions
MixupTrain:  epoch  0, batch    34 | loss: 3.6972754something wrong with mask positions
MixupTrain:  epoch  0, batch    35 | loss: 3.1632967something wrong with mask positions
MixupTrain:  epoch  0, batch    36 | loss: 3.1201274something wrong with mask positions
MixupTrain:  epoch  0, batch    37 | loss: 3.5287192something wrong with mask positions
MixupTrain:  epoch  0, batch    38 | loss: 2.8423591something wrong with mask positions
MixupTrain:  epoch  0, batch    39 | loss: 2.9273252something wrong with mask positions
MixupTrain:  epoch  0, batch    40 | loss: 3.2177930something wrong with mask positions
MixupTrain:  epoch  0, batch    41 | loss: 3.5512936something wrong with mask positions
MixupTrain:  epoch  0, batch    42 | loss: 3.0155630something wrong with mask positions
MixupTrain:  epoch  0, batch    43 | loss: 3.1723099something wrong with mask positions
MixupTrain:  epoch  0, batch    44 | loss: 3.1895962something wrong with mask positions
MixupTrain:  epoch  0, batch    45 | loss: 2.5138493something wrong with mask positions
MixupTrain:  epoch  0, batch    46 | loss: 2.4791217something wrong with mask positions
MixupTrain:  epoch  0, batch    47 | loss: 1.8399181something wrong with mask positions
MixupTrain:  epoch  0, batch    48 | loss: 2.2348061something wrong with mask positions
MixupTrain:  epoch  0, batch    49 | loss: 2.7651162something wrong with mask positions
MixupTrain:  epoch  0, batch    50 | loss: 2.1144838something wrong with mask positions
MixupTrain:  epoch  0, batch    51 | loss: 2.9841909something wrong with mask positions
MixupTrain:  epoch  0, batch    52 | loss: 2.6834898something wrong with mask positions
MixupTrain:  epoch  0, batch    53 | loss: 2.3640327something wrong with mask positions
MixupTrain:  epoch  0, batch    54 | loss: 2.0539567something wrong with mask positions
MixupTrain:  epoch  0, batch    55 | loss: 2.7498341something wrong with mask positions
MixupTrain:  epoch  0, batch    56 | loss: 2.7338138something wrong with mask positions
MixupTrain:  epoch  0, batch    57 | loss: 2.0416744something wrong with mask positions
MixupTrain:  epoch  0, batch    58 | loss: 1.9657094something wrong with mask positions
MixupTrain:  epoch  0, batch    59 | loss: 2.0017402something wrong with mask positions
MixupTrain:  epoch  0, batch    60 | loss: 2.5415034something wrong with mask positions
MixupTrain:  epoch  0, batch    61 | loss: 2.3874865something wrong with mask positions
MixupTrain:  epoch  0, batch    62 | loss: 2.6752880something wrong with mask positions
MixupTrain:  epoch  0, batch    63 | loss: 2.1074233something wrong with mask positions
MixupTrain:  epoch  0, batch    64 | loss: 2.6428483something wrong with mask positions
MixupTrain:  epoch  0, batch    65 | loss: 1.2987611something wrong with mask positions
MixupTrain:  epoch  0, batch    66 | loss: 2.2304254something wrong with mask positions
MixupTrain:  epoch  0, batch    67 | loss: 1.7103978something wrong with mask positions
MixupTrain:  epoch  0, batch    68 | loss: 1.2663522something wrong with mask positions
MixupTrain:  epoch  0, batch    69 | loss: 1.7284046something wrong with mask positions
MixupTrain:  epoch  0, batch    70 | loss: 1.6273351something wrong with mask positions
MixupTrain:  epoch  0, batch    71 | loss: 1.4895425something wrong with mask positions
MixupTrain:  epoch  0, batch    72 | loss: 1.3315494something wrong with mask positions
MixupTrain:  epoch  0, batch    73 | loss: 1.8040195something wrong with mask positions
MixupTrain:  epoch  0, batch    74 | loss: 1.7519393
MemoryTrain:  epoch  0, batch     0 | loss: 0.1185407MemoryTrain:  epoch  0, batch     1 | loss: 0.0563188MemoryTrain:  epoch  1, batch     0 | loss: 0.0280879MemoryTrain:  epoch  1, batch     1 | loss: 0.0172136MemoryTrain:  epoch  2, batch     0 | loss: 0.0136847MemoryTrain:  epoch  2, batch     1 | loss: 0.0071824MemoryTrain:  epoch  3, batch     0 | loss: 0.0328177MemoryTrain:  epoch  3, batch     1 | loss: 0.0136430MemoryTrain:  epoch  4, batch     0 | loss: 0.0170246MemoryTrain:  epoch  4, batch     1 | loss: 0.0272630MemoryTrain:  epoch  5, batch     0 | loss: 0.0067114MemoryTrain:  epoch  5, batch     1 | loss: 0.0057072MemoryTrain:  epoch  6, batch     0 | loss: 0.0045521MemoryTrain:  epoch  6, batch     1 | loss: 0.0044449MemoryTrain:  epoch  7, batch     0 | loss: 0.0046043MemoryTrain:  epoch  7, batch     1 | loss: 0.0055320MemoryTrain:  epoch  8, batch     0 | loss: 0.0040153MemoryTrain:  epoch  8, batch     1 | loss: 0.0031719MemoryTrain:  epoch  9, batch     0 | loss: 0.0038584MemoryTrain:  epoch  9, batch     1 | loss: 0.0041700
[EVAL] batch:    0 | acc: 43.75%,  total acc: 43.75%   [EVAL] batch:    1 | acc: 37.50%,  total acc: 40.62%   [EVAL] batch:    2 | acc: 37.50%,  total acc: 39.58%   [EVAL] batch:    3 | acc: 25.00%,  total acc: 35.94%   [EVAL] batch:    4 | acc: 0.00%,  total acc: 28.75%   [EVAL] batch:    5 | acc: 25.00%,  total acc: 28.12%   [EVAL] batch:    6 | acc: 25.00%,  total acc: 27.68%   [EVAL] batch:    7 | acc: 37.50%,  total acc: 28.91%   [EVAL] batch:    8 | acc: 31.25%,  total acc: 29.17%   [EVAL] batch:    9 | acc: 25.00%,  total acc: 28.75%   [EVAL] batch:   10 | acc: 50.00%,  total acc: 30.68%   [EVAL] batch:   11 | acc: 50.00%,  total acc: 32.29%   [EVAL] batch:   12 | acc: 37.50%,  total acc: 32.69%   [EVAL] batch:   13 | acc: 6.25%,  total acc: 30.80%   [EVAL] batch:   14 | acc: 37.50%,  total acc: 31.25%   [EVAL] batch:   15 | acc: 18.75%,  total acc: 30.47%   [EVAL] batch:   16 | acc: 6.25%,  total acc: 29.04%   [EVAL] batch:   17 | acc: 25.00%,  total acc: 28.82%   [EVAL] batch:   18 | acc: 43.75%,  total acc: 29.61%   [EVAL] batch:   19 | acc: 75.00%,  total acc: 31.87%   [EVAL] batch:   20 | acc: 62.50%,  total acc: 33.33%   [EVAL] batch:   21 | acc: 31.25%,  total acc: 33.24%   
[EVAL] batch:    0 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:    1 | acc: 12.50%,  total acc: 9.38%   [EVAL] batch:    2 | acc: 25.00%,  total acc: 14.58%   [EVAL] batch:    3 | acc: 18.75%,  total acc: 15.62%   [EVAL] batch:    4 | acc: 6.25%,  total acc: 13.75%   [EVAL] batch:    5 | acc: 18.75%,  total acc: 14.58%   [EVAL] batch:    6 | acc: 18.75%,  total acc: 15.18%   [EVAL] batch:    7 | acc: 25.00%,  total acc: 16.41%   [EVAL] batch:    8 | acc: 56.25%,  total acc: 20.83%   [EVAL] batch:    9 | acc: 43.75%,  total acc: 23.12%   [EVAL] batch:   10 | acc: 62.50%,  total acc: 26.70%   [EVAL] batch:   11 | acc: 56.25%,  total acc: 29.17%   [EVAL] batch:   12 | acc: 25.00%,  total acc: 28.85%   [EVAL] batch:   13 | acc: 12.50%,  total acc: 27.68%   [EVAL] batch:   14 | acc: 50.00%,  total acc: 29.17%   [EVAL] batch:   15 | acc: 37.50%,  total acc: 29.69%   [EVAL] batch:   16 | acc: 31.25%,  total acc: 29.78%   [EVAL] batch:   17 | acc: 37.50%,  total acc: 30.21%   [EVAL] batch:   18 | acc: 37.50%,  total acc: 30.59%   [EVAL] batch:   19 | acc: 37.50%,  total acc: 30.94%   [EVAL] batch:   20 | acc: 12.50%,  total acc: 30.06%   [EVAL] batch:   21 | acc: 6.25%,  total acc: 28.98%   [EVAL] batch:   22 | acc: 31.25%,  total acc: 29.08%   [EVAL] batch:   23 | acc: 25.00%,  total acc: 28.91%   [EVAL] batch:   24 | acc: 18.75%,  total acc: 28.50%   [EVAL] batch:   25 | acc: 37.50%,  total acc: 28.85%   [EVAL] batch:   26 | acc: 37.50%,  total acc: 29.17%   [EVAL] batch:   27 | acc: 31.25%,  total acc: 29.24%   [EVAL] batch:   28 | acc: 25.00%,  total acc: 29.09%   [EVAL] batch:   29 | acc: 37.50%,  total acc: 29.38%   [EVAL] batch:   30 | acc: 31.25%,  total acc: 29.44%   [EVAL] batch:   31 | acc: 25.00%,  total acc: 29.30%   [EVAL] batch:   32 | acc: 56.25%,  total acc: 30.11%   [EVAL] batch:   33 | acc: 31.25%,  total acc: 30.15%   [EVAL] batch:   34 | acc: 31.25%,  total acc: 30.18%   [EVAL] batch:   35 | acc: 18.75%,  total acc: 29.86%   [EVAL] batch:   36 | acc: 6.25%,  total acc: 29.22%   [EVAL] batch:   37 | acc: 25.00%,  total acc: 29.11%   [EVAL] batch:   38 | acc: 12.50%,  total acc: 28.69%   [EVAL] batch:   39 | acc: 18.75%,  total acc: 28.44%   [EVAL] batch:   40 | acc: 37.50%,  total acc: 28.66%   [EVAL] batch:   41 | acc: 12.50%,  total acc: 28.27%   [EVAL] batch:   42 | acc: 6.25%,  total acc: 27.76%   [EVAL] batch:   43 | acc: 18.75%,  total acc: 27.56%   [EVAL] batch:   44 | acc: 12.50%,  total acc: 27.22%   [EVAL] batch:   45 | acc: 0.00%,  total acc: 26.63%   [EVAL] batch:   46 | acc: 12.50%,  total acc: 26.33%   [EVAL] batch:   47 | acc: 37.50%,  total acc: 26.56%   [EVAL] batch:   48 | acc: 0.00%,  total acc: 26.02%   [EVAL] batch:   49 | acc: 0.00%,  total acc: 25.50%   [EVAL] batch:   50 | acc: 0.00%,  total acc: 25.00%   [EVAL] batch:   51 | acc: 0.00%,  total acc: 24.52%   [EVAL] batch:   52 | acc: 0.00%,  total acc: 24.06%   [EVAL] batch:   53 | acc: 37.50%,  total acc: 24.31%   [EVAL] batch:   54 | acc: 12.50%,  total acc: 24.09%   [EVAL] batch:   55 | acc: 50.00%,  total acc: 24.55%   [EVAL] batch:   56 | acc: 56.25%,  total acc: 25.11%   [EVAL] batch:   57 | acc: 6.25%,  total acc: 24.78%   [EVAL] batch:   58 | acc: 6.25%,  total acc: 24.47%   [EVAL] batch:   59 | acc: 12.50%,  total acc: 24.27%   [EVAL] batch:   60 | acc: 25.00%,  total acc: 24.28%   [EVAL] batch:   61 | acc: 12.50%,  total acc: 24.09%   [EVAL] batch:   62 | acc: 0.00%,  total acc: 23.71%   [EVAL] batch:   63 | acc: 18.75%,  total acc: 23.63%   [EVAL] batch:   64 | acc: 18.75%,  total acc: 23.56%   [EVAL] batch:   65 | acc: 25.00%,  total acc: 23.58%   [EVAL] batch:   66 | acc: 37.50%,  total acc: 23.79%   [EVAL] batch:   67 | acc: 43.75%,  total acc: 24.08%   [EVAL] batch:   68 | acc: 31.25%,  total acc: 24.18%   [EVAL] batch:   69 | acc: 18.75%,  total acc: 24.11%   [EVAL] batch:   70 | acc: 6.25%,  total acc: 23.86%   [EVAL] batch:   71 | acc: 31.25%,  total acc: 23.96%   [EVAL] batch:   72 | acc: 18.75%,  total acc: 23.89%   [EVAL] batch:   73 | acc: 31.25%,  total acc: 23.99%   [EVAL] batch:   74 | acc: 37.50%,  total acc: 24.17%   [EVAL] batch:   75 | acc: 31.25%,  total acc: 24.26%   [EVAL] batch:   76 | acc: 50.00%,  total acc: 24.59%   [EVAL] batch:   77 | acc: 37.50%,  total acc: 24.76%   [EVAL] batch:   78 | acc: 37.50%,  total acc: 24.92%   [EVAL] batch:   79 | acc: 18.75%,  total acc: 24.84%   [EVAL] batch:   80 | acc: 31.25%,  total acc: 24.92%   [EVAL] batch:   81 | acc: 18.75%,  total acc: 24.85%   [EVAL] batch:   82 | acc: 6.25%,  total acc: 24.62%   [EVAL] batch:   83 | acc: 31.25%,  total acc: 24.70%   [EVAL] batch:   84 | acc: 56.25%,  total acc: 25.07%   [EVAL] batch:   85 | acc: 68.75%,  total acc: 25.58%   [EVAL] batch:   86 | acc: 56.25%,  total acc: 25.93%   [EVAL] batch:   87 | acc: 18.75%,  total acc: 25.85%   
cur_acc:  ['0.7405', '0.5402', '0.3047', '0.4519', '0.3324']
his_acc:  ['0.7405', '0.5824', '0.4734', '0.3646', '0.2585']
Mixup data size:  1465
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
something wrong with mask positions
MixupTrain:  epoch  0, batch     0 | loss: 4.1199999something wrong with mask positions
MixupTrain:  epoch  0, batch     1 | loss: 4.0046077something wrong with mask positions
MixupTrain:  epoch  0, batch     2 | loss: 3.3904910something wrong with mask positions
MixupTrain:  epoch  0, batch     3 | loss: 3.9597049something wrong with mask positions
MixupTrain:  epoch  0, batch     4 | loss: 3.0611022something wrong with mask positions
MixupTrain:  epoch  0, batch     5 | loss: 4.4647422something wrong with mask positions
MixupTrain:  epoch  0, batch     6 | loss: 3.5256195something wrong with mask positions
MixupTrain:  epoch  0, batch     7 | loss: 3.1423960something wrong with mask positions
MixupTrain:  epoch  0, batch     8 | loss: 1.9610559something wrong with mask positions
MixupTrain:  epoch  0, batch     9 | loss: 3.0976138something wrong with mask positions
MixupTrain:  epoch  0, batch    10 | loss: 2.4283276something wrong with mask positions
MixupTrain:  epoch  0, batch    11 | loss: 2.6790297something wrong with mask positions
MixupTrain:  epoch  0, batch    12 | loss: 1.9679470something wrong with mask positions
MixupTrain:  epoch  0, batch    13 | loss: 2.8602824something wrong with mask positions
MixupTrain:  epoch  0, batch    14 | loss: 2.2438729something wrong with mask positions
MixupTrain:  epoch  0, batch    15 | loss: 2.5049138something wrong with mask positions
MixupTrain:  epoch  0, batch    16 | loss: 1.9483854something wrong with mask positions
MixupTrain:  epoch  0, batch    17 | loss: 2.3192515something wrong with mask positions
MixupTrain:  epoch  0, batch    18 | loss: 2.5727651something wrong with mask positions
MixupTrain:  epoch  0, batch    19 | loss: 2.8622718something wrong with mask positions
MixupTrain:  epoch  0, batch    20 | loss: 1.6417965something wrong with mask positions
MixupTrain:  epoch  0, batch    21 | loss: 2.6094134something wrong with mask positions
MixupTrain:  epoch  0, batch    22 | loss: 1.7149644something wrong with mask positions
MixupTrain:  epoch  0, batch    23 | loss: 2.0684559something wrong with mask positions
MixupTrain:  epoch  0, batch    24 | loss: 1.5628040something wrong with mask positions
MixupTrain:  epoch  0, batch    25 | loss: 2.2407076something wrong with mask positions
MixupTrain:  epoch  0, batch    26 | loss: 1.9398344something wrong with mask positions
MixupTrain:  epoch  0, batch    27 | loss: 1.1381918something wrong with mask positions
MixupTrain:  epoch  0, batch    28 | loss: 1.7573948something wrong with mask positions
MixupTrain:  epoch  0, batch    29 | loss: 1.6106460something wrong with mask positions
MixupTrain:  epoch  0, batch    30 | loss: 1.4751263something wrong with mask positions
MixupTrain:  epoch  0, batch    31 | loss: 1.8085464something wrong with mask positions
MixupTrain:  epoch  0, batch    32 | loss: 1.7907476something wrong with mask positions
MixupTrain:  epoch  0, batch    33 | loss: 1.3842896something wrong with mask positions
MixupTrain:  epoch  0, batch    34 | loss: 1.6364987something wrong with mask positions
MixupTrain:  epoch  0, batch    35 | loss: 1.1771530something wrong with mask positions
MixupTrain:  epoch  0, batch    36 | loss: 1.3568709something wrong with mask positions
MixupTrain:  epoch  0, batch    37 | loss: 1.1255004something wrong with mask positions
MixupTrain:  epoch  0, batch    38 | loss: 1.6676842something wrong with mask positions
MixupTrain:  epoch  0, batch    39 | loss: 1.6446310something wrong with mask positions
MixupTrain:  epoch  0, batch    40 | loss: 1.2047307something wrong with mask positions
MixupTrain:  epoch  0, batch    41 | loss: 0.7543438something wrong with mask positions
MixupTrain:  epoch  0, batch    42 | loss: 1.2113616something wrong with mask positions
MixupTrain:  epoch  0, batch    43 | loss: 0.8982135something wrong with mask positions
MixupTrain:  epoch  0, batch    44 | loss: 1.2159584something wrong with mask positions
MixupTrain:  epoch  0, batch    45 | loss: 1.4455261something wrong with mask positions
MixupTrain:  epoch  0, batch    46 | loss: 0.6579173something wrong with mask positions
MixupTrain:  epoch  0, batch    47 | loss: 1.0205693something wrong with mask positions
MixupTrain:  epoch  0, batch    48 | loss: 0.7448587something wrong with mask positions
MixupTrain:  epoch  0, batch    49 | loss: 0.7991886something wrong with mask positions
MixupTrain:  epoch  0, batch    50 | loss: 0.9625122something wrong with mask positions
MixupTrain:  epoch  0, batch    51 | loss: 0.6245915something wrong with mask positions
MixupTrain:  epoch  0, batch    52 | loss: 0.8790655something wrong with mask positions
MixupTrain:  epoch  0, batch    53 | loss: 0.5433047something wrong with mask positions
MixupTrain:  epoch  0, batch    54 | loss: 0.4935147something wrong with mask positions
MixupTrain:  epoch  0, batch    55 | loss: 0.5117218something wrong with mask positions
MixupTrain:  epoch  0, batch    56 | loss: 0.5382798something wrong with mask positions
MixupTrain:  epoch  0, batch    57 | loss: 0.6183944something wrong with mask positions
MixupTrain:  epoch  0, batch    58 | loss: 0.3657159something wrong with mask positions
MixupTrain:  epoch  0, batch    59 | loss: 0.3998963something wrong with mask positions
MixupTrain:  epoch  0, batch    60 | loss: 0.2591782something wrong with mask positions
MixupTrain:  epoch  0, batch    61 | loss: 0.4696807something wrong with mask positions
MixupTrain:  epoch  0, batch    62 | loss: 0.4323350something wrong with mask positions
MixupTrain:  epoch  0, batch    63 | loss: 0.2242680something wrong with mask positions
MixupTrain:  epoch  0, batch    64 | loss: 0.4313668something wrong with mask positions
MixupTrain:  epoch  0, batch    65 | loss: 0.2420660something wrong with mask positions
MixupTrain:  epoch  0, batch    66 | loss: 0.2788315something wrong with mask positions
MixupTrain:  epoch  0, batch    67 | loss: 0.3511008something wrong with mask positions
MixupTrain:  epoch  0, batch    68 | loss: 0.2405302something wrong with mask positions
MixupTrain:  epoch  0, batch    69 | loss: 0.5974832something wrong with mask positions
MixupTrain:  epoch  0, batch    70 | loss: 0.2269154something wrong with mask positions
MixupTrain:  epoch  0, batch    71 | loss: 0.4081566something wrong with mask positions
MixupTrain:  epoch  0, batch    72 | loss: 0.5906329something wrong with mask positions
MixupTrain:  epoch  0, batch    73 | loss: 0.5047427something wrong with mask positions
MixupTrain:  epoch  0, batch    74 | loss: 0.2697563something wrong with mask positions
MixupTrain:  epoch  0, batch    75 | loss: 0.8263758something wrong with mask positions
MixupTrain:  epoch  0, batch    76 | loss: 0.2768458something wrong with mask positions
MixupTrain:  epoch  0, batch    77 | loss: 0.2020397something wrong with mask positions
MixupTrain:  epoch  0, batch    78 | loss: 0.4693584something wrong with mask positions
MixupTrain:  epoch  0, batch    79 | loss: 0.2252032something wrong with mask positions
MixupTrain:  epoch  0, batch    80 | loss: 0.2254560something wrong with mask positions
MixupTrain:  epoch  0, batch    81 | loss: 0.4168204something wrong with mask positions
MixupTrain:  epoch  0, batch    82 | loss: 0.1674348something wrong with mask positions
MixupTrain:  epoch  0, batch    83 | loss: 0.2508147something wrong with mask positions
MixupTrain:  epoch  0, batch    84 | loss: 0.3985385something wrong with mask positions
MixupTrain:  epoch  0, batch    85 | loss: 0.3471892something wrong with mask positions
MixupTrain:  epoch  0, batch    86 | loss: 0.2905174something wrong with mask positions
MixupTrain:  epoch  0, batch    87 | loss: 0.2184597something wrong with mask positions
MixupTrain:  epoch  0, batch    88 | loss: 0.2377253something wrong with mask positions
MixupTrain:  epoch  0, batch    89 | loss: 0.1848287something wrong with mask positions
MixupTrain:  epoch  0, batch    90 | loss: 0.1845456something wrong with mask positions
MixupTrain:  epoch  0, batch    91 | loss: 0.2615118
MemoryTrain:  epoch  0, batch     0 | loss: 0.0209526MemoryTrain:  epoch  0, batch     1 | loss: 0.0183664MemoryTrain:  epoch  1, batch     0 | loss: 0.0050410MemoryTrain:  epoch  1, batch     1 | loss: 0.0192438MemoryTrain:  epoch  2, batch     0 | loss: 0.0056330MemoryTrain:  epoch  2, batch     1 | loss: 0.0052076MemoryTrain:  epoch  3, batch     0 | loss: 0.0046444MemoryTrain:  epoch  3, batch     1 | loss: 0.0036418MemoryTrain:  epoch  4, batch     0 | loss: 0.0040929MemoryTrain:  epoch  4, batch     1 | loss: 0.0028996MemoryTrain:  epoch  5, batch     0 | loss: 0.0038403MemoryTrain:  epoch  5, batch     1 | loss: 0.0038309MemoryTrain:  epoch  6, batch     0 | loss: 0.0032046MemoryTrain:  epoch  6, batch     1 | loss: 0.0028602MemoryTrain:  epoch  7, batch     0 | loss: 0.0024350MemoryTrain:  epoch  7, batch     1 | loss: 0.0032246MemoryTrain:  epoch  8, batch     0 | loss: 0.0026162MemoryTrain:  epoch  8, batch     1 | loss: 0.0024022MemoryTrain:  epoch  9, batch     0 | loss: 0.0024539MemoryTrain:  epoch  9, batch     1 | loss: 0.0021738
[EVAL] batch:    0 | acc: 87.50%,  total acc: 87.50%   [EVAL] batch:    1 | acc: 93.75%,  total acc: 90.62%   [EVAL] batch:    2 | acc: 62.50%,  total acc: 81.25%   [EVAL] batch:    3 | acc: 75.00%,  total acc: 79.69%   [EVAL] batch:    4 | acc: 75.00%,  total acc: 78.75%   [EVAL] batch:    5 | acc: 43.75%,  total acc: 72.92%   [EVAL] batch:    6 | acc: 81.25%,  total acc: 74.11%   [EVAL] batch:    7 | acc: 93.75%,  total acc: 76.56%   [EVAL] batch:    8 | acc: 56.25%,  total acc: 74.31%   [EVAL] batch:    9 | acc: 37.50%,  total acc: 70.62%   [EVAL] batch:   10 | acc: 62.50%,  total acc: 69.89%   [EVAL] batch:   11 | acc: 87.50%,  total acc: 71.35%   [EVAL] batch:   12 | acc: 75.00%,  total acc: 71.63%   [EVAL] batch:   13 | acc: 62.50%,  total acc: 70.98%   
[EVAL] batch:    0 | acc: 6.25%,  total acc: 6.25%   [EVAL] batch:    1 | acc: 12.50%,  total acc: 9.38%   [EVAL] batch:    2 | acc: 12.50%,  total acc: 10.42%   [EVAL] batch:    3 | acc: 18.75%,  total acc: 12.50%   [EVAL] batch:    4 | acc: 6.25%,  total acc: 11.25%   [EVAL] batch:    5 | acc: 18.75%,  total acc: 12.50%   [EVAL] batch:    6 | acc: 12.50%,  total acc: 12.50%   [EVAL] batch:    7 | acc: 18.75%,  total acc: 13.28%   [EVAL] batch:    8 | acc: 50.00%,  total acc: 17.36%   [EVAL] batch:    9 | acc: 37.50%,  total acc: 19.38%   [EVAL] batch:   10 | acc: 37.50%,  total acc: 21.02%   [EVAL] batch:   11 | acc: 50.00%,  total acc: 23.44%   [EVAL] batch:   12 | acc: 25.00%,  total acc: 23.56%   [EVAL] batch:   13 | acc: 12.50%,  total acc: 22.77%   [EVAL] batch:   14 | acc: 25.00%,  total acc: 22.92%   [EVAL] batch:   15 | acc: 18.75%,  total acc: 22.66%   [EVAL] batch:   16 | acc: 12.50%,  total acc: 22.06%   [EVAL] batch:   17 | acc: 0.00%,  total acc: 20.83%   [EVAL] batch:   18 | acc: 31.25%,  total acc: 21.38%   [EVAL] batch:   19 | acc: 25.00%,  total acc: 21.56%   [EVAL] batch:   20 | acc: 6.25%,  total acc: 20.83%   [EVAL] batch:   21 | acc: 0.00%,  total acc: 19.89%   [EVAL] batch:   22 | acc: 25.00%,  total acc: 20.11%   [EVAL] batch:   23 | acc: 18.75%,  total acc: 20.05%   [EVAL] batch:   24 | acc: 12.50%,  total acc: 19.75%   [EVAL] batch:   25 | acc: 25.00%,  total acc: 19.95%   [EVAL] batch:   26 | acc: 37.50%,  total acc: 20.60%   [EVAL] batch:   27 | acc: 25.00%,  total acc: 20.76%   [EVAL] batch:   28 | acc: 25.00%,  total acc: 20.91%   [EVAL] batch:   29 | acc: 37.50%,  total acc: 21.46%   [EVAL] batch:   30 | acc: 31.25%,  total acc: 21.77%   [EVAL] batch:   31 | acc: 37.50%,  total acc: 22.27%   [EVAL] batch:   32 | acc: 25.00%,  total acc: 22.35%   [EVAL] batch:   33 | acc: 31.25%,  total acc: 22.61%   [EVAL] batch:   34 | acc: 56.25%,  total acc: 23.57%   [EVAL] batch:   35 | acc: 18.75%,  total acc: 23.44%   [EVAL] batch:   36 | acc: 6.25%,  total acc: 22.97%   [EVAL] batch:   37 | acc: 31.25%,  total acc: 23.19%   [EVAL] batch:   38 | acc: 25.00%,  total acc: 23.24%   [EVAL] batch:   39 | acc: 25.00%,  total acc: 23.28%   [EVAL] batch:   40 | acc: 18.75%,  total acc: 23.17%   [EVAL] batch:   41 | acc: 12.50%,  total acc: 22.92%   [EVAL] batch:   42 | acc: 6.25%,  total acc: 22.53%   [EVAL] batch:   43 | acc: 12.50%,  total acc: 22.30%   [EVAL] batch:   44 | acc: 6.25%,  total acc: 21.94%   [EVAL] batch:   45 | acc: 6.25%,  total acc: 21.60%   [EVAL] batch:   46 | acc: 56.25%,  total acc: 22.34%   [EVAL] batch:   47 | acc: 50.00%,  total acc: 22.92%   [EVAL] batch:   48 | acc: 0.00%,  total acc: 22.45%   [EVAL] batch:   49 | acc: 0.00%,  total acc: 22.00%   [EVAL] batch:   50 | acc: 0.00%,  total acc: 21.57%   [EVAL] batch:   51 | acc: 0.00%,  total acc: 21.15%   [EVAL] batch:   52 | acc: 0.00%,  total acc: 20.75%   [EVAL] batch:   53 | acc: 31.25%,  total acc: 20.95%   [EVAL] batch:   54 | acc: 12.50%,  total acc: 20.80%   [EVAL] batch:   55 | acc: 62.50%,  total acc: 21.54%   [EVAL] batch:   56 | acc: 43.75%,  total acc: 21.93%   [EVAL] batch:   57 | acc: 12.50%,  total acc: 21.77%   [EVAL] batch:   58 | acc: 12.50%,  total acc: 21.61%   [EVAL] batch:   59 | acc: 6.25%,  total acc: 21.35%   [EVAL] batch:   60 | acc: 25.00%,  total acc: 21.41%   [EVAL] batch:   61 | acc: 25.00%,  total acc: 21.47%   [EVAL] batch:   62 | acc: 12.50%,  total acc: 21.33%   [EVAL] batch:   63 | acc: 37.50%,  total acc: 21.58%   [EVAL] batch:   64 | acc: 6.25%,  total acc: 21.35%   